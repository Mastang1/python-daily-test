# 项目路径: C:\temp\pkt_folder
# 打包时间: 当前日期: 2025/12/24 周三 
输入新日期: (年月日)
# 共打包 185 个源文件（已自动排除二进制文件）
#================================================================================

===== 文件 [1/185]: include\Eth_43_PFE.h =====
/**
*   @file       Eth_43_PFE.h
*
*   @brief   AUTOSAR Eth driver interface header file
*   @details Implementation of the AUTOSAR Ethernet driver
*
*   @addtogroup ETH_43_PFE_DRIVER
*   @{
*/
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  (c) Copyright 2006-2016 Freescale Semiconductor, Inc.
 *      Copyright 2017-2024 NXP
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/

#ifndef ETH_43_PFE_H
#define ETH_43_PFE_H

#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/
#include "Eth_GeneralTypes.h"  /* Mandatory include - see the SWS */
#include "pfe_cfg.h"
#include "oal_types.h"
#include "pfe_tmu.h"
#include "Eth_43_PFE_Cfg.h" /* Mandatory include - see the SWS */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define ETH_43_PFE_VENDOR_ID                    43
#define ETH_43_PFE_MODULE_ID                    88
#define ETH_43_PFE_SW_MAJOR_VERSION             1
#define ETH_43_PFE_SW_MINOR_VERSION             5
#define ETH_43_PFE_SW_PATCH_VERSION             0

/*==================================================================================================
*                                     FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
*                                          CONSTANTS
==================================================================================================*/
/* Service IDs definition */
#define ETH_43_PFE_SID_INIT                    0x01
#define ETH_43_PFE_SID_SETCONTROLLERMODE       0x03
#define ETH_43_PFE_SID_GETCONTROLLERMODE       0x04
#define ETH_43_PFE_SID_GETPHYSADDR             0x08
#define ETH_43_PFE_SID_WRITEMII                0x05
#define ETH_43_PFE_SID_READMII                 0x06
#define ETH_43_PFE_SID_PROVIDETXBUFFER         0x09
#define ETH_43_PFE_SID_TRANSMIT                0x0A
#define ETH_43_PFE_SID_RECEIVE                 0x0B
#define ETH_43_PFE_SID_TXCONFIRMATION          0x0C
#define ETH_43_PFE_SID_GETVERSIONINFO          0x0D
#define ETH_43_PFE_SID_SETPHYSADDR             0x13
#define ETH_43_PFE_SID_UPDATEADDRFILTER        0x12
#define ETH_43_PFE_SID_GETCOUNTERVALUE         0x14
#define ETH_43_PFE_SID_GETRXSTATS              0x15
#define ETH_43_PFE_SID_GETCURRENTTIME          0x16
#define ETH_43_PFE_SID_ENABLEEGRESSTIMESTAMP   0x17
#define ETH_43_PFE_SID_GETEGRESSTIMESTAMP      0x18
#define ETH_43_PFE_SID_GETINGRESSTIMESTAMP     0x19
#define ETH_43_PFE_SID_SETCORRECTIONTIME       0x1A
#define ETH_43_PFE_SID_SETGLOBALTIME           0x1B
#define ETH_43_PFE_SID_GETTXSTATS              0x1C
#define ETH_43_PFE_SID_GETTXERRORCOUNTERVALUE  0x1D
#if STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API
    #define ETH_43_PFE_SID_WRITEMII45          0x1E
    #define ETH_43_PFE_SID_READMII45           0x1F
#endif /* STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API */
#define ETH_43_PFE_SID_MAINFUNCTION            0x20
#define ETH_43_PFE_SID_PREINIT                 0x21
#define ETH_43_PFE_SID_GETPLATFORM             0x22
#define ETH_43_PFE_SID_GETCLASSSTATS           0x23
#define ETH_43_PFE_SID_GETBMUSTATS             0x24
#define ETH_43_PFE_SID_GETGPISTATS             0x25
#define ETH_43_PFE_SID_GETL2BRIDGESTATS        0x26
#define ETH_43_PFE_SID_GETL2BRIDGEDOMAINSTATS  0x27
#define ETH_43_PFE_SID_GETWDTSTATS             0x28
#define ETH_43_PFE_SID_GETRTABLESTATS          0x29
#define ETH_43_PFE_SID_GETTMUSTATS             0x2A
#define ETH_43_PFE_SID_DEINIT                  0x2B
#if STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API
    #define ETH_43_PFE_SID_RELEASETXBUFFER     0x2C
#endif  /* STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API */

/* DET error codes */
#if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
#define ETH_43_PFE_E_INV_CTRL_IDX      ((uint8)0x01)
#define ETH_43_PFE_E_UNINIT            ((uint8)0x02)
#define ETH_43_PFE_E_PARAM_POINTER     ((uint8)0x03)
#define ETH_43_PFE_E_INV_PARAM         ((uint8)0x04)
#define ETH_43_PFE_E_INV_MODE          ((uint8)0x05)
#endif
/* Define Specific Error code for Std_ReturnType */
#define ETH_43_PFE_E_NO_ACCESS         ((uint8)0x03U)
#define ETH_43_PFE_E_AGAIN             ((uint8)0x04U)

/*==================================================================================================
*                                      DEFINES AND MACROS
==================================================================================================*/
#define ETH_43_PFE_PHY_ADDR_MAX              0x1FU
#define ETH_43_PFE_PHY_REG_ADDR_MII22_MAX    0x1FU
#define ETH_43_PFE_PHY_DEV_MII45_MAX         0x1FU
#define PFE_INVALID_STAT                     0xFFFFFFFFU
#define PFE_BMU_NUMBER_MAX_MAS_BUFF_CNT      32U
#define PFE_TMU_PHY_CNT                      6U
#define PFE_TMU_PHY_QUEUE_CNT                8U

/*==================================================================================================
*                                             ENUMS
==================================================================================================*/

/*==================================================================================================
*                                STRUCTURES AND OTHER TYPEDEFS
==================================================================================================*/
typedef struct
{
    uint32 bmu_debug_bus;
    uint32 buff_base;
    uint32 buff_remain;
    uint32 buff_allocated;
    uint32 low_watermark;
    uint32 high_watermark;
    uint32 irq_threshold;
    uint32 free_error_add;
    uint32 irq_source;
    uint32 irq_enable;
    uint32 master_buf_count[PFE_BMU_NUMBER_MAX_MAS_BUFF_CNT];
    uint32 revision;
    uint32 version;
    uint32 id;
    uint32 free_error_cnt;
    uint32 active_buff;
    uint32 buff_size;
}Eth_43_PFE_BmuStatsType;

typedef struct
{
    uint32 fifo_debug;
    uint32 tx_debug_reg1;
    uint32 tx_debug_reg2;
    uint32 tx_debug_reg3;
    uint32 tx_debug_reg4;
    uint32 tx_debug_reg5;
    uint32 tx_debug_reg6;
    uint32 rx_debug_reg1;
    uint32 rx_debug_reg2;
    uint32 fifo_status;
    uint32 revision;
    uint32 version;
    uint32 id;
    uint32 iqos_queue_status;
    uint32 iqos_class_drop_cnt;
    uint32 iqos_lmem_drop_cnt;
    uint32 iqos_dmem_drop_cnt;
    uint32 iqos_rxf_drop_cnt;
    uint32 iqos_shp0_drop_cnt;
    uint32 iqos_shp1_drop_cnt;
    uint32 iqos_manage_pkts;
    uint32 iqos_unmanage_pkts;
    uint32 iqos_reserved_pkts;
    uint32 tx_underrun;
    uint32 tx_fifo_packets;
    uint32 rx_fifo_packets;
    uint32 tx_fifo_level;
    uint32 rx_fifo_level;
    uint32 aseq_length;
    uint32 enable_reg_1588;
    uint32 overrun_drop_cnt;
}Eth_43_PFE_GpiStatsType;

typedef struct
{
    uint32 wdp_version;
    uint32 wdt_int_en;
    uint32 class_wdt_int_en;
    uint32 upe_wdt_int_en;
    uint32 hgpi_wdt_int_en;
    uint32 hif_wdt_int_en;
    uint32 tlite_wdt_int_en;
    uint32 hncpy_wdt_int_en;
    uint32 bmu1_wdt_int_en;
    uint32 bmu2_wdt_int_en;
    uint32 emac0_wdt_int_en;
    uint32 emac1_wdt_int_en;
    uint32 emac2_wdt_int_en;
    uint32 ext_gpt_wdt_int_en;
    uint32 lmem_wdt_int_en;
    uint32 wdt_int_src;
    uint32 wdt_timer_val_upe;
    uint32 wdt_timer_val_bmu;
    uint32 wdt_timer_val_hif;
    uint32 wdt_timer_val_tlite;
    uint32 wdt_timer_val_hif_ncpy;
    uint32 wdt_timer_val_class;
    uint32 wdt_timer_val_gpi;
    uint32 wdt_timer_val_gpt;
    uint32 wdt_timer_val_lmem;
    uint32 wdt_timer_val_route_lmem;
    uint32 wsp_dbug_bus1_g3;
    uint32 wsp_dbug_bus1;
}Eth_43_PFE_WdtStatsType;

typedef struct
{
    uint8 mac_address[6];
    uint32 vlan;
    uint32 action_data;
    uint32 col_ptr;
    uint32 flags;
    uint32 mac_entries_count;
}Eth_43_PFE_L2BridgeStatsType;

typedef struct
{
    uint32 tmu_phy_inq_pktptr;
    uint32 tmu_phy_inq_pktinfo;
    uint32 tmu_phy_inq_stat;
    uint32 tmu_dbg_bus_stop;
    uint32 tmu_dbg_bus_pp0;
    uint32 tmu_dbg_bus_pp1;
    uint32 tmu_dbg_bus_pp2;
    uint32 tmu_dbg_bus_pp3;
    uint32 tmu_dbg_bus_pp4;
    uint32 tmu_dbg_bus_pp5;
    uint32 revision;
    uint32 version;
    uint32 id;
    uint32 ctrl;
    pfe_tmu_queue_stats aQueue[PFE_TMU_PHY_CNT][PFE_TMU_PHY_QUEUE_CNT]; 
}Eth_43_PFE_TmuStatsType;
/*==================================================================================================
*                                GLOBAL VARIABLE DECLARATIONS
==================================================================================================*/
#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* Eth_43_PFE_CtrlState: Used to store state of Eth controller(s). */
extern volatile Eth_StateType Eth_43_PFE_CtrlState[ETH_43_PFE_MAXCTRLS_SUPPORTED];

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
extern const Eth_43_PFE_ConfigType * Eth_43_PFE_InternalCfgPtr;
#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                    FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

extern void Eth_43_PFE_PreInit(const Eth_43_PFE_ConfigType * CfgPtr);
extern void Eth_43_PFE_Init(const Eth_43_PFE_ConfigType * CfgPtr);
extern void Eth_43_PFE_DeInit(void);
extern Std_ReturnType Eth_43_PFE_SetControllerMode ( \
                                    uint8 u8CtrlIdx, \
                                    Eth_ModeType CtrlMode \
                                                            );
extern Std_ReturnType Eth_43_PFE_GetControllerMode ( \
                                    uint8 u8CtrlIdx, \
                                    Eth_ModeType * CtrlModePtr \
                                                            );
extern void Eth_43_PFE_GetPhysAddr ( \
                        uint8 u8CtrlIdx, \
                        uint8 * PhysAddrPtr \
                                            );
extern void Eth_43_PFE_SetPhysAddr(uint8 u8CtrlIdx, const uint8 * PhysAddrPtr);

extern Std_ReturnType Eth_43_PFE_UpdatePhysAddrFilter ( \
                                    uint8 u8CtrlIdx, \
                                    const uint8 * PhysAddrPtr, \
                                    Eth_FilterActionType Action \
                                                            );

extern BufReq_ReturnType Eth_43_PFE_ProvideTxBuffer( \
                                uint8 u8CtrlIdx, \
                                uint8 Priority, \
                                Eth_BufIdxType * BufIdxPtr, \
                                uint8 **BufPtr, \
                                uint16 * LenBytePtr \
                                                            );
extern Std_ReturnType Eth_43_PFE_Transmit  (
                            uint8 u8CtrlIdx,
                            Eth_BufIdxType BufIdx,
                            Eth_FrameType FrameType,
                            boolean TxConfirmation,
                            uint16 LenByte,
                            const uint8 * PhysAddrPtr
                                                    );
extern void Eth_43_PFE_Receive(uint8 u8CtrlIdx, \
                                    uint8 FifoIdx,  \
                                    Eth_RxStatusType * RxStatusPtr   \
                                 ) ;
extern void Eth_43_PFE_TxConfirmation(uint8 u8CtrlIdx);

#if STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API
extern BufReq_ReturnType Eth_43_PFE_ReleaseTxBuffer(uint8 u8CtrlIdx, Eth_BufIdxType BufIdx);
#endif  /* STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API */

#if STD_ON == ETH_43_PFE_CTRLENABLE_MII
extern Std_ReturnType Eth_43_PFE_WriteMii(uint8 u8CtrlIdx, \
                                            uint8 u8TrcvIdx, \
                                            uint8 u8RegIdx, \
                                            uint16 u16RegVal
                                        );

extern Std_ReturnType Eth_43_PFE_ReadMii(uint8 u8CtrlIdx, \
                                            uint8 u8TrcvIdx, \
                                            uint8 u8RegIdx, \
                                            uint16 * pu16RegValPtr
                                        );

#if STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API
extern Std_ReturnType Eth_43_PFE_WriteMii45(uint8 u8CtrlIdx, \
                                            uint8 u8TrcvIdx, \
                                            uint8 u8DevIdx, \
                                            uint16 u16RegIdx, \
                                            uint16 u16RegVal
                                        );

extern Std_ReturnType Eth_43_PFE_ReadMii45(uint8 u8CtrlIdx, \
                                            uint8 u8TrcvIdx, \
                                            uint8 u8DevIdx, \
                                            uint16 u16RegIdx, \
                                            uint16 * pu16RegValPtr
                                        );
#endif /* STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API */
#endif /* STD_OFF == ETH_43_PFE_CTRLENABLE_MII */

#if STD_ON == ETH_43_GET_CLASS_STATISTIC_API
extern Std_ReturnType Eth_43_PFE_GetClassStats(pfe_ct_classify_stats_t * stat);
#endif /* ETH_43_GET_CLASS_STATISTIC_API */

#if STD_ON == ETH_43_GET_PFE_STATISTIC_API
extern Std_ReturnType Eth_43_PFE_GetTmuStats(Eth_43_PFE_TmuStatsType * stat);
extern Std_ReturnType Eth_43_PFE_GetRtableStats(pfe_ct_conntrack_stats_t * stat, uint8 conntrack_index);
extern Std_ReturnType Eth_43_PFE_GetL2BridgeDomainStats(pfe_ct_vlan_stats_t* stat, uint32 index_vlan);
extern Std_ReturnType Eth_43_PFE_GetL2BridgeStats(Eth_43_PFE_L2BridgeStatsType * stat, uint32 index_entry);
extern Std_ReturnType Eth_43_PFE_GetWdtStats(Eth_43_PFE_WdtStatsType * stat);
extern Std_ReturnType Eth_43_PFE_GetGpiStats(uint8 u8GpiIndex, Eth_43_PFE_GpiStatsType * stat);
extern Std_ReturnType Eth_43_PFE_GetBmuStats(uint8 u8BmuIndex, Eth_43_PFE_BmuStatsType* stat);
#endif /* ETH_43_GET_PFE_STATISTIC_API */

#if STD_ON == ETH_43_GET_COUNTER_API
extern Std_ReturnType Eth_43_PFE_GetCounterValues(uint8 u8CtrlIdx, \
                                            Eth_CounterType * CounterPtr
                                        );
#endif /* STD_ON == ETH_43_GET_COUNTER_API */

#if STD_ON == ETH_43_GET_RXSTATS_API
extern Std_ReturnType Eth_43_PFE_GetRxStats(uint8 u8CtrlIdx, \
                                            Eth_RxStatsType * RxStatsPtr
                                        );
#endif /* STD_ON == ETH_43_GET_RXSTATS_API */

#if STD_ON == ETH_43_GET_TXSTATS_API
extern Std_ReturnType Eth_43_PFE_GetTxStats(uint8 u8CtrlIdx, \
                                            Eth_TxStatsType * TxStatsPtr
                                        );
#endif /* STD_ON == ETH_43_GET_TXSTATS_API */

#if STD_ON == ETH_43_GET_TXERROR_COUNTER_API
extern Std_ReturnType Eth_43_PFE_GetTxErrorCounterValues(uint8 u8CtrlIdx, \
                                            Eth_TxErrorCounterValuesType * TxErrorCounterValuesPtr
                                        );
#endif /* STD_ON == ETH_43_GET_TXERROR_COUNTER_API */

#if STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API
extern Std_ReturnType Eth_43_PFE_ChannelBdFlushRx(pfe_ct_phy_if_id_t slaveHifPhyIfID);
#endif /* STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API */

#if STD_ON == ETH_43_PFE_VERSION_INFO_API
    #if STD_OFF == ETH_43_PFE_VERSION_INFO_API_MACRO
        extern void Eth_43_PFE_GetVersionInfo(Std_VersionInfoType * VersionInfoPtr);
    #endif /* ETH_43_PFE_VERSION_INFO_API_MACRO */
#endif /* ETH_43_PFE_VERSION_INFO_API */
extern void Eth_43_PFE_MainFunction(void);
extern void * Eth_43_PFE_GetPlatform(void);

#if STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT
extern Std_ReturnType Eth_43_PFE_SetGlobalTime  (   uint8 u8CtrlIdx, \
                                                    const Eth_TimeStampType *timeStampPtr \
                                                );
extern Std_ReturnType Eth_43_PFE_SetCorrectionTime  (   uint8 u8CtrlIdx, \
                                                        const Eth_TimeIntDiffType *timeOffsetPtr, \
                                                        const Eth_RateRatioType *rateRatioPtr \
                                                    );
extern Std_ReturnType Eth_43_PFE_GetCurrentTime (   uint8 u8CtrlIdx, \
                                                    Eth_TimeStampQualType *timeQualPtr, \
                                                    Eth_TimeStampType *timeStampPtr \
                                                );
extern Std_ReturnType Eth_43_PFE_GetEgressTimeStamp (   uint8 u8CtrlIdx, \
                                                        Eth_BufIdxType BufIdx, \
                                                        Eth_TimeStampQualType *timeQualPtr, \
                                                        Eth_TimeStampType *timeStampPtr \
                                                    );
extern Std_ReturnType Eth_43_PFE_GetIngressTimeStamp(   uint8 u8CtrlIdx, \
                                                        const Eth_DataType *DataPtr, \
                                                        Eth_TimeStampQualType *timeQualPtr, \
                                                        Eth_TimeStampType *timeStampPtr \
                                                    );
extern void Eth_43_PFE_EnableEgressTimeStamp(uint8 u8CtrlIdx, Eth_BufIdxType BufIdx);
#endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#ifdef __cplusplus
}
#endif

#endif /* ETH_43_PFE_H */

/** @} */


===== 文件 [2/185]: include\Eth_43_PFE_Irq.h =====
/**
 *  @file    Eth_43_PFE_Irq.h
 *
 *  @brief AUTOSAR Eth driver interrupt handlers prototypes
 *  @details Prototypes of interrupt handling routines for the Ethernet driver.
 *
 *  @addtogroup ETH_43_PFE_DRIVER
 *  @{
 */
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  (c) Copyright 2006-2016 Freescale Semiconductor, Inc.
 *      Copyright 2017-2022 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/
#ifndef ETH_43_PFE_IRQ_H
#define ETH_43_PFE_IRQ_H

#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
/*==================================================================================================
*                                     FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
*                                          CONSTANTS
==================================================================================================*/

/*==================================================================================================
*                                      DEFINES AND MACROS
==================================================================================================*/

/*==================================================================================================
*                                             ENUMS
==================================================================================================*/

/*==================================================================================================
*                                STRUCTURES AND OTHER TYPEDEFS
==================================================================================================*/

/*==================================================================================================
*                                GLOBAL VARIABLE DECLARATIONS
==================================================================================================*/

/*==================================================================================================
*                                    FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
#if (TRUE == ETH_43_PFE_USINGHIF0)
extern ISR(Eth_43_PFE_HifIrqHdlr_0);
#endif /* ETH_43_PFE_USINGHIF0 */
#if (TRUE == ETH_43_PFE_USINGHIF1)
extern ISR(Eth_43_PFE_HifIrqHdlr_1);
#endif /* ETH_43_PFE_USINGHIF1 */
#if (TRUE == ETH_43_PFE_USINGHIF2)
extern ISR(Eth_43_PFE_HifIrqHdlr_2);
#endif /* ETH_43_PFE_USINGHIF2 */
#if (TRUE == ETH_43_PFE_USINGHIF3)
extern ISR(Eth_43_PFE_HifIrqHdlr_3);
#endif /* ETH_43_PFE_USINGHIF3 */
#if (TRUE == ETH_43_PFE_USINGHIF_NOCPY)
extern ISR(Eth_43_PFE_HifNoCpyIrqHdlr);
#endif /* ETH_43_PFE_USINGHIF_NOCPY */
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
extern ISR(Eth_43_PFE_BmuIrqHdlr);
#endif /* PFE_CFG_BMU_IRQ_ENABLED */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#ifdef __cplusplus
}
#endif

#endif /* ETH_43_PFE_IRQ_H */

/** @} */


===== 文件 [3/185]: include\Eth_PFE_LLD.h =====
/**
*   @file    Eth_PFE_LLD.h
*
*   @brief   PFE controller interface header file
*   @details Implementation of the PFE controller interface for
*            the Ethernet driver
*
*   @addtogroup ETH_43_PFE_DRIVER
*   @{
*/
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  (c) Copyright 2006-2016 Freescale Semiconductor, Inc.
 *      Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/
#ifndef ETH_PFE_LLD_H
#define ETH_PFE_LLD_H
#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "oal.h"
#include "pfe_platform.h"
#include "linked_list.h"
#include "pfe_hif_drv.h"

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/

/*==================================================================================================
*                                     FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
*                                          TYPEDEFS
==================================================================================================*/
typedef  struct
{
    uint16 u16BufIdx;
    uint8  u8CtrlIdx;
} Eth_PFE_LLD_trTxRefData;

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
typedef struct
{
    uint8  u8MessageType;
    uint16 u16SourcePortID;
    uint16 u16SequenceID;
} Eth_PFE_LLD_trTxTsRef;
#endif

typedef struct
{
    boolean bDoTxIndication;
    boolean bDoTS; /* Used in pfe_hif_drv to request timestamp on demand */
} trTxMeta;

/*==================================================================================================
*                                          CONSTANTS
==================================================================================================*/

/*==================================================================================================
*                                      DEFINES AND MACROS
==================================================================================================*/
#define PFE_LLD_L2_HEADER_SIZE        14U
#if (STD_ON == ETH_43_PFE_ENABLE_USER_MODE_SUPPORT)
    #define Local_Macro_hal_ip_ready_set(on)    OsIf_Trusted_Call1param(hal_ip_ready_set, (on))
    #define Local_Macro_hal_ip_ready_get()      OsIf_Trusted_Call_Return(hal_ip_ready_get)
#else
    #define Local_Macro_hal_ip_ready_set(on)    hal_ip_ready_set(on)
    #define Local_Macro_hal_ip_ready_get()      hal_ip_ready_get()
#endif

/*==================================================================================================
*                                       GLOBAL VARABLES
==================================================================================================*/
#if ((TRUE == PFE_CFG_HIF_IRQ_ENABLED) || (TRUE == PFE_CFG_BMU_IRQ_ENABLED))
#define ETH_43_PFE_START_SEC_VAR_CLEARED_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
extern volatile boolean Eth_PFE_LLD_bIrqInitStatus;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
#endif

/*==================================================================================================
*                                      FUNCTION PROTOTYPES
==================================================================================================*/

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
extern boolean Eth_PFE_LLD_Check_Driver_Init(void);
extern void Eth_PFE_LLD_ReportTransmission
(
    const uint8 u8CtrlIdx, const uint8 u8FifoIdx
);

#if STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API
boolean Eth_PFE_LLD_ReleaseTxBuffer(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx);
#endif

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
extern void Eth_PFE_LLD_ReportTransmissionTS(const uint8 u8CtrlIdx, const uint8 u8FifoIdx);
extern Eth_PFE_LLD_trTxTsRef *Eth_PFE_LLD_GetTxBufTsRef(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx);
#endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */
extern Eth_ModeType Eth_PFE_LLD_CheckControllerIsActive(const uint8 u8CtrlIdx);
extern boolean Eth_PFE_LLD_EnableController(const uint8 u8CtrlIdx);
extern Std_ReturnType Eth_PFE_LLD_ConfigureController(const uint8 u8CtrlIdx);
extern boolean Eth_PFE_LLD_CheckInitializationStatus(const uint8 u8CtrlIdx);
extern Std_ReturnType Eth_PFE_LLD_DisableController(const uint8 u8CtrlIdx);
extern void Eth_PFE_LLD_InitInterfaces
(
    const Eth_43_PFE_ConfigType * cfgPtr
);
extern void Eth_PFE_LLD_InitEMACs
(
    const Eth_43_PFE_ConfigType * cfgPtr
);
extern void Eth_PFE_LLD_GetPhysicalAddress
(
    const uint8 u8CtrlIdx,
    uint8 * pu8PhysAddr
);
extern boolean Eth_PFE_LLD_SetPhysAddr
(
    const uint8 u8CtrlIdx,
    const uint8 * pPhysAddrPtr
);
extern Std_ReturnType Eth_PFE_LLD_UpdatePhysAddrFilter
(
    uint8 u8CtrlIdx,
    const uint8 * PhysAddrPtr,
    Eth_FilterActionType Action
);
extern Eth_RxStatusType Eth_PFE_LLD_ReportReception
(
    const uint8 u8CtrlIdx,
    uint8 u8FifoIdx,
    const boolean bIrq
);
extern uint16 Eth_43_PFE_LLD_GetLmemHdrSize(const uint8 u8CtrlIdx);
extern uint8 Eth_43_PFE_LLD_GetTxFifoIdx
(
    const uint8 u8CtrlIdx,
    const Eth_BufIdxType BufIdx
);
extern uint32 Eth_43_PFE_LLD_GetTxBufferSize
(
    const uint8 u8CtrlIdx,
    const uint8 u8FifoIdx
);
extern Std_ReturnType Eth_PFE_LLD_Transmit
(
    const uint8 u8CtrlIdx,
    const Eth_BufIdxType BufIdx,
    const Eth_FrameType u16Type,
    const uint16 u16Length,
    const boolean bConfirm,
    const uint8 * pDest
);
extern boolean Eth_PFE_LLD_ProvideBufferDataArea
(
    const uint8 u8CtrlIdx,
    const uint8 u8QueuIdx,
    Eth_BufIdxType * const pBufIdx,
    uint8 **pData,
    uint16 * const pLength
);
extern void Eth_PFE_LLD_MainFunction(void);
extern Std_ReturnType Eth_PFE_LLD_PlatformDrvPrepare(void);
extern void Eth_PFE_LLD_DeInit(void);
extern void Eth_PFE_LLD_InterfacePrepare(uint8 u8CtrlIdx);

#ifndef PFE_CFG_PFE_SLAVE
extern void Eth_PFE_LLD_EMACPrepare(void);
#endif

#if STD_ON == ETH_43_PFE_CTRLENABLE_MII
extern Std_ReturnType Eth_43_PFE_LLD_WriteMii
(
    uint8 u8CtrlIdx,
    uint8 u8TrcvIdx,
    uint8 u8RegIdx,
    uint16 u16RegVal
);

extern Std_ReturnType Eth_43_PFE_LLD_ReadMii
(
    uint8 u8CtrlIdx,
    uint8 u8TrcvIdx,
    uint8 u8RegIdx,
    uint16 * pu16RegValPtr
);

#if STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API
extern Std_ReturnType Eth_43_PFE_LLD_WriteMii45
(
    uint8 u8CtrlIdx,
    uint8 u8TrcvIdx,
    uint8 u8DevIdx,
    uint16 u16RegIdx,
    uint16 u16RegVal
);

extern Std_ReturnType Eth_43_PFE_LLD_ReadMii45
(
    uint8 u8CtrlIdx,
    uint8 u8TrcvIdx,
    uint8 u8DevIdx,
    uint16 u16RegIdx,
    uint16 * pu16RegValPtr
);
#endif /* STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API */
#endif /* STD_OFF == ETH_43_PFE_CTRLENABLE_MII */

#if STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT
extern Std_ReturnType Eth_43_PFE_LLD_SetGlobalTime  (   uint8 u8CtrlIdx, \
                                                        const Eth_TimeStampType *pTimeStampPtr \
                                                    );
extern Std_ReturnType Eth_43_PFE_LLD_SetCorrectionTime (   uint8 u8CtrlIdx, \
                                                           const Eth_TimeIntDiffType *pTimeOffsetPtr, \
                                                           const Eth_RateRatioType *pRateRatioPtr \
                                                        );
extern void Eth_43_PFE_LLD_GetCurrentTime   (   uint8 u8CtrlIdx, \
                                                Eth_TimeStampQualType *timeQualPtr, \
                                                Eth_TimeStampType *timeStampPtr \
                                            );
extern errno_t Eth_43_PFE_LLD_GetRxTimeStamp(  uint8 u8CtrlIdx, \
                                               const Eth_DataType *DataPtr, \
                                               Eth_TimeStampQualType *timeQualPtr, \
                                               Eth_TimeStampType *timeStampPtr \
                                            );
extern void Eth_43_PFE_LLD_GetTxTimeStamp( uint8 u8CtrlIdx, \
                                           Eth_BufIdxType BufIdx, \
                                           Eth_TimeStampQualType *timeQualPtr, \
                                           Eth_TimeStampType *timeStampPtr \
                                         );

extern void Eth_43_PFE_LLD_EnableEgressTimeStamp(uint8 u8CtrlIdx, Eth_BufIdxType BufIdx);
#endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */

extern void * Eth_PFE_LLD_GetPlatform(void);

#if STD_ON == ETH_43_GET_CLASS_STATISTIC_API
extern Std_ReturnType Eth_43_PFE_LLD_GetClassStats(pfe_ct_classify_stats_t * stat);
#endif /* ETH_43_GET_CLASS_STATISTIC_API */

#if STD_ON == ETH_43_GET_PFE_STATISTIC_API
extern Std_ReturnType Eth_43_PFE_LLD_GetTmuStats(Eth_43_PFE_TmuStatsType * stat);
extern Std_ReturnType Eth_43_PFE_LLD_GetRtableStats(pfe_ct_conntrack_stats_t * stat, uint8 conntrack_index);
extern Std_ReturnType Eth_43_PFE_LLD_GetL2BridgeDomainStats(pfe_ct_vlan_stats_t * stat, uint8 index_vlan);
extern Std_ReturnType Eth_43_PFE_LLD_GetL2BridgeStats(Eth_43_PFE_L2BridgeStatsType * stat, uint32 index_entry);
extern Std_ReturnType Eth_43_PFE_LLD_GetWdtStats(Eth_43_PFE_WdtStatsType * stat);
extern Std_ReturnType Eth_43_PFE_LLD_GetGpiStats(uint8 u8GpiIndex, Eth_43_PFE_GpiStatsType * stat);
extern Std_ReturnType Eth_43_PFE_LLD_GetBmuStats(uint8 u8BmuIndex, Eth_43_PFE_BmuStatsType* stat);
#endif /* ETH_43_GET_PFE_STATISTIC_API */

#if STD_ON == ETH_43_GET_COUNTER_API
extern Std_ReturnType Eth_PFE_LLD_GetCounterValues(uint8 u8CtrlIdx, \
                                            Eth_CounterType * CounterPtr
                                        );
#endif /* STD_ON == ETH_43_GET_COUNTER_API */

#if STD_ON == ETH_43_GET_RXSTATS_API
extern Std_ReturnType Eth_PFE_LLD_GetRxStats(uint8 u8CtrlIdx, \
                                            Eth_RxStatsType * RxStatsPtr
                                        );
#endif /* STD_ON == ETH_43_GET_RXSTATS_API */

#if STD_ON == ETH_43_GET_TXSTATS_API
extern Std_ReturnType Eth_PFE_LLD_GetTxStats(uint8 u8CtrlIdx, \
                                            Eth_TxStatsType * TxStatsPtr
                                        );
#endif /* STD_ON == ETH_43_GET_TXSTATS_API */

#if STD_ON == ETH_43_GET_TXERROR_COUNTER_API
extern Std_ReturnType Eth_PFE_LLD_GetTxErrorCounterValues(uint8 u8CtrlIdx, \
                                            Eth_TxErrorCounterValuesType * TxErrorCounterValuesPtr
                                        );
#endif /* STD_ON == ETH_43_GET_TXERROR_COUNTER_API */

#if (STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER)
extern Std_ReturnType Eth_PFE_LLD_ChannelBdFlushRx(pfe_ct_phy_if_id_t DestHifChnl);
#endif /* ETH_43_PFE_CHANNEL_BD_FLUSH_API && PFE_CFG_PFE_MASTER */

extern trTxMeta *Eth_PFE_LLD_GetTxBufMeta(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx);

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#ifdef PFE_CFG_PFE_MASTER
extern void Eth_43_PFE_LLD_SetMasterUp(void);
#endif /* PFE_CFG_PFE_MASTER */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#ifdef __cplusplus
}
#endif

#endif /* ETH_PFE_LLD_H */
/** @} */


===== 文件 [4/185]: include\autolibc.h =====
/**
  @file             autolibc.h
  @brief            Header file for the AutoLibc.c
*/
/*==============================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright (c) 2012-2016 Freescale Semiconductor Inc.
 *  Copyright 2016-2018, 2020, 2022-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==============================================================================*/
/*==============================================================================
==============================================================================*/

#ifndef AUTOLIBC_H
#define AUTOLIBC_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*==============================================================================
                                INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==============================================================================*/
#include "pfe_cfg.h"
#include "oal_types.h"

/*==============================================================================
                      SOURCE FILE VERSION INFORMATION
==============================================================================*/

/*==============================================================================
                            FILE VERSION CHECKS
==============================================================================*/

/*==============================================================================
                                 CONSTANTS
==============================================================================*/

/*==============================================================================
                             DEFINES AND MACROS
==============================================================================*/

/*==============================================================================
                                    ENUMS
==============================================================================*/

/*==============================================================================
                        STRUCTURES AND OTHER TYPEDEFS
==============================================================================*/

/*==============================================================================
                         GLOBAL VARIABLE DECLARATIONS
==============================================================================*/

/*==============================================================================
                             FUNCTION PROTOTYPES
==============================================================================*/

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

extern void *autolibc_memcpy (void *pavDest2, const void *pcoavSource2, uint32 u32Length2);
extern void *autolibc_memset (void *pavDest3, sint32 s32Fill3, uint32 u32Length3);
extern void *autolibc_memmove (void *pavDest4, const void *pcoavSource4, uint32 u32Length4);
extern sint32 autolibc_memcmp (const void *pcoavMemA5, const void *pcoavMemB5, uint32 u32Size5);
extern sint32 autolibc_strcmp (const char_t *pcoszStrA6, const char_t *pcoszStrB6);
extern char_t *autolibc_strncpy (char_t *pszDest7, const char_t *pcoszSrc7, uint32 u32Length7);
extern uint32 autolibc_strlen (const char_t pcozsStr8[]);
extern char_t *autolibc_strcpy(char_t *pszDest, const char_t *pcoszSrc);
extern uint32 autolibc_strnlen(const char_t pcozsStr8[], uint32 u32Strsz);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


#endif /* AUTOLIBC_H */


===== 文件 [5/185]: include\blalloc.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */



#ifndef SRC_BLALLOC_H_
#define SRC_BLALLOC_H_


/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/**
 * @brief   Number of chunks encoded within single byte. Not intended to be modified.
 */
#define BLALLOC_CFG_CHUNKS_IN_BYTE 4U

/**
 * @brief   Block allocator instance status
 */
typedef enum
{
    BL_INVALID = 0,
    BL_DYNAMIC = 10,
    BL_STATIC = 20
} blalloc_status_t;

/**
 * @brief      Block allocator context representation
 */
typedef struct
{
    uint32 size;      /* Size */
    uint32 chunk_size;/* Size of a memory chunk is 2^this_value */
    uint32 start_srch;/* Remember position of the 1st free chunk */
    uint32 allocated; /* Sum of all allocated bytes (including those freed and allocated again) */
    uint32 requested; /* Sum of all requested bytes to be allocated */
    blalloc_status_t status;   /* Instance status */
    uint8 *chunkinfo;/* Pointer to free space that follows this struct */
    /* The free space for chunkinfo will be here (if extra size was allocated) */
} blalloc_t;

/**
 * @brief   Static block allocator instance constructor
 * @details Intended to be used to create static block allocator instances. Static instances
 *          shall be initialized and finalized using blalloc_init() and blalloc_fini() calls
 *          instead of dynamic blalloc_create() and blalloc_destroy().
 */
#define BLALLOC_STATIC_INST(__name, __size, __chunk_size) \
static uint8 blalloc_buf_##__name[((((__size) >> (__chunk_size)) + BLALLOC_CFG_CHUNKS_IN_BYTE - 1U) / BLALLOC_CFG_CHUNKS_IN_BYTE)] = {0U}; \
static blalloc_t __name = \
    { \
        .chunkinfo = blalloc_buf_##__name, \
        .size = (__size), \
        .chunk_size = (__chunk_size) \
    }

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

blalloc_t *blalloc_create(uint32 size, uint32 chunk_size);
void blalloc_destroy(blalloc_t *ctx);
errno_t blalloc_init(blalloc_t *ctx);
void blalloc_fini(blalloc_t *ctx);
errno_t blalloc_alloc_offs(blalloc_t *ctx, uint32 size, uint32 align, addr_t *addr);
void blalloc_free_offs(blalloc_t *ctx, addr_t offset);

#if defined(PFE_CFG_TEXT_STATS)
uint32 blalloc_get_text_statistics(const blalloc_t *ctx, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* SRC_BLALLOC_H_ */


===== 文件 [6/185]: include\ct_assert.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 * Original code: https://www.pixelbeat.org/programming/gcc/static_assert.html
 * Licensed under the GNU All-Permissive License.
 *
 * Modifications Copyright 2018-2022 NXP
 *
 * ========================================================================= */
 
#ifndef CT_ASSERT_H
#define CT_ASSERT_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#define STRINGIFY(x) #x
#define TOSTRING(x) STRINGIFY(x)

#define ASSERT_CONCAT_(a, b) a##b
#define ASSERT_CONCAT(a, b) ASSERT_CONCAT_(a, b)

#define ct_assert(e) enum { ASSERT_CONCAT(precompile_assert_, __COUNTER__) = (1/(!!(e))) }

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
    /* The compiler options for MCAL driver generate errors or warnings when offsetof is used inside of ct_assert.
    So it is not possible to assert offset of structures at compile time for MCAL driver.
    This is done at runtime in test case Eth_43_PFE_TC_CT_ASSERT in test suite Eth_43_PFE_TS_017.
    Therefore ct_assert_offsetof is a dummy implementation on MCAL driver.
    */
    #define ct_assert_offsetof(e) enum { ASSERT_CONCAT(precompile_assert_, __COUNTER__) = 1 } 
#else
    #define ct_assert_offsetof(e) enum { ASSERT_CONCAT(precompile_assert_, __COUNTER__) = 1/(!!(e)) }
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#endif /* CT_ASSERT_H */


===== 文件 [7/185]: include\elf.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @defgroup    dxgr_ELF ELF Parser
 * @brief       The ELF parser
 * @details
 *
 * @addtogroup dxgr_ELF
 * @{
 *
 * @file            elf.h
 * @version         0.0.0.0
 *
 * @brief           Header file for the ELF module.
 *
 */
/*==================================================================================================
==================================================================================================*/

/*==================================================================================================
                                         MISRA VIOLATIONS
==================================================================================================*/

#ifndef ELF_H
    #define ELF_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*==================================================================================================
                                         INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==================================================================================================*/
#include "oal.h"

/*==================================================================================================
                               SOURCE FILE VERSION INFORMATION
==================================================================================================*/

/*==================================================================================================
                                      FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
                                           CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       DEFINES AND MACROS
==================================================================================================*/
#define ELF_NIDENT                  16U
#define ELF_NAMED_SECT_IDX_FLAG     0x80000000U

/* Macros for change of endianness */
#define ENDIAN_SW_2B(VAL) ( (((VAL)&0xFF00U)>>8U) | (((VAL)&0x00FFU)<<8U) )
#define ENDIAN_SW_4B(VAL) ( (((VAL)&0xFF000000U)>>24U) | (((VAL)&0x000000FFU)<<24U) \
                          | (((VAL)&0x00FF0000U)>>8U) | (((VAL)&0x0000FF00U)<<8U) \
                          )
#define ENDIAN_SW_8B(VAL) ( (((VAL)&0xFF00000000000000U)>>56U) | (((VAL)&0x00000000000000FFU)<<56U) \
                          | (((VAL)&0x00FF000000000000U)>>40U) | (((VAL)&0x000000000000FF00U)<<40U) \
                          | (((VAL)&0x0000FF0000000000U)>>24U) | (((VAL)&0x0000000000FF0000U)<<24U) \
                          | (((VAL)&0x000000FF00000000U)>>8U ) | (((VAL)&0x00000000FF000000U)<<8U ) \
                          )
/*==================================================================================================
                                             ENUMS
==================================================================================================*/
enum
{
    EI_MAG0         = 0, /* 0x7F */
    EI_MAG1         = 1, /* 'E' */
    EI_MAG2         = 2, /* 'L' */
    EI_MAG3         = 3, /* 'F' */
    EI_CLASS        = 4, /* Architecture 32-bit Architecture or 64-bit Architecture */
    EI_DATA         = 5, /* Byte Order */
    EI_VERSION      = 6, /* ELF Version */
    EI_OSABI        = 7, /* OS Specific */
    EI_ABIVERSION   = 8, /* OS Specific */
    EI_PAD          = 9  /* Padding */
};

/* any section that is of type SHT_NOBITS and has the attribute SHF_ALLOC should be allocated */
enum
{
    SHT_NULL      = 0U,   /* Null section */
    SHT_PROGBITS  = 1U,   /* Program information */
    SHT_SYMTAB    = 2U,   /* Symbol table */
    SHT_STRTAB    = 3U,   /* String table */
    SHT_RELA      = 4U,   /* Relocation with addend*/
    SHT_NOBITS    = 8U,   /* Not present in file */
    SHT_REL       = 9U,   /* Relocation (no addend) */
};

enum
{
    SHF_WRITE = 0x1, /* Writable */
    SHF_ALLOC = 0x2, /* Occupies memory during execution */
    SHF_EXECINSTR = 0x4, /* Executable */
    SHF_MERGE = 0x10, /* Might be merged */
    SHF_STRINGS = 0x20, /* Contains nul-terminated strings */
    SHF_INFO_LINK = 0x40, /* 'sh info' contains SHT index */
    SHF_LINK_ORDER = 0x80, /* Preserve order after combining */
    SHF_OS_NONCONFORMING = 0x100, /* Non-standard OS specific handling required */
    SHF_GROUP = 0x200, /* Section is member of a group */
    SHF_TLS = 0x400, /* Section hold thread-local data */
    SHF_MASKOS = 0x0ff00000, /* OS-specific */
    SHF_MASKPROC = (sint32)0xf000000, /* Processor-specific *//* Cast to avoid warning on some compilers */
    SHF_ORDERED = 0x4000000, /* Special ordering requirement (Solaris) */
    SHF_EXCLUDE = 0x8000000, /* Section is excluded unless referenced or allocated (Solaris) */
};

/*==================================================================================================
                                 STRUCTURES AND OTHER TYPEDEFS
==================================================================================================*/
typedef enum
{
    ELF_Arch_None    = 0x00u,
    ELF_Arch_SPARC   = 0x02u,
    ELF_Arch_x86     = 0x03u,
    ELF_Arch_MIPS    = 0x08u,
    ELF_Arch_PowerPC = 0x14u,
    ELF_Arch_ARM     = 0x28u,
    ELF_Arch_SuperH  = 0x2Au,
    ELF_Arch_IA_64   = 0x32u,
    ELF_Arch_x86_64  = 0x3Eu,
    ELF_Arch_AArch64 = 0xB7u,
    ELF_Arch_eXcess  = 0x6Fu,
} ELF_Arch_t;

typedef uint32 Elf32_Off;     /* Unsigned offset */
typedef uint32 Elf32_Addr;    /* Unsigned address */
typedef uint64 Elf64_Off;     /* Unsigned offset */
typedef uint64 Elf64_Addr;    /* Unsigned address */

typedef struct __attribute__((packed))
{
    uint8     e_ident[ELF_NIDENT];
    uint16    e_type;
    uint16    e_machine;
    uint32    e_version;
    Elf32_Addr  e_entry;
    Elf32_Off   e_phoff;
    Elf32_Off   e_shoff;
    uint32    e_flags;
    uint16    e_ehsize;
    uint16    e_phentsize;
    uint16    e_phnum;
    uint16    e_shentsize;
    uint16    e_shnum;
    uint16    e_shstrndx;
} Elf32_Ehdr;
typedef struct __attribute__((packed))
{
    uint8     e_ident[ELF_NIDENT];
    uint16    e_type;
    uint16    e_machine;
    uint32    e_version;
    Elf64_Addr  e_entry;
    Elf64_Off   e_phoff;
    Elf64_Off   e_shoff;
    uint32    e_flags;
    uint16    e_ehsize;
    uint16    e_phentsize;
    uint16    e_phnum;
    uint16    e_shentsize;
    uint16    e_shnum;
    uint16    e_shstrndx;
} Elf64_Ehdr;

typedef struct __attribute__((packed))
{
    uint32   p_type;
    Elf32_Off  p_offset;
    Elf32_Addr p_vaddr;
    Elf32_Addr p_paddr;
    uint32   p_filesz;
    uint32   p_memsz;
    uint32   p_flags;
    uint32   p_align;
} Elf32_Phdr;
typedef struct __attribute__((packed))
{
    uint32   p_type;
    uint32   p_flags;
    Elf64_Off  p_offset;
    Elf64_Addr p_vaddr;
    Elf64_Addr p_paddr;
    uint64   p_filesz;
    uint64   p_memsz;
    uint64   p_align;
} Elf64_Phdr;

typedef struct __attribute__((packed))
{
    uint32   sh_name;
    uint32   sh_type;
    uint32   sh_flags;
    Elf32_Addr sh_addr;
    Elf32_Off  sh_offset;
    uint32   sh_size;
    uint32   sh_link;
    uint32   sh_info;
    uint32   sh_addralign;
    uint32   sh_entsize;
} Elf32_Shdr;
typedef struct __attribute__((packed))
{
    uint32   sh_name;
    uint32   sh_type;
    uint64   sh_flags;
    Elf64_Addr sh_addr;
    Elf64_Off  sh_offset;
    uint64   sh_size;
    uint32   sh_link;
    uint32   sh_info;
    uint64   sh_addralign;
    uint64   sh_entsize;
} Elf64_Shdr;

typedef struct __attribute__((packed))
{
    union
    {
        Elf64_Ehdr r64;
        Elf32_Ehdr r32;
        uint8    e_ident[ELF_NIDENT]; /* Direct access, same for both 64 and 32 */
    }          Header;
    Elf64_Phdr *arProgHead64;
    Elf64_Shdr *arSectHead64;
    Elf32_Phdr *arProgHead32;
    Elf32_Shdr *arSectHead32;
    sint8     *acSectNames;
    uint32   u32ProgScanIdx;
    bool_t     bIs64Bit;
    const void __attribute__((aligned(4))) *pvData; /* Raw file */
} ELF_File_t;

/*==================================================================================================
                                 GLOBAL VARIABLE DECLARATIONS
==================================================================================================*/

/*==================================================================================================
                                     FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

extern bool_t ELF_Open(ELF_File_t *pElfFile, const void *pvFile);
extern void ELF_Close(ELF_File_t *pElfFile);

#if TRUE == ELF_CFG_PROGRAM_TABLE_USED
    extern bool_t ELF_ProgSectFindNext( ELF_File_t *pElfFile, uint32 *pu32ProgIdx,
                                         uint64 *pu64LoadVAddr, uint64 *pu64LoadPAddr, uint64 *pu64Length
                                       );
    extern bool_t ELF_ProgSectLoad( const ELF_File_t *pElfFile,
                                     uint32 u32ProgIdx, addr_t AccessAddr, addr_t AllocSize
                                   );
#endif

#if TRUE == ELF_CFG_SECTION_TABLE_USED
    extern bool_t ELF_SectFindName( const ELF_File_t *pElfFile, const char_t *szSectionName,
                                     uint32 *pu32SectIdx, uint64 *pu64LoadAddr, uint64 *pu64Length
                                   );
    extern bool_t ELF_SectLoad( const ELF_File_t *pElfFile,
                                 uint32 u32SectIdx, addr_t AccessAddr, addr_t AllocSize
                               );
#endif

#if TRUE == ELF_CFG_SECTION_PRINT_ENABLED
    extern void ELF_PrintSections(const ELF_File_t *pElfFile);
#endif

/*==================================================================================================
                                    GLOBAL INLINE FUNCTIONS
==================================================================================================*/
/**
* @brief        Provides entry point memory address.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @return       The entry point address
*/
static inline uint64 ELF_GetEntryPoint(const ELF_File_t *pElfFile)
{
    uint64 u64Addr;
    if(TRUE == pElfFile->bIs64Bit)
    {
        u64Addr = pElfFile->Header.r64.e_entry;
    }
    else
    {
        u64Addr = pElfFile->Header.r32.e_entry;
    }
    return u64Addr;
}

/**
* @brief        Makes function ELF_ProgSectFindNext search again from beginning.
* @details      It is not needed to call this function after the ELF is opened.
* @param[out]   pElfFile Structure holding all informations about opened ELF file.
*/
static inline void ELF_ProgSectSearchReset(ELF_File_t *pElfFile)
{
    pElfFile->u32ProgScanIdx = 0U;
}

/**
* @brief        Use to get ELF format if needed.
* @param[in]    pElfFile Structure holding all informations about (partially) opened ELF file.
* @retval       TRUE It is 64bit ELF
* @retval       FALSE It is 32bit ELF
*/
static inline bool_t ELF_Is64bit(const ELF_File_t *pElfFile)
{
    return (2U == pElfFile->Header.e_ident[EI_CLASS]) ? TRUE : FALSE;
}
/**
* @brief        Use to get ELF format if needed.
* @param[in]    pElfFile Structure holding all informations about (partially) opened ELF file.
* @retval       TRUE It is 32bit ELF
* @retval       FALSE It is 64bit ELF
*/
static inline bool_t ELF_Is32bit(const ELF_File_t *pElfFile)
{
    return (1U == pElfFile->Header.e_ident[EI_CLASS]) ? TRUE : FALSE;
}
/**
* @brief        Use to get ELF endianness if needed.
* @param[in]    pElfFile Structure holding all informations about (partially) opened ELF file.
* @retval       TRUE It is BIG endian ELF
* @retval       FALSE It is LITTLE endian ELF
*/
static inline bool_t ELF_IsBigEndian(const ELF_File_t *pElfFile)
{
    return (2U == pElfFile->Header.e_ident[EI_DATA]) ? TRUE : FALSE;
}
/**
* @brief        Use to get ELF endianness if needed.
* @param[in]    pElfFile Structure holding all informations about (partially) opened ELF file.
* @retval       TRUE It is LITTLE endian ELF
* @retval       FALSE It is BIG endian ELF
*/
static inline bool_t ELF_IsLittleEndian(const ELF_File_t *pElfFile)
{
    return (1U == pElfFile->Header.e_ident[EI_DATA]) ? TRUE : FALSE;
}
/**
* @brief        Use to check target architecture of the ELF.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @param[in]    eArch Expected architecture specification.
* @retval       TRUE ELF architecture matches given value.
* @retval       FALSE ELF targets different architecture.
*/
static inline bool_t ELF_IsArchitecture(const ELF_File_t *pElfFile, ELF_Arch_t eArch)
{
    bool_t bRetVal;
    if(TRUE == pElfFile->bIs64Bit)
    {
        bRetVal = ((uint16)eArch == pElfFile->Header.r64.e_machine) ? TRUE : FALSE;
    }
    else
    {
        bRetVal = ((uint16)eArch == pElfFile->Header.r32.e_machine) ? TRUE : FALSE;
    }
    return bRetVal;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* ELF_H */

/** @}*/


===== 文件 [8/185]: include\elf_cfg.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2018-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup dxgr_ELF
 * @{
 * 
 * @file            elf_cfg.h
 * @version         0.0.0.0
 *
 * @brief           Configuration header file for the ELF module.
 *
 */
/*==================================================================================================
==================================================================================================*/

/*==================================================================================================
                                         MISRA VIOLATIONS
==================================================================================================*/

#ifndef ELF_CFG_H
    #define ELF_CFG_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#ifndef TRUE
    #define TRUE 1
#endif /* TRUE */
#ifndef FALSE
    #define FALSE 0
#endif /* FALSE */

/*==================================================================================================
                                         INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==================================================================================================*/  

/*==================================================================================================
                               SOURCE FILE VERSION INFORMATION
==================================================================================================*/

/*==================================================================================================
                                      FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
                                           CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       DEFINES AND MACROS
==================================================================================================*/
/**
* @def      ELF_CFG_PROGRAM_TABLE_USED
* @brief    Configures whether functions for loading binary from program table will be built.
* @details  This is the standard way of loading ELFs.
*/
#define ELF_CFG_PROGRAM_TABLE_USED TRUE

/**
* @def      ELF_CFG_SECTION_TABLE_USED
* @brief    Configures whether functions for loading binary from section table will be built.
* @details  This is a non-standard way of loading ELFs.
*/
#define ELF_CFG_SECTION_TABLE_USED TRUE

/**
* @def      ELF_CFG_ELF32_SUPPORTED
* @brief    Configures whether 32-bit ELF format support shall be built.
*/
#define ELF_CFG_ELF32_SUPPORTED TRUE

/**
* @def      ELF_CFG_ELF64_SUPPORTED
* @brief    Configures whether 64-bit ELF format support shall be built.
*/
#ifndef ELF_CFG_ELF64_SUPPORTED
#define ELF_CFG_ELF64_SUPPORTED FALSE
#endif

/**
* @def      ELF_CFG_SECTION_PRINT_ENABLED
* @brief    Configures whether function ELF_PrintSections shall be built.
* @details  Normally it will be FALSE.
*/
#define ELF_CFG_SECTION_PRINT_ENABLED TRUE

/*==================================================================================================
                                             ENUMS
==================================================================================================*/

/*==================================================================================================
                                 STRUCTURES AND OTHER TYPEDEFS
==================================================================================================*/

/*==================================================================================================
                                 GLOBAL VARIABLE DECLARATIONS
==================================================================================================*/

/*==================================================================================================
                                     FUNCTION PROTOTYPES
==================================================================================================*/

#endif /* ELF_CFG_H */

/** @}*/


===== 文件 [9/185]: include\fci.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef FCI_H_
#define FCI_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "oal.h"
#include "pfe_emac.h" /* pfe_mac_addr_t */
#include "pfe_rtable.h" /* pfe_rtable_t, pfe_rtable_dst_if_t */
#include "pfe_l2br.h" /* pfe_l2br_t */
#include "pfe_class.h" /* pfe_class_t */
#include "pfe_if_db.h"
#include "pfe_tmu.h"    /* pfe_tmu_t */
#include "fci_msg.h"

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#include "fci_ownership_mask.h"
#endif /* #ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT */

/**
 * @brief   Information passed into the fci_init() function
 * @note    For future use
 */
typedef struct
{
    pfe_rtable_t *rtable;   /* The routing table object */
    pfe_l2br_t *l2_bridge;  /* The L2 bridge instance */
    pfe_class_t *class;     /* The classifier instance */
    pfe_if_db_t *phy_if_db; /* Pointer to platform driver phy_if DB */
    pfe_if_db_t *log_if_db; /* Pointer to platform driver log_if DB */
    pfe_tmu_t *tmu;         /* Pointer to platform driver tmu */
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    pfe_fci_owner_hif_id_t hif_fci_owner_chnls_mask;    /* Bit mask representing allowed FCI ownership */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
} fci_init_info_t;

/**
 * @brief   FCI instance type
 */
typedef struct fci_tag fci_t;

typedef struct
{
    uint32 stats;
} pfe_fp_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Send message to all FCI clients
 * @param[in]   msg Pointer to the buffer containing payload to be sent
 * @param[in]   rep Pointer to buffer where reply data shall be stored
 * @return      EOK if success, error code otherwise
 */
errno_t fci_core_client_send_broadcast(fci_msg_t *msg, fci_msg_t *rep);

errno_t fci_init(fci_init_info_t *info, const char_t *const identifier);
void fci_fini(void);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_fp_get_text_statistics(pfe_fp_t *temp, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg);    /* This is here because FCI proxy RPC calls need it. */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* FCI_H_ */


===== 文件 [10/185]: include\fci_core.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_core.h
 * @brief       The FCI core header file
 * @details     The FCI core is OS-specific module responsible for:
 *                  -   IPC with FCI clients running within separated processes within the OS
 *                      environment.
 *                  -   Reception of commands from clients and executing OS-independent command
 *                      translator provided by FCI.
 *                  -   Maintenance of list of the clients.
 *                  -   Provision of API to the rest of FCI to communicate with the clients.
 *
 *              This file specifies common API the FCI core implementation has to implement.
 *
 */

#ifndef SRC_FCI_CORE_H_
#define SRC_FCI_CORE_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "oal_types.h"  /* Common types */
#include "fci_msg.h"    /* The fci_msg_t and related stuff */

/**
 * @brief   FCI core type
 * @details This is OS-specific part of FCI
 */
typedef struct fci_core_tag fci_core_t;

/**
 * @brief   FCI core client type
 */
typedef struct fci_core_client_tag fci_core_client_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create FCI core instance
 * @details     The FCI core is OS-specific part of the FCI endpoint. It is responsible
 *              for IPC connectivity with the rest of system.
 * @param[in]   id String identifier specifying the core instance. Intended to be used
 *              by libFCI to locate the endpoint.
 * @retval      EOK Success
 * @retval      EINVAL invalid argument received
 * @retval      ENOMEM initialization failed
 */
errno_t fci_core_init(const char_t *const id);

/**
 * @brief       Destroy FCI core
 * @details     Close all connections and release all associated resources
 */
void fci_core_fini(void);

/**
 * @brief       Send message to FCI client
 * @param[in]   client The FCI client instance
 * @param[in]   msg Pointer to the buffer containing payload to be sent
 * @param[in]   rep Pointer to buffer where reply data shall be stored
 * @return      EOK if success, error code otherwise
 */
errno_t fci_core_client_send(fci_core_client_t *client, fci_msg_t *msg, fci_msg_t *rep);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* SRC_FCI_CORE_H_ */

/** @}*/


===== 文件 [11/185]: include\fci_fp.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2022, 2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
#ifndef FCI_FP_H
#define FCI_FP_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

extern errno_t fci_fp_table_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fp_table_cmd_t *reply_buf, uint32 *reply_len);
extern errno_t fci_fp_rule_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fp_rule_cmd_t *reply_buf, uint32 *reply_len);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [12/185]: include\fci_fp_db.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
#ifndef FCI_FP_DB_H
#define FCI_FP_DB_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_class.h"
/**
* @def PFE_FP_RULE_POSITION_LAST
* @brief Macro to define position in function pfe_fp_add_rule_to_table() as the last one
*/
#define FCI_FP_RULE_POSITION_LAST  (0xFFU + 1U)
/**
* @def PFE_FP_RULE_POSITION_FIRST
* @brief Macro to define position in function pfe_fp_add_rule_to_table() as the first one
*/
#define FCI_FP_RULE_POSITION_FIRST 0x0U

/* table names should not exceed this length including terminating 0 */
#define FCI_FP_TABLE_NAME_LENGTH 16

typedef struct fci_fp_table_tag fci_fp_table_t;

/**
 * @brief   Rule data details type
 */
typedef struct
{
    char *rule_name;
    uint32 data;
    uint32 mask;
    uint16 offset;
    pfe_ct_fp_flags_t flags;
} fci_fp_rule_info_t;

/**
* @brief Criterion for table database search
*/
typedef enum
{
    FP_TABLE_CRIT_ALL,
    FP_TABLE_CRIT_NAME,
    FP_TABLE_CRIT_ADDRESS
} fci_fp_table_criterion_t;

/**
* @brief Argument (requested value) for table database
*/
typedef union
{
    char_t name[FCI_FP_TABLE_NAME_LENGTH];
    uint32 address;
} fci_fp_table_criterion_arg_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* Initialize the module */
void fci_fp_db_init(void);
/* Create set of rules */
errno_t fci_fp_db_create_rule(char_t *name, uint32 data, uint32 mask, uint16 offset, pfe_ct_fp_flags_t flags, char_t *next_rule);
/* Create set of tables */
errno_t fci_fp_db_create_table(char_t *name);
/* Group rules into tables */
errno_t fci_fp_db_add_rule_to_table(char_t *table_name, char_t *rule_name, uint16 position);
/* Write tables into DMEM */
errno_t fci_fp_db_push_table_to_hw(pfe_class_t *class, char_t *table_name);
/* Get the DMEM address to allow table usage */
uint32 fci_fp_db_get_table_dmem_addr(char_t *table_name);

/* Remove table from DMEM */
errno_t fci_fp_db_pop_table_from_hw(char_t *table_name);
/* Remove a single rule from the table */
errno_t fci_fp_db_remove_rule_from_table(char_t *rule_name);
/* Remove all rules from the table (and destroy the table) */
errno_t fci_fp_db_destroy_table(char_t *name, bool_t force);
/* Destroy the rule */
errno_t fci_fp_db_destroy_rule(char_t *name);

/* DB query functions */
fci_fp_table_t *fci_fp_db_get_first(fci_fp_table_criterion_t crit, void *arg);

/* Get the table from address */
errno_t fci_fp_db_get_table_from_addr(uint32 addr, char_t **table_name);

#if defined(PFE_CFG_TEXT_STATS)
/* Printing the information */
uint32 fci_fp_print_tables(char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

/* FCI queries */
errno_t fci_fp_db_get_first_rule(fci_fp_rule_info_t *rule_info, char_t **next_rule);
errno_t fci_fp_db_get_next_rule(fci_fp_rule_info_t *rule_info, char_t **next_rule);
errno_t fci_fp_db_get_table_first_rule(char_t *table_name, fci_fp_rule_info_t *rule_info, char_t **next_rule);
errno_t fci_fp_db_get_table_next_rule(char_t *table_name, fci_fp_rule_info_t *rule_info, char_t **next_rule);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [13/185]: include\fci_fw_features.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2020, 2022-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef FCI_FW_FEATURES_H
#define FCI_FW_FEATURES_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

extern errno_t fci_fw_features_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fw_features_cmd_t *reply_buf, uint32 *reply_len);
extern errno_t fci_fw_features_element_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [14/185]: include\fci_internal.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_internal.c
 * @brief       Internal header distributing FCI-related artifacts not intended
 *              to be exposed to public.
 * @details
 *
 */

#ifndef SRC_FCI_INTERNAL_H_
#define SRC_FCI_INTERNAL_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_cfg.h"
#include "oal.h"

#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "pfe_if_db.h"
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#include "fci_ownership_mask.h"
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#include "fci.h"
#include "fci_msg.h"   /* The IPC message format (fci_msg_t) */
#include "fci_core.h"  /* The OS-specific FCI core */
#ifdef PFE_CFG_RTABLE_ENABLE
#include "fci_rt_db.h" /* Database of routes */
#endif /* PFE_CFG_RTABLE_ENABLE */

#ifdef PFE_CFG_FCI_ENABLE

/**
 * @brief   This is the FCI endpoint representation structure.
 */
struct fci_tag
{
    fci_core_t *core;

    pfe_if_db_t *phy_if_db;         /* Pointer to platform driver phy_if DB */
    bool_t phy_if_db_initialized;   /* Logical interface DB was initialized */

    pfe_if_db_t *log_if_db;         /* Pointer to platform driver log_if DB */
    bool_t log_if_db_initialized;   /* Logical interface DB was initialized */

    uint32 if_session_id;         /* Holds session ID for interface session */

    #ifdef PFE_CFG_PFE_MASTER
    #ifdef PFE_CFG_RTABLE_ENABLE
    fci_rt_db_t route_db;
    #endif /* PFE_CFG_RTABLE_ENABLE */
    #endif /* PFE_CFG_PFE_MASTER */
    
    #ifdef PFE_CFG_RTABLE_ENABLE
    bool_t rt_db_initialized;
    pfe_rtable_t *rtable;
    bool_t rtable_initialized;
    #endif /* PFE_CFG_RTABLE_ENABLE */

    #ifdef PFE_CFG_L2BRIDGE_ENABLE
    pfe_l2br_t *l2_bridge;
    bool_t l2_bridge_initialized;
    #endif /* PFE_CFG_L2BRIDGE_ENABLE */

    pfe_tmu_t *tmu;                 /* Pointer to platform driver tmu */
    bool_t tmu_initialized;         /* Platform TMU was initialized */

    pfe_class_t *class;

    struct
    {
        uint32 timeout_tcp;
        uint32 timeout_udp;
        uint32 timeout_other;
    } default_timeouts;

    bool_t hm_cb_registered;
    bool_t is_some_client;          /* TRUE if there is at least one client registered for FCI events. */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    bool_t fci_owner_initialized;
#endif /* #ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT */

    bool_t fci_initialized;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* Global variable used across all fci files */
extern fci_t context;

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t fci_interfaces_session_cmd(uint32 code, uint16 *fci_ret);
errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_log_if_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_phy_if_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_if_mac_cmd_t *reply_buf, uint32 *reply_len);
#ifdef PFE_CFG_RTABLE_ENABLE
errno_t fci_routes_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_rt_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_connections_ipv4_ct_cmd(const fci_msg_t *msg, uint16 *fci_ret, fpp_ct_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_connections_ipv6_ct_cmd(const fci_msg_t *msg, uint16 *fci_ret, fpp_ct6_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_timeout_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry);
errno_t fci_connections_set_default_timeout(uint8 ip_proto, uint32 timeout);
uint32 fci_connections_get_default_timeout(uint8 ip_proto);
void fci_routes_drop_all(void);
void fci_routes_drop_all_ipv4(void);
void fci_routes_drop_all_ipv6(void);
void fci_connections_drop_all(void);
#endif /* PFE_CFG_RTABLE_ENABLE */
#ifdef PFE_CFG_L2BRIDGE_ENABLE
errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_l2_bd_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_l2_static_ent_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_l2br_flush_cmd(uint32 code, uint16 *fci_ret);
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_RTABLE_ENABLE
errno_t fci_routes_drop_one(fci_rt_db_entry_t *route);
#endif /* PFE_CFG_RTABLE_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */
errno_t fci_qos_queue_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_queue_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_qos_scheduler_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_scheduler_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_qos_shaper_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_shaper_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_qos_policer_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_qos_policer_flow_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_flow_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_qos_policer_wred_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_wred_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_qos_policer_shp_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_shp_cmd_t *reply_buf, uint32 *reply_len);
void fci_hm_send_events(void);
errno_t fci_hm_cb_register(void);
errno_t fci_hm_cb_deregister(void);
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
errno_t fci_owner_session_cmd(pfe_ct_phy_if_id_t sender, uint32 code, uint16 *fci_ret);
errno_t fci_owner_get_floating_lock(pfe_ct_phy_if_id_t sender, uint16 *fci_ret, bool_t *floating_lock);
errno_t fci_owner_clear_floating_lock(void);
errno_t fci_owner_authorize(pfe_ct_phy_if_id_t sender, bool_t *auth_ret);
errno_t fci_sender_get_phy_if_id(uint32 sender, pfe_ct_phy_if_id_t *phy_if_id);
errno_t fci_owner_mutex_lock(void);
errno_t fci_owner_mutex_unlock(void);
errno_t fci_owner_init(fci_init_info_t *info);
#endif /* #ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT */
errno_t fci_timer_owner_lock_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_timer_cmd_t *reply_buf, uint32 *reply_len);
errno_t fci_timer_owner_unlock_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_timer_cmd_t *reply_buf, uint32 *reply_len);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* SRC_FCI_INTERNAL_H_ */

/** @}*/


===== 文件 [15/185]: include\fci_mirror.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2021-2022, 2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
#ifndef FCI_MIRROR_H
#define FCI_MIRROR_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t fci_mirror_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_mirror_cmd_t *reply_buf, uint32 *reply_len);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [16/185]: include\fci_msg.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_msg.h
 * @brief       The FCI IPC message type
 * @details     This header provides the fci_msg_t.
 *
 */

#ifndef SRC_FCI_MSG_H_
#define SRC_FCI_MSG_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "ct_assert.h"

/**
 * @brief   Maximum size of FCI IPC message payload
 * @see     fci_msg_t
 */
#define FCI_CFG_MAX_CMD_PAYLOAD_LEN     256U

/**
 * @brief   FCI message types
 * @see     fci_msg_t
 */
typedef enum
{
    FCI_MSG_TYPE_MIN = 0x1000,
    FCI_MSG_CLIENT_REGISTER,
    FCI_MSG_CLIENT_UNREGISTER,
    FCI_MSG_CMD,
    FCI_MSG_CORE_CLIENT_BROADCAST,
    /* Ensure proper size */
    FCI_MSG_TYPE_MAX = (int)(1U << 31U)
} msg_type_t;

ct_assert(sizeof(msg_type_t) == sizeof(uint32));

/**
 * @brief   FCI message command type
 */
typedef struct
{
    uint32 code;                                  /*!< Message code */
    uint32 length;                                /*!< Message length */
    uint32 sender;                                /*!< Message sender originator identifier */
    uint8 payload[FCI_CFG_MAX_CMD_PAYLOAD_LEN];   /*!< Message payload */
} fci_msg_cmd_t;

#include "fci_msg_autosar.h"

#endif /* SRC_FCI_MSG_H_ */

/** @}*/


===== 文件 [17/185]: include\fci_msg_autosar.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_msg_autosar.h
 * @brief       The AUTOSAR-specific FCI IPC message (fci_msg_t) format
 * @details     The FCI message is used to transport FCI commands and events
 *              between FCI endpoint and FCI clients (libFCI) using IPC.
 *
 */

#ifndef PUBLIC_FCI_MSG_AUTOSAR_H_
#define PUBLIC_FCI_MSG_AUTOSAR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "fpp.h"

#ifndef SRC_FCI_MSG_H_
#include "fci_msg.h"
#endif

#define FCI_CFG_MSG_FIFO_DEPTH 8

/**
 * @brief   FCI IPC message format
 */
typedef struct CAL_ALIGNED(4)
{
    msg_type_t type;    /* 4 bytes */

    fci_msg_cmd_t msg_cmd;

    /*  FCI internal storage */
    void *client;
} fci_msg_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t fci_core_client_get_msg(fci_msg_t *msg);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_FCI_MSG_AUTOSAR_H_ */

/** @}*/


===== 文件 [18/185]: include\fci_ownership_mask.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2022, 2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @file        fci_ownership_mask.h
 * @brief       The FCI ownership permission mask
 */

#ifndef PUBLIC_FCI_OWNERSHIP_MASK_H_
#define PUBLIC_FCI_OWNERSHIP_MASK_H_

#include "pfe_ct.h"

/**
 * @brief   The bitmask list of HIF channels that are allowed to take FCI ownership
 */
typedef enum
{
    FCI_OWNER_HIF_INVALID = 0U,
    FCI_OWNER_HIF_0 = (1U << 0U),
    FCI_OWNER_HIF_1 = (1U << 1U),
    FCI_OWNER_HIF_2 = (1U << 2U),
    FCI_OWNER_HIF_3 = (1U << 3U),
    FCI_OWNER_HIF_NOCPY = (1U << 4U)
} pfe_fci_owner_hif_id_t;

/**
 * @brief       Convert interface id to bitmask value representing HIF channel that is allowed to take FCI ownership
 * @param[in]   phy interface id
 * @return      FCI owner HIF permission bitmask value
 */
static inline pfe_fci_owner_hif_id_t pfe_fci_owner_hif_from_phy_id(pfe_ct_phy_if_id_t phy)
{
    pfe_fci_owner_hif_id_t ret_val = FCI_OWNER_HIF_INVALID;
    static const pfe_fci_owner_hif_id_t pfe_fci_owner_hif_ids[PFE_PHY_IF_ID_INVALID + 1U] =
    {
        [PFE_PHY_IF_ID_HIF_NOCPY] = FCI_OWNER_HIF_NOCPY,
        [PFE_PHY_IF_ID_HIF0] = FCI_OWNER_HIF_0,
        [PFE_PHY_IF_ID_HIF1] = FCI_OWNER_HIF_1,
        [PFE_PHY_IF_ID_HIF2] = FCI_OWNER_HIF_2,
        [PFE_PHY_IF_ID_HIF3] = FCI_OWNER_HIF_3,
        [PFE_PHY_IF_ID_INVALID] = FCI_OWNER_HIF_INVALID
    };

    if (PFE_PHY_IF_ID_INVALID >= phy)
    {
        ret_val = pfe_fci_owner_hif_ids[phy];
    }

    return ret_val;
}

#endif /* PUBLIC_FCI_OWNERSHIP_MASK_H_ */


===== 文件 [19/185]: include\fci_rt_db.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_rt_db.h
 * @brief       Route database header file
 * @details
 *
 */

#ifndef SRC_FCI_RT_DB_H_
#define SRC_FCI_RT_DB_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#ifdef PFE_CFG_FCI_ENABLE
#ifdef PFE_CFG_PFE_MASTER

#include "fpp.h"        /* Due to IFNAMSIZ */
#include "pfe_rtable.h" /* IP and MAC address type */

/* Maximum capacity of entries available in FCI route database ISA */
#define FCI_CFG_RTDB_ENTRIES_CAPACITY (PFE_CFG_RT_HASH_SIZE + PFE_CFG_RT_COLLISION_SIZE)

/**
 * @brief   Route database entry type
 */
typedef struct
{
    void *refptr;                   /*  Reference pointer storage */
    uint32 id;                    /*  Route entry identifier */
    uint16 mtu;
    pfe_mac_addr_t src_mac;
    pfe_mac_addr_t dst_mac;
    pfe_ip_addr_t dst_ip;           /*  Destination IP (ipv4/ipv6) */
    pfe_phy_if_t *iface;            /*  Associated interface */
} fci_rt_db_entry_t;

/**
 * @brief   Route database select criteria type
 */
typedef enum
{
    RT_DB_CRIT_ALL,             /*!< Match any entry in the DB */
    RT_DB_CRIT_BY_IF,           /*!< Match entries by interface instance */
    RT_DB_CRIT_BY_IF_NAME,      /*!< Match entries by interface name */
    RT_DB_CRIT_BY_IP,           /*!< Match entries by destination IP address */
    RT_DB_CRIT_BY_MAC,          /*!< Match entries by destination MAC address */
    RT_DB_CRIT_BY_ID            /*!< Match entries by ID */
} fci_rt_db_get_criterion_t;

/**
 * @brief   Route database instance representation type
 */
typedef struct
{
    uint32 next_item;                 /*  Current entry to be returned. See ...get_first() and ...get_next() */
    fci_rt_db_get_criterion_t cur_crit; /*  Current criterion */
    union
    {
        char_t outif_name[IFNAMSIZ];
        pfe_ip_addr_t dst_ip;
        pfe_mac_addr_t dst_mac;
        uint32 id;
        const pfe_phy_if_t *iface;
    } cur_crit_arg;                     /*  Current criterion argument */
    /* route database entries storage ISA definition */
    pfe_isa_definition_t rtdb_entries_isa_def;
    /* route database entries storage ISA */
    pfe_isa_t rtdb_entries;
    /* route database entries storage ISA index */
    pfe_isa_index_t rtdb_entries_index[FCI_CFG_RTDB_ENTRIES_CAPACITY];
    /* route database entries storage ISA pool */
    fci_rt_db_entry_t rtdb_entries_pool[FCI_CFG_RTDB_ENTRIES_CAPACITY];
} fci_rt_db_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

void fci_rt_db_init(fci_rt_db_t *db);
errno_t fci_rt_db_add(fci_rt_db_t *db, pfe_ip_addr_t *dst_ip,
                    pfe_mac_addr_t *src_mac, pfe_mac_addr_t *dst_mac,
                    pfe_phy_if_t *iface, uint32 id, void *refptr, bool_t overwrite);
errno_t fci_rt_db_remove(fci_rt_db_t *db, fci_rt_db_entry_t *entry);
errno_t fci_rt_db_drop_all(fci_rt_db_t *db);
fci_rt_db_entry_t *fci_rt_db_get_first(fci_rt_db_t *db, fci_rt_db_get_criterion_t crit, const void *arg);
fci_rt_db_entry_t *fci_rt_db_get_next(fci_rt_db_t *db);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_PFE_MASTER */
#endif /* PFE_CFG_FCI_ENABLE */

#endif /* SRC_FCI_RT_DB_H_ */

/** @}*/


===== 文件 [20/185]: include\fifo.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef SRC_fifo_H_
#define SRC_fifo_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "hal.h"
#include "oal_util.h"

struct __attribute__((aligned(HAL_CACHE_LINE_SIZE))) fifo_tag
{
    uint32 read;
    uint32 write;
    uint32 depth;
    uint32 depth_mask;
    bool_t protected;
    void **data;
};

typedef volatile struct fifo_tag fifo_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static inline errno_t fifo_put(fifo_t *const fifo, void *const ptr)
{
    uint32 fill_level;
    errno_t err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fifo))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fill_level = (fifo->write - fifo->read);

        if (likely(fill_level < fifo->depth))
        {
            fifo->data[fifo->write & fifo->depth_mask] = ptr;

            /*  Ensure that entry contains correct data */
            hal_wmb();

            fifo->write++;

            err = EOK;
        }
        else
        {
            /*  Overflow */
            err = EOVERFLOW;
        }
    }

    return err;
}

static inline void * fifo_get(fifo_t * const fifo)
{
    void *ret = NULL;
    uint32 fill_level;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fifo))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fill_level = (fifo->write - fifo->read);

        if (likely(fill_level > 0U))
        {
            ret = fifo->data[fifo->read & fifo->depth_mask];
            fifo->read = (uint32)(((uint64)fifo->read + 1U) & UINT32_MAX);
        }
    }

    return (void *)ret;
}

fifo_t * fifo_create(const uint32 depth, fifo_t *fifo, void **data) __attribute__((cold));
void fifo_destroy(fifo_t *fifo) __attribute__((cold));
void fifo_clear(fifo_t *const fifo) __attribute__((cold));
void * fifo_peek(const fifo_t * const fifo, uint32 num) __attribute__((hot));
errno_t fifo_get_fill_level(const fifo_t *const fifo, uint32 *fill_level) __attribute__((hot));
errno_t fifo_get_free_space(const fifo_t *const fifo, uint32 *free_space) __attribute__((hot));

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* SRC_fifo_H_ */


===== 文件 [21/185]: include\fpp.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright (C) 2010 Mindspeed Technologies, Inc.
 *  Copyright 2014-2016 Freescale Semiconductor, Inc.
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */


#ifndef FPP_H_
#define FPP_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*  Compiler abstraction macros */
#ifndef CAL_PACKED
#define CAL_PACKED              __attribute__((packed))
#endif /* CAL_PACKED */

#ifndef CAL_PACKED_ALIGNED
#define CAL_PACKED_ALIGNED(n)   __attribute__((packed, aligned(n)))
#endif /* CAL_PACKED_ALIGNED */

#ifndef CAL_ALIGNED
#define CAL_ALIGNED(n)  __attribute__((aligned(n)))
#endif /* CAL_ALIGNED */

/**
 * @file    fpp.h
 * @brief   The legacy FCI API
 * @details This file origin is the fpp.h file from CMM sources.
 */

#include "pfe_cfg.h"
#include "oal_types.h"

#define IFNAMSIZ    16  /*  Maximum length of interface name */

/*--------------------------------------- General ---------------------------*/
/* Errors */
#define FPP_ERR_OK                                      0U
#define FPP_ERR_UNKNOWN_COMMAND                         1U
#define FPP_ERR_WRONG_COMMAND_SIZE                      2U
#define FPP_ERR_WRONG_COMMAND_PARAM                     3U
#define FPP_ERR_UNKNOWN_ACTION                          4U
#define FPP_ERR_SA_ENTRY_NOT_FOUND                      909U

/**
 * @brief Generic 'register' action for FPP_CMD_*.
 * @hideinitializer
 */
#define FPP_ACTION_REGISTER     0U

/**
 * @brief Generic 'deregister' action for FPP_CMD_*.
 * @hideinitializer
 */
#define FPP_ACTION_DEREGISTER   1
#define FPP_ACTION_KEEP_ALIVE   2
#define FPP_ACTION_REMOVED      3

/**
 * @brief Generic 'update' action for FPP_CMD_*.
 * @hideinitializer
 */
#define FPP_ACTION_UPDATE       4

/**
 * @brief Generic 'query' action for FPP_CMD_*.
 * @hideinitializer
 */
#define FPP_ACTION_QUERY        6

/**
 * @brief Generic 'query continue' action for FPP_CMD_*.
 * @hideinitializer
 */
#define FPP_ACTION_QUERY_CONT   7
#define FPP_ACTION_QUERY_LOCAL  8
#define FPP_ACTION_TCP_FIN      9

/*----------------------------------Tunnels-----------------------------------*/
#define FPP_ERR_TNL_ALREADY_CREATED         1004    

/*------------------------------------- Sockets ------------------------------*/
#define FPP_ERR_SOCK_ALREADY_OPEN           1200
#define FPP_ERR_SOCKID_ALREADY_USED         1201
#define FPP_ERR_SOCK_ALREADY_OPENED_WITH_OTHER_ID   1202
#define FPP_ERR_TOO_MANY_SOCKET_OPEN            1203
#define FPP_ERR_SOCKID_UNKNOWN              1204
#define FPP_ERR_SOCK_ALREADY_IN_USE         1206
#define FPP_ERR_RTP_CALLID_IN_USE           1207
#define FPP_ERR_RTP_UNKNOWN_CALL            1208
#define FPP_ERR_WRONG_SOCKID                1209
#define FPP_ERR_RTP_SPECIAL_PKT_LEN             1210
#define FPP_ERR_RTP_CALL_TABLE_FULL             1211
#define FPP_ERR_WRONG_SOCK_FAMILY           1212
#define FPP_ERR_WRONG_SOCK_PROTO            1213
#define FPP_ERR_WRONG_SOCK_TYPE             1214
#define FPP_ERR_MSP_NOT_READY               1215
#define FPP_ERR_WRONG_SOCK_MODE             1216

typedef struct {
    uint16 id;
    uint8 type;
    uint8 mode;
    uint32 saddr;
    uint32 daddr;
    uint16 sport;
    uint16 dport;
    uint8 proto;
    uint8 queue;
    uint16 dscp;
    uint32 route_id;
#if defined(COMCERTO_2000) || defined(LS1043)
        uint16 secure;
        uint16 sa_nr_rx;
        uint16 sa_handle_rx[4];
        uint16 sa_nr_tx;
        uint16 sa_handle_tx[4];
    uint16 pad;
#endif
} __attribute__((__packed__)) fpp_socket4_open_cmd_t;

typedef struct {
    uint16 id;
    uint16 rsvd1;
    uint32 saddr;
    uint16 sport;
    uint8 rsvd2;
    uint8 queue;
    uint16 dscp;
    uint16 pad;
    uint32 route_id;
#if defined(COMCERTO_2000) || defined(LS1043)
        uint16 secure;
        uint16 sa_nr_rx;
        uint16 sa_handle_rx[4];
        uint16 sa_nr_tx;
        uint16 sa_handle_tx[4];
    uint16 pad2;
#endif
} __attribute__((__packed__)) fpp_socket4_update_cmd_t;

typedef struct {
    uint16 id;
    uint16 pad1;
} __attribute__((__packed__)) fpp_socket4_close_cmd_t;

typedef struct {
    uint16 id;
    uint8 type;
    uint8 mode;
    uint32 saddr[4];
    uint32 daddr[4];
    uint16 sport;
    uint16 dport;
    uint8 proto;
    uint8 queue;
    uint16 dscp;
    uint32 route_id;
#if defined(COMCERTO_2000) || defined(LS1043)
        uint16 secure;
        uint16 sa_nr_rx;
        uint16 sa_handle_rx[4];
        uint16 sa_nr_tx;
        uint16 sa_handle_tx[4];
    uint16 pad;
#endif
} __attribute__((__packed__)) fpp_socket6_open_cmd_t;

typedef struct {
    uint16 id;
    uint16 rsvd1;
    uint32 saddr[4];
    uint16 sport;
    uint8 rsvd2;
    uint8 queue;
    uint16 dscp;
    uint16 pad;
    uint32 route_id;
#if defined(COMCERTO_2000) || defined(LS1043)
        uint16 secure;
        uint16 sa_nr_rx;
        uint16 sa_handle_rx[4];
        uint16 sa_nr_tx;
        uint16 sa_handle_tx[4];
    uint16 pad2;
#endif
} __attribute__((__packed__)) fpp_socket6_update_cmd_t;

typedef struct {
    uint16 id;
    uint16 pad1;
} __attribute__((__packed__)) fpp_socket6_close_cmd_t;

/*------------------------------------- Tunnel -------------------------------*/
#define FPP_ERR_TNL_ENTRY_NOT_FOUND                     1001

/*------------------------------------- Protocols ----------------------------*/
typedef enum {
        FPP_PROTO_IPV4 = 0,
        FPP_PROTO_IPV6,
        FPP_PROTO_PPPOE,
        FPP_PROTO_MC4,
        FPP_PROTO_MC6
} fpp_proto_t;

/*------------------------------------- Multicast ----------------------------*/
#define FPP_ERR_MC_ENTRY_NOT_FOUND          700

/*------------------------------------ Conntrack -----------------------------*/
#define FPP_ERR_CT_ENTRY_ALREADY_REGISTERED     100
#define FPP_ERR_CT_ENTRY_NOT_FOUND          101

/**
 * @addtogroup  dxgrLibFCI
 * @{
 */

/**
 * @def         FPP_CMD_IPV4_CONNTRACK
 * @brief       FCI command for management of IPv4 conntracks.
 * @details     Related topics: @ref l3_router
 * @details     Related data types: @ref fpp_ct_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new IPv4 conntrack and bind it to previously created route(s).
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing IPv4 conntrack.
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of IPv4 conntrack.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) IPv4 conntrack query session and get properties 
 *                   of the first IPv4 conntrack from the internal list of IPv4 conntracks.
 *              - @c FPP_ACTION_QUERY_CONT <br> 
 *                   Continue the query session and get properties of the next IPv4 conntrack
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new IPv4 conntrack.
 * @code{.c}
 *  .............................................  
 *  fpp_ct_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_REGISTER,  // Action
 *      
 *    .saddr = ...,        // 'orig' direction: Source IP address. [NBO]
 *    .daddr = ...,        // 'orig' direction: Destination IP address. [NBO]
 *    .sport = ...,        // 'orig' direction: Source port. [NBO]
 *    .dport = ...,        // 'orig' direction: Destination port. [NBO]
 *      
 *    .saddr_reply = ...,  // 'reply' direction: Source IP address. [NBO]
 *                         // Used for NAT, otherwise equals '.daddr'.
 *      
 *    .daddr_reply = ...,  // 'reply' direction: Destination IP address.
 *                         // Used for NAT, otherwise equals '.saddr'.
 *      
 *    .sport_reply = ...,  // 'reply' direction: Source port. [NBO]
 *                         // Used for NAT, otherwise equals '.dport'.
 *      
 *    .dport_reply = ...,  // 'reply' direction: Destination port. [NBO]
 *                         // Used for NAT, otherwise equals '.sport'.
 *      
 *    .protocol = ...,     // IANA IP Protocol Number (protocol ID). [NBO]
 *      
 *    .flags = ...,        // Flags. A bitset. [NBO]
 *      
 *    .route_id = ...,     // 'orig' direction: ID of an associated route. [NBO]
 *                         // See FPP_CMD_IP_ROUTE.
 *      
 *    .route_id_reply = ...,  // 'reply' direction: ID of an associated route. [NBO]
 *                            // See FPP_CMD_IP_ROUTE.
 *      
 *    .vlan = ...,         // 'orig' direction: VLAN tag. [NBO]
 *                         // If non-zero, then this VLAN tag is added to the routed packet.
 *                         // If the packet already has a VLAN tag, then its tag is replaced.
 *      
 *    .vlan_reply = ...    // 'reply' direction: VLAN tag. [NBO]
 *                         // If non-zero, then this VLAN tag is added to the routed packet.
 *                         // If the packet already has a VLAN tag, then its tag is replaced.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV4_CONNTRACK, sizeof(fpp_ct_cmd_t), 
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 * <b>orig and reply direction</b><br>
 * By default the connection is created as bi-directional. It means that two routing table entries
 * are created at once:
 *   - one for standard flow ('orig' direction), defined by `.protocol`, `.saddr`, `.daddr`, 
 *     `.sport`, and `.dport`
 *   - one for reverse flow ('reply' direction), defined by `.protocol`, `.saddr_reply`, `.daddr_reply`,
 *     `.sport_reply` and `.dport_reply`.
 * 
 * To create an uni-directional connection (only one routing table entry), set one of these flags 
 * (@b never both) when configuring a conntrack:
 * - 'orig' direction only:  `.flags |= CTCMD_FLAGS_REP_DISABLED`, and @b don't set `.route_id_reply`.
 * - 'reply' direction only: `.flags |= CTCMD_FLAGS_ORIG_DISABLED`, and @b don't set `.route_id`.
 *
 * <b>NAT and NAPT/PAT</b><br>
 * To configure NAT or NAPT/PAT connection, set 'reply' IP addresses and ports to different values
 * than 'orig' IP addresses and ports.
 * -# `.daddr_reply != .saddr`: Source address of packets in the 'orig' direction will be changed
 *    from `.saddr` to `daddr_reply`. In case of a bi-directional connection, destination address
 *    of packets in the 'reply' direction will be changed from `.daddr_reply` to `.saddr`.
 * -# `.saddr_reply != .daddr`: Destination address of packets in the 'orig' direction will be changed
 *    from `.daddr` to `.saddr_reply`. In case of a bi-directional connection, source address of
 *    packets in the 'reply' direction will be changed from `.saddr_reply` to `.daddr`.
 * -# `.dport_reply != .sport`: Source port of packets in the 'orig' direction will be changed
 *    from `.sport` to `.dport_reply. In case of a bi-directional connection, destination port of
 *    packets in the 'reply' direction will be changed from `.dport_reply` to `.sport`.
 * -# `.sport_reply != .dport`: Destination port of packets in the 'orig' direction will be changed
 *    from `.dport` to `.sport_reply`. In case of a bi-directional connection, source port of packets
 *    in the 'reply' direction will be changed from `.sport_reply` to `.dport`.
 *
 * <b>Disable port checking</b><br>
 * It is possible to leave out ports from matching process of a particular conntrack.
 * To do so, configure the conntrack's `.sport` and `.dport` to zero.
 * This allows routing based only on 3-tuple (protocol, source IP, destination IP).
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing IPv4 conntrack. 'Orig' properties are mandatory for this action.
 * 'Reply' properties are optional.
 * @code{.c}
 *  .............................................  
 *  fpp_ct_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *      
 *    // Identification of the target conntrack.
 *    .saddr = ...,        // 'orig' direction: Source IP address. [NBO]
 *    .daddr = ...,        // 'orig' direction: Destination IP address. [NBO]
 *    .sport = ...,        // 'orig' direction: Source port. [NBO]
 *    .dport = ...         // 'orig' direction: Destination port. [NBO]
 *    .protocol = ...,     // IANA IP Protocol Number (protocol ID). [NBO]
 *      
 *    .saddr_reply = ...,  // 'reply' direction: Source IP address. [NBO]
 *                         // Used for NAT, otherwise equals '.daddr'.
 *      
 *    .daddr_reply = ...,  // 'reply' direction: Destination IP address.
 *                         // Used for NAT, otherwise equals '.saddr'.
 *      
 *    .sport_reply = ...,  // 'reply' direction: Source port. [NBO]
 *                         // Used for NAT, otherwise equals '.dport'.
 *      
 *    .dport_reply = ...,  // 'reply' direction: Destination port. [NBO]
 *                         // Used for NAT, otherwise equals '.sport'.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV4_CONNTRACK, sizeof(fpp_ct_cmd_t), 
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of an IPv4 conntrack.
 * @code{.c}
 *  .............................................  
 *  fpp_ct_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *      
 *    // Identification of the target conntrack.
 *    .saddr = ...,     // 'orig' direction: Source IP address. [NBO]
 *    .daddr = ...,     // 'orig' direction: Destination IP address. [NBO]
 *    .sport = ...,     // 'orig' direction: Source port. [NBO]
 *    .dport = ...,     // 'orig' direction: Destination port. [NBO]
 *    .protocol = ...,  // IANA IP Protocol Number (protocol ID). [NBO]
 *      
 *    // Modification of the target conntrack.
 *    .flags |= ntohs(CTCMD_FLAGS_TTL_DECREMENT)  // The only modification available: 
 *                                                // set/unset TTL decrement flag.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV4_CONNTRACK, sizeof(fpp_ct_cmd_t), 
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of an IPv4 conntrack.
 * @code{.c}
 *  .............................................  
 *  fpp_ct_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *    
 *  fpp_ct_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u; 
 *    
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_IPV4_CONNTRACK,
 *                  sizeof(fpp_ct_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *    
 *  // 'reply_from_fci' now holds properties of the first IPv4 conntrack from 
 *  //  the internal list of IPv4 conntracks.
 *    
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_IPV4_CONNTRACK,
 *                  sizeof(fpp_ct_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *    
 *  // 'reply_from_fci' now holds properties of the next IPv4 conntrack from 
 *  //  the internal list of IPv4 conntracks.
 *  .............................................  
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_CT_ENTRY_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the IPv4 conntrack query session (no more IPv4 conntracks).
 *        - For other ACTIONs: Unknown (nonexistent) IPv4 conntrack was requested.
 * - @c FPP_ERR_CT_ENTRY_ALREADY_REGISTERED <br>
 *        Requested IPv4 conntrack already exists (is already registered).
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property (probably nonexistent route).
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IPV4_CONNTRACK              0x0314

/**
 * @def         FPP_CMD_IPV6_CONNTRACK
 * @brief       FCI command for management of IPv6 conntracks.
 * @details     Related topics: @ref l3_router
 * @details     Related data types: @ref fpp_ct6_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new IPv6 conntrack and bind it to previously created route(s).
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing IPv6 conntrack.
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of IPv6 conntrack.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) IPv6 conntrack query session and get properties 
 *                   of the first IPv6 conntrack from the internal list of IPv6 conntracks.
 *              - @c FPP_ACTION_QUERY_CONT <br> 
 *                   Continue the query session and get properties of the next IPv6 conntrack
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new IPv6 conntrack.
 * @code{.c}
 *  .............................................  
 *  fpp_ct6_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_REGISTER,  // Action
 *      
 *    .saddr = {...},         // 'orig' direction: Source IP address. [NBO]
 *    .daddr = {...},         // 'orig' direction: Destination IP address. [NBO]
 *    .sport =  ...,          // 'orig' direction: Source port. [NBO]
 *    .dport =  ...,          // 'orig' direction: Destination port. [NBO]
 *      
 *    .saddr_reply = {...},   // 'reply' direction: Source IP address. [NBO]
 *                            // Used for NAT, otherwise equals '.daddr'.
 *      
 *    .daddr_reply = {...},   // 'reply' direction: Destination IP address.
 *                            // Used for NAT, otherwise equals '.saddr'.
 *      
 *    .sport_reply = ...,     // 'reply' direction: Source port. [NBO]
 *                            // Used for NAT, otherwise equals '.dport'.
 *      
 *    .dport_reply = ...,     // 'reply' direction: Destination port. [NBO]
 *                            // Used for NAT, otherwise equals '.sport'.
 *      
 *    .protocol = ...,        // IANA IP Protocol Number (protocol ID). [NBO]
 *      
 *    .flags = ...,           // Flags. A bitset. [NBO]
 *      
 *    .route_id = ...,        // 'orig' direction: ID of an associated route. [NBO]
 *                            // See FPP_CMD_IP_ROUTE.
 *      
 *    .route_id_reply = ...,  // 'reply' direction: ID of an associated route. [NBO]
 *                            // See FPP_CMD_IP_ROUTE.
 *      
 *    .vlan = ...,         // 'orig' direction: VLAN tag. [NBO]
 *                         // If non-zero, then this VLAN tag is added to the routed packet.
 *                         // If the packet already has a VLAN tag, then its tag is replaced.
 *      
 *    .vlan_reply = ...    // 'reply' direction: VLAN tag. [NBO]
 *                         // If non-zero, then this VLAN tag is added to the routed packet.
 *                         // If the packet already has a VLAN tag, then its tag is replaced.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV6_CONNTRACK, sizeof(fpp_ct6_cmd_t), 
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 * <b>orig and reply direction</b><br>
 * By default the connection is created as bi-directional. It means that two routing table entries
 * are created at once:
 *   - one for standard flow ('orig' direction), defined by `.protocol`, `.saddr`, `.daddr`, 
 *     `.sport`, and `.dport`
 *   - one for reverse flow ('reply' direction), defined by `.protocol`, `.saddr_reply`, `.daddr_reply`,
 *     `.sport_reply` and `.dport_reply`.
 * 
 * To create an uni-directional connection (only one routing table entry), set one of these flags 
 * (@b never both) when configuring a conntrack:
 * - 'orig' direction only:  `.flags |= CTCMD_FLAGS_REP_DISABLED`, and @b don't set `.route_id_reply`.
 * - 'reply' direction only: `.flags |= CTCMD_FLAGS_ORIG_DISABLED`, and @b don't set `.route_id`.
 *
 * <b>NAT and NAPT/PAT</b><br>
 * To configure NAT or NAPT/PAT connection, set 'reply' IP addresses and ports to different values
 * than 'orig' IP addresses and ports.
 * -# `.daddr_reply != .saddr`: Source address of packets in the 'orig' direction will be changed
 *    from `.saddr` to `daddr_reply`. In case of a bi-directional connection, destination address
 *    of packets in the 'reply' direction will be changed from `.daddr_reply` to `.saddr`.
 * -# `.saddr_reply != .daddr`: Destination address of packets in the 'orig' direction will be changed
 *    from `.daddr` to `.saddr_reply`. In case of a bi-directional connection, source address of
 *    packets in the 'reply' direction will be changed from `.saddr_reply` to `.daddr`.
 * -# `.dport_reply != .sport`: Source port of packets in the 'orig' direction will be changed
 *    from `.sport` to `.dport_reply. In case of a bi-directional connection, destination port of
 *    packets in the 'reply' direction will be changed from `.dport_reply` to `.sport`.
 * -# `.sport_reply != .dport`: Destination port of packets in the 'orig' direction will be changed
 *    from `.dport` to `.sport_reply`. In case of a bi-directional connection, source port of packets
 *    in the 'reply' direction will be changed from `.sport_reply` to `.dport`.
 *
 * <b>Disable port checking</b><br>
 * It is possible to leave out ports from matching process of a particular conntrack.
 * To do so, configure the conntrack's `.sport` and `.dport` to zero.
 * This allows routing based only on 3-tuple (protocol, source IP, destination IP).
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing IPv6 conntrack. 'Orig' properties are mandatory for this action.
 * 'Reply' properties are optional.
 * @code{.c}
 *  .............................................  
 *  fpp_ct6_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *      
 *    // Identification of the target conntrack.
 *    .saddr = {...},        // 'orig' direction: Source IP address. [NBO]
 *    .daddr = {...},        // 'orig' direction: Destination IP address. [NBO]
 *    .sport =  ...,         // 'orig' direction: Source port. [NBO]
 *    .dport =  ...          // 'orig' direction: Destination port. [NBO]
 *    .protocol = ...,       // IANA IP Protocol Number (protocol ID). [NBO]
 *      
 *    .saddr_reply = {...},  // 'reply' direction: Source IP address. [NBO]
 *                           // Used for NAT, otherwise equals '.daddr'.
 *      
 *    .daddr_reply = {...},  // 'reply' direction: Destination IP address.
 *                           // Used for NAT, otherwise equals '.saddr'.
 *      
 *    .sport_reply = ...,    // 'reply' direction: Source port. [NBO]
 *                           // Used for NAT, otherwise equals '.dport'.
 *      
 *    .dport_reply = ...,    // 'reply' direction: Destination port. [NBO]
 *                           // Used for NAT, otherwise equals '.sport'.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV6_CONNTRACK, sizeof(fpp_ct6_cmd_t), 
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of an IPv6 conntrack.
 * @code{.c}
 *  .............................................  
 *  fpp_ct6_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *      
 *    // Identification of the target conntrack.
 *    .saddr = {...},   // 'orig' direction: Source IP address. [NBO]
 *    .daddr = {...},   // 'orig' direction: Destination IP address. [NBO]
 *    .sport =  ...,    // 'orig' direction: Source port. [NBO]
 *    .dport =  ...,    // 'orig' direction: Destination port. [NBO]
 *    .protocol = ...,  // IANA IP Protocol Number (protocol ID). [NBO]
 *      
 *    // Modification of the target conntrack.
 *    .flags |= ntohs(CTCMD_FLAGS_TTL_DECREMENT)  // The only modification available: 
 *                                                // set/unset TTL decrement flag.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV6_CONNTRACK, sizeof(fpp_ct6_cmd_t), 
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of an IPv6 conntrack.
 * @code{.c}
 *  .............................................  
 *  fpp_ct6_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *    
 *  fpp_ct6_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u; 
 *    
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_IPV6_CONNTRACK,
 *                  sizeof(fpp_ct6_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *    
 *  // 'reply_from_fci' now holds properties of the first IPv6 conntrack from 
 *  //  the internal list of IPv6 conntracks.
 *    
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_IPV6_CONNTRACK,
 *                  sizeof(fpp_ct6_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *    
 *  // 'reply_from_fci' now holds properties of the next IPv6 conntrack from 
 *  //  the internal list of IPv6 conntracks.
 *  .............................................  
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_CT_ENTRY_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the IPv6 conntrack query session (no more IPv6 conntracks).
 *        - For other ACTIONs: Unknown (nonexistent) IPv6 conntrack was requested.
 * - @c FPP_ERR_CT_ENTRY_ALREADY_REGISTERED <br>
 *        Requested IPv6 conntrack already exists (is already registered).
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property (probably nonexistent route).
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IPV6_CONNTRACK                  0x0414

/**
 * @brief       Conntrack statistics.
 * @details     Related data types: @ref fpp_ct_cmd_t and @ref fpp_ct6_cmd_t
 * @note        @b All values are in a network byte order [@b NBO].
 *
 * @snippet     fpp.h  fpp_conntrack_stats_t
 */
/* [fpp_conntrack_stats_t] */
typedef struct CAL_PACKED_ALIGNED(4) {
    uint32 hit;        /*< Number of frames that hit the conntrack */
    uint32 hit_bytes;  /*< Sum of bytesizes of all frames that hit the conntrack */
} fpp_conntrack_stats_t;
/* [fpp_conntrack_stats_t] */

/**
 * @brief       Data structure for IPv4 conntrack.
 * @details     Related FCI commands: @ref FPP_CMD_IPV4_CONNTRACK, @ref FPP_CMD_IP_ROUTE
 * @details     See @ref l3_router for detailed explanation how to create conntracks.
 *
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp.h  fpp_ct_cmd_t
 */
/* [fpp_ct_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4) {
    uint16 action;          /*< Action */
    uint16 rsvd0;           /*< RESERVED (do not use) */
    
    uint32 saddr;           /*< 'orig' direction: Source IP address. [NBO] */
    uint32 daddr;           /*< 'orig' direction: Destination IP address. [NBO] */
    uint16 sport;           /*< 'orig' direction: Source port. [NBO] */
    uint16 dport;           /*< 'orig' direction: Destination port. [NBO] */
    
    uint32 saddr_reply;     /*< 'reply' direction: Source IP address. [NBO] 
                                   Used for NAT, otherwise equals '.daddr'. */
    
    uint32 daddr_reply;     /*< 'reply' direction: Destination IP address. [NBO]
                                   Used for NAT, otherwise equals '.saddr'. */
    
    uint16 sport_reply;     /*< 'reply' direction: Source port. [NBO]
                                   Used for NAT, otherwise equals '.dport'. */
    
    uint16 dport_reply;     /*< 'reply' direction: Destination port. [NBO] 
                                   Used for NAT, otherwise equals '.sport'. */
    
    uint16 protocol;        /*< IANA IP Protocol Number (protocol ID). [NBO] */
    uint16 flags;           /*< Flags. A bitset. [NBO]. See FPP_CMD_IPV4_CONNTRACK. */
    uint32 fwmark;          /*< RESERVED (do not use) */
    
    uint32 route_id;        /*< 'orig' direction: ID of an associated route. [NBO]
                                  See FPP_CMD_IP_ROUTE. */
    
    uint32 route_id_reply;  /*< 'reply' direction: ID of an associated route. [NBO]
                                  See FPP_CMD_IP_ROUTE. */
    
    uint16 vlan;            /*< 'orig' direction: VLAN tag. [NBO]
                                  If non-zero, then this VLAN tag is added to the routed
                                  packet. If the packet already has a VLAN tag, then its tag
                                  is replaced. */
    
    uint16 vlan_reply;      /*< 'reply' direction: VLAN tag. [NBO]
                                  If non-zero, then this VLAN tag is added to the routed
                                  packet. If the packet already has a VLAN tag, then its tag
                                  is replaced. */

    fpp_conntrack_stats_t CAL_PACKED_ALIGNED(4) stats;        /*< 'orig'  statistics [ro] */
    fpp_conntrack_stats_t CAL_PACKED_ALIGNED(4) stats_reply;  /*< 'reply' statistics [ro] */
} fpp_ct_cmd_t;
/* [fpp_ct_cmd_t] */

typedef struct CAL_PACKED {
    uint16 action;                       /*Action to perform*/
    uint16 format;                       /* bit 0 : indicates if SA info are present in command */
                                                /* bit 1 : indicates if orig Route info is present in command  */
                                                /* bit 2 : indicates if repl Route info is present in command  */
    uint32 saddr;                        /*Source IP address*/
    uint32 daddr;                        /*Destination IP address*/
    uint16 sport;                        /*Source Port*/
    uint16 dport;                        /*Destination Port*/
    uint32 saddr_reply;
    uint32 daddr_reply;
    uint16 sport_reply;
    uint16 dport_reply;
    uint16 protocol;             /*TCP, UDP ...*/
    uint16 flags;
    uint32 fwmark;
    uint32 route_id;
    uint32 route_id_reply;
        /* optional security parameters */
        uint8 sa_dir;
        uint8 sa_nr;
        uint16 sa_handle[4];
        uint8 sa_reply_dir;
        uint8 sa_reply_nr;
        uint16 sa_reply_handle[4];
    uint32 tunnel_route_id;
    uint32 tunnel_route_id_reply;
} fpp_ct_ex_cmd_t;

/**
 * @brief       Data structure for IPv6 conntrack.
 * @details     Related FCI commands: @ref FPP_CMD_IPV6_CONNTRACK, @ref FPP_CMD_IP_ROUTE
 * @details     See @ref l3_router for detailed explanation how to create conntracks.
 *
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp.h  fpp_ct6_cmd_t
 */
/* [fpp_ct6_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4) {
    uint16 action;          /*< Action */
    uint16 rsvd1;           /*< RESERVED (do not use) */
    
    uint32 saddr[4];        /*< 'orig' direction: Source IP address. [NBO] */
    uint32 daddr[4];        /*< 'orig' direction: Destination IP address. [NBO] */
    uint16 sport;           /*< 'orig' direction: Source port. [NBO] */
    uint16 dport;           /*< 'orig' direction: Destination port. [NBO] */
    
    uint32 saddr_reply[4];  /*< 'reply' direction: Source IP address. [NBO] 
                                   Used for NAT, otherwise equals '.daddr'. */
    
    uint32 daddr_reply[4];  /*< 'reply' direction: Destination IP address. [NBO]
                                   Used for NAT, otherwise equals '.saddr'. */
    
    uint16 sport_reply;     /*< 'reply' direction: Source port. [NBO]
                                   Used for NAT, otherwise equals '.dport'. */
    
    uint16 dport_reply;     /*< 'reply' direction: Destination port. [NBO] 
                                   Used for NAT, otherwise equals '.sport'. */
    
    uint16 protocol;        /*< IANA IP Protocol Number (protocol ID). [NBO] */
    uint16 flags;           /*< Flags. A bitset. [NBO. See FPP_CMD_IPV4_CONNTRACK. */
    uint32 fwmark;          /*< RESERVED (do not use) */
    
    uint32 route_id;        /*< 'orig' direction: ID of an associated route. [NBO]
                                  See FPP_CMD_IP_ROUTE. */
    
    uint32 route_id_reply;  /*< 'reply' direction: ID of an associated route. [NBO]
                                  See FPP_CMD_IP_ROUTE. */
    
    uint16 vlan;            /*< 'orig' direction: VLAN tag. [NBO]
                                  If non-zero, then this VLAN tag is added to the routed
                                  packet. If the packet already has a VLAN tag, then its tag
                                  is replaced. */
    
    uint16 vlan_reply;      /*< 'reply' direction: VLAN tag. [NBO]
                                  If non-zero, then this VLAN tag is added to the routed
                                  packet. If the packet already has a VLAN tag, then its tag
                                  is replaced. */

    fpp_conntrack_stats_t CAL_PACKED_ALIGNED(4) stats;        /*< 'orig'  statistics [ro] */
    fpp_conntrack_stats_t CAL_PACKED_ALIGNED(4) stats_reply;  /*< 'reply' statistics [ro] */
} fpp_ct6_cmd_t;
/* [fpp_ct6_cmd_t] */

typedef struct CAL_PACKED {
    uint16 action;                       /*Action to perform*/
    uint16 format;                       /* indicates if SA info are present in command */
    uint32 saddr[4];                     /*Source IP address*/
    uint32 daddr[4];                     /*Destination IP address*/
    uint16 sport;                        /*Source Port*/
    uint16 dport;                        /*Destination Port*/
    uint32 saddr_reply[4];
    uint32 daddr_reply[4];
    uint16 sport_reply;
    uint16 dport_reply;
    uint16 protocol;                     /*TCP, UDP ...*/
    uint16 flags;
    uint32 fwmark;
    uint32 route_id;
    uint32 route_id_reply;
    uint8 sa_dir;
    uint8 sa_nr;
    uint16 sa_handle[4];
    uint8 sa_reply_dir;
    uint8 sa_reply_nr;
    uint16 sa_reply_handle[4];
    uint32 tunnel_route_id;
    uint32 tunnel_route_id_reply;
} fpp_ct6_ex_cmd_t;

/** @}*/

/*--------------------------------------- IP ---------------------------------*/ 
#define FPP_ERR_RT_ENTRY_ALREADY_REGISTERED     200
#define FPP_ERR_RT_ENTRY_NOT_FOUND          201

/**
 * @addtogroup  dxgrLibFCI
 * @{
 */

/**
 * @def         FPP_CMD_IP_ROUTE
 * @brief       FCI command for management of IP routes.
 * @details     Related topics: @ref l3_router
 * @details     Related data types: @ref fpp_rt_cmd_t
 * @details     In the context of PFE, a route represents a direction where the matching 
 *              traffic shall be forwarded to. Every route specifies an egress physical interface
 *              and a MAC address of the next network node.
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new route.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing route.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a route query session and get properties 
 *                   of the first route from the internal collective list of all routes
 *                   (regardless of IP type nor conntrack affiliation).
 *              - @c FPP_ACTION_QUERY_CONT <br> 
 *                   Continue the query session and get properties of the next route
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new route. For detailed info about route properties, see fpp_rt_cmd_t.
 * @code{.c}
 *  .............................................  
 *  fpp_rt_cmd_t cmd_to_fci = 
 *  {
 *    .action  = FPP_ACTION_REGISTER,  // Action
 *    .src_mac = ...,                  // Source MAC address.
 *    .dst_mac = ...,                  // Destination MAC address.
 *    .output_device = ...,            // Name of the egress physical interface.
 *    .id    = ...,                    // Route ID. [NBO]. User-defined.
 *    .flags = ...                     // Flags. [NBO]. 1 for IPv4 routes, 2 for IPv6 routes.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IP_ROUTE, sizeof(fpp_rt_cmd_t), 
 *                                           (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing route.
 * @code{.c}
 *  .............................................  
 *  fpp_rt_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .id     = ...                     // Route ID. [NBO]. User-defined.
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IP_ROUTE, sizeof(fpp_rt_cmd_t), 
 *                                           (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of a route.
 * @code{.c}
 *  .............................................  
 *  fpp_rt_cmd_t cmd_to_fci = 
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *    
 *  fpp_rt_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u; 
 *    
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_IP_ROUTE,
 *                  sizeof(fpp_rt_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *    
 *  // 'reply_from_fci' now holds properties of the first route from 
 *  //  the internal collective list of all routes.
 *    
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_IP_ROUTE,
 *                  sizeof(fpp_rt_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *    
 *  // 'reply_from_fci' now holds properties of the next route from 
 *  //  the internal collective list of all routes.
 *  .............................................  
 * @endcode 
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_RT_ENTRY_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the route query session (no more routes).
 *        - For other ACTIONs: Unknown (nonexistent) route was requested.
 * - @c FPP_ERR_RT_ENTRY_ALREADY_REGISTERED <br>
 *        Requested route already exists (is already registered).
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IP_ROUTE            0x0313

/**
 * @def         FPP_CMD_IPV4_RESET
 * @brief       FCI command to remove all IPv4 routes and conntracks. 
 * @details     Related topics: @ref l3_router, @ref FPP_CMD_IP_ROUTE, <br> @ref FPP_CMD_IPV4_CONNTRACK
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................  
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV4_RESET, 0, NULL); 
 *  .............................................  
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IPV4_RESET          0x0316
#define FPP_CMD_IP_ROUTE_CHANGE         0x0318

/**
 * @def         FPP_CMD_IPV6_RESET
 * @brief       FCI command to remove all IPv6 routes and conntracks. 
 * @details     Related topics: @ref l3_router, @ref FPP_CMD_IP_ROUTE, <br> @ref FPP_CMD_IPV6_CONNTRACK
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................  
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV6_RESET, 0, NULL); 
 *  .............................................  
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IPV6_RESET              0x0416

/**
 * @brief       Data structure for a route.
 * @details     Related FCI commands: @ref FPP_CMD_IP_ROUTE
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp.h  fpp_rt_cmd_t
 */
/* [fpp_rt_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4) {
    uint16 action;        /*< Action */
    uint16 mtu;           /*< RESERVED (do not use) */
    
    uint8 src_mac[6];     /*< Source MAC address. When a packet is routed, this address 
                                is set as the source MAC address of the packet. If left
                                unset (all-zero), then PFE automatically uses MAC address
                                of the associated physical interface (.output_device). */
    
    uint8 dst_mac[6];     /*< Destination MAC address. When a packet is routed, this address
                                is set as the destination MAC address of the packet. */
    
    uint16 pad;           /*< RESERVED (do not use) */
    
    char output_device[IFNAMSIZ];   /*< Name of the egress physical interface. 
                                        When a packet is routed, it is egressed
                                        through this physical interface. */
    
    char input_device[IFNAMSIZ];            /*< RESERVED (do not use) */
    char underlying_input_device[IFNAMSIZ]; /*< RESERVED (do not use) */
    
    uint32 id;            /*< Route ID. [NBO]. Unique route identifier. */
    uint32 flags;         /*< Flags. [NBO]. 1 for IPv4 routes, 2 for IPv6 routes. */
    
    uint32 dst_addr[4];   /*< RESERVED (do not use) */
} fpp_rt_cmd_t;
/* [fpp_rt_cmd_t] */

#define FPP_IP_ROUTE_6o4    (1<<0)
#define FPP_IP_ROUTE_4o6    (1<<1)

/* Structure representing the command sent to enable/disable Ipsec pre-fragmentation */
typedef struct {
    uint16 pre_frag_en;
    uint16 rsvd;
} __attribute__((__packed__)) fpp_ipsec_cmd_t;

/** @}*/

/* ----------------------------------- RTP ----------------------------------*/
#define FPP_ERR_RTP_STATS_MAX_ENTRIES           1230
#define FPP_ERR_RTP_STATS_STREAMID_ALREADY_USED 1231
#define FPP_ERR_RTP_STATS_STREAMID_UNKNOWN      1232
#define FPP_ERR_RTP_STATS_DUPLICATED            1233
#define FPP_ERR_RTP_STATS_WRONG_DTMF_PT         1234
#define FPP_ERR_RTP_STATS_WRONG_TYPE            1235


#define FPP_CMD_RTP_OPEN        0x0801
#define FPP_CMD_RTP_UPDATE      0x0802
#define FPP_CMD_RTP_TAKEOVER    0x0803
#define FPP_CMD_RTP_CONTROL     0x0804
#define FPP_CMD_RTP_SPECTX_PLD  0x0805
#define FPP_CMD_RTP_SPECTX_CTRL 0x0806
#define FPP_CMD_RTCP_QUERY      0x0807
#define FPP_CMD_RTP_CLOSE       0x0808

#define FPP_RTP_TAKEOVER_MODE_TSINCR_FREQ   1
#define FPP_RTP_TAKEOVER_MODE_SSRC          2

#define FPP_MAX_SPTX_STRING_SIZE    160

typedef struct {
    uint16    call_id;
    uint16    socket_a;
    uint16    socket_b;
    uint16    rsvd;
} __attribute__((__packed__)) fpp_rtp_open_cmd_t;

typedef struct {
    uint16    call_id;
    uint16    rsvd;
} __attribute__((__packed__)) fpp_rtp_close_cmd_t;

typedef struct {
    uint16    call_id;
    uint16    socket;
    uint16    mode;
    uint16    seq_number_base;
    uint32    ssrc;
    uint32    ts_base;
    uint32    ts_incr;
} __attribute__((__packed__)) fpp_rtp_takeover_cmd_t;

typedef struct {
    uint16    call_id;
    uint16    control_dir;
} __attribute__((__packed__)) fpp_rtp_ctrl_cmd_t;

#define FPP_RTP_SPEC_TX_START       0
#define FPP_RTP_SPEC_TX_RESPONSE    1
#define FPP_RTP_SPEC_TX_STOP        2

typedef struct {
        uint16    call_id;
        uint16    type;
} __attribute__((__packed__)) fpp_rtp_spec_tx_ctrl_cmd_t;

typedef struct {
        uint16    call_id;
        uint16    payload_id;
        uint16    payload_length;
        uint16    payload[80];
} __attribute__((__packed__)) fpp_rtp_spec_tx_payload_cmd_t;

typedef struct {
    uint16    socket_id;
    uint16       flags;
} __attribute__((__packed__)) fpp_rtcp_query_cmd_t;

typedef struct {
    uint32    prev_reception_period;
    uint32    last_reception_period;
    uint32    num_tx_pkts;
    uint32    num_rx_pkts;
    uint32    last_rx_seq;
    uint32    last_rx_timestamp;
    uint8 rtp_header[12];
    uint32    num_rx_dup;
    uint32    num_rx_since_rtcp;
    uint32    num_tx_bytes;
    uint32    min_jitter;
    uint32    max_jitter;
    uint32    average_jitter;
    uint32    num_rx_lost_pkts;
    uint32    min_reception_period;
    uint32    max_reception_period;
    uint32    average_reception_period;
    uint32    num_malformed_pkts;
    uint32    num_expected_pkts;
    uint32    num_late_pkts;
    uint16    sport;
    uint16    dport;
    uint32    num_cumulative_rx_lost_pkts;
    uint32    ssrc_overwrite_value;
} __attribute__((__packed__)) fpp_rtcp_query_res_t;

/*-------------------------------- RTP QoS Measurement-----------------------*/
#define FPP_CMD_RTP_STATS_ENABLE        0x0810
#define FPP_CMD_RTP_STATS_DISABLE       0x0811
#define FPP_CMD_RTP_STATS_QUERY         0x0812
#define FPP_CMD_RTP_STATS_DTMF_PT       0x0813

#define FPP_RTPSTATS_TYPE_IP4       0
#define FPP_RTPSTATS_TYPE_IP6       1
#define FPP_RTPSTATS_TYPE_MC4       2
#define FPP_RTPSTATS_TYPE_MC6       3
#define FPP_RTPSTATS_TYPE_RLY       4
#define FPP_RTPSTATS_TYPE_RLY6      5

typedef struct {
    uint16 stream_id;
    uint16 stream_type;
    uint32 saddr[4];
    uint32 daddr[4];
    uint16 sport;
    uint16 dport;
    uint16 proto;
    uint16 mode;
} __attribute__((__packed__)) fpp_rtp_stat_enable_cmd_t;

typedef struct {
    uint16 stream_id;
} __attribute__((__packed__)) fpp_rtp_stat_disable_cmd_t;

typedef struct  {
    uint16 pt; /* 2 payload types coded on 8bits */
} __attribute__((__packed__)) fpp_rtp_stat_dtmf_pt_cmd_t;


/*-------------------------------- Voice Buffer-----------------------*/
#define FPP_CMD_VOICE_BUFFER_LOAD   0x0820
#define FPP_CMD_VOICE_BUFFER_UNLOAD 0x0821
#define FPP_CMD_VOICE_BUFFER_START  0x0822
#define FPP_CMD_VOICE_BUFFER_STOP   0x0823
#define FPP_CMD_VOICE_BUFFER_RESET  0x0824

#define FPP_VOICE_BUFFER_SCATTER_MAX    48

typedef struct {
    uint16 buffer_id;
    uint16 payload_type;
    uint16 frame_size;
    uint16 entries;
    uint32 data_len;
    uint8 page_order[FPP_VOICE_BUFFER_SCATTER_MAX];
    uint32 addr[FPP_VOICE_BUFFER_SCATTER_MAX];
} __attribute__((__packed__)) fpp_voice_buffer_load_cmd_t;

typedef struct {
    uint16 buffer_id;
} __attribute__((__packed__)) fpp_voice_buffer_unload_cmd_t;

typedef struct {
    uint16 socket_id;
    uint16 buffer_id;
    uint16 seq_number_base;
    uint16 padding;
    uint32 ssrc;
    uint32 timestamp_base;
} __attribute__((__packed__)) fpp_voice_buffer_start_cmd_t;

typedef struct {
        uint16 socket_id;
} __attribute__((__packed__)) fpp_voice_buffer_stop_cmd_t;
/*-------------------------------- Exceptions -------------------------------*/
#define FPP_CMD_EXPT_QUEUE_DSCP             0x0C01
#define FPP_CMD_EXPT_QUEUE_CONTROL          0x0C02
#define FPP_CMD_EXPT_QUEUE_RESET            0x0C03

#define FPP_EXPT_Q0 0
#define FPP_EXPT_Q1 1
#define FPP_EXPT_Q2 2
#define FPP_EXPT_Q3 3
#define FPP_EXPT_MAX_QUEUE  FPP_EXPT_Q3

#define FPP_EXPT_MAX_DSCP   63

typedef struct {
    uint16    queue;
    uint16    num_dscp;
    uint8 dscp[FPP_EXPT_MAX_DSCP];
    uint8 pad;
} __attribute__((__packed__)) fpp_expt_queue_dscp_cmd_t;

typedef struct {
    uint16    queue;
    uint16    pad;
} __attribute__((__packed__)) fpp_expt_queue_control_cmd_t;

/*--------------------------------------------- QM ---------------------------*/
/* 0x0200 -> 0x02FF : QM module */
#define FPP_CMD_QM_QOSENABLE        0x0201
#define FPP_CMD_QM_QOSALG       0x0202
#define FPP_CMD_QM_NHIGH        0x0203
#define FPP_CMD_QM_MAX_TXDEPTH      0x0204
#define FPP_CMD_QM_MAX_QDEPTH       0x0205
#define FPP_CMD_QM_MAX_WEIGHT       0x0206
#define FPP_CMD_QM_RATE_LIMIT       0x0207
#define FPP_CMD_QM_EXPT_RATE        0x020c
#define FPP_CMD_QM_QUERY        0x020d
#define FPP_CMD_QM_QUERY_EXPT_RATE  0x020e
                
#define FPP_CMD_QM_RESET        0x0210 
#define FPP_CMD_QM_SHAPER_CFG       0x0211 
#define FPP_CMD_QM_SCHED_CFG        0x0212 
#define FPP_CMD_QM_DSCP_MAP     0x0213 
#define FPP_CMD_QM_QUEUE_QOSENABLE    0x0214

#define FPP_CMD_QM_QUERY_PORTINFO   0x0220
#define FPP_CMD_QM_QUERY_QUEUE      0x0221
#define FPP_CMD_QM_QUERY_SHAPER     0x0222
#define FPP_CMD_QM_QUERY_SCHED      0x0223

#define FPP_MAX_DSCP                63
#define FPP_NUM_DSCP                64

#if defined(COMCERTO_2000) ||  defined(LS1043)
#define FPP_NUM_QUEUES          16
#define FPP_PORT_SHAPER_NUM     0xffff
#else
#define FPP_NUM_QUEUES          32
#endif

#ifndef LS1043
#define FPP_NUM_SHAPERS         8
#define FPP_NUM_SCHEDULERS      8
#else
#define FPP_NUM_SHAPERS         1
#define FPP_NUM_SCHEDULERS      1
#endif

#define FPP_EXPT_TYPE_ETH   0x0
#define FPP_EXPT_TYPE_WIFI  0x1
#define FPP_EXPT_TYPE_ARP   0x2
#define FPP_EXPT_TYPE_PCAP  0x3

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
    uint16    enable;
} __attribute__((__packed__)) fpp_qm_qos_enable_cmd_t;              

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
    uint16 enable_flag;
    uint32 queue_qosenable_mask; /* Bit mask of queues on which Qos is enabled */
} __attribute__((__packed__)) fpp_qm_queue_qos_enable_cmd_t;


typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    scheduler;
} __attribute__((__packed__)) fpp_qm_qos_alg_cmd_t;
                
typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    number_high_queues;
} __attribute__((__packed__)) fpp_qm_nhigh_cmd_t;

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    max_bytes;
} __attribute__((__packed__)) fpp_qm_max_txdepth_cmd_t;

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    qtxdepth[FPP_NUM_QUEUES];
} __attribute__((__packed__)) fpp_qm_max_qdepth_cmd_t;

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    qxweight[FPP_NUM_QUEUES];
} __attribute__((__packed__)) fpp_qm_max_weight_cmd_t;

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    enable;
        uint32    queues;
        uint32    rate;
        uint32    bucket_size;
} __attribute__((__packed__)) fpp_qm_rate_limit_cmd_t;

typedef struct {
        uint16    if_type;
        uint16    pkts_per_msec;
} __attribute__((__packed__)) fpp_qm_expt_rate_cmd_t;

typedef struct
{
        uint16    action;
        uint16    mask;
        uint32    aggregate_bandwidth;
        uint32    bucketsize;
} __attribute__((__packed__)) fpp_qm_query_rl_t;

#ifndef COMCERTO_2000
typedef struct
{
    uint16 action;
    uint16 port;
    uint32 queue_qosenable_mask;         /* bit mask of queues on which Qos is enabled */
    uint32 max_txdepth;

    uint32 shaper_qmask[FPP_NUM_SHAPERS];         /* mask of queues assigned to this shaper */
    uint32 tokens_per_clock_period[FPP_NUM_SHAPERS];  /* bits worth of tokens available on every 1 msec clock period */
    uint32 bucket_size[FPP_NUM_SHAPERS];      /* max bucket size in bytes */

    uint32 sched_qmask[FPP_NUM_SCHEDULERS];
    uint8 sched_alg[FPP_NUM_SCHEDULERS];              /* current scheduling algorithm */
    
    uint16 max_qdepth[FPP_NUM_QUEUES];
} __attribute__((__packed__)) fpp_qm_query_cmd_t;
#endif

#if defined(COMCERTO_2000) || defined(LS1043)
typedef struct fpp_qm_query_portinfo_cmd
{
    uint16 status;
#ifndef LS1043
    uint16 port;
#else
    uint8 interface[IFNAMSIZ];
#endif
    uint32 queue_qosenable_mask;         /* bit mask of queues on which Qos is enabled */
    uint16 max_txdepth;           /* ignored on C2000 */
    uint8  ifg;
    uint8  unused;
} __attribute__((__packed__)) fpp_qm_query_portinfo_cmd_t;

typedef struct fpp_qm_query_queue_cmd
{
    uint16 status;
#ifndef LS1043
    uint16 port;
#else
    uint8 interface[IFNAMSIZ];
#endif
    uint16 queue_num;
    uint16 qweight;
    uint16 max_qdepth;
    uint16 unused;
} __attribute__((__packed__)) fpp_qm_query_queue_cmd_t;

typedef struct fpp_qm_query_shaper_cmd
{
    uint16 status;
#ifndef LS1043
    uint16 port;
#else
    uint8 interface[IFNAMSIZ];
#endif
    uint16 shaper_num;
    uint8  enabled;
    uint8  unused;
    uint32 qmask;
    uint32 rate;
    uint32 bucket_size;
} __attribute__((__packed__)) fpp_qm_query_shaper_cmd_t;

typedef struct fpp_qm_query_sched_cmd
{
    uint16 status;
#ifndef LS1043
    uint16 port;
#else
    uint8 interface[IFNAMSIZ];
#endif
    uint16 sched_num;
    uint8  alg;
    uint8  unused;
    uint32 qmask;
} __attribute__((__packed__)) fpp_qm_query_sched_cmd_t;
#endif

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
    uint16    pad;
} __attribute__((__packed__)) fpp_qm_reset_cmd_t;

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    shaper;
        uint16    enable;
        uint8 ifg;
        uint8 ifg_change_flag;
        uint32    rate;
        uint32    bucket_size;
        uint32    queues;
} __attribute__((__packed__)) fpp_qm_shaper_cfg_t;

typedef struct {
#ifndef LS1043
    uint16    interface;
#else
    uint8 interface[IFNAMSIZ];
#endif
        uint16    scheduler;
        uint8 algo;
        uint8 algo_change_flag;
    uint16    pad;
        uint32    queues;
} __attribute__((__packed__)) fpp_qm_scheduler_cfg_t;

typedef struct {
        uint16    queue;
        uint16    num_dscp;
        uint8 dscp[FPP_NUM_DSCP];
} __attribute__((__packed__)) fpp_qm_dscp_queue_mod_t;

/*---------------------------------------- RX --------------------------------*/
/*Function codes*/
/* 0x00xx : Rx module */
#define FPP_CMD_RX_CNG_ENABLE           0x0003
#define FPP_CMD_RX_CNG_DISABLE          0x0004
#define FPP_CMD_RX_CNG_SHOW         0x0005

#define FPP_CMD_RX_L2BRIDGE_ENABLE      0x0008
#define FPP_CMD_RX_L2BRIDGE_ADD         0x0009
#define FPP_CMD_RX_L2BRIDGE_REMOVE      0x000a
#define FPP_CMD_RX_L2BRIDGE_QUERY_STATUS    0x000b
#define FPP_CMD_RX_L2BRIDGE_QUERY_ENTRY     0x000c
#define FPP_CMD_RX_L2FLOW_ENTRY     0x000d
#define FPP_CMD_RX_L2BRIDGE_MODE            0x000e
#define FPP_CMD_RX_L2BRIDGE_FLOW_TIMEOUT    0x000f
#define FPP_CMD_RX_L2BRIDGE_FLOW_RESET      0x0010


#define FPP_CMD_L2BRIDGE_LRN_TIMEOUT   0x0020
#define FPP_CMD_L2BRIDGE_LRN_RESET     0x0021
#define FPP_CMD_L2BRIDGE_ENABLE_PORT   0x0022
#define FPP_CMD_L2BRIDGE_ADD_ENTRY     0x0023
#define FPP_CMD_L2BRIDGE_REMOVE_ENTRY  0x0024
#define FPP_CMD_L2BRIDGE_QUERY_ENTRY   0x0025
#define FPP_CMD_L2BRIDGE_QUERY_STATUS  0x0026
#define FPP_CMD_L2BRIDGE_MODE          0x0027

#define FPP_ERR_BRIDGE_ENTRY_NOT_FOUND  50
#define FPP_ERR_BRIDGE_ENTRY_ALREADY_EXISTS  51

#define FPP_BRIDGE_QMOD_NONE            0
#define FPP_BRIDGE_QMOD_DSCP            1

#define FPP_L2_BRIDGE_MODE_MANUAL   0   
#define FPP_L2_BRIDGE_MODE_AUTO     1
#define FPP_L2_BRIDGE_MODE_LEARNING    2
#define FPP_L2_BRIDGE_MODE_NO_LEARNING 3

typedef struct {
    uint16    interface;
    uint16    acc_value;
    uint16    on_thr;
    uint16    off_thr;
    uint32    flag;
    uint32    val1;
    uint32    val2;
} __attribute__((__packed__)) fpp_rx_icc_enable_cmd_t;

typedef struct {
    uint16    interface;
} __attribute__((__packed__)) fpp_rx_icc_disable_cmd_t;

typedef struct {
    uint16    padding_in_rc_out;
    uint16    state;
    uint16    acc_value;
    uint16    on_thr;
    uint16    off_thr;
} __attribute__((__packed__)) fpp_rx_icc_show_return_cmd_t;

/* L2 Bridging Enable command */
typedef struct {
    uint16    interface;
    uint16    enable_flag;
    char        input_name[IFNAMSIZ];
} __attribute__((__packed__)) fpp_l2_bridge_enable_cmd_t;


/* L2 Bridging Add Entry command */
typedef struct {
    uint16    input_interface;
    uint16    input_svlan;
    uint16    input_cvlan;
    uint8 destaddr[6];
    uint8 srcaddr[6];
    uint16    ethertype;
    uint16    output_interface;
    uint16    output_svlan;
    uint16    output_cvlan;
    uint16    pkt_priority;
    uint16    svlan_priority;
    uint16    cvlan_priority;
    char        input_name[IFNAMSIZ];
    char        output_name[IFNAMSIZ];
    uint16    queue_modifier;
    uint16    session_id;
} __attribute__((__packed__)) fpp_l2_bridge_add_entry_cmd_t;


/* L2 Bridging Remove Entry command */
typedef struct {
    uint16    input_interface;
    uint16    input_svlan;
    uint16    input_cvlan;
        uint8 destaddr[6];
        uint8 srcaddr[6];
    uint16    ethertype;
    uint16    session_id;
    uint16    reserved;
    char        input_name[IFNAMSIZ];
} __attribute__((__packed__)) fpp_l2_bridge_remove_entry_cmd_t;


/* L2 Bridging Query Status response */
typedef struct {
    uint16 ackstatus;
    uint16 status;
    uint8 ifname[IFNAMSIZ];
    uint32 eof;
} __attribute__((__packed__)) fpp_l2_bridge_query_status_response_t;


/* L2 Bridging Query Entry response */
typedef struct {
    uint16    ackstatus;
    uint16    eof;
    uint16    input_interface;
    uint16    input_svlan;
    uint16    input_cvlan;
    uint8 destaddr[6];
    uint8 srcaddr[6];
    uint16    ethertype;
    uint16    output_interface;
    uint16    output_svlan;
    uint16    output_cvlan;
    uint16    pkt_priority;
    uint16    svlan_priority;
    uint16    cvlan_priority;
    char        input_name[IFNAMSIZ];
    char        output_name[IFNAMSIZ];
    uint16    queue_modifier;
    uint16    session_id;
} __attribute__((__packed__)) fpp_l2_bridge_query_entry_response_t;

/* L2 Bridging  Flow entry command */
typedef struct {
    uint16 action;                /*Action to perform*/
    uint16    ethertype;          /* If VLAN Tag !=0, ethertype of next header */
    uint8 destaddr[6];            /* Dst MAC addr */
    uint8 srcaddr[6];         /* Src MAC addr */
    uint16    svlan_tag;          /* S TCI */
    uint16    cvlan_tag;          /* C TCI */
    uint16    session_id;         /* Meaningful only if ethertype PPPoE */
    uint16    pad1;
    char        input_name[IFNAMSIZ];       /* Input itf name */
    char        output_name[IFNAMSIZ];  /* Output itf name */
    /* L3-4 optional information*/
    uint32 saddr[4];
    uint32 daddr[4];
    uint16 sport;
    uint16 dport;
    uint8 proto;
    uint8 pad;
    uint16 mark;              /* QoS Mark*/
    uint32 timeout;           /* Entry timeout only for QUERY */
} __attribute__((__packed__)) fpp_l2_bridge_flow_entry_cmd_t;

/* L2 Bridging Control command */
typedef struct {
    uint16 mode_timeout;      /* Either set bridge mode or set timeout for flow entries */
} __attribute__((__packed__)) fpp_l2_bridge_control_cmd_t;

/*------------------------------------- Stat ----------------------------------*/
/*Function codes*/
/* 0x00xx : Stat module */
#define FPP_CMD_STAT_ENABLE     0x0E01 
#define FPP_CMD_STAT_QUEUE      0x0E02  
#define FPP_CMD_STAT_INTERFACE_PKT  0x0E03
#define FPP_CMD_STAT_CONNECTION     0x0E04
#define FPP_CMD_STAT_PPPOE_STATUS   0x0E05
#define FPP_CMD_STAT_PPPOE_ENTRY    0x0E06
#define FPP_CMD_STAT_BRIDGE_STATUS  0x0E07
#define FPP_CMD_STAT_BRIDGE_ENTRY   0x0E08
#define FPP_CMD_STAT_IPSEC_STATUS   0x0E09
#define FPP_CMD_STAT_IPSEC_ENTRY    0x0E0A
#define FPP_CMD_STAT_VLAN_STATUS        0x0E0B
#define FPP_CMD_STAT_VLAN_ENTRY         0x0E0C
#define FPP_CMD_STAT_TUNNEL_STATUS      0x0E0D
#define FPP_CMD_STAT_TUNNEL_ENTRY       0x0E0E
#define FPP_CMD_STAT_FLOW               0x0E0F

#define FPP_CMM_STAT_RESET      0x0001
#define FPP_CMM_STAT_QUERY      0x0002
#define FPP_CMM_STAT_QUERY_RESET    0x0003

#define FPP_CMM_STAT_ENABLE     0x0001
#define FPP_CMM_STAT_DISABLE        0x0000

/* Definitions of Bit Masks for the features */
#define FPP_STAT_QUEUE_BITMASK      0x00000001
#define FPP_STAT_INTERFACE_BITMASK  0x00000002
#define FPP_STAT_PPPOE_BITMASK      0x00000008
#define FPP_STAT_BRIDGE_BITMASK     0x00000010
#define FPP_STAT_IPSEC_BITMASK      0x00000020
#define FPP_STAT_VLAN_BITMASK       0x00000040
#define FPP_STAT_TUNNEL_BITMASK     0x00000080
#define FPP_STAT_FLOW_BITMASK           0x00000100

#define FPP_STAT_UNKNOWN_CMD        0
#define FPP_STAT_ENABLE_CMD     1 
#define FPP_STAT_QUEUE_CMD      2
#define FPP_STAT_INTERFACE_PKT_CMD  3
#define FPP_STAT_CONNECTION_CMD     4
#define FPP_STAT_PPPOE_CMD      5
#define FPP_STAT_BRIDGE_CMD     6
#define FPP_STAT_IPSEC_CMD      7
#define FPP_STAT_VLAN_CMD               8
#define FPP_STAT_TUNNEL_CMD             9
#define FPP_STAT_FLOW_CMD              10

#define FPP_ERR_FLOW_ENTRY_NOT_FOUND    1600
#define FPP_ERR_INVALID_IP_FAMILY   1601

typedef struct {
    uint16    action; /* 1 - Enable, 0 - Disable */
    uint16    pad;
    uint32    bitmask; /* Specifies the feature to be enabled or disabled */
} __attribute__((__packed__)) fpp_stat_enable_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    interface;
    uint16    queue;
    uint16    pad;
} __attribute__((__packed__)) fpp_stat_queue_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    interface;
} __attribute__((__packed__)) fpp_stat_interface_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    pad;
} __attribute__((__packed__)) fpp_stat_connection_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    pad;
} __attribute__((__packed__)) fpp_stat_pppoe_status_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    pad;
} __attribute__((__packed__)) fpp_stat_bridge_status_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    pad;
} __attribute__((__packed__)) fpp_stat_ipsec_status_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    pad;
} __attribute__((__packed__)) fpp_stat_vlan_status_cmd_t;

typedef struct {
    uint16    action; /* Reset, Query, Query & Reset */
    uint16    pad;
        char            if_name[IFNAMSIZ];
} __attribute__((__packed__)) fpp_stat_tunnel_status_cmd_t;

typedef struct {
    uint8 action;
    uint8 pad;
    uint8 ip_family;
    uint8 Protocol;
    uint16    Sport;      /*Source Port*/
    uint16    Dport;      /*Destination Port*/
    union {
        struct {
            uint32    Saddr;      /*Source IPv4 address*/
            uint32    Daddr;      /*Destination IPv4 address*/
        } v4;
        struct {
            uint32    Saddr_v6[4];        /*Source IPv6 address*/
            uint32    Daddr_v6[4];        /*Destination IPv6 address*/
        } v6;
    } ipv;
} __attribute__((__packed__)) fpp_stat_flow_status_cmd_t;

typedef struct {
    uint16    ackstatus;
    uint16    rsvd1;
    uint32    peak_queue_occ;
    uint32    emitted_pkts;
    uint32    dropped_pkts;
} __attribute__((__packed__)) fpp_stat_queue_response_t;

typedef struct {
    uint16    ackstatus;
    uint16    rsvd1;
    uint32    total_pkts_transmitted;
    uint32    total_pkts_received;
    uint32    total_bytes_transmitted[2]; /* 64 bit counter stored as 2*32 bit counters */
    uint32    total_bytes_received[2]; /* 64 bit counter stored as 2*32 bit counters */
} __attribute__((__packed__)) fpp_stat_interface_pkt_response_t;

typedef struct {
    uint16    ackstatus;
    uint16    rsvd1;
    uint32    max_active_connections;
    uint32    num_active_connections;
} __attribute__((__packed__)) fpp_stat_conn_response_t;

typedef struct {
    uint16 ackstatus;
} __attribute__((__packed__)) fpp_stat_pppoe_status_response_t;

typedef struct {
    uint16    ackstatus;
    uint16    eof;
    uint16    sessionid;
    uint16    interface_no; /* WAN_PORT_ID for WAN & LAN_PORT_ID for LAN */
    uint32    total_packets_received;
    uint32    total_packets_transmitted;
} __attribute__((__packed__)) fpp_stat_pppoe_entry_response_t;

typedef struct {
    uint16    ackstatus;
} __attribute__((__packed__)) fpp_stat_bridge_status_response_t;

typedef struct {
    uint16    ackstatus;
    uint16    eof;
    uint16    input_interface;
    uint16    input_svlan;
    uint16    input_cvlan;
    uint8 dst_mac[6];
    uint8 src_mac[6];
    uint16    ether_type;
    uint16    output_interface;
    uint16    output_svlan;
    uint16    output_cvlan;
    uint16    session_id;
    uint32    total_packets_transmitted;
    char        input_name[IFNAMSIZ];
    char        output_name[IFNAMSIZ];
} __attribute__((__packed__)) fpp_stat_bridge_entry_response_t;

typedef struct {
    uint16    ackstatus;
    uint16    eof;
    uint16    family;
    uint16    proto;
    uint32    spi;
    uint32    dst_ip[4];
    uint32    total_pkts_processed;
    uint32    total_bytes_processed[2];
    uint16    sagd;
    uint16    pad;
} __attribute__((__packed__)) fpp_stat_ipsec_entry_response_t;


typedef struct {
    uint16 ackstatus;
    uint16 eof;
    uint16 vlanID;
    uint16 rsvd;
    uint32 total_packets_received;
    uint32 total_packets_transmitted;
    uint32 total_bytes_received[2];
    uint32 total_bytes_transmitted[2];
    unsigned char vlanifname[IFNAMSIZ];
    unsigned char phyifname[IFNAMSIZ];
} __attribute__((__packed__)) fpp_stat_vlan_entry_response_t;


typedef struct {
    uint16 ackstatus;
    uint16 eof;
    uint32 rsvd;
    uint32 total_packets_received;
    uint32 total_packets_transmitted;
    uint32 total_bytes_received[2];
    uint32 total_bytes_transmitted[2];
    unsigned char if_name[IFNAMSIZ];
} __attribute__((__packed__)) fpp_stat_tunnel_entry_response_t;

typedef struct {
    uint16    ackstatus;
    uint8 ip_family;
    uint8 Protocol;
    uint16    Sport;      /*Source Port*/
    uint16    Dport;      /*Destination Port*/
    union {
        struct {
            uint32    Saddr;      /*Source IPv4 address*/
            uint32    Daddr;      /*Destination IPv4 address*/
        } v4;
        struct {
            uint32    Saddr_v6[4];        /*Source IPv6 address*/
            uint32    Daddr_v6[4];        /*Destination IPv6 address*/
        } v6;
    } ipv;
    uint64    TotalPackets;
    uint64    TotalBytes;
} __attribute__((__packed__)) fpp_stat_flow_entry_response_t;


/*------------------------------------ Altconf --------------------------------*/
#define FPP_CMD_ALTCONF_SET     0x1001
#define FPP_CMD_ALTCONF_RESET       0x1002

/* option IDs */
#define FPP_ALTCONF_OPTION_MCTTL    0x0001  /*Multicast TTL option */
#define FPP_ALTCONF_OPTION_IPSECRL  0x0002  /*IPSEC Rate Limiting option */
#define FPP_ALTCONF_OPTION_ALL      0xFFFF
#define FPP_ALTCONF_OPTION_MAX      FPP_ALTCONF_OPTION_IPSECRL + 1 /*include the "all" option*/

#define FPP_ALTCONF_MODE_DEFAULT    0 /* same default value used for all options */
#define FPP_ALTCONF_OPTION_MAX_PARAMS   3 /* IPSEC Rate Limiting has 3 parameters. To be updated if a new option is add with more 32bits params */

/* ALL options */
#define FPP_ALTCONF_ALL_NUM_PARAMS  1
#define FPP_ALTCONF_ALL_MODE_DEFAULT    FPP_ALTCONF_MODE_DEFAULT

/* Multicast TTL Configuration definitions */
#define FPP_ALTCONF_MCTTL_MODE_DEFAULT  FPP_ALTCONF_MODE_DEFAULT
#define FPP_ALTCONF_MCTTL_MODE_IGNORE   1
#define FPP_ALTCONF_MCTTL_MODE_MAX  FPP_ALTCONF_MCTTL_MODE_IGNORE
#define FPP_ALTCONF_MCTTL_NUM_PARAMS    1  /* maximu number of u32 allowed for this option */

/* IPSEC Rate Limiting Configuration definitions */
#define FPP_ALTCONF_IPSECRL_OFF     0
#define FPP_ALTCONF_IPSECRL_ON      1
#define FPP_ALTCONF_IPSECRL_NUM_PARAMS  3  /* maximu number of u32 allowed for this option */

typedef struct {
    uint16    option_id;
    uint16    num_params;
    uint32    params[FPP_ALTCONF_OPTION_MAX_PARAMS];
} __attribute__((__packed__)) fpp_alt_set_cmd_t;

/*--------------------------------- NATPT ------------------------------------*/
#define FPP_CMD_NATPT_OPEN      0x1101
#define FPP_CMD_NATPT_CLOSE     0x1102
#define FPP_CMD_NATPT_QUERY     0x1103

#define FPP_NATPT_CONTROL_6to4      0x01
#define FPP_NATPT_CONTROL_4to6      0x02
#define FPP_NATPT_CONTROL_TCPFIN    0x0100

typedef struct {
    uint16        socket_a;
    uint16        socket_b;
    uint16        control;
    uint16        rsvd1;
} __attribute__((__packed__)) fpp_natpt_open_cmd_t;

typedef struct {
    uint16        socket_a;
    uint16        socket_b;
} __attribute__((__packed__)) fpp_natpt_close_cmd;

typedef struct {
    uint16        reserved1;
    uint16        socket_a;
    uint16        socket_b;
    uint16        reserved2;
} __attribute__((__packed__)) fpp_natpt_query_cmd_t;

typedef struct {
    uint16        retcode;
    uint16        socket_a;
    uint16        socket_b;
    uint16        control;
    uint64        stat_v6_received;
    uint64        stat_v6_transmitted;
    uint64        stat_v6_dropped;
    uint64        stat_v6_sent_to_ACP;
    uint64        stat_v4_received;
    uint64        stat_v4_transmitted;
    uint64        stat_v4_dropped;
    uint64        stat_v4_sent_to_ACP;
} __attribute__((__packed__)) fpp_natpt_query_response_t;

/*---------------------------------- Fast Forwarding -------------------------*/
#define FPP_CMD_IPV4_FF_CONTROL     0x0321

/* Structure representing the command sent to enable/disable fast-forward */
typedef struct {
        uint16 enable;
        uint16 reserved;
} __attribute__((__packed__)) fpp_ff_ctrl_cmd_t;

/*---------------------------------- VLAN ------------------------------------*/
#define FPP_ERR_VLAN_ENTRY_ALREADY_REGISTERED   600
#define FPP_ERR_VLAN_ENTRY_NOT_FOUND        601

#define FPP_CMD_VLAN_ENTRY      0x0901
#define FPP_CMD_VLAN_RESET      0x0902

/* VLAN command as understood by FPP */
typedef struct {
        uint16       action;
        uint16       vlan_id; /* Carries skip count for ACTION_QUERY */
        char        vlan_ifname[IFNAMSIZ];
        char        vlan_phy_ifname[IFNAMSIZ];
} __attribute__((__packed__)) fpp_vlan_cmd_t;

/*---------------------------------- MacVlan ------------------------------------*/
#define FPP_CMD_MACVLAN_ENTRY       0x1401
#define FPP_CMD_MACVLAN_RESET           0x1402

#define FPP_ERR_MACVLAN_ENTRY_ALREADY_REGISTERED       60
#define FPP_ERR_MACVLAN_ENTRY_NOT_FOUND                61


/* MacVlan command as understood by FPP */
typedef struct {
        uint16       action;
        unsigned char   macaddr[6]; 
        char        macvlan_ifname[IFNAMSIZ];
        char        macvlan_phy_ifname[IFNAMSIZ];
} __attribute__((__packed__)) fpp_macvlan_cmd_t;

/*--------------------------------- Ipsec ------------------------------------*/
/* 0x0axx : IPSec module */
#define FPP_CMD_IPSEC_SA_ADD            0x0a01
#define FPP_CMD_IPSEC_SA_DELETE         0x0a02
#define FPP_CMD_IPSEC_SA_FLUSH          0x0a03
#define FPP_CMD_IPSEC_SA_SET_KEYS       0x0a04
#define FPP_CMD_IPSEC_SA_SET_TUNNEL     0x0a05
#define FPP_CMD_IPSEC_SA_SET_NATT       0x0a06
#define FPP_CMD_IPSEC_SA_SET_STATE      0x0a07
#define FPP_CMD_IPSEC_SA_SET_LIFETIME       0x0a08
#define FPP_CMD_IPSEC_SA_NOTIFY         0x0a09 
#define FPP_CMD_IPSEC_SA_ACTION_QUERY       0x0a0a 
#define FPP_CMD_IPSEC_SA_ACTION_QUERY_CONT  0x0a0b 
#define FPP_CMD_IPSEC_FLOW_ADD          0x0a11
#define FPP_CMD_IPSEC_FLOW_REMOVE       0x0a12
#define FPP_CMD_IPSEC_FLOW_NOTIFY       0x0a13
#define FPP_CMD_IPSEC_FRAG_CFG          0x0a14
#define FPP_CMD_IPSEC_SA_TNL_ROUTE      0x0a15
#define FPP_CMD_IPSEC_SA_ACTION_SHOW        0x0a16

#define FPP_CMD_NETKEY_SA_ADD           FPP_CMD_IPSEC_SA_ADD
#define FPP_CMD_NETKEY_SA_DELETE        FPP_CMD_IPSEC_SA_DELETE
#define FPP_CMD_NETKEY_SA_FLUSH         FPP_CMD_IPSEC_SA_FLUSH
#define FPP_CMD_NETKEY_SA_SET_KEYS      FPP_CMD_IPSEC_SA_SET_KEYS
#define FPP_CMD_NETKEY_SA_SET_TUNNEL        FPP_CMD_IPSEC_SA_SET_TUNNEL
#define FPP_CMD_NETKEY_SA_SET_NATT      FPP_CMD_IPSEC_SA_SET_NATT
#define FPP_CMD_NETKEY_SA_SET_STATE     FPP_CMD_IPSEC_SA_SET_STATE
#define FPP_CMD_NETKEY_SA_SET_LIFETIME      FPP_CMD_IPSEC_SA_SET_LIFETIME
#define FPP_CMD_NETKEY_FLOW_ADD         FPP_CMD_IPSEC_FLOW_ADD
#define FPP_CMD_NETKEY_FLOW_REMOVE      FPP_CMD_IPSEC_FLOW_REMOVE
#define FPP_CMD_NETKEY_FLOW_NOTIFY      FPPCMD_IPSEC_FLOW_NOTIFY

typedef struct {
        uint16    action;
        uint16    handle; /* handle */
        /* SPI information */
        uint16    mtu;    /* mtu configured */
        uint16    rsvd1;
        uint32    spi;      /* spi */
        uint8 sa_type; /* SA TYPE Prtocol ESP/AH */
        uint8 family; /* Protocol Family */
        uint8 mode; /* Tunnel/Transport mode */
        uint8 replay_window; /* Replay Window */
        uint32    dst_ip[4];
        uint32    src_ip[4];

          /* Key information */
        uint8 key_alg;
        uint8 state; /* SA VALID /EXPIRED / DEAD/ DYING */
    uint16    flags; /* ESP AH enabled /disabled */

        uint8 cipher_key[32];
        uint8 auth_key[20];
        uint8 ext_auth_key[12];


        /* Tunnel Information */
        uint8 tunnel_proto_family;
        uint8 rsvd[3];
        union {
                struct {
                        uint32    daddr;
                        uint32    saddr;
                        uint8 tos;
                        uint8 protocol;
                        uint16    total_length;
                } ipv4;

                struct {
                        uint32    traffic_class_hi:4;
                        uint32    version:4;
                        uint32    flow_label_high:4;
                        uint32    traffic_class:4;
                        uint32    flow_label_lo:16;
                        uint32    daddr[4];
                        uint32    saddr[4];
                } ipv6;

        } tnl;

        uint64    soft_byte_limit;
        uint64    hard_byte_limit;
        uint64    soft_packet_limit;
        uint64    hard_packet_limit;

} __attribute__((__packed__)) fpp_sa_query_cmd_t;

/*--------------------------------------- PPPoE --------------------------------*/
#define FPP_CMD_PPPOE_ENTRY             0x0601
#define FPP_CMD_PPPOE_GET_IDLE      0x0603
#define FPP_CMD_PPPOE_RELAY_ENTRY   0x0610
#define FPP_CMD_PPPOE_RELAY_ADD     0x0611
#define FPP_CMD_PPPOE_RELAY_REMOVE  0x0612

#define FPP_ERR_PPPOE_ENTRY_ALREADY_REGISTERED  800
#define FPP_ERR_PPPOE_ENTRY_NOT_FOUND       801

/* Structure representing the command sent to add or remove a pppoe session */
typedef struct {
    uint16 action;            /*Action to perform*/
    uint16 sessionid;
    uint8  macaddr[6];
    char      phy_intf[IFNAMSIZ];
    char      log_intf[IFNAMSIZ];
    uint16 mode;
} __attribute__((__packed__)) fpp_pppoe_cmd_t;

typedef struct {
    char        ppp_if[IFNAMSIZ];
    uint32    xmit_idle;
    uint32    recv_idle;
} __attribute__((__packed__)) fpp_pppoe_idle_t;

typedef struct {
        uint8        peermac1[6];
        uint8        peermac2[6];
        char            ipifname[IFNAMSIZ];
        char            opifname[IFNAMSIZ];
        uint16       sesID;
        uint16       relaysesID;
} __attribute__((__packed__)) fpp_relay_info_t;

/* Structure representing the command sent to add or remove a pppoe session */
typedef struct {
        uint16       action;      /*Action to perform */
        uint8        peermac1[6];
        uint8        peermac2[6];
    uint8        ipif_mac[6];
    uint8        opif_mac[6];
        char            ipifname[IFNAMSIZ];
        char            opifname[IFNAMSIZ];
        uint16       sesID;
        uint16       relaysesID;
        uint16       pad;
} __attribute__((__packed__)) fpp_pppoe_relay_cmd_t;

#ifdef WIFI_ENABLE
/*----------------------------------------WiFi ------------------------------*/
#define FPP_ERR_WIFI_DUPLICATE_OPERATION    2001
/* 0x2000: WiFi module */
#define FPP_CMD_WIFI_VAP_ENTRY          0x2001
#define FPP_CMD_VWD_ENABLE          0x2002
#define FPP_CMD_VWD_DISABLE         0x2003
#define FPP_CMD_WIFI_VAP_QUERY          0x2004
#define FPP_CMD_WIFI_VAP_RESET          0x2005

typedef struct fpp_wifi_vap_query_response
{
    uint16    vap_id;
    char        ifname[IFNAMSIZ];
    uint16    phy_port_id;
} __attribute__((__packed__)) fpp_wifi_vap_query_response_t;

typedef struct fpp_wifi_cmd
{
#define     FPP_VWD_VAP_ADD     0
#define     FPP_VWD_VAP_REMOVE  1
#define     FPP_VWD_VAP_UPDATE  2
#define     FPP_VWD_VAP_RESET   3
#define     FPP_VWD_VAP_CONFIGURE   4
    uint16    action;
    uint16    vap_id;
    char        ifname[IFNAMSIZ];
    char        mac_addr[6];
    uint16    wifi_guest_flag;
} __attribute__((__packed__)) fpp_wifi_cmd_t;

#endif

/*-------------------------------------- Tunnel -----------------------------*/
#define FPP_CMD_TUNNEL_ADD      0x0B01
#define FPP_CMD_TUNNEL_DEL      0x0B02
#define FPP_CMD_TUNNEL_UPDATE       0x0B03
#define FPP_CMD_TUNNEL_SEC      0x0B04
#define FPP_CMD_TUNNEL_QUERY        0x0B05
#define FPP_CMD_TUNNEL_QUERY_CONT   0x0B06
#define FPP_CMD_TUNNEL_4rd_ID_CONV_dport    0x0B07
#define FPP_CMD_TUNNEL_4rd_ID_CONV_psid     0x0B08

/* CMM / FPP API Command */
typedef struct {
    char            name[IFNAMSIZ];
    uint32       local[4];
    uint32       remote[4];
    char            output_device[IFNAMSIZ];
    uint8        mode;
    uint8        secure;
    uint8        encap_limit;
    uint8        hop_limit;
    uint32       flow_info; /* Traffic class and FlowLabel */
    uint16       frag_off;
    uint16       enabled;
    uint32    route_id;
    uint16    mtu;
    uint16    pad;
} __attribute__((__packed__)) fpp_tunnel_create_cmd_t;

typedef struct {
        char            name[IFNAMSIZ];
} __attribute__((__packed__)) fpp_tunnel_del_cmd_t;

typedef struct {
        char            name[IFNAMSIZ];
        uint16       sa_nr;
        uint16       sa_reply_nr;
        uint16       sa_handle[4];
        uint16       sa_reply_handle[4];
} __attribute__((__packed__)) fpp_tunnel_sec_cmd_t;

/* CMM / FPP API Command */
typedef struct {
    unsigned short  result;
    unsigned short  unused;
        char            name[IFNAMSIZ];
        uint32       local[4];
        uint32       remote[4];
        uint8        mode;
        uint8        secure;
        uint8        encap_limit;
        uint8        hop_limit;
        uint32       flow_info; /* Traffic class and FlowLabel */
        uint16       frag_off;
        uint16       enabled;
        uint32       route_id;
        uint16       mtu;
        uint16       pad;
} __attribute__((__packed__)) fpp_tunnel_query_cmd_t;


#ifdef SAM_LEGACY

typedef struct {
          int                            port_set_id;                    /**< Port Set ID               */
          int                            port_set_id_length;             /**< Port Set ID length        */
          int                            psid_offset;                    /**< PSID offset               */
}sam_port_info_t;
typedef sam_port_info_t rt_mw_ipstack_sam_port_t;

typedef struct {
       uint8        name[IFNAMSIZ];
       sam_port_info_t sam_port_info;
        uint32       IdConvStatus:1,
                       unused:31;
} __attribute__((__packed__)) fpp_tunnel_id_conv_cmd_t;

#else

typedef struct {
    uint16 IdConvStatus;
        uint16       Pad;
} __attribute__((__packed__)) fpp_tunnel_id_conv_cmd_t;
#endif

/*--------------------------------- Timeout ---------------------------------*/

/**
 * @addtogroup  dxgrLibFCI
 * @{
 */

/**
 * @def         FPP_CMD_IPV4_SET_TIMEOUT
 * @brief       FCI command for configuration of conntrack timeouts.
 * @details     Related topics: @ref l3_router
 * @details     Related data types: @ref fpp_timeout_cmd_t
 * @details     @ref FPP_CMD_IPV4_SET_TIMEOUT sets default timeout for @b both @ref FPP_CMD_IPV4_CONNTRACK 
 *              and @ref FPP_CMD_IPV6_CONNTRACK.
 * @details     This command allows for configuration of conntrack default timeout periods. 
 *              Three protocol groups are distinguished: `TCP (6)`, `UDP (17)` and `others` 
 *              (all other protocols; usually represented by 0).
 *              Timeout can be set independently for each of these groups.
 * @details     Factory-default timeout values are:
 *                - 5 days for `TCP`
 *                - 300 seconds for `UDP`
 *                - 240 seconds for `others`
 * @details     If these timeouts are updated (changed), then all newly created conntracks 
 *              are created with updated timeout values. Conntracks which were created before 
 *              the change have their timeout updated with the first received packet after the change.
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................  
 *  fpp_timeout_cmd_t cmd_to_fci = 
 *  {
 *    .protocol = ...,       // IP Protocol Number (protocol ID). [NBO]
 *                           // The only accepted values are 6 (TCP), 17 (UDP) or 0 (others).
 *    
 *    .timeout_value1 = ...  // Timeout value in seconds. [NBO]
 *  };
 *    
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IPV4_SET_TIMEOUT, sizeof(fpp_timeout_cmd_t), 
 *                                                   (unsigned short*)(&cmd_to_fci));
 *  .............................................  
 * @endcode
 *
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IPV4_SET_TIMEOUT    0x0319
#define FPP_CMD_IPV4_GET_TIMEOUT    0x0320
#define FPP_CMD_IPV4_FRAGTIMEOUT        0x0333
#define FPP_CMD_IPV4_SAMFRAGTIMEOUT 0x0334
#define FPP_CMD_IPV6_GET_TIMEOUT    0x0420
#define FPP_CMD_IPV6_FRAGTIMEOUT    0x0433

/**
 * @brief       Data structure for conntrack timeout setting.
 * @details     Related FCI commands: @ref FPP_CMD_IPV4_SET_TIMEOUT
 * @details     @ref FPP_CMD_IPV4_SET_TIMEOUT sets timeout for @b both @ref FPP_CMD_IPV4_CONNTRACK 
 *              and @ref FPP_CMD_IPV6_CONNTRACK.
 *
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp.h  fpp_timeout_cmd_t
 */
/* [fpp_timeout_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4) {
    uint16    protocol;         /*< IP Protocol Number (protocol ID). [NBO]
                                      The only accepted values are 6 (TCP), 17 (UDP) or
                                      0 (others). */
    
    uint16    sam_4o6_timeout;  /*< RESERVED (do not use) */
    uint32    timeout_value1;   /*< Timeout value in seconds. [NBO] */
    uint32    timeout_value2;   /*< RESERVED (do not use) */
} fpp_timeout_cmd_t;
/* [fpp_timeout_cmd_t] */

typedef struct {
    uint16    timeout;
    uint16    mode;
} __attribute__((__packed__)) fpp_frag_timeout_cmd_t;

/** @}*/

/*---------------------------------------PKTCAP---------------------------------*/
#define FPP_CMD_PKTCAP_IFSTATUS             0x0d02
#define FPP_CMD_PKTCAP_FLF                              0x0d03
#define FPP_CMD_PKTCAP_SLICE                0x0d04
#define FPP_CMD_PKTCAP_QUERY                0x0d05

#define FPP_PKTCAP_STATUS               0x1
#define FPP_PKTCAP_SLICE                0x2

typedef struct {
    uint16    action;
    uint8     ifindex;
    uint8 status;
}__attribute__((__packed__)) fpp_pktcap_status_cmd_t;

typedef struct {
    uint16    action;
    uint8     ifindex;
    uint8 rsvd;
    uint16    slice;
}__attribute__((__packed__)) fpp_pktcap_slice_cmd_t;

typedef struct {
    uint16    slice;
    uint16    status;
}__attribute__((__packed__)) fpp_pktcap_query_cmd_t;

/*----------------------------------------PKTCAP-------------------------------*/

/* Port Update command - begin */

#define FPP_CMD_PORT_UPDATE 0x0505
typedef struct {
    uint16 port_id;
    char ifname[IFNAMSIZ];
}__attribute__((__packed__)) fpp_port_update_cmd_t;


/*---------------------------------------ICC---------------------------------*/

#define FPP_CMD_ICC_RESET               0x1500
#define FPP_CMD_ICC_THRESHOLD               0x1501
#define FPP_CMD_ICC_ADD_DELETE              0x1502
#define FPP_CMD_ICC_QUERY               0x1503

#define FPP_ERR_ICC_TOO_MANY_ENTRIES        1500
#define FPP_ERR_ICC_ENTRY_ALREADY_EXISTS    1501
#define FPP_ERR_ICC_ENTRY_NOT_FOUND     1502
#define FPP_ERR_ICC_THRESHOLD_OUT_OF_RANGE  1503
#define FPP_ERR_ICC_INVALID_MASKLEN     1504

typedef struct {
    uint16    reserved1;
    uint16    reserved2;
} __attribute__((__packed__)) fpp_icc_reset_cmd_t;

typedef struct {
    uint16    bmu1_threshold;
    uint16    bmu2_threshold;
} __attribute__((__packed__)) fpp_icc_threshold_cmd_t;

typedef struct {
    uint16    action;
    uint8 interface;
    uint8 table_type;
    union {
        struct {
            uint16 type;
        } ethertype;
        struct {
            uint8 ipproto[256 / 8];
        } protocol;
        struct {
            uint8 dscp_value[64 / 8];
        } dscp;
        struct {
            uint32 v4_addr;
            uint8 v4_masklen;
        } ipaddr;
        struct {
            uint32 v6_addr[4];
            uint8 v6_masklen;
        } ipv6addr;
        struct {
            uint16 sport_from;
            uint16 sport_to;
            uint16 dport_from;
            uint16 dport_to;
        } port;
        struct {
            uint16 vlan_from;
            uint16 vlan_to;
            uint16 prio_from;
            uint16 prio_to;
        } vlan;
    } icc;
} __attribute__((__packed__)) fpp_icc_add_delete_cmd_t;

typedef struct {
    uint16    action;
    uint8 interface;
    uint8 reserved;
} __attribute__((__packed__)) fpp_icc_query_cmd_t;

typedef struct {
    uint16    rtncode;
    uint16    query_result;
    uint8 interface;
    uint8 table_type;
    union {
        struct {
            uint16 type;
        } ethertype;
        struct {
            uint8 ipproto[256 / 8];
        } protocol;
        struct {
            uint8 dscp_value[64 / 8];
        } dscp;
        struct {
            uint32 v4_addr;
            uint8 v4_masklen;
        } ipaddr;
        struct {
            uint32 v6_addr[4];
            uint8 v6_masklen;
        } ipv6addr;
        struct {
            uint16 sport_from;
            uint16 sport_to;
            uint16 dport_from;
            uint16 dport_to;
        } port;
        struct {
            uint16 vlan_from;
            uint16 vlan_to;
            uint16 prio_from;
            uint16 prio_to;
        } vlan;
    } icc;
} __attribute__((__packed__)) fpp_icc_query_reply_t;

/*----------------------------------------L2TP-------------------------------*/
#define FPP_CMD_L2TP_ITF_ADD        0x1600
#define FPP_CMD_L2TP_ITF_DEL        0x1601

typedef struct {
    char ifname[IFNAMSIZ];
    uint16    sock_id;
    uint16    local_tun_id;
    uint16    peer_tun_id;
    uint16    local_ses_id;
    uint16    peer_ses_id;
    uint16    options;
}__attribute__((__packed__)) fpp_l2tp_itf_add_cmd_t;

typedef struct {
    char ifname[IFNAMSIZ];
}__attribute__((__packed__)) fpp_l2tp_itf_del_cmd_t;
#endif /* FPP_H_ */


===== 文件 [22/185]: include\fpp_ext.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrLibFCI
 * @{
 *
 * @file        fpp_ext.h
 * @brief       Extension of the legacy fpp.h
 * @details     All FCI commands and related elements not present within the
 *              legacy fpp.h shall be put into this file. All macro values
 *              (uint16) shall have the upper nibble set to b1111 to ensure
 *              no conflicts with the legacy macro values.
 * @note        Documentation is part of libfci.h.
 */

#ifndef FPP_EXT_H_
#define FPP_EXT_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*  Compiler abstraction macros */
#ifndef CAL_PACKED
#define CAL_PACKED              __attribute__((packed))
#endif /* CAL_PACKED */

#ifndef CAL_PACKED_ALIGNED
#define CAL_PACKED_ALIGNED(n)   __attribute__((packed, aligned(n)))
#endif /* CAL_PACKED_ALIGNED */

#define FPP_ERR_ENTRY_NOT_FOUND                 0xf104
#define FPP_ERR_INTERNAL_FAILURE                0xffff

/* Size limit for the strings specifying mirror name. */
#define MIRROR_NAME_SIZE 16

/**
 * @def         FPP_CMD_PHY_IF
 * @brief       FCI command for management of physical interfaces.
 * @details     Related topics: @ref mgmt_phyif
 * @details     Related data types: @ref fpp_phy_if_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of a physical interface.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a physical interface query session and get properties
 *                   of the first physical interface from the internal list of physical interfaces.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next physical interface
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * @note
 * All operations with physical interfaces require exclusive lock of the interface database.
 * See @ref FPP_CMD_IF_LOCK_SESSION.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of a physical interface. It is recommended to use the read-modify-write
 * approach (see @ref mgmt_phyif). Some properties cannot be modified (see fpp_phy_if_cmd_t).
 * @code{.c}
 *  .............................................
 *  fpp_phy_if_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *    .name   = "...",              // Interface name (see chapter Physical Interface)
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_phy_if_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_PHY_IF, sizeof(fpp_phy_if_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of a physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_phy_if_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *
 *  fpp_phy_if_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_PHY_IF,
 *                  sizeof(fpp_phy_if_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the first physical interface from
 *  //  the internal list of physical interfaces.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_PHY_IF,
 *                  sizeof(fpp_phy_if_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next physical interface from
 *  //  the internal list of physical interfaces.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_ENTRY_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the physical interface query session (no more interfaces).
 *        - For other ACTIONs: Unknown (nonexistent) physical interface was requested.
 * - @c FPP_ERR_IF_WRONG_SESSION_ID <br>
 *        Some other client has the interface database locked for exclusive access.
 * - @c FPP_ERR_MIRROR_NOT_FOUND <br>
 *        Unknown (nonexistent) mirroring rule in the `.rx_mirrors` or `.tx_mirrors` property.
 * - @c FPP_ERR_FW_FEATURE_NOT_AVAILABLE <br>
 *        Attempted to modify properties which are not available (not enabled in FW).
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_PHY_IF                  0xf100

/**
 * @def         FPP_CMD_LOG_IF
 * @brief       FCI command for management of logical interfaces.
 * @details     Related topics: @ref mgmt_logif
 * @details     Related data types: @ref fpp_log_if_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new logical interface.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing logical interface.
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of a logical interface.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a logical interface query session and get properties
 *                   of the first logical interface from the internal collective list of all
 *                   logical interfaces (regardless of physical interface affiliation).
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next logical interface
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * @note
 * All operations with logical interfaces require exclusive lock of the interface database.
 * See @ref FPP_CMD_IF_LOCK_SESSION.
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new logical interface. The newly created interface is by default disabled and
 * without any configuration. For configuration, see the following FPP_ACTION_UPDATE.
 * @code{.c}
 *  .............................................
 *  fpp_log_if_cmd_t cmd_to_fci =
 *  {
 *    .action      = FPP_ACTION_REGISTER,  // Action
 *    .name        = "...",                // Interface name (user-defined)
 *    .parent_name = "..."                 // Parent physical interface name
 *                                         // (see chapter Physical Interface)
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 * @warning Do not create multiple logical interfaces with the same name.
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing logical interface.
 * @code{.c}
 *  .............................................
 *  fpp_log_if_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .name   = "..."                   // Name of an existing logical interface.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of a logical interface. It is recommended to use the read-modify-write
 * approach (see @ref mgmt_logif). Some properties cannot be modified (see fpp_log_if_cmd_t).
 * @code{.c}
 *  .............................................
 *  fpp_log_if_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *    .name   = "...",              // Name of an existing logical interface.
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_log_if_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_LOG_IF, sizeof(fpp_log_if_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of a logical interface.
 * @code{.c}
 *  .............................................
 *  fpp_log_if_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *
 *  fpp_log_if_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_LOG_IF,
 *                  sizeof(fpp_log_if_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the first logical interface from
 *  //  the internal collective list of all logical interfaces.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_LOG_IF,
 *                  sizeof(fpp_log_if_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next logical interface from
 *  //  the internal collective list of all logical interfaces.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_ENTRY_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the logical interface query session (no more interfaces).
 *        - For other ACTIONs: Unknown (nonexistent) logical interface was requested.
 * - @c FPP_ERR_IF_ENTRY_ALREADY_REGISTERED <br>
 *        Requested logical interface already exists (is already registered).
 * - @c FPP_ERR_IF_WRONG_SESSION_ID <br>
 *        Some other client has the interface database locked for exclusive access.
 * - @c FPP_ERR_IF_RESOURCE_ALREADY_LOCKED <br>
 *        Same as FPP_ERR_IF_WRONG_SESSION_ID.
 * - @c FPP_ERR_IF_MATCH_UPDATE_FAILED <br>
 *        Update of match flags has failed.
 * - @c FPP_ERR_IF_EGRESS_UPDATE_FAILED <br>
 *        Update of the `.egress` bitset has failed.
 * - @c FPP_ERR_IF_EGRESS_DOESNT_EXIST <br>
 *        Invalid (nonexistent) egress physical interface in the `.egress` bitset.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_LOG_IF                  0xf101

/**
 * @def         FPP_ERR_IF_ENTRY_ALREADY_REGISTERED
 * @hideinitializer
 */
#define FPP_ERR_IF_ENTRY_ALREADY_REGISTERED     0xf103

/**
 * @def         FPP_ERR_IF_ENTRY_NOT_FOUND
 * @hideinitializer
 */
#define FPP_ERR_IF_ENTRY_NOT_FOUND              0xf104

/**
 * @def         FPP_ERR_IF_EGRESS_DOESNT_EXIST
 * @hideinitializer
 */
#define FPP_ERR_IF_EGRESS_DOESNT_EXIST          0xf105

/**
 * @def         FPP_ERR_IF_EGRESS_UPDATE_FAILED
 * @hideinitializer
 */
#define FPP_ERR_IF_EGRESS_UPDATE_FAILED         0xf106

/**
 * @def         FPP_ERR_IF_MATCH_UPDATE_FAILED
 * @hideinitializer
 */
#define FPP_ERR_IF_MATCH_UPDATE_FAILED          0xf107

/**
 * @def         FPP_ERR_IF_OP_UPDATE_FAILED
 * @hideinitializer
 */
#define FPP_ERR_IF_OP_UPDATE_FAILED             0xf108

/**
 * @def         FPP_ERR_IF_OP_CANNOT_CREATE
 * @hideinitializer
 */
#define FPP_ERR_IF_OP_CANNOT_CREATE             0xf109

/**
 * @def         FPP_ERR_IF_NOT_SUPPORTED
 * @hideinitializer
 */
#define FPP_ERR_IF_NOT_SUPPORTED                0xf117

/**
 * @def         FPP_ERR_IF_RESOURCE_ALREADY_LOCKED
 * @hideinitializer
 */
#define FPP_ERR_IF_RESOURCE_ALREADY_LOCKED      0xf110

/**
 * @def         FPP_ERR_IF_WRONG_SESSION_ID
 * @hideinitializer
 */
#define FPP_ERR_IF_WRONG_SESSION_ID             0xf111

/**
 * @def         FPP_CMD_IF_LOCK_SESSION
 * @brief       FCI command to get exclusive access to interface database.
 * @details     Related topics: @ref mgmt_phyif, @ref mgmt_logif, @ref flex_router
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IF_LOCK_SESSION, 0, NULL);
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_RESOURCE_ALREADY_LOCKED <br>
 *        Some other client has the interface database locked for exclusive access.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IF_LOCK_SESSION                 0x0015

/**
 * @def         FPP_CMD_IF_UNLOCK_SESSION
 * @brief       FCI command to cancel exclusive access to interface database.
 * @details     Related topics: @ref mgmt_phyif, @ref mgmt_logif, @ref flex_router
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IF_UNLOCK_SESSION, 0, NULL);
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_WRONG_SESSION_ID <br>
 *        Either the database is not locked, or it is currently locked by some other client.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IF_UNLOCK_SESSION               0x0016

/**
 * @brief       Interface flags
 * @details     Related data types: @ref fpp_phy_if_cmd_t, @ref fpp_log_if_cmd_t
 * @details     Some of these flags are applicable only for physical interfaces [phyif],
 *              some are applicable only for logical interfaces [logif] and some are applicable
 *              for both [phyif,logif].
 */
typedef enum CAL_PACKED
{
    FPP_IF_ENABLED = (1UL << 0U),          /**< [phyif,logif] <br>
                                             If set, the interface is enabled. */
    FPP_IF_PROMISC = (1UL << 1U),          /**< [phyif,logif] <br>
                                             If set, the interface is configured as promiscuous.
                                             - promiscuous phyif: all ingress traffic is accepted, regardless of destination MAC.
                                             - promiscuous logif: all inspected traffic is accepted, regardless of active match rules. */
    FPP_IF_FF_ALL_TCP = (1 << 2),          /**< [phyif] <br>
                                             Special handling of ingress TCP SYN|FIN|RST packets in routing process.
                                             Applicable only when the interface uses mode which involves traffic 
                                             routing (e.g. FPP_IF_OP_ROUTER).
                                             If set, ingress TCP SYN|FIN|RST packets which match some conntrack are
                                             fast-forwarded as usual (according to the matching conntrack). This is default behavior.
                                             If @not set, ingress TCP SYN|FIN|RST packets which match some conntrack are @not 
                                             fast-forwarded. Instead, they are passed to the default logical interface. */
    FPP_IF_MATCH_OR = (1UL << 3U),         /**< [logif] <br>
                                             If multiple match rules are active and this flag is set,
                                             then the final result of a match process is a logical OR of the rules.
                                             If this flag is @b not set, then the final result is a logical AND of the rules. */
    FPP_IF_DISCARD = (1UL << 4U),          /**< [logif] <br>
                                             If set, discard matching frames. */
    FPP_IF_MIRROR = (1UL << 5U),           /* DEPRECATED. Do not use.
                                             [phyif] <br>
                                             If set, mirroring is enabled. */
    FPP_IF_LOADBALANCE = (1UL << 6U),      /* DEPRECATED. Do not use.
                                             [phyif] <br>
                                             If set, the interface is a part of a loadbalance bucket. */
    FPP_IF_VLAN_CONF_CHECK = (1UL << 7U),  /**< [phyif] <br>
                                             If set, the interface enforces a strict VLAN conformance check. */
    FPP_IF_PTP_CONF_CHECK = (1UL << 8U),   /**< [phyif] <br>
                                             If set, the interface enforces a strict PTP conformance check. */
    FPP_IF_PTP_PROMISC = (1UL << 9U),      /**< [phyif] <br>
                                             If set, then PTP traffic is accepted even if the FPP_IF_VLAN_CONF_CHECK is set. */
    FPP_IF_ALLOW_Q_IN_Q = (1UL << 11U),    /**< [phyif] <br>
                                             If set, the interface accepts QinQ-tagged traffic. */
    FPP_IF_DISCARD_TTL = (1UL << 12U),     /**< [phyif] <br>
                                             If set, then packets with TTL<2 are automatically discarded.
                                             If @b not set, then packets with TTL<2 are passed to the default logical interface. */
    FPP_IF_MAX = (int)(1U << 31U)
} fpp_if_flags_t;

/**
 * @brief       Physical interface operation mode.
 * @details     Related data types: @ref fpp_phy_if_cmd_t
 */
typedef enum CAL_PACKED
{
    FPP_IF_OP_DEFAULT = 0,          /**< Default operation mode */
    FPP_IF_OP_VLAN_BRIDGE = 1,      /**< @ref l2_bridge, VLAN aware version */
    FPP_IF_OP_ROUTER = 2,           /**< @ref l3_router */
    FPP_IF_OP_FLEXIBLE_ROUTER = 3,  /**< @ref flex_router */
    FPP_IF_OP_L2L3_VLAN_BRIDGE = 4, /**< @ref l2l3_bridge, VLAN-aware version */
} fpp_phy_if_op_mode_t;

/**
 * @brief       Match rules.
 * @details     Related data types: @ref fpp_log_if_cmd_t, @ref fpp_if_m_args_t
 * @note        L2/L3/L4 are layers of the OSI model.
 */
typedef enum CAL_PACKED
{
    FPP_IF_MATCH_TYPE_ETH = (1 << 0),     /**< Match ETH packets */
    FPP_IF_MATCH_TYPE_VLAN = (1 << 1),    /**< Match VLAN tagged packets */
    FPP_IF_MATCH_TYPE_PPPOE = (1 << 2),   /**< Match PPPoE packets */
    FPP_IF_MATCH_TYPE_ARP = (1 << 3),     /**< Match ARP packets */
    FPP_IF_MATCH_TYPE_MCAST = (1 << 4),   /**< Match multicast (L2) packets */
    FPP_IF_MATCH_TYPE_IPV4 = (1 << 5),    /**< Match IPv4 packets */
    FPP_IF_MATCH_TYPE_IPV6 = (1 << 6),    /**< Match IPv6 packets */
    FPP_IF_MATCH_RESERVED7 = (1 << 7),    /**< Reserved */
    FPP_IF_MATCH_RESERVED8 = (1 << 8),    /**< Reserved */
    FPP_IF_MATCH_TYPE_IPX = (1 << 9),     /**< Match IPX packets */
    FPP_IF_MATCH_TYPE_BCAST = (1 << 10),  /**< Match L2 broadcast packets */
    FPP_IF_MATCH_TYPE_UDP = (1 << 11),    /**< Match UDP packets */
    FPP_IF_MATCH_TYPE_TCP = (1 << 12),    /**< Match TCP packets */
    FPP_IF_MATCH_TYPE_ICMP = (1 << 13),   /**< Match ICMP packets */
    FPP_IF_MATCH_TYPE_IGMP = (1 << 14),   /**< Match IGMP packets */
    FPP_IF_MATCH_VLAN = (1 << 15),        /**< Match VLAN ID (see fpp_if_m_args_t) */
    FPP_IF_MATCH_PROTO = (1 << 16),       /**< Match IP Protocol Number (protocol ID) See fpp_if_m_args_t. */
    FPP_IF_MATCH_SPORT = (1 << 20),       /**< Match L4 source port (see fpp_if_m_args_t) */
    FPP_IF_MATCH_DPORT = (1 << 21),       /**< Match L4 destination port (see fpp_if_m_args_t) */
    FPP_IF_MATCH_SIP6 = (1 << 22),        /**< Match source IPv6 address (see fpp_if_m_args_t) */
    FPP_IF_MATCH_DIP6 = (1 << 23),        /**< Match destination IPv6 address (see fpp_if_m_args_t) */
    FPP_IF_MATCH_SIP = (1 << 24),         /**< Match source IPv4 address (see fpp_if_m_args_t) */
    FPP_IF_MATCH_DIP = (1 << 25),         /**< Match destination IPv4 address (see fpp_if_m_args_t) */
    FPP_IF_MATCH_ETHTYPE = (1 << 26),     /**< Match EtherType (see fpp_if_m_args_t) */
    FPP_IF_MATCH_FP0 = (1 << 27),         /**< Match Ethernet frames accepted by Flexible Parser 0 (see fpp_if_m_args_t) */
    FPP_IF_MATCH_FP1 = (1 << 28),         /**< Match Ethernet frames accepted by Flexible Parser 1 (see fpp_if_m_args_t) */
    FPP_IF_MATCH_SMAC = (1 << 29),        /**< Match source MAC address (see fpp_if_m_args_t) */
    FPP_IF_MATCH_DMAC = (1 << 30),        /**< Match destination MAC address (see fpp_if_m_args_t) */
    FPP_IF_MATCH_HIF_COOKIE = (int)(1U << 31U),  /**< Match HIF header cookie. HIF header cookie is a part of internal overhead data.
                                                      It is attached to traffic data by a host's PFE driver. */

    /* Ensure proper size */
    FPP_IF_MATCH_MAX = (int)(1U << 31U)
} fpp_if_m_rules_t;

/**
 * @brief       Match rules arguments.
 * @details     Related data types: @ref fpp_log_if_cmd_t, @ref fpp_if_m_rules_t
 * @details     Each value is an argument for some match rule.
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp_ext.h  fpp_if_m_args_t
 */
/* [fpp_if_m_args_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 vlan;     /*< VLAN ID. [NBO]. See FPP_IF_MATCH_VLAN. */
    uint16 ethtype;  /*< EtherType. [NBO]. See FPP_IF_MATCH_ETHTYPE. */
    uint16 sport;    /*< L4 source port. [NBO]. See FPP_IF_MATCH_SPORT. */
    uint16 dport;    /*< L4 destination port [NBO]. See FPP_IF_MATCH_DPORT. */

    /* Source and destination IP addresses */
    struct
    {
        struct
        {
            uint32 sip;     /*< IPv4 source address. [NBO]. See FPP_IF_MATCH_SIP. */
            uint32 dip;     /*< IPv4 destination address. [NBO]. See FPP_IF_MATCH_DIP. */
        } v4;

        struct
        {
            uint32 sip[4];  /*< IPv6 source address. [NBO]. See FPP_IF_MATCH_SIP6. */
            uint32 dip[4];  /*< IPv6 destination address. [NBO]. See FPP_IF_MATCH_DIP6. */
        } v6;
    } ipv;

    uint8 proto;        /*< IP Protocol Number (protocol ID). See FPP_IF_MATCH_PROTO. */
    uint8 smac[6];      /*< Source MAC Address. See FPP_IF_MATCH_SMAC. */
    uint8 dmac[6];      /*< Destination MAC Address. See FPP_IF_MATCH_DMAC. */
    char fp_table0[16];   /*< Flexible Parser table 0 (name). See FPP_IF_MATCH_FP0. */
    char fp_table1[16];   /*< Flexible Parser table 1 (name). See FPP_IF_MATCH_FP1. */
    uint32 hif_cookie;  /*< HIF header cookie. [NBO]. See FPP_IF_MATCH_HIF_COOKIE. */
} fpp_if_m_args_t;
/* [fpp_if_m_args_t] */

/**
 * @brief       Physical interface statistics.
 * @details     Related data types: @ref fpp_phy_if_cmd_t
 * @note        @b All values are in a network byte order [@b NBO].
 *
 * @snippet     fpp_ext.h  fpp_phy_if_stats_t
 */
/* [fpp_phy_if_stats_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint32 ingress;    /*< Count of ingress frames for the given interface. */
    uint32 egress;     /*< Count of egress frames for the given interface. */
    uint32 malformed;  /*< Count of ingress frames with detected error (e.g. checksum). */
    uint32 discarded;  /*< Count of ingress frames which were discarded. */
} fpp_phy_if_stats_t;
/* [fpp_phy_if_stats_t] */

/**
 * @brief       Logical interface statistics.
 * @details     Related data types: @ref fpp_log_if_cmd_t
 * @note        @b All values are in a network byte order [@b NBO].
 *
 * @snippet     fpp_ext.h  fpp_algo_stats_t
 */
/* [fpp_algo_stats_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint32 processed;  /*< Count of frames processed (regardless of the result). */
    uint32 accepted;   /*< Count of frames matching the selection criteria. */
    uint32 rejected;   /*< Count of frames not matching the selection criteria. */
    uint32 discarded;  /*< Count of frames marked to be dropped. */
} fpp_algo_stats_t;
/* [fpp_algo_stats_t] */

/**
 * @brief       Physical interface blocking state.
 * @details     Related data types: @ref fpp_phy_if_cmd_t
 * @details     Used when a physical interface is configured in a Bridge-like mode.
 *              See @ref l2_bridge and @ref l2l3_bridge. Affects the following Bridge-related
 *              capabilities of a physical interface:
 *              - Learning of MAC addresses from the interface's ingress traffic.
 *              - Forwarding of the interface's ingress traffic.
 */
typedef enum CAL_PACKED
{
    BS_NORMAL = 0,       /**< Learning and forwarding enabled. */
    BS_BLOCKED = 1,      /**< Learning and forwarding disabled. */
    BS_LEARN_ONLY = 2,   /**< Learning enabled, forwarding disabled. */
    BS_FORWARD_ONLY = 3  /**< Learning disabled, forwarding enabled. <br>
                              Traffic is forwarded only if its both source and destination MAC addresses
                              are known to the bridge. */
} fpp_phy_if_block_state_t;

/* Number of mirrors which can be configured per rx/tx on a physical interface.
   The value is equal to the number supported by the firmware. */
#define FPP_MIRRORS_CNT 2U

/**
 * @brief       Data structure for a physical interface.
 * @details     Related FCI commands: @ref FPP_CMD_PHY_IF
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_phy_if_cmd_t
 */
/* [fpp_phy_if_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;            /*< Action */
    char name[IFNAMSIZ];        /*< Interface name. [ro] */
    uint32 id;                /*< Interface ID. [NBO,ro] */
    fpp_if_flags_t flags;       /*< Interface flags. [NBO]. A bitset. */
    fpp_phy_if_op_mode_t mode;  /*< Interface mode. */
    fpp_phy_if_block_state_t block_state;  /*< Interface blocking state. */
    fpp_phy_if_stats_t stats;   /*< Physical interface statistics. [ro] */

    /* Names of associated mirroring rules for ingress traffic. See FPP_CMD_MIRROR.
       Empty string at given position == position is disabled. */
    char rx_mirrors[FPP_MIRRORS_CNT][MIRROR_NAME_SIZE];

    /* Names of associated mirroring rules for egress traffic. See FPP_CMD_MIRROR.
       Empty string at given position == position is disabled. */
    char tx_mirrors[FPP_MIRRORS_CNT][MIRROR_NAME_SIZE];

    char ftable[16];    /*< Name of a Flexible Parser table which shall be used
                            as a Flexible Filter of this physical interface.
                            Empty string == Flexible filter is disabled.
                            See Flexible Parser for more info. */

    char ptp_mgmt_if[IFNAMSIZ];  /*< Name of a physical interface which serves as
                                     a PTP management interface.
                                     Empty string == disabled */

} fpp_phy_if_cmd_t;
/* [fpp_phy_if_cmd_t] */

/**
 * @brief       Data structure for a logical interface.
 * @details     Related FCI commands: @ref FPP_CMD_LOG_IF
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_log_if_cmd_t
 */
/* [fpp_log_if_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;            /*< Action */
    uint8 res[2];             /*< RESERVED (do not use) */
    char name[IFNAMSIZ];        /*< Interface name. [ro] */
    uint32 id;                /*< Interface ID. [NBO,ro] */
    char parent_name[IFNAMSIZ]; /*< Parent physical interface name. [ro] */
    uint32 parent_id;         /*< Parent physical interface ID. [NBO,ro] */

    uint32 egress;            /*< Egress physical interfaces. [NBO]. A bitset.
                                    Each physical interface is represented by a bitflag.
                                    Conversion between a physical interface ID and a corr-
                                    esponding bitflag is (1uL << "physical interface ID"). */

    fpp_if_flags_t flags;       /*< Interface flags. [NBO]. A bitset. */
    fpp_if_m_rules_t match;     /*< Match rules. [NBO]. A bitset. */
    fpp_if_m_args_t CAL_PACKED_ALIGNED(4) arguments;  /*< Match rules arguments. */
    fpp_algo_stats_t CAL_PACKED_ALIGNED(4) stats;     /*< Logical interface statistics [ro] */
} fpp_log_if_cmd_t;
/* [fpp_log_if_cmd_t] */

/**
 * @def         FPP_CMD_IF_MAC
 * @brief       FCI command for management of interface MAC addresses.
 * @details     Related topics: @ref mgmt_phyif
 * @details     Related data types: @ref fpp_if_mac_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Add a new MAC address to an interface.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove an existing MAC address from an interface.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a MAC address query session and get
 *                   the first MAC address of the requested interface.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get the next MAC address
 *                   of the requested interface. Intended to be called in a loop
 *                   (to iterate through the list).
 *
 * @note
 * All operations with interface MAC addresses require exclusive lock of the interface database.
 * See @ref FPP_CMD_IF_LOCK_SESSION.
 *
 * @note
 * MAC address management is available only for @b emac physical interfaces.
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Add a new MAC address to emac physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_if_mac_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_REGISTER,  // Action
 *    .name   = "...",                // Physical interface name
 *    .mac    = {...}                 // Physical interface MAC
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IF_MAC, sizeof(fpp_if_mac_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove an existing MAC address from emac physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_if_mac_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .name   = "...",                  // Physical interface name
 *    .mac    = {...}                   // Physical interface MAC
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_IF_MAC, sizeof(fpp_if_mac_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get MAC addresses of a requested emac physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_if_mac_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *    .name   = "...",            // Physical interface name
 *  };
 *
 *  fpp_if_mac_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_IF_MAC,
 *                  sizeof(fpp_if_mac_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds the first MAC address of the requested physical interface.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_IF_MAC,
 *                  sizeof(fpp_if_mac_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds the next MAC address of the requested physical interface.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_MAC_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the MAC address query session (no more MAC addresses).
 *        - For other ACTIONs: Unknown (nonexistent) MAC address was requested.
 * - @c FPP_ERR_IF_MAC_ALREADY_REGISTERED <br>
 *        Requested MAC address already exists (is already registered).
 * - @c FPP_ERR_IF_ENTRY_NOT_FOUND <br>
 *        Unknown (nonexistent) physical interface was requested.
 * - @c FPP_ERR_IF_NOT_SUPPORTED <br>
 *        Requested physical interface does not support MAC address management.
 * - @c FPP_ERR_IF_WRONG_SESSION_ID <br>
 *        Some other client has the interface database locked for exclusive access.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_IF_MAC                          0xf120

#define FPP_ERR_IF_MAC_ALREADY_REGISTERED       0xf121
#define FPP_ERR_IF_MAC_NOT_FOUND                0xf122

/**
 * @brief       Data structure for interface MAC address.
 * @details     Related FCI commands: @ref FPP_CMD_IF_MAC
 *
 * @snippet     fpp_ext.h  fpp_if_mac_cmd_t
 */
/* [fpp_if_mac_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(2)
{
    uint16 action;      /*< Action */
    char name[IFNAMSIZ];  /*< Physical interface name. */
    uint8 mac[6];       /*< Physical interface MAC. */
} fpp_if_mac_cmd_t;
/* [fpp_if_mac_cmd_t] */

/**
 * @def         FPP_CMD_MIRROR
 * @brief       FCI command for management of interface mirroring rules.
 * @details     Related topics: @ref if_mgmt
 * @details     Related data types: @ref fpp_mirror_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new mirroring rule.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing mirroring rule.
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of a mirroring rule.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a mirroring rule query session and get properties
 *                   of the first mirroring rule from the internal list of mirroring rules.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next mirroring rule
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new mirroring rule. When creating a new mirroring rule, it is also possible to
 * simultaneously set its properties (using the same rules which apply to @ref FPP_ACTION_UPDATE).
 * @code{.c}
 *  .............................................
 *  fpp_mirror_cmd_t cmd_to_fci =
 *  {
 *    .action        = FPP_ACTION_REGISTER, // Action
 *    .name          = "...",               // Name of the mirroring rule.
 *    .egress_phy_if = "...",               // Name of the physical interface where to mirror.
 *
 *    // optional
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing mirroring rule.
 * @code{.c}
 *  .............................................
 *  fpp_mirror_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .name   = "...",                  // Name of the mirroring rule.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of a mirroring rule. It is recommended to use the read-modify-write
 * approach. Some properties cannot be modified (see fpp_mirror_cmd_t).
 * @code{.c}
 *  .............................................
 *  fpp_mirror_cmd_t cmd_to_fci =
 *  {
 *    .action        = FPP_ACTION_REGISTER, // Action
 *    .name          = "...",               // Name of the mirroring rule.
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_mirror_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_MIRROR, sizeof(fpp_mirror_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of a mirroring rule.
 * @code{.c}
 *  .............................................
 *  fpp_mirror_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *
 *  fpp_mirror_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_MIRROR,
 *                  sizeof(fpp_mirror_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the first mirroring rule from
 *  //  the internal list of mirroring rules.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_MIRROR,
 *                  sizeof(fpp_mirror_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next mirroring rule from
 *  //  the internal list of mirroring rules.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_MIRROR_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the mirroring rule query session (no more mirroring rules).
 *        - For other ACTIONs: Unknown (nonexistent) mirroring rule was requested.
 * - @c FPP_ERR_MIRROR_ALREADY_REGISTERED <br>
 *        Requested mirroring rule already exists (is already registered).
 * - @c FPP_ERR_MIRROR_CURRENTLY_UTILIZED <br>
 *        Requested mirror is in use and can't be deleted.
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_IF_ENTRY_NOT_FOUND <br>
 *        Unknown (nonexistent) physical interface in the `.egress_phy_if` property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_MIRROR                      0xf130

#define FPP_ERR_MIRROR_ALREADY_REGISTERED   0xf131
#define FPP_ERR_MIRROR_NOT_FOUND            0xf132
#define FPP_ERR_MIRROR_CURRENTLY_UTILIZED   0xf133

/**
 * @brief       Mirroring rule modification actions.
 * @details     Related data types: @ref fpp_mirror_cmd_t, @ref fpp_modify_args_t
 */
typedef enum CAL_PACKED
{
    MODIFY_ACT_NONE = 0U,                   /**< No action to be done. */
    MODIFY_ACT_ADD_VLAN_HDR = (1U << 1),    /**< Construct/Update outer VLAN Header. */

    /* Ensure proper size */
    MODIFY_ACT_INVALID = (int)(1U << 31)
} fpp_modify_actions_t;

/**
 * @brief       Arguments for mirroring rule modification actions.
 * @details     Related data types: @ref fpp_mirror_cmd_t, @ref fpp_modify_actions_t
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp_ext.h  fpp_modify_args_t
 */
/* [fpp_modify_args_t] */
typedef struct CAL_PACKED_ALIGNED(2)
{
    uint16 vlan;  /*< VLAN ID to be used by MODIFY_ACT_ADD_VLAN_HDR. [NBO] */
} fpp_modify_args_t;
/* [fpp_modify_args_t] */

/**
 * @brief       Data structure for interface mirroring rule.
 * @details     Related FCI commands: @ref FPP_CMD_MIRROR
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_mirror_cmd_t
 */
/* [fpp_mirror_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;               /*< Action */
    char name[MIRROR_NAME_SIZE];   /*< Name of the mirroring rule. [ro] */
    char egress_phy_if[IFNAMSIZ];  /*< Name of the physical interface where to mirror. */

    char filter_table_name[16];    /*< Name of a Flexible Parser table that can be used
                                       to filter which frames to mirror.
                                       Empty string == disabled (no filtering).
                                       See Flexible Parser for more info. */

    fpp_modify_actions_t m_actions;  /*< Modifications to be done on mirrored frame. [NBO] */
    fpp_modify_args_t    m_args;     /*< Configuration values (arguments) for m_actions. */
} fpp_mirror_cmd_t;
/* [fpp_mirror_cmd_t] */

/**
 * @def         FPP_CMD_L2_BD
 * @brief       FCI command for management of L2 bridge domains.
 * @details     Related topics: @ref l2_bridge, @ref l2l3_bridge
 * @details     Related data types: @ref fpp_l2_bd_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new bridge domain.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing bridge domain.
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of a bridge domain.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a bridge domain query session and get properties
 *                   of the first bridge domain from the internal list of bridge domains.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next bridge domain
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new bridge domain. When creating a new bridge domain, it is also possible to
 * simultaneously set its properties (using the same rules which apply to @ref FPP_ACTION_UPDATE).
 * @code{.c}
 *  .............................................
 *  fpp_l2_bd_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_REGISTER,  // Action
 *    .vlan   = ...,                  // VLAN ID of a new bridge domain. [NBO] (user-defined)
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_l2_bd_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t),
 *                                        (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing bridge domain.
 * @code{.c}
 *  .............................................
 *  fpp_l2_bd_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .vlan   = ...,                    // VLAN ID of an existing bridge domain. [NBO]
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t),
 *                                        (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of a logical interface. It is recommended to use the read-modify-write
 * approach. Some properties cannot be modified (see fpp_l2_bd_cmd_t).
 * @code{.c}
 *  .............................................
 *  fpp_l2_bd_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *    .vlan   = ...,                // VLAN ID of an existing bridge domain. [NBO]
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_l2_bd_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_BD, sizeof(fpp_l2_bd_cmd_t),
 *                                        (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of a bridge domain.
 * @code{.c}
 *  .............................................
 *  fpp_l2_bd_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *
 *  fpp_l2_bd_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_L2_BD,
 *                  sizeof(fpp_l2_bd_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the first bridge domain from
 *  //  the internal list of bridge domains.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_L2_BD,
 *                  sizeof(fpp_l2_bd_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next bridge domain from
 *  //  the internal list of bridge domains.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_L2_BD_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the bridge domain query session (no more bridge domains).
 *        - For other ACTIONs: Unknown (nonexistent) bridge domain was requested.
 * - @c FPP_ERR_L2_BD_ALREADY_REGISTERED <br>
 *        Requested bridge domain already exists (is already registered).
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_L2_BD                       0xf200

#define FPP_ERR_L2_BD_ALREADY_REGISTERED    0xf201
#define FPP_ERR_L2_BD_NOT_FOUND             0xf202

/**
 * @brief       L2 bridge domain flags
 * @details     Related data types: @ref fpp_l2_bd_cmd_t
 */
typedef enum CAL_PACKED
{
    FPP_L2_BD_DEFAULT = (1 << 0),   /*!< Domain type is default */
    FPP_L2_BD_FALLBACK = (1 << 1)   /*!< Domain type is fallback */
} fpp_l2_bd_flags_t;

/**
 * @brief       Domain statistics.
 * @details     Related data types: @ref fpp_l2_bd_cmd_t
 * @note        @b All values are in a network byte order [@b NBO].
 *
 * @snippet     fpp_ext.h  fpp_l2_bd_stats_t
 */
/* [fpp_l2_bd_stats_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint32 ingress;       /*< Count of ingress frames for the given domain. */
    uint32 egress;        /*< Count of egress frames for the given domain. */
    uint32 ingress_bytes; /*< Count of ingress bytes. */
    uint32 egress_bytes;  /*< Count of egress bytes. */
} fpp_l2_bd_stats_t;
/* [fpp_l2_bd_stats_t] */

/**
 * @brief       Data structure for L2 bridge domain.
 * @details     Related FCI commands: @ref FPP_CMD_L2_BD
 * @details     Bridge domain actions (what to do with a frame):
 *              | value | meaning |
 *              |-------|---------|
 *              | 0     | Forward |
 *              | 1     | Flood   |
 *              | 2     | Punt    |
 *              | 3     | Discard |
 *
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_l2_bd_cmd_t
 */
/* [fpp_l2_bd_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;    /*< Action */
    uint16 vlan;      /*< Bridge domain VLAN ID. [NBO,ro] */

    uint8 ucast_hit;  /*< Bridge domain action when the destination MAC of an inspected
                            frame is an unicast MAC and it matches some entry in the
                            Bridge MAC table. */

    uint8 ucast_miss; /*< Bridge domain action when the destination MAC of an inspected
                            frame is an unicast MAC and it does NOT match any entry in the
                            Bridge MAC table. */

    uint8 mcast_hit;  /*< Similar to ucast_hit, but for frames which have a multicast
                            destination MAC address. */

    uint8 mcast_miss; /*< Similar to ucast_miss, but for frames which have a multicast
                            destination MAC address. */

    uint32 if_list;   /*< Bridge domain ports. [NBO]. A bitset.
                            Ports are represented by physical interface bitflags.
                            If a bitflag of some physical interface is set here, the interface
                            is then considered a port of the given bridge domain.
                            Conversion between a physical interface ID and a corresponding
                            bitflag is (1uL << "physical interface ID"). */

    uint32 untag_if_list; /*< A bitset [NBO], denoting which bridge domain ports from
                                '.if_list' are considered untagged (their egress frames
                                have the VLAN tag removed).
                                Ports which are present in both the '.if_list' bitset and
                                this bitset are considered untagged.
                                Ports which are present only in the '.if_list' bitset are
                                considered tagged. */

    fpp_l2_bd_flags_t flags;  /*< Bridge domain flags [NBO,ro] */

    fpp_l2_bd_stats_t CAL_PACKED_ALIGNED(4) stats; /*< Domain traffic statistics. [ro] */
} fpp_l2_bd_cmd_t;
/* [fpp_l2_bd_cmd_t] */

/**
 * @def         FPP_CMD_L2_STATIC_ENT
 * @brief       FCI command for management of L2 static entries.
 * @details     Related topics: @ref l2_bridge, @ref l2l3_bridge
 * @details     Related data types: @ref fpp_l2_static_ent_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new static entry.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing static entry.
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of a static entry.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) static entry query session and get properties
 *                   of the first static entry from the internal collective list of all
 *                   L2 static entries (regardless of bridge domain affiliation).
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next static entry
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * @note
 * When using this command, it is recommended to disable dynamic learning of MAC addresses on all
 * physical interfaces which are configured to be a part of @ref l2_bridge or @ref l2l3_bridge.
 * See @ref FPP_CMD_PHY_IF and @ref fpp_phy_if_block_state_t.
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new L2 static entry.
 * @code{.c}
 *  .............................................
 *  fpp_l2_static_ent_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_REGISTER,  // Action
 *    .vlan   = ...,                  // VLAN ID of an associated bridge domain. [NBO]
 *    .mac    = ...,                  // Static entry MAC address.
 *    .forward_list = ...             // Egress physical interfaces. [NBO]
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t),
 *                                                (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing L2 static entry.
 * @code{.c}
 *  .............................................
 *  fpp_l2_static_ent_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .vlan   = ...,                    // VLAN ID of an associated bridge domain. [NBO]
 *    .mac    = ...                     // Static entry MAC address.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t),
 *                                                (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of L2 static entry. It is recommended to use the read-modify-write
 * approach. Some properties cannot be modified (see fpp_l2_static_ent_cmd_t).
 * @code{.c}
 *  .............................................
 *  fpp_l2_static_ent_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *    .vlan   = ...,                // VLAN ID of an associated bridge domain. [NBO]
 *    .mac    = ...,                // Static entry MAC address.
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_l2_static_ent_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_STATIC_ENT, sizeof(fpp_l2_static_ent_cmd_t),
 *                                                (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of L2 static entry.
 * @code{.c}
 *  .............................................
 *  fpp_l2_static_ent_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *
 *  fpp_l2_static_ent_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_L2_STATIC_ENT,
 *                  sizeof(fpp_l2_static_ent_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the first static entry from
 *  //  the internal collective list of all static entries.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_L2_STATIC_ENT,
 *                  sizeof(fpp_l2_static_ent_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next static entry from
 *  //  the internal collective list of all static entries.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_L2_STATIC_EN_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the L2 static entry query session (no more L2 static entries).
 *        - For other ACTIONs: Unknown (nonexistent) L2 static entry was requested.
 * - @c FPP_ERR_L2_STATIC_ENT_ALREADY_REGISTERED <br>
 *        Requested L2 static entry already exists (is already registered).
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_L2_STATIC_ENT                       0xf340

#define FPP_ERR_L2_STATIC_ENT_ALREADY_REGISTERED    0xf341
#define FPP_ERR_L2_STATIC_EN_NOT_FOUND              0xf342

/**
 * @brief       Data structure for L2 static entry.
 * @details     Related FCI commands: @ref FPP_CMD_L2_STATIC_ENT
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_l2_static_ent_cmd_t
 */
/* [fpp_l2_static_ent_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;        /*< Action */

    uint16 vlan;          /*< VLAN ID of an associated bridge domain. [NBO,ro]
                                VLAN-aware static entries are applied only on frames
                                which have a matching VLAN tag.
                                For non-VLAN aware static entries, use VLAN ID of
                                the Default BD (Default Bridge Domain). */

    uint8 mac[6];         /*< Static entry MAC address. [ro] */

    uint32 forward_list;  /*< Egress physical interfaces. [NBO]. A bitset.
                                Frames with matching destination MAC address (and VLAN tag)
                                are forwarded through all physical interfaces which are a part
                                of this bitset. Physical interfaces are represented by
                                bitflags. Conversion between a physical interface ID and
                                a corresponding bitflag is (1uL << "physical interface ID").*/

    uint8 local;          /*< Local MAC address. (0 == false, 1 == true)
                                A part of L2L3 Bridge feature. If true, then the forward list
                                of such a static entry is ignored and frames with
                                a corresponding destination MAC address are passed to
                                the IP router algorithm. See chapter about L2L3 Bridge. */

    uint8 dst_discard;    /*< Frames with matching destination MAC address (and VLAN tag)
                                shall be discarded. (0 == disabled, 1 == enabled) */

    uint8 src_discard;    /*< Frames with matching source MAC address (and VLAN tag)
                                shall be discarded. (0 == disabled, 1 == enabled) */
} fpp_l2_static_ent_cmd_t;
/* [fpp_l2_static_ent_cmd_t] */

/**
 * @def         FPP_CMD_L2_FLUSH_LEARNED
 * @brief       FCI command to remove all dynamically learned MAC table entries.
 * @details     Related topics: @ref l2_bridge, @ref l2l3_bridge
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_LEARNED, 0, NULL);
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_L2_FLUSH_LEARNED                    0xf380

/**
 * @def         FPP_CMD_L2_FLUSH_STATIC
 * @brief       FCI command to remove all static MAC table entries.
 * @details     Related topics: @ref l2_bridge, @ref l2l3_bridge, @ref FPP_CMD_L2_STATIC_ENT
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_STATIC, 0, NULL);
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_L2_FLUSH_STATIC                     0xf390

/**
 * @def         FPP_CMD_L2_FLUSH_ALL
 * @brief       FCI command to remove all MAC table entries (clear the whole MAC table).
 * @details     Related topics: @ref l2_bridge, @ref l2l3_bridge
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_L2_FLUSH_ALL, 0, NULL);
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_L2_FLUSH_ALL                        0xf3a0

/**
 * @def         FPP_CMD_FP_TABLE
 * @brief       FCI command for management of Flexible Parser tables.
 * @details     Related topics: @ref flex_parser
 * @details     Related data types: @ref fpp_fp_table_cmd_t, @ref fpp_fp_rule_props_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new FP table.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing FP table.
 *              - @c FPP_ACTION_USE_RULE <br>
 *                   Insert an FP rule into an FP table at the specified position.
 *              - @c FPP_ACTION_UNUSE_RULE <br>
 *                   Remove an FP rule from an FP table.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) an FP table query session and get properties
 *                   of the first FP @b rule from the requested FP table.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next FP @b rule
 *                   from the requested FP table. Intended to be called in a loop
 *                   (to iterate through the requested FP table).
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new FP table.
 * @code{.c}
 *  .............................................
 *  fpp_fp_table_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_REGISTER,    // Action
 *    .table_info.t.table_name = "..."  // Name of a new FP table.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
 *                                                  (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing FP table.
 * @code{.c}
 *  .............................................
 *  fpp_fp_table_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .table_info.t.table_name = "..."  // Name of an existing FP table.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
 *                                                  (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 * @note FP table cannot be destroyed if it is in use by some PFE feature.
 *       First remove the table from use, then destroy it.
 *
 * FPP_ACTION_USE_RULE
 * -------------------
 * Insert an FP rule at the specified position in an FP table.
 * - If there are already some rules in the table, they are shifted accordingly to make room
 *   for the newly inserted rule.
 * - If the desired position is greater than the count of all rules in the table, the newly
 *   inserted rule is placed as the last rule of the table.
 *
 * @code{.c}
 *  .............................................
 *  fpp_fp_table_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_USE_RULE,     // Action
 *    .table_info.t.table_name = "...",  // Name of an existing FP table.
 *    .table_info.t.rule_name  = "...",  // Name of an existing FP rule.
 *    .table_info.t.position   = ...     // Desired position of the rule in the table.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
 *                                                  (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 * @note Each FP rule can be assigned only to one FP table (cannot be simultaneously a member of multiple FP tables).
 *
 * FPP_ACTION_UNUSE_RULE
 * ---------------------
 * Remove an FP rule from an FP table.
 * @code{.c}
 *  .............................................
 *  fpp_fp_table_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UNUSE_RULE,   // Action
 *    .table_info.t.table_name = "...",  // Name of an existing FP table.
 *    .table_info.t.rule_name  = "...",  // Name of an FP rule which is a member of the table.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FP_TABLE, sizeof(fpp_fp_table_cmd_t),
 *                                                  (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of an FP @b rule from the requested FP table.
 * Query result (properties of the @b rule) is stored in the member `.table_info.r`.
 * @code{.c}
 *  .............................................
 *  fpp_fp_table_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY         // Action
 *    .table_info.t.table_name = "...",  // Name of an existing FP table.
 *  };
 *
 *  fpp_fp_table_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_FP_TABLE,
 *                  sizeof(fpp_fp_table_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci.table_info.r' now holds properties of the first FP rule from
 *  //  the requested FP table.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_FP_TABLE,
 *                  sizeof(fpp_fp_table_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci.table_info.r' now holds properties of the next FP rule from
 *  //  the requested FP table.
 *  .............................................
 * @endcode
 * @note There is currently no way to read a list of existing FP tables from PFE.
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c ENOENT @c (-2)
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the FP table query session (no more FP @b rules in the requested table).
 *        - For other ACTIONs: Unknown (nonexistent) FP table was requested.
 * - @c EEXIST @c (-17) <br>
 *        Requested FP table already exists (is already registered).
 * - @c EACCES @c (-13) <br>
 *        Requested FP table cannot be destroyed (is probably in use by some PFE feature).
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_FP_TABLE                        0xf220

/**
 * @def         FPP_CMD_FP_RULE
 * @brief       FCI command for management of Flexible Parser rules.
 * @details     Related topics: @ref flex_parser
 * @details     Related data types: @ref fpp_fp_rule_cmd_t, @ref fpp_fp_rule_props_t
 * @details     Each FP rule consists of a condition specified by the following properties:
 *              `.data`, `.mask` and `.offset` + `.offset_from`. FP rule then works as follows:
 *              32-bit data value from the inspected Ethernet frame (at given @c offset_from +
 *              @c offset position, masked by the @c mask) is compared with the @c data value
 *              (masked by the same @c mask). If the values are equal, then condition of the FP rule
 *              is true. An invert flag may be set to invert the condition result.
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new FP rule.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing FP rule.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) an FP rule query session and get properties
 *                   of the first FP rule from the internal collective list of all
 *                   FP rules (regardless of FP table affiliation).
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next FP rule
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new FP rule. For detailed info about FP rule properties, see fpp_fp_rule_cmd_t.
 * @code{.c}
 *  .............................................
 *  fpp_fp_rule_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_REGISTER,  // Action
 *    .r.rule_name = "...",           // Rule name. A string of up to 15 characters + '\0'.
 *    .r.data      = ...,             // Expected data. [NBO]
 *    .r.mask      = ...,             // Bitmask. [NBO]
 *    .r.offset    = ...,             // Offset (in bytes). [NBO]
 *    .r.invert    = ...,             // Invert the match result.
 *
 *    .r.next_rule_name = "...",      // Name of the FP rule to jump to if '.match_action' ==
 *                                    // FP_NEXT_RULE. Set all-zero if unused.
 *
 *    .r.match_action = ...,          // Action to do if the inspected frame matches
 *                                    // the FP rule criteria.
 *
 *    .r.offset_from = ...            // Header for offset calculation.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FP_RULE, sizeof(fpp_fp_rule_cmd_t),
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing FP rule.
 * @code{.c}
 *  .............................................
 *  fpp_fp_rule_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_DEREGISTER,  // Action
 *    .r.rule_name = "...",             // Name of an existing FP rule.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FP_RULE, sizeof(fpp_fp_rule_cmd_t),
 *                                                 (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 * @note FP rule cannot be destroyed if it is a member of some FP table.
 *       First remove the rule from the table, then destroy the rule.
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of an FP rule. Query result is stored in the member `.r`.
 * @code{.c}
 *  .............................................
 *  fpp_fp_rule_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *
 *  fpp_fp_rule_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_FP_RULE,
 *                  sizeof(fpp_fp_rule_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci.r' now holds properties of the first FP rule from
 *  //  the internal collective list of all FP rules.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_FP_RULE,
 *                  sizeof(fpp_fp_rule_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci.r' now holds properties of the next FP rule from
 *  //  the internal collective list of all FP rules.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c ENOENT @c (-2)
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the FP rule query session (no more FP rules).
 *        - For other ACTIONs: Unknown (nonexistent) FP rule was requested.
 * - @c EEXIST @c (-17) <br>
 *        Requested FP rule already exists (is already registered).
 * - @c EACCES @c (-13) <br>
 *        Requested FP rule cannot be destroyed (is probably a member of some FP table).
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_FP_RULE                     0xf221

#define FPP_ERR_FP_RULE_NOT_FOUND           0xf222

/**
 * @def     FPP_ACTION_USE_RULE
 * @brief   Flexible Parser specific 'use' action for FPP_CMD_FP_TABLE.
 * @hideinitializer
 */
#define FPP_ACTION_USE_RULE 10

/**
 * @def     FPP_ACTION_UNUSE_RULE
 * @brief   Flexible Parser specific 'unuse' action for FPP_CMD_FP_TABLE.
 * @hideinitializer
 */
#define FPP_ACTION_UNUSE_RULE 11

/**
 * @brief       Action to do with an inspected Ethernet frame if the frame matches FP rule criteria.
 * @details     Related data types: @ref fpp_fp_rule_props_t
 * @details     Exact meaning of FP_ACCEPT and FP_REJECT (what happens with the inspected frame)
 *              depends on the context in which the parent FP table is used. See @ref flex_parser.
 *              Generally (without any further logic inversions), FP_ACCEPT means the frame is
 *              accepted and processed by PFE, while FP_REJECT means the frame is discarded.
 */
typedef enum CAL_PACKED
{
    FP_ACCEPT,    /**< Flexible Parser accepts the frame. */
    FP_REJECT,    /**< Flexible Parser rejects the frame. */
    FP_NEXT_RULE  /**< Flexible Parser continues with the matching process, but jumps to
                       a specific FP rule in the FP table. */
} fpp_fp_rule_match_action_t;

/**
 * @brief       Header for offset calculation.
 * @details     Related data types: @ref fpp_fp_rule_props_t <br>
 * @details     Offset can be calculated either from the L2, L3 or L4 header beginning.
 *              The L2 header is also the beginning of an Ethernet frame.
 * @details     L2 header is always a valid header for offset calculation. Other headers may be missing
 *              in some Ethernet frames. If an FP rule expects L3/L4 header (for offset calculation)
 *              but the given header is missing in the inspected Ethernet frame, then the result
 *              of the matching process is "frame does not match FP rule criteria".
 */
typedef enum CAL_PACKED
{
    FP_OFFSET_FROM_L2_HEADER = 2,  /**< Calculate offset from the L2 header (frame beginning). */
    FP_OFFSET_FROM_L3_HEADER = 3,  /**< Calculate offset from the L3 header. */
    FP_OFFSET_FROM_L4_HEADER = 4   /**< Calculate offset from the L4 header. */
} fpp_fp_offset_from_t;

/**
 * @brief       Properties of an FP rule (Flexible Parser rule).
 * @details     Related data types: @ref fpp_fp_table_cmd_t, @ref fpp_fp_rule_cmd_t
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp_ext.h  fpp_fp_rule_props_t
 */
/* [fpp_fp_rule_props_t] */
typedef struct CAL_PACKED
{
    uint8 rule_name[16];  /*< Rule name. A string of up to 15 characters + '\0'. */

    uint32 data;          /*< Expected data. [NBO]. This value is expected to be found
                                at the specified offset in the inspected Ethernet frame. */

    uint32 mask;          /*< Bitmask [NBO], selecting which bits of a 32bit value shall
                                be used for data comparison. This bitmask is applied on both
                                '.data' value and the inspected value for the frame. */

    uint16 offset;        /*< Offset (in bytes) of the inspected value in the frame. [NBO]
                                This offset is calculated from the '.offset_from' header. */

    uint8 invert;         /*< Invert the match result before match action is selected. */

    uint8 next_rule_name[16];  /*< Name of the FP rule to jump to if '.match_action' ==
                                     FP_NEXT_RULE. Set all-zero if unused. This next rule must
                                     be in the same FP table (cannot jump across tables). */

    fpp_fp_rule_match_action_t match_action;  /*< Action to do if the inspected frame
                                                  matches the FP rule criteria. */

    fpp_fp_offset_from_t offset_from;  /*< Header for offset calculation. */
} fpp_fp_rule_props_t;
/* [fpp_fp_rule_props_t] */

/**
 * @brief       Data structure for an FP rule.
 * @details     Related FCI commands: @ref FPP_CMD_FP_RULE
 *
 * @snippet     fpp_ext.h  fpp_fp_rule_cmd_t
 */
/* [fpp_fp_rule_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(2)
{
    uint16 action;        /*< Action */
    fpp_fp_rule_props_t r;  /*< Properties of the rule. */
} fpp_fp_rule_cmd_t;
/* [fpp_fp_rule_cmd_t] */

/**
 * @brief       Data structure for an FP table.
 * @details     Related FCI commands: @ref FPP_CMD_FP_TABLE
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp_ext.h  fpp_fp_table_cmd_t
 */
/* [fpp_fp_table_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(2)
{
    uint16 action;                 /*< Action */
    union
    {
        struct
        {
            uint8 table_name[16];  /*< Name of the FP table to be administered. */
            uint8 rule_name[16];   /*< Name of the FP rule to be added/removed. */
            uint16 position;       /*< Position in the table where to add the rule. [NBO] */
        } t;
        fpp_fp_rule_props_t r;       /*< Query result - properties of a rule from the table */
    } table_info;
} fpp_fp_table_cmd_t;
/* [fpp_fp_table_cmd_t] */

/**
 * @def FPP_CMD_DATA_BUF_PUT
 * @brief FCI command to send an arbitrary data to the accelerator
 * @details Command is intended to be used to send custom data to the accelerator.
 *          Format of the command argument is given by the @ref fpp_buf_cmd_t
 *          structure which also defines the maximum payload length. Subsequent
 *          commands are not successful until the accelerator reads and
 *          acknowledges the current request.
 *
 * Items to be set in command argument structure:
 * @code{.c}
 *   fpp_buf_cmd_t cmd_data =
 *   {
 *     // Specify buffer payload
 *     .payload = ...,
 *     // Payload length in number of bytes
 *     .len = ...,
 *   };
 * @endcode
 *
 * Possible command return values are:
 *     - @c FPP_ERR_OK: Data written and available to the accelerator
 *     - @c FPP_ERR_AGAIN: Previous command has not been finished yet
 *     - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER: The client is not FCI owner
 *     - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED: The client is not authorized get FCI ownership
 *     - @c FPP_ERR_INTERNAL_FAILURE: Internal FCI failure
 */
#define FPP_CMD_DATA_BUF_PUT        0xf300

/**
 * @def FPP_CMD_DATA_BUF_AVAIL
 * @brief Event reported when accelerator wants to send a data buffer to host
 * @details Indication of this event also carries the buffer payload and payload
 *          length. Both are available via the event callback arguments (see the
 *          callback type and arguments within description of @ref fci_register_cb()).
 */
#define FPP_CMD_DATA_BUF_AVAIL      0xf301

/**
 * @def FPP_ERR_AGAIN
 * @hideinitializer
 */
#define FPP_ERR_AGAIN               0xf302

/**
 * @def FPP_CMD_ENDPOINT_SHUTDOWN
 * @brief Notify client about endpoint shutdown event.
 */
#define FPP_CMD_ENDPOINT_SHUTDOWN   0xf303

/**
 * @brief Argument structure for the FPP_CMD_DATA_BUF_PUT command
 */
typedef struct CAL_PACKED
{
    uint8 payload[64];    /**< The payload area */
    uint8 len;            /**< Payload length in number of bytes */
    uint8 reserved1;
    uint16 reserved2;
} fpp_buf_cmd_t;

/**
 * @def         FPP_CMD_SPD
 * @brief       FCI command for management of the IPsec offload (SPD entries).
 * @details     Related topics: @ref ipsec_offload
 * @details     Related data types: @ref fpp_spd_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Create a new SPD entry.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove (destroy) an existing SPD entry.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) an SPD entry query session and get properties
 *                   of the first SPD entry from the SPD database of a target physical interface.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next SPD entry
 *                   from the SPD database of the target physical interface.
 *                   Intended to be called in a loop (to iterate through the database).
 *
 *              @b WARNING: <br>
 *              The IPsec offload feature is available only for some Premium versions of PFE firmware.
 *              The feature should @b not be used with a firmware which does not support it.
 *              Failure to adhere to this warning will result in an undefined behavior of PFE.
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Create a new SPD entry in the SPD database of a target physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_spd_cmd_t cmd_to_fci =
 *  {
 *    .action   = FPP_ACTION_REGISTER,  // Action
 *
 *    .name     = "...",  // Physical interface name (see chapter Physical Interface).
 *    .flags    =  ...,   // SPD entry flags. A bitset.
 *    .position =  ...,   // Entry position. [NBO]
 *    .saddr    = {...},  // Source IP address. [NBO]
 *    .daddr    = {...},  // Destination IP address. [NBO]
 *
 *    .sport    =  ...,   // Source port. [NBO]
 *                        // Optional (does not have to be set). See '.flags'.
 *
 *    .dport    =  ...,   // Destination port. [NBO]
 *                        // Optional (does not have to be set). See '.flags'.
 *
 *    .protocol =  ...,   // IANA IP Protocol Number (protocol ID).
 *
 *    .sa_id    =  ...,   // SAD entry identifier for HSE. [NBO]
 *                        // Used only when '.spd_action' == SPD_ACT_PROCESS_ENCODE).
 *
 *    .spi      =  ...    // SPI to match in the ingress traffic. [NBO]
 *                        // Used only when '.spd_action' == SPD_ACT_PROCESS_DECODE).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(cliet, FPP_CMD_SPD, sizeof(fpp_spd_cmd_t),
 *                                     (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove (destroy) an existing SPD entry.
 * @code{.c}
 *  .............................................
 *  fpp_spd_cmd_t cmd_to_fci =
 *  {
 *    .action   = FPP_ACTION_DEREGISTER,  // Action
 *    .name     = "...",  // Physical interface name (see chapter Physical Interface).
 *    .position =  ...,   // Entry position. [NBO]
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(cliet, FPP_CMD_SPD, sizeof(fpp_spd_cmd_t),
 *                                     (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of an SPD entry.
 * @code{.c}
 *  .............................................
 *  fpp_spd_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *    .name   = "...",  // Physical interface name (see chapter Physical Interface).
 *  };
 *
 *  fpp_spd_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_SPD,
 *                  sizeof(fpp_spd_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the first SPD entry from
 *  //  the SPD database of the target physical interface..
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_SPD,
 *                  sizeof(fpp_spd_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next SPD entry from
 *  //  the SPD database of the target physical interface.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_ENTRY_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the SPD entry query session (no more SPD entries).
 *        - For other ACTIONs: Unknown (nonexistent) SPD entry was requested.
 * - @c FPP_ERR_FW_FEATURE_NOT_AVAILABLE <br>
 *        The feature is not available (not enabled in FW).
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_SPD 0xf226

/**
 * @brief       Action to be done for frames matching the SPD entry criteria.
 * @details     Related data types: @ref fpp_spd_cmd_t
 */
typedef enum CAL_PACKED
{
    FPP_SPD_ACTION_INVALID = 0U,    /**< RESERVED (do not use) */
    FPP_SPD_ACTION_DISCARD,         /**< Discard the frame. */
    FPP_SPD_ACTION_BYPASS,          /**< Bypass IPsec and forward normally. */
    FPP_SPD_ACTION_PROCESS_ENCODE,  /**< Send to HSE for encoding. */
    FPP_SPD_ACTION_PROCESS_DECODE   /**< Send to HSE for decoding. */
} fpp_spd_action_t;

/**
 * @brief       Flags for SPD entry.
 * @details     Related data types: @ref fpp_spd_cmd_t
 */
typedef enum CAL_PACKED
{
    FPP_SPD_FLAG_IPv6 = (1U << 1U),         /**< IPv4 if this flag @b not set. IPv6 if set. */
    FPP_SPD_FLAG_SPORT_OPAQUE = (1U << 2U), /**< Do @b not match @c fpp_spd_cmd_t.sport. */
    FPP_SPD_FLAG_DPORT_OPAQUE = (1U << 3U), /**< Do @b not match @c fpp_spd_cmd_t.dport. */
} fpp_spd_flags_t;

/**
 * @brief       Data structure for an SPD entry.
 * @details     Related FCI commands: @ref FPP_CMD_SPD
 * @note        Some values are in a network byte order [NBO].
 * @note        HSE is a Hardware Security Engine, a separate HW accelerator.
 *              Its configuration is outside the scope of this document.
 *
 * @snippet     fpp_ext.h  fpp_spd_cmd_t
 */
/* [fpp_spd_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;        /*< Action */
    char name[IFNAMSIZ];    /*< Physical interface name. */
    fpp_spd_flags_t flags;  /*< SPD entry flags. A bitset. */

    uint16 position;      /*< Entry position. [NBO]
                                0 : insert as the first entry of the SPD table.
                                N : insert as the Nth entry of the SPD table, starting from 0.
                                Entries are inserted (not overwritten). Already existing
                                entries are shifted to make room for the newly inserted one.
                                If (N > current count of SPD entries) then the new entry
                                gets inserted as the last entry of the SPD table. */

    uint32 saddr[4];      /*< Source IP address. [NBO]
                                IPv4 uses only element [0]. Address type is set in '.flags' */

    uint32 daddr[4];      /*< Destination IP address. [NBO]
                                IPv4 uses only element [0]. Address type is set in '.flags' */

    uint16 sport;         /*< Source port. [NBO]
                                Optional (does not have to be set). See '.flags' */

    uint16 dport;         /*< Destination port. [NBO]
                                Optional (does not have to be set). See '.flags' */

    uint8 protocol;       /*< IANA IP Protocol Number (protocol ID). */

    uint32 sa_id;         /*< SAD entry identifier for HSE. [NBO]
                                Used only when '.spd_action' == SPD_ACT_PROCESS_ENCODE).
                                Corresponding SAD entry must exist in HSE. */

    uint32 spi;           /*< SPI to match in the ingress traffic. [NBO]
                                Used only when '.spd_action' == SPD_ACT_PROCESS_DECODE). */

    fpp_spd_action_t spd_action;  /*< Action to be done on the frame. */
} fpp_spd_cmd_t;
/* [fpp_spd_cmd_t] */

/**
 * @def         FPP_CMD_QOS_QUEUE
 * @brief       FCI command for management of Egress QoS queues.
 * @details     Related topics: @ref egress_qos
 * @details     Related data types: @ref fpp_qos_queue_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of Egress QoS queue.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Get properties of a target Egress QoS queue.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of an Egress QoS queue.
 * @code{.c}
 *  .............................................
 *  fpp_qos_queue_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_UPDATE,  // Action
 *    .if_name = "...",              // Physical interface name.
 *    .id      =  ...,               // Queue ID.
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_qos_queue_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_QUEUE, sizeof(fpp_qos_queue_cmd_t),
 *                                            (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY
 * ----------------
 * Get properties of a target Egress QoS queue.
 * @code{.c}
 *  .............................................
 *  fpp_qos_queue_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_QUERY  // Action
 *    .if_name = "...",            // Physical interface name.
 *    .id      =  ...              // Queue ID.
 *  };
 *
 *  fpp_qos_queue_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_QOS_QUEUE,
 *                  sizeof(fpp_qos_queue_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the target Egress QoS queue.
 *  .............................................
 * @endcode
 *
  * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_QOS_QUEUE_NOT_FOUND <br>
 *        Unknown (nonexistent) Egress QoS queue was requested.
 * - @c FPP_ERR_QOS_QUEUE_SUM_OF_LENGTHS_EXCEEDED <br>
 *        Sum of all Egress QoS queue lengths for a given physical interface would exceed limits of the interface.
 *        First shorten some other queues of the interface, then lengthen the queue of interest.
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_IF_NOT_SUPPORTED <br>
 *        Requested interface does not support Egress QoS queue management.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_QOS_QUEUE           0xf400

/**
 * @def FPP_ERR_QOS_QUEUE_NOT_FOUND
 * @hideinitializer
 */
#define FPP_ERR_QOS_QUEUE_NOT_FOUND 0xf401

/**
 * @def FPP_ERR_QOS_SCHEDULER_NOT_FOUND
 * @hideinitializer
 */
#define FPP_ERR_QOS_QUEUE_SUM_OF_LENGTHS_EXCEEDED   0xf402

/**
 * @brief       Data structure for QoS queue.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_QUEUE
 * @details     Related topics: @ref egress_qos
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_qos_queue_cmd_t
 */
/* [fpp_qos_queue_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;         /*< Action */
    char if_name[IFNAMSIZ];  /*< Physical interface name. [ro] */

    uint8 id;         /*< Queue ID. [ro]
                            minimal ID == 0
                            maximal ID is implementation defined. See Egress QoS. */

    uint8 mode;       /*< Queue mode:
                            0 == Disabled. Queue will drop all packets.
                            1 == Default. HW implementation-specific. Normally not used.
                            2 == Tail drop
                            3 == WRED */

    uint32 min;       /*< Minimum threshold. [NBO]. Value is `.mode`-specific:
                            - Disabled, Default: n/a
                            - Tail drop: n/a
                            - WRED: Threshold in number of packets in the queue at which
                                    the WRED lowest drop probability zone starts.
                                    While the queue fill level is below this threshold,
                                    the drop probability is 0%. */

    uint32 max;       /*< Maximum threshold. [NBO]. Value is `.mode`-specific:
                            - Disabled, Default: n/a
                            - Tail drop: The queue length in number of packets. Queue length
                                         is the number of packets the queue can accommodate
                                         before drops will occur.
                            - WRED: Threshold in number of packets in the queue at which
                                    the WRED highest drop probability zone ends.
                                    While the queue fill level is above this threshold,
                                    the drop probability is 100%. */

    uint8 zprob[32];  /*< WRED drop probabilities for all probability zones in [%].
                            The lowest probability zone is `.zprob[0]`. Only valid for
                            `.mode = WRED`. Value 255 means 'invalid'. Number of zones
                            per queue is implementation-specific. See Egress QoS. */
} fpp_qos_queue_cmd_t;
/* [fpp_qos_queue_cmd_t] */

/**
 * @def         FPP_CMD_QOS_SCHEDULER
 * @brief       FCI command for management of Egress QoS schedulers.
 * @details     Related topics: @ref egress_qos
 * @details     Related data types: @ref fpp_qos_scheduler_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of Egress QoS scheduler.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Get properties of a target Egress QoS scheduler.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of an Egress QoS scheduler.
 * @code{.c}
 *  .............................................
 *  fpp_qos_scheduler_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_UPDATE,  // Action
 *    .if_name = "...",              // Physical interface name.
 *    .id      =  ...,               // Scheduler ID.
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_qos_scheduler_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_SCHEDULER, sizeof(fpp_qos_scheduler_cmd_t),
 *                                                (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY
 * ----------------
 * Get properties of a target Egress QoS scheduler.
 * @code{.c}
 *  .............................................
 *  fpp_qos_scheduler_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_QUERY  // Action
 *    .if_name = "...",            // Physical interface name.
 *    .id      =  ...              // Scheduler ID.
 *  };
 *
 *  fpp_qos_scheduler_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_QOS_SCHEDULER,
 *                  sizeof(fpp_qos_scheduler_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the target Egress QoS scheduler.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_QOS_SCHEDULER_NOT_FOUND <br>
 *        Unknown (nonexistent) Egress QoS scheduler was requested.
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_IF_NOT_SUPPORTED <br>
 *        Requested interface does not support Egress QoS scheduler management.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_QOS_SCHEDULER           0xf410

/**
 * @def FPP_ERR_QOS_SCHEDULER_NOT_FOUND
 * @hideinitializer
 */
#define FPP_ERR_QOS_SCHEDULER_NOT_FOUND 0xf411

/**
 * @brief       Data structure for QoS scheduler.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_SCHEDULER
 * @details     Related topics: @ref egress_qos
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_qos_scheduler_cmd_t
 */
/* [fpp_qos_scheduler_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;        /*< Action */
    char if_name[IFNAMSIZ]; /*< Physial interface name. [ro] */

    uint8 id;             /*< Scheduler ID. [ro]
                                minimal ID == 0
                                maximal ID is implementation defined. See Egress QoS. */

    uint8 mode;           /*< Scheduler mode:
                                0 == Scheduler disabled
                                1 == Data rate (payload length)
                                2 == Packet rate (number of packets) */

    uint8 algo;           /*< Scheduler algorithm:
                                0 == PQ (Priority Queue). Input with the highest priority
                                     is serviced first. Input 0 has the @b lowest priority.
                                1 == DWRR (Deficit Weighted Round Robin).
                                2 == RR (Round Robin).
                                3 == WRR (Weighted Round Robin). */

    uint32 input_en;      /*< Input enable bitfield. [NBO]
                                When a bit `n` is set it means that scheduler input `n`
                                is enabled and connected to traffic source defined by
                                `.source[n]`. Number of inputs is implementation-specific.
                                See Egress QoS. */

    uint32 input_w[32];   /*< Input weight. [NBO]. Scheduler algorithm-specific:
                                - PQ, RR - n/a
                                - WRR, DWRR - Weight in units given by `.mode` */

    uint8 input_src[32];  /*< Traffic source for each scheduler input. Traffic sources
                                are implementation-specific. See Egress QoS. */
} fpp_qos_scheduler_cmd_t;
/* [fpp_qos_scheduler_cmd_t] */

/**
 * @def         FPP_CMD_QOS_SHAPER
 * @brief       FCI command for management of Egress QoS shapers.
 * @details     Related topics: @ref egress_qos
 * @details     Related data types: @ref fpp_qos_shaper_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of Egress QoS shaper.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Get properties of a target Egress QoS shaper.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Modify properties of an Egress QoS shaper.
 * @code{.c}
 *  .............................................
 *  fpp_qos_shaper_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_UPDATE,  // Action
 *    .if_name = "...",              // Physical interface name.
 *    .id      =  ...,               // Shaper ID.
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_qos_shaper_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_SHAPER, sizeof(fpp_qos_shaper_cmd_t),
 *                                             (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY
 * ----------------
 * Get properties of a target Egress QoS shaper.
 * @code{.c}
 *  .............................................
 *  fpp_qos_shaper_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_QUERY  // Action
 *    .if_name = "...",            // Physical interface name.
 *    .id      =  ...,             // Shaper ID.
 *  };
 *
 *  fpp_qos_shaper_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_QOS_SHAPER,
 *                  sizeof(fpp_qos_shaper_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the target Egress QoS shaper.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_QOS_SHAPER_NOT_FOUND <br>
 *        Unknown (nonexistent) Egress QoS shaper was requested.
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Unexpected value of some property.
 * - @c FPP_ERR_IF_NOT_SUPPORTED <br>
 *        Requested interface does not support Egress QoS shaper management.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_QOS_SHAPER              0xf420

/**
 * @def FPP_ERR_QOS_SHAPER_NOT_FOUND
 * @hideinitializer
 */
#define FPP_ERR_QOS_SHAPER_NOT_FOUND    0xf421

/**
 * @brief       Data structure for QoS shaper.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_SHAPER
 * @details     Related topics: @ref egress_qos
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_qos_shaper_cmd_t
 */
/* [fpp_qos_shaper_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;        /*< Action */
    char if_name[IFNAMSIZ]; /*< Physial interface name. [ro] */

    uint8 id;             /*< Shaper ID. [ro]
                                minimal ID == 0
                                maximal ID is implementation defined. See Egress QoS. */

    uint8 position;       /*< Position of the shaper.
                                Positions are implementation defined. See Egress QoS. */

    uint32 isl;           /*< Idle slope in units per second (see `.mode`). [NBO] */
    sint32 max_credit;     /*< Max credit. [NBO] */
    sint32 min_credit;     /*< Min credit. [NBO] */

    uint8 mode;           /*< Shaper mode:
                                0 == Shaper disabled
                                1 == Data rate.
                                     `.isl` is in bits-per-second.
                                     `.max_credit` and `.min_credit` are in number of bytes.
                                2 == Packet rate.
                                     `isl` is in packets-per-second.
                                     `.max_credit` and `.min_credit` are in number of packets.
                                */
} fpp_qos_shaper_cmd_t;
/* [fpp_qos_shaper_cmd_t] */

/**
 * @def         FPP_CMD_QOS_POLICER
 * @brief       FCI command for Ingress QoS policer enable/disable.
 * @details     Related topics: @ref ingress_qos, @ref FPP_CMD_QOS_POLICER_FLOW, @ref FPP_CMD_QOS_POLICER_WRED, @ref FPP_CMD_QOS_POLICER_SHP
 * @details     Related data types: @ref fpp_qos_policer_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Enable/disable Ingress QoS policer of a physical interface.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Get status of a target Ingress QoS policer.
 *
 * @note
 * Management of Ingress QoS policer is available only for @b emac physical interfaces.
 *
 * @note
 * Effects of enable/disable:
 * - If an Ingress QoS policer gets disabled, its associated flow table, WRED module and shaper module are disabled as well.
 * - If an Ingress QoS policer gets enabled, it starts with default configuration
 *   (clear flow table, default WRED configuration, default shaper configuration).
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Enable/disable Ingress QoS policer of an @b emac physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_UPDATE,
 *    .if_name = "...",    // Physical interface name ('emac' interfaces only).
 *    .enable  =  ...      // 0 == disabled ; 1 == enabled
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_POLICER, sizeof(fpp_qos_policer_cmd_t),
 *                                              (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY
 * ----------------
 * Get status (enabled/disabled) of an Ingress QoS policer.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_QUERY,
 *    .if_name = "...",    // Physical interface name ('emac' interfaces only).
 *  };
 *
 *  fpp_qos_policer_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_QOS_POLICER,
 *                  sizeof(fpp_qos_policer_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds the '.enable' field set accordingly.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Wrong physical interface provided (i.e. non-'emac'), or unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_QOS_POLICER 0xf430

/**
 * @brief       Data structure for Ingress QoS policer enable/disable.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_POLICER
 * @details     Related topics: @ref ingress_qos
 * @note        Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_qos_policer_cmd_t
 */
/* [fpp_qos_policer_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;
    char if_name[IFNAMSIZ]; /*< Physical interface name ('emac' interfaces only). [ro] */
    uint8 enable;         /*< Enable/disable switch of the Ingress QoS Policer HW module.
                                0 == disabled, 1 == enabled. */
} fpp_qos_policer_cmd_t;
/* [fpp_qos_policer_cmd_t] */

/**
 * @def         FPP_CMD_QOS_POLICER_FLOW
 * @brief       FCI command for management of Ingress QoS packet flows.
 * @details     Related topics: @ref ingress_qos
 * @details     Related data types: @ref fpp_qos_policer_flow_cmd_t, @ref fpp_iqos_flow_spec_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_REGISTER <br>
 *                   Add a flow to an Ingress QoS flow classification table.
 *              - @c FPP_ACTION_DEREGISTER <br>
 *                   Remove a flow from an Ingress QoS flow classification table.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a flow query session and get properties
 *                   of the first flow from an Ingress QoS flow clasification table.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next
 *                   flow from the table. Intended to be called in a loop
 *                   (to iterate through the table).
 *
 * @note
 * - Management of Ingress QoS packet flows is available only for @b emac physical interfaces.
 * - Management of Ingress QoS packet flows is possible only if the associated @ref FPP_CMD_QOS_POLICER is enabled.
 *
 * FPP_ACTION_REGISTER
 * -------------------
 * Add a packet flow to an Ingress QoS flow classification table. Specify flow parameters and
 * the action to be done for packets which conform to the given flow.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_flow_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_REGISTER,
 *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
 *    .id      =  ...,   // Position in the classification table. 0xFF == automatic placement.
 *
 *    .flow    = {...}   // Flow specification structure.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_FLOW, sizeof(fpp_qos_policer_flow_cmd_t),
 *                                                   (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_DEREGISTER
 * ---------------------
 * Remove a flow from an Ingress QoS flow classification table.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_flow_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_DEREGISTER,
 *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
 *    .id      =  ...,   // Position in the classification table.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_FLOW, sizeof(fpp_qos_policer_flow_cmd_t),
 *                                                   (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of the Ingress QoS flow.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_flow_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_QUERY,
 *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
 *    .id      =  ...,   // Entry position in the table, from 0 to "table size - 1".
 *  };
 *
 *  fpp_qos_policer_flow_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_FLOW,
 *                  sizeof(fpp_qos_policer_flow_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds the content of the first available (i.e. active) flow
 *  //  from the Ingress QoS flow classification table of the target physical interface.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_FLOW,
 *                  sizeof(fpp_qos_policer_flow_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next available flow from the table.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_QOS_POLICER_FLOW_NOT_FOUND
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the Ingress QoS flow query session (no more flows).
 *        - For other ACTIONs: Unknown (nonexistent) Ingress QoS flow was requested.
 * - @c FPP_ERR_QOS_POLICER_FLOW_TABLE_FULL <br>
 *        Attempting to register flow with `.id >= FPP_IQOS_FLOW_TABLE_SIZE` or flow table full.
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Wrong physical interface provided (i.e. non-'emac'), or unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_QOS_POLICER_FLOW            0xf440

#define FPP_ERR_QOS_POLICER_FLOW_TABLE_FULL 0xf441
#define FPP_ERR_QOS_POLICER_FLOW_NOT_FOUND  0xf442

/**
 * @brief       Argumentless flow types (match flags).
 * @details     Related data types: @ref fpp_iqos_flow_spec_t
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_FLOW_TYPE_ETH = (1 << 0),     /**< Match ETH packets. */
    FPP_IQOS_FLOW_TYPE_PPPOE = (1 << 1),   /**< Match PPPoE packets. */
    FPP_IQOS_FLOW_TYPE_ARP = (1 << 2),     /**< Match ARP packets. */
    FPP_IQOS_FLOW_TYPE_IPV4 = (1 << 3),    /**< Match IPv4 packets. */
    FPP_IQOS_FLOW_TYPE_IPV6 = (1 << 4),    /**< Match IPv6 packets. */
    FPP_IQOS_FLOW_TYPE_IPX = (1 << 5),     /**< Match IPX packets. */
    FPP_IQOS_FLOW_TYPE_MCAST = (1 << 6),   /**< Match L2 multicast packets. */
    FPP_IQOS_FLOW_TYPE_BCAST = (1 << 7),   /**< Match L2 broadcast pakcets. */
    FPP_IQOS_FLOW_TYPE_VLAN = (1 << 8),    /**< Match VLAN tagged packets. */

    FPP_IQOS_FLOW_TYPE_MAX = FPP_IQOS_FLOW_TYPE_VLAN,
    /* Ensure proper size */
    FPP_IQOS_FLOW_TYPE_RESERVED = (uint16)(1U << 15U)
} fpp_iqos_flow_type_t;

/**
 * @brief       Argumentful flow types (match flags).
 * @details     Related data types: @ref fpp_iqos_flow_spec_t, @ref fpp_iqos_flow_args_t
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_ARG_VLAN = (1 << 0),     /**< Match bitmasked VLAN value. */
    FPP_IQOS_ARG_TOS = (1 << 1),      /**< Match bitmasked TOS value. */
    FPP_IQOS_ARG_L4PROTO = (1 << 2),  /**< Match bitmasked L4 protocol value. */
    FPP_IQOS_ARG_SIP = (1 << 3),      /**< Match prefixed source IPv4/IPv6 address. */
    FPP_IQOS_ARG_DIP = (1 << 4),      /**< Match prefixed destination IPv4/IPv6 address. */
    FPP_IQOS_ARG_SPORT = (1 << 5),    /**< Match L4 source port range. */
    FPP_IQOS_ARG_DPORT = (1 << 6),    /**< Match L4 destination port range. */

    FPP_IQOS_ARG_MAX = FPP_IQOS_ARG_DPORT,
    /* Ensure proper size */
    FPP_IQOS_ARG_RESERVED = (uint16)(1U << 15U)
} fpp_iqos_flow_arg_type_t;

/**
 * @brief       @ref FPP_CMD_QOS_POLICER_FLOW, @ref fpp_iqos_flow_args_t : <br>
 *              Bitmask for comparison of the whole VLAN ID (all bits compared).
*/
#define FPP_IQOS_VLAN_ID_MASK 0xFFF

/**
 * @brief       @ref FPP_CMD_QOS_POLICER_FLOW, @ref fpp_iqos_flow_args_t : <br>
 *              Bitmask for comparison of the whole TOS/TCLASS field (all bits compared).
*/
#define FPP_IQOS_TOS_MASK     0xFF

/**
 * @brief       @ref FPP_CMD_QOS_POLICER_FLOW, @ref fpp_iqos_flow_args_t : <br>
 *              Bitmask for comparison of the whole L4 protocol field (all bits compared).
*/
#define FPP_IQOS_L4PROTO_MASK 0xFF

/**
 * @brief       @ref FPP_CMD_QOS_POLICER_FLOW, @ref fpp_iqos_flow_args_t : <br>
 *              Network prefix for comparison of the whole IP address (all bits compared).
*/
#define FPP_IQOS_SDIP_MASK    0x3F

/**
 * @brief       Arguments for argumentful flow types.
 * @details     Related data types: @ref fpp_iqos_flow_spec_t, @ref fpp_iqos_flow_arg_type_t
 *
 * @details
 * Bitmasking
 * ----------
 * Explanation: <br>
 *   In the comparison process for argumentful flow types, bitmasking works as follows: <br>
 *   `if ((PacketData & Mask) == (ArgData & Mask)), then packet matches the flow.`
 *   - `PacketData` is the inspected value from an ingress packet.
 *   - `ArgData` is the argument value of an argumentful flow type.
 *   - `Mask` is the bitmask of an argumentful flow type. <br>
 *      For IP addresses, the network prefix (e.g. /24) is internally converted into
 *      a valid subnet mask (/24 == 0xFFFFFFF0).
 *
 * Example: <br>
 *   If `.l4proto_m = 0x07` , then only the lowest 3 bits of the TOS field would be compared.
 *   That means any protocol value with matching lowest 3 bits would be accepted.
 *
 * Hint: <br>
 * Use the provided bitmask symbols (see descriptions of struct fields) to compare whole values (all bits).
 * Do not use custom bitmasks, unless some specific scenario requires such refinement.
 *
 * Description
 * -----------
 * @note
 * Some values are in a network byte order [NBO].
 *
 * @snippet     fpp_ext.h  fpp_iqos_flow_args_t
 */
/* [fpp_iqos_flow_args_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 vlan;       /*< FPP_IQOS_ARG_VLAN: VLAN ID (max 4095). [NBO] */

    uint16 vlan_m;     /*< FPP_IQOS_ARG_VLAN: VLAN ID comparison bitmask (12b). [NBO]
                             Use FPP_IQOS_VLAN_ID_MASK to compare whole value (all bits). */

    uint8 tos;         /*< FPP_IQOS_ARG_TOS: TOS field for IPv4, TCLASS for IPv6. */

    uint8 tos_m;       /*< FPP_IQOS_ARG_TOS: TOS comparison bitmask.
                             Use FPP_IQOS_TOS_MASK to compare whole value (all bits). */

    uint8 l4proto;     /*< FPP_IQOS_ARG_L4PROTO: L4 protocol field for IPv4 and IPv6. */

    uint8 l4proto_m;   /*< FPP_IQOS_ARG_L4PROTO: L4 protocol comparison bitmask.
                             Use FPP_IQOS_L4PROTO_MASK to compare whole value (all bits). */

    uint32 sip;        /*< FPP_IQOS_ARG_SIP: Source IP address for IPv4/IPv6. [NBO] */
    uint32 dip;        /*< FPP_IQOS_ARG_DIP: Destination IP address for IPv4/IPv6. [NBO] */

    uint8 sip_m;       /*< FPP_IQOS_ARG_SIP: Source IP address - network prefix.
                             Use FPP_IQOS_SDIP_MASK to compare whole address (all bits). */

    uint8 dip_m;       /*< FPP_IQOS_ARG_DIP: Destination IP address - network prefix.
                             Use FPP_IQOS_SDIP_MASK to compare whole address (all bits). */

    uint16 sport_max;  /*< FPP_IQOS_ARG_SPORT: Max L4 source port. [NBO] */
    uint16 sport_min;  /*< FPP_IQOS_ARG_SPORT: Min L4 source port. [NBO] */
    uint16 dport_max;  /*< FPP_IQOS_ARG_DPORT: Max L4 destination port. [NBO] */
    uint16 dport_min;  /*< FPP_IQOS_ARG_DPORT: Min L4 destination port. [NBO] */
} fpp_iqos_flow_args_t;
/* [fpp_iqos_flow_args_t] */

/**
 * @brief       Action to be done for matching packets.
 * @details     Related data types: @ref fpp_iqos_flow_spec_t
 * @note        See @ref ingress_qos for explanation of Ingress QoS traffic classification.
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_FLOW_MANAGED = 0,  /**< Classify the matching packet as Managed traffic. Default action. */
    FPP_IQOS_FLOW_DROP,         /**< Drop the packet. */
    FPP_IQOS_FLOW_RESERVED,     /**< Classify the matching packet as Reserved traffic. */

    FPP_IQOS_FLOW_COUNT         /* must be last */
} fpp_iqos_flow_action_t;

/**
 * @brief       Specification of Ingress QoS packet flow.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_POLICER_FLOW
 * @details     Related data types: @ref fpp_qos_policer_flow_cmd_t
 * @note        Some values are in a network byte order [NBO].
 *
 * @snippet     fpp_ext.h  fpp_iqos_flow_spec_t
 */
/* [fpp_iqos_flow_spec_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    fpp_iqos_flow_type_t type_mask;          /*< Argumentless flow types to match. [NBO]
                                                 A bitset mask. */

    fpp_iqos_flow_arg_type_t arg_type_mask;  /*< Argumentful flow types to match. [NBO]
                                                 A bitset mask. */

    fpp_iqos_flow_args_t CAL_PACKED_ALIGNED(4) args; /*< Arguments for argumentful flow types.
                                                         Related to 'arg_type_mask'. */

    fpp_iqos_flow_action_t action;           /*< Action to be done for matching packets. */
} fpp_iqos_flow_spec_t;
/* [fpp_iqos_flow_spec_t] */

/**
 * @brief       Data structure for Ingress QoS packet flow.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_POLICER_FLOW
 * @details     Related topics: @ref ingress_qos
 *
 * @snippet     fpp_ext.h  fpp_qos_policer_flow_cmd_t
 */
/* [fpp_qos_policer_flow_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;
    char if_name[IFNAMSIZ]; /*< Physical interface name ('emac' interfaces only). */

    uint8 id;             /*< Position in the classification table.
                                minimal ID == 0
                                maximal ID is implementation defined. See Ingress QoS.
                                For FPP_ACTION_REGISTER, value 0xFF means "don't care".
                                If 0xFF is set as registration id, driver will automatically
                                choose the first available free position. */

    fpp_iqos_flow_spec_t CAL_PACKED_ALIGNED(4) flow;  /*< Flow specification. */
} fpp_qos_policer_flow_cmd_t;
/* [fpp_qos_policer_flow_cmd_t] */

/**
 * @def         FPP_CMD_QOS_POLICER_WRED
 * @brief       FCI command for management of Ingress QoS WRED queues.
 * @details     Related topics: @ref ingress_qos
 * @details     Related data types: @ref fpp_qos_policer_wred_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of Ingress QoS WRED queue.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Get properties of a target Ingress QoS WRED queue.
 *
 * @note
 * - Management of Ingress QoS WRED queues is available only for @b emac physical interfaces.
 * - Management of Ingress QoS WRED queues is possible only if the associated @ref FPP_CMD_QOS_POLICER is enabled.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Update Ingress QoS WRED queue of a target physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_wred_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_UPDATE,
 *    .if_name = "...",      // Physical interface name ('emac' interfaces only).
 *    .queue   =  ...,       // Target Ingress QoS WRED queue (DMEM, LMEM, RXF).
 *    .enable  =  ...,       // Enable/disable switch (0 == disabled, 1 == enabled).
 *
 *    .thr[]   = {...},      // Min/max/full WRED thresholds.
 *                           // 0xFFFF == let HW keep its currently configured thld value.
 *
 *    .zprob[] = {...}       // WRED drop probabilities for all zones in 1/16 increments.
 *                           // 0xFF == let HW keep its currently configured zone value.
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_WRED, sizeof(fpp_qos_policer_wred_cmd_t),
 *                                                   (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY
 * ----------------
 * Get properties of a target Ingress QoS WRED queue.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_wred_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_QUERY,
 *    .if_name = "...",      // Physical interface name ('emac' interfaces only).
 *    .queue   =  ...,       // Target Ingress QoS WRED queue (DMEM, LMEM, RXF).
 *  };
 *
 *  fpp_qos_policer_wred_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_WRED,
 *                  sizeof(fpp_qos_policer_wred_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the target Ingress QoS WRED queue.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Wrong physical interface provided (i.e. non-'emac'), or unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_QOS_POLICER_WRED            0xf450

/**
 * @brief       Supported target queues of Ingress QoS WRED.
 * @details     Related data types: @ref fpp_qos_policer_wred_cmd_t
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_Q_DMEM = 0,/**< Queue which is in DMEM (Data Memory). Standard storage. */
    FPP_IQOS_Q_LMEM,    /**< Queue which is in LMEM (Local Memory). Faster execution but smaller capacity. */
    FPP_IQOS_Q_RXF,     /**< Queue which is in FIFO of the associated physical interface. */

    FPP_IQOS_Q_COUNT    /* must be last */
} fpp_iqos_queue_t;

/**
 * @brief       Supported probability zones of Ingress QoS WRED queue.
 * @details     Related data types: @link fpp_qos_policer_wred_cmd_t @endlink`.zprob[]`
 * @note        This enum represents valid array indexes.
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_WRED_ZONE1 = 0,   /**< WRED probability zone 1 (lowest). */
    FPP_IQOS_WRED_ZONE2,       /**< WRED probability zone 2. */
    FPP_IQOS_WRED_ZONE3,       /**< WRED probability zone 3. */
    FPP_IQOS_WRED_ZONE4,       /**< WRED probability zone 4 (highest). */

    FPP_IQOS_WRED_ZONES_COUNT  /* must be last */
} fpp_iqos_wred_zone_t;

/**
 * @brief       Thresholds of Ingress QoS WRED queue.
 * @details     Related data types: @link fpp_qos_policer_wred_cmd_t @endlink`.thr[]`
 * @note        - This enum represents valid array indexes.
 * @note        - See @ref ingress_qos for explanation of Ingress QoS traffic classification. <br>
 *                (Unmanaged/Managed/Reserved)
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_WRED_MIN_THR = 0,  /**< WRED queue min threshold. <br>
                                     If queue fill below `.thr[FPP_IQOS_WRED_MIN_THR]`, the following applies:
                                     - Drop Unmanaged traffic by probability zones.
                                     - Keep Managed and Reserved traffic. */

    FPP_IQOS_WRED_MAX_THR,      /**< WRED queue max threshold. <br>
                                     If queue fill over `.thr[FPP_IQOS_WRED_MIN_THR]` but below `.thr[FPP_IQOS_WRED_MAX_THR]`, the following applies:
                                     - Drop all Unmanaged and Managed traffic.
                                     - Keep Reserved traffic. */

    FPP_IQOS_WRED_FULL_THR,     /**< WRED queue full threshold. <br>
                                     If queue fill over `.thr[FPP_IQOS_WRED_FULL_THR]`, then drop all traffic. */

    FPP_IQOS_WRED_THR_COUNT     /* must be last */
} fpp_iqos_wred_thr_t;

/**
 * @brief       Data structure for Ingress QoS WRED queue.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_POLICER_WRED
 * @details     Related topics: @ref ingress_qos
 * @details     Related data types: @ref fpp_iqos_wred_thr_t, @ref fpp_iqos_wred_zone_t
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_qos_policer_wred_cmd_t
 */
/* [fpp_qos_policer_wred_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;
    char if_name[IFNAMSIZ];  /*< Physical interface name ('emac' interfaces only). [ro] */
    fpp_iqos_queue_t queue;  /*< Target Ingress QoS WRED queue. [ro] */
    uint8 enable;          /*< Enable/disable switch of the target WRED queue HW module.
                                 0 == disabled, 1 == enabled. */

    uint16 thr[FPP_IQOS_WRED_THR_COUNT]; /*< WRED queue thresholds. [NBO]
                                               See 'fpp_iqos_wred_thr_t'.
                                               Unit is "number of packets".
                                               Min value == 0
                                               Max value is implementation defined. See
                                               Ingress QoS chapter for implementation details.
                                               Value 0xFFFF == HW keeps its currently
                                                               configured value. */

    uint8 zprob[FPP_IQOS_WRED_ZONES_COUNT]; /*< WRED drop probabilities for all probability
                                                  zones. See 'fpp_iqos_wred_zone_t'.
                                                  One unit (1) represents probability of 1/16.
                                                  Min value == 0   ( 0/16 = 0%)
                                                  Max value == 15  (15/16 = 93,75%)
                                                  Value 255 == HW keeps its currently
                                                               configured value. */
} fpp_qos_policer_wred_cmd_t;
/* [fpp_qos_policer_wred_cmd_t] */

/**
 * @def         FPP_CMD_QOS_POLICER_SHP
 * @brief       FCI command for management of Ingress QoS shapers.
 * @details     Related topics: @ref ingress_qos
 * @details     Related data types: @ref fpp_qos_policer_shp_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Modify properties of Ingress QoS shaper.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Get properties of a target Ingress QoS shaper.
 *
 * @note
 * - Management of Ingress QoS shapers is available only for @b emac physical interfaces.
 * - Management of Ingress QoS shapers is possible only if the associated @ref FPP_CMD_QOS_POLICER is enabled.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Configure Ingress QoS credit based shaper (IEEE 802.1Q) of a target physical interface.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_shp_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_UPDATE,
 *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
 *    .id      =  ...,   // ID of the target Ingress QoS shaper.
 *
 *    ... = ...  // Properties (data fields) to be updated, and their new (modified) values.
 *               // Some properties cannot be modified (see fpp_qos_policer_shp_cmd_t).
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_QOS_POLICER_SHP, sizeof(fpp_qos_policer_shp_cmd_t),
 *                                                  (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY
 * ----------------
 * Get properties of a target Ingress QoS shaper.
 * @code{.c}
 *  .............................................
 *  fpp_qos_policer_shp_cmd_t cmd_to_fci =
 *  {
 *    .action  = FPP_ACTION_QUERY,
 *    .if_name = "...",  // Physical interface name ('emac' interfaces only).
 *    .id      =  ...    // ID of the target Ingress QoS shaper.
 *  };
 *
 *  fpp_qos_policer_shp_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_QOS_POLICER_SHP,
 *                  sizeof(fpp_qos_policer_shp_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the target Ingress QoS shaper.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_WRONG_COMMAND_PARAM <br>
 *        Wrong physical interface provided (i.e. non-'emac'), or unexpected value of some property.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_QOS_POLICER_SHP             0xf460

/**
 * @brief       Types of Ingress QoS shaper.
 * @details     Related data types: @ref fpp_qos_policer_shp_cmd_t
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_SHP_PORT_LEVEL = 0,    /**< Port level data rate shaper. */
    FPP_IQOS_SHP_BCAST,             /**< Shaper for broadcast packets. */
    FPP_IQOS_SHP_MCAST,             /**< Shaper for multicast packets. */

    FPP_IQOS_SHP_TYPE_COUNT         /* must be last */
} fpp_iqos_shp_type_t;

/**
 * @brief       Modes of Ingress QoS shaper.
 * @details     Related data types: @ref fpp_qos_policer_shp_cmd_t
 */
typedef enum CAL_PACKED
{
    FPP_IQOS_SHP_BPS = 0,          /**< `.isl` is in bits-per-second. <br>
                                        `.max_credit` and `.min_credit` are in number of bytes. */

    FPP_IQOS_SHP_PPS,              /**< `.isl` is in packets-per-second. <br>
                                        `.max_credit` and `.min_credit` are in number of packets. */

    FPP_IQOS_SHP_RATE_MODE_COUNT   /* must be last */
} fpp_iqos_shp_rate_mode_t;

/**
 * @brief       Data structure for Ingress QoS shaper.
 * @details     Related FCI commands: @ref FPP_CMD_QOS_POLICER_SHP
 * @details     Related topics: @ref ingress_qos
 * @note        - Some values are in a network byte order [NBO].
 * @note        - Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_qos_policer_shp_cmd_t
 */
/* [fpp_qos_policer_shp_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;
    char if_name[IFNAMSIZ];    /*< Physical interface name ('emac' interfaces only). [ro] */

    uint8 id;                /*< ID of the target Ingress QoS shaper. [ro]
                                   Min ID == 0
                                   Max ID is implementation defined. See Ingress QoS. */

    uint8 enable;            /*< Enable/disable switch of the target Ingress QoS shaper 
                                   HW module. 0 == disabled, 1 == enabled. */

    fpp_iqos_shp_type_t type;  /*< Shaper type. Port level, bcast or mcast. */

    fpp_iqos_shp_rate_mode_t mode;  /*< Shaper mode. Bits or packets. */
    uint32 isl;                   /*< Idle slope. Units are '.mode' dependent. [NBO] */
    sint32 max_credit;             /*< Max credit. Units are '.mode' dependent. [NBO] */
    sint32 min_credit;             /*< Min credit. Units are '.mode' dependent. [NBO]
                                        Must be negative. */
} fpp_qos_policer_shp_cmd_t;
/* [fpp_qos_policer_shp_cmd_t] */

/**
 * @def         FPP_CMD_FW_FEATURE
 * @brief       FCI command for management of configurable FW features.
 * @details     Related topics: ---
 * @details     Related data types: @ref fpp_fw_features_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Enable/disable a FW feature.
 *              - @c FPP_ACTION_QUERY <br>
 *                   Initiate (or reinitiate) a FW feature query session and get properties
 *                   of the first FW feature from the internal list of FW features.
 *              - @c FPP_ACTION_QUERY_CONT <br>
 *                   Continue the query session and get properties of the next FW feature
 *                   from the list. Intended to be called in a loop (to iterate through the list).
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Enable/disable a FW feature.
 * @code{.c}
 *  .............................................
 *  fpp_fw_features_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *    .val    = ...                 // 0 == disabled ; 1 == enabled
 *  };
 *
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FW_FEATURE, sizeof(fpp_fw_features_cmd_t),
 *                                             (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT
 * ------------------------------------------
 * Get properties of a FW feature.
 * @code{.c}
 *  .............................................
 *  fpp_fw_features_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_QUERY  // Action
 *  };
 *
 *  fpp_fw_features_cmd_t reply_from_fci = {0};
 *  unsigned short reply_length = 0u;
 *
 *  int rtn = 0;
 *  rtn = fci_query(client, FPP_CMD_FW_FEATURE,
 *                  sizeof(fpp_fw_features_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the first FW feature from
 *  //  the internal list of FW features.
 *
 *  cmd_to_fci.action = FPP_ACTION_QUERY_CONT;
 *  rtn = fci_query(client, FPP_CMD_FW_FEATURE,
 *                  sizeof(fpp_fw_features_cmd_t), (unsigned short*)(&cmd_to_fci),
 *                  &reply_length, (unsigned short*)(&reply_from_fci));
 *
 *  // 'reply_from_fci' now holds properties of the next FW feature from
 *  //  the internal list of FW features.
 *  .............................................
 * @endcode
 *
 * Command return values (for all applicable ACTIONs)
 * --------------------------------------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c ENOENT @c (-2)
 *        - For FPP_ACTION_QUERY or FPP_ACTION_QUERY_CONT: The end of the FW feature query session (no more FW features).
 *        - For other ACTIONs: Unknown (nonexistent) FW feature was requested.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_FW_FEATURE                  0xf250
#define FPP_ERR_FW_FEATURE_NOT_FOUND        0xf251
#define FPP_ERR_FW_FEATURE_NOT_AVAILABLE    0xf252
#define FPP_FEATURE_NAME_SIZE 32
#define FPP_FEATURE_DESC_SIZE 128

/**
 * @brief       Feature flags
 * @details     Flags combinations:
 *              - @c FEAT_PRESENT is missing: <br>
 *                     The feature is not available.
 *              - @c FEAT_PRESENT is set, but @c FEAT_RUNTIME is missing: <br>
 *                     The feature is always enabled (cannot be disabled).
 *              - @c FEAT_PRESENT is set and @c FEAT_RUNTIME is set: <br>
 *                     The feature can be enabled/disable at runtime.
 *                     Enable state must be read out of DMEM.
 */
typedef enum CAL_PACKED
{
    FEAT_NONE = 0U,
    FEAT_PRESENT = (1U << 0U),      /**< Feature not available if this not set. */
    FEAT_RUNTIME = (1U << 1U)       /**< Feature can be enabled/disabled at runtime. */
} fpp_fw_feature_flags_t;

/**
 * @brief       Data structure for FW feature setting.
 * @details     Related FCI commands: @ref FPP_CMD_FW_FEATURE
 * @note        Some values cannot be modified by FPP_ACTION_UPDATE [ro].
 *
 * @snippet     fpp_ext.h  fpp_fw_features_cmd_t
 */
/* [fpp_fw_features_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(2)
{
    uint16 action;                       /*< Action */
    char name[FPP_FEATURE_NAME_SIZE + 1];  /*< Feature name. [ro] */
    char desc[FPP_FEATURE_DESC_SIZE + 1];  /*< Feature description. [ro] */

    uint8 val;        /*< Feature current state.
                            0 == disabled ; 1 == enabled */

    fpp_fw_feature_flags_t flags;  /*< Feature configuration variant. [ro] */
    uint8 def_val;               /*< Factory default value of the '.val' property. [ro] */
    uint8 reserved;              /*< RESERVED (do not use) */
} fpp_fw_features_cmd_t;
/* [fpp_fw_features_cmd_t] */

#define FPP_CMD_FW_FEATURE_ELEMENT                  (0xf260)
#define FPP_ERR_FW_FEATURE_ELEMENT_NOT_FOUND        (0xf261)
#define FPP_ERR_FW_FEATURE_ELEMENT_READ_ONLY        (0xf262)

enum CAL_PACKED
{
    FW_FEATURE_ELEMENT_DEFAUT = 0U,
    FW_FEATURE_ELEMENT_CONFIG = 1U,
    FW_FEATURE_ELEMENT_STATS = 2U
};

/* [fpp_fw_feature_element_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;                                 /*< Action */
    char fw_feature_name[FPP_FEATURE_NAME_SIZE + 1]; /*< Name of a fw feature (see fpp_fw_features_cmd_t) */
    char element_name[FPP_FEATURE_NAME_SIZE + 1];    /*< Name of the fw feature's target element */
    uint8 group; /*< Element group
                                             0 == ANY ; No group specified. Special value, intended only for FPP_ACTION_QUERY.
                                                        FPP_ACTION_QUERY command with EMPTY element_name[] and with this group starts
                                                        a QUERY/QUERY_CONT process that will successively report all elements of 
                                                        the parent fw feature (regardless of their element group).
                                             1 == CFG  ;Configuration group. Command with this group can target only some configuration element.
                                                        FPP_ACTION_QUERY command with EMPTY element_name[] and with this group starts
                                                        a QUERY/QUERY_CONT process that will successively report all configuration elements of 
                                                        the parent fw feature.
                                             2 == STATS ; Statistics group. Command with this group can target only some statistics element.
                                                        FPP_ACTION_QUERY command with EMPTY element_name[] and with this group starts
                                                        a QUERY/QUERY_CONT process that will successively report all statistics elements of 
                                                        the parent fw feature. */

    uint8 unit_size;     /*< Byte size of element's data unit.
                               Data unit exact size (and underlying data type) is feature and element specific.
                               See appropriate documentation of fw feature elements. */
    uint8 index;         /*< Index into element's data (as laid out in PFE firmware) which correspond with the first data unit in the .payload */
    uint8 count;         /*< Count of consecutive data units in the .payload */
    uint8 payload[128];  /*< Data (composed of one or more data units). */
} fpp_fw_features_element_cmd_t;
/* [fpp_fw_feature_element_cmd_t] */

/**
 * @def         FPP_CMD_FCI_OWNERSHIP_LOCK
 * @brief       FCI command to get FCI ownership.
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FCI_OWNERSHIP_LOCK, 0, NULL);
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED <br>
 *        The client is not authorized get FCI ownership.
 * - @c FPP_ERR_FCI_OWNERSHIP_ALREADY_LOCKED <br>
 *        The FCI ownership is already held by other client.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_FCI_OWNERSHIP_LOCK  0xf500U

/**
 * @def         FPP_CMD_FCI_OWNERSHIP_UNLOCK
 * @brief       FCI command to release FCI ownership.
 * @details     Supported `.action` values: ---
 * <br>
 * @code{.c}
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_FCI_OWNERSHIP_UNLOCK, 0, NULL);
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_FCI_OWNERSHIP_NOT_OWNER <br>
 *        The client is not FCI owner.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_FCI_OWNERSHIP_UNLOCK  0xf501U

/**
 * @def         FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED
 * @hideinitializer
 */
#define FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED  0xf502

/**
 * @def         FPP_ERR_FCI_OWNERSHIP_ALREADY_LOCKED
 * @hideinitializer
 */
#define FPP_ERR_FCI_OWNERSHIP_ALREADY_LOCKED  0xf503

/**
 * @def         FPP_ERR_FCI_OWNERSHIP_NOT_OWNER
 * @hideinitializer
 */
#define FPP_ERR_FCI_OWNERSHIP_NOT_OWNER 0xf504

/**
 * @def         FPP_ERR_FCI_OWNERSHIP_NOT_ENABLED
 * @hideinitializer
 */
#define FPP_ERR_FCI_OWNERSHIP_NOT_ENABLED 0xf505

/**
 * @def FPP_CMD_HEALTH_MONITOR_EVENT
 * @brief FCI event that notifies client about some Health Monitor event from driver.
 */
#define FPP_CMD_HEALTH_MONITOR_EVENT    0xf660
#define FPP_HEALTH_MONITOR_DESC_SIZE    64

/**
 * @brief       Data structure for Health Monitor event.
 * @details     For details about events (exact meaning of ID, type and src), see Health Monitor documentation.
 */
/* [fpp_health_monitor_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(2)
{
    uint16 action;
    uint16 id;     /*< Event ID as reported by Health Monitor. */
    uint8 type;    /*< 0 == information ; 1 == warning ; 2 == error */
    uint8 src;     /*< Source (which part of PFE asserted the event) */
    char desc[FPP_HEALTH_MONITOR_DESC_SIZE];  /*< Event description */
} fpp_health_monitor_cmd_t;
/* [fpp_health_monitor_cmd_t] */

/**
 * @def         FPP_CMD_TIMER_LOCK
 * @brief       FCI command to set FCI timer ownership.
 * @details     Related data types: @ref fpp_timer_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Set timer ownership for the client.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Set timer ownership for the client. 
 * @code{.c}
 *  .............................................
 *  fpp_timer_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *    .name   = "...",              // Physical interface name
 *  };
 * 
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_TIMER_LOCK, sizeof(fpp_timer_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_ENTRY_NOT_FOUND <br>
 *        Unknown (nonexistent) physical interface was requested.
 * - @c FPP_ERR_IF_NOT_SUPPORTED <br>
 *        Requested physical interface does not support setting timer ownership.
 * - @c FPP_ERR_TIMER_ALREADY_LOCKED <br>
 *        The FCI timer ownership is already held by other client.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_TIMER_LOCK            0xf520

/**
 * @def         FPP_CMD_TIMER_UNLOCK
 * @brief       FCI command to release FCI timer ownership.
 * @details     Related data types: @ref fpp_timer_cmd_t
 * @details     Supported `.action` values:
 *              - @c FPP_ACTION_UPDATE <br>
 *                   Release timer ownership for the client.
 *
 * FPP_ACTION_UPDATE
 * -----------------
 * Release timer ownership for the client. 
 * @code{.c}
 *  .............................................
 *  fpp_timer_cmd_t cmd_to_fci =
 *  {
 *    .action = FPP_ACTION_UPDATE,  // Action
 *    .name   = "...",              // Physical interface name
 *  };
 * 
 *  .............................................
 *  int rtn = 0;
 *  rtn = fci_write(client, FPP_CMD_TIMER_UNLOCK, sizeof(fpp_timer_cmd_t),
 *                                         (unsigned short*)(&cmd_to_fci));
 *  .............................................
 * @endcode
 *
 * Command return values
 * ---------------------
 * - @c FPP_ERR_OK <br>
 *        Success
 * - @c FPP_ERR_IF_ENTRY_NOT_FOUND <br>
 *        Unknown (nonexistent) physical interface was requested.
 * - @c FPP_ERR_IF_NOT_SUPPORTED <br>
 *        Requested physical interface does not support setting timer ownership.
 * - @c FPP_ERR_TIMER_NOT_OWNER <br>
 *        The client is not FCI timer owner.
 * - @c FPP_ERR_INTERNAL_FAILURE <br>
 *        Internal FCI failure.
 *
 * @hideinitializer
 */
#define FPP_CMD_TIMER_UNLOCK          0xf521

/**
 * @def         FPP_ERR_TIMER_ALREADY_LOCKED
 * @hideinitializer
 */
#define FPP_ERR_TIMER_ALREADY_LOCKED  0xf523

/**
 * @def         FPP_ERR_TIMER_NOT_OWNER
 * @hideinitializer
 */
#define FPP_ERR_TIMER_NOT_OWNER       0xf524

/* [fpp_timer_cmd_t] */
typedef struct CAL_PACKED_ALIGNED(4)
{
    uint16 action;            /*< Action */
    char if_name[IFNAMSIZ];     /*< Physical interface name. */
    uint32 reserved;          /*< RESERVED (do not use) */
} fpp_timer_cmd_t;
/* [fpp_timer_cmd_t] */

#endif /* FPP_EXT_H_ */

/** @}*/


===== 文件 [23/185]: include\hal.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @defgroup    dxgrHAL HAL
 * @brief       The HW Abstraction Layer
 * @details
 *
 *
 * @addtogroup  dxgrHAL
 * @{
 *
 * @file        hal.h
 * @brief       The main HAL header file
 * @details     Use this header to include all the HAL-provided functionality
 *
 */

#ifndef HAL_H_
#define HAL_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_cfg.h"
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    /* Required only for hal_ip_ready API */
    #include "oal_types.h"
    #if (TRUE == PFE_CFG_SHARED_REG_VIA_MCU)
        #include "Mcu.h"
    #else
        #define PFE_IP_READY_CTRL_REG   ((uint32_t*)0x4007CAECU)
        #define CTRL_REG_LEN            4U
        #define BIT_IP_READY            16U
        #define IP_READY                ((uint32)1U << BIT_IP_READY)
    #endif
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#if defined(GHS)
    #define hal_nop()       __asm(" nop")
#else /* GCC and DIAB */
    #define hal_nop()       __asm__ volatile("nop" ::: "memory")
#endif

/*  AXI writes immediately followed by an AXI read, cause writes to be lost,
    as a workaround, add a hal_nop after each write */
#define hal_write32(val, addr) \
                            do {    \
                                (*(volatile uint32 *)(addr) = ((uint32)(val))); \
                            } while (0!=0)

#define hal_write16(val, addr) \
                            do {    \
                                    (*(volatile uint16 *)(addr) = ((uint16)(val))); \
                            } while (0!=0)

#define hal_write8(val, addr) \
                            do {    \
                                    (*(volatile uint8 *)(addr) = ((uint8)(val)));   \
                            } while (0!=0)

#define hal_read32(addr)    (*(volatile uint32 *)(addr))
#define hal_read16(addr)    (*(volatile uint16 *)(addr))
#define hal_read8(addr)     (*(volatile uint8 *)(addr))

#define ADDR_BASE_OFFSET(BASE,OFFS) (addr_t)(((uint64)(BASE)+(OFFS)) & UINT32_MAX)
#define OFFSET_ADDR_BASE(ADDR,BASE) (uint32)(((uint64)(ADDR)+UINT32_MAX+1U-(BASE)) & UINT32_MAX)

#ifndef likely
    #if defined(__ghs__) || defined(__DCC__)
        #define likely(x)   (x)
    #else
        #define likely(x)   __builtin_expect(!!(x),1)
    #endif

#endif

#ifndef unlikely
    #if defined(__ghs__) || defined(__DCC__)
        #define unlikely(x) (x)
    #else
        #define unlikely(x) __builtin_expect(!!(x),0)
    #endif
#endif

#if defined(__ghs__) || defined(__DCC__)
    #if defined(PFE_CFG_TARGET_ARCH_aarch64le) || defined(PFE_CFG_TARGET_ARCH_armv7le)
        #define hal_wmb()   __asm(" dmb oshst")
    #else
        #error Unsupported or no platform defined
    #endif
#else
    #if defined(PFE_CFG_TARGET_ARCH_aarch64le)
        #define hal_wmb()   __asm__ __volatile__(" dmb oshst" : : : "memory")
    #elif defined(PFE_CFG_TARGET_ARCH_x86) || defined(PFE_CFG_TARGET_ARCH_x86_64)
        #define hal_wmb()   asm volatile("sfence" ::: "memory")
    #elif defined(PFE_CFG_TARGET_ARCH_aarch64)
        #define hal_wmb()           smp_wmb()
    #elif defined(PFE_CFG_TARGET_ARCH_armv7le)
        #define hal_wmb()   __asm__ __volatile__(" dmb":::"memory")
    #else
        #error Unsupported or no platform defined
    #endif
#endif

/**
 * @brief   Specify cache line size in number of bytes.
 */
#define HAL_CACHE_LINE_SIZE 64U

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief   Set IP-ready flag for Master-Slave signalization
 * @warning We hijacked GPR:GENCTRL3 register for this purpose, using 16 higher bits,
 *          low 16 bits remains untouched for security reason
 */
__attribute__((unused)) static void hal_ip_ready_set(bool_t on)
{
    uint32 val;

#if (TRUE == PFE_CFG_SHARED_REG_VIA_MCU)
    val = (TRUE == on) ? 1U : 0U;
    Mcu_SetSharedIpSetting(SHARED_SETTINGS_IP_S32G_GPR_PFE_GENCTRL3_REG_ID, val);
    Mcu_TriggerHardwareUpdate();
#else
    val = hal_read32(PFE_IP_READY_CTRL_REG);
    if (TRUE == on)
    {
        val |= IP_READY;
    }
    else
    {
        val &= ~IP_READY;
    }
    hal_write32(val, PFE_IP_READY_CTRL_REG);
#endif
}

/**
 * @brief Return status of IP-ready flag
 * @return True if IP-ready
 */
__attribute__((unused)) static bool_t hal_ip_ready_get(void)
{
    uint32 val;

#if (TRUE == PFE_CFG_SHARED_REG_VIA_MCU)
    val = Mcu_GetSharedIpSetting(SHARED_SETTINGS_IP_S32G_GPR_PFE_GENCTRL3_REG_ID);
#else
    val = hal_read32(PFE_IP_READY_CTRL_REG);
    val &= IP_READY;
#endif
    return (0U != val);
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#endif /* HAL_H_ */

/** @}*/


===== 文件 [24/185]: include\isa.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2022-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef SRC_ISA_H_
#define SRC_ISA_H_


/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


/**
 * @brief ISA index type
 * Limiting number of items ISA may contain
 * uint8 256 items max.
 * uint16 65536 item max.
 */
typedef uint16 pfe_isa_index_t;

/**
 * @brief ISA index/item array properties
 */
typedef struct
{
    /* ISA capacity */
    uint32 item_count;
    /* sizeof(item_t) item array single entry size */
    uint32 item_size;
    struct
    {
        /* =ISA_FLAG_STRICT_ORDER preserve insert time defined ordering
         * when =ISA_FLAG_STRICT_ORDER isa_liberate has complexity O(n)
         * when =ISA_FLAG_ANY_ORDER isa_liberate has complexity O(1)
         */
        uint8 ordered : 1;
    } flags;
    /* index array
     * layout:
     * occupied subscripts: <0, occupied_items_count - 1> if occupied_items_count > 0
     * vacant subscripts:   <occupied_items_count, total_items_count - 1>
     */
    pfe_isa_index_t *item_indexes;
    /* data item array */
    void *items;
} pfe_isa_definition_t;

/* see explanation for flags.keep_in_order */
#define ISA_FLAG_ANY_ORDER 0U
#define ISA_FLAG_STRICT_ORDER 1U

/**
 * @brief ISA context representation
 */
typedef struct
{
    /* total items count currently occupied in item array */
    uint32 occupied_items_count;
    /* items array properties managed by ISA */
    const pfe_isa_definition_t *props;

} pfe_isa_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

void isa_init(pfe_isa_t *isa, const pfe_isa_definition_t *props);
void isa_clear(pfe_isa_t *isa);
void *isa_item(const pfe_isa_t *isa, uint32 index_subscript);
void *isa_reserve(pfe_isa_t *isa);
bool_t isa_release_subscript(pfe_isa_t *isa, uint32 index_subscript);
sint32 isa_release(pfe_isa_t *isa, const void *item);
bool_t isa_isempty(const pfe_isa_t *isa);
uint32 isa_occupiedcount(const pfe_isa_t *isa);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* isa_release return value for case if item not found in the ISA */
#define ISA_ITEM_NOT_FOUND (-1)

#endif /* SRC_ISA_H_ */


===== 文件 [25/185]: include\libfci.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright (C) 2007 Mindspeed Technologies, Inc.
 *  Copyright 2015-2016 Freescale Semiconductor, Inc.
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @defgroup    dxgrLibFCI  LibFCI
 * @brief       This is Fast Control Interface available for host applications to
 *              communicate with the networking engine.
 * @details     The FCI is intended to provide a generic configuration and monitoring interface
 *              for the networking acceleration HW. Provided API shall remain the same within all
 *              HW/OS-specific implementations to keep dependent applications portable across
 *              various systems.
 *
 *              The LibFCI is not directly touching the HW. Instead, it only passes commands to
 *              a dedicated software component (OS/HW-specific endpoint) and receives return values.
 *              The endpoint is then responsible for HW configuration. This approach supports
 *              a kernel-user space deployment where the user space contains only API and the logic is
 *              implemented in kernel.
 *
 *              Implementation uses appropriate transport mechanism to pass data between
 *              LibFCI user and the endpoint. For reference: in Linux a netlink socket is used;
 *              in QNX a message is used.
 *
 * @section     how_to_use  How to use the FCI API
 * @subsection  fciuse_cmd  Sending FCI commands
 *              -# Call @ref fci_open() to get an @ref FCI_CLIENT instance, using @ref FCI_GROUP_NONE
 *                 as a multicast group mask. This opens a connection to an FCI endpoint.
 *              -# Call @ref fci_write() or @ref fci_query() to send a command to the endpoint. <br> See @ref fci_cs.
 *                 - Endpoint receives the command and executes requested actions.
 *                 - Endpoint generates a response and sends it back to the client.
 *              -# [optional] Repeat the previous step to send all requested FCI commands.
 *              -# Call @ref fci_close() to finalize the @ref FCI_CLIENT instance.
 * @subsection  fci_owner  FCI ownership in Master-Slave setup
 *              The FCI ownership applies only to PFE driver Master-Slave setup. This feature ensures that at any given time
 *              there is only one driver instance which can successfully issue FCI commands.
 *              Configuration of FCI Ownership is stored in the Master instance. The configuration specifies
 *              which driver instances are allowed to acquire FCI ownership.
 *
 *              There can be only one FCI owner at a time. Only the FCI commands issued by the FCI
 *              owner can be executed successfully. FCI commands issued by a driver instance which
 *              does not have FCI ownership are never executed and return an error code instead.
 *              Driver instance can acquire or release the FCI ownership via the following means:
 *                 - <b>Manually</b>, by requesting the FCI ownership via dedicated FCI commands
 *              @ref FPP_CMD_FCI_OWNERSHIP_LOCK and @ref FPP_CMD_FCI_OWNERSHIP_UNLOCK.
 *              If the ownership is acquired manually, it has to be manually released as well
 *              (responsibility of the requesting driver).
 *                 - <b>Automatically</b>, by acquiring floating FCI ownership if it is not held at the moment by
 *              other client. The floating FCI ownership is granted temporarily for each issued FCI
 *              command. Once the execution of the respective FCI command is finished, the FCI
 *              ownership is automatically released, so other sender can take FCI ownership.
 *
 * @if INCLUDE_ASYNC_DESC
 * @subsection  fciuse_msg  Asynchronous message processing
 *              -# User calls @ref fci_open() to get the @ref FCI_CLIENT instance. It is
 *                 important to set @ref FCI_GROUP_CATCH bit in multicast group mask.
 *              -# User calls @ref fci_register_cb() to register custom function for handling
 *                 asynchronous messages from PFE.
 *              -# User calls @ref fci_catch() function.
 *              -# For each received message, the @ref fci_catch() calls previously registered
 *                 callback.
 *              -# When the callback returns @ref FCI_CB_CONTINUE, the @ref fci_catch() function
 *                 waits for another message.
 *              -# When the callback returns @ref FCI_CB_STOP or when error occurred,
 *                 function @ref fci_catch() returns.
 *              -# User calls fci_close() to finalize the @ref FCI_CLIENT instance.
 * @endif
 *
 * @section     a_and_d  Acronyms and Definitions
 *              - <b>PFE:</b> <br>
 *                Packet Forwarding Engine. A dedicated HW component (networking accelerator)
 *                which is configured by this FCI API.
 *              - <b>NBO:</b> <br>
 *                Network Byte Order. When working with values or properties which are stored in [NBO],
 *                consider using appropriate endianess conversion functions.
 *              - <b>L2/L3/L4:</b> <br>
 *                Layers of the OSI model.
 *              - <b>Physical Interface:</b> <br>
 *                See @ref mgmt_phyif.
 *              - <b>Logical Interface:</b> <br>
 *                See @ref mgmt_logif.
 *              - <b>Classification Algorithm:</b> <br>
 *                Method how ingress traffic is processed by the PFE firmware.
 *              - <b>Route:</b> <br> @anchor ref__route
 *                In the context of PFE, a route represents a direction where the matching
 *                traffic shall be forwarded to. Every route specifies an egress physical interface
 *                and a MAC address of the next network node.
 *              - <b>Conntrack:</b> <br> @anchor ref__conntrack
 *                "Tracked connection", a data structure with information about a connection.
 *                In the context of PFE, it always refers to an IP connection (TCP, UDP, other).
 *                The term is equal to a 'routing table entry'. Each conntrack is linked with some @b route.
 *                The route is used to forward traffic that matches the conntrack's properties.
 *              - <b>RSPAN:</b> <br>
 *                Remote Switch port Analyzer. A way of monitoring traffic via traffic mirroring between ports.
 *                In the context of PFE, this refers to traffic mirroring between physical interfaces.
 *                See chapter @ref mgmt_phyif and its subchapter @link ref__mirroring_rules_mgmt Mirroring rules management @endlink.
 *
 * @section     lfs  Functions Summary
 *              - @ref fci_open() <br>
 *                <i>Connect to endpoint and create a client instance.</i>
 *              - @ref fci_close() <br>
 *                <i>Close a connection to endpoint and destroy the client instance.</i>
 *              - @ref fci_write() <br>
 *                <i>Execute FCI command without data response.</i>
 *              - @ref fci_cmd() <br>
 *                <i>Execute FCI command with data response.</i>
 *              - @ref fci_query() <br>
 *                <i>Alternative to @ref fci_cmd().</i>
 *              - @ref fci_catch() <br>
 *                <i>Poll for and process received asynchronous messages.</i>
 *              - @ref fci_register_cb() <br>
 *                <i>Register a callback to be called in case of a received message.</i>
 *
 * @section     fci_cs  Commands Summary
 *              - @ref FPP_CMD_PHY_IF <br>
 *                <i>Management of physical interfaces.</i>
 *              - @ref FPP_CMD_LOG_IF <br>
 *                <i>Management of logical interfaces.</i>
 *              - @ref FPP_CMD_IF_LOCK_SESSION <br>
 *                <i>Get exclusive access to interface database.</i>
 *              - @ref FPP_CMD_IF_UNLOCK_SESSION <br>
 *                <i>Cancel exclusive access to interface database.</i>
 *              - @ref FPP_CMD_IF_MAC <br>
 *                <i>Management of interface MAC addresses.</i>
 *              - @ref FPP_CMD_MIRROR <br>
 *                <i>Management of interface mirroring rules.</i>
 *              - @ref FPP_CMD_L2_BD <br>
 *                <i>Management of L2 bridge domains.</i>
 *              - @ref FPP_CMD_L2_STATIC_ENT <br>
 *                <i>Management of L2 static entries.</i>
 *              - @ref FPP_CMD_L2_FLUSH_LEARNED <br>
 *                <i>Remove all dynamically learned MAC table entries.</i>
 *              - @ref FPP_CMD_L2_FLUSH_STATIC <br>
 *                <i>Remove all static MAC table entries.</i>
 *              - @ref FPP_CMD_L2_FLUSH_ALL <br>
 *                <i>Remove all MAC table entries.</i>
 *              - @ref FPP_CMD_FP_TABLE <br>
 *                <i>Management of @ref flex_parser tables.</i>
 *              - @ref FPP_CMD_FP_RULE <br>
 *                <i>Management of @ref flex_parser rules.</i>
 *              - @ref FPP_CMD_IPV4_RESET <br>
 *                <i>Remove all IPv4 routes and conntracks.</i>
 *              - @ref FPP_CMD_IPV6_RESET <br>
 *                <i>Remove all IPv6 routes and conntracks.</i>
 *              - @ref FPP_CMD_IP_ROUTE <br>
 *                <i>Management of IP routes.</i>
 *              - @ref FPP_CMD_IPV4_CONNTRACK <br>
 *                <i>Management of IPv4 conntracks.</i>
 *              - @ref FPP_CMD_IPV6_CONNTRACK <br>
 *                <i>Management of IPv6 conntracks.</i>
 *              - @ref FPP_CMD_IPV4_SET_TIMEOUT <br>
 *                <i>Configuration of conntrack timeouts.</i>
 *              - @ref FPP_CMD_DATA_BUF_PUT <br>
 *                <i>Send arbitrary data to the accelerator.</i>
 *              - @ref FPP_CMD_SPD <br>
 *                <i>Management of the IPsec offload.</i>
 *              - @ref FPP_CMD_QOS_QUEUE <br>
 *                <i>Management of @ref egress_qos queues.</i>
 *              - @ref FPP_CMD_QOS_SCHEDULER <br>
 *                <i>Management of @ref egress_qos schedulers.</i>
 *              - @ref FPP_CMD_QOS_SHAPER <br>
 *                <i>Management of @ref egress_qos shapers.</i>
 *              - @ref FPP_CMD_QOS_POLICER <br>
 *                <i>@ref ingress_qos policer enable/disable.</i>
 *              - @ref FPP_CMD_QOS_POLICER_FLOW <br>
 *                <i>Management of @ref ingress_qos packet flows.</i>
 *              - @ref FPP_CMD_QOS_POLICER_WRED <br>
 *                <i>Management of @ref ingress_qos WRED queues.</i>
 *              - @ref FPP_CMD_QOS_POLICER_SHP <br>
 *                <i>Management of @ref ingress_qos shapers.</i>
 *              - @ref FPP_CMD_FCI_OWNERSHIP_LOCK <br>
 *                <i>Management of @ref fci_owner.</i>
 *              - @ref FPP_CMD_FCI_OWNERSHIP_UNLOCK <br>
 *                <i>Management of @ref fci_owner.</i>
 *
 * @section     cbks  Events summary
 * @if FCI_EVENTS_IMPLEMENTED
 *              - @ref FPP_CMD_IPV4_CONNTRACK_CHANGE <br>
 *                <i>Endpoint reports events related to IPv4 conntracks.</i>
 *              - @ref FPP_CMD_IPV6_CONNTRACK_CHANGE <br>
 *                <i>Endpoint reports events related to IPv6 conntracks.</i>
 * @endif
 *              - @ref FPP_CMD_DATA_BUF_AVAIL <br>
 *                <i>Network accelerator sends a data buffer to a host.</i>
 *
 * @section     if_mgmt  Interface Management
 * @subsection  mgmt_phyif  Physical Interface
 *              Physical interfaces are static objects (defined at startup), which represent hardware
 *              interfaces of PFE. They are used by PFE for ingress/egress of network traffic.
 *
 *              Physical interfaces have several configurable properties. See @ref FPP_CMD_PHY_IF
 *              and @ref fpp_phy_if_cmd_t. Among all these properties, a `.mode` property
 *              is especially important. Mode of a physical interface specifies which classification
 *              algorithm shall be applied on ingress traffic of the interface.
 *
 *              Every physical interface can have a list of logical interfaces.
 *              By default, all physical interfaces are in a default mode (@ref FPP_IF_OP_DEFAULT).
 *              In the default mode, ingress traffic of a given physical interface is processed using
 *              only the associated @b default @ref mgmt_logif.
 *
 *              <br>
 *              Supported FCI operations related to physical interfaces:
 *
 *              To @b list available physical interfaces:
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Read out properties of physical interface(s).
 *                 <br> (@ref FPP_CMD_PHY_IF + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              To @b modify properties of a physical interface (read-modify-write):
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Read out properties of the target physical interface.
 *                 <br> (@ref FPP_CMD_PHY_IF + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              -# Locally modify the properties. See fpp_phy_if_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_PHY_IF + FPP_ACTION_UPDATE)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              <br><br>
 *              Hardcoded physical interface names and physical interface IDs:
 *              | name     | ID | comment                                                |
 *              | -------- | -- | ------------------------------------------------------ |
 *              | emac0    | 0  | Representation of real physical ports connected to PFE.
 *              | emac1    | 1  | ^
 *              | emac2    | 2  | ^
 *              | ---      | -- | ---reserved---
 *              | util     | 5  | Special internal port for communication with the util firmware. <br> (fully functional only with the PREMIUM firmware)
 *              | hif0     | 6  | Host Interfaces. Used for traffic forwarding between PFE and a host.
 *              | hif1     | 7  | ^
 *              | hif2     | 8  | ^
 *              | hif3     | 9  | ^
 *
 *              MAC address management
 *              ----------------------
 *              @b Emac physical interfaces can have multiple MAC addresses. This can be used
 *              for MAC address filtering - emac physical interfaces can be configured to accept traffic
 *              intended for several different recipients (several different destination MAC addresses).
 *
 *              To @b add a new MAC address to emac physical interface:
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Add a new MAC address to emac physical interface.
 *                 <br> (@ref FPP_CMD_IF_MAC + FPP_ACTION_REGISTER)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              To @b remove a MAC address from emac physical interface:
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Remove the MAC address from emac physical interface.
 *                 <br> (@ref FPP_CMD_IF_MAC + FPP_ACTION_DEREGISTER)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              To @b list MAC addresses of emac physical interface:
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Read out MAC address(es) of the target emac physical interface.
 *                 <br> (@ref FPP_CMD_IF_MAC + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              Mirroring rules management @anchor ref__mirroring_rules_mgmt
 *              --------------------------
 *              Physical interfaces can be configured to mirror their ingress or egress traffic.
 *              Configuration data for mirroring are managed as separate entities - mirroring rules.
 *
 *              To @b create a new mirroring rule:
 *              <br> (@ref FPP_CMD_MIRROR + FPP_ACTION_REGISTER)
 *
 *              To @b assign a mirroring rule to a physical interface:
 *              <br> Write name of the desired mirror rule in `.rx_mirrors[i]` or `.tx_mirrors[i]` property
 *                   of the physical interface. Use steps described in @ref mgmt_phyif, section @b modify.
 *
 *              To @b update a mirroring rule:
 *              <br> (@ref FPP_CMD_MIRROR + FPP_ACTION_UPDATE)
 *
 *              To @b list available mirroring rules:
 *              <br> (@ref FPP_CMD_MIRROR + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *
 *              Examples
 *              --------
 *              @ref demo_feature_physical_interface.c
 *
 * @subsection  mgmt_logif  Logical Interface
 *              Logical interfaces are dynamic objects (definable at runtime) which represent traffic endpoints.
 *              They are associated with their respective parent physical interfaces. Logical interfaces
 *              can be used for the following purposes:
 *              - To forward traffic from PFE to a host.
 *              - To forward traffic or its replicas between physical interfaces (1:N distribution).
 *              - To serve as classification & forwarding rules for @ref flex_router.
 *
 *              Logical interfaces have several configurable properties. See @ref FPP_CMD_LOG_IF
 *              and @ref fpp_log_if_cmd_t.
 *
 *              Logical interfaces can be created and destroyed at runtime. Every @e physical interface
 *              can have a list of associated @e logical interfaces. The very first logical interface
 *              in the list (tail position) is considered the @b default logical interface of the given
 *              physical interface. New logical interfaces are always added to the top of the list (head position),
 *              creating a sequence which is ordered from the head (the newest one) back to the tail (the default one).
 *              This forms a classification sequence, which is important if the parent physical interface
 *              operates in the Flexible Router mode.
 *
 *              Similar to physical interfaces, the logical interfaces can be set to a @b promiscuous mode.
 *              For logical interfaces, a promiscuous mode means a logical interface will accept all
 *              ingress traffic it is asked to classify, regardless of the interface's active match rules.
 *
 *              <br>
 *              Supported operations related to logical interfaces:
 *
 *              To @b create a new logical interface in PFE:
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Create a new logical interface.
 *                 <br> (@ref FPP_CMD_LOG_IF + FPP_ACTION_REGISTER)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              To @b remove a logical interface from PFE:
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Remove the logical interface.
 *                 <br> (@ref FPP_CMD_LOG_IF + FPP_ACTION_DEREGISTER)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              To @b list available logical interfaces:
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Read out properties of logical interface(s).
 *                 <br> (@ref FPP_CMD_LOG_IF + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 *              To @b modify properties of a logical interface (read-modify-write):
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Read out properties of the target logical interface.
 *                 <br> (@ref FPP_CMD_LOG_IF + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              -# Locally modify the properties. See fpp_log_if_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_LOG_IF + FPP_ACTION_UPDATE)
 *              -# Unlock the interface database.
 *                 <br> (@ref FPP_CMD_IF_UNLOCK_SESSION)
 *
 * @section     features  Features
 * @subsection  l3_router  IPv4/IPv6 Router (TCP/UDP)
 *              Introduction
 *              ------------
 *              IPv4/IPv6 Router is a dedicated feature to offload a host from tasks
 *              related to forwarding of specific IP packets between physical interfaces.
 *              Without the offload, IP packets are passed to the host's TCP/IP stack and
 *              the host is responsible for routing of packets. That is "slow path" routing.
 *              PFE can be configured to provide "fast path" routing, identifying IP packets
 *              which can be forwarded directly by PFE (using its internal routing table)
 *              without host intervention.
 *
 *              Configuration
 *              -------------
 *              -# [optional] Reset the Router.
 *                 <br> This clears all existing IPv4/IPv6 routes and conntracks in PFE.
 *                 <br> (@ref FPP_CMD_IPV4_RESET)
 *                 <br> (@ref FPP_CMD_IPV6_RESET)
 *              -# Create one or more IPv4/IPv6 routes.
 *                 <br> (@ref FPP_CMD_IP_ROUTE + FPP_ACTION_REGISTER)
 *              -# Create one or more IPv4/IPv6 conntracks.
 *                 <br> (@ref FPP_CMD_IPV4_CONNTRACK + FPP_ACTION_REGISTER)
 *                 <br> (@ref FPP_CMD_IPV6_CONNTRACK + FPP_ACTION_REGISTER)
 *              -# Configure the physical interfaces which shall classify their ingress traffic
 *                 by the Router classification algorithm. Use steps described in
 *                 @ref mgmt_phyif (section @b modify) and do the following for each desired physical interface:
 *                 - Set mode of the interface to @ref FPP_IF_OP_ROUTER.
 *                 - Enable the interface by setting the flag @ref FPP_IF_ENABLED.
 *
 *              Once the Router is operational, all ingress IP packets of the Router-configured physical
 *              interfaces are matched against existing conntracks using a 5-tuple match (protocol, source IP,
 *              destination IP, source port, destination port). If a packet matches some existing conntrack,
 *              it is processed and modified according to conntrack's properties (destination MAC, NAT, PAT, etc.)
 *              and then gets fast-forwarded to an egress physical interface as specified by the conntrack's route.
 *
 *              Additional operations
 *              ---------------------
 *              Conntracks are subjected to aging. If no matching packets are detected on a conntrack
 *              for a specified time period, the conntrack is automatically removed from PFE.
 *              To @b set the @b timeout period, use the following command (shared for both
 *              IPv4 and IPv6 conntracks):
 *              <br> (@ref FPP_CMD_IPV4_SET_TIMEOUT)
 *
 *              <br>
 *              To @b remove a route or a conntrack:
 *              - (@ref FPP_CMD_IP_ROUTE + FPP_ACTION_DEREGISTER)
 *              - (@ref FPP_CMD_IPV4_CONNTRACK + FPP_ACTION_DEREGISTER)
 *              - (@ref FPP_CMD_IPV6_CONNTRACK + FPP_ACTION_DEREGISTER)
 *
 *              <small>
 *              Note: <br>
 *              Removing a route which is used by some conntracks causes the associated connntracks
 *              to be removed as well.
 *              </small> <br>
 *
 *              To @b list available routes or conntracks:
 *              - (@ref FPP_CMD_IP_ROUTE + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              - (@ref FPP_CMD_IPV4_CONNTRACK + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              - (@ref FPP_CMD_IPV6_CONNTRACK + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *
 *              By default, PFE conntracks decrement TTL of processed IP packets. This behavior can be
 *              set/unset for individual conntracks by their flag @ref CTCMD_FLAGS_TTL_DECREMENT.
 *              To @b modify an already existing conntrack:
 *              - (@ref FPP_CMD_IPV4_CONNTRACK + FPP_ACTION_UPDATE)
 *              - (@ref FPP_CMD_IPV6_CONNTRACK + FPP_ACTION_UPDATE)
 *
 *              Examples
 *              --------
 *              @ref demo_feature_router_simple.c, @ref demo_feature_router_nat.c
 *
 * @subsection  l2_bridge  L2 Bridge (Switch)
 *              Introduction
 *              ------------
 *              L2 Bridge is a dedicated feature to offload a host from tasks related
 *              to MAC address-based forwarding of Ethernet frames. PFE can be configured
 *              to act as a network switch, implementing the following functionality:
 *              - <b>MAC table:</b>
 *                L2 Bridge uses its own MAC table to keep track of encountered MAC addresses.
 *                Each MAC table entry consists of a MAC address and a physical interface
 *                which should be used to reach the given MAC address. MAC table entries can
 *                be dynamic (learned) or static.
 *              - <b>MAC address learning:</b>
 *                L2 Bridge is capable of automatically adding (learning) new MAC table entries from
 *                ingress frames with new (not yet encountered) source MAC addresses.
 *              - <b>Aging:</b>
 *                MAC table entries are subjected to aging. If a MAC table entry is not used for
 *                a certain (hardcoded) time period, it is automatically removed from the MAC table.
 *                Static entries are not affected by aging.
 *              - <b>Static entries:</b>
 *                It is possible to manually add static (non-aging) entries to the MAC table.
 *                Static entries can be used as a part of L2 Bridge forward-only configuration
 *                (with MAC learning disabled). With such a setup, only a predetermined
 *                traffic (matching the static entries) will be forwarded.
 *              - <b>Blocking states of physical interfaces:</b>
 *                Each physical interface which is configured to be a part of the L2 Bridge can
 *                be finetuned to allow/deny MAC learning or frame forwarding of its ingress traffic.
 *                See @ref fpp_phy_if_block_state_t.
 *              - <b>Port migration:</b>
 *                If there is already a learned MAC table entry (a MAC address + a target physical interface)
 *                and the MAC address is detected on another interface, then the entry is automatically
 *                updated (new target physical interface is set).
 *              - <b>VLAN Awareness:</b>
 *                The L2 Bridge uses its own VLAN table to support VLAN-based policies
 *                like Ingress or Egress port membership. It also supports configuration of bridge
 *                domain ports (represented by physical interfaces) to provide VLAN tagging and
 *                untagging services, effectively allowing creation of access / trunk ports.
 *
 *              The L2 Bridge utilizes PFE HW accelerators to perform highly optimized MAC and VLAN
 *              table lookups. Host is responsible only for the initial bridge configuration via
 *              the FCI API.
 *
 *              L2 Bridge VLAN Awareness and Domains
 *              ------------------------------------
 *              The VLAN awareness is based on entities called Bridge Domains (BD), which are visible to
 *              both the classifier firmware and the driver. BDs are used to abstract particular VLANs.
 *              Every BD has a configurable set of properties (see @ref fpp_l2_bd_cmd_t):
 *              - Associated VLAN ID.
 *              - Set of physical interfaces which represent ports of the BD.
 *              - Information about which ports are tagged or untagged.
 *                - Tagged port adds a VLAN tag to egressed frames if they are not VLAN tagged, or keeps
 *                  the tag of the frames intact if they are already VLAN tagged.
 *                - Untagged port removes the VLAN tag from egressed frames if the frames are VLAN tagged.
 *              - Instruction how to process matching uni-cast frames.
 *              - Instruction how to process matching multi-cast frames.
 *
 *              The L2 Bridge recognizes several BD types:
 *              - <b>Default BD:</b> @anchor ref__default_bd <br>
 *                Factory default VLAN ID of this bridge domain is @b 1.
 *                This domain is used to process ingress frames which either have a VLAN tag equal
 *                to the Default BD's VLAN ID, or don't have a VLAN tag at all (untagged Ethernet frames).
 *              - <b>Fall-back BD:</b> <br>
 *                This domain is used to process ingress frames which have an unknown VLAN tag.
 *                Unknown VLAN tag means that the VLAN tag does not match any existing standard BD nor the default BD.
 *              - <b>Standard BD:</b> <br>
 *                Standard user-defined bridge domains. Used by a VLAN-aware Bridge. These BDs
 *                process ingress frames which have a VLAN tag that matches the BD's VLAN ID.
 *
 *              Configuration
 *              -------------
 *              -# Create a bridge domain (VLAN domain).
 *                 <br> (@ref FPP_CMD_L2_BD + FPP_ACTION_REGISTER)
 *              -# Configure hit/miss actions of the bridge domain.
 *                 <br> (@ref FPP_CMD_L2_BD + FPP_ACTION_UPDATE)
 *              -# Configure which physical interfaces are considered members (ports) of the bridge domain.
 *                 Also specify which ports are VLAN tagged and which ports are not.
 *                 <br> (@ref FPP_CMD_L2_BD + FPP_ACTION_UPDATE)
 *              -# Repeat previous steps to create all required bridge domains (VLAN domains).
 *                 Physical interfaces can be members of multiple bridge domains.
 *              -# Configure the physical interfaces which shall classify their ingress traffic
 *                 by the VLAN-aware Bridge classification algorithm. Use steps described in
 *                 @ref mgmt_phyif (section @b modify) and do the following for each desired physical interface:
 *                 - Set mode of the interface to @ref FPP_IF_OP_VLAN_BRIDGE.
 *                 - Enable the promiscuous mode by setting the flag @ref FPP_IF_PROMISC.
 *                 - Enable the interface by setting the flag @ref FPP_IF_ENABLED.
 *
 *              Once the L2 Bridge is operational, ingress Ethernet frames of the Bridge-configured
 *              physical interfaces are processed according to setup of bridge domains. VLAN tag of
 *              every ingress frame is inspected and the frame is then processed by an appropriate bridge domain.
 *
 *              Additional operations
 *              ---------------------
 *              To @b remove a bridge domain:
 *              <br> (@ref FPP_CMD_L2_BD + FPP_ACTION_DEREGISTER)
 *
 *              <small>
 *              Note: <br>
 *              Default BD and Fall-back BD cannot be removed.
 *              </small> <br>
 *
 *              To @b list available bridge domains:
 *              <br> (@ref FPP_CMD_L2_BD + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *
 *              To @b modify properties of a bridge domain (read-modify-write):
 *              -# Read properties of the target bridge domain.
 *                 <br> (@ref FPP_CMD_L2_BD + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              -# Locally modify the properties. See fpp_l2_bd_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_L2_BD + FPP_ACTION_UPDATE)
 *
 *              Operations related to MAC table static entries
 *              ----------------------------------------------
 *              To @b create a new static entry:
 *              <br> (@ref FPP_CMD_L2_STATIC_ENT + FPP_ACTION_REGISTER)
 *
 *              To @b remove a static entry:
 *              <br> (@ref FPP_CMD_L2_STATIC_ENT + FPP_ACTION_DEREGISTER)
 *
 *              To @b list available static entries:
 *              <br> (@ref FPP_CMD_L2_STATIC_ENT + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *
 *              To @b modify properties of a static entry (read-modify-write):
 *              -# Read properties of the target static entry.
 *                 <br> (@ref FPP_CMD_L2_STATIC_ENT + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              -# Locally modify the properties. See fpp_l2_static_ent_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_L2_STATIC_ENT + FPP_ACTION_UPDATE)
 *
 *              To @b flush all static entries in PFE:
 *              <br> (@ref FPP_CMD_L2_FLUSH_STATIC)
 *
 *              Examples
 *              --------
 *              @ref demo_feature_L2_bridge_vlan.c
 *
 * @subsection  l2l3_bridge  L2L3 Bridge
 *              Introduction
 *              ------------
 *              L2L3 Bridge is an extension of the L2 Bridge and IP Router features.
 *              It allows both features to be simultaneously available on a physical interface.
 *              Traffic with specific destination MAC addresses is passed to the IP Router.
 *              The rest is handled by the L2 Bridge.
 *
 *              Configuration
 *              -------------
 *              -# Configure @ref l3_router.
 *              -# Configure @ref l2_bridge.
 *              -# Create at least one MAC table static entry with the 'local' flag. Note that
 *                 if a static entry is configured as local, then its egress list is ignored.
 *                 Also note that 'local' static entries must have a correct VLAN (and MAC address)
 *                 in order to properly match the ingress traffic.
 *                 <br> (@ref FPP_CMD_L2_STATIC_ENT + FPP_ACTION_REGISTER)
 *                 <br> (@ref FPP_CMD_L2_STATIC_ENT + FPP_ACTION_UPDATE)
 *              -# Configure the physical interfaces which shall classify their ingress traffic
 *                 by the L2L3 Bridge classification algorithm. Use steps described in
 *                 @ref mgmt_phyif (section @b modify) and do the following for each desired physical interface:
 *                 - Set mode of the interface to @ref FPP_IF_OP_L2L3_VLAN_BRIDGE.
 *                 - Enable the promiscuous mode by setting the flag @ref FPP_IF_PROMISC.
 *                 - Enable the interface by setting the flag @ref FPP_IF_ENABLED.
 *
 *              Once the L2L3 Bridge is operational, it checks the ingress traffic of
 *              L2L3 Bridge-configured physical interfaces against 'local' static entries
 *              in the L2 Bridge MAC table. If traffic's destination MAC matches a MAC address
 *              of some 'local' static entry, then the traffic is passed to the IP Router.
 *              Otherwise the traffic is passed to the L2 Bridge.
 *
 *              Examples
 *              --------
 *              @ref demo_feature_L2L3_bridge_vlan.c
 *
 * @subsection  flex_parser  Flexible Parser
 *              Introduction
 *              ------------
 *              Flexible Parser is a PFE firmware-based feature which can classify ingress traffic
 *              according to a set of custom classification rules. The feature is intended to be used
 *              as an extension of other PFE features/classification algorithms. Flexible Parser consists
 *              of the following elements:
 *              - <b>FP rule:</b>
 *                A classification rule. See @ref FPP_CMD_FP_RULE.
 *                FP rules inspect content of Ethernet frames. Based on the inspection result
 *                (whether the condition of a rule is satisfied or not), a next step of the Flexible Parser
 *                classification process is taken.
 *              - <b>FP table:</b> @anchor ref__fp_table
 *                An ordered set of FP rules. See @ref FPP_CMD_FP_TABLE. These tables can be assigned
 *                as extensions of other PFE features/classification algorithms. Namely, they can be used
 *                as an argument for:
 *                - Flexible Filter of a physical interface. See @ref fpp_phy_if_cmd_t (`.ftable`).
 *                  Flexible Filter acts as a traffic filter, pre-emptively discarding ingress traffic
 *                  which is rejected by the associated FP table. Accepted traffic is then processed
 *                  according to mode of the physical interface.
 *                - @ref FPP_IF_MATCH_FP0 / @ref FPP_IF_MATCH_FP1 match rules of a logical interface.
 *                  See @ref flex_router.
 *
 *              Flexible Parser classification introduces a performance penalty which is proportional to a count
 *              of rules and complexity of a used table. Always consider whether the use of this feature is
 *              really necessary. If it is necessary, then try to use FP tables with as few rules as possible.
 *
 *              Configuration
 *              -------------
 *              -# Create one or multiple FP rules.
 *                 <br> (@ref FPP_CMD_FP_RULE + FPP_ACTION_REGISTER)
 *              -# Create one or multiple FP tables.
 *                 <br> (@ref FPP_CMD_FP_TABLE + FPP_ACTION_REGISTER)
 *              -# Assign rules to tables. Each rule can be assigned only to one table.
 *                 <br> (@ref FPP_CMD_FP_TABLE + FPP_ACTION_USE_RULE)
 *              -# [optional] If required, an FP rule can be removed from an FP table.
 *                 The rule can be then assigned to a different table.
 *                 <br> (@ref FPP_CMD_FP_TABLE + FPP_ACTION_UNUSE_RULE)
 *              -# Use FP tables wherever they are required. See @link ref__fp_table FP table @endlink.
 *
 *              @b WARNING: <br>
 *              Do not modify FP tables which are already in use! Always first remove the FP table
 *              from use, then modify it (add/delete/rearrange rules), then put it back to its use.
 *              Failure to adhere to this warning will result in an undefined behavior of Flexible Parser.
 *              <br>
 *
 *              Once an FP table is configured and put to use, it will start classifying the ingress traffic
 *              in whatever role it was assigned to (see @link ref__fp_table FP table @endlink).
 *              Classification always starts from the very first rule of the table (index 0). Normally,
 *              rules of the table are evaluated sequentially till the traffic is either accepted, rejected,
 *              or the end of the table is reached. If the end of the table is reached and the traffic is
 *              still not accepted nor rejected, then Flexible Parser automatically rejects it.
 *
 *              Based on the action of an FP rule, it is possible to make a jump from the currently
 *              evaluated rule to any other rule in the same table. This can be used in some complex scenarios.
 *
 *              @b WARNING: <br>
 *              It is prohibited to use jumps to create loops. Failure to adhere to this warning
 *              will result in an undefined behavior of Flexible Parser.
 *
 *              Additional operations
 *              ---------------------
 *              It is advised to always remove rules and tables which are not needed, because these
 *              unused objects would needlessly occupy limited internal memory of PFE. To @b remove
 *              an FP rule or an FP table:
 *              - (@ref FPP_CMD_FP_RULE + FPP_ACTION_DEREGISTER)
 *              - (@ref FPP_CMD_FP_TABLE + FPP_ACTION_DEREGISTER)
 *
 *              To @b list FP rules or FP tables:
 *              - (@ref FPP_CMD_FP_RULE + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *              - (@ref FPP_CMD_FP_TABLE + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *
 *              FP table example
 *              ----------------
 *              This is an example of how a Flexible Parser table can look like.
 *              - Every row is one FP rule.
 *              - The classification process starts from the rule 0.
 *              - ACCEPT/REJECT means the classification is terminated with the given result.
 *              - CONTINUE means that the next rule in a sequence (next row) shall be evaluated.
 *              - NEXT_RULE <name> means that the next rule to evaluate shall be the rule <name>.
 *              - FrameData is an inspected value from an ingress Ethernet frame.
 *                Each rule can inspect a different value from the frame.
 *                See @ref FPP_CMD_FP_RULE and @ref fpp_fp_rule_props_t, fields `.offset` and `.offset_from`.
 *              - RuleData is a template value inside the FP rule. It is compared with the inspected value
 *                from the ingress Ethernet frame.
 *              - Mask is a bitmask specifying which bits of the RuleData and FrameData shall be compared
 *                (the rest of the bits is ignored).
 *
 *               i | Rule   | Flags                          | Mask | Condition of the rule + actions
 *              ---|--------|--------------------------------|------|------------------------------------------
 *               0 | MyR_01 | @b FP_INVERT <br> FP_REJECT    | != 0 | if ((FrameData & Mask) @b != (RuleData & Mask)) <br> then REJECT <br> else CONTINUE
 *               1 | MyR_02 |    FP_ACCEPT                   | != 0 | if ((FrameData & Mask)==(RuleData & Mask)) <br> then ACCEPT <br> else CONTINUE
 *               2 | MyR_03 |    FP_NEXT_RULE                | != 0 | if ((FrameData & Mask)==(RuleData & Mask)) <br> then NEXT_RULE MyR_11 <br> else CONTINUE
 *               3 | MyR_0r |    FP_REJECT                   | == 0 | REJECT
 *               4 | MyR_11 | @b FP_INVERT <br> FP_NEXT_RULE | != 0 | if ((FrameData & Mask) @b != (RuleData & Mask)) <br> then NEXT_RULE MyR_21 <br> else CONTINUE
 *               5 | MyR_1a |    FP_ACCEPT                   | == 0 | ACCEPT
 *               6 | MyR_21 | @b FP_INVERT <br> FP_ACCEPT    | != 0 | if ((FrameData & Mask) @b != (RuleData & Mask)) <br> then ACCEPT <br> else CONTINUE
 *               7 | MyR_2r |    FP_REJECT                   | == 0 | REJECT
 *
 *              Examples
 *              --------
 *              @ref demo_feature_flexible_filter.c
 *
 * @subsection  flex_router  Flexible Router
 *              Introduction
 *              ------------
 *              Flexible Router is a PFE firmware-based feature which uses logical interfaces
 *              (and their match rules) to classify ingress traffic. Replicas of the accepted traffic
 *              can be forwarded to one or multiple physical interfaces.
 *
 *              Flexible Router classification introduces a performance penalty which is proportional to a count
 *              of used logical interfaces (and their match rules). Always consider whether the use of this feature
 *              is really necessary. If it is necessary, then try to use as few logical interfaces as possible.
 *
 *              Configuration
 *              -------------
 *              -# Lock the interface database.
 *                 <br> (@ref FPP_CMD_IF_LOCK_SESSION)
 *              -# Create one or multiple logical interfaces. See @ref mgmt_logif for more info.
 *                 For Flexible Router purposes, pay attention to the order of logical interfaces.
 *                 <br> (@ref FPP_CMD_LOG_IF + FPP_ACTION_REGISTER)
 *              -# Configure the logical interfaces. Use steps described in
 *                 @ref mgmt_logif (section @b modify) and do the following for each desired logical interface:
 *                 - [optional] Set interface properties such as egress, match rules and match rule arguments.
 *                 - [optional] If multiple match rules are used, then set or clear the flag
 *                   @ref FPP_IF_MATCH_OR in order to specify a logical relation between the rules.
 *                 - Enable the interface by setting the flag @ref FPP_IF_ENABLED.
 *              -# Configure the physical interfaces which shall classify their ingress traffic
 *                 by the Flexible Router classification algorithm. Use steps described in
 *                 @ref mgmt_phyif (section @b modify) and do the following for each desired physical interface:
 *                 - Set mode of the interface to @ref FPP_IF_OP_FLEXIBLE_ROUTER.
 *                 - Enable the interface by setting the flag @ref FPP_IF_ENABLED.
 *              -# Unlock the interface database with @ref FPP_CMD_IF_UNLOCK_SESSION.
 *
 *              Once the Flexible Router is operational, it classifies the ingress traffic of
 *              Flexible Router-configured physical interfaces. The process is based on the
 *              classification sequence of logical interfaces (see @ref mgmt_logif). Classifier walks
 *              through the sequence from the head position back to tail, matching the ingress
 *              traffic against match rules of logical interfaces which are in the sequence.
 *              If a match is found (traffic conforms with match rules of the given logical interface),
 *              then the traffic is processed according to the interface's configuration (forwarded,
 *              dropped, sent to a host, etc.).
 *
 *              Configuration example
 *              ---------------------
 *              This example shows a scenario where emac1 physical interface is configured in
 *              the @ref FPP_IF_OP_FLEXIBLE_ROUTER mode. Goal is to classify ingress traffic
 *              on emac1 interface. If the traffic matches classification criteria,
 *              a replica of the traffic is egressed through both emac2 and hif0 interfaces.
 *              <br>
 *              @image latex flexible_router.eps "Configuration Example" width=7cm
 *              -# Traffic is ingressed (received) through emac1 port of PFE.
 *              -# Classifier walks through the list of logical interfaces associated with the emac1
 *                 physical interface.
 *              -# If some logical interface accepts the traffic, then information about the matching
 *                 logical interface (and its parent physical interface) is passed to the Routing and
 *                 Forwarding Algorithm. Algorithm reads the logical interface and retrieves forwarding properties.
 *              -# Traffic is forwarded by the Routing and Forwarding Algorithm based on the provided information.
 *                 In this example, the logical interface specified that a replica of the traffic shall be
 *                 forwarded to both emac2 and hif0 interfaces.
 *              -# Traffic is transmitted via physical interfaces.
 *
 *              Examples
 *              --------
 *              @ref demo_feature_flexible_router.c
 *
 * @subsection  ipsec_offload IPsec Offload
 *              Introduction
 *              ------------
 *              The IPsec offload feature is a premium one and requires a special premium firmware version
 *              to be available for use. It allows the chosen IP frames to be transparently encoded by the IPsec and
 *              IPsec frames to be transparently decoded without the CPU intervention using just the PFE and HSE engines.
 *
 *              @b WARNING: <br>
 *              The IPsec offload feature is available only for some Premium versions of PFE firmware.
 *              The feature should @b not be used with a firmware which does not support it.
 *              Failure to adhere to this warning will result in an undefined behavior of PFE.
 *              <br>
 *
 *              The SPD database needs to be established on an interface which contains entries describing frame
 *              match criteria together with the SA ID reference to the SA established within the HSE describing
 *              the IPsec processing criteria. Frames matching the criteria are then processed by the HSE according
 *              to the chosen SA and returned for the classification via physical interface of UTIL PE. Normal
 *              classification follows the IPsec processing thus the decrypted packets can be e.g. routed.
 *
 *              <br>Supported operations related to the IPsec offload:
 *
 *              To @b create a new SPD entry in the SPD table of a physical interface:
 *              <br> (@ref FPP_CMD_SPD + FPP_ACTION_REGISTER)
 *
 *              To @b remove an SPD entry from the SPD table of a physical interface:
 *              <br> (@ref FPP_CMD_SPD + FPP_ACTION_DEREGISTER)
 *
 *              To @b list existing SPD entries from the SPD table of a physical interface:
 *              <br> (@ref FPP_CMD_SPD + FPP_ACTION_QUERY and FPP_ACTION_QUERY_CONT)
 *
 *              The HSE also requires the configuration via interfaces of the HSE firmware which is out of the scope of this
 *              document. The SAs referenced within the SPD entries must exist prior creation of the respective SPD entry.
 *
 *              Examples
 *              --------
 *              @ref demo_feature_spd.c
 *
 * @subsection  egress_qos Egress QoS
 *              Introduction
 *              ------------
 *              The Egress QoS allows user to prioritize, aggregate and shape traffic intended to
 *              leave the accelerator through some @link mgmt_phyif physical interface @endlink.
 *              Egress QoS is implemented as follows:
 *              - Each @b emac physical interface has its own QoS block.
 *              - All @b hif physical interfaces share one common QoS block.
 *
 *              Every QoS block has a platform-specific number of queues, schedulers and shapers.
 *
 *              @if S32G2
 *                The following applies for each @b S32G2/PFE QoS block:
 *                - @b Queues: @anchor ref__queues
 *                     - Number of queues: 8
 *                     - Size of a @link ref__queue_slot_pools queue slot pool @endlink for each @b emac : 255
 *                     - Size of a queue slot pool for each @b hif : 32
 *                     - Probability zones per queue: 8
 *                       <small><br><br>
 *                       Queues of @b hif interfaces:
 *                       Every hif interface has only @b 2 queues, indexed as follows:
 *                         - [0] : low priority queue (L)
 *                         - [1] : high priority queue (H)
 *
 *                       Use only these indexes if hif queues are configured via FCI commands.
 *                       </small>
 *                - @b Schedulers:
 *                     - Number of schedulers: 2
 *                     - Number of scheduler inputs: 8
 *                     - Traffic sources which can be connected to scheduler inputs:
 *                       (see @link fpp_qos_scheduler_cmd_t @endlink.input_src)
 *                         Source|Description
 *                         ------|----------------------
 *                         0 - 7 | Queue 0 - 7
 *                         8     | Output of Scheduler 0
 *                         255   | Invalid (nothing connected)
 *
 *                - @b Shapers:
 *                     - Number of shapers: 4
 *                     - Shaper positions:
 *                       (see @link fpp_qos_shaper_cmd_t @endlink.position)
 *                         Position  |Description
 *                         ----------|------------------------------------------
 *                         0         | Output of Scheduler 1 (QoS master output)
 *                         1 - 8     | Input 0 - 7 of Scheduler 1
 *                         9 - 16    | Input 0 - 7 of Scheduler 0
 *                         255       | Invalid (shaper disconnected)
 *                     Note that only shapers connected to common scheduler inputs are aware
 *                     of each other and do share the 'conflicting transmission' signal.
 *              @endif
 *
 *              Queue slot pools @anchor ref__queue_slot_pools
 *              ----------------
 *              Every QoS block has it own pool of queue slots. These slots can be assigned to particular queues.
 *              Length of a queue is equal to number of assigned slots. It is possible to configure queue lengths via FCI API.
 *              Setting a queue length (@link fpp_qos_queue_cmd_t @endlink.max) means assigning given number of slots to the given queue.
 *              Sum of all queue lengths of the particular physical interface cannot be bigger than size of its queue slot pool.
 *
 *              See section @link ref__queues Queues @endlink for info about queue slot pool sizes for various physical interfaces.
 *              <small><br><br>
 *              Examples of queue slots distribution:
 *              - Asymmetrical queue slots distribution for @b emac0.
 *                Only 241 slots of the emac0 are used. Emac0 still has 14 free queue slots which could be used to
 *                lenghten some emac0 queues, if needed.
 *                  - queue 0 : 150 slots
 *                  - queues 1 .. 7 : 13 slots per each queue
 *              - Symmetrical queue slots distribution for @b hif0.
 *                All 32 queue slots of the hif0 are used. There are no free queue slots left on hif0.
 *                  - queue 0 : 16 slots
 *                  - queue 1 : 16 slots
 *              </small>
 *
 *              Traffic queueing algorithm
 *              --------------------------
 *              The following pseudocode explains traffic queueing algorithm of PFE:
 *              @code{.c}
 *              .............................................
 *              get_queue_for_packet(pkt)
 *              {
 *                queue = 0;
 *
 *                if (pkt.hasVlanTag)
 *                {
 *                  queue = pkt.VlanHdr.PCP;
 *                }
 *                else
 *                {
 *                  if (pkt.isIPv4)
 *                  {
 *                    queue = (pkt.IPv4Hdr.DSCP) / 8;
 *                  }
 *                  if (pkt.isIPv6)
 *                  {
 *                    queue = (pkt.IPv6Hdr.TrafficClass.DS) / 8;
 *                  }
 *                }
 *
 *                return queue;
 *              }
 *              .............................................
 *              @endcode
 *
 *              <small>
 *              @b Note:
 *              Hif interfaces have only two queues. Their queueing algorithm is similar to the
 *              aforementioned pseudocode, but is modified to produce only two results:
 *                - 0 : traffic belongs to the hif's low priority queue.
 *                - 1 : traffic belongs to the hif's high priority queue.
 *
 *              </small>
 *
 *              Configuration
 *              -------------
 *              By default, the egress QoS topology looks like this:
 *              @verbatim
                         SCH1
                         (RR)
                      +--------+
                Q0--->| 0      |
                Q1--->| 1      |
                Q2--->| 2      |
                Q3--->| 3      +--->
                Q4--->| 4      |
                ...   | ...    |
                Q7--->| 7      |
                      +--------+
                @endverbatim
 *
 *              All queues are connected to Scheduler 1 and the scheduler discipline
 *              is set to Round Robin. Rate mode is set to Data Rate (bps). Queues are
 *              in Tail Drop mode.
 *
 *              To <b> list QoS queue </b> properties:
 *              -# Read QoS queue properties.
 *                 <br> (@ref FPP_CMD_QOS_QUEUE + FPP_ACTION_QUERY)
 *
 *              To <b> list QoS scheduler </b> properties:
 *              -# Read QoS scheduler properties.
 *                 <br> (@ref FPP_CMD_QOS_SCHEDULER + FPP_ACTION_QUERY)
 *
 *              To <b> list QoS shaper </b> properties:
 *              -# Read QoS shaper properties.
 *                 <br> (@ref FPP_CMD_QOS_SHAPER + FPP_ACTION_QUERY)
 *
 *              To <b> modify QoS queue </b> properties (read-modify-write):
 *              -# Read QoS queue properties.
 *                 <br> (@ref FPP_CMD_QOS_QUEUE + FPP_ACTION_QUERY)
 *              -# Locally modify the properties. See fpp_qos_queue_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_QOS_QUEUE + FPP_ACTION_UPDATE)
 *
 *              To <b> modify QoS scheduler </b> properties (read-modify-write):
 *              -# Read QoS scheduler properties.
 *                 <br> (@ref FPP_CMD_QOS_SCHEDULER + FPP_ACTION_QUERY)
 *              -# Locally modify the properties. See fpp_qos_scheduler_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_QOS_SCHEDULER + FPP_ACTION_UPDATE)
 *
 *              To <b> modify QoS shaper </b> properties (read-modify-write):
 *              -# Read QoS shaper properties.
 *                 <br> (@ref FPP_CMD_QOS_SHAPER + FPP_ACTION_QUERY)
 *              -# Locally modify the properties. See fpp_qos_shaper_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_QOS_SHAPER + FPP_ACTION_UPDATE)
 *
 *              Examples
 *              --------
 *              @ref demo_feature_qos.c
 *
 * @subsection  ingress_qos Ingress QoS
 *              Introduction
 *              ------------
 *              The Ingress QoS allows user to prioritize, aggregate and shape traffic as
 *              it comes into the accelerator through an @b emac @link mgmt_phyif physical interface @endlink,
 *              before it is further processed by the accelerator.
 *
 *              Each @b emac physical interface has its own Ingress QoS Policer block.
 *              Every Policer block has its dedicated flow classification table, WRED queues and Ingress QoS shapers.
 *              Exact size of flow classification table and exact numbers/limits of WRED queues and
 *              Ingress QoS shapers are platform-specific.
 *
 *              @if S32G2
 *                The following applies for each @b S32G2/PFE Ingress QoS block ("policer"):
 *                - @b Flow classification table:
 *                     - Maximum number of flows: 64
 *
 *                - @b WRED queues:
 *                     - Number of queues: 3 (DMEM, LMEM, RXF)
 *                     - Maximum queue depth: 8192 for DMEM ; 512 for LMEM and RXF
 *                     - Probability zones per queue: 4
 *
 *                - @b Ingress @b QoS @b shapers:
 *                     - Number of shapers: 2
 *              @endif
 *
 *              Configuration
 *              -------------
 *              By default, the Ingress QoS block ("policer") is organized as follows:
 *              @verbatim
                              policer
         +-------------------------------------------------+
         |                                                 |
         |  +------------+   +--------+   +-------------+  |
Ingress  |  |            |   |  WRED  |   | Ingress QoS |  |   Further PFE
traffic--+->| flow table +-->| queues +-->|   shapers   +--+-->processing
         |  |            |   |        |   |             |  |
         |  +-----+------+   +---+----+   +-------------+  |
         |        |              |                         |
         +--------+--------------+-------------------------+
                  |              |
                 possible packet drop
                @endverbatim
 *
 *              - <tt>policer</tt>  (@ref FPP_CMD_QOS_POLICER)
 *                    - The Ingress QoS block ("policer") itself.
 *                    - The whole block can be enabled/disabled. If the block is disabled,
 *                      it is bypassed and does not affect performance.
 *              - <tt>flow table</tt> which contains flows  (@ref FPP_CMD_QOS_POLICER_FLOW)
 *                    - Flow classification table. Contains user-defined flows.
 *                    - Each flow represents a certain criteria, such as traffic type to match
 *                      (VLAN, ARP, IPv4, etc.) or some data within the traffic to match
 *                      (match VLAN ID, match IP address, etc).
 *                    - Ingressing traffic is compared with flows and their criteria.
 *                      If traffic matches some flow, then (based on flow action), the traffic gets
 *                      either dropped or marked as Managed or Reserved.
 *                      Traffic which does not match any flow from the table is marked as Unmanaged.
 *              - <tt>WRED queues</tt>  (@ref FPP_CMD_QOS_POLICER_WRED)
 *                    - Ingress QoS WRED queues. These queues (by HW design) always use WRED algorithm.
 *                    - Individual queues can be disabled. If all queues are disabled,
 *                      then the WRED queueing module is bypassed.
 *                    - Traffic is queued (or possibly dropped) based on the momentary queue fill and
 *                      also based on the marking of the traffic (Unmanaged/Managed/Reserved).
 *                      See description of @ref fpp_iqos_wred_thr_t enum members.
 *              - <tt>Ingress QoS shapers</tt>  (@ref FPP_CMD_QOS_POLICER_SHP)
 *                    - Ingress QoS shapers. These shapers can be used to shape ingress traffic
 *                      to ensure optimal data flow.
 *                    - Individual shapers can be disabled. If all shapers are disabled,
 *                      then the Ingress QoS shaper module is bypassed.
 *                    - Shapers can be assigned to shape one of several predefined traffic types.
 *                      See description of @ref fpp_iqos_shp_type_t enum members.
 *
 *              To @b get Ingress QoS @b policer status:
 *              -# (@ref FPP_CMD_QOS_POLICER + FPP_ACTION_QUERY)
 *
 *              To @b list Ingress QoS @b flow properties:
 *              -# (@ref FPP_CMD_QOS_POLICER_FLOW + FPP_ACTION_QUERY, FPP_ACTION_QUERY_CONT)
 *
 *              To @b list Ingress QoS @b WRED queue properties:
 *              -# (@ref FPP_CMD_QOS_POLICER_WRED + FPP_ACTION_QUERY)
 *
 *              To @b list Ingress QoS @b shaper properties:
 *              -# (@ref FPP_CMD_QOS_POLICER_SHP + FPP_ACTION_QUERY)
 *
 *              <br>
 *              To @b enable/disable Ingress QoS @b policer:
 *              -# (@ref FPP_CMD_QOS_POLICER + FPP_ACTION_UPDATE)
 *
 *              To @b add Ingress QoS @b flow to flow classification table:
 *              -# (@ref FPP_CMD_QOS_POLICER_FLOW + FPP_ACTION_REGISTER)
 *
 *              To @b remove Ingress QoS @b flow from flow classification table:
 *              -# (@ref FPP_CMD_QOS_POLICER_FLOW + FPP_ACTION_DEREGISTER)
 *
 *              To @b modify Ingress QoS @b WRED queue properties (read-modify-write):
 *              -# Read Ingress QoS WRED queue properties.
 *                 <br> (@ref FPP_CMD_QOS_POLICER_WRED + FPP_ACTION_QUERY)
 *              -# Locally modify the properties. See fpp_qos_policer_wred_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_QOS_POLICER_WRED + FPP_ACTION_UPDATE)
 *
 *              To @b modify Ingress QoS @b shaper properties (read-modify-write):
 *              -# Read Ingress QoS shaper properties.
 *                 <br> (@ref FPP_CMD_QOS_POLICER_SHP + FPP_ACTION_QUERY)
 *              -# Locally modify the properties. See fpp_qos_policer_shp_cmd_t.
 *              -# Write the modified properties back to PFE.
 *                 <br> (@ref FPP_CMD_QOS_POLICER_SHP + FPP_ACTION_UPDATE)
 *
 *              Examples
 *              --------
 *              @ref demo_feature_qos_policer.c
 */

/**
 * @example demo_feature_physical_interface.c
 * @example demo_feature_L2_bridge_vlan.c
 * @example demo_feature_router_simple.c
 * @example demo_feature_router_nat.c
 * @example demo_feature_L2L3_bridge_vlan.c
 * @example demo_feature_flexible_filter.c
 * @example demo_feature_flexible_router.c
 * @example demo_feature_spd.c
 * @example demo_feature_qos.c
 * @example demo_feature_qos_policer.c
 *
 * @example demo_common.c
 * @example demo_phy_if.c
 * @example demo_log_if.c
 * @example demo_if_mac.c
 * @example demo_mirror.c
 * @example demo_l2_bd.c
 * @example demo_fp.c
 * @example demo_rt_ct.c
 * @example demo_spd.c
 * @example demo_qos.c
 * @example demo_qos_pol.c
 * @example demo_fwfeat.c
 * @example demo_fci_owner.c
 */

/**
 * @addtogroup  dxgrLibFCI
 * @{
 *
 * @file        libfci.h
 * @brief       Generic LibFCI header file
 * @details     This file contains generic API and API description
 */

#ifndef LIBFCI_H
#define LIBFCI_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#ifndef TRUE
#define TRUE 1
#endif /* TRUE */

#ifndef FALSE
#define FALSE 0
#endif /* FALSE */


/**
 * @def         CTCMD_FLAGS_ORIG_DISABLED
 * @brief       Disable connection originator.
 * @details      <!-- empty, but is needed by Doxygen generator -->
 * @hideinitializer
 */
#define CTCMD_FLAGS_ORIG_DISABLED           ((uint16)1U << 0)

/**
 * @def         CTCMD_FLAGS_REP_DISABLED
 * @brief       Disable connection replier.
 * @details     Used to create uni-directional connections (see @ref FPP_CMD_IPV4_CONNTRACK,
 *              @ref FPP_CMD_IPV4_CONNTRACK)
 * @hideinitializer
 */
#define CTCMD_FLAGS_REP_DISABLED            ((uint16)1U << 1)

/**
 * @def         CTCMD_FLAGS_TTL_DECREMENT
 * @brief       Enable TTL decrement
 * @details     Used to decrement TTL field when the pkt is routed
 * @hideinitializer
 */
#define CTCMD_FLAGS_TTL_DECREMENT            ((uint16)1U << 2)

/**
 * @def FCI_CFG_FORCE_LEGACY_API
 * @brief       Changes the LibFCI API so it is more compatible with legacy implementation
 * @details     LibFCI API was modified to avoid some inconvenient properties. Here are the points
 *              the legacy API differs in:
 *              -# With legacy API, argument @c rsp_data of function @c fci_query shall be provided shifted by two
 *                 bytes this way:
 *                 @code{.c}
 *                   reply_struct_t rsp_data;
 *                   retval = fci_query(this_client, fcode, cmd_len, &pcmd, &rsplen, (unsigned short *)(&rsp_data) + 1u);
 *                 @endcode
 *                 Where @c reply_struct_t is the structure type depending on command being called.
 *              -# In legacy API, macros @ref FPP_CMD_IPV4_CONNTRACK_CHANGE and @ref FPP_CMD_IPV6_CONNTRACK_CHANGE are
 *                 defined in application files. In current API they are defined here in @ref libfci.h.
 *
 * @warning     It is not recommended to enable this feature.
 *
 * @hideinitializer
 */
#define FCI_CFG_FORCE_LEGACY_API FALSE

#if FALSE == FCI_CFG_FORCE_LEGACY_API
    /**
     * @if FCI_EVENTS_IMPLEMENTED
     * @def         FPP_CMD_IPV4_CONNTRACK_CHANGE
     * @brief       Callback event value for IPv4 conntracks
     * @details     One of the values the callback registered by @ref fci_register_cb can get in @c fcode
     *              argument.
     *
     *              This value indicates IPv4 conntrack event. The payload argument shall be cast to
     *              @ref fpp_ct_ex_cmd type. Then all addresses, all ports and protocol shall be used to
     *              identify connection while the @c action item indicates type of event:
     *              - @ref FPP_ACTION_KEEP_ALIVE: conntrack entry is still active
     *              - @ref FPP_ACTION_REMOVED: conntrack entry was removed
     *              - @ref FPP_ACTION_TCP_FIN: TCP FIN or TCP RST packet was received, conntrack was removed
     * @hideinitializer
     * @endif
     */
    #define FPP_CMD_IPV4_CONNTRACK_CHANGE   0x0315u
    /**
     * @if FCI_EVENTS_IMPLEMENTED
     * @def         FPP_CMD_IPV6_CONNTRACK_CHANGE
     * @brief       Callback event value for IPv6 conntracks
     * @details     One of the values the callback registered by @ref fci_register_cb can get in @c fcode
     *              argument.
     *
     *              This value indicates IPv6 conntrack event. The payload argument shall be cast to
     *              @ref fpp_ct6_ex_cmd type. Otherwise the event is same as
     *              @ref FPP_CMD_IPV4_CONNTRACK_CHANGE.
     * @hideinitializer
     * @endif
     */
    #define FPP_CMD_IPV6_CONNTRACK_CHANGE   0x0415u
#endif /* FCI_CFG_FORCE_LEGACY_API */


/**
 * @struct      FCI_CLIENT
 * @brief       The FCI client representation type
 * @details     This is the FCI instance representation. It is used by the rest of the API to
 *              communicate with associated endpoint. The endpoint can be a standalone
 *              application/driver taking care of HW configuration tasks and shall be able to
 *              interpret commands sent via the LibFCI API.
 *
 * @internal
 * @note        The fci_client_tag structure has to be provided by the OS/HW specific
 *              implementation.
 * @endinternal
 */
typedef struct fci_client_tag FCI_CLIENT;

/**
 * @typedef     fci_mcast_groups_t
 * @brief       List of supported multicast groups
 * @details     An FCI client instance can be member of a multicast group. It means it can send and
 *              receive multicast messages to/from another group members (another FCI instances or FCI
 *              endpoints). This can be in most cases used by FCI endpoint to notify all associated
 *              FCI instances about some event has occurred.
 * @note        Each group is intended to be represented by a single bit flag (max 32-bit, so it is
 *              possible to have max 32 multicast groups). Then, groups can be combined using
 *              bitwise OR operation.
 */
typedef enum
{
    FCI_GROUP_NONE  = 0x00000000, /**< Default MCAST group value, no group, for sending FCI commands */
    FCI_GROUP_CATCH = 0x00000001  /**< MCAST group for catching events */
} fci_mcast_groups_t;

/**
 * @typedef     fci_client_type_t
 * @brief       List of supported FCI client types
 * @details     FCI client can specify using this type to which FCI endpoint shall be connected.
 */
typedef enum
{
    FCI_CLIENT_DEFAULT = 0, /**< Default type (equivalent of legacy FCILIB_FF_TYPE macro) */
    FCILIB_FF_TYPE = 0 /* Due to compatibility purposes */
} fci_client_type_t;

/**
 * @typedef     fci_cb_retval_t
 * @brief       The FCI callback return values
 * @details     These return values shall be used in FCI callback (see @ref fci_register_cb).
 *              It tells @ref fci_catch function whether it should return or continue.
 */
typedef enum
{
    FCI_CB_STOP = 0, /**< Stop waiting for events and exit @ref fci_catch function */
    FCI_CB_CONTINUE  /**< Continue waiting for next events */
} fci_cb_retval_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Creates new FCI client and opens a connection to FCI endpoint
 * @details     Binds the FCI client with FCI endpoint. This enables sending/receiving data
 *              to/from the endpoint. Refer to the remaining API for possible communication
 *              options.
 * @param[in]   client_type Client type. Default value is FCI_CLIENT_DEFAULT. See @ref fci_client_type_t.
 * @param[in]   group A 32-bit multicast group mask. Each bit represents single multicast address.
 *                    FCI instance will listen to specified multicast addresses as well it will
 *                    send data to all specified multicast groups. See @ref fci_mcast_groups_t.
 * @return      The FCI client instance or NULL if failed
 */
FCI_CLIENT * fci_open(fci_client_type_t client_type, fci_mcast_groups_t group);

/**
 * @brief       Disconnects from FCI endpoint and destroys FCI client instance
 * @details     Terminate the FCI client and release all allocated resources.
 * @param[in]   client The FCI client instance
 * @return      0 if success, error code otherwise
 */
int fci_close(FCI_CLIENT *client);

/**
 * @brief       Catch and process all FCI messages delivered to the FCI client
 * @details     Function is intended to be called in its own thread. It waits for message/event
 *              reception. If there is an event callback associated with the FCI client, assigned
 *              by function @ref fci_register_cb(), then, when message is received, the callback is
 *              called to process the data. As long as there is no error and the callback returns
 *              @ref FCI_CB_CONTINUE, @ref fci_catch() continues waiting for another message. Otherwise it
 *              returns.
 *
 * @note        This is a blocking function.
 *
 * @note        Multicast group FCI_GROUP_CATCH shall be used when opening the client for catching
 *              messages
 *
 * @see         fci_register_cb()
 * @param[in]   client The FCI client instance
 * @return      0 if success, error code otherwise
 */
int fci_catch(FCI_CLIENT *client);

/**
 * @brief       Run an FCI command with optional data response
 * @details     This routine can be used when one need to perform any command either with or
 *              without data response. If the command responded with some data structure the
 *              structure is written into the rep_buf. The length of the returned data structure
 *              (number of bytes) is written into rep_len.
 *
 * @internal
 * @note        This shall be a blocking call.
 * @endinternal
 *
 * @note        The @c rep_buf buffer must be aligned to 4.
 *
 * @param[in]   client The FCI client instance
 * @param[in]   fcode Command to be executed. Available commands are listed in @ref fci_cs.
 * @param[in]   cmd_buf Pointer to structure holding command arguments.
 * @param[in]   cmd_len Length of the command arguments structure in bytes.
 * @param[out]  rep_buf Pointer to memory where the data response shall be written. Can be NULL.
 * @param[in,out]   rep_len Pointer to variable where number of response bytes shall be written.
 * @retval      <0 Failed to execute the command.
 * @retval      >=0 Command was executed with given return value (@c FPP_ERR_OK for success).
 */
int fci_cmd(FCI_CLIENT *client, unsigned short fcode, unsigned short *cmd_buf, unsigned short cmd_len, unsigned short *rep_buf, unsigned short *rep_len);

/**
 * @brief       Run an FCI command with data response
 * @details     This routine can be used when one need to perform a command which is resulting
 *              in a data response. It is suitable for various 'query' commands like reading of
 *              whole tables or structured entries from the endpoint.
 *
 * @internal
 * @note        This shall be a blocking call.
 * @endinternal
 *
 * @note        If either @c rsp_data or @c rsplen is NULL pointer, the response data is discarded.
 *
 * @param[in]   client The FCI client instance
 * @param[in]   fcode Command to be executed. Available commands are listed in @ref fci_cs.
 * @param[in]   cmd_len Length of the command arguments structure in bytes
 * @param[in]   cmd_buf Pointer to structure holding command arguments.
 * @param[out]  rep_len Pointer to memory where length of the data response will be provided
 * @param[out]  rep_buf Pointer to memory where the data response shall be written.
 * @retval      <0 Failed to execute the command.
 * @retval      >=0 Command was executed with given return value (@c FPP_ERR_OK for success).
 */
int fci_query(FCI_CLIENT *client, unsigned short fcode, unsigned short cmd_len, unsigned short *cmd_buf, unsigned short *rep_len, unsigned short *rep_buf);
/**
 * @brief       Run an FCI command
 * @details     Similar as the fci_query() but without data response. The endpoint receiving the
 *              command is still responsible for generating response but the response is not
 *              delivered to the caller.
 *
 * @internal
 * @note        This shall be a blocking call.
 * @endinternal
 *
 * @param[in]   client The FCI client instance
 * @param[in]   fcode Command to be executed. Available commands are listed in @ref fci_cs.
 * @param[in]   cmd_len Length of the command arguments structure in bytes
 * @param[in]   cmd_buf Pointer to structure holding command arguments
 * @retval      <0 Failed to execute the command.
 * @retval      >=0 Command was executed with given return value (@c FPP_ERR_OK for success).
 */
int fci_write(FCI_CLIENT *client, unsigned short fcode, unsigned short cmd_len, unsigned short *cmd_buf);

/**
 * @brief       Register event callback function
 * @details     FCI endpoint can send various asynchronous messages to the FCI client. In such case,
 *              a callback registered via this function is executed if @ref fci_catch() is running.
 * @param[in]   client The FCI client instance
 * @param[in]   event_cb The callback function to be executed. When called then @c fcode specifies event
 *                       code (available events are listed in @ref cbks), @c payload is pointer to event
 *                       payload and the @c len is number of bytes in the payload buffer.
 * @return      0 if success, error code otherwise
 * @note        In order to continue receiving messages, the callback function shall always return
 *              @ref FCI_CB_CONTINUE. Any other value will cause the @ref fci_catch to return.
 */
int fci_register_cb(FCI_CLIENT *client, fci_cb_retval_t (*event_cb)(unsigned short fcode, unsigned short len, unsigned short *payload));

/**
 * @brief       Obsolete function, shall not be used
 */
int fci_fd(FCI_CLIENT *client);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* LIBFCI_H */


===== 文件 [26/185]: include\linked_list.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2017-2022 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef LINKED_LIST_H
#define LINKED_LIST_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/**
* @brief   This structure shall be used to link structures of data.
* @details Just put this anywhere into the structs which shall be linked.
*/
typedef struct  __attribute__((packed)) LLIST_Struct
{
   struct LLIST_Struct *prNext;
   struct LLIST_Struct *prPrev;
} LLIST_t;

/**
* @def   LLIST_Init
* @brief Initializes given linked list as empty.
*/
#define LLIST_Init(prList) \
do \
{ \
    (prList)->prNext = (prList); \
    (prList)->prPrev = (prList); \
}while(0!=0)

/**
* @def        LLIST_ForEach
* @brief      Iterates through all list items, do not use to delete them.
* @details    The list shall not be modified during the loop.
* @param[out] prCurrent Provide a pointer of type LLIST_t *. In each iteration an item
*             from the list is assigned to it. Do not free this memory - it must exist
*             in the next iteration.
* @param[in]  prHead Head of the list to loop in. Type is again LLIST_t *.
*/
#define LLIST_ForEach(prCurrent, prHead) \
            for( \
                 (prCurrent) = (prHead)->prNext; \
                 (prCurrent) != (prHead); \
                 (prCurrent) = (prCurrent)->prNext \
               )

/**
* @def        LLIST_ForEachRemovable
* @brief      Iterates through all list items with purpose of deleting them.
* @details    It is possible to remove prCurrent in the iteration.
* @param[out] prCurrent Provide a pointer of type LLIST_t *. In each iteration an item
*             from the list is assigned to it. It is safe to free this memory because
*             information for next iterations is stored in prAuxNext.
* @param[out] prAuxNext One extra pointer of type LLIST_t * must be provided to be
*             used for internal use by this macro.
*             internally by the macro.
* @param[in]  prHead Head of the list to loop in. Type is again LLIST_t *.
*/
#define LLIST_ForEachRemovable(prCurrent, prAuxNext, prHead) \
            for( \
                 (prCurrent) = (prHead)->prNext, (prAuxNext) = (prCurrent)->prNext; \
                 (prCurrent) != (prHead); \
                 (prCurrent) = (prAuxNext), (prAuxNext) = (prAuxNext)->prNext \
               )

/**
* @def   LLIST_OffsetOff
* @brief Custom definition of offsetof macro.
*/
#define LLIST_OffsetOff(TypeOfData,NameOfList) (&(((TypeOfData*)0U)->NameOfList))

/**
* @def       LLIST_Data
* @brief     Provide pointer to the structure given list is contained in.
* @param[in] prListItem The pointer to LLIST_t.
* @param[in] TypeOfData The type of the struct this is embedded in.
* @param[in] NameOfList The name of the LLIST_t within the struct.
*/
#define LLIST_Data(prListItem,TypeOfData,NameOfList) \
            ( (TypeOfData*)(((char_t *)(prListItem)) \
              - ((char_t *)(LLIST_OffsetOff(TypeOfData, NameOfList)))) \
            )

/**
* @def       LLIST_DataChkNull
* @brief     Same as LLIST_Data with NULL pointer check.
* @details   If the prListItem is NULL then it returns NULL.
* @param[in] prListItem The pointer to LLIST_t.
* @param[in] TypeOfData The type of the struct this is embedded in.
* @param[in] NameOfList The name of the LLIST_t within the struct.
*/
#define LLIST_DataChkNull(prListItem,TypeOfData,NameOfList) \
            ( ((prListItem)==NULL) ? \
              NULL : LLIST_Data((prListItem),TypeOfData,NameOfList) \
            )

/**
* @def   LLIST_DataFirst
* @brief Like LLIST_Data but returns next structure in the list.
*/
#define LLIST_DataFirst(prListHead,TypeOfData,NameOfList) \
            LLIST_Data((prListHead)->prNext,TypeOfData,NameOfList)

/**
* @def   LLIST_DataLast
* @brief Like LLIST_Data but returns previous structure in the list.
*/
#define LLIST_DataLast(prListHead,TypeOfData,NameOfList) \
            LLIST_Data((prListHead)->prPrev,TypeOfData,NameOfList)

/**
* @def   LLIST_AddAtBegin
* @brief Adds given entry to the beginning of given list.
*/
#define LLIST_AddAtBegin(prNew, prHead) \
do \
{ \
    (prNew)->prNext = (prHead)->prNext; \
    (prNew)->prPrev = (prHead); \
    (prHead)->prNext->prPrev = (prNew); \
    (prHead)->prNext = (prNew); \
}while(0!=0)

/**
* @def   LLIST_AddAtEnd
* @brief Adds given entry to the end of given list.
*/
#define LLIST_AddAtEnd(prNew, prHead) \
do \
{ \
    (prNew)->prPrev = (prHead)->prPrev; \
    (prNew)->prNext = (prHead); \
    (prHead)->prPrev->prNext = (prNew); \
    (prHead)->prPrev = (prNew); \
}while(0!=0)

/**
* @def       LLIST_Remove
* @brief     Removes given entry from its list.
* @details   After this, the entry is in an undefined state.
* @param[in] prEntry Pointer to item to be removed.
*/
#define LLIST_Remove(prEntry) \
do \
{ \
    (prEntry)->prPrev->prNext = (prEntry)->prNext; \
    (prEntry)->prNext->prPrev = (prEntry)->prPrev; \
    (prEntry)->prPrev = NULL; \
    (prEntry)->prNext = NULL; \
}while(0!=0)

/**
* @def   LLIST_IsEmpty
* @brief Returns boolean information whether the list is empty.
*/
#define LLIST_IsEmpty(prList) ((prList)->prNext == (prList))

/**
* @def LLIST_Insert
* @brief Inserts entry into the existing list at a given position
* @param[in] prEntry Pointer to entry to be inserted
* @param[in] prPos Pointer to the entry which position shall be taken by the new one
* @details Having a chain of entries A-B-C-D, an entry X, and calling LLIST_Insert(X, C) results
*          in chain A-B-X-C-D.
*/
#define LLIST_Insert(prEntry, prPos) \
do \
{ \
    (prEntry)->prPrev = (prPos)->prPrev; \
    (prEntry)->prPrev->prNext = (prEntry); \
    (prPos)->prPrev = (prEntry); \
    (prEntry)->prNext = (prPos); \
}while(0!=0)

#endif /* LINKED_LIST_H */


===== 文件 [27/185]: include\nxp_snprintf.h =====
/**
 *  @file             nxp_snprintf.h
 *  @brief            Module serves to printing debug messages
 */
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright (c) 2014-2016 Freescale Semiconductor Inc.
 *  Copyright 2016-2018, 2022-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/

#ifndef NXP_SNPRINTF_H
#define NXP_SNPRINTF_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*==================================================================================================
                                         INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==================================================================================================*/
#include "nxp_snprintf_cfg.h"
#include <stdarg.h>

/*==================================================================================================
                               SOURCE FILE VERSION INFORMATION
==================================================================================================*/

/*==================================================================================================
                                      FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
                                           CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       DEFINES AND MACROS
==================================================================================================*/

/*==================================================================================================
                                             ENUMS
==================================================================================================*/

/*==================================================================================================
                                 STRUCTURES AND OTHER TYPEDEFS
==================================================================================================*/

/*==================================================================================================
                                 GLOBAL VARIABLE DECLARATIONS
==================================================================================================*/

/*==================================================================================================
                                     FUNCTION PROTOTYPES
==================================================================================================*/

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

extern uint32 nxp_snprintf(char_t *str, uint32 size, const char_t *pcocStr, ...);
extern uint32 nxp_vsnprintf(char_t *str, uint32 size, const char_t *pcocStr, va_list VarArg);

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#endif /* NXP_SNPRINTF_H */


===== 文件 [28/185]: include\nxp_snprintf_cfg.h =====
/**
 *  @file          nxp_snprintf_cfg.h
 *  @brief         nxp_snprintf module configuration file
 */
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright (c) 2014 Freescale Semiconductor Inc.
 *  Copyright 2016, 2018, 2021-2022 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 */

/*==================================================================================================
==================================================================================================*/

#ifndef NXP_SNPRINTF_CFG_H
#define NXP_SNPRINTF_CFG_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*==================================================================================================
                                         INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "oal_types.h"

/*==================================================================================================
                               SOURCE FILE VERSION INFORMATION
==================================================================================================*/

/*==================================================================================================
                                      FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
                                           CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       DEFINES AND MACROS
==================================================================================================*/
/**
* @brief Enable floating point numbers support (time consuming)
*/
#define NXP_SNPRINTF_CFG_FLOAT_SUPPORT        (FALSE)
/**
* @brief Enable long long integer types support
*/
#define NXP_SNPRINTF_CFG_LLINT_SUPPORT        (TRUE)

/*==================================================================================================
                                             ENUMS
==================================================================================================*/

/*==================================================================================================
                                 STRUCTURES AND OTHER TYPEDEFS
==================================================================================================*/

/*==================================================================================================
                                 GLOBAL VARIABLE DECLARATIONS
==================================================================================================*/

/*==================================================================================================
                                     FUNCTION PROTOTYPES
==================================================================================================*/

/*==================================================================================================*/
#endif /* NXP_SNPRINTF_CFG_H */


===== 文件 [29/185]: include\oal.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @defgroup    dxgrOAL OAL
 * @brief       The OS Abstraction Layer
 * @details     OAL is intended to provide OS abstraction. To write portable SW one shall use
 *              OAL calls instead of OS-specific ones. This OAL module incorporates following
 *              functionality:
 *              
 *              - oal_irq - Interrupt management
 *              - oal_mm - Memory management
 *              - oal_types - Abstraction of standard types
 *              - oal_sync - Thread synchronization
 *              - oal_util - Simplification utility
 *              - oaj_job - Job context abstraction
 *              
 * 
 * @addtogroup  dxgrOAL
 * @{
 * 
 * @file        oal.h
 * @brief       The main OAL header file
 * @details     Use this header to include all the OAL-provided functionality
 *
 */

#ifndef OAL_H_
#define OAL_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#ifndef PFE_CFG_H
    #error Please include the pfe_cfg.h first.
#endif

#include "oal_types.h"
#include "oal_util.h"
#include "oal_sync.h"
#include "oal_master_if.h"
#include "oal_irq.h"
#include "oal_time.h"
#include "oal_job.h"

#endif /* OAL_H_ */

/** @}*/


===== 文件 [30/185]: include\oal_irq.h =====

/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 *
 * @defgroup    dxgr_OAL_IRQ IRQ
 * @brief       IRQ abstraction
 * @details
 *              Purpose
 *              -------
 *              Purpose of the oal_irq block is to abstract IRQ management tasks.
 *
 *              Initialization
 *              --------------
 *              Each IRQ can be represented as instance of the oal_irq_t created by successful call
 *              of oal_irq_create(). Function binds a logical IRQ number with a handler which is
 *              optional and instance can exists also without an attached handler.
 *
 *              @note The oal_irq_crete() automatically un-masks the created IRQ.
 *
 *              Operation
 *              ---------
 *              An IRQ instance can be manipulated using oal_irq_mask() to suppress the interrupt
 *              and oal_irq_unmask() to re-enable it. To get the logical interrupt number as
 *              assigned during instance creation the oal_irq_get_id() can be used.
 *
 *              Shutdown
 *              --------
 *              Just call the oal_irq_destroy(). It ensures all interrupt de-initialization and
 *              releases all allocated resources.
 *
 * @addtogroup  dxgr_OAL_IRQ
 * @{
 *
 * @file        oal_irq.h
 * @brief       The oal_irq module header file.
 * @details     This file contains generic irq-related API.
 *
 */
#ifndef OAL_IRQ_H_
#define OAL_IRQ_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#include "oal_irq_autosar.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

typedef struct oal_irq_tag oal_irq_t;

/**
 * @brief       The IRQ handler type
 * @param[in]   data Custom data
 * @return      TRUE if IRQ has been handled, FALSE if not
 */
typedef bool_t (* oal_irq_handler_t)(void *data);

/**
 * @brief       ISR handle
 * @details     Handle to identify registered interrupt handlers.
 */
typedef uint32 oal_irq_isr_handle_t;

/**
 * @brief       Interrupt types
 * @details     Describes the state of interrupt ownership
 */
typedef enum
{
    OAL_IRQ_FLAG_PRIVATE = (1 << 0),    /* Interrupt is owned exclusively by the irq instance */
    OAL_IRQ_FLAG_SHARED = (1 << 1),     /* Interrupt is shared by other OS components */
    OAL_IRQ_FLAG_DISABLED = (1 << 2)    /* Don't automatically enable interrupt when created */
} oal_irq_flags_t;

/**
 * @brief       Create new IRQ instance
 * @details     After successful call the IRQ is automatically unmasked.
 * @param[in]   id The IRQ ID as seen by the OS
 * @param[in]   flags Interrupt type flags
 * @param[in]   data A cookie passed back to the handler function
 * @return      The new IRQ instance or NULL if failed
 */
oal_irq_t * oal_irq_create(sint32 id, oal_irq_flags_t flags, const char_t *name);

/**
 * @brief       Add handler for particular IRQ
 * @details     Adds IRQ handler. Only one handler per irq is supported.
 * @param[in]   irq The IRQ instance
 * @param[in]   handler The handler to be called when IRQ occurs or NULL
 *                      if handler should be not used.
 * @param[in]   data A cookie passed back to the handler function
 * @param[out]  handle Pointer to memory where handle identifying the handler shall
 *                     be written.
 * @return      EOK if success, error code otherwise
 */
errno_t oal_irq_add_handler(oal_irq_t *irq, oal_irq_handler_t handler, void *data, oal_irq_isr_handle_t *handle);

/**
 * @brief       Delete handler
 * @param[in]   irq The IRQ instance
 * @param[in]   handle The handler identifier
 * @return      EOK if success, error code otherwise
 */
errno_t oal_irq_del_handler(oal_irq_t *irq, oal_irq_isr_handle_t handle);

/**
 * @brief       Destroy an IRQ instance
 * @details     Masks the IRQ and releases all associated resources
 * @param[in]   irq The IRQ instance
 */
void oal_irq_destroy(oal_irq_t *irq);

/**
 * @brief       Mask IRQ
 * @param[in]   irq The IRQ instance
 * @return      EOK if success, error code otherwise
 */
errno_t oal_irq_mask(oal_irq_t *irq);

/**
 * @brief       Un-mask IRQ
 * @param[in]   irq The IRQ instance
 * @return      EOK if success, error code otherwise
 */
errno_t oal_irq_unmask(oal_irq_t *irq);

/**
 * @brief       Get IRQ ID
 * @param[in]   irq The IRQ instance
 * @return      The IRQ ID associated with the instance or -1 if failed
 */
sint32 oal_irq_get_id(const oal_irq_t *irq);

bool_t oal_irq_in_atomic(void);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* OAL_IRQ_H_ */

/** @}*/
/** @}*/


===== 文件 [31/185]: include\oal_irq_autosar.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 */
#ifndef OAL_IRQ_AUTOSAR_H_
#define OAL_IRQ_AUTOSAR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/* Interrupt indexes */
typedef enum {
    Eth_43_PFE_IRQ_IDX_HIF0 = 0U,
    Eth_43_PFE_IRQ_IDX_HIF1 = 1U,
    Eth_43_PFE_IRQ_IDX_HIF2 = 2U,
    Eth_43_PFE_IRQ_IDX_HIF3 = 3U,
    Eth_43_PFE_IRQ_IDX_HIFNOCPY,
    Eth_43_PFE_IRQ_IDX_BMU,
    Eth_43_PFE_IRQ_COUNT
} oal_irq_idx_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* Mapping of interrupt IDs to the indexes */
static inline oal_irq_idx_t find_irq_idx_from_id(sint32 id)
{
    oal_irq_idx_t ret_val;

    switch(id)
    {
        case 190:
            ret_val = Eth_43_PFE_IRQ_IDX_HIF0;
            break;
        case 191:
            ret_val = Eth_43_PFE_IRQ_IDX_HIF1;
            break;
        case 192:
            ret_val = Eth_43_PFE_IRQ_IDX_HIF2;
            break;
        case 193:
            ret_val = Eth_43_PFE_IRQ_IDX_HIF3;
            break;
        case 194:
            ret_val = Eth_43_PFE_IRQ_IDX_BMU;
            break;
        case 195:
            ret_val = Eth_43_PFE_IRQ_IDX_HIFNOCPY;
            break;
        default:
            ret_val = Eth_43_PFE_IRQ_COUNT; /* ERROR */
            break;
    }
    return ret_val;
}

/**
 * @brief       Handle any interrupt
 * @details     This function calls a registered interrupt handler (if any)
 *              that matches the idx argument
 * @param[in]   idx Index of registered interrupt handler to be called,
 */
extern void oal_irq_common_handler(oal_irq_idx_t idx);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* OAL_IRQ_AUTOSAR_H_ */

/** @}*/


===== 文件 [32/185]: include\oal_job.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 *
 * @defgroup    dxgr_OAL_JOB JOB
 * @brief       Deferred job abstraction
 *
 *
 * @addtogroup  dxgr_OAL_JOB
 * @{
 *
 * @file        oal_job.h
 * @brief       The oal_job module header file.
 * @details     This file contains generic deferred job management-related API.
 *
 */

#ifndef PUBLIC_OAL_JOB_H_
#define PUBLIC_OAL_JOB_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "oal_sync.h"

typedef void (* oal_job_func)(void *arg);

typedef struct
{
    oal_job_func   func;
    void           *arg;
    const char_t   *name;
} oal_job_t;

/**
 * @brief   Priority enumeration type
 */
typedef enum
{
    OAL_PRIO_LOW,
    OAL_PRIO_NORMAL,
    OAL_PRIO_HIGH,
    OAL_PRIO_TOP
} oal_prio_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create new job
 * @param[in]   func Function to be executed within the job
 * @param[in]   arg Function argument
 * @param[in]   name The job name in string form
 * @param[in]   prio Job priority
 * @param[in]   new_job New job instance to be initialized
 * @return      New job instance or NULL if failed
 */
oal_job_t *oal_job_create(oal_job_func func, void *arg, const char_t *name, oal_prio_t prio, oal_job_t *new_job);

/**
 * @brief        Trigger job execution
 * @details        Schedule the job. Can be called multiple times to enqueue multiple
 *                 triggers. Is a non-blocking call.
 * @param[in]    job The job instance
 * @return        EOK if success, error code otherwise
 */
errno_t oal_job_run(oal_job_t *job);

/**
 * @brief       Wait until job is done
 * @param[in]   job The job instance
 * @return      EOK if success, error code otherwise
 */
errno_t oal_job_drain(const oal_job_t *job);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_OAL_JOB_H_ */

/** @}*/
/** @}*/


===== 文件 [33/185]: include\oal_master_if.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * 
 * @file        oal_master_if.h
 * @brief       Master/Slave HIF master interface header file
 * @details     Use this header to include all the OS-dependent HIF master interface transparency
 *
 */

#ifndef OAL_MASTER_IF_H_
#define OAL_MASTER_IF_H_

#define OAL_PFE_CFG_MASTER_IF PFE_CFG_MASTER_IF

#endif /* OAL_MASTER_IF_H_ */


===== 文件 [34/185]: include\oal_mutex_autosar.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_OAL_SYNC
 * @{
 *
 * @file        oal_mutex_autosar.h
 * @brief       The AUTOSAR-specific mutex implementation.
 * @details     This file contains AUTOSAR-specific mutex implementation.
 *
 */

#ifndef PUBLIC_OAL_MUTEX_AUTOSAR_H_
#define PUBLIC_OAL_MUTEX_AUTOSAR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "SchM_Eth_43_PFE.h"
#include "oal_types.h"

#define MUTEX_POOL_SIZE      97U

enum
{
    MUTEX_ID_00  = 0,
    MUTEX_ID_01  = 1,
    MUTEX_ID_02  = 2,
    MUTEX_ID_03  = 3,
    MUTEX_ID_04  = 4,
    MUTEX_ID_05  = 5,
    MUTEX_ID_06  = 6,
    MUTEX_ID_07  = 7,
    MUTEX_ID_08  = 8,
    MUTEX_ID_09  = 9,
    MUTEX_ID_10  = 10,
    MUTEX_ID_11  = 11,
    MUTEX_ID_12  = 12,
    MUTEX_ID_13  = 13,
    MUTEX_ID_14  = 14,
    MUTEX_ID_15  = 15,
    MUTEX_ID_16  = 16,
    MUTEX_ID_17  = 17,
    MUTEX_ID_18  = 18,
    MUTEX_ID_19  = 19,
    MUTEX_ID_20  = 20,
    MUTEX_ID_21  = 21,
    MUTEX_ID_22  = 22,
    MUTEX_ID_23  = 23,
    MUTEX_ID_24  = 24,
    MUTEX_ID_25  = 25,
    MUTEX_ID_26  = 26,
    MUTEX_ID_27  = 27,
    MUTEX_ID_28  = 28,
    MUTEX_ID_29  = 29,
    MUTEX_ID_30  = 30,
    MUTEX_ID_31  = 31,
    MUTEX_ID_32  = 32,
    MUTEX_ID_33  = 33,
    MUTEX_ID_34  = 34,
    MUTEX_ID_35  = 35,
    MUTEX_ID_36  = 36,
    MUTEX_ID_37  = 37,
    MUTEX_ID_38  = 38,
    MUTEX_ID_39  = 39,
    MUTEX_ID_40  = 40,
    MUTEX_ID_41  = 41,
    MUTEX_ID_42  = 42,
    MUTEX_ID_43  = 43,
    MUTEX_ID_44  = 44,
    MUTEX_ID_45  = 45,
    MUTEX_ID_46  = 46,
    MUTEX_ID_47  = 47,
    MUTEX_ID_48  = 48,
    MUTEX_ID_49  = 49,
    MUTEX_ID_50  = 50,
    MUTEX_ID_51  = 51,
    MUTEX_ID_52  = 52,
    MUTEX_ID_53  = 53,
    MUTEX_ID_54  = 54,
    MUTEX_ID_55  = 55,
    MUTEX_ID_56  = 56,
    MUTEX_ID_57  = 57,
    MUTEX_ID_58  = 58,
    MUTEX_ID_59  = 59,
    MUTEX_ID_60  = 60,
    MUTEX_ID_61  = 61,
    MUTEX_ID_62  = 62,
    MUTEX_ID_63  = 63,
    MUTEX_ID_64  = 64,
    MUTEX_ID_65  = 65,
    MUTEX_ID_66  = 66,
    MUTEX_ID_67  = 67,
    MUTEX_ID_68  = 68,
    MUTEX_ID_69  = 69,
    MUTEX_ID_70  = 70,
    MUTEX_ID_71  = 71,
    MUTEX_ID_72  = 72,
    MUTEX_ID_73  = 73,
    MUTEX_ID_74  = 74,
    MUTEX_ID_75  = 75,
    MUTEX_ID_76  = 76,
    MUTEX_ID_77  = 77,
    MUTEX_ID_78  = 78,
    MUTEX_ID_79  = 79,
    MUTEX_ID_80  = 80,
    MUTEX_ID_81  = 81,
    MUTEX_ID_82  = 82,
    MUTEX_ID_83  = 83,
    MUTEX_ID_84  = 84,
    MUTEX_ID_85  = 85,
    MUTEX_ID_86  = 86,
    MUTEX_ID_87  = 87,
    MUTEX_ID_88  = 88,
    MUTEX_ID_89  = 89,
    MUTEX_ID_90  = 90,
    MUTEX_ID_91  = 91,
    MUTEX_ID_92  = 92,
    MUTEX_ID_93  = 93,
    MUTEX_ID_94  = 94,
    MUTEX_ID_95  = 95,
    MUTEX_ID_96  = 96
};

typedef enum 
{
    PFE_BLALLOC_MUTEX_00            = MUTEX_ID_00,
    PFE_BLALLOC_MUTEX_01            = MUTEX_ID_01,
    PFE_BLALLOC_MUTEX_03            = MUTEX_ID_02,
    PFE_LOG_IF_MUTEX_00             = MUTEX_ID_03,
    PFE_LOG_IF_MUTEX_01             = MUTEX_ID_04,
    PFE_TX_REQ_QUEUE_WRITE_MUTEX    = MUTEX_ID_05,
    PFE_LOG_IF_MUTEX_03             = MUTEX_ID_06,
    PFE_LOG_IF_MUTEX_04             = MUTEX_ID_07,
    PFE_LOG_IF_MUTEX_05             = MUTEX_ID_08,
    PFE_LOG_IF_MUTEX_06             = MUTEX_ID_09,
    PFE_LOG_IF_MUTEX_09             = MUTEX_ID_10,
    PFE_LOG_IF_MUTEX_10             = MUTEX_ID_11,
    PFE_LOG_IF_MUTEX_11             = MUTEX_ID_12,
    PFE_LOG_IF_MUTEX_12             = MUTEX_ID_13,
    PFE_TS_QUEUE_WRITE_MUTEX        = MUTEX_ID_14,
    PFE_TS_QUEUE_READ_MUTEX         = MUTEX_ID_15,
    PFE_TX_BUFFER_POOL_MUTEX        = MUTEX_ID_16,
    PFE_ETHIF_TXCONFIR_API_MUTEX_00 = MUTEX_ID_17,
    PFE_ETHIF_TXCONFIR_API_MUTEX_01 = MUTEX_ID_18,
    PFE_CLASS_PE_MUTEX_00           = MUTEX_ID_19,
    PFE_CLASS_PE_MUTEX_01           = MUTEX_ID_20,
    PFE_CLASS_PE_MUTEX_02           = MUTEX_ID_21,
    PFE_CLASS_PE_MUTEX_03           = MUTEX_ID_22,
    PFE_CLASS_PE_MUTEX_04           = MUTEX_ID_23,
    PFE_CLASS_PE_MUTEX_06           = MUTEX_ID_24,
    PFE_CLASS_PE_MUTEX_07           = MUTEX_ID_25,
    PFE_UTIL_PE_MUTEX_00            = MUTEX_ID_26,
    PFE_UTIL_PE_MUTEX_01            = MUTEX_ID_27,
    PFE_UTIL_PE_MUTEX_02            = MUTEX_ID_28,
    PFE_UTIL_PE_MUTEX_03            = MUTEX_ID_29,
    PFE_UTIL_PE_MUTEX_05            = MUTEX_ID_30,
    PFE_HIF_PTP_TS_DB_MUTEX_00      = MUTEX_ID_31,
    PFE_HIF_PTP_TS_DB_MUTEX_01      = MUTEX_ID_32,
    PFE_HIF_PTP_TS_DB_MUTEX_02      = MUTEX_ID_33,
    PFE_HIF_PTP_TS_DB_MUTEX_03      = MUTEX_ID_34,
    PFE_HIF_PTP_TS_DB_MUTEX_04      = MUTEX_ID_35,
    PFE_CHNL_LOCK_MUTEX_00          = MUTEX_ID_36,
    PFE_CHNL_LOCK_MUTEX_01          = MUTEX_ID_37,
    PFE_CHNL_LOCK_MUTEX_02          = MUTEX_ID_38,
    PFE_CHNL_LOCK_MUTEX_03          = MUTEX_ID_39,
    PFE_CHNL_LOCK_MUTEX_04          = MUTEX_ID_40,
    PFE_CHNL_LOCK_MUTEX_05          = MUTEX_ID_41,
    PFE_CHNL_LOCK_MUTEX_06          = MUTEX_ID_42,
    PFE_CHNL_LOCK_MUTEX_07          = MUTEX_ID_43,
    PFE_CHNL_LOCK_MUTEX_08          = MUTEX_ID_44,
    PFE_CHNL_LOCK_MUTEX_09          = MUTEX_ID_45,
    PFE_CHNL_LOCK_MUTEX_10          = MUTEX_ID_46,
    PFE_CHNL_LOCK_MUTEX_11          = MUTEX_ID_47,
    PFE_CHNL_LOCK_MUTEX_12          = MUTEX_ID_48,
    PFE_CHNL_RX_LOCK_MUTEX          = MUTEX_ID_49,
    PFE_CHNL_A_LOCK_MUTEX_00        = MUTEX_ID_50,
    PFE_CHNL_A_LOCK_MUTEX_01        = MUTEX_ID_51,
    PFE_EMAC_MUTEX_00               = MUTEX_ID_52,
    PFE_EMAC_MUTEX_01               = MUTEX_ID_53,
    PFE_EMAC_MUTEX_02               = MUTEX_ID_54,
    PFE_EMAC_MUTEX_03               = MUTEX_ID_55,
    PFE_EMAC_TS_MUTEX_00            = MUTEX_ID_56,
    PFE_EMAC_TS_MUTEX_01            = MUTEX_ID_57,
    PFE_EMAC_TS_MUTEX_02            = MUTEX_ID_58,
    PFE_EMAC_TS_MUTEX_03            = MUTEX_ID_59,
    PFE_EMAC_TS_MUTEX_04            = MUTEX_ID_60,
    PFE_EMAC_TS_MUTEX_05            = MUTEX_ID_61,
    PFE_RTABLE_LOCK_MUTEX_00        = MUTEX_ID_62,
    PFE_RTABLE_LOCK_MUTEX_01        = MUTEX_ID_63,
    PFE_RTABLE_LOCK_MUTEX_02        = MUTEX_ID_64,
    PFE_RTABLE_LOCK_MUTEX_03        = MUTEX_ID_65,
    PFE_RTABLE_LOCK_MUTEX_04        = MUTEX_ID_66,
    PFE_RTABLE_LOCK_MUTEX_05        = MUTEX_ID_67,
    PFE_RTABLE_LOCK_MUTEX_06        = MUTEX_ID_68,
    PFE_RTABLE_LOCK_MUTEX_07        = MUTEX_ID_69,
    PFE_RTABLE_LOCK_MUTEX_10        = MUTEX_ID_70,
    PFE_RTABLE_LOCK_MUTEX_11        = MUTEX_ID_71,
    PFE_RTABLE_LOCK_MUTEX_12        = MUTEX_ID_72,
    PFE_RTABLE_LOCK_MUTEX_13        = MUTEX_ID_73,
    PFE_RTABLE_LOCK_MUTEX_14        = MUTEX_ID_74,
    PFE_RTABLE_LOCK_MUTEX_15        = MUTEX_ID_75,
    PFE_IF_DB_CONTEXT_MUTEX_00      = MUTEX_ID_76,
    PFE_IF_DB_CONTEXT_MUTEX_01      = MUTEX_ID_77,
    PFE_IF_DB_CONTEXT_MUTEX_02      = MUTEX_ID_78,
    PFE_IF_DB_CONTEXT_MUTEX_03      = MUTEX_ID_79,
    PFE_IF_DB_CONTEXT_MUTEX_05      = MUTEX_ID_80,
    PFE_IF_DB_CONTEXT_MUTEX_06      = MUTEX_ID_81,
    PFE_IF_DB_CONTEXT_MUTEX_07      = MUTEX_ID_82,
    PFE_HIF_DRV_MUTEX_00            = MUTEX_ID_83,
    PFE_HIF_DRV_MUTEX_01            = MUTEX_ID_84,
    PFE_OAL_UTIL_SEQNUM_MUTEX       = MUTEX_ID_85,
    PFE_HIF_TX_JOB_MUTEX            = MUTEX_ID_86,
    PFE_FCI_FIFO_MUTEX_00           = MUTEX_ID_87,
    PFE_FCI_FIFO_MUTEX_01           = MUTEX_ID_88,
    PFE_FCI_CONTEXT_DB_MUTEX_00     = MUTEX_ID_89,
    PFE_FCI_CONTEXT_DB_MUTEX_01     = MUTEX_ID_90,
    PFE_FCI_OWNER_MUTEX             = MUTEX_ID_91,   /* This mutex cannot be implemented as suspend all interrupts */
    PFE_HM_MUTEX_00                 = MUTEX_ID_92,
    PFE_HM_MUTEX_01                 = MUTEX_ID_93,
    PFE_CLASS_MUTEX_00              = MUTEX_ID_94,
    PFE_CLASS_MUTEX_01              = MUTEX_ID_95,
    PFE_CLASS_MUTEX_02              = MUTEX_ID_96
} oal_mutex_id_t;

typedef oal_mutex_id_t oal_mutex_t;

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/* coverity[misra_c_2012_rule_8_9_violation:FALSE] */
static void (*SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_ID[MUTEX_POOL_SIZE])(void) =
{
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_00]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_00,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_01]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_01,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_02]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_02,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_03]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_03,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_04]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_04,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_05]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_05,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_06]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_06,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_07]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_07,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_08]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_08,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_09]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_09,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_10]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_10,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_11]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_11,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_12]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_12,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_13]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_13,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_14]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_14,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_15]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_15,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_16]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_16,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_17]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_17,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_18]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_18,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_19]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_19,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_20]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_20,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_21]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_21,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_22]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_22,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_23]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_23,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_24]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_24,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_25]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_25,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_26]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_26,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_27]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_27,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_28]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_28,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_29]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_29,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_30]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_30,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_31]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_31,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_32]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_32,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_33]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_33,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_34]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_34,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_35]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_35,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_36]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_36,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_37]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_37,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_38]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_38,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_39]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_39,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_40]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_40,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_41]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_41,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_42]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_42,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_43]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_43,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_44]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_44,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_45]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_45,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_46]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_46,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_47]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_47,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_48]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_48,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_49]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_49,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_50]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_50,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_51]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_51,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_52]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_52,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_53]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_53,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_54]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_54,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_55]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_55,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_56]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_56,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_57]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_57,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_58]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_58,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_59]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_59,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_60]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_60,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_61]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_61,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_62]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_62,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_63]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_63,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_64]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_64,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_65]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_65,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_66]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_66,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_67]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_67,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_68]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_68,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_69]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_69,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_70]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_70,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_71]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_71,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_72]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_72,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_73]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_73,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_74]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_74,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_75]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_75,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_76]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_76,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_77]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_77,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_78]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_78,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_79]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_79,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_80]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_80,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_81]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_81,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_82]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_82,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_83]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_83,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_84]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_84,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_85]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_85,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_86]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_86,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_87]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_87,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_88]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_88,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_89]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_89,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_90]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_90,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_91]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_91,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_92]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_92,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_93]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_93,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_94]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_94,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_95]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_95,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_96]  = SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_96
};

/* coverity[misra_c_2012_rule_8_9_violation:FALSE] */
static void (*SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_ID[MUTEX_POOL_SIZE])(void) =
{
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_00]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_00,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_01]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_01,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_02]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_02,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_03]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_03,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_04]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_04,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_05]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_05,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_06]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_06,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_07]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_07,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_08]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_08,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_09]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_09,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_10]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_10,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_11]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_11,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_12]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_12,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_13]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_13,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_14]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_14,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_15]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_15,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_16]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_16,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_17]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_17,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_18]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_18,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_19]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_19,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_20]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_20,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_21]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_21,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_22]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_22,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_23]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_23,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_24]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_24,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_25]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_25,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_26]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_26,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_27]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_27,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_28]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_28,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_29]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_29,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_30]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_30,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_31]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_31,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_32]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_32,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_33]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_33,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_34]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_34,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_35]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_35,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_36]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_36,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_37]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_37,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_38]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_38,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_39]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_39,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_40]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_40,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_41]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_41,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_42]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_42,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_43]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_43,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_44]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_44,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_45]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_45,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_46]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_46,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_47]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_47,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_48]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_48,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_49]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_49,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_50]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_50,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_51]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_51,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_52]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_52,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_53]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_53,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_54]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_54,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_55]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_55,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_56]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_56,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_57]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_57,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_58]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_58,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_59]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_59,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_60]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_60,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_61]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_61,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_62]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_62,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_63]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_63,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_64]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_64,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_65]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_65,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_66]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_66,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_67]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_67,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_68]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_68,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_69]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_69,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_70]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_70,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_71]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_71,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_72]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_72,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_73]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_73,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_74]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_74,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_75]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_75,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_76]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_76,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_77]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_77,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_78]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_78,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_79]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_79,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_80]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_80,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_81]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_81,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_82]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_82,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_83]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_83,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_84]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_84,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_85]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_85,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_86]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_86,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_87]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_87,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_88]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_88,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_89]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_89,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_90]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_90,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_91]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_91,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_92]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_92,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_93]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_93,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_94]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_94,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_95]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_95,
    /* coverity[misra_c_2012_rule_17_12_violation:FALSE] */
    [MUTEX_ID_96]  = SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_96
};

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/
/* =========================================================================================== */
/*  Implementation continues below to ensure Doxygen will put the API description
    from oal_sync.h at right place (related to oal_sync.h header). */
static inline void oal_mutex_lock(const oal_mutex_t mutex)
{
    if (MUTEX_POOL_SIZE > (uint32) mutex)
    {
        /* coverity[misra_c_2012_rule_5_9_violation:FALSE] */
        SchM_Enter_Eth_43_PFE_ETH_EXCLUSIVE_AREA_ID[mutex]();
    }
    else
    {
        NXP_LOG_RAW_ERROR("Critical development Error !! Invalid mutex id: %u for oal_mutex_lock()\n", (uint_t)mutex);
    }
}

/* =========================================================================================== */
static inline void oal_mutex_unlock(const oal_mutex_t mutex)
{
    if (MUTEX_POOL_SIZE > (uint32) mutex)
    {
        /* coverity[misra_c_2012_rule_5_9_violation:FALSE] */
        SchM_Exit_Eth_43_PFE_ETH_EXCLUSIVE_AREA_ID[mutex]();
    }
    else
    {
        NXP_LOG_RAW_ERROR("Critical development Error !! Invalid mutex id: %u for oal_mutex_unlock()\n", (uint_t)mutex);
    }
}

/* =========================================================================================== */
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_OAL_MUTEX_AUTOSAR_H_ */


===== 文件 [35/185]: include\oal_sync.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 *
 * @defgroup    dxgr_OAL_SYNC SYNC
 * @brief       Thread synchronization
 * @details     Package provides OS-independent thread synchronization primitives. All API should
 *              be implemented with performance taken into account.
 *
 *
 * @addtogroup  dxgr_OAL_SYNC
 * @{
 *
 * @file        oal_sync.h
 * @brief       The thread synchronization header file
 * @details     Use this header to include all the OS-independent thread synchronization functionality
 *
 */

#ifndef OAL_SYNC_H_
#define OAL_SYNC_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*
 * AUTOSAR
 *
 */
#if defined(PFE_CFG_TARGET_OS_AUTOSAR)
#include "oal_mutex_autosar.h"
#include "SchM_Eth_43_PFE.h"

/*
 * BARE METAL
 *
 */
#elif defined(PFE_CFG_TARGET_OS_BARE)
#include "oal_spinlock_bare.h"
#include "oal_mutex_bare.h"

/*
 * unknown OS
 *
 */
#else
#error "PFE_CFG_TARGET_OS_xx was not set!"
#endif /* PFE_CFG_TARGET_OS_xx */

/** @}*/
/** @}*/

#endif /* OAL_SYNC_H_ */


===== 文件 [36/185]: include\oal_time.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 *
 * @defgroup    dxgr_OAL_TIME TIME
 * @brief       Time abstraction
 *
 *
 * @addtogroup  dxgr_OAL_TIME
 * @{
 *
 * @file        oal_time.h
 * @brief       The oal_time module header file.
 * @details     This file contains generic time management-related API.
 *
 */

#ifndef PUBLIC_OAL_TIME_H_
#define PUBLIC_OAL_TIME_H_

#include "oal_types.h"


/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Suspend a thread for a given number of microseconds
 * @param[in]   usec The number of microseconds that you want the process to sleep for
 */
void oal_time_usleep(uint32 usec);

/**
 * @brief       Suspend a thread for a given number of milliseconds
 * @param[in]   msec The number of milliseconds that you want the process to sleep for
 */
void oal_time_msleep(uint32 msec);

void oal_time_udelay(uint32 usec);

void oal_time_mdelay(uint32 msec);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_OAL_TIME_H_ */

/** @}*/
/** @}*/


===== 文件 [37/185]: include\oal_types.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 *
 * @defgroup    dxgr_OAL_TYPES TYPES
 * @brief       Standard types
 * @details
 *
 *
 * @addtogroup  dxgr_OAL_TYPES
 * @{
 *
 * @file        oal_types.h
 * @brief       Header for standard types
 *
 */

#ifndef OAL_TYPES_H_
#define OAL_TYPES_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#include "Platform_Types.h"
#include "Mcal.h"
#include "pfe_cfg.h"

typedef signed int errno_t;
typedef signed int int_t;
typedef unsigned int uint_t;
typedef unsigned char bool_t;
typedef char char_t;
typedef unsigned uaddr_t;
typedef unsigned addr_t;

#if defined(NO_STDINT_H)
    typedef unsigned int uintptr_t;
    #define INT8_MIN -128
    #define INT8_MAX 127
    #define UINT8_MIN 0U
    #define UINT8_MAX 255U
    #define INT16_MIN -32768
    #define INT16_MAX 32767
    #define UINT16_MIN 0U
    #define UINT16_MAX 65535U
    #define INT32_MIN -2147483648L
    #define INT32_MAX 2147483647L
    #define UINT32_MIN 0U
    #define UINT32_MAX 4294967295UL
    #define SIZE_MAX 0xffffffffU
#endif /*defined(NO_STDINT_H)*/

#define PRINT64         "ll"
#define PRINTADDR_T     "x"
#define MAX_ADDR_T_VAL  0xFFFFFFFFUL
#define NULL_ADDR       ((addr_t)0U)
#define UINT_MAX        0xffffffffU

#define EOK 0
#define ENOENT 2
#define EIO 5
#define ENOMEM 11
#define EACCES 13
#define ENODEV 19
#define EINVAL 22
#define ETIME 62
#define EOVERFLOW 75
#define ETIMEDOUT 110
#define EBUSY 111
#define ENXIO 112
#define ENOSPC 113
#define ENOEXEC 114
#define EPERM 115
#define EEXIST 116
#define EFAULT 117
#define EAGAIN 118
#define ENOCLK 119
#define ENOLCK 120
#define ECANCELED 121
#define ENOTSUP 122

#ifndef NULL
#define NULL NULL_PTR
#endif /* NULL */

/* Little endian */
#define oal_htons(a) ((uint16)((((uint16)(a) & 0xFF00U) >> 8) | \
                                 (((uint16)(a) & 0x00FFU) << 8)))
#define oal_htonl(a) ((((uint32)(a) & 0xFF000000U) >> 24) | \
                      (((uint32)(a) & 0x00FF0000U) >> 8 ) | \
                      (((uint32)(a) & 0x0000FF00U) << 8 ) | \
                      (((uint32)(a) & 0x000000FFU) << 24))

#define oal_ntohs(x)    oal_htons(x)
#define oal_ntohl(x)    oal_htonl(x)

#define pu8_to_be16(PU8) ((uint16)(((uint16)(PU8)[0] << 8) & 0xFF00U)                     | (uint16)(PU8)[1])
#define pu8_to_be32(PU8) ((uint32)(((uint32)pu8_to_be16(&(PU8)[0]) << 16) & 0xFFFF0000UL) | (uint32)pu8_to_be16(&(PU8)[2]))

#define pu8_to_le16(PU8) ((uint16)(((uint16)(PU8)[1] << 8) & 0xFF00U)                     | (uint16)(PU8)[0])
#define pu8_to_le32(PU8) ((uint32)(((uint32)pu8_to_le16(&(PU8)[2]) << 16) & 0xFFFF0000UL) | (uint32)pu8_to_le16(&(PU8)[0]))

#define be32_to_cpu(val)    oal_htonl(val)
#define cpu_to_be32(val)    oal_htonl(val)
#define be16_to_cpu(val)    oal_htons(val)
#define cpu_to_be16(val)    oal_htons(val)
#define be64_to_cpu(val) \
        ( \
          ((((uint64)(val)) >> 56) & 0x00000000000000ffULL) | \
          ((((uint64)(val)) >> 40) & 0x000000000000ff00ULL) | \
          ((((uint64)(val)) >> 24) & 0x0000000000ff0000ULL) | \
          ((((uint64)(val)) >> 8 ) & 0x00000000ff000000ULL) | \
          ((uint64)(((uint64)(val)) << 8 ) & 0x000000ff00000000ULL) | \
          ((uint64)(((uint64)(val)) << 24) & 0x0000ff0000000000ULL) | \
          ((uint64)(((uint64)(val)) << 40) & 0x00ff000000000000ULL) | \
          ((uint64)(((uint64)(val)) << 56) & 0xff00000000000000ULL) \
        )
#define cpu_to_be64(val)    be64_to_cpu(val)

#include "ct_assert.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Swap byte order in a buffer
 * @detail      Convert byte order of each 4-byte word within given buffer
 * @param[in]   data Pointer to buffer to be converted
 * @param[in]   size Number of bytes in the buffer
 */
static inline void oal_swap_endian_long(void *data, uint32 size)
{
    uint32 ii, words = size >> 2;
    uint32 *word = (uint32 *)data;

    if (0U != (size & 0x3U))
    {
        words += 1U;
    }

    for (ii=0U; ii<words; ii++)
    {
        word[ii] = oal_htonl(word[ii]);
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* OAL_TYPES_H_ */

/** @}*/
/** @}*/


===== 文件 [38/185]: include\oal_util.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 *
 * @defgroup    dxgr_OAL_UTIL UTIL
 * @brief       Advanced utilities
 *
 *
 * @addtogroup  dxgr_OAL_UTIL
 * @{
 *
 * @file        oal_util.h
 * @brief       The oal_util module header file.
 * @details     This file contains utility management-related API.
 *
 */

#ifndef OAL_UTIL_H_
#define OAL_UTIL_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#if defined(PFE_CFG_TARGET_OS_AUTOSAR)
    #include "oal_util_autosar.h"
#elif defined(PFE_CFG_TARGET_OS_BARE)
    #include "oal_util_bare.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#ifdef PFE_CFG_IEEE1588_SUPPORT
/**
 * @brief   PTP packet header
 */
typedef struct __attribute__((packed))
{
    struct {
        uint8 messageType : 4;
        uint8 transportSpecific : 4;
    } byte1;

    struct {
        uint8 versionPTP : 4;
        uint8 reserved0 : 4;
    } byte2;

    uint16 messageLength;
    uint8 domainNumber;
    uint8 reserved1;
    uint16 flags;
    uint64 correctionField;
    uint32 reserved2;
    uint64 sourcePortIdentity;
    uint16 sourcePortID;
    uint16 sequenceID;
    uint8 controlField;
    uint8 logMessageInterval;
} oal_util_ptp_header_t;
#endif /* PFE_CFG_IEEE1588_SUPPORT */

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#if !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(NXP_LOG_ENABLED)
/**
 * @brief       Modified nxp_snprintf function
 * @details     Function return real number of written data into buffer
 * @details     in case of lack of space fills buffer with warming message.
 * @param[in]   *buffer buffer to write data
 * @param[in]   buf_len buffer length
 * @param[in]   Format input data format (same as printf format)
 * @param[in]   ... variable arguments according to Format
 *
 * @return      Number of bytes written to the buffer
 */
extern uint32 oal_util_snprintf(char_t *buffer, uint32 buf_len, const char_t *format, ...);
#endif /* !defined(PFE_CFG_TARGET_OS_AUTOSAR) || defined(NXP_LOG_ENABLED) */

#ifdef PFE_CFG_IEEE1588_SUPPORT
/**
 * @brief           Parse PTP packet
 * @details         Find out if packet in 'buffer' is PTP packet and if so then fill
 *                  the 'ptph' with parsed values.
 * @param[in]       buffer Pointer to the Ethernet frame
 * @param[in]       len Number of byte in the buffer
 * @param[in,out]   ptph Pointer to memory where parsed PTP header values shall be
 *                       stored
 * @retval          EOK Success, frame is PTP, values in 'ptph' are valid
 * @retval          ENOENT The 'buffer' contains non-PTP frame
 */
errno_t oal_util_parse_ptp(uint8 *buffer, uint32 len, oal_util_ptp_header_t **ptph);

/**
 * @brief       Get unique sequence number
 * @details     System-wide, sequential numbers generator. Each call produces
 *              number incremented by 1 from the previous one. The counter wraps
 *              with 32nd bit.
 * @note        Must be reentrant and thread-safe
 * @return      The number
 */
uint32 oal_util_get_unique_seqnum32(void);
#endif /* PFE_CFG_IEEE1588_SUPPORT */

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#endif /* OAL_UTIL_H_ */

/** @}*/
/** @}*/


===== 文件 [39/185]: include\oal_util_autosar.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL
 * @{
 *
 * @defgroup    dxgr_OAL_UTIL_AUTOSAR UTIL
 * @brief       Advanced utilities, autosar specific file
 *
 *
 * @addtogroup  dxgr_OAL_UTIL_AUTOSAR
 * @{
 *
 * @file        oal_util_autosar.h
 * @brief       The oal_util_autosar module header file.
 * @details     This file contains utility management-related API.
 *
 */

#ifndef OAL_UTIL_AUTOSAR_H_
#define OAL_UTIL_AUTOSAR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "autolibc.h"
#include "nxp_snprintf.h"
#include <stdarg.h>
#include "pfe_hm.h"
#include "ct_assert.h"

#ifdef PFE_DEV_ERROR_DETECT
#define PfeDevAssert(EXPR)  do { if(EXPR) {break;} NXP_LOG_RAW_ERROR("Assertion failed: " STRINGIFY(EXPR) ); while(TRUE){} } while(FALSE)
#else
#define PfeDevAssert(EXPR)  (void)(EXPR)
#endif

#undef offsetof
#define offsetof(structure, curItem) ((uint32)((addr_t)(&(((structure *)NULL)->curItem))))

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

void oal_util_raise_dem_for_drv_runtime_err(void);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* Debug message support */
#ifdef NXP_LOG_ENABLED
    #define __STR_HELPER(x) #x
    #define __STR(x) __STR_HELPER(x)

    #define NXP_LOG_ASR_CFG_LINE_SIZE   256U /* Better be power of 2 */
    #define NXP_LOG_ASR_CFG_LINE_COUNT  256U /* Must be power of 2 */
    #define NXP_LOG_ASR_MASK            (NXP_LOG_ASR_CFG_LINE_COUNT-1U) /* Don't change */

    #define ETH_43_PFE_START_SEC_VAR_CLEARED_8
    #include "Eth_43_PFE_MemMap.h"

    /* Define the variables in the application */
    extern char_t debug_buff[NXP_LOG_ASR_CFG_LINE_COUNT][NXP_LOG_ASR_CFG_LINE_SIZE]; /* Dump to read the messages */

    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_8
    #include "Eth_43_PFE_MemMap.h"

    #define ETH_43_PFE_START_SEC_VAR_CLEARED_32
    #include "Eth_43_PFE_MemMap.h"

    extern uint32 debug_line;

    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_32
    #include "Eth_43_PFE_MemMap.h"

    #define NXP_LOG(...)            do{ uint32 my_line = debug_line; \
                                        debug_line = (uint32)(((uint64)debug_line + 1U) & UINT32_MAX); \
                                        int num = nxp_snprintf(debug_buff[my_line&NXP_LOG_ASR_MASK], \
                                                               NXP_LOG_ASR_CFG_LINE_SIZE, __VA_ARGS__); \
                                        num = (num > (int)(NXP_LOG_ASR_CFG_LINE_SIZE-1U)) ? (int)(NXP_LOG_ASR_CFG_LINE_SIZE-1U) : num; \
                                        num = (num < 0) ? 0 : num; \
                                        autolibc_memset(debug_buff[my_line&NXP_LOG_ASR_MASK]+num, \
                                                        0x20, (uint32)NXP_LOG_ASR_CFG_LINE_SIZE-(uint32)num); \
                                    }while(FALSE)
    #define NXP_LOG_HM(...)         NXP_LOG(__VA_ARGS__)
    #define NXP_LOG_WARNING(...)    NXP_LOG("WRN["__FILE__":"__STR(__LINE__)"] : " __VA_ARGS__)
    #define NXP_LOG_RAW_ERROR(...)  NXP_LOG("ERR["__FILE__":"__STR(__LINE__)"] : " __VA_ARGS__)
    #define NXP_LOG_INFO(...)       NXP_LOG("INF["__FILE__":"__STR(__LINE__)"] : " __VA_ARGS__)
    #define NXP_LOG_DEBUG(...)      NXP_LOG("DBG["__FILE__":"__STR(__LINE__)"] : " __VA_ARGS__)
#else /* not NXP_LOG_ENABLED */
    #define NXP_LOG_WARNING(...)
    #define NXP_LOG_RAW_ERROR(...)
    #define NXP_LOG_INFO(...)
    #define NXP_LOG_DEBUG(...)
#endif /* NXP_LOG_ENABLED */

/* NXP_LOG_ERROR is used to log the driver runtime error to Health Monitor and raise the event to Dem */
#define NXP_LOG_ERROR(...)          do{ pfe_hm_report_error(HM_SRC_DRIVER, HM_EVT_RUNTIME, __VA_ARGS__); \
                                        oal_util_raise_dem_for_drv_runtime_err(); \
                                    }while(FALSE)

#endif /* OAL_UTIL_AUTOSAR_H_ */

/** @}*/
/** @}*/


===== 文件 [40/185]: include\oal_util_net.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrOAL_UTIL
 * @{
 *
 * @defgroup    dxgr_OAL_UTIL_NET NET
 * @brief       Advanced utilities, network subsection
 * @details     Network specific utilities
 *
 *
 * @addtogroup  dxgr_OAL_UTIL_NET
 * @{
 *
 * @file        oal_util_net.h
 * @brief       The oal_util_net module header file.
 * @details     This file contains network specific utilities API.
 *
 */

#ifndef OAL_UTIL_NET_H_
#define OAL_UTIL_NET_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "oal_types.h"
#include "oal_util_net_autosar.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Convert a numeric network address to a string
 * @details     Function return the pointer to the buffer containing
 * @details     the string version of network address, NULL otherwise
 * @param[in]   af The address network family
 * @param[in]   src The numeric network address
 * @param[out]  dst The buffer with string represented the netowrk address
 * @param[in]   size The size of the buffer
 *
 * @return      The pointer the to buffer, NULL if error occured
 */
char_t *oal_util_net_inet_ntop(sint32 af, const void *src, char_t *dst, uint32 size);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* OAL_UTIL_NET_H_ */

/** @}*/
/** @}*/


===== 文件 [41/185]: include\oal_util_net_autosar.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef OAL_UTIL_NET_AUTOSAR_H_
#define OAL_UTIL_NET_AUTOSAR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#define AF_INET         2   /* IP protocol family.  */
#define AF_INET6        10  /* IP version 6.  */
#define EAFNOSUPPORT    97  /* Address family not supported by protocol */

#endif


===== 文件 [42/185]: include\pfe_bmu.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_BMU_H_
#define PUBLIC_PFE_BMU_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#define PFE_BMU_INSTANCES                 2U

typedef struct
{
    uint32 revision;
    uint32 version;
    uint32 id;
    uint32 free_error_cnt;
    uint32 active_buff;
    uint32 buff_size;
}pfe_bmu_stats_special_t;

typedef struct pfe_bmu_tag pfe_bmu_t;
typedef struct
{
    addr_t pool_pa;             /*  Buffer pool base (physical, as seen by PFE). Needs to be aligned to buf_cnt * buf_size. */
    addr_t pool_va;             /*  Buffer pool base (virtual) */
    uint32 max_buf_cnt;       /*  Maximum number of buffers that can be used */
    uint32 buf_size;          /*  Buffer size of each of the buffers allocated and freed (size = 2^buf_size) */
    uint32 bmu_ucast_thres;
    uint32 bmu_mcast_thres;
    uint32 int_mem_loc_cnt;
    uint32 buf_mem_loc_cnt;
} pfe_bmu_cfg_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_bmu_t *pfe_bmu_create(addr_t cbus_base_va, addr_t bmu_base, const pfe_bmu_cfg_t *cfg, uint32 bmu_index) __attribute__((cold));
errno_t pfe_bmu_isr(pfe_bmu_t *bmu) __attribute__((cold));
void pfe_bmu_irq_mask(pfe_bmu_t *bmu);
void pfe_bmu_irq_unmask(pfe_bmu_t *bmu);
void pfe_bmu_enable(pfe_bmu_t *bmu) __attribute__((cold));
void pfe_bmu_reset(pfe_bmu_t *bmu) __attribute__((cold));
void pfe_bmu_disable(pfe_bmu_t *bmu) __attribute__((cold));
void *pfe_bmu_alloc_buf(const pfe_bmu_t *bmu) __attribute__((hot));
void *pfe_bmu_get_va(const pfe_bmu_t *bmu, addr_t pa) __attribute__((hot, pure));
void *pfe_bmu_get_pa(const pfe_bmu_t *bmu, addr_t va) __attribute__((hot, pure));
void pfe_bmu_free_buf(const pfe_bmu_t *bmu, addr_t buffer) __attribute__((hot));

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_bmu_get_text_statistics(const pfe_bmu_t *bmu, char_t *buf, uint32 buf_len, uint8 verb_level) __attribute__((cold));
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_bmu_get_stat_value(const pfe_bmu_t* bmu, uint32 stat_id);
errno_t pfe_bmu_get_special_stats(const pfe_bmu_t* bmu, pfe_bmu_stats_special_t* special_stats);
void pfe_bmu_destroy(pfe_bmu_t *bmu) __attribute__((cold));

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_BMU_H_ */


===== 文件 [43/185]: include\pfe_bmu_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_BMU_CSR_H_
#define PFE_BMU_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_bmu.h"
#include "pfe_cbus.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define BMU_VERSION                 0x000U
#define BMU_CTRL                    0x004U
#define BMU_UCAST_CONFIG            0x008U
#define BMU_UCAST_BASEADDR          0x00cU
#define BMU_BUF_SIZE                0x010U
#define BMU_BUF_CNT                 0x014U
#define BMU_THRES                   0x018U
#define BMU_LOW_WATERMARK           0x050U
#define BMU_HIGH_WATERMARK          0x054U
#define BMU_MCAST_CNT               0x040U
#define BMU_REM_BUF_CNT             0x048U
#define BMU_INT_SRC                 0x020U
#define BMU_INT_ENABLE              0x024U
#define BMU_ALLOC_CTRL              0x030U
#define BMU_FREE_CTRL               0x034U
#define BMU_MCAST_ALLOC_CTRL        0x044U
#define BMU_FREE_ERROR_ADDR         0x038U
#define BMU_CURR_BUF_CNT            0x03cU
#define BMU_MAS0_BUF_CNT            0x060U
#define BMU_MAS1_BUF_CNT            0x064U
#define BMU_MAS2_BUF_CNT            0x068U
#define BMU_MAS3_BUF_CNT            0x06cU
#define BMU_MAS4_BUF_CNT            0x070U
#define BMU_MAS5_BUF_CNT            0x074U
#define BMU_MAS6_BUF_CNT            0x078U
#define BMU_MAS7_BUF_CNT            0x07cU
#define BMU_MAS8_BUF_CNT            0x080U
#define BMU_MAS9_BUF_CNT            0x084U
#define BMU_MAS10_BUF_CNT           0x088U
#define BMU_MAS11_BUF_CNT           0x08cU
#define BMU_MAS12_BUF_CNT           0x090U
#define BMU_MAS13_BUF_CNT           0x094U
#define BMU_MAS14_BUF_CNT           0x098U
#define BMU_MAS15_BUF_CNT           0x09cU
#define BMU_MAS16_BUF_CNT           0x0a0U
#define BMU_MAS17_BUF_CNT           0x0a4U
#define BMU_MAS18_BUF_CNT           0x0a8U
#define BMU_MAS19_BUF_CNT           0x0acU
#define BMU_MAS20_BUF_CNT           0x0b0U
#define BMU_MAS21_BUF_CNT           0x0b4U
#define BMU_MAS22_BUF_CNT           0x0b8U
#define BMU_MAS23_BUF_CNT           0x0bcU
#define BMU_MAS24_BUF_CNT           0x0c0U
#define BMU_MAS25_BUF_CNT           0x0c4U
#define BMU_MAS26_BUF_CNT           0x0c8U
#define BMU_MAS27_BUF_CNT           0x0ccU
#define BMU_MAS28_BUF_CNT           0x0d0U
#define BMU_MAS29_BUF_CNT           0x0d4U
#define BMU_MAS30_BUF_CNT           0x0d8U
#define BMU_MAS31_BUF_CNT           0x0dcU
#define BMU_DEBUG_BUS               0x0e0U
#define BMU_INT_MEM_ACCESS          0x100U
#define BMU_INT_MEM_ACCESS2         0x104U
#define BMU_INT_MEM_ACCESS_ADDR     0x108U
#define BMU_BUF_CNT_MEM_ACCESS      0x10cU
#define BMU_BUF_CNT_MEM_ACCESS2     0x110U
#define BMU_BUF_CNT_MEM_ACCESS_ADDR 0x114U

#define BMU_INT                     (1UL << 0U)
#define BMU_EMPTY_INT               (1UL << 1U)
#define BMU_FULL_INT                (1UL << 2U)
#define BMU_THRES_INT               (1UL << 3U)
#define BMU_FREE_ERR_INT            (1UL << 4U)
#define BMU_MCAST_EMPTY_INT         (1UL << 5U)
#define BMU_MCAST_FULL_INT          (1UL << 6U)
#define BMU_MCAST_THRES_INT         (1UL << 7U)
#define BMU_MCAST_FREE_ERR_INT      (1UL << 8U)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_bmu_cfg_isr(addr_t base_va, addr_t cbus_base_va);
 void pfe_bmu_cfg_irq_mask(addr_t base_va);
 void pfe_bmu_cfg_irq_unmask(addr_t base_va);
void pfe_bmu_cfg_init(addr_t base_va, const pfe_bmu_cfg_t *cfg);
void pfe_bmu_cfg_fini(addr_t base_va);
errno_t pfe_bmu_cfg_reset(addr_t base_va);
void pfe_bmu_cfg_enable(addr_t base_va);
void pfe_bmu_cfg_disable(addr_t base_va);
void * pfe_bmu_cfg_alloc_buf(addr_t base_va);
void pfe_bmu_cfg_free_buf(addr_t base_va, addr_t buffer);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_bmu_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_bmu_cfg_get_stat_value(addr_t base_va, uint32 stat_id);
void pfe_bmu_cfg_get_special_stats(addr_t base_va, pfe_bmu_stats_special_t* special_stats);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_BMU_CSR_H_ */


===== 文件 [44/185]: include\pfe_bus_err.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_BUS_ERR_H_
#define PUBLIC_PFE_BUS_ERR_H_

typedef struct pfe_bus_err_tag pfe_bus_err_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_bus_err_t *pfe_bus_err_create(addr_t cbus_base_va, addr_t bus_err_base);
void pfe_bus_err_destroy(pfe_bus_err_t *bus_err);
errno_t pfe_bus_err_isr(const pfe_bus_err_t *bus_err);
void pfe_bus_err_irq_mask(const pfe_bus_err_t *bus_err);
void pfe_bus_err_irq_unmask(const pfe_bus_err_t *bus_err);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_BUS_ERR_H_ */


===== 文件 [45/185]: include\pfe_bus_err_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_BUS_ERR_CSR_H_
#define PFE_BUS_ERR_CSR_H_

#include "pfe_bus_err.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_bus_err_cfg_isr(addr_t base_va);
void pfe_bus_err_cfg_irq_mask(addr_t base_va);
void pfe_bus_err_cfg_irq_unmask(addr_t base_va);
void pfe_bus_err_cfg_irq_unmask_all(addr_t base_va);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_BUS_ERR_CSR_H_ */


===== 文件 [46/185]: include\pfe_cbus.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_CBUS_H_
#define PFE_CBUS_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#define CBUS_EMAC1_BASE_ADDR        (0xA0000U)
#define CBUS_EGPI1_BASE_ADDR        (0xAC000U)
#define CBUS_ETGPI1_BASE_ADDR       (0xB8000U)
#define CBUS_EMAC2_BASE_ADDR        (0xA4000U)
#define CBUS_EGPI2_BASE_ADDR        (0xB0000U)
#define CBUS_ETGPI2_BASE_ADDR       (0xBC000U)
#define CBUS_EMAC3_BASE_ADDR        (0xA8000U)
#define CBUS_EGPI3_BASE_ADDR        (0xB4000U)
#define CBUS_ETGPI3_BASE_ADDR       (0xC0000U)
#define CBUS_BMU1_BASE_ADDR         (0x88000U)
#define CBUS_BMU2_BASE_ADDR         (0x8C000U)
#define CBUS_HIF_BASE_ADDR          (0x98000U)
#define CBUS_HGPI_BASE_ADDR         (0x9C000U)
#define CBUS_LMEM_BASE_ADDR         (0x00000U)
#define CBUS_LMEM_SIZE              (0x20000U)
#define CBUS_LMEM_END               (LMEM_BASE_ADDR + LMEM_SIZE - 1U)
#define CBUS_TMU_CSR_BASE_ADDR      (0x80000U)
#define CBUS_CLASS_CSR_BASE_ADDR    (0x90000U)
#define CBUS_HIF_NOCPY_BASE_ADDR    (0xD0000U)
#define CBUS_UTIL_CSR_BASE_ADDR     (0xCC000U)
#define CBUS_GLOBAL_CSR_BASE_ADDR   (0x94000U)

#define PFE_CORE_DISABLE            0x00000000U
#define PFE_CORE_ENABLE             0x00000001U
#define PFE_CORE_SW_RESET           0x00000002U

#endif /* PFE_CBUS_H_ */


===== 文件 [47/185]: include\pfe_class.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_CLASS_H_
#define PFE_CLASS_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_ct.h"
#include "pfe_ct_comp.h"
#include "pfe_fw_feature.h"

typedef struct pfe_classifier_tag pfe_class_t;

typedef struct
{
    bool_t resume;                  /*  Resume flag */
    bool_t toe_mode;                /*  TCP offload mode */
    uint32 pe_sys_clk_ratio;      /*  Clock mode ratio for sys_clk and pe_clk */
    uint32 pkt_parse_offset;      /*  Offset which says from which point packet needs to be parsed */
    void * route_table_base_pa;     /*  Route table physical address */
    void * route_table_base_va;     /*  Route table virtual address */
    uint32 route_entry_size;      /*  Route entry size */
    uint32 route_hash_size;       /*  Route hash size (bits) */
    void * ddr_base_va;             /*  DDR region base address (virtual) */
    void * ddr_base_pa;             /*  DDR region base address (physical) */
    uint32 ddr_size;              /*  Size of the DDR region */
    uint16 lmem_header_size;
    uint16 ro_header_size;
    bool_t g2_ordered_class_writes;
} pfe_class_cfg_t;


#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_class_t *pfe_class_create(addr_t cbus_base_va, uint32 pe_num, const pfe_class_cfg_t *cfg);
errno_t pfe_class_isr(pfe_class_t *class);
void pfe_class_irq_mask(const pfe_class_t *class);
void pfe_class_irq_unmask(const pfe_class_t *class);
void pfe_class_enable(pfe_class_t *class);
void pfe_class_reset(pfe_class_t *class);
void pfe_class_disable(pfe_class_t *class);
errno_t pfe_class_load_firmware(pfe_class_t *class, const void *elf);
errno_t pfe_class_get_mmap(pfe_class_t *class, sint32 pe_idx, pfe_ct_class_mmap_t *mmap);
errno_t pfe_class_write_dmem(void *class_p, sint32 pe_idx, addr_t dst_addr, const void *src_ptr, uint32 len);
errno_t pfe_class_read_dmem(void *class_p, sint32 pe_idx, void *dst_ptr, addr_t src_addr, uint32 len);
errno_t pfe_class_gather_read_dmem(pfe_class_t *class, void *dst_ptr, addr_t src_addr, uint32 buffer_len, uint32 read_len);
errno_t pfe_class_set_rtable(pfe_class_t *class, addr_t rtable_pa, uint32 rtable_len, uint32 entry_size);
errno_t pfe_class_set_default_vlan(const pfe_class_t *class, uint16 vlan);
uint32 pfe_class_get_num_of_pes(const pfe_class_t *class);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_class_fp_stat_to_str(const pfe_ct_class_flexi_parser_stats_t *stat, char *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

void pfe_class_destroy(pfe_class_t *class);
addr_t pfe_class_dmem_heap_alloc(const pfe_class_t *class, uint32 size);
void pfe_class_dmem_heap_free(const pfe_class_t *class, addr_t addr);
errno_t pfe_class_put_data(pfe_class_t *class, pfe_ct_buffer_t *buf);
errno_t pfe_class_get_fw_version(const pfe_class_t *class, pfe_ct_version_t *ver);

errno_t pfe_class_get_feature_first(pfe_class_t *class, pfe_fw_feature_t **feature);
errno_t pfe_class_get_feature_next(pfe_class_t *class, pfe_fw_feature_t **feature);
errno_t pfe_class_get_feature(pfe_class_t *class, pfe_fw_feature_t **feature, const char *name);

void pfe_class_flexi_parser_stats_endian(pfe_ct_class_flexi_parser_stats_t *stats);
void pfe_class_sum_flexi_parser_stats(pfe_ct_class_flexi_parser_stats_t *sum, const pfe_ct_class_flexi_parser_stats_t *val);
errno_t pfe_class_get_stats(pfe_class_t *class, pfe_ct_classify_stats_t *stat);
void pfe_class_rtable_lookup_enable(const pfe_class_t *class);
void pfe_class_rtable_lookup_disable(const pfe_class_t *class);
void pfe_class_update_hw_bridge_lookup(pfe_class_t *class, uint32 if_bitmap, bool_t br_mode);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CLASS_H_ */


===== 文件 [48/185]: include\pfe_class_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2015-2016 Freescale Semiconductor, Inc.
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_CLASS_CSR_H_
#define PFE_CLASS_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_class.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define CLASS_VERSION               (CBUS_CLASS_CSR_BASE_ADDR + 0x000U)
#define CLASS_TX_CTRL               (CBUS_CLASS_CSR_BASE_ADDR + 0x004U)
#define CLASS_INQ_PKTPTR            (CBUS_CLASS_CSR_BASE_ADDR + 0x010U)
#define CLASS_HDR_SIZE              (CBUS_CLASS_CSR_BASE_ADDR + 0x014U)
#define CLASS_PE0_QB_DM_ADDR0       (CBUS_CLASS_CSR_BASE_ADDR + 0x020U)
#define CLASS_PE0_QB_DM_ADDR1       (CBUS_CLASS_CSR_BASE_ADDR + 0x024U)
#define CLASS_PE0_RO_DM_ADDR0       (CBUS_CLASS_CSR_BASE_ADDR + 0x060U)
#define CLASS_PE0_RO_DM_ADDR1       (CBUS_CLASS_CSR_BASE_ADDR + 0x064U)
#define CLASS_MEM_ACCESS_ADDR       (CBUS_CLASS_CSR_BASE_ADDR + 0x100U)
#define CLASS_MEM_ACCESS_WDATA      (CBUS_CLASS_CSR_BASE_ADDR + 0x104U)
#define CLASS_MEM_ACCESS_RDATA      (CBUS_CLASS_CSR_BASE_ADDR + 0x108U)
#define CLASS_TM_INQ_ADDR           (CBUS_CLASS_CSR_BASE_ADDR + 0x114U)
#define CLASS_PE_STATUS             (CBUS_CLASS_CSR_BASE_ADDR + 0x118U)
#define CLASS_PHY1_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x11cU)
#define CLASS_PHY1_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x120U)
#define CLASS_PHY1_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x124U)
#define CLASS_PHY1_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x128U)
#define CLASS_PHY1_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x12cU)
#define CLASS_PHY1_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x130U)
#define CLASS_PHY1_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x134U)
#define CLASS_PHY1_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x138U)
#define CLASS_PHY1_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x13cU)
#define CLASS_PHY1_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x140U)
#define CLASS_PHY2_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x144U)
#define CLASS_PHY2_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x148U)
#define CLASS_PHY2_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x14cU)
#define CLASS_PHY2_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x150U)
#define CLASS_PHY2_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x154U)
#define CLASS_PHY2_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x158U)
#define CLASS_PHY2_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x15cU)
#define CLASS_PHY2_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x160U)
#define CLASS_PHY2_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x164U)
#define CLASS_PHY2_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x168U)
#define CLASS_PHY3_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x16cU)
#define CLASS_PHY3_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x170U)
#define CLASS_PHY3_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x174U)
#define CLASS_PHY3_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x178U)
#define CLASS_PHY3_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x17cU)
#define CLASS_PHY3_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x180U)
#define CLASS_PHY3_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x184U)
#define CLASS_PHY3_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x188U)
#define CLASS_PHY3_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x18cU)
#define CLASS_PHY3_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x190U)
#define CLASS_PHY1_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x194U)
#define CLASS_PHY1_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x198U)
#define CLASS_PHY1_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x19cU)
#define CLASS_PHY1_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x1a0U)
#define CLASS_PHY2_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x1a4U)
#define CLASS_PHY2_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x1a8U)
#define CLASS_PHY2_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x1acU)
#define CLASS_PHY2_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x1b0U)
#define CLASS_PHY3_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x1b4U)
#define CLASS_PHY3_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x1b8U)
#define CLASS_PHY3_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x1bcU)
#define CLASS_PHY3_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x1c0U)
#define CLASS_PHY4_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x1c4U)
#define CLASS_PHY4_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x1c8U)
#define CLASS_PHY4_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x1ccU)
#define CLASS_PHY4_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x1d0U)
#define CLASS_PHY4_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x1d4U)
#define CLASS_PHY4_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x1d8U)
#define CLASS_PHY4_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x1dcU)
#define CLASS_PHY4_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x1e0U)
#define CLASS_PHY4_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x1e4U)
#define CLASS_PHY4_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x1e8U)
#define CLASS_PHY4_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x1ecU)
#define CLASS_PHY4_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x1f0U)
#define CLASS_PHY4_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x1f4U)
#define CLASS_PHY4_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x1f8U)
#define CLASS_PE_SYS_CLK_RATIO      (CBUS_CLASS_CSR_BASE_ADDR + 0x200U)
#define CLASS_AFULL_THRES           (CBUS_CLASS_CSR_BASE_ADDR + 0x204U)
#define CLASS_GAP_BETWEEN_READS     (CBUS_CLASS_CSR_BASE_ADDR + 0x208U)
#define CLASS_MAX_BUF_CNT           (CBUS_CLASS_CSR_BASE_ADDR + 0x20cU)
#define CLASS_TSQ_FIFO_THRES        (CBUS_CLASS_CSR_BASE_ADDR + 0x210U)
#define CLASS_TSQ_MAX_CNT           (CBUS_CLASS_CSR_BASE_ADDR + 0x214U)
#define CLASS_IRAM_DATA_0           (CBUS_CLASS_CSR_BASE_ADDR + 0x218U)
#define CLASS_IRAM_DATA_1           (CBUS_CLASS_CSR_BASE_ADDR + 0x21cU)
#define CLASS_IRAM_DATA_2           (CBUS_CLASS_CSR_BASE_ADDR + 0x220U)
#define CLASS_IRAM_DATA_3           (CBUS_CLASS_CSR_BASE_ADDR + 0x224U)
#define CLASS_BUS_ACCESS_ADDR       (CBUS_CLASS_CSR_BASE_ADDR + 0x228U)
#define CLASS_BUS_ACCESS_WDATA      (CBUS_CLASS_CSR_BASE_ADDR + 0x22cU)
#define CLASS_BUS_ACCESS_RDATA      (CBUS_CLASS_CSR_BASE_ADDR + 0x230U)
#define CLASS_ROUTE_HASH_ENTRY_SIZE (CBUS_CLASS_CSR_BASE_ADDR + 0x234U)
#define ROUTE_ENTRY_SIZE(size)      ((size) & 0x3ffU)
#define ROUTE_HASH_SIZE(hash_bits)  (((uint32)(hash_bits) & 0xffUL) << 16U)
#define CLASS_ROUTE_TABLE_BASE      (CBUS_CLASS_CSR_BASE_ADDR + 0x238U)
#define CLASS_ROUTE_MULTI           (CBUS_CLASS_CSR_BASE_ADDR + 0x23cU)
#define CLASS_SMEM_OFFSET           (CBUS_CLASS_CSR_BASE_ADDR + 0x240U)
#define CLASS_LMEM_BUF_SIZE         (CBUS_CLASS_CSR_BASE_ADDR + 0x244U)
#define CLASS_VLAN_ID               (CBUS_CLASS_CSR_BASE_ADDR + 0x248U)
#define CLASS_BMU1_BUF_FREE         (CBUS_CLASS_CSR_BASE_ADDR + 0x24cU)
#define CLASS_USE_TMU_INQ           (CBUS_CLASS_CSR_BASE_ADDR + 0x250U)
#define CLASS_VLAN_ID1              (CBUS_CLASS_CSR_BASE_ADDR + 0x254U)
#define CLASS_BUS_ACCESS_BASE       (CBUS_CLASS_CSR_BASE_ADDR + 0x258U)
#define CLASS_HIF_PARSE             (CBUS_CLASS_CSR_BASE_ADDR + 0x25cU)
#define CLASS_HOST_PE0_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x260U)
#define CLASS_PE0_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x264U)
#define CLASS_HOST_PE1_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x268U)
#define CLASS_PE1_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x26cU)
#define CLASS_HOST_PE2_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x270U)
#define CLASS_PE2_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x274U)
#define CLASS_HOST_PE3_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x278U)
#define CLASS_PE3_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x27cU)
#define CLASS_HOST_PE4_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x280U)
#define CLASS_PE4_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x284U)
#define CLASS_HOST_PE5_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x288U)
#define CLASS_PE5_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x28cU)
#define CLASS_PE_INT_SRC            (CBUS_CLASS_CSR_BASE_ADDR + 0x290U)
#define CLASS_PE_INT_ENABLE         (CBUS_CLASS_CSR_BASE_ADDR + 0x294U)
#define CLASS_TPID0_TPID1           (CBUS_CLASS_CSR_BASE_ADDR + 0x298U)
#define CLASS_TPID2                 (CBUS_CLASS_CSR_BASE_ADDR + 0x29cU)
#define CLASS_L4_CHKSUM             (CBUS_CLASS_CSR_BASE_ADDR + 0x2a0U)
#define CLASS_PE0_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2a4U)
#define CLASS_PE1_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2a8U)
#define CLASS_PE2_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2acU)
#define CLASS_PE3_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2b0U)
#define CLASS_PE4_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2b4U)
#define CLASS_PE5_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2b8U)
#define CLASS_STATE                 (CBUS_CLASS_CSR_BASE_ADDR + 0x2bcU)
#define CLASS_QB_BUF_AVAIL          (CBUS_CLASS_CSR_BASE_ADDR + 0x2c0U)
#define CLASS_RO_BUF_AVAIL          (CBUS_CLASS_CSR_BASE_ADDR + 0x2c4U)
#define CLASS_PE6_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2c8U)
#define CLASS_PE7_DEBUG             (CBUS_CLASS_CSR_BASE_ADDR + 0x2ccU)
#define CLASS_HOST_PE6_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x2d0U)
#define CLASS_PE6_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x2d4U)
#define CLASS_HOST_PE7_GP           (CBUS_CLASS_CSR_BASE_ADDR + 0x2d8U)
#define CLASS_PE7_GP                (CBUS_CLASS_CSR_BASE_ADDR + 0x2dcU)
#define CLASS_DOS_CONTRL1           (CBUS_CLASS_CSR_BASE_ADDR + 0x2e0U)
#define CLASS_DOS_CONTRL2           (CBUS_CLASS_CSR_BASE_ADDR + 0x2e4U)
#define CLASS_DOS_TCP_FLAGCHK_COMB_VALUE1   (CBUS_CLASS_CSR_BASE_ADDR + 0x2e8U)
#define CLASS_DOS_ICMPV4_MAX_PKTLEN (CBUS_CLASS_CSR_BASE_ADDR + 0x2ecU)
#define CLASS_INQ_AFULL_THRES       (CBUS_CLASS_CSR_BASE_ADDR + 0x2f0U)
#define CLASS_DMEM_BRS_OFFSET       (CBUS_CLASS_CSR_BASE_ADDR + 0x2f4U)
#define CLASS_PHY5_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x300U)
#define CLASS_PHY5_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x304U)
#define CLASS_PHY5_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x308U)
#define CLASS_PHY5_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x30cU)
#define CLASS_PHY5_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x310U)
#define CLASS_PHY5_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x314U)
#define CLASS_PHY5_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x318U)
#define CLASS_PHY5_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x31cU)
#define CLASS_PHY5_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x320U)
#define CLASS_PHY5_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x324U)
#define CLASS_PHY5_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x328U)
#define CLASS_PHY5_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x32cU)
#define CLASS_PHY5_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x330U)
#define CLASS_PHY5_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x334U)
#define CLASS_PHY6_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x340U)
#define CLASS_PHY6_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x344U)
#define CLASS_PHY6_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x348U)
#define CLASS_PHY6_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x34cU)
#define CLASS_PHY6_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x350U)
#define CLASS_PHY6_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x354U)
#define CLASS_PHY6_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x358U)
#define CLASS_PHY6_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x35cU)
#define CLASS_PHY6_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x360U)
#define CLASS_PHY6_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x364U)
#define CLASS_PHY6_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x368U)
#define CLASS_PHY6_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x36cU)
#define CLASS_PHY6_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x370U)
#define CLASS_PHY6_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x374U)
#define CLASS_PHY7_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x380U)
#define CLASS_PHY7_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x384U)
#define CLASS_PHY7_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x388U)
#define CLASS_PHY7_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x38cU)
#define CLASS_PHY7_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x390U)
#define CLASS_PHY7_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x394U)
#define CLASS_PHY7_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x398U)
#define CLASS_PHY7_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x39cU)
#define CLASS_PHY7_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x3a0U)
#define CLASS_PHY7_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x3a4U)
#define CLASS_PHY7_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x3a8U)
#define CLASS_PHY7_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x3acU)
#define CLASS_PHY7_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x3b0U)
#define CLASS_PHY7_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x3b4U)
#define CLASS_PHY8_RX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x3c0U)
#define CLASS_PHY8_TX_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x3c4U)
#define CLASS_PHY8_LP_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x3c8U)
#define CLASS_PHY8_INTF_FAIL_PKTS   (CBUS_CLASS_CSR_BASE_ADDR + 0x3ccU)
#define CLASS_PHY8_INTF_MATCH_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x3d0U)
#define CLASS_PHY8_L3_FAIL_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x3d4U)
#define CLASS_PHY8_V4_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x3d8U)
#define CLASS_PHY8_V6_PKTS          (CBUS_CLASS_CSR_BASE_ADDR + 0x3dcU)
#define CLASS_PHY8_CHKSUM_ERR_PKTS  (CBUS_CLASS_CSR_BASE_ADDR + 0x3e0U)
#define CLASS_PHY8_TTL_ERR_PKTS     (CBUS_CLASS_CSR_BASE_ADDR + 0x3e4U)
#define CLASS_PHY8_ICMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x3e8U)
#define CLASS_PHY8_IGMP_PKTS        (CBUS_CLASS_CSR_BASE_ADDR + 0x3ecU)
#define CLASS_PHY8_TCP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x3f0U)
#define CLASS_PHY8_UDP_PKTS         (CBUS_CLASS_CSR_BASE_ADDR + 0x3f4U)
#define CLASS_SNOOP_SPL_MCAST_ADDR1_LSB (CBUS_CLASS_CSR_BASE_ADDR + 0x3f8U)
#define CLASS_SNOOP_SPL_MCAST_ADDR1_MSB (CBUS_CLASS_CSR_BASE_ADDR + 0x3fcU)
#define CLASS_SNOOP_SPL_MCAST_ADDR2_LSB (CBUS_CLASS_CSR_BASE_ADDR + 0x400U)
#define CLASS_SNOOP_SPL_MCAST_ADDR2_MSB (CBUS_CLASS_CSR_BASE_ADDR + 0x404U)
#define CLASS_SNOOP_SPL_MCAST_MASK1_LSB (CBUS_CLASS_CSR_BASE_ADDR + 0x408U)
#define CLASS_SNOOP_SPL_MCAST_MASK1_MSB (CBUS_CLASS_CSR_BASE_ADDR + 0x40cU)
#define CLASS_SNOOP_SPL_MCAST_MASK2_LSB (CBUS_CLASS_CSR_BASE_ADDR + 0x410U)
#define CLASS_SNOOP_SPL_MCAST_MASK2_MSB (CBUS_CLASS_CSR_BASE_ADDR + 0x414U)

#define CLASS_LMEM_DATA_OFFSET              (CBUS_CLASS_CSR_BASE_ADDR + 0x418U)
#define CLASS_BCAST_PORTMAP                 (CBUS_CLASS_CSR_BASE_ADDR + 0x41cU)
#define CLASS_DAMACHASH_HOST_CMD_REG        (CBUS_CLASS_CSR_BASE_ADDR + 0x420U)
#define CLASS_DAMACHASH_HOST_MAC_ADDR1_REG  (CBUS_CLASS_CSR_BASE_ADDR + 0x424U)
#define CLASS_DAMACHASH_HOST_MAC_ADDR2_REG  (CBUS_CLASS_CSR_BASE_ADDR + 0x428U)
#define CLASS_DAMACHASH_HOST_MAC_ADDR3_REG  (CBUS_CLASS_CSR_BASE_ADDR + 0x42cU)
#define CLASS_DAMACHASH_HOST_MAC_ADDR4_REG  (CBUS_CLASS_CSR_BASE_ADDR + 0x430U)
#define CLASS_DAMACHASH_HOST_MAC_ADDR5_REG  (CBUS_CLASS_CSR_BASE_ADDR + 0x434U)
#define CLASS_DAMACHASH_HOST_ENTRY_REG      (CBUS_CLASS_CSR_BASE_ADDR + 0x438U)
#define CLASS_DAMACHASH_HOST_STATUS_REG     (CBUS_CLASS_CSR_BASE_ADDR + 0x43cU)
#define CLASS_DAMACHASH_HOST_DIRECT         (CBUS_CLASS_CSR_BASE_ADDR + 0x440U)
#define CLASS_DAMACHASH_PE_CMD_REG          (CBUS_CLASS_CSR_BASE_ADDR + 0x444U)
#define CLASS_DAMACHASH_PE_MAC_ADDR1_REG    (CBUS_CLASS_CSR_BASE_ADDR + 0x448U)
#define CLASS_DAMACHASH_PE_MAC_ADDR2_REG    (CBUS_CLASS_CSR_BASE_ADDR + 0x44cU)
#define CLASS_DAMACHASH_PE_MAC_ADDR3_REG    (CBUS_CLASS_CSR_BASE_ADDR + 0x450U)
#define CLASS_DAMACHASH_PE_MAC_ADDR4_REG    (CBUS_CLASS_CSR_BASE_ADDR + 0x454U)
#define CLASS_DAMACHASH_PE_MAC_ADDR5_REG    (CBUS_CLASS_CSR_BASE_ADDR + 0x458U)
#define CLASS_DAMACHASH_PE_ENTRY_REG        (CBUS_CLASS_CSR_BASE_ADDR + 0x45cU)
#define CLASS_DAMACHASH_PE_STATUS_REG       (CBUS_CLASS_CSR_BASE_ADDR + 0x460U)
#define CLASS_DAMACHASH_PE_DIRECT           (CBUS_CLASS_CSR_BASE_ADDR + 0x464U)
#define CLASS_DAMACHASH_FREELIST_ENTRIES    (CBUS_CLASS_CSR_BASE_ADDR + 0x468U)
#define CLASS_DAMACHASH_FREELIST_HEAD_PTR   (CBUS_CLASS_CSR_BASE_ADDR + 0x46cU)
#define CLASS_DAMACHASH_FREELIST_TAIL_PTR   (CBUS_CLASS_CSR_BASE_ADDR + 0x470U)
#define CLASS_DAVLANHASH_HOST_CMD_REG       (CBUS_CLASS_CSR_BASE_ADDR + 0x474U)
#define CLASS_DAVLANHASH_HOST_MAC_ADDR1_REG (CBUS_CLASS_CSR_BASE_ADDR + 0x478U)
#define CLASS_DAVLANHASH_HOST_MAC_ADDR2_REG (CBUS_CLASS_CSR_BASE_ADDR + 0x47cU)
#define CLASS_DAVLANHASH_HOST_MAC_ADDR3_REG (CBUS_CLASS_CSR_BASE_ADDR + 0x480U)
#define CLASS_DAVLANHASH_HOST_MAC_ADDR4_REG (CBUS_CLASS_CSR_BASE_ADDR + 0x484U)
#define CLASS_DAVLANHASH_HOST_MAC_ADDR5_REG (CBUS_CLASS_CSR_BASE_ADDR + 0x488U)
#define CLASS_DAVLANHASH_HOST_ENTRY_REG     (CBUS_CLASS_CSR_BASE_ADDR + 0x48cU)
#define CLASS_DAVLANHASH_HOST_STATUS_REG    (CBUS_CLASS_CSR_BASE_ADDR + 0x490U)
#define CLASS_DAVLANHASH_HOST_DIRECT        (CBUS_CLASS_CSR_BASE_ADDR + 0x494U)
#define CLASS_DAVLANHASH_PE_CMD_REG         (CBUS_CLASS_CSR_BASE_ADDR + 0x498U)
#define CLASS_DAVLANHASH_PE_MAC_ADDR1_REG   (CBUS_CLASS_CSR_BASE_ADDR + 0x49cU)
#define CLASS_DAVLANHASH_PE_MAC_ADDR2_REG   (CBUS_CLASS_CSR_BASE_ADDR + 0x4a0U)
#define CLASS_DAVLANHASH_PE_MAC_ADDR3_REG   (CBUS_CLASS_CSR_BASE_ADDR + 0x4a4U)
#define CLASS_DAVLANHASH_PE_MAC_ADDR4_REG   (CBUS_CLASS_CSR_BASE_ADDR + 0x4a8U)
#define CLASS_DAVLANHASH_PE_MAC_ADDR5_REG   (CBUS_CLASS_CSR_BASE_ADDR + 0x4acU)
#define CLASS_DAVLANHASH_PE_ENTRY_REG       (CBUS_CLASS_CSR_BASE_ADDR + 0x4b0U)
#define CLASS_DAVLANHASH_PE_STATUS_REG      (CBUS_CLASS_CSR_BASE_ADDR + 0x4b4U)
#define CLASS_DAVLANHASH_PE_DIRECT          (CBUS_CLASS_CSR_BASE_ADDR + 0x4b8U)
#define CLASS_DAVLANHASH_FREELIST_ENTRIES   (CBUS_CLASS_CSR_BASE_ADDR + 0x4bcU)
#define CLASS_DAVLANHASH_FREELIST_HEAD_PTR  (CBUS_CLASS_CSR_BASE_ADDR + 0x4c0U)
#define CLASS_DAVLANHASH_FREELIST_TAIL_PTR  (CBUS_CLASS_CSR_BASE_ADDR + 0x4c4U)
#define CLASS_SNOOP_SPL_ETYPE_REG01     (CBUS_CLASS_CSR_BASE_ADDR + 0x4c8U)
#define CLASS_SNOOP_SPL_ETYPE_REG23     (CBUS_CLASS_CSR_BASE_ADDR + 0x4ccU)
#define CLASS_SNOOP_CONTROL             (CBUS_CLASS_CSR_BASE_ADDR + 0x4d0U)

#define CLASS_TPID_EN                   (CBUS_CLASS_CSR_BASE_ADDR + 0x4d4U)
#define CLASS_STPID01                   (CBUS_CLASS_CSR_BASE_ADDR + 0x4d8U)
#define CLASS_STPID2                    (CBUS_CLASS_CSR_BASE_ADDR + 0x4dcU)
#define CLASS_DIS_PORT_FETCH            (CBUS_CLASS_CSR_BASE_ADDR + 0x4e0U)

#define CLASS_GLOBAL_REGISTER           (CBUS_CLASS_CSR_BASE_ADDR + 0x4e4U)
#define CLASS_DOS_ICMPV6_MAX_PKTLEN     (CBUS_CLASS_CSR_BASE_ADDR + 0x4e8U)
#define CLASS_DEBUG_BUS01               (CBUS_CLASS_CSR_BASE_ADDR + 0x4ecU)
#define CLASS_DEBUG_BUS23               (CBUS_CLASS_CSR_BASE_ADDR + 0x4f0U)
#define CLASS_DEBUG_BUS45               (CBUS_CLASS_CSR_BASE_ADDR + 0x4f4U)
#define CLASS_DEBUG_BUS67               (CBUS_CLASS_CSR_BASE_ADDR + 0x4f8U)
#define CLASS_DEBUG_BUS89               (CBUS_CLASS_CSR_BASE_ADDR + 0x4fcU)
#define CLASS_DEBUG_BUS1011             (CBUS_CLASS_CSR_BASE_ADDR + 0x500U)
#define CLASS_DEBUG_BUS12               (CBUS_CLASS_CSR_BASE_ADDR + 0x504U)
#define CLASS_DDR_BUF_SIZE              (CBUS_CLASS_CSR_BASE_ADDR + 0x508U)
#define CLASS_AXI_CTRL_ADDR             (CBUS_CLASS_CSR_BASE_ADDR + 0x50cU)
#define CLASS_PE_CONFIG                 (CBUS_CLASS_CSR_BASE_ADDR + 0x510U)
#define CLASS_PE_CUM_DROP_COUNT_ADDR    (CBUS_CLASS_CSR_BASE_ADDR + 0x514U)

/* CLASS defines */
#define CLASS_PBUF_SIZE             0x200UL
#define CLASS_PBUF_HEADER_OFFSET    0x00UL

#define CLASS_PBUF0_BASE_ADDR       0x000UL
#define CLASS_PBUF1_BASE_ADDR       (CLASS_PBUF0_BASE_ADDR + CLASS_PBUF_SIZE)
#define CLASS_PBUF2_BASE_ADDR       (CLASS_PBUF1_BASE_ADDR + CLASS_PBUF_SIZE)
#define CLASS_PBUF3_BASE_ADDR       (CLASS_PBUF2_BASE_ADDR + CLASS_PBUF_SIZE)

#define CLASS_PBUF0_HEADER_BASE_ADDR    (CLASS_PBUF0_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)
#define CLASS_PBUF1_HEADER_BASE_ADDR    (CLASS_PBUF1_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)
#define CLASS_PBUF2_HEADER_BASE_ADDR    (CLASS_PBUF2_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)
#define CLASS_PBUF3_HEADER_BASE_ADDR    (CLASS_PBUF3_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)

#define CLASS_PE0_RO_DM_ADDR0_VAL   ((CLASS_PBUF1_BASE_ADDR << 16U) | CLASS_PBUF0_BASE_ADDR)
#define CLASS_PE0_RO_DM_ADDR1_VAL   ((CLASS_PBUF3_BASE_ADDR << 16U) | CLASS_PBUF2_BASE_ADDR)

#define CLASS_PE0_QB_DM_ADDR0_VAL   ((CLASS_PBUF1_HEADER_BASE_ADDR << 16U) | CLASS_PBUF0_HEADER_BASE_ADDR)
#define CLASS_PE0_QB_DM_ADDR1_VAL   ((CLASS_PBUF3_HEADER_BASE_ADDR << 16U) | CLASS_PBUF2_HEADER_BASE_ADDR)

#define CLASS_TPID_DOT1Q            0x8100UL
#define CLASS_TPID_DOT1AD_0         0x88A8UL
#define CLASS_TPID_DOT1AD_1         0x9100UL
#define CLASS_TPID0_TPID1_VAL         ((CLASS_TPID_DOT1AD_0 << 16U) | CLASS_TPID_DOT1Q)
#define CLASS_TPID2_VAL                               (CLASS_TPID_DOT1AD_1)

#define RT_TWO_LEVEL_REF(x)         ((!!x) ? (1UL << 0U) : 0U)
#define PHYNO_IN_HASH(x)            ((!!x) ? (1UL << 1U) : 0U)
#define PARSE_ROUTE_EN(x)           ((!!x) ? (1UL << 3U) : 0U)
#define VLAN_AWARE_BRIDGE(x)        ((!!x) ? (1UL << 4U) : 0U)
#define PARSE_BRIDGE_EN(x)          ((!!x) ? (1UL << 5U) : 0U)
#define IPALIGNED_PKT(x)            ((!!x) ? (1UL << 6U) : 0U)
#define ARC_HIT_CHECK_EN(x)         ((!!x) ? (1UL << 7U) : 0U)
#define VLAN_AWARE_BRIDGE_PHY1(x)   ((!!x) ? (1UL << 8U) : 0U)
#define VLAN_AWARE_BRIDGE_PHY2(x)   ((!!x) ? (1UL << 9U) : 0U)
#define VLAN_AWARE_BRIDGE_PHY3(x)   ((!!x) ? (1UL << 10U) : 0U)
#define CLASS_TOE(x)                ((!!x) ? (1UL << 11U) : 0U)
#define ASYM_HASH(x)                ((((uint32)(x)) & 0x3UL) << 12U)
#define ASYM_HASH_NORMAL            0x0U
#define ASYM_HASH_SPORT_CRC         0x1U
#define ASYM_HASH_SIP_CRC           0x2U
#define ASYM_HASH_SIP_SPORT_CRC     0x3U
#define SYM_RTENTRY(x)              ((!!x) ? (1UL << 14U) : 0U)
#define QB2BUS_ENDIANESS(x)         ((!!x) ? (1UL << 15U) : 0U)
#define LEN_CHECK(x)                ((!!x) ? (1UL << 16U) : 0U)
#define USE_DEFAULT_VLANID(x)       ((!!x) ? (1UL << 0U) : 0UL)
#define DEF_VLANID(x)               ((((uint32)(x)) & 0xfffUL) << 1U)
#define PE_IBUS_WRITE               (1UL<<31U)
#define PE_IBUS_READ                (0UL<<31U)
#define PE_IBUS_ACCESS_IMEM         (1UL<<17U)
#define PE_IBUS_ACCESS_DMEM         (1UL<<18U)
#define PE_IBUS_PE_ID(x)            ((((uint32)(x)) & 0xfUL) << 20U)
#define PE_IBUS_WREN(x)             ((((uint32)(x)) & 0xfUL) << 24U)
#define PE_IBUS_BYTES(x)            ((1UL << (x)) - 1U) << (4U - (x)) /* 0x1 = LSB, 0x8 = MSB (BE) */
#define AXI_DBUS_BURST_SIZE(x)      ((((uint16)(x)) & 0x3ffU) << 4U)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

void pfe_class_cfg_set_config(addr_t base_va, const pfe_class_cfg_t *cfg);
void pfe_class_cfg_reset(addr_t base_va);
void pfe_class_cfg_enable(addr_t base_va);
void pfe_class_cfg_disable(addr_t base_va);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_class_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

errno_t pfe_class_cfg_set_rtable(addr_t base_va, addr_t rtable_pa, uint32 rtable_len, uint32 entry_size);
void pfe_class_cfg_set_def_vlan(addr_t base_va, uint16 vlan);
void pfe_class_cfg_rtable_lookup_enable(const addr_t base_va);
void pfe_class_cfg_rtable_lookup_disable(const addr_t base_va);
void pfe_class_cfg_bridge_lookup_enable(const addr_t base_va);
void pfe_class_cfg_bridge_lookup_disable(const addr_t base_va);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CLASS_CSR_H_ */


===== 文件 [49/185]: include\pfe_compiler.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2020-2022 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
#ifndef PFE_COMPILER_H
#define PFE_COMPILER_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

/*------------------------------------------------------------------------------------------------*/
/* Section describing behavior of supported compilers:
*  - do no modify this section
*  - macro values are intentionally not 0 and 1 to avoid confusion with undefined macros having
*    one of these values
*/

/** 
* @brief Order of bit fields in the structure 
* @details Either bit field corresponding to the highest bits in the memory is specified as the first
*          member or the last member of the structure.
*/
#define PFE_COMPILER_BITFIELD_HIGH_FIRST 3
#define PFE_COMPILER_BITFIELD_HIGH_LAST 2

/**
* @brief Result of the compilation - either driver or firmware
*/
#define PFE_COMPILER_RESULT_DRV 4
#define PFE_COMPILER_RESULT_FW 5

/*------------------------------------------------------------------------------------------------*/
/* Section describing result of the compilation: */
#define PFE_COMPILER_RESULT PFE_COMPILER_RESULT_DRV

/*------------------------------------------------------------------------------------------------*/
/* Section describing behavior of supported compilers regarding bit-fields position in structure:
*  - when adding a new compiler, just add it and define the macro PFE_COMPILER_BITFIELD_BEHAVIOR to one
*    of the variants
*/

/* Various supported GCC variants: */
#if (defined(__GNUC__))
    #if ((__GNUC__ == 5) && (__GNUC_MINOR__ == 4) && (__GNUC_PATCHLEVEL__ == 0))
        /* GCC version 5.4.0 */
        #if (defined(PFE_CFG_TARGET_ARCH_x86))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #elif (defined(PFE_CFG_TARGET_ARCH_x86_64))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #elif (defined(PFE_CFG_TARGET_ARCH_aarch64le))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #endif
    #elif ((__GNUC__ == 6) && (__GNUC_MINOR__ == 3) && (__GNUC_PATCHLEVEL__ == 1))
        /* GCC version 6.3.1 */
        #if (defined(PFE_CFG_TARGET_ARCH_aarch64))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #elif (defined(PFE_CFG_TARGET_ARCH_armv7le))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #endif
    #elif ((__GNUC__ == 9) && (__GNUC_MINOR__ == 2) && (__GNUC_PATCHLEVEL__ == 0))
        /* GCC version 9.2.0 */
        #if (defined(PFE_CFG_TARGET_ARCH_aarch64))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #elif (defined(PFE_CFG_TARGET_ARCH_armv7le))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #endif
    #elif ((__GNUC__ == 8) && (__GNUC_MINOR__ == 3) && (__GNUC_PATCHLEVEL__ == 0))
        /* GCC version 8.3.0 */
        #if (defined(PFE_CFG_TARGET_ARCH_aarch64le))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #elif (defined(PFE_CFG_TARGET_ARCH_armv7le))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
        #endif
    #elif (defined (__KERNEL__))
        /* Linux kernel compilation for not supported compiler */
        #if (defined(PFE_CFG_TARGET_ARCH_aarch64))
            /* Compiling driver */
            #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
            #define PFE_COMPILER_BEHAVIOR_GUESSED_ONLY
        #endif
    #endif
#endif

/* Supported GHS variants */
#if (defined(__ghs__))
    #if ((__GHS_VERSION_NUMBER == 201814) || (__GHS_VERSION_NUMBER == 201914) || (__GHS_VERSION_NUMBER == 202014)) && defined(__LITTLE_ENDIAN__)
        /* Compiling MCAL driver */
        #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
    #endif
#endif

/* Supported DIAB variants */
#if (defined(__DCC__))
    #if (((__VERSION_NUMBER__ == 7020) || (__VERSION_NUMBER__ == 7030)) && defined(__ORDER_LITTLE_ENDIAN__))
        /* Compiling MCAL driver */
        #define PFE_COMPILER_BITFIELD_BEHAVIOR PFE_COMPILER_BITFIELD_HIGH_LAST
    #endif
#endif

/*------------------------------------------------------------------------------------------------*/
/* Checks for correctness: */

#if(!defined(PFE_COMPILER_BITFIELD_BEHAVIOR))
    /* Required macro not defined */
    #error Please specify your compiler behavior by defining PFE_COMPILER_BITFIELD_BEHAVIOR.
#endif

#if ((PFE_COMPILER_BITFIELD_BEHAVIOR != PFE_COMPILER_BITFIELD_HIGH_LAST) && (PFE_COMPILER_BITFIELD_BEHAVIOR != PFE_COMPILER_BITFIELD_HIGH_FIRST))
    /* Wrong macro value */
    #error PFE_COMPILER_BITFIELD_BEHAVIOR shall be either PFE_COMPILER_BITFIELD_HIGH_LAST or PFE_COMPILER_BITFIELD_HIGH_FIRST
#endif

#if(!defined(PFE_COMPILER_RESULT))
    /* Required macro not defined */
    #error Please specify your compiler output by defining PFE_COMPILER_RESULT.
#endif

#if ((PFE_COMPILER_RESULT != PFE_COMPILER_RESULT_DRV) && (PFE_COMPILER_RESULT != PFE_COMPILER_RESULT_FW))
    /* Wrong macro value */
    #error PFE_COMPILER_RESULT shall be either PFE_COMPILER_RESULT_DRV or PFE_COMPILER_RESULT_FW
#endif

#endif /* PFE_COMPILER_H */


===== 文件 [50/185]: include\pfe_ct.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_PFE_PLATFORM
 * @{
 *
 * @file        pfe_ct.h
 * @brief       Common types (s32g).
 * @details     This header contains data types shared by host as well as PFE firmware.
 *
 */

#ifndef HW_S32G_PFE_CT_H_
#define HW_S32G_PFE_CT_H_

#include "pfe_compiler.h"
#if (!defined(PFE_COMPILER_BITFIELD_BEHAVIOR))
    #error PFE_COMPILER_BITFIELD_BEHAVIOR is not defined
#endif
#if (!defined(PFE_COMPILER_BITFIELD_HIGH_FIRST))
    #error PFE_COMPILER_BITFIELD_HIGH_FIRST is not defined
#endif
#if (!defined(PFE_COMPILER_BITFIELD_HIGH_LAST))
    #error PFE_COMPILER_BITFIELD_HIGH_LAST is not defined
#endif
#if (PFE_COMPILER_BITFIELD_HIGH_LAST == PFE_COMPILER_BITFIELD_HIGH_FIRST)
    #error PFE_COMPILER_BITFIELD_HIGH_LAST is equal to PFE_COMPILER_BITFIELD_HIGH_FIRST
#endif
#if (!defined(PFE_COMPILER_RESULT))
    #error PFE_COMPILER_RESULT is not defined
#endif
#if (!defined(PFE_COMPILER_RESULT_FW))
    #error PFE_COMPILER_RESULT_FW is not defined
#endif
#if (!defined(PFE_COMPILER_RESULT_DRV))
    #error PFE_COMPILER_RESULT_DRV is not defined
#endif
#if (PFE_COMPILER_RESULT_DRV == PFE_COMPILER_RESULT_FW)
    #error PFE_COMPILER_RESULT_DRV is equal to PFE_COMPILER_RESULT_FW
#endif

#if PFE_COMPILER_RESULT == PFE_COMPILER_RESULT_DRV
    /* Compiling for the driver */
    #include "oal_types.h"
    #define PFE_PTR(type)   uint32
#elif PFE_COMPILER_RESULT == PFE_COMPILER_RESULT_FW
    /* Compiling for the firmware */
    #include "fp_types.h"
    #define PFE_PTR(type)   type *
#else
    #error Ambiguous value of PFE_COMPILER_RESULT
#endif

/**
 * @brief   List of available interfaces
 * @details This is list of identifiers specifying particular available
 *          (physical) interfaces of the PFE.
 * @note    Current PFE does support max 8-bit IDs.
 */
typedef enum __attribute__((packed))
{
    /*  HW interfaces */
    PFE_PHY_IF_ID_EMAC0 = 0U,
    PFE_PHY_IF_ID_EMAC1 = 1U,
    PFE_PHY_IF_ID_EMAC2 = 2U,
    PFE_PHY_IF_ID_HIF = 3U,
    PFE_PHY_IF_ID_HIF_NOCPY = 4U,
    /*  UTIL PE - FW internal use */
    PFE_PHY_IF_ID_UTIL = 5U,
    /*  Synthetic interfaces */
    PFE_PHY_IF_ID_HIF0 = 6U,
    PFE_PHY_IF_ID_HIF1 = 7U,
    PFE_PHY_IF_ID_HIF2 = 8U,
    PFE_PHY_IF_ID_HIF3 = 9U,
    /*  Internals */
    PFE_PHY_IF_ID_MAX = PFE_PHY_IF_ID_HIF3,
    PFE_PHY_IF_ID_INVALID
} pfe_ct_phy_if_id_t;

typedef pfe_ct_phy_if_id_t pfe_drv_id_t;

/*  We expect given pfe_ct_phy_if_id_t size due to byte order compatibility. In case this
    assert fails the respective code must be reviewed and every usage of the type must
    be treated by byte order swap where necessary (typically any place in host software
    where the values are communicated between firmware and the host). */
ct_assert(sizeof(pfe_ct_phy_if_id_t) == sizeof(uint8));

/**
 * @brief   Interface matching rules
 * @details This flags can be used to define matching rules for every logical interface. Every
 *          packet received via physical interface is classified to get associated logical
 *          interface. The classification can be done on single, or combination of rules.
 */
typedef uint32 pfe_ct_if_m_rules_t;
    /* HW Accelerated Rules */
#define IF_MATCH_NONE       (pfe_ct_if_m_rules_t)0U               /*!< No match rule used */
#define IF_MATCH_TYPE_ETH   (pfe_ct_if_m_rules_t)(1UL << 0U)      /*!< Match ETH Packets */
#define IF_MATCH_TYPE_VLAN  (pfe_ct_if_m_rules_t)(1UL << 1U)      /*!< Match VLAN Tagged Packets */
#define IF_MATCH_TYPE_PPPOE (pfe_ct_if_m_rules_t)(1UL << 2U)      /*!< Match PPPoE Packets */
#define IF_MATCH_TYPE_ARP   (pfe_ct_if_m_rules_t)(1UL << 3U)      /*!< Match ARP Packets */
#define IF_MATCH_TYPE_MCAST (pfe_ct_if_m_rules_t)(1UL << 4U)      /*!< Match Multicast (L2) Packets */
#define IF_MATCH_TYPE_IPV4  (pfe_ct_if_m_rules_t)(1UL << 5U)      /*!< Match IPv4 Packets */
#define IF_MATCH_TYPE_IPV6  (pfe_ct_if_m_rules_t)(1UL << 6U)      /*!< Match IPv6 Packets */
#define IF_MATCH_RESERVED7  (pfe_ct_if_m_rules_t)(1UL << 7U)      /*!< Reserved */
#define IF_MATCH_RESERVED8  (pfe_ct_if_m_rules_t)(1UL << 8U)      /*!< Reserved */
#define IF_MATCH_TYPE_IPX   (pfe_ct_if_m_rules_t)(1UL << 9U)      /*!< Match IPX Packets */
#define IF_MATCH_TYPE_BCAST (pfe_ct_if_m_rules_t)(1UL << 10U)     /*!< Match Broadcast (L2) Packets */
#define IF_MATCH_TYPE_UDP   (pfe_ct_if_m_rules_t)(1UL << 11U)     /*!< Match UDP Packets */
#define IF_MATCH_TYPE_TCP   (pfe_ct_if_m_rules_t)(1UL << 12U)     /*!< Match TCP Packets */
#define IF_MATCH_TYPE_ICMP  (pfe_ct_if_m_rules_t)(1UL << 13U)     /*!< Match ICMP Packets */
#define IF_MATCH_TYPE_IGMP  (pfe_ct_if_m_rules_t)(1UL << 14U)     /*!< Match IGMP Packets */
#define IF_MATCH_VLAN       (pfe_ct_if_m_rules_t)(1UL << 15U)     /*!< Match VLAN ID */
#define IF_MATCH_PROTO      (pfe_ct_if_m_rules_t)(1UL << 16U)     /*!< Match IP Protocol */
#define IF_MATCH_SPORT      (pfe_ct_if_m_rules_t)(1UL << 20U)     /*!< Match L4 Source Port */
#define IF_MATCH_DPORT      (pfe_ct_if_m_rules_t)(1UL << 21U)     /*!< Match L4 Destination Port */
    /* Pure SW */
#define IF_MATCH_SIP6       (pfe_ct_if_m_rules_t)(1UL << 22U)     /*!< Match Source IPv6 Address */
#define IF_MATCH_DIP6       (pfe_ct_if_m_rules_t)(1UL << 23U)     /*!< Match Destination IPv6 Address */
#define IF_MATCH_SIP        (pfe_ct_if_m_rules_t)(1UL << 24U)     /*!< Match Source IPv4 Address */
#define IF_MATCH_DIP        (pfe_ct_if_m_rules_t)(1UL << 25U)     /*!< Match Destination IPv4 Address */
#define IF_MATCH_ETHTYPE    (pfe_ct_if_m_rules_t)(1UL << 26U)     /*!< Match EtherType */
#define IF_MATCH_FP0        (pfe_ct_if_m_rules_t)(1UL << 27U)     /*!< Match Packets Accepted by Flexible Parser 0 */
#define IF_MATCH_FP1        (pfe_ct_if_m_rules_t)(1UL << 28U)     /*!< Match Packets Accepted by Flexible Parser 1 */
#define IF_MATCH_SMAC       (pfe_ct_if_m_rules_t)(1UL << 29U)     /*!< Match Source MAC Address */
#define IF_MATCH_DMAC       (pfe_ct_if_m_rules_t)(1UL << 30U)     /*!< Match Destination MAC Address */
#define IF_MATCH_HIF_COOKIE (pfe_ct_if_m_rules_t)(1UL << 31U)     /*!< Match HIF header cookie value */

typedef uint8 pfe_ct_fp_flags_t;
#define FP_FL_NONE      (pfe_ct_fp_flags_t)0U          /* No flag set */
#define FP_FL_INVERT    (pfe_ct_fp_flags_t)(1UL << 0U) /* Invert match result */
#define FP_FL_REJECT    (pfe_ct_fp_flags_t)(1UL << 1U) /* Reject packet in case of match */
#define FP_FL_ACCEPT    (pfe_ct_fp_flags_t)(1UL << 2U) /* Accept packet in case of match */
#define FP_FL_L3_OFFSET (pfe_ct_fp_flags_t)(1UL << 3U) /* Data offset is relative from start of L3 header */
#define FP_FL_L4_OFFSET (pfe_ct_fp_flags_t)(1UL << 4U) /* Data offset is relative from start of L4 header */

/**
 * @brief The Flexible Parser rule
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /* Data to be matched with packet payload */
    uint32 data;
    /* Mask to be applied to data before comparison */
    uint32 mask;
    /* Offset within packet where data to be compared is
    located . It is relative value depending on rule
    configuration ( FP_FL_xx_OFFSET ). In case when none
    of FP_FL_xx_OFFSET flags is set the offset is from
    0th byte of the packet . */
    uint16 offset;
    /* Index within the Flexible Parser table identifying
    next rule to be applied in case the current rule does
    not contain FP_FL_REJECT nor FP_FL_ACCEPT flags . */
    uint8 next_idx;
    /* Control flags */
    pfe_ct_fp_flags_t flags;
} pfe_ct_fp_rule_t;

ct_assert(sizeof(pfe_ct_fp_rule_t) == 12U);

/*
* @brief Statistics gathered during flexible parser classification
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of frames matching the selection criteria */
    uint32 accepted;
    /* Number of frames not matching the selection criteria */
    uint32 rejected;
} pfe_ct_class_flexi_parser_stats_t;

/**
 * @brief The Flexible Parser table
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of rules in the table */
    uint16 count;
    /* Reserved variables to keep "rules" aligned */
    uint16 reserved16;
    /* Pointer to the array of "count" rules */
    PFE_PTR (pfe_ct_fp_rule_t) rules;
    pfe_ct_class_flexi_parser_stats_t  __attribute__((aligned(4))) fp_stats; /* Must be aligned at 4 bytes */
} pfe_ct_fp_table_t;

ct_assert(sizeof(pfe_ct_fp_table_t) == 16U);

typedef union __attribute__((packed, aligned(4)))
{
    /*  IPv4 (for IF_MATCH_SIP, IF_MATCH_DIP) */
    struct
    {
        uint32 sip;
        uint32 dip;
        uint32 pad[6U];
    } v4;

    /*  IPv6 (for IF_MATCH_SIP6, IF_MATCH_DIP6) */
    struct
    {
        uint32 sip[4U];
        uint32 dip[4U];
    } v6;
} pfe_ct_ip_addresses_t;

/**
 * @brief   Interface matching rules arguments
 * @details Argument values needed by particular rules given by pfe_ct_if_m_rules_t.
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /* VLAN ID (IF_MATCH_VLAN) */
    uint16 vlan;
    /* Ether Type (IF_MATCH_ETHTYPE) */
    uint16 ethtype;
    /* L4 source port number (IF_MATCH_SPORT) */
    uint16 sport;
    /* L4 destination port number (IF_MATCH_DPORT) */
    uint16 dport;
    /* Source and destination addresses */
    pfe_ct_ip_addresses_t ipv;
    /* Flexible Parser 0 table (IF_MATCH_FP0) */
    PFE_PTR(pfe_ct_fp_table_t) fp0_table;
    /* Flexible Parser 1 table (IF_MATCH_FP1) */
    PFE_PTR(pfe_ct_fp_table_t) fp1_table;
    /* HIF header cookie (IF_MATCH_HIF_COOKIE) */
    uint32 hif_cookie;
    /* Source MAC Address (IF_MATCH_SMAC) */
    uint8 __attribute__((aligned(4))) smac[6U]; /* Must be aligned at 4 bytes */
    /* IP protocol (IF_MATCH_PROTO) */
    uint8 proto;
    /* Reserved */
    uint8 reserved;
    /* Destination MAC Address (IF_MATCH_DMAC) */
    uint8 __attribute__((aligned(4))) dmac[6U]; /* Must be aligned at 4 bytes */
} pfe_ct_if_m_args_t;

/*
* @brief Statistics gathered during classification (per algorithm and per logical interface)
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of frames processed regardless the result */
    uint32 processed;
    /* Number of frames matching the selection criteria */
    uint32 accepted;
    /* Number of frames not matching the selection criteria */
    uint32 rejected;
    /* Number of frames marked to be dropped */
    uint32 discarded;
} pfe_ct_class_algo_stats_t;

/*
* @brief Statistics gathered for each physical interface
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of ingress frames for the given interface  */
    uint32 ingress;
    /* Number of egress frames for the given interface */
    uint32 egress;
    /* Number of ingress frames with detected error (i.e. checksum) */
    uint32 malformed;
    /* Number of ingress frames which were discarded */
    uint32 discarded;
} pfe_ct_phy_if_stats_t;

/*
* @brief Statistic entry for vlan
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of ingress frames for the given vlan */
    uint32 ingress;
    /* Number of egress frames for the given vlan */
    uint32 egress;
    /* Number of ingress bytes for the given vlan */
    uint32 ingress_bytes;
    /* Number of egress bytes for the given vlan */
    uint32 egress_bytes;
} pfe_ct_vlan_stats_t;

/*
* @brief Statistics gathered for each vlan
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of configured vlan */
    uint16 vlan_count;
    /* Reserved variables to keep "stats" aligned */
    uint16 reserved16;
    /* Pointer to vlan stats table */
    PFE_PTR (pfe_ct_vlan_stats_t) vlan; 
} pfe_ct_vlan_statistics_t;

/*
* @brief Statistic entry for conntrack
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of frames that hit the conntrack */
    uint32 hit;
    /* Number of bytes of frames that hit the conntrack */
    uint32 hit_bytes;
} pfe_ct_conntrack_stats_t;

/*
* @brief Statistics gathered for each conntrack
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of configured conntracks */
    uint16 conntrack_count;
    /* Reserved variables to keep "stats" aligned */
    uint16 reserved16;
    /* Pointer to conntrack stats table */
    PFE_PTR (pfe_ct_conntrack_stats_t) stats_table;
} pfe_ct_conntrack_statistics_t;

/*
* @brief Statistics gathered for the whole processing engine (PE)
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of packets processed by the PE */
    uint32 processed;
    /* Number of packets discarded by the PE */
    uint32 discarded;
    /* Count of frames with replicas count 1, 2, ...
    PFE_PHY_IF_ID_MAX+1 (+1 because interfaces are numbered from 0) */
    uint32 replicas[PFE_PHY_IF_ID_MAX + 1U];
    /* Number of HIF frames with HIF_TX_INJECT flag */
    uint32 injected;
} pfe_ct_pe_stats_t;

/**
 * @brief   Interface operational flags
 * @details Defines way how ingress packets matching given interface will be processed
 *          by the classifier.
 */
typedef enum __attribute__((packed))
{
    IF_OP_DEFAULT = 0U,     /*!< Default operational mode */
    IF_OP_VLAN_BRIDGE = 1U,     /*!< L2 bridge with VLAN */
    IF_OP_ROUTER = 2U,      /*!< L3 router */
    IF_OP_FLEX_ROUTER = 3U,     /*!< Flexible router */
    IF_OP_L2L3_VLAN_BRIDGE = 4U,    /*!< L2-L3 bridge with VLAN */
} pfe_ct_if_op_mode_t;

/*  We expect given pfe_ct_if_op_mode_t size due to byte order compatibility. */
ct_assert(sizeof(pfe_ct_if_op_mode_t) == sizeof(uint8));

typedef uint32 pfe_ct_if_flags_t;
#define IF_FL_NONE            (pfe_ct_if_flags_t)0U           /*!< No flag set */
#define IF_FL_ENABLED         (pfe_ct_if_flags_t)(1UL << 0U)  /*!< If set, interface is enabled */
#define IF_FL_PROMISC         (pfe_ct_if_flags_t)(1UL << 1U)  /*!< If set, interface is promiscuous */
#define IF_FL_FF_ALL_TCP      (pfe_ct_if_flags_t)(1UL << 2U)  /*!< Enable fast-forwarding of ingress TCP SYN|FIN|RST packets */
#define IF_FL_MATCH_OR        (pfe_ct_if_flags_t)(1UL << 3U)  /*!< Result of match is logical OR of rules, else AND */
#define IF_FL_DISCARD         (pfe_ct_if_flags_t)(1UL << 4U)  /*!< Discard packets on rules match */
#define IF_FL_LOAD_BALANCE    (pfe_ct_if_flags_t)(1UL << 6U)  /*!< HIF channel participates in load balancing */
#define IF_FL_VLAN_CONF_CHECK (pfe_ct_if_flags_t)(1UL << 7U)  /*!< Enable VLAN conformance check */
#define IF_FL_PTP_CONF_CHECK  (pfe_ct_if_flags_t)(1UL << 8U)  /*!< Enable PTP conformance check */
#define IF_FL_PTP_PROMISC     (pfe_ct_if_flags_t)(1UL << 9U)  /*!< PTP traffic will bypass all ingress checks */
#define IF_FL_LOOPBACK        (pfe_ct_if_flags_t)(1UL << 10U) /*!< If set, interface is in loopback mode */
#define IF_FL_ALLOW_Q_IN_Q    (pfe_ct_if_flags_t)(1UL << 11U) /*!< If set, QinQ traffic is accepted */
#define IF_FL_DISCARD_TTL     (pfe_ct_if_flags_t)(1UL << 12U) /*!< Discard packet with TTL<2 instead of passing to default logical interface */

/**
 * @brief   Acceptable frame types
 */
typedef enum  __attribute__((packed))
{
    IF_AFT_ANY_TAGGING = 0U,
    IF_AFT_TAGGED_ONLY = 1U,
    IF_AFT_UNTAGGED_ONLY = 2U
} pfe_ct_if_aft_t;

/*  We expect given pfe_ct_if_aft_t size due to byte order compatibility. */
ct_assert(sizeof(pfe_ct_if_aft_t) == sizeof(uint8));

/**
 * @brief   Interface blocking state
 */
typedef enum __attribute__((packed))
{
    IF_BS_FORWARDING = 0U,  /*!< Learning and forwarding enabled */
    IF_BS_BLOCKED = 1U,     /*!< Learning and forwarding disabled */
    IF_BS_LEARN_ONLY = 2U,  /*!< Learning enabled, forwarding disabled */
    IF_BS_FORWARD_ONLY = 3U /*!< Learning disabled, forwarding enabled */
} pfe_ct_block_state_t;

/*  We expect given pfe_ct_block_state_t size due to byte order compatibility. */
ct_assert(sizeof(pfe_ct_block_state_t) == sizeof(uint8));

/**
 * @brief   The logical interface structure as seen by firmware
 * @details This structure is shared between firmware and the driver. It represents
 *          the logical interface as it is stored in the DMEM.
 * @warning Do not modify this structure unless synchronization with firmware is ensured.
 */
typedef struct __attribute__((packed, aligned(4))) pfe_ct_log_if_tag
{
    /*  Pointer to next logical interface in the list (DMEM) */
    PFE_PTR(struct pfe_ct_log_if_tag) next;
    /*  List of egress physical interfaces. Bit positions correspond
        to pfe_ct_phy_if_id_t values (1U << pfe_ct_phy_if_id_t). */
    uint32 e_phy_ifs;
    /*  Flags */
    pfe_ct_if_flags_t flags;
    /*  Match rules. Zero means that matching is disabled and packets
        can be accepted on interface in promiscuous mode only. */
    pfe_ct_if_m_rules_t m_rules;
    /*  Interface identifier */
    uint8 id;
    /*  Operational mode */
    pfe_ct_if_op_mode_t mode;
    /*  Reserved */
    uint8 res[2];
    /*  Arguments required by matching rules */
    pfe_ct_if_m_args_t __attribute__((aligned(4))) m_args; /* Must be aligned at 4 bytes */
    /*  Gathered statistics */
    pfe_ct_class_algo_stats_t __attribute__((aligned(4))) class_stats; /* Must be aligned at 4 bytes */
} pfe_ct_log_if_t;

typedef enum __attribute__((packed))
{
    SPD_ACT_INVALID = 0U,           /* Undefined action - configuration is required */
    SPD_ACT_DISCARD,                /* Discard the frame */
    SPD_ACT_BYPASS,                 /* Bypass IPsec and forward normally */
    SPD_ACT_PROCESS_ENCODE,         /* Process IPsec */
    SPD_ACT_PROCESS_DECODE          /* Process IPsec */
} pfe_ct_spd_entry_action_t;
ct_assert(sizeof(pfe_ct_spd_entry_action_t) == sizeof(uint8));

typedef uint8 pfe_ct_spd_flags_t;
#define SPD_FLAG_NONE         (pfe_ct_spd_flags_t)0U          /* No flag set */
#define SPD_FLAG_5T           (pfe_ct_spd_flags_t)(1UL << 0U) /* 5-tuple acceleration by HW, if not set the id5t shall be 0 */
#define SPD_FLAG_IPv6         (pfe_ct_spd_flags_t)(1UL << 1U) /* IPv4 if not set, IPv6 if set */
#define SPD_FLAG_SPORT_OPAQUE (pfe_ct_spd_flags_t)(1UL << 2U) /* Do not match Source PORT */
#define SPD_FLAG_DPORT_OPAQUE (pfe_ct_spd_flags_t)(1UL << 3U) /* Do not match Destination PORT */

typedef struct __attribute__((packed, aligned(4)))
{
    pfe_ct_spd_flags_t flags;
    /* --- Match criteria ---*/
    /*  IP protocol number */
    uint8 proto;  /* IP protocol */
    uint16 pad;   /* align at 4 bytes boundary */
    /*  L4 source port number */
    uint16 sport;
    /*  L4 destination port number */
    uint16 dport;
    /*  Source and destination IP addresses */
    pfe_ct_ip_addresses_t ipv;
    uint32 id5t;  /* 5-tuple ID to speed search, 0 = invalid ID */
    uint32 spi;   /* SPI value to match - only for action SPD_ACT_PROCESS_DECODE */
    /* --- Action --- */
    uint32 sad_entry; /* How to process IPsec */
    pfe_ct_spd_entry_action_t action; /* What to do on match */
    uint8 pad8[3U];
} pfe_ct_spd_entry_t;

typedef struct __attribute__((packed, aligned(4)))
{
    uint32 entry_count;                   /* Count of the entries in the database */
    pfe_ct_spd_entry_action_t no_ip_action; /* Non-ip traffic action - may not be SPD_ACT_PROCESS */
    uint8 pad[3U];                        /* Align to 4 bytes */
    PFE_PTR(pfe_ct_spd_entry_t) entries;    /* Database entries */
} pfe_ct_ipsec_spd_t;

/**
* @brief Configures mirroring 
*/
typedef struct __attribute__((packed, aligned(4))) pfe_ct_mirror_tag pfe_ct_mirror_t;

/*
* @def PFE_CT_MIRRORS_COUNT
* @brief Number of RX and TX mirrors supported by physical interface.
*/
#define PFE_CT_MIRRORS_COUNT 2U
/**
 * @brief   The physical interface structure as seen by classifier/firmware
 * @details This structure is shared between firmware and the driver. It represents
 *          the interface as it is stored in the DMEM.
 * @warning Do not modify this structure unless synchronization with firmware is ensured.
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /*  Pointer to head of list of logical interfaces (DMEM) */
    PFE_PTR(pfe_ct_log_if_t) log_ifs;
    /*  Pointer to default logical interface (DMEM) */
    PFE_PTR(pfe_ct_log_if_t) def_log_if;
    /*  Flags */
    pfe_ct_if_flags_t flags;
    /*  Physical port number */
    pfe_ct_phy_if_id_t id;
    /*  Operational mode */
    pfe_ct_if_op_mode_t mode;
    /*  Block state */
    pfe_ct_block_state_t block_state;
    /*  Mirroring to given port */
    PFE_PTR(pfe_ct_mirror_t) rx_mirrors[PFE_CT_MIRRORS_COUNT];
    PFE_PTR(pfe_ct_mirror_t) tx_mirrors[PFE_CT_MIRRORS_COUNT];
    /*  SPD for IPsec */
    PFE_PTR(pfe_ct_ipsec_spd_t) ipsec_spd;
    /*  Flexible Filter */
    PFE_PTR(pfe_ct_fp_table_t) filter;
    /* management interface */
    pfe_ct_phy_if_id_t mgmt_interface;
    /*  Gathered statistics */
    pfe_ct_phy_if_stats_t phy_stats __attribute__((aligned(4))); /* Must be aligned to 4 bytes */
} pfe_ct_phy_if_t;

/**
 * @brief   L2 Bridge Actions
 */
typedef enum __attribute__((packed))
{
    L2BR_ACT_FORWARD = 0U,   /*!< Forward normally */
    L2BR_ACT_FLOOD = 1U,     /*!< Flood */
    L2BR_ACT_PUNT = 2U,      /*!< Punt */
    L2BR_ACT_DISCARD = 3U,   /*!< Discard */
} pfe_ct_l2br_action_t;

#if PFE_COMPILER_BITFIELD_BEHAVIOR == PFE_COMPILER_BITFIELD_HIGH_LAST
/**
 * @brief   MAC table lookup result (31-bit)
 */
typedef union __attribute__((packed))
{
    struct
    {
        /* [19:0] Forward port list */
        uint32 forward_list : 20;
        /* [25:20] Reserved */
        uint32 reserved : 6;
        /* [26] Discard on DST MAC match */
        uint32 dst_discard : 1;
        /* [27] Discard on SRC MAC match */
        uint32 src_discard : 1;
        /* [28] Local L3 */
        uint32 local_l3 : 1;
        /* [29] Fresh */
        uint32 fresh_flag : 1;
        /* [30] Static */
        uint32 static_flag : 1;
        /* [31] Reserved */
        uint32 reserved1 : 1;
    } item;

    uint32 val : 32;
} pfe_ct_mac_table_result_t;

/**
 * @brief   VLAN table lookup result (64-bit)
 */
typedef union __attribute__((packed))
{
    struct
    {
        /*  [17:0]  Forward list (1U << pfe_ct_phy_if_id_t) */
        uint64 forward_list : 18;
        /*  [35:18] Untag list (1U << pfe_ct_phy_if_id_t) */
        uint64 untag_list : 18;
        /*  [38:36] Unicast hit action (pfe_ct_l2br_action_t) */
        uint64 ucast_hit_action : 3;
        /*  [41:39] Multicast hit action (pfe_ct_l2br_action_t) */
        uint64 mcast_hit_action : 3;
        /*  [44:42] Unicast miss action (pfe_ct_l2br_action_t) */
        uint64 ucast_miss_action : 3;
        /*  [47:45] Multicast miss action (pfe_ct_l2br_action_t) */
        uint64 mcast_miss_action : 3;
        /*  [54:48] Stats index */
        uint64 stats_index : 7;
        /*  [55 : 63] */ /* Reserved */
        uint64  hw_reserved : 9;
    } item;

    uint64 val;
} pfe_ct_vlan_table_result_t;
#elif PFE_COMPILER_BITFIELD_BEHAVIOR == PFE_COMPILER_BITFIELD_HIGH_FIRST
/**
 * @brief   MAC table lookup result (31-bit)
 */
typedef union __attribute__((packed))
{
    struct
    {
        /* [31] Reserved */
        uint32 reserved1 : 1;
        /* [30] Static */
        uint32 static_flag : 1;
        /* [29] Fresh */
        uint32 fresh_flag : 1;
        /* [28] Local L3 */
        uint32 local_l3 : 1;
        /* [27] Discard on SRC MAC match */
        uint32 src_discard : 1;
        /* [26] Discard on DST MAC match */
        uint32 dst_discard : 1;
        /* [25:20] Reserved */
        uint32 reserved : 6;
        /* [19:0] Forward port list */
        uint32 forward_list : 20;
    } item;

    uint32 val : 32;
} pfe_ct_mac_table_result_t;

/**
 * @brief   VLAN table lookup result (64-bit)
 */
typedef union __attribute__((packed))
{
    struct
    {
        /*  [55 : 63] */ /* Reserved */
        uint64 hw_reserved : 9;
        /*  [54:48] Index in vlan stats table (pfe_ct_vlan_statistics_t) */
        uint64 stats_index : 7;
        /*  [47:45] Multicast miss action (pfe_ct_l2br_action_t) */
        uint64 mcast_miss_action : 3;
        /*  [44:42] Unicast miss action (pfe_ct_l2br_action_t) */
        uint64 ucast_miss_action : 3;
        /*  [41:39] Multicast hit action (pfe_ct_l2br_action_t) */
        uint64 mcast_hit_action : 3;
        /*  [38:36] Unicast hit action (pfe_ct_l2br_action_t) */
        uint64 ucast_hit_action : 3;
        /*  [35:18] Untag list (1U << pfe_ct_phy_if_id_t) */
        uint64 untag_list : 18;  /* List of ports to remove VLAN tag */
        /*  [17:0]  Forward list (1U << pfe_ct_phy_if_id_t) */
        uint64 forward_list : 18;
    } item;

    uint64 val;
} pfe_ct_vlan_table_result_t;
#else
    #error Ambiguous definition of PFE_COMPILER_BITFIELD_BEHAVIOR
#endif /* Compiler Behavior */

ct_assert(sizeof(pfe_ct_mac_table_result_t) == sizeof(uint32));
ct_assert(sizeof(pfe_ct_vlan_table_result_t) == sizeof(uint64));

/**
 * @brief Bridge domain entry
 */
typedef pfe_ct_vlan_table_result_t pfe_ct_bd_entry_t;

/*  Date string type */
typedef uint8 pfe_date_str_t[16U];

/*  We expect given pfe_date_str_t size. */
ct_assert(sizeof(pfe_date_str_t) > sizeof(__DATE__));

/**
 * @brief Time string type
 */
typedef uint8 pfe_time_str_t[16U];

/*  We expect given pfe_time_str_t size. */
ct_assert(sizeof(pfe_time_str_t) > sizeof(__TIME__));

/**
 * @brief Version control identifier string type
 */
typedef uint8 pfe_vctrl_str_t[16U];

/**
 * @brief This header version MD5 checksum string type
 */
typedef char_t pfe_cthdr_str_t[36U]; /* 32 Characters + NULL + 3 padding */

/**
* @brief Identification of PE type the FW is used for
*/
typedef enum __attribute__((packed))
{
    PE_TYPE_INVALID,
    PE_TYPE_CLASS,
    PE_TYPE_TMU,
    PE_TYPE_UTIL,
    PE_TYPE_MAX
} pfe_ct_pe_type_t;
ct_assert(sizeof(pfe_ct_pe_type_t) == 1U);

/**
* @brief Feature flags
* Flags combinations:
* F_PRESENT is missing - the feature is not available
* F_PRESENT is set and F_RUNTIME is missing - the feature is always enabled (cannot be disabled)
* F_PRESENT is set and F_RUNTIME is set - the feature can be enabled/disable at runtime, enabled state must be read out of DMEM 
*/
typedef uint8 pfe_ct_feature_flags_t;
#define F_NONE    (pfe_ct_feature_flags_t)0U
#define F_PRESENT (pfe_ct_feature_flags_t)(1UL << 0U)     /* Feature not available if not set */
#define F_RUNTIME (pfe_ct_feature_flags_t)(1UL << 1U)     /* Feature can be enabled/disabled at runtime */
#define F_CLASS   (pfe_ct_feature_flags_t)(1UL << 5U)     /* Feature implemented in Class firmware */
#define F_UTIL    (pfe_ct_feature_flags_t)(1UL << 6U)     /* Feature implemented in Util firmware */

/**
* @brief Storage for firmware features description
*/
typedef struct __attribute__((packed,aligned(4)))
{
    PFE_PTR(const char)name;               /* Feature name */
    PFE_PTR(const char)description;        /* Feature description */
    PFE_PTR(uint8) position;             /* Position of the run-time enable byte */
    const pfe_ct_feature_flags_t flags;    /* Configuration variant: 0 = disabled, 1 = enabled, 2 = runtime configured */
    const uint8 def_val;                 /* Enable/disable default value used for runtime configuration */
    const uint8 reserved[2];             /* Pad */
} pfe_ct_feature_desc_t;

ct_assert(sizeof(pfe_ct_feature_desc_t) == 16);

/**
* @brief Version of the HW detected by the FW
*/
typedef enum __attribute__((packed))
{
    HW_VERSION_UNKNOWN = 0U,          /* FW has not recognized the HW version */
    HW_VERSION_S32G2 = 2U,            /* S32G2 */
    HW_VERSION_S32G3 = 3U,            /* S32G3 */
    HW_VERSION_MAX = (int)(1UL << 31)  /* Ensure proper size */
} pfe_ct_hw_version_t;

ct_assert(sizeof(pfe_ct_hw_version_t) == sizeof(uint32));

/**
 * @brief Firmware version information
 */
typedef struct __attribute__((packed))
{
    /*  ID */
    uint32 id;
    /*  Revision info */
    uint8 major;
    uint8 minor;
    uint8 patch;
    /*  PE type */
    pfe_ct_pe_type_t pe_type;
    /*  Firmware properties */
    uint32 flags;
    /*  Build date and time */
    pfe_date_str_t build_date;
    pfe_time_str_t build_time;
    /*  Version control ID (e.g. GIT commit) */
    pfe_vctrl_str_t vctrl;
    /*  This header version */
    pfe_cthdr_str_t cthdr;
    /*  Feature descriptions */
    PFE_PTR(pfe_ct_feature_desc_t) features;
    /*  Features count - number of items in features */
    uint32 features_count;
    /*  Hardware Versions */
    PFE_PTR(pfe_ct_hw_version_t) hw_version;
} pfe_ct_version_t;

/**
    @brief Miscellaneous control commands between host and PE
*/
typedef struct __attribute__ (( packed, aligned (4) ))
{
    /*  Request from host to trigger the PE graceful stop. Writing a non - zero value triggers the stop.
        Once PE entered the stop state it notifies the host via setting the graceful_stop_confirmation
        to a non-zero value. To resume from stop state the host clear the graceful_stop_request to
        zero and waits until PE clears the graceful_stop_confirmation. */
    uint8 graceful_stop_request;
    /*  Confirmation from PE that has entered or left the graceful stop state */
    uint8 graceful_stop_confirmation;
} pfe_ct_pe_misc_control_t;

/**
    @brief Miscellaneous config between host and PE
*/
typedef struct __attribute__ (( packed, aligned (4) ))
{
    /*  Timeout of mac aging algorithm of l2 bridge in seconds*/
    uint16 l2_mac_aging_timeout;
} pfe_ct_misc_config_t;

/*
* @brief Statistics gathered during IHC classification
*/
typedef struct __attribute__((packed, aligned(4)))
{
    /* Number of send IHC frames */
    uint32 tx;
    /* Number of received IHC frames */
    uint32 rx;
    /* Number of IHC frames marked to be dropped */
    uint32 discarded;
} pfe_ct_class_ihc_stats_t;

/**
 * @brief Statistics gathered for each classification algorithm
 * @details NULL pointer means that given statistics are no available
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /* Statistics gathered by Flexible Router algorithm */
    pfe_ct_class_algo_stats_t flexible_router;
    /* Statistics gathered by IP router algorithm (IF_OP_ROUTER) */
    pfe_ct_class_algo_stats_t ip_router;
    /* Statistics gathered by VLAN bridge algorithm (IF_OP_VLAN_BRIDGE) */
    pfe_ct_class_algo_stats_t vlan_bridge;
    /* Statistics gathered by logical interface matching algorithm (IF_OP_DEFAULT) */
    pfe_ct_class_algo_stats_t log_if;
    /* Statistics gathered when hif-to-hif classification is done */
    pfe_ct_class_ihc_stats_t hif_to_hif[PFE_PHY_IF_ID_MAX + 1];
} pfe_ct_classify_stats_t;

/**
 * @brief Number of FW messages which can be stored in pfe_ct_message_record_t
 * @details The value must be power of 2.
 */
#define FP_MESSAGE_RECORD_SIZE 64U

/**
 * @brief   List of message levels
 */
typedef enum __attribute__((packed))
{
    PFE_MESSAGE_EXCEPTION = 0U,
    PFE_MESSAGE_ERROR     = 1U,
    PFE_MESSAGE_WARNING   = 2U,
    PFE_MESSAGE_INFO      = 3U,
    PFE_MESSAGE_DEBUG     = 4U
} pfe_ct_message_level_t;

/**
 * @brief Reported message storage
 * @note Instances of this structure are stored in an elf-file section .messages which
 *       is not loaded into any memory and the driver accesses it only through the
 *       elf-file.
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /* Message content - string in .messages section */
    PFE_PTR(const char_t)message;
    /* File name where message was logged - string in .messages section */
    PFE_PTR(const char_t)file;
    /* Line where message was logged */
    const uint32 line;
} pfe_ct_message_t;

/**
 * @brief Storage for runtime messeges
 * @note The pointers cannot be dereferenced because the .messages section is not loaded
 *       into memory and the elf-file parsing is needed to translate them.
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /* Next position to write: (write_index & (FP_MESSAGE_RECORD_SIZE - 1)) */
    uint32 write_index;
    /* Stored messages - pointers point to section .messages which is not
        part of any memory, just the elf-file */
    PFE_PTR(const pfe_ct_message_t) messages[FP_MESSAGE_RECORD_SIZE];
    uint32 values[FP_MESSAGE_RECORD_SIZE];
    pfe_ct_message_level_t  level[FP_MESSAGE_RECORD_SIZE];
} pfe_ct_message_record_t;

/**
 * @brief The firmware internal state
 */
typedef enum __attribute__((packed))
{
    PFE_FW_STATE_UNINIT = 0U,        /* FW not started */
    PFE_FW_STATE_INIT,               /* FW passed initialization */
    PFE_FW_STATE_FRAMEWAIT,          /* FW waiting for a new frame arrival */
    PFE_FW_STATE_FRAMEPARSE,         /* FW started parsing a new frame */
    PFE_FW_STATE_FRAMECLASSIFY,      /* FW started classification of parsed frame */
    PFE_FW_STATE_FRAMEDISCARD,       /* FW is discarding the frame */
    PFE_FW_STATE_FRAMEMODIFY,        /* FW is modifying the frame */
    PFE_FW_STATE_FRAMESEND,          /* FW is sending frame out (towards EMAC or HIF) */
    PFE_FW_STATE_STOPPED,            /* FW was gracefully stopped by external request */
    PFE_FW_STATE_EXCEPTION,          /* FW is stopped after an exception */
    PFE_FW_STATE_FAIL_STOP           /* FW is stopped due to a safety fault */
} pfe_ct_pe_sw_state_t;

/**
 * @brief Monitoring of the firmware state (watchdog)
 * @details FW updates the variable with the current state and increments counter
 *          with each state transition. The driver monitors the variable.
 * @note Written only by FW and read by Driver.
 */
typedef struct __attribute__((packed, aligned(4)))
{
    uint32 counter;               /* Incremented with each state change */
    pfe_ct_pe_sw_state_t state;     /* Reflect the current FW state */
    uint8 reserved[3U];            /* To make size multiple of 4 bytes */
} pfe_ct_pe_sw_state_monitor_t;

ct_assert(sizeof(pfe_ct_pe_sw_state_monitor_t) == 8U);


/**
 * @brief Storage for measured time intervals used during firmware performance monitoring
 */
typedef struct __attribute__((packed, aligned(4)))
{
    uint32 min;   /* Minimal measured value */
    uint32 max;   /* Maximal measured value */
    uint32 avg;   /* Average of measured values */
    uint32 cnt;   /* Count of measurements */
} pfe_ct_measurement_t;

/**
 * @brief   Size of buffer defined by pfe_ct_buffer_t in number of bytes
 */
#define PFE_CT_BUFFER_LEN   64U

/**
 * @brief   Generic buffer descriptor
 */
typedef struct __attribute__((packed))
{
    /*  The buffer data area */
    uint8 payload[PFE_CT_BUFFER_LEN];
    /*  Number of bytes in buffer */
    uint8 len;
    /*  Non-zero value indicates that the buffer is valid */
    uint8 flags;
} pfe_ct_buffer_t;

/**
 * @brief Common PE memory map representation type shared between host and PFE
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /*  Size of the structure in number of bytes - must be 1st in structure */
    uint32 size;
    /*  Version information */
    pfe_ct_version_t version;
    /*  Misc. control  */
    PFE_PTR(pfe_ct_pe_misc_control_t) pe_misc_control;
    /*  Misc. config  */
    PFE_PTR(pfe_ct_misc_config_t) misc_config;
    /*  Messages logged by the FW */
    PFE_PTR(pfe_ct_message_record_t) message_record;
    /*  FW state */
    PFE_PTR(pfe_ct_pe_sw_state_monitor_t) state_monitor;
    /*  Count of the measurement storages - 0 = feature not enabled */
    uint32 measurement_count;
    /*  Performance measurement storages - NULL = none (feature not enabled) */
    PFE_PTR(pfe_ct_measurement_t) measurements;
} pfe_ct_common_mmap_t;

/**
 * @brief Information about configured HIF TMU queue sizes 
 * @details The value is sum of TMU Queue sizes belonging to the HIF channel with number
 *          equal to array index.
 */
typedef struct
{
    uint16 hif_channel[4U];
} pfe_ct_hif_tmu_queue_sizes_t;

/**
 * @brief Class PE memory map representation type shared between host and PFE
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /*  Common part for all PE types - must be 1st in the structure */
    pfe_ct_common_mmap_t common;
    /*  Pointer to DMEM heap */
    PFE_PTR(void) dmem_heap_base;
    /*  DMEM heap size in number of bytes */
    uint32 dmem_heap_size;
    /*  Pointer to array of physical interfaces */
    PFE_PTR(pfe_ct_phy_if_t) dmem_phy_if_base;
    /*  Physical interfaces memory space size in number of bytes */
    uint32 dmem_phy_if_size;
    /*  Fall-back bridge domain structure location (DMEM) */
    PFE_PTR(pfe_ct_bd_entry_t) dmem_fb_bd_base;
    /*  Default bridge domain structure location (DMEM) */
    PFE_PTR(pfe_ct_bd_entry_t) dmem_def_bd_base;
    /*  Statistics provided for the PE (by the firmware) */
    PFE_PTR(pfe_ct_pe_stats_t) pe_stats;
    /*  Statistics provided for each classification algorithm */
    PFE_PTR(pfe_ct_classify_stats_t) classification_stats;
    /*  Statistics provided for each vlan */
    PFE_PTR(pfe_ct_vlan_statistics_t) vlan_statistics;
    /*  Statistics provided for each conntrack */
    PFE_PTR(pfe_ct_conntrack_statistics_t) conntrack_statistics;
    /*  Put buffer: FW-to-SW data transfers */
    PFE_PTR(pfe_ct_buffer_t) put_buffer;
    /*  Get buffer: SW-to-FW data transfers */
    PFE_PTR(pfe_ct_buffer_t) get_buffer;
    /*  HIF TMU Queue sizes information for errata ERR051211 workaround*/
    PFE_PTR(pfe_ct_hif_tmu_queue_sizes_t) hif_tmu_queue_sizes;
} pfe_ct_class_mmap_t;

/**
 * @brief IPsec state
 */
typedef struct  {
    uint32 hse_mu;                    /* HSE MU to be used */
    uint32 hse_mu_chn;                /* HSE MU channel to be used (currently unused) */
    uint32 response_ok;               /* HSE_SRV_RSP_OK */
    uint32 verify_failed;             /* HSE_SRV_RSP_VERIFY_FAILED */
    uint32 ipsec_invalid_data;        /* HSE_SRV_RSP_IPSEC_INVALID_DATA */
    uint32 ipsec_replay_detected;     /* HSE_SRV_RSP_IPSEC_REPLAY_DETECTED */
    uint32 ipsec_replay_late;         /* HSE_SRV_RSP_IPSEC_REPLAY_LATE */
    uint32 ipsec_seqnum_overflow;     /* HSE_SRV_RSP_IPSEC_SEQNUM_OVERFLOW */
    uint32 ipsec_ce_drop;             /* HSE_SRV_RSP_IPSEC_CE_DROP */
    uint32 ipsec_ttl_exceeded;        /* HSE_SRV_RSP_IPSEC_TTL_EXCEEDED */
    uint32 ipsec_valid_dummy_payload; /* HSE_SRV_RSP_IPSEC_VALID_DUMMY_PAYLOAD */
    uint32 ipsec_header_overflow;     /* HSE_SRV_RSP_IPSEC_HEADER_LEN_OVERFLOW */
    uint32 ipsec_padding_check_fail;  /* HSE_SRV_RSP_IPSEC_PADDING_CHECK_FAIL */
    uint32 handled_error_code;        /* Code of handled error (one of above errors) */
    uint32 handled_error_said;        /* SAId of handled error (one of above errors) */
    uint32 unhandled_error_code;      /* default case store code */
    uint32 unhandled_error_said;      /* default case store code */
} ipsec_state_t;

/**
 * @brief UTIL PE memory map representation type shared between host and PFE
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /*  Common part for all PE types - must be 1st in the structure */
    pfe_ct_common_mmap_t common;
    PFE_PTR(ipsec_state_t) ipsec_state;
} pfe_ct_util_mmap_t;

typedef union __attribute__((packed, aligned(4)))
{
    pfe_ct_common_mmap_t common;    /* Common for both */
    pfe_ct_class_mmap_t class_pe;   /* Class PE variant */
    pfe_ct_util_mmap_t util_pe;     /* UTIL PE variant */
} pfe_ct_pe_mmap_t;

typedef uint32 pfe_ct_hif_rx_flags_t;
#define HIF_RX_NO_FLAG    (pfe_ct_hif_rx_flags_t)0U             /*  No flag being set */
#define HIF_RX_IPV4_CSUM  (pfe_ct_hif_rx_flags_t)(1UL << 0U)    /*  IPv4 checksum valid */
#define HIF_RX_TCPV4_CSUM (pfe_ct_hif_rx_flags_t)(1UL << 1U)    /*  TCP of IPv4 checksum valid */
#define HIF_RX_TCPV6_CSUM (pfe_ct_hif_rx_flags_t)(1UL << 2U)    /*  TCP of IPv6 checksum valid */
#define HIF_RX_UDPV4_CSUM (pfe_ct_hif_rx_flags_t)(1UL << 3U)    /*  UDP of IPv4 checksum valid */
#define HIF_RX_UDPV6_CSUM (pfe_ct_hif_rx_flags_t)(1UL << 4U)    /*  UDP of IPv6 checksum valid */
#define HIF_RX_PTP        (pfe_ct_hif_rx_flags_t)(1UL << 5U)    /*  PTP packet */
#define HIF_RX_TS         (pfe_ct_hif_rx_flags_t)(1UL << 7U)    /*  Timestamp flag. When set, timestamp is valid. */
#define HIF_RX_IHC        (pfe_ct_hif_rx_flags_t)(1UL << 8U)    /*  Inter - HIF communication frame */
#define HIF_RX_ETS        (pfe_ct_hif_rx_flags_t)(1UL << 9U)    /*  Frame is Egress Timestamp Report */
#define HIF_RX_IPV6_CSUM  (pfe_ct_hif_rx_flags_t)(1UL << 10U)   /*  IPv6 checksum valid */
#define HIF_RX_ICMP_CSUM  (pfe_ct_hif_rx_flags_t)(1UL << 11U)   /*  ICMP checksum valid */
#define HIF_RX_HIF0_VLAN  (pfe_ct_hif_rx_flags_t)(1UL << 12U)   /*  Frame send to HIF0 has vlan tag*/
#define HIF_RX_HIF1_VLAN  (pfe_ct_hif_rx_flags_t)(1UL << 13U)   /*  Frame send to HIF1 has vlan tag*/
#define HIF_RX_HIF2_VLAN  (pfe_ct_hif_rx_flags_t)(1UL << 14U)   /*  Frame send to HIF2 has vlan tag*/
#define HIF_RX_HIF3_VLAN  (pfe_ct_hif_rx_flags_t)(1UL << 15U)   /*  Frame send to HIF3 has vlan tag*/

/**
 * @brief   HIF RX packet header
 */
typedef struct __attribute__((packed))
{
    /*  Rx frame flags */
    pfe_ct_hif_rx_flags_t flags;
    /*  Ingress physical interface ID */
    pfe_ct_phy_if_id_t i_phy_if;
    /*  Ingress logical interface ID */
    uint8 i_log_if;
    /*  Queue */
    uint8 queue;
    /*  Reserved */
    uint8 reserved;
    /*  RX timestamp */
    uint32 rx_timestamp_ns;
    uint32 rx_timestamp_s;
} pfe_ct_hif_rx_hdr_t;

ct_assert(sizeof(pfe_ct_hif_rx_hdr_t) == 16U);

typedef uint8 pfe_ct_hif_tx_flags_t;
#define HIF_TX_NO_FLAG   (pfe_ct_hif_tx_flags_t)0U             /*  No flag being set */
#define HIF_TX_RESERVED0 (pfe_ct_hif_tx_flags_t)(1UL << 0U)
#define HIF_TX_ICMP_CSUM (pfe_ct_hif_tx_flags_t)(1UL << 1U)    /*  ICMP checksum offload. If set then PFE will calculate and
                                                               insert ICMP header checksum. */
#define HIF_TX_ETS       (pfe_ct_hif_tx_flags_t)(1UL << 2U)    /*  Generate egress timestamp */
#define HIF_TX_IP_CSUM   (pfe_ct_hif_tx_flags_t)(1UL << 3U)    /*  IP checksum offload. If set then PFE will calculate and
                                                               insert IP header checksum. */
#define HIF_TX_TCP_CSUM  (pfe_ct_hif_tx_flags_t)(1UL << 4U)    /*  TCP checksum offload. If set then PFE will calculate and
                                                               insert TCP header checksum. */
#define HIF_TX_UDP_CSUM  (pfe_ct_hif_tx_flags_t)(1UL << 5U)    /*  UDP checksum offload. If set then PFE will calculate and
                                                               insert UDP header checksum. */
#define HIF_TX_INJECT    (pfe_ct_hif_tx_flags_t)(1UL << 6U)    /*  Transmit Inject Flag. If not set the packet will be processed
                                                               according to Physical Interface configuration. If set then
                                                               e_phy_ifs is valid and packet will be transmitted via physical
                                                               interfaces given by the list. */
#define HIF_TX_IHC       (pfe_ct_hif_tx_flags_t)(1UL << 7U)    /*  Inter-HIF communication frame */

/**
 * @brief   HIF TX packet header
 */
typedef struct __attribute__((packed))
{
    /*  TX flags */
    pfe_ct_hif_tx_flags_t flags;
    /*  Queue number within TMU to be used for packet transmission. Default value
        is zero but can be changed according to current QoS feature configuration. */
    uint8 queue;
    /*  Source HIF channel ID. To be used to identify HIF channel being originator
        of the frame (0, 1, 2, ...). */
    uint8 chid;
    /*  Reserved */
    uint8 reserved1;
    uint16 reserved2;
    /*  Reference number to match transmitted frame and related egress timestamp
        report. Up-most 4 bits must stay 0s. */
    uint16 refnum;
    /*  List of egress physical interfaces to be used for injection. Bit positions
        correspond to pfe_ct_phy_if_id_t values (1U << pfe_ct_phy_if_id_t). */
    uint32 e_phy_ifs;
    /*  HIF cookie. Arbitrary 32-bit value to be passed to classifier. Can be used
        as matching rule within logical interface. See pfe_ct_if_m_rules_t. */
    uint32 cookie;
} pfe_ct_hif_tx_hdr_t;

ct_assert(sizeof(pfe_ct_hif_tx_hdr_t) == 16U);

/*  We expect given pfe_ct_hif_tx_hdr_t size due to byte order compatibility. */
ct_assert(0U == (sizeof(pfe_ct_hif_tx_hdr_t) % sizeof(uint32)));

/**
 * @brief   Egress Timestamp Report
 */
typedef struct __attribute__((packed))
{
    uint8 reserved[3U];
    uint8 ctrl;
    uint32 reserved1;
    uint32 ts_nsec;
    uint32 ts_sec;
    uint8 reserved2;
    uint8 i_phy_if;
    uint16 ref_num;
} pfe_ct_ets_report_t;

/**
 * @brief   Post-classification header
 */
typedef struct __attribute__((packed))
{
    uint8 reserved[16U];
} pfe_ct_post_cls_hdr_t;

/**
 * @brief   Routing actions
 * @details When packet is routed an action or actions can be assigned to be executed
 *          during the routing process. This can be used to configure the router to do
 *          NAT, update TTL, or insert  VLAN header.
 */
typedef uint32 pfe_ct_route_actions_t;
#define RT_ACT_NONE            (pfe_ct_route_actions_t)0U               /*!< No action set */
#define RT_ACT_ADD_ETH_HDR     (pfe_ct_route_actions_t)(1UL << 0U)      /*!< Construct/Update Ethernet Header */
#define RT_ACT_ADD_VLAN_HDR    (pfe_ct_route_actions_t)(1UL << 1U)      /*!< Construct/Update outer VLAN Header */
#define RT_ACT_ADD_PPPOE_HDR   (pfe_ct_route_actions_t)(1UL << 2U)      /*!< Construct/Update PPPOE Header */
#define RT_ACT_DEC_TTL         (pfe_ct_route_actions_t)(1UL << 7U)      /*!< Decrement TTL */
#define RT_ACT_ADD_VLAN1_HDR   (pfe_ct_route_actions_t)(1UL << 11U)     /*!< Construct/Update inner VLAN Header */
#define RT_ACT_CHANGE_SIP_ADDR (pfe_ct_route_actions_t)(1UL << 17U)     /*!< Change Source IP Address */
#define RT_ACT_CHANGE_SPORT    (pfe_ct_route_actions_t)(1UL << 18U)     /*!< Change Source Port */
#define RT_ACT_CHANGE_DIP_ADDR (pfe_ct_route_actions_t)(1UL << 19U)     /*!< Change Destination IP Address */
#define RT_ACT_CHANGE_DPORT    (pfe_ct_route_actions_t)(1UL << 20U)     /*!< Change Destination Port */
#define RT_ACT_DEL_VLAN_HDR    (pfe_ct_route_actions_t)(1UL << 21U)     /*!< Delete outer VLAN Header */
#define RT_ACT_MOD_VLAN_HDR    (pfe_ct_route_actions_t)(1UL << 22U)     /*!< Modify outer VLAN Header */
#define RT_ACT_INVALID         (pfe_ct_route_actions_t)(1UL << 31U)     /*!< Invalid value */

/**
 * @brief   Arguments for routing actions
 */
typedef struct __attribute__((packed, aligned(4)))
{
    /*  Source MAC address (RT_ACT_ADD_ETH_HDR) */
    uint8 smac[6U];
    /*  Destination MAC address (RT_ACT_ADD_ETH_HDR) */
    uint8 dmac[6U];
    /*  PPPOE session ID (RT_ACT_ADD_PPPOE_HDR) */
    uint16 pppoe_sid;
    /*  VLAN ID (RT_ACT_ADD_VLAN_HDR) */
    uint16 vlan;
    /*  L4 source port number (RT_ACT_CHANGE_SPORT) */
    uint16 sport;
    /*  L4 destination port number (RT_ACT_CHANGE_DPORT) */
    uint16 dport;
    /*  Source and destination IPv4 and IPv6 addresses
        (RT_ACT_CHANGE_SIP_ADDR, RT_ACT_CHANGE_DIP_ADDR) */
    pfe_ct_ip_addresses_t ipv;
    /*  Inner VLAN ID (RT_ACT_ADD_VLAN1_HDR) */
    uint16 vlan1;
    /*  Egress vlan index in stats table (RT_ACT_ADD_VLAN_HDR) */
    uint16 vlan_stats_index;
    uint32 sa;
} pfe_ct_route_actions_args_t;

/**
* @brief Configures mirroring 
*/
struct __attribute__((packed, aligned(4))) pfe_ct_mirror_tag
{
    PFE_PTR(pfe_ct_fp_table_t) flexible_filter; /* Only accepted frames are mirrored if pointer is set */
    pfe_ct_route_actions_t actions;             /* Action to be done on mirrored frames */
    pfe_ct_route_actions_args_t args;           /* Arguments for modification actions */
    pfe_ct_phy_if_id_t e_phy_if;                /* Destination for mirrored frames (outbound interface) */
};

/**
 * @brief   Routing table entry flags
 */
typedef uint32 pfe_ct_rtable_flags_t;
#define RT_FL_NONE  (pfe_ct_rtable_flags_t)0U                /*!< No flag set */
#define RT_FL_VALID (pfe_ct_rtable_flags_t)(1UL << 0U)       /*!< Entry is valid */
#define RT_FL_IPV6  (pfe_ct_rtable_flags_t)(1UL << 1U)       /*!< If set entry is IPv6 else it is IPv4 */

/**
 * @brief   Routing table entry status flags
 */
typedef uint8 pfe_rtable_entry_status_t;
#define RT_STATUS_NONE   (pfe_rtable_entry_status_t)0U            /*!< No bit set */
#define RT_STATUS_ACTIVE (pfe_rtable_entry_status_t)(1UL << 0U)   /*!< If set, entry has been matched by routing table lookup algorithm */

/**
 * @brief   The physical routing table entry structure
 * @details This structure is shared between firmware and the driver. It represents
 *          the routing table entry as it is stored in the memory. In case the QB-RFETCH
 *          routing table lookup is enabled (see classifier configuration) then the format
 *          of leading 6*8 bytes of the routing table entry is given by PFE HW and shall
 *          not be modified as well as size of the entry should be 128 bytes. In case the
 *          lookup is done by classifier PE (firmware) the format and length can be adjusted
 *          according to application needs.
 *
 * @warning Do not modify this structure unless synchronization with firmware is ensured.
 */
typedef struct __attribute__((packed, aligned(4))) pfe_ct_rtable_entry_tag
{
    /*  Pointer to next entry in a hash bucket */
    PFE_PTR(struct pfe_ct_rtable_entry_tag) next;
    /*  Flags */
    pfe_ct_rtable_flags_t flags;
    /*  L4 source port number */
    uint16 sport;
    /*  L4 destination port number */
    uint16 dport;
    /*  IP protocol number */
    uint8 proto;
    /*  Ingress physical interface ID */
    pfe_ct_phy_if_id_t i_phy_if;
    /*  Hash storage */
    uint16 hash;
    /*  Source and destination IP addresses */
    pfe_ct_ip_addresses_t ipv;

    /*  ---------- 6x8 byte boundary ---------- */

    /*  */
    /*  Information updated by the Classifier */
    pfe_rtable_entry_status_t status;
    uint8 entry_state;
    /*  Egress physical interface ID */
    pfe_ct_phy_if_id_t e_phy_if;
    /*  IPv6 flag */
    uint8 flag_ipv6;
    /*  Routing actions */
    pfe_ct_route_actions_t actions;
    pfe_ct_route_actions_args_t args;
    /*  General purpose storage */
    uint32 id5t; /* 5-tuple identifier for the IPsec */
    uint16 conntrack_stats_index; /*index in the stats table*/
    uint16 dummy;
    uint32 rt_orig;
} pfe_ct_rtable_entry_t;

/*  We expect given pfe_ct_rtable_entry_t size due to HW requirement. */
ct_assert(sizeof(pfe_ct_rtable_entry_t) == 128U);

#endif /* HW_S32G_PFE_CT_H_ */
/** @} */


===== 文件 [51/185]: include\pfe_ct_comp.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef HW_S32G_PFE_CT_COMP_H_
#define HW_S32G_PFE_CT_COMP_H_
#include "pfe_ct.h"

typedef struct __attribute__((packed,aligned(4)))
{
    const char name[16];
    PFE_PTR(uint8) const data;
    const uint8 size;
    const uint8 multiplicity;
    const uint8 reserved[2];
} pfe_ct_feature_tbl_entry_t ;

typedef struct __attribute__((packed,aligned(4)))
{
    pfe_ct_feature_desc_t feature;
    PFE_PTR(const pfe_ct_feature_tbl_entry_t) cfg;
    PFE_PTR(const pfe_ct_feature_tbl_entry_t) stats;
}pfe_ct_feature_desc_ext_t;

ct_assert(sizeof(pfe_ct_feature_desc_ext_t) == 24);

typedef struct __attribute__((packed, aligned(4)))
{
    uint16 vlan;                      /*!< VLAN value if applicable */
    pfe_ct_vlan_table_result_t entry;   /*!< Entry value - port map and other */
    uint8 field_valids;               /*!< see pfe_mac2f_table_entry_valid_bits_t */
    uint8 flags;                      /*!< see pfe_mac2f_table_entry_flags_t */
    uint16 col_ptr;                   /*!< Collision entry pointer */
} l2br_vlan_hash_entry_t;

ct_assert(sizeof(l2br_vlan_hash_entry_t) == 16);

#endif /* HW_S32G_PFE_CT_COMP_H_ */


===== 文件 [52/185]: include\pfe_ecc_err.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_ECC_ERR_H_
#define PUBLIC_PFE_ECC_ERR_H_

typedef struct pfe_ecc_err_tag pfe_ecc_err_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_ecc_err_t *pfe_ecc_err_create(addr_t cbus_base_va, addr_t ecc_err_base);
void pfe_ecc_err_destroy(pfe_ecc_err_t *ecc_err);
errno_t pfe_ecc_err_isr(const pfe_ecc_err_t *ecc_err);
void pfe_ecc_err_irq_mask(const pfe_ecc_err_t *ecc_err);
void pfe_ecc_err_irq_unmask(const pfe_ecc_err_t *ecc_err);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_ECC_ERR_H_ */


===== 文件 [53/185]: include\pfe_ecc_err_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_ECC_ERR_CSR_H_
#define PFE_ECC_ERR_CSR_H_

#include "pfe_ecc_err.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_ecc_err_cfg_isr(addr_t base_va);
void pfe_ecc_err_cfg_irq_mask(addr_t base_va);
void pfe_ecc_err_cfg_irq_unmask(addr_t base_va);
void pfe_ecc_err_cfg_irq_unmask_all(addr_t base_va);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_ECC_ERR_CSR_H_ */


===== 文件 [54/185]: include\pfe_emac.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_EMAC_H_
#define PUBLIC_PFE_EMAC_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_ct.h"
#include "pfe_gpi.h"
#include "pfe_mac_db.h"
#include "oal.h"

#define PFE_EMAC_INSTANCES 3U

typedef enum
{
    EMAC_MODE_INVALID,
    EMAC_MODE_MII,
    EMAC_MODE_RMII,
    EMAC_MODE_RGMII,
    EMAC_MODE_SGMII
} pfe_emac_mii_mode_t;

typedef enum
{
    EMAC_SPEED_INVALID,
    EMAC_SPEED_10_MBPS,
    EMAC_SPEED_100_MBPS,
    EMAC_SPEED_1000_MBPS,
    EMAC_SPEED_2500_MBPS
} pfe_emac_speed_t;

typedef enum
{
    EMAC_DUPLEX_INVALID,
    EMAC_DUPLEX_HALF,
    EMAC_DUPLEX_FULL
} pfe_emac_duplex_t;

typedef enum
{
    EMAC_LINK_SPEED_INVALID,
    EMAC_LINK_SPEED_2_5_MHZ,
    EMAC_LINK_SPEED_25_MHZ,
    EMAC_LINK_SPEED_125_MHZ
} pfe_emac_link_speed_t;

typedef enum
{
    PFE_FLUSH_MODE_ALL,
    PFE_FLUSH_MODE_UNI,
    PFE_FLUSH_MODE_MULTI
} pfe_flush_mode_t;

typedef struct
{
    addr_t cbus_base_va;            /*  CBUS base virtual address */
    addr_t emac_base_offset;        /*  MAC base offset within CBUS space */
    addr_t emac_base_va;            /*  MAC base address (virtual) */
    pfe_mac_db_t mac_db;            /* MAC database */
    uint8 mac_addr_slots;     /*  Bitmask representing local address slots where '1' means 'slot is used' */
    pfe_emac_mii_mode_t mode;   /*  Current MII mode */
    pfe_emac_speed_t speed;     /*  Current speed */
    pfe_emac_duplex_t duplex;   /*  Current duplex */
    bool_t mdio_locked;         /*  If TRUE then MDIO access is locked and 'mdio_key' is valid */
    uint32 mdio_key;
    uint32 i_clk_hz;          /*  IEEE1588 input clock */
    uint32 o_clk_hz;          /*  IEEE1588 desired output clock */
    uint32 adj_ppb;           /*  IEEE1588 frequency adjustment value */
    bool_t adj_sign;            /*  IEEE1588 frequency adjustment sign (TRUE - positive, FALSE - negative) */
    pfe_gpi_t *gpi;             /* gpi handle, to export gpi services for this emac instance */
    pfe_ct_phy_if_id_t emac_id; /* EMAC id */
} pfe_emac_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#if defined(PFE_CFG_TEXT_STATS)
static inline const char_t *
pfe_emac_mii_mode_to_str(pfe_emac_mii_mode_t mode)
{
    const char_t * ret;
    static const char_t * names[] =
        {"Invalid", "MII", "RMII", "RGMII", "SGMII"};

    if (mode <= EMAC_MODE_SGMII)
    {
        ret = names[mode];
    }
    else
    {
        ret = "out-of-range";
    }
    return ret;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

pfe_emac_t *pfe_emac_create(addr_t cbus_base_va, addr_t emac_base, pfe_emac_mii_mode_t mode, pfe_emac_speed_t speed, pfe_emac_duplex_t duplex);
uint8 pfe_emac_get_index(const pfe_emac_t *emac);
errno_t pfe_emac_bind_gpi(pfe_emac_t *emac, pfe_gpi_t *gpi);
pfe_gpi_t *pfe_emac_get_gpi(const pfe_emac_t *emac);
void pfe_emac_enable(const pfe_emac_t *emac);
void pfe_emac_disable(const pfe_emac_t *emac);
errno_t pfe_emac_enable_ts(pfe_emac_t *emac, uint32 i_clk_hz, uint32 o_clk_hz);
errno_t pfe_emac_set_ts_freq_adjustment(pfe_emac_t *emac, uint32 ppb, bool_t sgn);
errno_t pfe_emac_get_ts_freq_adjustment(pfe_emac_t *emac, uint32 *ppb, bool_t *sgn);
errno_t pfe_emac_set_ts_time(pfe_emac_t *emac, uint32 sec, uint32 nsec, uint16 sec_hi);
errno_t pfe_emac_adjust_ts_time(pfe_emac_t *emac, uint32 sec, uint32 nsec, bool_t sgn);
errno_t pfe_emac_get_ts_time(pfe_emac_t *emac, uint32 *sec, uint32 *nsec, uint16 *sec_hi);
void pfe_emac_enable_loopback(const pfe_emac_t *emac);
void pfe_emac_disable_loopback(const pfe_emac_t *emac);
void pfe_emac_enable_promisc_mode(const pfe_emac_t *emac);
void pfe_emac_disable_promisc_mode(const pfe_emac_t *emac);
void pfe_emac_enable_allmulti_mode(const pfe_emac_t *emac);
void pfe_emac_disable_allmulti_mode(const pfe_emac_t *emac);
void pfe_emac_enable_broadcast(const pfe_emac_t *emac);
void pfe_emac_disable_broadcast(const pfe_emac_t *emac);
void pfe_emac_enable_tx_flow_control(const pfe_emac_t *emac);
void pfe_emac_disable_tx_flow_control(const pfe_emac_t *emac);
void pfe_emac_enable_rx_flow_control(const pfe_emac_t *emac);
void pfe_emac_disable_rx_flow_control(const pfe_emac_t *emac);
void pfe_emac_get_flow_control(const pfe_emac_t *emac, bool_t *tx_enable, bool_t *rx_enable);
errno_t pfe_emac_set_max_frame_length(const pfe_emac_t *emac, uint32 len);
pfe_emac_mii_mode_t pfe_emac_get_mii_mode(const pfe_emac_t *emac);
errno_t pfe_emac_get_link_config(const pfe_emac_t *emac, pfe_emac_speed_t *speed, pfe_emac_duplex_t *duplex);
errno_t pfe_emac_get_link_status(const pfe_emac_t *emac, pfe_emac_link_speed_t *link_speed, pfe_emac_duplex_t *duplex, bool_t *link);
errno_t pfe_emac_set_link_speed(const pfe_emac_t *emac, pfe_emac_speed_t link_speed);
errno_t pfe_emac_set_link_duplex(const pfe_emac_t *emac, pfe_emac_duplex_t duplex);
errno_t pfe_emac_mdio_lock(pfe_emac_t *emac, uint32 *key);
errno_t pfe_emac_mdio_unlock(pfe_emac_t *emac, uint32 key);
errno_t pfe_emac_mdio_read22(pfe_emac_t *emac, uint8 pa, uint8 ra, uint16 *val, uint32 key);
errno_t pfe_emac_mdio_write22(pfe_emac_t *emac, uint8 pa, uint8 ra, uint16 val, uint32 key);
errno_t pfe_emac_mdio_read45(pfe_emac_t *emac, uint8 pa, uint8 dev, uint16 ra, uint16 *val, uint32 key);
errno_t pfe_emac_mdio_write45(pfe_emac_t *emac, uint8 pa, uint8 dev, uint16 ra, uint16 val, uint32 key);
errno_t pfe_emac_add_addr(pfe_emac_t *emac, const pfe_mac_addr_t addr, pfe_drv_id_t owner);
errno_t pfe_emac_flush_mac_addrs(pfe_emac_t *emac, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner);
errno_t pfe_emac_del_addr(pfe_emac_t *emac, const pfe_mac_addr_t addr, pfe_drv_id_t owner);
void pfe_emac_destroy(pfe_emac_t *emac);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_emac_get_text_statistics(const pfe_emac_t *emac, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_emac_get_rx_cnt(const pfe_emac_t *emac);
uint32 pfe_emac_get_tx_cnt(const pfe_emac_t *emac);
uint32 pfe_emac_get_stat_value(const pfe_emac_t *emac, uint32 stat_id);
errno_t pfe_emac_isr(pfe_emac_t *emac);
void pfe_emac_irq_mask(pfe_emac_t *emac);
void pfe_emac_irq_unmask(pfe_emac_t *emac);
errno_t pfe_emac_set_timer_ownership(pfe_emac_t *emac, pfe_drv_id_t drv_id);
errno_t pfe_emac_check_timer_ownership(pfe_emac_t *emac, bool_t *has_owner, pfe_drv_id_t *drv_id);
errno_t pfe_emac_clear_timer_ownership(pfe_emac_t *emac, pfe_drv_id_t drv_id);
errno_t pfe_emac_local_is_timer_owner(pfe_emac_t *emac, bool_t *is_owner);
errno_t pfe_emac_pps0_configure(pfe_emac_t *emac, bool_t enable, uint32 period, uint32 pulse_width);

#ifdef PFE_CFG_EMAC0_PPS0_ENABLE
void pfe_emac_pps0_resync(pfe_emac_t *emac);
#endif

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_EMAC_H_ */


===== 文件 [55/185]: include\pfe_emac_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef SRC_PFE_EMAC_CSR_H_
#define SRC_PFE_EMAC_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_emac.h"
#include "Eth_43_PFE_Cfg.h"

#define MAC_CONFIGURATION                       0x0000U
#define MAC_EXT_CONFIGURATION                   0x0004U
#define MAC_PACKET_FILTER                       0x0008U
#define MAC_WATCHDOG_TIMEOUT                    0x000cU
#define MAC_HASH_TABLE_REG0                     0x0010U
#define MAC_HASH_TABLE_REG1                     0x0014U
#define MAC_HASH_TABLE_REG(n)                   (MAC_HASH_TABLE_REG0 + ((n) * 4U))
#define MAC_VLAN_TAG_CTRL                       0x0050U
#define MAC_VLAN_TAG_DATA                       0x0054U
#define MAC_VLAN_INCL                           0x0060U
#define MAC_INNER_VLAN_INCL                     0x0064U
#define MAC_Q0_TX_FLOW_CTRL                     0x0070U
#define MAC_Q1_TX_FLOW_CTRL                     0x0074U
#define MAC_Q2_TX_FLOW_CTRL                     0x0078U
#define MAC_Q3_TX_FLOW_CTRL                     0x007cU
#define MAC_Q4_TX_FLOW_CTRL                     0x0080U
#define MAC_RX_FLOW_CTRL                        0x0090U
#define MAC_RXQ_CTRL4                           0x0094U
#define MAC_TXQ_PRTY_MAP0                       0x0098U
#define MAC_TXQ_PRTY_MAP1                       0x009cU
#define MAC_RXQ_CTRL0                           0x00a0U
#define MAC_RXQ_CTRL1                           0x00a4U
#define MAC_RXQ_CTRL2                           0x00a8U
#define MAC_RXQ_CTRL3                           0x00acU
#define MAC_INTERRUPT_STATUS                    0x00b0U
#define MAC_INTERRUPT_ENABLE                    0x00b4U
#define MAC_RX_TX_STATUS                        0x00b8U
#define MAC_PMT_CONTROL_STATUS                  0x00c0U
#define MAC_RWK_PACKET_FILTER                   0x00c4U
#define MAC_PHYIF_CONTROL_STATUS                0x00f8U
#define MAC_VERSION                             0x0110U
#define MAC_DEBUG                               0x0114U
#define MAC_HW_FEATURE0                         0x011cU
#define MAC_HW_FEATURE1                         0x0120U
#define MAC_HW_FEATURE2                         0x0124U
#define MAC_HW_FEATURE3                         0x0128U
#define MAC_DPP_FSM_INTERRUPT_STATUS            0x0140U
#define MAC_FSM_CONTROL                         0x0148U
#define MAC_FSM_ACT_TIMER                       0x014cU
#define MAC_SNPS_SCS_REG1                       0x0150U
#define MAC_MDIO_ADDRESS                        0x0200U
#define MAC_MDIO_DATA                           0x0204U
#define MAC_CSR_SW_CTRL                         0x0230U
#define MAC_FPE_CTRL_STS                        0x0234U
#define MAC_EXT_CFG1                            0x0238U
#define MAC_PRESN_TIME_NS                       0x0240U
#define MAC_PRESN_TIME_UPDT                     0x0244U
#define MAC_ADDRESS0_HIGH                       0x0300U
#define MAC_ADDRESS0_LOW                        0x0304U
#define MAC_ADDRESS1_HIGH                       0x0308U
#define MAC_ADDRESS1_LOW                        0x030cU
#define MAC_ADDRESS2_HIGH                       0x0310U
#define MAC_ADDRESS2_LOW                        0x0314U
#define MAC_ADDRESS3_HIGH                       0x0318U
#define MAC_ADDRESS3_LOW                        0x031cU
#define MAC_ADDRESS4_HIGH                       0x0320U
#define MAC_ADDRESS4_LOW                        0x0324U
#define MAC_ADDRESS5_HIGH                       0x0328U
#define MAC_ADDRESS5_LOW                        0x032cU
#define MAC_ADDRESS6_HIGH                       0x0330U
#define MAC_ADDRESS6_LOW                        0x0334U
#define MAC_ADDRESS7_HIGH                       0x0338U
#define MAC_ADDRESS7_LOW                        0x033cU
#define MAC_ADDRESS_HIGH(n)                     (MAC_ADDRESS0_HIGH + ((n) * 8U))
#define MAC_ADDRESS_LOW(n)                      (MAC_ADDRESS0_LOW + ((n) * 8U))

#define MMC_CONTROL                             0x0700U
#define MMC_RX_INTERRUPT                        0x0704U
#define MMC_TX_INTERRUPT                        0x0708U
#define MMC_RX_INTERRUPT_MASK                   0x070cU
#define MMC_TX_INTERRUPT_MASK                   0x0710U

#define MMC_IPC_RX_INTERRUPT_MASK               0x800U
#define MMC_IPC_RX_INTERRUPT                    0x808U

#define TX_OCTET_COUNT_GOOD_BAD                 0x0714U
#define TX_PACKET_COUNT_GOOD_BAD                0x0718U
#define TX_BROADCAST_PACKETS_GOOD               0x071cU
#define TX_MULTICAST_PACKETS_GOOD               0x0720U
#define TX_64OCTETS_PACKETS_GOOD_BAD            0x0724U
#define TX_65TO127OCTETS_PACKETS_GOOD_BAD       0x0728U
#define TX_128TO255OCTETS_PACKETS_GOOD_BAD      0x072cU
#define TX_256TO511OCTETS_PACKETS_GOOD_BAD      0x0730U
#define TX_512TO1023OCTETS_PACKETS_GOOD_BAD     0x0734U
#define TX_1024TOMAXOCTETS_PACKETS_GOOD_BAD     0x0738U
#define TX_UNICAST_PACKETS_GOOD_BAD             0x073cU
#define TX_MULTICAST_PACKETS_GOOD_BAD           0x0740U
#define TX_BROADCAST_PACKETS_GOOD_BAD           0x0744U
#define TX_UNDERFLOW_ERROR_PACKETS              0x0748U
#define TX_SINGLE_COLLISION_GOOD_PACKETS        0x074cU
#define TX_MULTIPLE_COLLISION_GOOD_PACKETS      0x0750U
#define TX_DEFERRED_PACKETS                     0x0754U
#define TX_LATE_COLLISION_PACKETS               0x0758U
#define TX_EXCESSIVE_COLLISION_PACKETS          0x075cU
#define TX_CARRIER_ERROR_PACKETS                0x0760U
#define TX_OCTET_COUNT_GOOD                     0x0764U
#define TX_PACKET_COUNT_GOOD                    0x0768U
#define TX_EXCESSIVE_DEFERRAL_ERROR             0x076cU
#define TX_PAUSE_PACKETS                        0x0770U
#define TX_VLAN_PACKETS_GOOD                    0x0774U
#define TX_OSIZE_PACKETS_GOOD                   0x0778U

#define RX_PACKETS_COUNT_GOOD_BAD               0x0780U
#define RX_OCTET_COUNT_GOOD_BAD                 0x0784U
#define RX_OCTET_COUNT_GOOD                     0x0788U
#define RX_BROADCAST_PACKETS_GOOD               0x078cU
#define RX_MULTICAST_PACKETS_GOOD               0x0790U
#define RX_CRC_ERROR_PACKETS                    0x0794U
#define RX_ALIGNMENT_ERROR_PACKETS              0x0798U
#define RX_RUNT_ERROR_PACKETS                   0x079cU
#define RX_JABBER_ERROR_PACKETS                 0x07a0U
#define RX_UNDERSIZE_PACKETS_GOOD               0x07a4U
#define RX_OVERSIZE_PACKETS_GOOD                0x07a8U
#define RX_64OCTETS_PACKETS_GOOD_BAD            0x07acU
#define RX_65TO127OCTETS_PACKETS_GOOD_BAD       0x07b0U
#define RX_128TO255OCTETS_PACKETS_GOOD_BAD      0x07b4U
#define RX_256TO511OCTETS_PACKETS_GOOD_BAD      0x07b8U
#define RX_512TO1023OCTETS_PACKETS_GOOD_BAD     0x07bcU
#define RX_1024TOMAXOCTETS_PACKETS_GOOD_BAD     0x07c0U
#define RX_UNICAST_PACKETS_GOOD                 0x07c4U
#define RX_LENGTH_ERROR_PACKETS                 0x07c8U
#define RX_OUT_OF_RANGE_TYPE_PACKETS            0x07ccU
#define RX_PAUSE_PACKETS                        0x07d0U
#define RX_FIFO_OVERFLOW_PACKETS                0x07d4U
#define RX_VLAN_PACKETS_GOOD_BAD                0x07d8U
#define RX_WATCHDOG_ERROR_PACKETS               0x07dcU
#define RX_RECEIVE_ERROR_PACKETS                0x07e0U
#define RX_CONTROL_PACKETS_GOOD                 0x07e4U

#define MAC_TIMESTAMP_CONTROL                   0x0b00U
#define MAC_SUB_SECOND_INCREMENT                0x0b04U
#define MAC_SYSTEM_TIME_SECONDS                 0x0b08U
#define MAC_SYSTEM_TIME_NANOSECONDS             0x0b0cU
#define MAC_STSU                                0x0b10U
#define MAC_STNSU                               0x0b14U
#define MAC_TIMESTAMP_ADDEND                    0x0b18U
#define MAC_STS_HIGHER_WORD                     0x0b1cU
#define MAC_PPS_CONTROL                         0x0b70U
#define MAC_PPS0_TARGET_TIME_SECONDS            0x0b80U
#define MAC_PPS0_TARGET_TIME_NANOSECONDS        0x0b84U
#define MAC_PPS0_INTERVAL                       0x0b88U
#define MAC_PPS0_WIDTH                          0x0b8cU
#define MTL_OPERATION_MODE                      0x0c00U
#define MTL_ECC_ERR_ADDR_STATUS                 0x0cd4U
#define MTL_DPP_CONTROL                         0x0ce0U
#define MTL_ECC_CONTROL                         0x0cc0U
#define MTL_ECC_INTERRUPT_STATUS                0x0cccU
#define MTL_ECC_ERR_ADDR_STATUS                 0x0cd4U
#define MTL_ECC_ERR_CNTR_STATUS                 0x0cd8U
#define MTL_TXQ0_OPERATION_MODE                 0x0d00U
#define MTL_RXQ0_OPERATION_MODE                 0x0d30U

#define DMA_ECC_INTERRUPT_STATUS                0x1088U

#define RECEIVE_ALL(x)                  ((!!(x)) ? (1UL << 31U) : 0U)   /* RA */
#define DROP_NON_TCP_UDP(x)             ((!!(x)) ? (1UL << 21U) : 0U)   /* DNTU */
#define L3_L4_FILTER_ENABLE(x)          ((!!(x)) ? (1UL << 20U) : 0U)   /* IPFE */
#define VLAN_TAG_FILTER_ENABLE(x)       ((!!(x)) ? (1UL << 16U) : 0U)   /* VTFE */
#define HASH_OR_PERFECT_FILTER(x)       ((!!(x)) ? (1UL << 10U) : 0U)   /* HPF  */
#define SA_FILTER(x)                    ((!!(x)) ? (1UL << 9U) : 0U)    /* SAF  */
#define SA_INVERSE_FILTER(x)            ((!!(x)) ? (1UL << 8U) : 0U)    /* SAIF  */
#define PASS_CONTROL_PACKETS(x)         (((uint32)(x) & 3UL) << 6U)           /* PCF  */
#define BLOCK_ALL                       0x0U
#define FORWARD_ALL_EXCEPT_PAUSE        0x1U
#define FORWARD_ALL                     0x2U
#define FORWARD_ADDRESS_FILTERED        0x3U
#define DISABLE_BROADCAST_PACKETS(x)    ((!!(x)) ? (1UL << 5U) : 0U)    /* DBF  */
#define PASS_ALL_MULTICAST(x)           ((!!(x)) ? (1UL << 4U) : 0U)    /* PM  */
#define DA_INVERSE_FILTER(x)            ((!!(x)) ? (1UL << 3U) : 0U)    /* DAIF  */
#define HASH_MULTICAST(x)               ((!!(x)) ? (1UL << 2U) : 0U)    /* HMC  */
#define HASH_UNICAST(x)                 ((!!(x)) ? (1UL << 1U) : 0U)    /* HUC  */
#define PROMISCUOUS_MODE(x)             ((!!(x)) ? (1UL << 0U) : 0U)    /* PR  */
#define ARP_OFFLOAD_ENABLE(x)           ((!!(x)) ? (1UL << 31U) : 0U)   /* ARPEN  */
#define SA_INSERT_REPLACE_CONTROL(x)    (((uint32)(x) & 0x7UL) << 28U)    /* SARC   */
#define CTRL_BY_SIGNALS                 0x0U
#define INSERT_MAC0                     0x2U
#define INSERT_MAC1                     0x6U
#define REPLACE_BY_MAC0                 0x3U
#define REPLACE_BY_MAC1                 0x7U
#define CHECKSUM_OFFLOAD(x)             ((!!(x)) ? (1UL << 27U) : 0U)   /* IPC    */
#define INTER_PACKET_GAP(x)             ((((uint32)(x)) & 0x7UL) << 24U)      /* IPG    */
#define GIANT_PACKET_LIMIT_CONTROL(x)   ((!!(x)) ? (1UL << 23U) : 0U)   /* GPSLCE */
#define SUPPORT_2K_PACKETS(x)           ((!!(x)) ? (1UL << 22U) : 0U)   /* S2KP   */
#define CRC_STRIPPING_FOR_TYPE(x)       ((!!(x)) ? (1UL << 21U) : 0U)   /* CST    */
#define AUTO_PAD_OR_CRC_STRIPPING(x)    ((!!(x)) ? (1UL << 20U) : 0U)   /* ACS    */
#define WATCHDOG_DISABLE(x)             ((!!(x)) ? (1UL << 19U) : 0U)   /* WD     */
#define PACKET_BURST_ENABLE(x)          ((!!(x)) ? (1UL << 18U) : 0U)   /* BE     */
#define JABBER_DISABLE(x)               ((!!(x)) ? (1UL << 17U) : 0U)   /* JD     */
#define JUMBO_PACKET_ENABLE(x)          ((!!(x)) ? (1UL << 16U) : 0U)   /* JE     */
#define PORT_SELECT(x)                  ((!!(x)) ? (1UL << 15U) : 0U)   /* PS     */
#define SPEED(x)                        ((!!(x)) ? (1UL << 14U) : 0U)   /* FES    */
#define GET_LINE_SPEED(x)               (((x) >> 14U) & 3U)         /* FES+PS */
#define DUPLEX_MODE(x)                  ((!!(x)) ? (1UL << 13U) : 0U)   /* DM     */
#define GET_DUPLEX_MODE(x)              (((x) >> 13U) & 1U)         /* DM     */
#define LOOPBACK_MODE(x)                ((!!(x)) ? (1UL << 12U) : 0U)   /* LM     */
#define CARRIER_SENSE_BEFORE_TX(x)      ((!!(x)) ? (1UL << 11U) : 0U)   /* ECRSFD */
#define DISABLE_RECEIVE_OWN(x)          ((!!(x)) ? (1UL << 10U) : 0U)   /* DO     */
#define DISABLE_CARRIER_SENSE_TX(x)     ((!!(x)) ? (1UL << 9U) : 0U)    /* DCRS   */
#define DISABLE_RETRY(x)                ((!!(x)) ? (1UL << 8U) : 0U)    /* DR     */
#define BACK_OFF_LIMIT(x)               ((((uint32)(x)) & 3UL) << 5U)         /* BL     */
#define MIN_N_10                        0x0U
#define MIN_N_8                         0x1U
#define MIN_N_4                         0x2U
#define MIN_N_1                         0x3U
#define DEFERRAL_CHECK(x)               ((!!(x)) ? (1UL << 4U) : 0U)    /* DC     */
#define PREAMBLE_LENGTH_TX(x)           (((uint32)(x) & 3UL) << 2U)           /* PRELEN */
#define PREAMBLE_7B                     0x0U
#define PREAMBLE_5B                     0x1U
#define PREAMBLE_3B                     0x2U
#define TRANSMITTER_ENABLE(x)           ((!!(x)) ? (1UL << 1U) : 0UL)   /* TE     */
#define RECEIVER_ENABLE(x)              ((!!(x)) ? (1UL << 0U) : 0UL)   /* RE     */
#define ENABLE_DOUBLE_VLAN(x)           ((!!(x)) ? (1UL << 26U) : 0U)   /* EDVLP  */
#define GIANT_PACKET_SIZE_LIMIT(x)      (((uint32)(x) & 0x3fffUL) << 0U)      /* GPSL   */
#define TX_PAUSE_TIME(x)            (((uint32)(x) & 0xffffUL) << 16U)       /* PT  */
#define TX_PAUSE_LOW_TRASHOLD(x)        (((uint32)(x) & 0x7UL) << 4U)       /* PLT  */
#define TX_FLOW_CONTROL_ENABLE(x)       ((!!(x)) ? (1UL << 1U) : 0U)    /* TFE    */
#define RX_FLOW_CONTROL_ENABLE(x)       ((!!(x)) ? (1UL << 0U) : 0U)    /* RFE    */
#define RX_FLOW_CONTROL_UNICAST(x)      ((!!(x)) ? (1UL << 1U) : 0U)    /* UP    */
#define BUSY_OR_BACKPRESSURE_ACTIVE(x)  ((!!(x)) ? (1UL << 0U) : 0U)    /* FCB_BPA */
#define GMII_BUSY(x)                    ((!!(x)) ? (1UL << 0U) : 0UL)   /* GB     */
#define CLAUSE45_ENABLE(x)              ((!!(x)) ? (1UL << 1U) : 0UL)   /* C45E   */
#define GMII_OPERATION_CMD(x)           (((uint32)(x) & 0x3UL) << 2U)
#define GMII_WRITE                      0x1U
#define GMII_POST_INC_ADDR_CLAUSE45     0x2U
#define GMII_READ                       0x3U
#define SKIP_ADDRESS_PACKET(x)          ((!!(x)) ? (1UL << 4U) : 0UL)   /* SKAP   */
#define CSR_CLOCK_RANGE(x)              (((uint32)(x) & 0xfUL) << 8U)         /* CR     */
#define CSR_CLK_60_100_MHZ_MDC_CSR_DIV_42       0x0U
#define CSR_CLK_100_150_MHZ_MDC_CSR_DIV_62      0x1U
#define CSR_CLK_20_35_MHZ_MDC_CSR_DIV_16        0x2U
#define CSR_CLK_35_60_MHZ_MDC_CSR_DIV_26        0x3U
#define CSR_CLK_150_250_MHZ_MDC_CSR_DIV_102     0x4U
#define CSR_CLK_250_300_MHZ_MDC_CSR_DIV_124     0x5U
#define CSR_CLK_300_500_MHZ_MDC_CSR_DIV_204     0x6U
#define CSR_CLK_500_800_MHZ_MDC_CSR_DIV_324     0x7U
#define CSR_DIV_4                       0x8U
#define CSR_DIV_6                       0x9U
#define CSR_DIV_8                       0xaU
#define CSR_DIV_10                      0xbU
#define CSR_DIV_12                      0xcU
#define CSR_DIV_14                      0xdU
#define CSR_DIV_16                      0xeU
#define CSR_DIV_18                      0xfU
#define NUM_OF_TRAILING_CLOCKS(x)       (((uint32)(x) & 0x7UL) << 12U)        /* NTC    */
#define REG_DEV_ADDR(x)                 (((uint32)(x) & 0x1fUL) << 16L)       /* RDA    */
#define PHYS_LAYER_ADDR(x)              (((uint32)(x) & 0x1fUL) << 21L)       /* PA     */
#define BACK_TO_BACK(x)                 ((!!(x)) ? (1UL << 26U) : 0UL)  /* BTB    */
#define PREAMBLE_SUPPRESSION(x)         ((!!(x)) ? (1UL << 27U) : 0UL)  /* PSE    */
#define GMII_DATA(x)                    ((uint32)(x) & 0xffffUL)
#define GMII_REGISTER_ADDRESS(x)        (((uint32)(x) & 0xffffUL) << 16U)
#define FINE_UPDATE(x)                  ((!!(x)) ? (1UL << 1U) : 0U)    /* TSCFUPDT   */
#define UPDATE_TIMESTAMP(x)             ((!!(x)) ? (1UL << 3U) : 0U)    /* TSUPDT     */
#define FORWARD_ERROR_PACKETS(x)        ((!!(x)) ? (1UL << 4U) : 0UL)   /* FEP        */
#define UPDATE_ADDEND(x)                ((!!(x)) ? (1UL << 5U) : 0U)    /* TSADDREG   */
#define ENABLE_TIMESTAMP(x)             ((!!(x)) ? (1UL << 0U) : 0U)    /* TSENA      */
#define INITIALIZE_TIMESTAMP(x)         ((!!(x)) ? (1UL << 2U) : 0U)    /* TSINIT     */
#define ENABLE_TIMESTAMP_FOR_All(x)     ((!!(x)) ? (1UL << 8U) : 0U)    /* TSENALL    */
#define DIGITAL_ROLLOVER(x)             ((!!(x)) ? (1UL << 9U) : 0U)    /* TSCTRLSSR  */
#define ENABLE_PTP_PROCESSING(x)        ((!!(x)) ? (1UL << 11U) : 0U)   /* TSIPENA    */
#define PTP_OVER_IPV4(x)                ((!!(x)) ? (1UL << 13U) : 0U)   /* TSIPV4ENA  */
#define PTP_OVER_IPV6(x)                ((!!(x)) ? (1UL << 12U) : 0U)   /* TSIPV6ENA  */
#define PTP_OVER_ETH(x)                 ((!!(x)) ? (1UL << 11U) : 0U)   /* TSIPENA    */
#define PTPV2(x)                        ((!!(x)) ? (1UL << 10U) : 0U)   /* TSVER2ENA  */
#define SELECT_PTP_PACKETS(x)           (((uint32)(x) & 0x3UL) << 16U)        /* SNAPTYPSEL */
#define EXTERNAL_TIME(x)                ((!!(x)) ? (1UL << 20U) : 0U)   /* ESTI */
#define LNKSTS(x)                       (((x) >> 19U) & 0x1U)
#define LNKSPEED(x)                     (((x) >> 17U) & 0x3U)
#define LNKMOD(x)                       (((x) >> 16U) & 0x1U)
#define ADDSUB(x)                       ((!!(x)) ? (1UL << 31U) : 0U)
#define ECC_TX(x)                       ((!!(x)) ? (1UL << 0U) : 0U)    /* MTXEE     */
#define ECC_RX(x)                       ((!!(x)) ? (1UL << 1U) : 0U)    /* MRXEE     */
#define ECC_EST(x)                      ((!!(x)) ? (1UL << 2U) : 0U)    /* MESTEE    */
#define ECC_RXP(x)                      ((!!(x)) ? (1UL << 3U) : 0U)    /* MRXPEE    */
#define ECC_TSO(x)                      ((!!(x)) ? (1UL << 4U) : 0U)    /* TSOEE     */
#define DATA_PARITY_PROTECTION(x)       ((!!(x)) ? (1UL << 0U) : 0U)    /* EDPP     */
#define SLAVE_PARITY_CHECK(x)           ((!!(x)) ? (1UL << 2U) : 0U)    /* EPSI     */
#define FSM_TIMEOUT_ENABLE(x)           ((!!(x)) ? (1UL << 0U) : 0U)    /* TMOUTEN  */
#define FSM_PARITY_ENABLE(x)            ((!!(x)) ? (1UL << 1U) : 0U)    /* PRTYEN   */
#define LARGE_MODE_TIMEOUT(x)           ((uint32)(x) << 20U)          /* LTMRMD   */
#define NORMAL_MODE_TIMEOUT(x)          ((uint32)(x) << 16U)          /* NTMRMD   */
#define EMAC_CFG_PPS0_MCGR_ENABLE           (1UL << 7U)                 /* MCGREN0 */
#define EMAC_CFG_PPS0_TRGTMODSEL0(x)        ((uint32)(x) << 5U)       /* TRGTMODSEL0 */
#define EMAC_CFG_PPS0_TRGTMODSEL0_MASK      0x60U                       /* TRGTMODSEL0 */
#define EMAC_CFG_PPS_TRGTMODSEL_ONLY_INT    0U
#define EMAC_CFG_PPS_TRGTMODSEL_INT_ST      2U
#define EMAC_CFG_PPS_TRGTMODSEL_ONLY_ST     3U
#define EMAC_CFG_PPS0_FLEXIBLE_MODE         (1UL << 4U)                 /* PPSEN0 */
#define EMAC_CFG_PPS_PPSCMD_MASK            0xfU                        /* PPSCTRL_PPSCMD */
#define EMAC_CFG_PPS_PPSCMD_NONE               0U                       /* PPSCTRL_PPSCMD */
#define EMAC_CFG_PPS_PPSCMD_START_SINGLE_PULSE 1U                       /* PPSCTRL_PPSCMD */
#define EMAC_CFG_PPS_PPSCMD_START_PULSE_TRAIN  2U                       /* PPSCTRL_PPSCMD */
#define EMAC_CFG_PPS_PPSCMD_CANCEL_START       3U                       /* PPSCTRL_PPSCMD */
#define EMAC_CFG_PPS_PPSCMD_STOP_PULSE_TRAIN   4U                       /* PPSCTRL_PPSCMD */
#define EMAC_CFG_PPS_PPSCMD_STOP_IMMEDIATELY   5U                       /* PPSCTRL_PPSCMD */
#define EMAC_CFG_PPS_PPSCMD_CANCEL_STOP        6U                       /* PPSCTRL_PPSCMD */

/**
 * @brief   Number of HW slots able to hold individual MAC addresses
 * @details The HW can have multiple individual MAC addresses assigned at
 *          a time. The number is limited and this parameter specifies
 *          number of available HW resources.
 */
#define EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT    8U

/**
 * @brief   Mask for upper six bits from 32-bit hash value to index hash table 
 */
#define EMAC_CFG_MAC_HASH_MASK 0xfc000000U

/* Default Tx time between frame control pkts */
#define DEFAULT_PAUSE_QUANTA                   0xF000U

/* MAC_Address(#i)_High reset value */
#define MAC_ADDRESS0_HIGH_RESET_VAL    0x8000FFFFU  /* First MAC entry is always enabled, bit 31 is always set (readonly actually) */
#define MAC_ADDRESSX_HIGH_RESET_VAL    0x0000FFFFU  /* Other MAC entry are disabled */
/* MAC_Address(#i)_Low reset value */
#define MAC_ADDRESSX_LOW_RESET_VAL    0xFFFFFFFFU

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

void pfe_emac_cfg_pre_init(addr_t base_va);
errno_t pfe_emac_cfg_init(addr_t base_va, pfe_emac_mii_mode_t mode,
                                    pfe_emac_speed_t speed, pfe_emac_duplex_t duplex);
uint8 pfe_emac_cfg_get_index(addr_t emac_base, addr_t cbus_base);
errno_t pfe_emac_cfg_enable_ts(addr_t base_va, bool_t eclk, uint32 i_clk_hz, uint32 o_clk_hz);
void pfe_emac_cfg_disable_ts(addr_t base_va);
errno_t pfe_emac_cfg_adjust_ts_freq(addr_t base_va, uint32 i_clk_hz, uint32 o_clk_hz, uint32 ppb, bool_t sgn);
void pfe_emac_cfg_get_ts_time(addr_t base_va, uint32 *sec, uint32 *nsec, uint16 *sec_hi);
errno_t pfe_emac_cfg_set_ts_time(addr_t base_va, uint32 sec, uint32 nsec, uint16 sec_hi);
errno_t pfe_emac_cfg_adjust_ts_time(addr_t base_va, uint32 sec, uint32 nsec, bool_t sgn);
errno_t pfe_emac_cfg_set_duplex(addr_t base_va, pfe_emac_duplex_t duplex);
errno_t pfe_emac_cfg_set_mii_mode(addr_t base_va, pfe_emac_mii_mode_t mode);
errno_t pfe_emac_cfg_set_speed(addr_t base_va, pfe_emac_speed_t speed);
errno_t pfe_emac_cfg_set_max_frame_length(addr_t base_va, uint32 len);
errno_t pfe_emac_cfg_get_link_config(addr_t base_va, pfe_emac_speed_t *speed, pfe_emac_duplex_t *duplex);
errno_t pfe_emac_cfg_get_link_status(addr_t base_va, pfe_emac_link_speed_t *link_speed, pfe_emac_duplex_t *duplex, bool_t *link);
void pfe_emac_cfg_write_addr_slot(addr_t base_va, const pfe_mac_addr_t addr, uint8 slot);
void pfe_emac_cfg_read_addr_slot(addr_t base_va, pfe_mac_addr_t addr, uint8 slot);
uint32 pfe_emac_cfg_get_hash(addr_t base_va, const pfe_mac_addr_t addr);
void pfe_emac_cfg_set_hash_group(addr_t base_va, uint32 hash, bool_t en);
void pfe_emac_cfg_clear_hash_table(addr_t base_va);
void pfe_emac_cfg_set_loopback(addr_t base_va, bool_t en);
void pfe_emac_cfg_set_promisc_mode(addr_t base_va, bool_t en);
void pfe_emac_cfg_set_allmulti_mode(addr_t base_va, bool_t en);
void pfe_emac_cfg_set_broadcast(addr_t base_va, bool_t en);
void pfe_emac_cfg_set_enable(addr_t base_va, bool_t en);
void pfe_emac_cfg_set_tx_flow_control(addr_t base_va, bool_t en);
void pfe_emac_cfg_set_rx_flow_control(addr_t base_va, bool_t en);
void pfe_emac_cfg_get_tx_flow_control(addr_t base_va, bool_t *en);
void pfe_emac_cfg_get_rx_flow_control(addr_t base_va, bool_t *en);
errno_t pfe_emac_cfg_mdio_read22(addr_t base_va, uint8 pa, uint8 ra, uint16 *val);
errno_t pfe_emac_cfg_mdio_read45(addr_t base_va, uint8 pa, uint8 dev, uint16 ra, uint16 *val);
errno_t pfe_emac_cfg_mdio_write22(addr_t base_va, uint8 pa, uint8 ra, uint16 val);
errno_t pfe_emac_cfg_mdio_write45(addr_t base_va, uint8 pa, uint8 dev, uint16 ra, uint16 val);
void pfe_emac_cfg_pps0_configure(addr_t base_va, bool_t mcgr_en, uint8 trgtmodsel, bool_t flexible_en);
void pfe_emac_cfg_pps_cmd(addr_t base_va, uint8 cmd);
void pfe_emac_cfg_pps0_set_target_time(addr_t base_va, uint32 seconds, uint32 nanoseconds);
void pfe_emac_cfg_pps0_set_period(addr_t base_va, uint32 period);
void pfe_emac_cfg_pps0_set_pulse_width(addr_t base_va, uint32 pulse_width);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_emac_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_emac_cfg_get_tx_cnt(addr_t base_va);
uint32 pfe_emac_cfg_get_rx_cnt(addr_t base_va);
uint32 pfe_emac_cfg_get_stat_value(addr_t base_va, uint32 stat_id);
errno_t pfe_emac_cfg_isr(addr_t base_va, addr_t cbus_base);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* SRC_PFE_EMAC_CSR_H_ */


===== 文件 [56/185]: include\pfe_fail_stop.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_FAIL_STOP_H_
#define PUBLIC_PFE_FAIL_STOP_H_

typedef struct pfe_fail_stop_tag pfe_fail_stop_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_fail_stop_t *pfe_fail_stop_create(addr_t cbus_base_va, addr_t fail_stop_base);
void pfe_fail_stop_destroy(pfe_fail_stop_t *fail_stop);
errno_t pfe_fail_stop_isr(const pfe_fail_stop_t *fail_stop);
void pfe_fail_stop_irq_mask(const pfe_fail_stop_t *fail_stop);
void pfe_fail_stop_irq_unmask(const pfe_fail_stop_t *fail_stop);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_FAIL_STOP_H_ */


===== 文件 [57/185]: include\pfe_fail_stop_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_FAIL_STOP_CSR_H_
#define PFE_FAIL_STOP_CSR_H_

#include "pfe_fail_stop.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_fail_stop_cfg_isr(addr_t base_va);
void pfe_fail_stop_cfg_irq_mask(addr_t base_va);
void pfe_fail_stop_cfg_irq_unmask(addr_t base_va);
void pfe_fail_stop_cfg_irq_unmask_all(addr_t base_va);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_FAIL_STOP_CSR_H_ */


===== 文件 [58/185]: include\pfe_feature_mgr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
#ifndef PFE_FEATURE_MGR_H
#define PFE_FEATURE_MGR_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_class.h"
#include "pfe_util.h"
#include "pfe_tmu.h"

#define PFE_HW_FEATURE_RUN_ON_G3    "drv_run_on_g3"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* coverity[misra_c_2012_rule_1_2_violation:FALSE] */
typedef enum __attribute__((packed))
{
    FW_FEATURE_TABLE_DEFAULT = 0U,
    FW_FEATURE_TABLE_CONFIG = 1U,
    FW_FEATURE_TABLE_STATS = 2U
}pfe_table_type_t;

errno_t pfe_feature_mgr_init(uint32 *cbus_base);
errno_t pfe_feature_mgr_fini(void);
errno_t pfe_feature_mgr_add_modules(pfe_class_t *class, pfe_util_t *util, pfe_tmu_t *tmu);
bool_t pfe_feature_mgr_is_available(const char *feature_name);
errno_t pfe_feature_mgr_set_val(const char *feature_name, const uint8 val);
errno_t pfe_feature_mgr_get_val(const char *feature_name, uint8 *val);

errno_t pfe_feature_mgr_get_first(const char **feature_name);
errno_t pfe_feature_mgr_get_next(const char **feature_name);
errno_t pfe_feature_mgr_get_def_val(const char *feature_name, uint8 *val);
errno_t pfe_feature_mgr_get_desc(const char *feature_name, const char **desc);
errno_t pfe_feature_mgr_get_variant(const char *feature_name, uint8 *val);

errno_t pfe_feature_mgr_enable(const char *feature_name);
errno_t pfe_feature_mgr_disable(const char *feature_name);

errno_t pfe_feature_mgr_table_first(const char *feature_name, pfe_table_type_t table_type, const char **table_el_name);
errno_t pfe_feature_mgr_table_next(const char *feature_name, pfe_table_type_t table_type, const char **table_el_name);
errno_t pfe_feature_mgr_table_get_size(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 *size);
errno_t pfe_feature_mgr_table_get_multiplicity(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 *count);
errno_t pfe_feature_mgr_table_get_payload(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 *payload);

errno_t pfe_feature_mgr_table_set_val(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 index, uint8* val);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [59/185]: include\pfe_fp.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
#ifndef PFE_FP_H
#define PFE_FP_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_class.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

void pfe_fp_init(void);
uint32 pfe_fp_create_table(pfe_class_t *class, uint16 rules_count);
uint32 pfe_fp_table_write_rule(pfe_class_t *class, uint32 table_address, const pfe_ct_fp_rule_t *rule, uint16 position);
void pfe_fp_destroy_table(const pfe_class_t *class, uint32 table_address);
errno_t pfe_fp_table_get_statistics(pfe_class_t *class, uint32 pe_idx ,uint32 table_address, pfe_ct_class_flexi_parser_stats_t *stats);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [60/185]: include\pfe_fw_fail_stop.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_FW_FAIL_STOP_H_
#define PUBLIC_PFE_FW_FAIL_STOP_H_

typedef struct pfe_fw_fail_stop_tag pfe_fw_fail_stop_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_fw_fail_stop_t *pfe_fw_fail_stop_create(addr_t cbus_base_va, addr_t fw_fail_stop_base);
void pfe_fw_fail_stop_destroy(pfe_fw_fail_stop_t *fw_fail_stop);
errno_t pfe_fw_fail_stop_isr(const pfe_fw_fail_stop_t *fw_fail_stop);
void pfe_fw_fail_stop_irq_mask(const pfe_fw_fail_stop_t *fw_fail_stop);
void pfe_fw_fail_stop_irq_unmask(const pfe_fw_fail_stop_t *fw_fail_stop);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_FW_FAIL_STOP_H_ */


===== 文件 [61/185]: include\pfe_fw_fail_stop_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_FW_FAIL_STOP_CSR_H_
#define PFE_FW_FAIL_STOP_CSR_H_

#include "pfe_fw_fail_stop.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_fw_fail_stop_cfg_isr(addr_t base_va);
void pfe_fw_fail_stop_cfg_irq_mask(addr_t base_va);
void pfe_fw_fail_stop_cfg_irq_unmask(addr_t base_va);
void pfe_fw_fail_stop_cfg_irq_unmask_all(addr_t base_va);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_FW_FAIL_STOP_CSR_H_ */


===== 文件 [62/185]: include\pfe_fw_feature.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_FW_FEATURE_H
#define PFE_FW_FEATURE_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

typedef errno_t(*dmem_read_func_t)(void *class_p, sint32 pe_idx, void *dst_ptr, addr_t src_addr, uint32 len);
typedef errno_t(*dmem_write_func_t)(void *class_p, sint32 pe_idx, addr_t dst_addr, const void *src_ptr, uint32 len);

typedef struct
{
    union {
        pfe_ct_feature_desc_t *data;
        pfe_ct_feature_desc_ext_t *data_ext;
    } ll;
    const char *string_base;
    dmem_read_func_t dmem_read_func;
    dmem_write_func_t dmem_write_func;
    void *dmem_rw_func_data;
    uint8 current_cfg;
    uint8 current_stats;
    uint8 instances;
} pfe_fw_feature_t;

typedef struct
{
    const pfe_fw_feature_t *feature;
    pfe_ct_feature_tbl_entry_t *tbl_curr;
} pfe_fw_tbl_handle_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_fw_feature_t *pfe_fw_feature_create(pfe_fw_feature_t *feature);
void pfe_fw_feature_destroy(const pfe_fw_feature_t *feature);
errno_t pfe_fw_feature_set_ll_data(pfe_fw_feature_t *feature, pfe_ct_feature_desc_t *ll_data, uint8 instances);
errno_t pfe_fw_feature_set_string_base(pfe_fw_feature_t *feature, const char *string_base);
errno_t pfe_fw_feature_set_dmem_funcs(pfe_fw_feature_t *feature, dmem_read_func_t read_func, dmem_write_func_t write_func, void *data);
errno_t pfe_fw_feature_get_name(const pfe_fw_feature_t *feature, const char **name);
errno_t pfe_fw_feature_get_desc(const pfe_fw_feature_t *feature, const char **desc);
errno_t pfe_fw_feature_get_flags(const pfe_fw_feature_t *feature, pfe_ct_feature_flags_t *flags);
errno_t pfe_fw_feature_get_def_val(const pfe_fw_feature_t *feature, uint8 *def_val);
errno_t pfe_fw_feature_get_val(const pfe_fw_feature_t *feature, uint8 *val);
bool_t pfe_fw_feature_enabled(const pfe_fw_feature_t *feature);
errno_t pfe_fw_feature_set_val(const pfe_fw_feature_t *feature, uint8 val);
bool_t pfe_fw_feature_is_in_class(const pfe_fw_feature_t *feature);
bool_t pfe_fw_feature_is_in_util(const pfe_fw_feature_t *feature);

errno_t pfe_fw_feature_table_stats_first(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table);
errno_t pfe_fw_feature_table_stats_next(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table);
errno_t pfe_fw_feature_table_cfg_first(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table);
errno_t pfe_fw_feature_table_cfg_next(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table);
errno_t pfe_fw_feature_table_entry_name(pfe_fw_tbl_handle_t handle, const char **table_name);
errno_t pfe_fw_feature_table_stats_by_name(const pfe_fw_feature_t *feature, const char_t *name, pfe_fw_tbl_handle_t *entry);
errno_t pfe_fw_feature_table_cfg_by_name(const pfe_fw_feature_t *feature, const char *name, pfe_fw_tbl_handle_t *entry);
uint32 pfe_fw_feature_table_entry_size(pfe_fw_tbl_handle_t handle);
uint32 pfe_fw_feature_table_entry_multiplicity(pfe_fw_tbl_handle_t handle);
uint32 pfe_fw_feature_table_entry_allocsize(pfe_fw_tbl_handle_t handle);
errno_t pfe_fw_feature_table_entry_get(pfe_fw_tbl_handle_t handle, void *mem, uint16 size, bool_t collect);
errno_t pfe_fw_feature_table_entry_get_by_idx(pfe_fw_tbl_handle_t handle, void *mem, uint16 idx, bool_t collect);
errno_t pfe_fw_feature_table_entry_set_by_idx(pfe_fw_tbl_handle_t handle, void *val, uint16 idx);
errno_t pfe_fw_feature_table_entry_set(pfe_fw_tbl_handle_t handle, void *val, uint16 size);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [63/185]: include\pfe_global_wsp.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2019-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_GLOBAL_WSP_CSR_H_
#define PFE_GLOBAL_WSP_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define WSP_VERSION             (0x00U)
#define WSP_CLASS_PE_CNT        (0x04U)
#define WSP_PE_IMEM_DMEM_SIZE   (0x08U)
#define WSP_LMEM_SIZE           (0x0cU)
#define WSP_TMU_EMAC_PORT_COUNT (0x10U)
#define WSP_EGPIS_PHY_NO        (0x14U)
#define WSP_HIF_SUPPORT_PHY_NO  (0x18U)
#define WSP_CLASS_HW_SUPPORT    (0x1cU)
#define WSP_SYS_GENERIC_CONTROL (0x20U)
#define WSP_SYS_GENERIC_STATUS  (0x24U)
#define WSP_SYS_GEN_CON0        (0x28U)
#define WSP_SYS_GEN_CON1        (0x2cU)
#define WSP_SYS_GEN_CON2        (0x30U)
#define WSP_SYS_GEN_CON3        (0x34U)
#define WSP_SYS_GEN_CON4        (0x38U)
#define WSP_DBUG_BUS            (0x3cU)
#define WSP_CLK_FRQ             (0x40U)
#define WSP_EMAC_CLASS_CONFIG   (0x44U)
#define WSP_EGPIS_PHY_NO1       (0x48U)
#define WSP_PARITY_INT_SRC      (0x4cU)
#define WSP_PARITY_INT_EN       (0x50U)
#define WDT_INT_EN              (0x54U)

#define CLASS_WDT_INT_EN        (0x58U)
#define UPE_WDT_INT_EN          (0x5cU)
#define HGPI_WDT_INT_EN         (0x60U)
#define HIF_WDT_INT_EN          (0x64U)
#define TLITE_WDT_INT_EN        (0x68U)
#define HNCPY_WDT_INT_EN        (0x6cU)
#define BMU1_WDT_INT_EN         (0x70U)
#define BMU2_WDT_INT_EN         (0x74U)
#define EMAC0_WDT_INT_EN        (0x78U)
#define EMAC1_WDT_INT_EN        (0x7cU)
#define EMAC2_WDT_INT_EN        (0x80U)
#define EXT_GPT_WDT_INT_EN      (0x134U)
#define LMEM_WDT_INT_EN         (0x140U)

#define WDT_INT_SRC             (0x84U)

#define WDT_TIMER_VAL_UPE       (0x88U)
#define WDT_TIMER_VAL_BMU       (0x8cU)
#define WDT_TIMER_VAL_HIF       (0x90U)
#define WDT_TIMER_VAL_TLITE     (0x94U)
#define WSP_DBUG_BUS1           (0x98U)
#define WDT_TIMER_VAL_HIF_NCPY  (0x98U)
#define WDT_TIMER_VAL_CLASS     (0x9cU)
#define WDT_TIMER_VAL_GPI       (0xa0U)
#define WDT_TIMER_VAL_GPT       (0x138U)
#define WDT_TIMER_VAL_LMEM      (0x144U)
#define WDT_TIMER_VAL_ROUTE_LMEM    (0x148U)

#define WSP_DBUG_BUS1_G3        (0xA4U)

#define WSP_FAIL_STOP_MODE_EN   (0xb4U)
#define WSP_FAIL_STOP_MODE_INT_SRC  (0xbcU)
#define WSP_FAIL_STOP_MODE_INT_EN   (0xc0U)
#define WSP_FW_FAIL_STOP_MODE_INT_SRC (0xc8U)
#define WSP_FW_FAIL_STOP_MODE_INT_EN (0xccU)
#define WSP_BUS_ERR_INT_SRC     (0xd0U)
#define WSP_BUS_ERR_INT_EN      (0xd4U)
#define WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_SRC (0xe0U)
#define WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN (0xe4U)
#define WSP_FAILSTOP_INTERRUPT_SOURCE   (0x128U)
#define WSP_ECC_ERR_INT_SRC     (0x12cU)
#define WSP_ECC_ERR_INT_EN      (0x130U)

/* WSP_SYS_GENERIC_CONTROL bits */
#define WSP_SYS_GEN_SOFT_RST_BIT                    (1UL << 30U)

/* WSP_SYS_GENERIC_CONTROL bits (G3) */
#define WSP_SYS_GEN_SOFT_RST_DONE_CLR_BIT_G3        (1UL << 27U)
#define WSP_SYS_GEN_BMU1_SOFT_RST_DONE_CLR_BIT_G3   (1UL << 28U)
#define WSP_SYS_GEN_BMU2_SOFT_RST_DONE_CLR_BIT_G3   (1UL << 29U)
#define WSP_SYS_GEN_SOFT_RST_DONE_CLR_MASK_G3       (WSP_SYS_GEN_SOFT_RST_DONE_CLR_BIT_G3 | WSP_SYS_GEN_BMU1_SOFT_RST_DONE_CLR_BIT_G3 | WSP_SYS_GEN_BMU2_SOFT_RST_DONE_CLR_BIT_G3)

/* WSP_DBUG_BUS1_G3 bits (G3) */
#define WSP_DBUG_BUS1_SOFT_RST_DONE_BIT_G3          (1UL << 19U)
#define WSP_DBUG_BUS1_BMU1_SOFT_RST_DONE_BIT_G3     (1UL << 20U)
#define WSP_DBUG_BUS1_BMU2_SOFT_RST_DONE_BIT_G3     (1UL << 21U)

/* G2 WDT_INT_EN bits */
#define WDT_INT_EN_BIT_G2               (1UL << 0U)
#define WDT_CLASS_WDT_INT_EN_BIT_G2     (1UL << 1U)
#define WDT_UTIL_PE_WDT_INT_EN_BIT_G2   (1UL << 2U)
#define WDT_HIF_GPI_WDT_INT_EN_BIT_G2   (1UL << 3U)
#define WDT_HIF_WDT_INT_EN_BIT_G2       (1UL << 4U)
#define WDT_TLITE_WDT_INT_EN_BIT_G2     (1UL << 5U)
#define WDT_HIF_NOCPY_WDT_INT_EN_BIT_G2 (1UL << 6U)
#define WDT_BMU1_WDT_INT_EN_BIT_G2      (1UL << 7U)
#define WDT_BMU2_WDT_INT_EN_BIT_G2      (1UL << 8U)
#define WDT_EMAC0_GPI_WDT_INT_EN_BIT_G2 (1UL << 9U)
#define WDT_EMAC1_GPI_WDT_INT_EN_BIT_G2 (1UL << 10U)
#define WDT_EMAC2_GPI_WDT_INT_EN_BIT_G2 (1UL << 11U)

/* G2 WDT_INT_SRC bits*/
#define WDT_INT_G2                  (1UL << 0U)
#define WDT_BMU1_WDT_INT_G2         (1UL << 1U)
#define WDT_BMU2_WDT_INT_G2         (1UL << 2U)
#define WDT_CLASS_WDT_INT_G2        (1UL << 3U)
#define WDT_EMAC0_GPI_WDT_INT_G2    (1UL << 4U)
#define WDT_EMAC1_GPI_WDT_INT_G2    (1UL << 5U)
#define WDT_EMAC2_GPI_WDT_INT_G2    (1UL << 6U)
#define WDT_HIF_GPI_WDT_INT_G2      (1UL << 7U)
#define WDT_HIF_NOCPY_WDT_INT_G2    (1UL << 8U)
#define WDT_HIF_WDT_INT_G2          (1UL << 9U)
#define WDT_TLITE_WDT_INT_G2        (1UL << 10U)
#define WDT_UTIL_WDT_INT_G2         (1UL << 11U)

/* G3 WDT_INT_EN bits */
#define WDT_INT_EN_BIT                  (1UL << 0U)
#define WDT_BMU1_WDT_INT_EN_BIT         (1UL << 1U)
#define WDT_BMU2_WDT_INT_EN_BIT         (1UL << 2U)
#define WDT_CLASS_WDT_INT_EN_BIT        (1UL << 3U)
#define WDT_EMAC0_GPI_WDT_INT_EN_BIT    (1UL << 4U)
#define WDT_EMAC1_GPI_WDT_INT_EN_BIT    (1UL << 5U)
#define WDT_EMAC2_GPI_WDT_INT_EN_BIT    (1UL << 6U)
#define WDT_HIF_GPI_WDT_INT_EN_BIT      (1UL << 7U)
#define WDT_HIF_NOCPY_WDT_INT_EN_BIT    (1UL << 8U)
#define WDT_HIF_WDT_INT_EN_BIT          (1UL << 9U)
#define WDT_TLITE_WDT_INT_EN_BIT        (1UL << 10U)
#define WDT_UTIL_PE_WDT_INT_EN_BIT      (1UL << 11U)
#define WDT_EMAC0_ETGPI_WDT_INT_EN_BIT  (1UL << 12U)
#define WDT_EMAC1_ETGPI_WDT_INT_EN_BIT  (1UL << 13U)
#define WDT_EMAC2_ETGPI_WDT_INT_EN_BIT  (1UL << 14U)
#define WDT_EXT_GPT1_WDT_INT_EN_BIT     (1UL << 15U)
#define WDT_EXT_GPT2_WDT_INT_EN_BIT     (1UL << 16U)
#define WDT_LMEM_WDT_INT_EN_BIT         (1UL << 17U)
#define WDT_ROUTE_LMEM_WDT_INT_EN_BIT   (1UL << 18U)

/* G3 WDT_INT_SRC bits*/
#define WDT_INT                 (1UL << 0U)
#define WDT_BMU1_WDT_INT        (1UL << 1U)
#define WDT_BMU2_WDT_INT        (1UL << 2U)
#define WDT_CLASS_WDT_INT       (1UL << 3U)
#define WDT_EMAC0_GPI_WDT_INT   (1UL << 4U)
#define WDT_EMAC1_GPI_WDT_INT   (1UL << 5U)
#define WDT_EMAC2_GPI_WDT_INT   (1UL << 6U)
#define WDT_HIF_GPI_WDT_INT     (1UL << 7U)
#define WDT_HIF_NOCPY_WDT_INT   (1UL << 8U)
#define WDT_HIF_WDT_INT         (1UL << 9U)
#define WDT_TLITE_WDT_INT       (1UL << 10U)
#define WDT_UTIL_PE_WDT_INT     (1UL << 11U)
#define WDT_EMAC0_ETGPI_WDT_INT (1UL << 12U)
#define WDT_EMAC1_ETGPI_WDT_INT (1UL << 13U)
#define WDT_EMAC2_ETGPI_WDT_INT (1UL << 14U)
#define WDT_EXT_GPT1_WDT_INT    (1UL << 15U)
#define WDT_EXT_GPT2_WDT_INT    (1UL << 16U)
#define WDT_LMEM_WDT_INT        (1UL << 17U)
#define WDT_ROUTE_LMEM_WDT_INT  (1UL << 18U)

/* WSP_PARITY_INT_SRC bits*/
#define PARITY_INT              (1UL << 0U)
#define MASTER1_INT             (1UL << 1U)
#define MASTER2_INT             (1UL << 2U)
#define MASTER3_INT             (1UL << 3U)
#define MASTER4_INT             (1UL << 4U)
#define EMAC_CBUS_INT           (1UL << 5U)
#define EMAC_DBUS_INT           (1UL << 6U)
#define CLASS_CBUS_INT          (1UL << 7U)
#define CLASS_DBUS_INT          (1UL << 8U)
#define TMU_CBUS_INT            (1UL << 9U)
#define TMU_DBUS_INT            (1UL << 10U)
#define HIF_CBUS_INT            (1UL << 11U)
#define HIF_DBUS_INT            (1UL << 12U)
#define HIF_NOCPY_CBUS_INT      (1UL << 13U)
#define HIF_NOCPY_DBUS_INT      (1UL << 14U)
#define UPE_CBUS_INT            (1UL << 15U)
#define UPE_DBUS_INT            (1UL << 16U)
#define HRS_CBUS_INT            (1UL << 17U)
#define BRIDGE_CBUS_INT         (1UL << 18U)
#define EMAC_SLV_INT            (1UL << 19U)
#define BMU1_SLV_INT            (1UL << 20U)
#define BMU2_SLV_INT            (1UL << 21U)
#define CLASS_SLV_INT           (1UL << 22U)
#define HIF_SLV_INT             (1UL << 23U)
#define HIF_NOCPY_SLV_INT       (1UL << 24U)
#define LMEM_SLV_INT            (1UL << 25U)
#define TMU_SLV_INT             (1UL << 26U)
#define UPE_SLV_INT             (1UL << 27U)
#define WSP_GLOBAL_SLV_INT      (1UL << 28U)
#define GPT1_SLV_INT            (1UL << 29U)
#define GPT2_SLV_INT            (1UL << 30U)
#define ROUTEMEM_SLV_INT        (1UL << 31U)

/* WSP_PARITY_INT_EN bits*/
#define PARITY_INT_EN           (1UL << 0U)
#define MASTER1_INT_EN          (1UL << 1U)
#define MASTER2_INT_EN          (1UL << 2U)
#define MASTER3_INT_EN          (1UL << 3U)
#define MASTER4_INT_EN          (1UL << 4U)
#define EMAC_CBUS_INT_EN        (1UL << 5U)
#define EMAC_DBUS_INT_EN        (1UL << 6U)
#define CLASS_CBUS_INT_EN       (1UL << 7U)
#define CLASS_DBUS_INT_EN       (1UL << 8U)
#define TMU_CBUS_INT_EN         (1UL << 9U)
#define TMU_DBUS_INT_EN         (1UL << 10U)
#define HIF_CBUS_INT_EN         (1UL << 11U)
#define HIF_DBUS_INT_EN         (1UL << 12U)
#define HIF_NOCPY_CBUS_INT_EN   (1UL << 13U)
#define HIF_NOCPY_DBUS_INT_EN   (1UL << 14U)
#define UPE_CBUS_INT_EN         (1UL << 15U)
#define UPE_DBUS_INT_EN         (1UL << 16U)
#define HRS_CBUS_INT_EN         (1UL << 17U)
#define BRIDGE_CBUS_INT_EN      (1UL << 18U)
#define EMAC_SLV_INT_EN         (1UL << 19U)
#define BMU1_SLV_INT_EN         (1UL << 20U)
#define BMU2_SLV_INT_EN         (1UL << 21U)
#define CLASS_SLV_INT_EN        (1UL << 22U)
#define HIF_SLV_INT_EN          (1UL << 23U)
#define HIF_NOCPY_SLV_INT_EN    (1UL << 24U)
#define LMEM_SLV_INT_EN         (1UL << 25U)
#define TMU_SLV_INT_EN          (1UL << 26U)
#define UPE_SLV_INT_EN          (1UL << 27U)
#define WSP_GLOBAL_SLV_INT_EN   (1UL << 28U)
#define GPT1_SLV_INT_EN         (1UL << 29U)
#define GPT2_SLV_INT_EN         (1UL << 30U)
#define ROUTEMEM_SLV_INT_EN     (1UL << 31U)

#define PARITY_INT_ENABLE_ALL   0xFFFFFFFFU

/* WSP_BUS_ERR_INT_SRC bits*/
#define BUS_ERR_INT             (1UL << 0U)
#define M1_BUS_RD_ERR_INT       (1UL << 1U)
#define M2_BUS_WR_ERR_INT       (1UL << 2U)
#define M3_BUS_WR_ERR_INT       (1UL << 3U)
#define M4_BUS_RD_ERR_INT       (1UL << 4U)
#define HGPI_BUS_RD_ERR_INT     (1UL << 5U)
#define HGPI_BUS_WR_ERR_INT     (1UL << 6U)
#define EGPI0_BUS_RD_ERR_INT    (1UL << 7U)
#define EGPI0_BUS_WR_ERR_INT    (1UL << 8U)
#define EGPI1_BUS_RD_ERR_INT    (1UL << 9U)
#define EGPI1_BUS_WR_ERR_INT    (1UL << 10U)
#define EGPI2_BUS_RD_ERR_INT    (1UL << 11U)
#define EGPI2_BUS_WR_ERR_INT    (1UL << 12U)
#define CLASS_BUS_RD_ERR_INT    (1UL << 13U)
#define CLASS_BUS_WR_ERR_INT    (1UL << 14U)
#define HIF_NOCPY_BUS_RD_ERR_INT    (1UL << 15U)
#define HIF_NOCPY_BUS_WR_ERR_INT    (1UL << 16U)
#define TMU_BUS_RD_ERR_INT      (1UL << 17U)
#define FET_BUS_RD_ERR_INT      (1UL << 18U)
#define UPE_BUS_RD_ERR_INT      (1UL << 19U)
#define UPE_BUS_WR_ERR_INT      (1UL << 20U)

/* WSP_BUS_ERR_INT_EN bits*/
#define BUS_ERR_INT_EN          (1UL << 0U)
#define M1_BUS_RD_ERR_INT_EN    (1UL << 1U)
#define M2_BUS_WR_ERR_INT_EN    (1UL << 2U)
#define M3_BUS_WR_ERR_INT_EN    (1UL << 3U)
#define M4_BUS_RD_ERR_INT_EN    (1UL << 4U)
#define HGPI_BUS_RD_ERR_INT_EN  (1UL << 5U)
#define HGPI_BUS_WR_ERR_INT_EN  (1UL << 6U)
#define EGPI0_BUS_RD_ERR_INT_EN (1UL << 7U)
#define EGPI0_BUS_WR_ERR_INT_EN (1UL << 8U)
#define EGPI1_BUS_RD_ERR_INT_EN (1UL << 9U)
#define EGPI1_BUS_WR_ERR_INT_EN (1UL << 10U)
#define EGPI2_BUS_RD_ERR_INT_EN (1UL << 11U)
#define EGPI2_BUS_WR_ERR_INT_EN (1UL << 12U)
#define CLASS_BUS_RD_ERR_INT_EN (1UL << 13U)
#define CLASS_BUS_WR_ERR_INT_EN (1UL << 14U)
#define HIF_NOCPY_BUS_RD_ERR_INT_EN     (1UL << 15U)
#define HIF_NOCPY_BUS_WR_ERR_INT_EN     (1UL << 16U)
#define TMU_BUS_RD_ERR_INT_EN   (1UL << 17U)
#define FET_BUS_RD_ERR_INT_EN   (1UL << 18U)
#define UPE_BUS_RD_ERR_INT_EN   (1UL << 19U)
#define UPE_BUS_WR_ERR_INT_EN   (1UL << 20U)

#define BUS_ERR_INT_ENABLE_ALL  0x001FFFFFU

/* WSP_FW_FAIL_STOP_MODE_INT_SRC bits*/
#define FW_FAIL_STOP_INT        (1UL << 0U)
#define FW_FAIL_STOP_MODE_INT   (1UL << 1U)

/* WSP_FW_FAIL_STOP_MODE_INT_EN bits*/
#define FW_FAIL_STOP_INT_EN     (1UL << 0U)
#define FW_FAIL_STOP_MODE_INT_EN    (1UL << 1U)

#define FW_FAIL_STOP_INT_ENABLE_ALL 0x00000003U

/* WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_SRC bits*/
#define HOST_FORCE_DEBUG_FAIL_STOP_INT  (1UL << 0U)
#define HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT     (1UL << 1U)

/* WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN bits*/
#define HOST_FORCE_DEBUG_FAIL_STOP_INT_EN   (1UL << 0U)
#define HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN  (1UL << 1U)

#define HOST_FORCE_DEBUG_FAIL_STOP_INT_ENABLE_ALL   0x00000003U

/* WSP_FAIL_STOP_MODE_INT_SRC bits*/
#define FAIL_STOP_INT           (1UL << 0U)
#define FAIL_STOP_MODE_INT      (1UL << 1U)

/* WSP_FAIL_STOP_MODE_INT_EN bits*/
#define FAIL_STOP_INT_EN        (1UL << 0U)
#define FAIL_STOP_MODE_INT_EN   (1UL << 1U)

#define FAIL_STOP_INT_ENABLE_ALL    0x00000003U

/* WSP_FAILSTOP_INTERRUPT_SOURCE bits */
#define PARITY_FS_INTERRUPT     (1UL << 0U)
#define WDT_FS_INTERRUPT        (1UL << 1U)
#define BUS_ERR_FS_INTERRUPT    (1UL << 2U)
#define ECC_FS_INTERRUPT        (1UL << 3U)
#define FW_FAIL_STOP_FS_INTERRUPT   (1UL << 4U)
#define HOST_FORCE_DEBUG_FAIL_STOP_FS_INTERRUPT (1UL << 5U)

#define WSP_FAILSTOP_INTERRUPT_SOURCE_ALL 0x0000003FU

/* WSP_FAIL_STOP_MODE_EN bits */
#define PARITY_FS_INTERRUPT_EN  (1UL << 0U)
#define WDT_FS_INTERRUPT_EN     (1UL << 1U)
#define BUS_ERR_FS_INTERRUPT_EN (1UL << 2U)
#define ECC_FS_INTERRUPT_EN     (1UL << 3U)
#define FW_FAIL_STOP_FS_INTERRUPT_EN    (1UL << 4U)
#define HOST_FORCE_DEBUG_FAIL_STOP_FS_INTERRUPT_EN  (1UL << 5U)

#define WSP_FAIL_STOP_MODE_ENABLE_ALL   0x0000003FU

/* WSP_ECC_ERR_INT_SRC: bits*/
#define ECC_ERR_INT             (1UL << 0U)
#define ECC_MULTI_ERR_INT       (1UL << 1U)

/* WSP_ECC_ERR_INT_EN bits*/
#define ECC_ERR_INT_EN          (1UL << 0U)
#define ECC_MULTI_ERR_INT_EN    (1UL << 1U)

#define ECC_ERR_INT_ENABLE_ALL  0x00000003U

#endif /* PFE_GLOBAL_WSP_CSR_H_ */


===== 文件 [64/185]: include\pfe_gpi.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_GPI_H_
#define PUBLIC_PFE_GPI_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#define PFE_GPI_INSTANCES 3U
#define PFE_ETGPI_INSTANCES 3U
#define PFE_HGPI_INSTANCES 1U

/* Ingress QoS flow specification */
#define PFE_IQOS_FLOW_TABLE_SIZE    64U
#define PFE_IQOS_FLOW_TABLE_ENTRY_SKIP  0xFFU

typedef struct
{
    uint32 revision;
    uint32 version;
    uint32 id;
    uint32 tx_fifo_packets;
    uint32 rx_fifo_packets;
    uint32 tx_fifo_level;
    uint32 rx_fifo_level;
}pfe_gpi_special_stats_t;

/* flow type to match */
typedef uint16 pfe_iqos_flow_type_t;
#define PFE_IQOS_FLOW_TYPE_ETH    (pfe_iqos_flow_type_t)(1UL << 0U)   /**< match ETH packets */
#define PFE_IQOS_FLOW_TYPE_PPPOE  (pfe_iqos_flow_type_t)(1UL << 1U)   /**< match PPPoE packets */
#define PFE_IQOS_FLOW_TYPE_ARP    (pfe_iqos_flow_type_t)(1UL << 2U)   /**< match ARP packets */
#define PFE_IQOS_FLOW_TYPE_IPV4   (pfe_iqos_flow_type_t)(1UL << 3U)   /**< match IPv4 packets */
#define PFE_IQOS_FLOW_TYPE_IPV6   (pfe_iqos_flow_type_t)(1UL << 4U)   /**< match IPv6 packets */
#define PFE_IQOS_FLOW_TYPE_IPX    (pfe_iqos_flow_type_t)(1UL << 5U)   /**< match IPX packets */
#define PFE_IQOS_FLOW_TYPE_MCAST  (pfe_iqos_flow_type_t)(1UL << 6U)   /**< match multicast (L2) packets */
#define PFE_IQOS_FLOW_TYPE_BCAST  (pfe_iqos_flow_type_t)(1UL << 7U)   /**< match L2 broadcast packets */
#define PFE_IQOS_FLOW_TYPE_VLAN   (pfe_iqos_flow_type_t)(1UL << 8U)   /**< match VLAN tagged packets */
#define PFE_IQOS_FLOW_TYPE_MAX    (pfe_iqos_flow_type_t)(PFE_IQOS_FLOW_TYPE_VLAN | (PFE_IQOS_FLOW_TYPE_VLAN-1U)) /* maximum mask */

/* header field argument type to match */
typedef uint16 pfe_iqos_flow_arg_type_t;
#define PFE_IQOS_ARG_VLAN    (pfe_iqos_flow_arg_type_t)(1UL << 0U)  /**< match on VLAN ID range arguments */
#define PFE_IQOS_ARG_TOS     (pfe_iqos_flow_arg_type_t)(1UL << 1U)  /**< match on TOS range arguments */
#define PFE_IQOS_ARG_L4PROTO (pfe_iqos_flow_arg_type_t)(1UL << 2U)  /**< match on L4 PROTO range arguments */
#define PFE_IQOS_ARG_SIP     (pfe_iqos_flow_arg_type_t)(1UL << 3U)  /**< match on source IPv4/IPv6 address range arguments */
#define PFE_IQOS_ARG_DIP     (pfe_iqos_flow_arg_type_t)(1UL << 4U)  /**< match on destination IPv4/IPv6 address range arguments */
#define PFE_IQOS_ARG_SPORT   (pfe_iqos_flow_arg_type_t)(1UL << 5U)  /**< match on L4 source port range arguments */
#define PFE_IQOS_ARG_DPORT   (pfe_iqos_flow_arg_type_t)(1UL << 6U)  /**< match on L4 destination port range arguments */
#define PFE_IQOS_ARG_MAX     (pfe_iqos_flow_arg_type_t)(PFE_IQOS_ARG_DPORT | (PFE_IQOS_ARG_DPORT-1U)) /* maximum mask */

/* header fields arguments to match */
typedef struct __attribute__((packed, aligned(4)))
{
    uint16 vlan;      /*< VLAN ID (12b) */
    uint16 vlan_m;    /*< VLAN ID mask (12b) */
    uint8 tos;        /*< TOS field for IPv4, TCLASS for IPv6 (8b) */
    uint8 tos_m;      /*< TOS mask (8b) */
    uint8 l4proto;    /*< L4 protocol field for IPv4 and IPv6 (8b)*/
    uint8 l4proto_m;  /*< L4 protocol mask (8b)*/
    uint32 sip;       /*< source IP address for IPv4 and IPv6 (32b) */
    uint32 dip;       /*< destination IP address for IPv4 and IPv6 (32b) */
    uint8 sip_m;      /*< source IP address mask, "6 bit encoded" */
    uint8 dip_m;      /*< destination IP address mask, "6 bit encoded" */
    uint16 sport_max; /*< max L4 source port (16b) */
    uint16 sport_min; /*< min L4 source port (16b) */
    uint16 dport_max; /*< max L4 destination port (16b) */
    uint16 dport_min; /*< min L4 destination port (16b) */
} pfe_iqos_flow_args_t;

#define PFE_IQOS_VLAN_ID_MASK   0xFFFU
#define PFE_IQOS_TOS_MASK   0xFF
#define PFE_IQOS_L4PROTO_MASK   0xFF
#define PFE_IQOS_SDIP_MASK  0x3FU

typedef enum __attribute__((packed))
{
    PFE_IQOS_FLOW_MANAGED = 0,  /**< Mark flow as Managed. Default action on flow match */
    PFE_IQOS_FLOW_DROP,     /**< Drop flow */
    PFE_IQOS_FLOW_RESERVED, /**< Mark flow as Reserved. */

    PFE_IQOS_FLOW_COUNT         /* must be last */
} pfe_iqos_flow_action_t;
ct_assert(sizeof(pfe_iqos_flow_action_t) == sizeof(uint8));

typedef struct __attribute__((packed, aligned(4)))
{
    pfe_iqos_flow_type_t type_mask;
    pfe_iqos_flow_arg_type_t arg_type_mask;
    pfe_iqos_flow_args_t args;
    pfe_iqos_flow_action_t action;
} pfe_iqos_flow_spec_t;

/* Ingress QoS WRED specification */
typedef enum __attribute__((packed))
{
    PFE_IQOS_Q_DMEM = 0,/**< select DMEM for WRED configuration */
    PFE_IQOS_Q_LMEM,    /**< select LMEM for WRED configuration */
    PFE_IQOS_Q_RXF,     /**< select RXF for WRED configuration */

    PFE_IQOS_Q_COUNT    /* must be last */
} pfe_iqos_queue_t;

typedef enum __attribute__((packed))
{
    PFE_IQOS_WRED_ZONE1 = 0,   /**< WRED probability zone1 */
    PFE_IQOS_WRED_ZONE2,       /**< WRED probability zone2 */
    PFE_IQOS_WRED_ZONE3,       /**< WRED probability zone3 */
    PFE_IQOS_WRED_ZONE4,       /**< WRED probability zone4 */

    PFE_IQOS_WRED_ZONES_COUNT  /* must be last */
} pfe_iqos_wred_zone_t;

#define PFE_IQOS_WRED_ZONE_PROB_MAX        15U /* increments of 1/16 */
#define PFE_IQOS_WRED_ZONE_PROB_SKIP      255U /* ignore provided prop value, preserve exiting one */
#define PFE_IQOS_WRED_ZONE1_PROB_DEFAULT    1U
#define PFE_IQOS_WRED_ZONE2_PROB_DEFAULT    2U
#define PFE_IQOS_WRED_ZONE3_PROB_DEFAULT    4U
#define PFE_IQOS_WRED_ZONE4_PROB_DEFAULT    8U

typedef enum __attribute__((packed))
{
    PFE_IQOS_WRED_MIN_THR = 0, /**< WRED queue threshold min level */
    PFE_IQOS_WRED_MAX_THR,     /**< WRED queue threshold max level */
    PFE_IQOS_WRED_FULL_THR,    /**< WRED queue threshold full level */

    PFE_IQOS_WRED_THR_COUNT    /* must be last */
} pfe_iqos_wred_thr_t;

#define PFE_IQOS_WRED_THR_MAX                0x200U
#define PFE_IQOS_WRED_DMEM_THR_MAX           0x2000U
#define PFE_IQOS_WRED_THR_SKIP               0xFFFFU /* ignore provided prop value, preserve exiting one */

#define PFE_IQOS_WRED_MIN_THR_DEFAULT        0x100U
#define PFE_IQOS_WRED_DMEM_MIN_THR_DEFAULT   0x1000U
#define PFE_IQOS_WRED_MAX_THR_DEFAULT        0x1F0U
#define PFE_IQOS_WRED_DMEM_MAX_THR_DEFAULT   0x1FF0U
#define PFE_IQOS_WRED_FULL_THR_DEFAULT       PFE_IQOS_WRED_THR_MAX
#define PFE_IQOS_WRED_DMEM_FULL_THR_DEFAULT  PFE_IQOS_WRED_DMEM_THR_MAX

#define PFE_IQOS_WRED_WEIGHT_MAX             0xFFFFU
#define PFE_IQOS_WRED_WEIGHT_DEFAULT         0x1U

/* Ingress QoS rate shaping specification */
#define PFE_IQOS_SHP_COUNT  2U   /* number of available shapers */

typedef enum __attribute__((packed))
{
    PFE_IQOS_SHP_PORT_LEVEL = 0,    /* port level data rate shaper */
    PFE_IQOS_SHP_BCAST,             /* shaper for broadcast packets */
    PFE_IQOS_SHP_MCAST,             /* shaper for multicast packets */

    PFE_IQOS_SHP_TYPE_COUNT         /* must be last */
} pfe_iqos_shp_type_t;

typedef enum __attribute__((packed))
{
    PFE_IQOS_SHP_BPS = 0,          /* specify data rate in bits per second */
    PFE_IQOS_SHP_PPS,              /* specify data rate in packets per second */

    PFE_IQOS_SHP_RATE_MODE_COUNT   /* must be last */
} pfe_iqos_shp_rate_mode_t;

#define IGQOS_BITMAP_ARR_SZ 2U
#define BITMAP_BITS_U32     32U
#define DECLARE_BITMAP_U32(name, SIZE) \
    uint32 name[SIZE]

typedef struct
{
    addr_t cbus_base_va;    /* CBUS base virtual address */
    addr_t gpi_base_offset; /* GPI base offset within CBUS space */
    addr_t gpi_base_va;     /* GPI base address (virtual) */

    /* bitmap of all (PFE_IQOS_FLOW_TABLE_SIZE) active classification table entries */
    DECLARE_BITMAP_U32(igqos_active_entries, IGQOS_BITMAP_ARR_SZ);
    uint8  igqos_entry_iter; /* classification table active entries interator */
    uint32 sys_clk_mhz;
    uint32 clk_div_log2;
} pfe_gpi_t;
ct_assert(PFE_IQOS_FLOW_TABLE_SIZE <= (BITMAP_BITS_U32 * IGQOS_BITMAP_ARR_SZ));

typedef struct
{
    uint32 alloc_retry_cycles;
    uint32 gpi_tmlf_txthres;
    uint32 gpi_dtx_aseq_len;
    uint16 lmem_header_size;
    bool_t emac_1588_ts_en;
    bool_t g2_ordered_class_writes;
} pfe_gpi_cfg_t;

/* xxGPI instance identification */
typedef enum __attribute__((packed))
{
    PFE_GPI_1 = 0,
    PFE_GPI_2,
    PFE_GPI_3,
    PFE_ETGPI_1,
    PFE_ETGPI_2,
    PFE_ETGPI_3,
    PFE_HGPI_1,
    PFE_XXGPI_INSTANCES
} pfe_xxgpi_id_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_gpi_t *pfe_gpi_create(addr_t cbus_base_va, addr_t gpi_base, const pfe_gpi_cfg_t *cfg, pfe_xxgpi_id_t xxgpi_id);
void pfe_gpi_enable(const pfe_gpi_t *gpi);
errno_t pfe_gpi_reset(const pfe_gpi_t *gpi);
void pfe_gpi_disable(const pfe_gpi_t *gpi);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_gpi_get_text_statistics(const pfe_gpi_t *gpi, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

void pfe_gpi_destroy(pfe_gpi_t *gpi);
uint32 pfe_gpi_cfg_get_sys_clk_mhz(addr_t cbus_base_va);

/* Ingress QoS API */
/* global ingress QoS block enable/disable */
errno_t pfe_gpi_qos_enable(pfe_gpi_t *gpi);
errno_t pfe_gpi_qos_disable(const pfe_gpi_t *gpi);
bool_t pfe_gpi_qos_is_enabled(const pfe_gpi_t *gpi);
errno_t pfe_gpi_qos_reset(pfe_gpi_t *gpi);

/* flow add/remove/get */
errno_t pfe_gpi_qos_add_flow(pfe_gpi_t *gpi, uint8 id, pfe_iqos_flow_spec_t *flow);
errno_t pfe_gpi_qos_rem_flow(pfe_gpi_t *gpi, uint8 id);
errno_t pfe_gpi_qos_get_flow(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_flow_spec_t *flow);
errno_t pfe_gpi_qos_get_first_flow(pfe_gpi_t *gpi, uint8 *id, pfe_iqos_flow_spec_t *flow);
errno_t pfe_gpi_qos_get_next_flow(pfe_gpi_t *gpi, uint8 *id, pfe_iqos_flow_spec_t *flow);

/* WRED API */
errno_t pfe_gpi_wred_enable(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue); /* enable with default settings */
errno_t pfe_gpi_wred_disable(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue);
bool_t pfe_gpi_wred_is_enabled(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue);
/* WRED modifiers */
errno_t pfe_gpi_wred_set_prob(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 val);
errno_t pfe_gpi_wred_get_prob(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 *val);
errno_t pfe_gpi_wred_set_thr(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 val);
errno_t pfe_gpi_wred_get_thr(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 *val);

/* shaper API*/
errno_t pfe_gpi_shp_enable(pfe_gpi_t *gpi, uint8 id); /* enable with default settings */
errno_t pfe_gpi_shp_disable(const pfe_gpi_t *gpi, uint8 id);
bool_t pfe_gpi_shp_is_enabled(const pfe_gpi_t *gpi, uint8 id);
/* shaper modifiers */
errno_t pfe_gpi_shp_set_mode(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_rate_mode_t mode);
errno_t pfe_gpi_shp_get_mode(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_rate_mode_t *mode);
errno_t pfe_gpi_shp_set_type(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_type_t type);
errno_t pfe_gpi_shp_get_type(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_type_t *type);
errno_t pfe_gpi_shp_set_idle_slope(pfe_gpi_t *gpi, uint8 id, uint32 isl);
errno_t pfe_gpi_shp_get_idle_slope(const pfe_gpi_t *gpi, uint8 id, uint32 *isl);
errno_t pfe_gpi_shp_set_limits(const pfe_gpi_t *gpi, uint8 id, sint32 max_credit, sint32 min_credit);
errno_t pfe_gpi_shp_get_limits(const pfe_gpi_t *gpi, uint8 id, sint32 *max_credit, sint32 *min_credit);
errno_t pfe_gpi_shp_get_drop_cnt(const pfe_gpi_t *gpi, uint8 id, uint32 *cnt);

uint32 pfe_gpi_get_stat_value(const pfe_gpi_t * gpi, uint32 stat_id);
errno_t pfe_gpi_get_special_stats(const pfe_gpi_t* gpi, pfe_gpi_special_stats_t* special_stats);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_GPI_H_ */


===== 文件 [65/185]: include\pfe_gpi_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_GPI_CSR_H_
#define PFE_GPI_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_gpi.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define GPI_VERSION                 0x000U
#define GPI_CTRL                    0x004U
#define GPI_RX_CONFIG                   0x008U
#define GPI_HDR_SIZE                    0x00cU
#define GPI_BUF_SIZE                    0x010U
#define GPI_LMEM_ALLOC_ADDR             0x014U
#define GPI_LMEM_FREE_ADDR              0x018U
#define GPI_DDR_ALLOC_ADDR              0x01cU
#define GPI_DDR_FREE_ADDR               0x020U
#define GPI_CLASS_ADDR                  0x024U
#define GPI_DRX_FIFO                    0x028U
#define GPI_TRX_FIFO                    0x02cU
#define GPI_INQ_PKTPTR                  0x030U
#define GPI_DDR_DATA_OFFSET             0x034U
#define GPI_LMEM_DATA_OFFSET                0x038U
#define GPI_TMLF_TX                 0x04cU
#define GPI_DTX_ASEQ                    0x050U
#define GPI_FIFO_STATUS                 0x054U
#define GPI_FIFO_DEBUG                  0x058U
#define GPI_TX_PAUSE_TIME               0x05cU
#define GPI_LMEM_SEC_BUF_DATA_OFFSET            0x060U
#define GPI_DDR_SEC_BUF_DATA_OFFSET         0x064U
#define GPI_CSR_TOE_CHKSUM_EN               0x068U
#define GPI_OVERRUN_DROPCNT             0x06cU
#define GPI_TX_DBUG_REG1                0x070U
#define GPI_TX_DBUG_REG2                0x074U
#define GPI_TX_DBUG_REG3                0x078U
#define GPI_TX_DBUG_REG4                0x07cU
#define GPI_TX_DBUG_REG5                0x080U
#define GPI_TX_DBUG_REG6                0x084U
#define GPI_RX_DBUG_REG1                0x090U
#define GPI_RX_DBUG_REG2                0x094U

#define GPI_PORT_SHP0_CTRL              0x098U
#define GPI_PORT_SHP0_WGHT              0x09cU
#define GPI_PORT_SHP0_STATUS                0x100U

#define GPI_BMU1_PHY_LOW_WATERMARK          0x104U
#define GPI_BMU1_PHY_HIGH_WATERMARK         0x108U
#define GPI_BMU2_PHY_LOW_WATERMARK          0x10cU
#define GPI_BMU2_PHY_HIGH_WATERMARK         0x110U

#define GPI_FW_CONTROL                  0x114U
#define GPI_USE_CLASS_INQ_AFULL             0x118U

#define GPI_PORT_SHP1_CTRL              0x11cU
#define GPI_PORT_SHP1_WGHT              0x120U
#define GPI_PORT_SHP1_STATUS                0x124U
#define GPI_PORT_SHP_CONFIG             0x128U
#define GPI_CSR_SHP_DROPCNT             0x12cU

#define GPI_FW_CONTROL1                 0x130U
#define GPI_RXF_FIFO_LOW_WATERMARK          0x134U
#define GPI_RXF_FIFO_HIGH_WATERMARK         0x138U

#define GPI_EMAC_1588_TIMESTAMP_EN          0x13cU

#define GPI_PORT_SHP0_MIN_CREDIT            0x140U
#define GPI_PORT_SHP1_MIN_CREDIT            0x144U
#define GPI_PORT_SHP_MIN_CREDIT(i)          ((addr_t)0x140U + ((i) * (addr_t)4U))

#define GPI_LMEM2_FREE_ADDR             0x148U
#define GPI_CSR_AXI_WRITE_DONE_ADDR         0x14cU

#define CSR_IQGOS_DMEMQ_ZONE_PROB           0x150U
#define CSR_IGQOS_DMEMQ_FULL_THRESH         0x154U
#define CSR_IGQOS_DMEMQ_DROP_THRESH         0x158U
#define CSR_IGQOS_LMEMQ_ZONE_PROB           0x15cU
#define CSR_IGQOS_LMEMQ_FULL_THRESH         0x160U
#define CSR_IGQOS_LMEMQ_DROP_THRESH         0x164U
#define CSR_IGQOS_RXFQ_ZONE_PROB            0x168U
#define CSR_IGQOS_RXFQ_FULL_THRESH          0x16cU
#define CSR_IGQOS_RXFQ_DROP_THRESH          0x170U
#define CSR_IQGOS_ZONE_PROB(q)              ((addr_t)0x150U + ((q) * (addr_t)0xcU))
#define CSR_IQGOS_FULL_THRESH(q)            ((addr_t)0x154U + ((q) * (addr_t)0xcU))
#define CSR_IQGOS_DROP_THRESH(q)            ((addr_t)0x158U + ((q) * (addr_t)0xcU))

#define CSR_IGQOS_CONTROL               0x174U
#define CSR_IGQOS_CLASS                 0x178U
#define CSR_IGQOS_QOS                   0x17cU
#define CSR_IGQOS_ENTRY_CMDSTATUS           0x180U
#define CSR_IGQOS_ENTRY_CMDCNTRL            0x184U
#define CSR_IGQOS_ENTRY_DATA_REG(i)         ((addr_t)0x188U + ((i) * (addr_t)4U))
#define CSR_IGQOS_QUEUE_STATUS              0x1a8U
#define CSR_IGQOS_STAT_CLASS_DROP_CNT           0x1acU
#define CSR_IGQOS_STAT_LMEM_QUEUE_DROP_CNT      0x1b0U
#define CSR_IGQOS_STAT_DMEM_QUEUE_DROP_CNT      0x1b4U
#define CSR_IGQOS_STAT_RXF_QUEUE_DROP_CNT       0x1b8U
#define CSR_IGQOS_STAT_SHAPER0_DROP_CNT         0x1bcU
#define CSR_IGQOS_STAT_SHAPER1_DROP_CNT         0x1c0U
#define CSR_IGQOS_STAT_SHAPER_DROP_CNT(i)       ((addr_t)CSR_IGQOS_STAT_SHAPER0_DROP_CNT + ((i) * (addr_t)4U))
#define CSR_IGQOS_STAT_MANAGED_PACKET_CNT       0x1c4U
#define CSR_IGQOS_STAT_UNMANAGED_PACKET_CNT     0x1c8U
#define CSR_IGQOS_STAT_RESERVED_PACKET_CNT      0x1ccU
#define CSR_IGQOS_STAT_GEN_CNT1             0x1d0U
#define CSR_IGQOS_STAT_GEN_CNT2             0x1d4U
#define CSR_IGQOS_STAT_GEN_CNT3             0x1d8U
#define CSR_IGQOS_STAT_GEN_CNT4             0x1dcU

#define CSR_IGQOS_PORT_SHP0_CTRL            0x1e0U
#define CSR_IGQOS_PORT_SHP0_WGHT            0x1e4U
#define CSR_IGQOS_PORT_SHP0_STATUS          0x1e8U
#define CSR_IGQOS_PORT_SHP1_CTRL            0x1ecU
#define CSR_IGQOS_PORT_SHP1_WGHT            0x1f0U
#define CSR_IGQOS_PORT_SHP1_STATUS          0x1f4U
#define CSR_IGQOS_PORT_SHP_CTRL(i)          ((addr_t)0x1e0U + ((i) * (addr_t)0xcU))
#define CSR_IGQOS_PORT_SHP_WGHT(i)          ((addr_t)0x1e4U + ((i) * (addr_t)0xcU))
#define CSR_IGQOS_PORT_SHP_STATUS(i)        (0x1e8U + ((i) * 0xcU))

#define CSR_IGQOS_PORT_SHP_CONFIG           0x1f8U
#define CSR_IGQOS_CSR_SHP_DROPCNT           0x1fcU

#define CSR_IGQOS_PORT_SHP0_MIN_CREDIT          0x200U
#define CSR_IGQOS_PORT_SHP1_MIN_CREDIT          0x204U
#define CSR_IGQOS_PORT_SHP_MIN_CREDIT(i)        ((addr_t)0x200U + ((i) * (addr_t)0x4U))

#define CSR_IGQOS_LRU_TIMER_VALUE           0x208U
#define CSR_IGQOS_LRU_ENTRY             0x20cU
#define CSR_IGQOS_SMEM_OFFSET               0x210U
#define CSR_IGQOS_LMEM_OFFSET               0x214U
#define CSR_IGQOS_TPID                  0x218U
#define CSR_IGQOS_DEBUG                 0x21cU
#define CSR_IGQOS_DEBUG1                0x220U
#define CSR_IGQOS_DEBUG2                0x224U
#define CSR_IGQOS_DEBUG3                0x228U
#define CSR_IGQOS_DEBUG4                0x22cU
#define CSR_IGQOS_DEBUG5                0x230U
#define CSR_IGQOS_DEBUG6                0x234U
#define CSR_IGQOS_DEBUG7                0x238U
#define CSR_IGQOS_STAT_TOTAL_DROP_CNT           0x23cU
#define CSR_IGQOS_LRU_TIMER             0x240U
#define CSR_IGQOS_LRU_TIMER_LOAD_VALUE          0x244U

/* reg values */
#define mask32(width)                   ((uint32)(((uint32)1U << (width)) - 1U))
#define IGQOS_CONTROL_QOS_EN                BIT(0)
#define IGQOS_TPID_DOT1Q                0x8100U

#define IGQOS_CLASS_TPID0_EN                BIT(4)
#define IGQOS_CLASS_TPID1_EN                BIT(5)

#define IGQOS_QOS_WRED_LMEMQ_EN             BIT(0)
#define IGQOS_QOS_WRED_DMEMQ_EN             BIT(1)
#define IGQOS_QOS_WRED_RXFQ_EN              BIT(2)
#define IGQOS_WRED_EN                   (IGQOS_QOS_WRED_LMEMQ_EN | IGQOS_QOS_WRED_DMEMQ_EN | \
                            IGQOS_QOS_WRED_RXFQ_EN)

#ifndef BIT
    #define BIT(x)  (1UL << (x))
#endif
#define IGQOS_PORT_SHP_FRACW_WIDTH          8
#define IGQOS_PORT_SHP_INTW_WIDTH           3
#define IGQOS_PORT_SHP_WEIGHT_MASK          mask32(IGQOS_PORT_SHP_FRACW_WIDTH + IGQOS_PORT_SHP_INTW_WIDTH)
#define IGQOS_PORT_SHP_MODE_PPS(i)          BIT(i)
#define IGQOS_PORT_SHP_TYPE_POS(i)          (((i) + 1U) * 2U)
#define IGQOS_PORT_SHP_TYPE_MASK            0x3U
#define IGQOS_PORT_SHP_CLKDIV_POS           1
#define IGQOS_PORT_SHP_CLKDIV_MASK          0xfU
#define IGQOS_PORT_SHP_MAX_CREDIT_POS           8U
#define IGQOS_PORT_SHP_CREDIT_MASK          0x3fffffU
#define IGQOS_PORT_SHP_CREDIT_MAX           0x3fffff

#define ENTRY_TABLE_SIZE                64U
#define ENTRY_DATA_REG_CNT              8U

#define CMDCNTRL_CMD_WRITE              0x1U
#define CMDCNTRL_CMD_READ               0x2U
#define CMDCNTRL_CMD_TAB_ADDR(x)            ((((uint32)(x)) & 0x7fU) << 8)
#define CMDCNTRL_CMD_TAB_SELECT_LRU         BIT(16)

#define GPI_LMEM_BUF_EN                 0x1U
#define GPI_DDR_BUF_EN                  0x2U
#define HGPI_LMEM_RTRY_CNT              0x40U
#define HGPI_TMLF_TXTHRES               0xBCU
#define HGPI_ASEQ_LEN                   0x40U

/* Class table entry formatting.
 * Each entry was divided into 8 32-bit registers.
 * The bitfield ranges were extracted directly from the h/w ref man.
 */
#define GPI_QOS_FLOW_REG_OFF(table_offset)  ((table_offset) % 32)
#define GPI_QOS_FLOW_ARG_WIDTH(off1, off2)  ((off2) - (off1))
/* data entry reg 0 */
#define GPI_QOS_FLOW_TYPE_OFF       GPI_QOS_FLOW_REG_OFF(0)
#define GPI_QOS_FLOW_TYPE_WIDTH     GPI_QOS_FLOW_ARG_WIDTH(0, 10)
#define GPI_QOS_FLOW_VLAN_ID_OFF    GPI_QOS_FLOW_REG_OFF(10)
#define GPI_QOS_FLOW_VLAN_ID_WIDTH  GPI_QOS_FLOW_ARG_WIDTH(10, 22)
#define GPI_QOS_FLOW_TOS_OFF        GPI_QOS_FLOW_REG_OFF(22)
#define GPI_QOS_FLOW_TOS_WIDTH      GPI_QOS_FLOW_ARG_WIDTH(22, 30)
#define GPI_QOS_FLOW_PROT_OFF       GPI_QOS_FLOW_REG_OFF(30)
#define GPI_QOS_FLOW_PROT_WIDTH     GPI_QOS_FLOW_ARG_WIDTH(30, 32)
/* data entry reg 1 */
#define GPI_QOS_FLOW_PROT_UP_OFF    GPI_QOS_FLOW_REG_OFF(32)
#define GPI_QOS_FLOW_PROT_UP_WIDTH  GPI_QOS_FLOW_ARG_WIDTH(30, 38)
#define GPI_QOS_FLOW_SIP_OFF        GPI_QOS_FLOW_REG_OFF(38)
#define GPI_QOS_FLOW_SIP_WIDTH      GPI_QOS_FLOW_ARG_WIDTH(38, 64)
/* data entry reg 2 */
#define GPI_QOS_FLOW_SIP_UP_OFF     GPI_QOS_FLOW_REG_OFF(64)
#define GPI_QOS_FLOW_SIP_UP_WIDTH   GPI_QOS_FLOW_ARG_WIDTH(64, 70)
#define GPI_QOS_FLOW_DIP_OFF        GPI_QOS_FLOW_REG_OFF(70)
#define GPI_QOS_FLOW_DIP_WIDTH      GPI_QOS_FLOW_ARG_WIDTH(70, 96)
/* data entry reg 3 */
#define GPI_QOS_FLOW_DIP_UP_OFF     GPI_QOS_FLOW_REG_OFF(96)
#define GPI_QOS_FLOW_DIP_UP_WIDTH   GPI_QOS_FLOW_ARG_WIDTH(96, 102)
#define GPI_QOS_FLOW_SPORT_MIN_OFF  GPI_QOS_FLOW_REG_OFF(102)
#define GPI_QOS_FLOW_SPORT_MIN_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(102, 118)
#define GPI_QOS_FLOW_SPORT_MAX_OFF  GPI_QOS_FLOW_REG_OFF(118)
#define GPI_QOS_FLOW_SPORT_MAX_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(118, 128)
/* data entry reg 4 */
#define GPI_QOS_FLOW_SPORT_MAX_UP_OFF   GPI_QOS_FLOW_REG_OFF(128)
#define GPI_QOS_FLOW_SPORT_MAX_UP_WIDTH GPI_QOS_FLOW_ARG_WIDTH(128, 134)
#define GPI_QOS_FLOW_DPORT_MIN_OFF  GPI_QOS_FLOW_REG_OFF(134)
#define GPI_QOS_FLOW_DPORT_MIN_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(134, 150)
#define GPI_QOS_FLOW_DPORT_MAX_OFF  GPI_QOS_FLOW_REG_OFF(150)
#define GPI_QOS_FLOW_DPORT_MAX_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(150, 160)
/* data entry reg 5 */
#define GPI_QOS_FLOW_DPORT_MAX_UP_OFF   GPI_QOS_FLOW_REG_OFF(160)
#define GPI_QOS_FLOW_DPORT_MAX_UP_WIDTH GPI_QOS_FLOW_ARG_WIDTH(160, 166)
#define GPI_QOS_FLOW_VALID_ENTRY_OFF    GPI_QOS_FLOW_REG_OFF(166)
#define GPI_QOS_FLOW_VALID_ENTRY_WIDTH  GPI_QOS_FLOW_ARG_WIDTH(166, 167)
#define GPI_QOS_FLOW_TYPE_M_OFF     GPI_QOS_FLOW_REG_OFF(167)
#define GPI_QOS_FLOW_TYPE_M_WIDTH   GPI_QOS_FLOW_ARG_WIDTH(167, 177)
#define GPI_QOS_FLOW_VLAN_ID_M_OFF  GPI_QOS_FLOW_REG_OFF(177)
#define GPI_QOS_FLOW_VLAN_ID_M_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(177, 189)
#define GPI_QOS_FLOW_TOS_M_OFF      GPI_QOS_FLOW_REG_OFF(189)
#define GPI_QOS_FLOW_TOS_M_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(189, 192)
/* data entry reg 6 */
#define GPI_QOS_FLOW_TOS_M_UP_OFF   GPI_QOS_FLOW_REG_OFF(192)
#define GPI_QOS_FLOW_TOS_M_UP_WIDTH GPI_QOS_FLOW_ARG_WIDTH(192, 197)
#define GPI_QOS_FLOW_PROT_M_OFF     GPI_QOS_FLOW_REG_OFF(197)
#define GPI_QOS_FLOW_PROT_M_WIDTH   GPI_QOS_FLOW_ARG_WIDTH(197, 205)
#define GPI_QOS_FLOW_SIP_M_OFF      GPI_QOS_FLOW_REG_OFF(205)
#define GPI_QOS_FLOW_SIP_M_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(205, 211)
#define GPI_QOS_FLOW_DIP_M_OFF      GPI_QOS_FLOW_REG_OFF(211)
#define GPI_QOS_FLOW_DIP_M_WIDTH    GPI_QOS_FLOW_ARG_WIDTH(211, 217)
#define GPI_QOS_FLOW_SPORT_M_OFF    GPI_QOS_FLOW_REG_OFF(217)
#define GPI_QOS_FLOW_SPORT_M_WIDTH  GPI_QOS_FLOW_ARG_WIDTH(217, 218)
#define GPI_QOS_FLOW_DPORT_M_OFF    GPI_QOS_FLOW_REG_OFF(218)
#define GPI_QOS_FLOW_DPORT_M_WIDTH  GPI_QOS_FLOW_ARG_WIDTH(218, 219)
#define GPI_QOS_FLOW_ACT_DROP_OFF   GPI_QOS_FLOW_REG_OFF(219)
#define GPI_QOS_FLOW_ACT_DROP_WIDTH GPI_QOS_FLOW_ARG_WIDTH(219, 220)
#define GPI_QOS_FLOW_ACT_RES_OFF    GPI_QOS_FLOW_REG_OFF(220)
#define GPI_QOS_FLOW_ACT_RES_WIDTH  GPI_QOS_FLOW_ARG_WIDTH(220, 221)

#define flow_arg_lower(name, arg)   (mask32(GPI_QOS_FLOW_##name##_WIDTH) & (arg))
#define flow_arg_upper(name, arg)   (mask32(GPI_QOS_FLOW_##name##_UP_WIDTH) & \
                     ((arg) >> GPI_QOS_FLOW_##name##_WIDTH))

#define entry_arg_set_lower(name, arg)  (flow_arg_lower(name, arg) << GPI_QOS_FLOW_##name##_OFF)
#define entry_arg_set_upper(name, arg)  (flow_arg_upper(name, arg) << GPI_QOS_FLOW_##name##_UP_OFF)
#define entry_arg_set(name, arg)    entry_arg_set_lower(name, arg)

#define entry_arg_get_lower(name, entry) (((entry) >> GPI_QOS_FLOW_##name##_OFF) & \
                      mask32(GPI_QOS_FLOW_##name##_WIDTH))
#define entry_arg_get_upper(name, entry) (((entry) & mask32(GPI_QOS_FLOW_##name##_UP_WIDTH)) << \
                      GPI_QOS_FLOW_##name##_WIDTH)
#define entry_arg_get(name, entry)  entry_arg_get_lower(name, entry)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

void pfe_gpi_cfg_init(addr_t base_va, const pfe_gpi_cfg_t *cfg);
errno_t pfe_gpi_cfg_reset(addr_t base_va);
void pfe_gpi_cfg_enable(addr_t base_va);
void pfe_gpi_cfg_disable(addr_t base_va);
/* IGQOS global API */
void pfe_gpi_cfg_qos_default_init(addr_t base_va);
void pfe_gpi_cfg_qos_enable(addr_t base_va);
void pfe_gpi_cfg_qos_disable(addr_t base_va);
bool_t pfe_gpi_cfg_qos_is_enabled(addr_t base_va);
/* IGQOS Class API */
void pfe_gpi_cfg_qos_write_flow_entry_req(addr_t base_va, uint32 addr, const uint32 entry[]);
void pfe_gpi_cfg_qos_clear_flow_entry_req(addr_t base_va, uint32 addr);
void pfe_gpi_cfg_qos_clear_lru_entry_req(addr_t base_va, uint32 addr);
void pfe_gpi_cfg_qos_rd_fl_entry_req(addr_t base_va, uint32 addr);
void pfe_gpi_cfg_qos_rd_fl_entry_resp(addr_t base_va, uint32 entry[]);
bool_t pfe_gpi_cfg_qos_entry_ready(addr_t base_va);
/* IGQOS WRED API */
void pfe_gpi_cfg_wred_default_init(addr_t base_va);
void pfe_gpi_cfg_wred_enable(addr_t base_va, pfe_iqos_queue_t queue);
void pfe_gpi_cfg_wred_disable(addr_t base_va, pfe_iqos_queue_t queue);
bool_t pfe_gpi_cfg_wred_is_enabled(addr_t base_va, pfe_iqos_queue_t queue);
void pfe_gpi_cfg_wred_set_prob(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 val);
void pfe_gpi_cfg_wred_get_prob(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 *val);
void pfe_gpi_cfg_wred_set_thr(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 val);
void pfe_gpi_cfg_wred_get_thr(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 *val);
/* IGQOS Shaper API */
void pfe_gpi_cfg_shp_default_init(addr_t base_va, uint8 id);
void pfe_gpi_cfg_shp_enable(addr_t base_va, uint8 id);
void pfe_gpi_cfg_shp_disable(addr_t base_va, uint8 id);
bool_t pfe_gpi_cfg_shp_is_enabled(addr_t base_va, uint8 id);
void pfe_gpi_cfg_shp_set_type(addr_t base_va, uint8 id, pfe_iqos_shp_type_t type);
void pfe_gpi_cfg_shp_get_type(addr_t base_va, uint8 id, pfe_iqos_shp_type_t *type);
void pfe_gpi_cfg_shp_set_mode(addr_t base_va, uint8 id, pfe_iqos_shp_rate_mode_t mode);
void pfe_gpi_cfg_shp_get_mode(addr_t base_va, uint8 id, pfe_iqos_shp_rate_mode_t *mode);
void pfe_gpi_cfg_shp_set_isl_weight(addr_t base_va, uint8 id, uint32 clk_div_log2, uint32 weight);
void pfe_gpi_cfg_shp_get_isl_weight(addr_t base_va, uint8 id, uint32 *weight);
void pfe_gpi_cfg_shp_set_limits(addr_t base_va, uint8 id, uint32 max_credit, uint32 min_credit);
void pfe_gpi_cfg_shp_get_limits(addr_t base_va, uint8 id, uint32 *max_credit, uint32 *min_credit);
uint32 pfe_gpi_cfg_shp_get_drop_cnt(addr_t base_va, uint8 id);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_gpi_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_gpi_cfg_get_stat_value(addr_t base_va, uint32 stat_id);
void pfe_gpi_cfg_get_special_stats(addr_t base_va, pfe_gpi_special_stats_t* special_stats);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_GPI_CSR_H_ */


===== 文件 [66/185]: include\pfe_hif.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_HIF_H_
#define PUBLIC_PFE_HIF_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_hif_ring.h"
#include "pfe_hif_chnl.h"

typedef enum
{
    HIF_CHNL_INVALID = 0,
    HIF_CHNL_0 = (1 << 0),
    HIF_CHNL_1 = (1 << 1),
    HIF_CHNL_2 = (1 << 2),
    HIF_CHNL_3 = (1 << 3)
} pfe_hif_chnl_id_t;

typedef struct pfe_hif_tag pfe_hif_t;

/* Way to translate physical interface ID to HIF channel ID... */
#include "pfe_ct.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* ========================================================================= */
static inline pfe_hif_chnl_id_t pfe_hif_chnl_from_phy_id(pfe_ct_phy_if_id_t phy)
{
    pfe_hif_chnl_id_t ret;
    if (phy == PFE_PHY_IF_ID_HIF0)
    {
        ret = HIF_CHNL_0;
    }
    else if (phy == PFE_PHY_IF_ID_HIF1)
    {
        ret = HIF_CHNL_1;
    }
    else if (phy == PFE_PHY_IF_ID_HIF2)
    {
        ret = HIF_CHNL_2;
    }
    else if (phy == PFE_PHY_IF_ID_HIF3)
    {
        ret = HIF_CHNL_3;
    }
    else
    {
        ret = HIF_CHNL_INVALID;
    }

    return ret;
}

/* ========================================================================= */
pfe_hif_t *pfe_hif_create(addr_t cbus_base_va, pfe_hif_chnl_id_t channels_mask);
pfe_hif_chnl_t *pfe_hif_get_channel(pfe_hif_t *hif, pfe_hif_chnl_id_t channel_id);
pfe_hif_chnl_t *pfe_hif_get_channel_phy(pfe_hif_t *hif, pfe_ct_phy_if_id_t phy);
void pfe_hif_destroy(pfe_hif_t *hif);

#ifdef PFE_CFG_PFE_MASTER
errno_t pfe_hif_isr(pfe_hif_t *hif);
void pfe_hif_irq_mask(pfe_hif_t *hif);
void pfe_hif_irq_unmask(pfe_hif_t *hif);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_hif_get_text_statistics(const pfe_hif_t *hif, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
void pfe_hif_clear_master_up(const pfe_hif_t *hif);
void pfe_hif_set_master_up(const pfe_hif_t *hif);
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
void pfe_hif_init_emac_timer_ownership(const pfe_hif_t *hif);
void pfe_hif_clear_emac_timer_ownership(const pfe_hif_t *hif);
#endif /* PFE_CFG_PFE_MASTER */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
void pfe_hif_set_master_detect_cfg(pfe_hif_t *hif, bool_t on);
bool_t pfe_hif_get_master_detect_cfg(const pfe_hif_t *hif);
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_HIF_H_ */


===== 文件 [67/185]: include\pfe_hif_chnl.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @file        pfe_hif_chnl.h
 * @brief       The Host Interface channel
 * @details
 *              Purpose
 *              -------
 *              This is the software representation of the HIF channel including both data RX, and
 *              TX functionality. HIF channel is a middle-level SW component which a driver shall
 *              use to gain access to the Ethernet traffic. All data transmission requests as well
 *              as data reception operations and related control tasks are provided by a HIF channel
 *              instance API.
 *
 *              Initialization
 *              --------------
 *              The channel instance is created by pfe_hif_chnl_create(). Then it needs to be
 *              initialized to perform instance-specific configuration. For this purpose
 *              the pfe_hif_chnl_init() shall be called. Once successfully initialized, the
 *              channel can be activated by pfe_hif_chnl_rx_enable() and pfe_hif_chnl_tx_enable().
 *
 *              RX traffic management
 *              ---------------------
 *              Upon activation the channel starts receiving data into its internal buffer ring.
 *              The RX buffers are not managed by the channel itself and need to be supplied by
 *              user via pfe_hif_chnl_supply_rx_buf(). Each set of supplied buffers must be
 *              confirmed by pfe_hif_chnl_rx_dma_start() to let the hardware know that new empty
 *              RX buffers have become available (this means that multiple calls of
 *              pfe_hif_chnl_supply_rx_buf() can be confirmed by a single
 *              pfe_hif_chnl_rx_dma_start()).
 *
 *              @note To query if the channel is able to accept new RX buffers one can also use
 *                    the helper function pfe_hif_chnl_can_accept_rx_buf().
 *
 *              Usually, new RX data is indicated via dedicated RX IRQ. The RX IRQ number associated
 *              with channel can be retrieved via pfe_chi_chnl_get_irq() call. Driver then
 *              processes the interrupt by calling the pfe_hif_chnl_rx() until the function
 *              indicates 'no data'. In that case the driver acknowledges the RX interrupt via
 *              pfe_hif_chnl_ack_rx_irq(). Note that buffers dequeued by pfe_hif_chnl_rx() must
 *              be replaced by fresh ones using the pfe_hif_chnl_supply_rx_buf() call to keep the
 *              reception active.
 *
 *              Typical RX operation could look like:
 *              @code{.c}
 *                  void rx_irq_handler(void)
 *                  {
 *                      while (EOK == pfe_hif_chnl_rx())
 *                      {
 *                          // Process the received buffer
 *                      }
 *
 *                      while (TRUE == pfe_hif_chnl_can_accept_rx_buf())
 *                      {
 *                          pfe_hif_chnl_supply_rx_buf();
 *                      }
 *
 *                      pfe_hif_chnl_rx_dma_start();
 *                      pfe_hif_chnl_ack_rx_irq();
 *                  }
 *              @endcode
 *
 *              TX traffic management
 *              ---------------------
 *              A packet can be committed for transmission using the pfe_hif_chnl_tx() call. Since
 *              packet can consist of multiple separated buffers the call provides possibility to
 *              mark each of them by so called 'lifm' (last-in-frame) flag and driver is responsible
 *              for its validity. Transmission of committed buffer(s) is triggered by the
 *              pfe_hif_chnl_tx_dma_start().
 *
 *              @note To query if the channel is able to accept new TX buffers one can use
 *                    the helper function pfe_hif_chnl_can_accept_rx_buf().
 *
 *              Typical TX sequence could look like:
 *              @code{.c}
 *              ...
 *              if (pfe_hif_chnl_can_accept_tx_buf())
 *              {
 *                  if (EOK == pfe_hif_chnl_tx(buf->data, buf->is_last))
 *                  {
 *                      // Committed
 *                  }
 *                  else
 *                  {
 *                      // Failed
 *                  }
 *              }
 *
 *              pfe_hif_chnl_tx_dma_start();
 *              ...
 *              @endcode
 *
 *              Once a buffer is transmitted a TX confirmation is generated. Driver can query
 *              for new TX confirmations using the pfe_hif_chnl_has_tx_conf(). If a TX
 *              confirmation is available it can be 'dequeued' via pfe_hif_chnl_get_tx_conf().
 *              Order of TX confirmations as returned by pfe_hif_chnl_get_tx_conf() is exactly
 *              the same as the TX buffers were committed for transmission. Since channel does
 *              not internally keep mapping between TX confirmations and transmitted buffers,
 *              the driver must do the mapping using order of transmitted buffers and received
 *              TX confirmations.
 *
 *              TX confirmations can be handled for instance by periodic calls (or driven by
 *              TX IRQs) of routine such:
 *              @code{.c}
 *              void handle_tx_conf(void)
 *              {
 *                  if (TRUE == pfe_hif_chnl_has_tx_conf())
 *                  {
 *                      while (EOK == pfe_hif_chnl_get_tx_conf())
 *                      {
 *                          // Next packet has been transmitted
 *                      }
 *                  }
 *              }
 *              @endcode
 *
 *              Shutdown handling
 *              -----------------
 *              Once the channel is no more needed it can be stopped and subsequently destroyed.
 *              Driver needs to perform following sequence to properly shut the channel down:
 *              1.  Disable RX traffic via pfe_hif_chnl_rx_disable()
 *              2.  Drain all RX buffers via pfe_hif_chnl_rx()
 *              3.  Disable TX traffic via pfe_hif_chnl_tx_disable()
 *              4.  Drain remaining TX confirmations via pfe_hif_get_tx_conf(). Note that buffers
 *                  committed for transmission but not transmitted yet will be confirmed as they
 *                  were transmitted.
 *              5.  Destroy the HIF channel instance calling the pfe_hif_chnl_destroy()
 */

#ifndef PUBLIC_PFE_HIF_CHNL_H_
#define PUBLIC_PFE_HIF_CHNL_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_ct.h"
#include "pfe_hif_ring.h"
#include "pfe_bmu.h"
#include "hal.h"

/**
 * @brief   List of available HIF channel events
 */
typedef enum
{
    HIF_CHNL_EVT_NONE = 0U,             /*!< No event */
    HIF_CHNL_EVT_RX_IRQ = (1U << 0U),   /*!< RX interrupt - packet received */
    HIF_CHNL_EVT_TX_IRQ = (1U << 1U),   /*!< TX interrupt - packet transmitted */
} pfe_hif_chnl_event_t;

typedef void (* pfe_hif_chnl_cbk_t)(void *arg);

/*  This is the channel ID used to identify HIF_NOCPY channel */
#define PFE_HIF_CHNL_NOCPY_ID       1000U

#define MAC_ADDRESS_SIZE        6U

typedef struct
{
    pfe_hif_chnl_cbk_t cbk;
    void *arg;
} pfe_hif_chnl_cbk_storage_t;

#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
typedef struct
{
    addr_t   base_addr;
    addr_t   meta_base_addr;
    uint16 buf_size;
    uint16 buf_number;
    uint16 get_idx;
} rx_pool_t;
#endif

/**
 * @brief   The HIF channel representation type
 * @details Members are accessed with every channel operation (transmit/receive)
 *          thus the structure is allocated with proper alignment to
 *          improve cache locality.
 */
typedef struct __attribute__((aligned(HAL_CACHE_LINE_SIZE)))
{
    addr_t cbus_base_va;                /*  CBUS base virtual address */
    uint32 id;                    /*  Channel ID within HIF (0, 1, 2, ...) */
    pfe_hif_ring_t *rx_ring;        /*  The RX ring instance */
    pfe_hif_ring_t *tx_ring;        /*  The TX ring instance */
#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
    rx_pool_t rx_pool;              /*  Pool of available RX buffers */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    const pfe_bmu_t *bmu;                   /*  Associated BMU instance */
#if defined(NXP_LOG_ENABLED)
    uint32 a_cnt;                 /*  BMU allocations counter */
#endif /* NXP_LOG_ENABLED */
    uint16 lmem_header_size;      /*  Size of the LMEM Header */
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */
    pfe_hif_chnl_cbk_storage_t rx_cbk;      /*  RX callback */
    pfe_hif_chnl_cbk_storage_t tx_cbk;      /*  TX callback */
} pfe_hif_chnl_t;

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

/*  RX */
errno_t pfe_hif_chnl_rx_enable(pfe_hif_chnl_t *chnl) __attribute__((cold));
void pfe_hif_chnl_rx_disable(pfe_hif_chnl_t *chnl) __attribute__((cold));
errno_t pfe_hif_chnl_rx(pfe_hif_chnl_t *chnl, void **buf_pa, uint32 *len, bool_t *lifm) __attribute__((hot));
errno_t pfe_hif_chnl_rx_va(pfe_hif_chnl_t *chnl, void **buf_va, uint32 *len, bool_t *lifm, void **meta) __attribute__((hot));
uint32 pfe_hif_chnl_get_meta_size(const pfe_hif_chnl_t *chnl) __attribute__((cold));
errno_t pfe_hif_chnl_release_rx_buf(pfe_hif_chnl_t *chnl, const void *buf_va) __attribute__((hot));
bool_t pfe_hif_chnl_can_accept_rx_buf(const pfe_hif_chnl_t *chnl) __attribute__((pure, hot));
errno_t pfe_hif_chnl_supply_rx_buf(const pfe_hif_chnl_t *chnl, const void *buf_pa, uint32 size) __attribute__((hot));
uint32 pfe_hif_chnl_get_rx_fifo_depth(const pfe_hif_chnl_t *chnl) __attribute__((pure, cold));
errno_t pfe_hif_chnl_bind_rx_ring(pfe_hif_chnl_t *chnl) __attribute__((cold));

/*  TX */
errno_t pfe_hif_chnl_tx_enable(pfe_hif_chnl_t *chnl) __attribute__((cold));
void pfe_hif_chnl_tx_disable(pfe_hif_chnl_t *chnl) __attribute__((cold));
errno_t pfe_hif_chnl_tx(const pfe_hif_chnl_t *chnl, const void *buf_va, uint32 len) __attribute__((hot));
bool_t pfe_hif_chnl_can_accept_tx(const pfe_hif_chnl_t *chnl) __attribute__((pure, hot));
bool_t pfe_hif_chnl_tx_fifo_empty(const pfe_hif_chnl_t *chnl) __attribute__((pure, hot));
bool_t pfe_hif_chnl_has_tx_conf(const pfe_hif_chnl_t *chnl) __attribute__((pure, hot));
errno_t pfe_hif_chnl_get_tx_conf(pfe_hif_chnl_t *chnl) __attribute__((hot));
uint32 pfe_hif_chnl_get_tx_fifo_depth(const pfe_hif_chnl_t *chnl) __attribute__((pure, cold));
errno_t pfe_hif_chnl_bind_tx_ring(pfe_hif_chnl_t *chnl) __attribute__((cold));

/*  Instance control */
errno_t pfe_hif_chnl_create_mcal(pfe_hif_chnl_t *chnl, addr_t cbus_base_va, uint32 id, const pfe_bmu_t *bmu) __attribute__((cold));
errno_t pfe_hif_chnl_create_minihif(pfe_hif_chnl_t *chnl, addr_t cbus_base_va, uint32 id, pfe_hif_ring_t *rx_ring, pfe_hif_ring_t *tx_ring) __attribute__((cold));
errno_t pfe_hif_chnl_init(pfe_hif_chnl_t *chnl) __attribute__((cold));
errno_t pfe_hif_chnl_isr(pfe_hif_chnl_t *chnl) __attribute__((hot));
void pfe_hif_chnl_destroy(pfe_hif_chnl_t *chnl) __attribute__((cold));
void pfe_hif_chnl_destroy_chnl(pfe_hif_chnl_t *chnl) __attribute__((cold));
errno_t pfe_hif_chnl_set_event_cbk(pfe_hif_chnl_t *chnl, pfe_hif_chnl_event_t event, pfe_hif_chnl_cbk_t cbk, void *arg);
void pfe_hif_chnl_irq_mask(pfe_hif_chnl_t *chnl);
void pfe_hif_chnl_irq_unmask(pfe_hif_chnl_t *chnl);
void pfe_hif_chnl_rx_irq_mask(pfe_hif_chnl_t *chnl) __attribute__((hot));
void pfe_hif_chnl_rx_irq_unmask(pfe_hif_chnl_t *chnl) __attribute__((hot));
void pfe_hif_chnl_tx_irq_mask(pfe_hif_chnl_t *chnl) __attribute__((hot));
void pfe_hif_chnl_tx_irq_unmask(pfe_hif_chnl_t *chnl) __attribute__((hot));
bool_t pfe_hif_chnl_is_rx_dma_active(const pfe_hif_chnl_t *chnl) __attribute__((hot));
bool_t pfe_hif_chnl_is_tx_dma_active(const pfe_hif_chnl_t *chnl) __attribute__((hot));
uint32 pfe_hif_chnl_get_id(const pfe_hif_chnl_t *chnl) __attribute__((pure, cold));
void pfe_hif_chnl_dump_ring(const pfe_hif_chnl_t *chnl, bool_t dump_rx, bool_t dump_tx) __attribute__((cold));
uint32 pfe_hif_chnl_get_text_statistics(const pfe_hif_chnl_t *chnl, char_t *buf, uint32 buf_len, uint8 verb_level) __attribute__((cold));
uint32 pfe_hif_chnl_get_tx_cnt(const pfe_hif_chnl_t *chnl);
uint32 pfe_hif_chnl_get_rx_cnt(const pfe_hif_chnl_t *chnl);
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
void *pfe_hif_chnl_bmu_alloc_buf_va(pfe_hif_chnl_t *chnl) __attribute__((hot));
void *pfe_hif_chnl_bmu_get_buf_pa(const pfe_hif_chnl_t *chnl, addr_t va) __attribute__((hot));
void pfe_hif_chnl_bmu_free_buf(pfe_hif_chnl_t *chnl, addr_t va) __attribute__((hot));
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
void pfe_hif_chnl_set_lmem_hdr_size(pfe_hif_chnl_t *chnl, uint16 lmem_header_size);
uint16 pfe_hif_chnl_get_lmem_hdr_size(const pfe_hif_chnl_t *chnl);
errno_t pfe_hif_chnl_set_emac_timer_ownership(addr_t cbus_base_va, pfe_ct_phy_if_id_t hif_id, pfe_ct_phy_if_id_t emac, bool_t value);
bool_t pfe_hif_chnl_get_emac_timer_ownership(addr_t cbus_base_va, pfe_ct_phy_if_id_t hif_id, pfe_ct_phy_if_id_t emac);
errno_t pfe_hif_chnl_inspect_hw_state(pfe_hif_chnl_t *chnl);

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#endif /* PUBLIC_PFE_HIF_CHNL_H_ */


===== 文件 [68/185]: include\pfe_hif_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_HIF_CSR_H_
#define PFE_HIF_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_hif.h"
#include "pfe_cbus.h"

#define HIF_VERSION                         (0x00U)
#define HIF_TX_POLL_CTRL                    (0x04U)
#define HIF_RX_POLL_CTRL                    (0x08U)
#define HIF_MISC                            (0x0cU)
#define HIF_TIMEOUT_REG                     (0x10U)
#define HIF_SOFT_RESET                      (0x14U)
#define HIF_INT_SRC                         (0x40U)
#define HIF_ERR_INT_SRC                     (0x68U)
#define HIF_ERR_INT_EN                      (0x6cU)
#define HIF_TX_FIFO_ERR_INT_SRC             (0x70U)
#define HIF_TX_FIFO_ERR_INT_EN              (0x74U)
#define HIF_RX_FIFO_ERR_INT_SRC             (0x78U)
#define HIF_RX_FIFO_ERR_INT_EN              (0x7cU)
#define HIF_TX_STATE                        (0x80U)
#define HIF_TX_ACTV                         (0x84U)
#define HIF_TX_CURR_CH_NO                   (0x88U)
#define HIF_DXR_TX_FIFO_CNT                 (0x8cU)
#define HIF_TX_CTRL_WORD_FIFO_CNT1          (0x90U)
#define HIF_TX_CTRL_WORD_FIFO_CNT2          (0x94U)
#define HIF_TX_BVALID_FIFO_CNT              (0x98U)
#define HIF_TX_PKT_CNT1                     (0x9cU)
#define HIF_TX_PKT_CNT2                     (0xa0U)
#define HIF_RX_STATE                        (0xa4U)
#define HIF_RX_ACTV                         (0xa8U)
#define HIF_RX_CURR_CH_NO                   (0xacU)
#define HIF_DXR_RX_FIFO_CNT                 (0xb0U)
#define HIF_RX_CTRL_WORD_FIFO_CNT           (0xb4U)
#define HIF_RX_BVALID_FIFO_CNT              (0xb8U)
#define HIF_RX_PKT_CNT1                     (0xbcU)
#define HIF_RX_PKT_CNT2                     (0xc0U)
#define HIF_DMA_BASE_ADDR                   (0xc4U)
#define HIF_DMA_BURST_SIZE_ADDR             (0xc8U)
#define HIF_RX_QUEUE_MAP_CH_NO_ADDR         (0xccU)
#define HIF_LTC_PKT_CTRL_ADDR               (0xd0U)

#define HIF_CTRL_CH0                        (0x100U)
#define HIF_RX_BDP_WR_LOW_ADDR_CH0          (0x104U)
#define HIF_RX_BDP_WR_HIGH_ADDR_CH0         (0x108U)
#define HIF_RX_BDP_RD_LOW_ADDR_CH0          (0x10cU)
#define HIF_RX_BDP_RD_HIGH_ADDR_CH0         (0x110U)
#define HIF_TX_BDP_WR_LOW_ADDR_CH0          (0x114U)
#define HIF_TX_BDP_WR_HIGH_ADDR_CH0         (0x118U)
#define HIF_TX_BDP_RD_LOW_ADDR_CH0          (0x11cU)
#define HIF_TX_BDP_RD_HIGH_ADDR_CH0         (0x120U)
#define HIF_RX_WRBK_BD_CH0_BUFFER_SIZE      (0x124U)
#define HIF_RX_CH0_START                    (0x128U)
#define HIF_TX_WRBK_BD_CH0_BUFFER_SIZE      (0x12cU)
#define HIF_TX_CH0_START                    (0x130U)
#define HIF_CH0_INT_SRC                     (0x160U)
#define HIF_CH0_INT_EN                      (0x164U)
#define HIF_TX_RD_CURR_BD_LOW_ADDR_CH0      (0x180U)
#define HIF_TX_RD_CURR_BD_HIGH_ADDR_CH0     (0x184U)
#define HIF_TX_WR_CURR_BD_LOW_ADDR_CH0      (0x188U)
#define HIF_TX_WR_CURR_BD_HIGH_ADDR_CH0     (0x18cU)
#define HIF_BDP_CH0_TX_FIFO_CNT             (0x190U)
#define HIF_TX_DMA_STATUS_0_CH0             (0x194U)
#define HIF_TX_STATUS_0_CH0                 (0x198U)
#define HIF_TX_STATUS_1_CH0                 (0x19cU)
#define HIF_TX_PKT_CNT0_CH0                 (0x1a0U)
#define HIF_TX_PKT_CNT1_CH0                 (0x1a4U)
#define HIF_TX_PKT_CNT2_CH0                 (0x1a8U)
#define HIF_RX_RD_CURR_BD_LOW_ADDR_CH0      (0x1c0U)
#define HIF_RX_RD_CURR_BD_HIGH_ADDR_CH0     (0x1c4U)
#define HIF_RX_WR_CURR_BD_LOW_ADDR_CH0      (0x1c8U)
#define HIF_RX_WR_CURR_BD_HIGH_ADDR_CH0     (0x1ccU)
#define HIF_BDP_CH0_RX_FIFO_CNT             (0x1d0U)
#define HIF_RX_DMA_STATUS_0_CH0             (0x1d4U)
#define HIF_RX_STATUS_0_CH0                 (0x1d8U)
#define HIF_RX_PKT_CNT0_CH0                 (0x1dcU)
#define HIF_RX_PKT_CNT1_CH0                 (0x1e0U)
#define HIF_LTC_MAX_PKT_CH0_ADDR            (0x1e4U)
#define HIF_ABS_INT_TIMER_CH0               (0x1e8U)
#define HIF_ABS_FRAME_COUNT_CH0             (0x1ecU)
#define HIF_INT_COAL_EN_CH0                 (0x1f0U)

#define HIF_CTRL_CHn(n)                     ((((n) & 0x3U) * 0x100U) + HIF_CTRL_CH0)
#define HIF_RX_BDP_WR_LOW_ADDR_CHn(n)       ((((n) & 0x3U) * 0x100U) + HIF_RX_BDP_WR_LOW_ADDR_CH0)
#define HIF_RX_BDP_WR_HIGH_ADDR_CHn(n)      ((((n) & 0x3U) * 0x100U) + HIF_RX_BDP_WR_HIGH_ADDR_CH0)
#define HIF_RX_BDP_RD_LOW_ADDR_CHn(n)       ((((n) & 0x3U) * 0x100U) + HIF_RX_BDP_RD_LOW_ADDR_CH0)
#define HIF_RX_BDP_RD_HIGH_ADDR_CHn(n)      ((((n) & 0x3U) * 0x100U) + HIF_RX_BDP_RD_HIGH_ADDR_CH0)
#define HIF_TX_BDP_WR_LOW_ADDR_CHn(n)       ((((n) & 0x3U) * 0x100U) + HIF_TX_BDP_WR_LOW_ADDR_CH0)
#define HIF_TX_BDP_WR_HIGH_ADDR_CHn(n)      ((((n) & 0x3U) * 0x100U) + HIF_TX_BDP_WR_HIGH_ADDR_CH0)
#define HIF_TX_BDP_RD_LOW_ADDR_CHn(n)       ((((n) & 0x3U) * 0x100U) + HIF_TX_BDP_RD_LOW_ADDR_CH0)
#define HIF_TX_BDP_RD_HIGH_ADDR_CHn(n)      ((((n) & 0x3U) * 0x100U) + HIF_TX_BDP_RD_HIGH_ADDR_CH0)
#define HIF_RX_WRBK_BD_CHn_BUFFER_SIZE(n)   ((((n) & 0x3U) * 0x100U) + HIF_RX_WRBK_BD_CH0_BUFFER_SIZE)
#define HIF_RX_CHn_START(n)                 ((((n) & 0x3U) * 0x100U) + HIF_RX_CH0_START)
#define HIF_TX_WRBK_BD_CHn_BUFFER_SIZE(n)   ((((n) & 0x3U) * 0x100U) + HIF_TX_WRBK_BD_CH0_BUFFER_SIZE)
#define HIF_TX_CHn_START(n)                 ((((n) & 0x3U) * 0x100U) + HIF_TX_CH0_START)
#define HIF_CHn_INT_SRC(n)                  ((((n) & 0x3U) * 0x100U) + HIF_CH0_INT_SRC)
#define HIF_CHn_INT_EN(n)                   ((((n) & 0x3U) * 0x100U) + HIF_CH0_INT_EN)
#define HIF_TX_RD_CURR_BD_LOW_ADDR_CHn(n)   ((((n) & 0x3U) * 0x100U) + HIF_TX_RD_CURR_BD_LOW_ADDR_CH0)
#define HIF_TX_RD_CURR_BD_HIGH_ADDR_CHn(n)  ((((n) & 0x3U) * 0x100U) + HIF_TX_RD_CURR_BD_HIGH_ADDR_CH0)
#define HIF_TX_WR_CURR_BD_LOW_ADDR_CHn(n)   ((((n) & 0x3U) * 0x100U) + HIF_TX_WR_CURR_BD_LOW_ADDR_CH0)
#define HIF_TX_WR_CURR_BD_HIGH_ADDR_CHn(n)  ((((n) & 0x3U) * 0x100U) + HIF_TX_WR_CURR_BD_HIGH_ADDR_CH0)
#define HIF_BDP_CHn_TX_FIFO_CNT(n)          ((((n) & 0x3U) * 0x100U) + HIF_BDP_CH0_TX_FIFO_CNT)
#define HIF_TX_DMA_STATUS_0_CHn(n)          ((((n) & 0x3U) * 0x100U) + HIF_TX_DMA_STATUS_0_CH0)
#define HIF_TX_STATUS_0_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_TX_STATUS_0_CH0)
#define HIF_TX_STATUS_1_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_TX_STATUS_1_CH0)
#define HIF_TX_PKT_CNT0_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_TX_PKT_CNT0_CH0)
#define HIF_TX_PKT_CNT1_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_TX_PKT_CNT1_CH0)
#define HIF_TX_PKT_CNT2_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_TX_PKT_CNT2_CH0)
#define HIF_RX_RD_CURR_BD_LOW_ADDR_CHn(n)   ((((n) & 0x3U) * 0x100U) + HIF_RX_RD_CURR_BD_LOW_ADDR_CH0)
#define HIF_RX_RD_CURR_BD_HIGH_ADDR_CHn(n)  ((((n) & 0x3U) * 0x100U) + HIF_RX_RD_CURR_BD_HIGH_ADDR_CH0)
#define HIF_RX_WR_CURR_BD_LOW_ADDR_CHn(n)   ((((n) & 0x3U) * 0x100U) + HIF_RX_WR_CURR_BD_LOW_ADDR_CH0)
#define HIF_RX_WR_CURR_BD_HIGH_ADDR_CHn(n)  ((((n) & 0x3U) * 0x100U) + HIF_RX_WR_CURR_BD_HIGH_ADDR_CH0)
#define HIF_BDP_CHn_RX_FIFO_CNT(n)          ((((n) & 0x3U) * 0x100U) + HIF_BDP_CH0_RX_FIFO_CNT)
#define HIF_RX_DMA_STATUS_0_CHn(n)          ((((n) & 0x3U) * 0x100U) + HIF_RX_DMA_STATUS_0_CH0)
#define HIF_RX_STATUS_0_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_RX_STATUS_0_CH0)
#define HIF_RX_PKT_CNT0_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_RX_PKT_CNT0_CH0)
#define HIF_RX_PKT_CNT1_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_RX_PKT_CNT1_CH0)
#define HIF_LTC_MAX_PKT_CHn_ADDR(n)         ((((n) & 0x3U) * 0x100U) + HIF_LTC_MAX_PKT_CH0_ADDR)
#define HIF_ABS_INT_TIMER_CHn(n)            ((((n) & 0x3U) * 0x100U) + HIF_ABS_INT_TIMER_CH0)
#define HIF_ABS_FRAME_COUNT_CHn(n)          ((((n) & 0x3U) * 0x100U) + HIF_ABS_FRAME_COUNT_CH0)
#define HIF_INT_COAL_EN_CHn(n)              ((((n) & 0x3U) * 0x100U) + HIF_INT_COAL_EN_CH0)

#define SEQ_NUM_CHECK_EN                    (1UL << 0U)
#define BDPRD_AXI_WRITE_DONE                (1UL << 1U)
#define DBPWR_AXI_WRITE_DONE                (1UL << 2U)
#define RXDXR_AXI_WRITE_DONE                (1UL << 3U)
#define TXDXR_AXI_WRITE_DONE                (1UL << 4U)
#define HIF_TIMEOUT_EN                      (1UL << 5U)
#define BD_START_SEQ_NUM(x)                 ((((uint32)(x)) & 0xffffUL) << 16U)
#define TX_DMA_ENABLE                       (1UL << 0U)
#define RX_DMA_ENABLE                       (1UL << 16U)
#define TX_BDP_POLL_CNTR_EN                 (1UL << 1U)
#define RX_BDP_POLL_CNTR_EN                 (1UL << 17U)
#define RX_BDP_CH_START                     (1UL << 0U)
#define TX_BDP_CH_START                     (1UL << 0U)
#define HIF_CH_INT_EN                       (1UL << 0U)
#define BDP_CSR_RX_CBD_CH_INT_EN            (1UL << 1U)
#define BDP_CSR_RX_PKT_CH_INT_EN            (1UL << 2U)
#define BDP_CSR_TX_CBD_CH_INT_EN            (1UL << 3U)
#define BDP_CSR_TX_PKT_CH_INT_EN            (1UL << 4U)
#define BDP_RD_CSR_RX_TIMEOUT_CH_INT_EN     (1UL << 5U)
#define BDP_WR_CSR_RX_TIMEOUT_CH_INT_EN     (1UL << 6U)
#define BDP_RD_CSR_TX_TIMEOUT_CH_INT_EN     (1UL << 7U)
#define BDP_WD_CSR_TX_TIMEOUT_CH_INT_EN     (1UL << 8U)
#define DXR_CSR_RX_TIMEOUT_CH_INT_EN        (1UL << 9U)
#define DXR_CSR_TX_TIMEOUT_CH_INT_EN        (1UL << 10U)
#define HIF_CH_INT                          (1UL << 0U)
#define BDP_CSR_RX_CBD_CH_INT               (1UL << 1U)
#define BDP_CSR_RX_PKT_CH_INT               (1UL << 2U)
#define BDP_CSR_TX_CBD_CH_INT               (1UL << 3U)
#define BDP_CSR_TX_PKT_CH_INT               (1UL << 4U)
#define BDP_RD_CSR_RX_TIMEOUT_CH_INT        (1UL << 5U)
#define BDP_WR_CSR_RX_TIMEOUT_CH_INT        (1UL << 6U)
#define BDP_RD_CSR_TX_TIMEOUT_CH_INT        (1UL << 7U)
#define BDP_WR_CSR_TX_TIMEOUT_CH_INT        (1UL << 8U)
#define DXR_CSR_RX_TIMEOUT_CH_INT           (1UL << 9U)
#define DXR_CSR_TX_TIMEOUT_CH_INT           (1UL << 10U)
#define HIF_INT                             (1UL << 0U)
#define HIF_RXBD_INT                        (1UL << 1U)
#define HIF_RXPKT_INT                       (1UL << 2U)
#define HIF_TXBD_INT                        (1UL << 3U)
#define HIF_TXPKT_INT                       (1UL << 4U)
#define HIF_CTRL_DMA_EN                     (1UL << 0U)
#define HIF_CTRL_BDP_POLL_CTRL_EN           (1UL << 1U)
#define HIF_CTRL_BDP_CH_START_WSTB          (1UL << 2U)
#define HIF_INT_EN                          (1UL << 0U)
#define HIF_RXBD_INT_EN                     (1UL << 1U)
#define HIF_RXPKT_INT_EN                    (1UL << 2U)
#define HIF_TXBD_INT_EN                     (1UL << 3U)
#define HIF_TXPKT_INT_EN                    (1UL << 4U)
#define HIF_RX_POLL_CTRL_CYCLE              0x0400UL
#define HIF_TX_POLL_CTRL_CYCLE              0x0400UL
#define HIF_INT_COAL_TIME_ENABLE            (1UL << 0U)
#define HIF_INT_COAL_FRAME_ENABLE           (1UL << 1U)
#define BDP_CSR_RX_DMA_ACTV                 (1UL << 16)
#define HIF_INT_SRC_HIF_CH0_INT             (1UL << 0U)
#define HIF_INT_SRC_HIF_CH1_INT             (1UL << 1U)
#define HIF_INT_SRC_HIF_CH2_INT             (1UL << 2U)
#define HIF_INT_SRC_HIF_CH3_INT             (1UL << 3U)
#define HIF_INT_SRC_HIF_ERR_INT             (1UL << 16U)
#define HIF_INT_SRC_HIF_TX_FIFO_ERR_INT     (1UL << 17U)
#define HIF_INT_SRC_HIF_RX_FIFO_ERR_INT     (1UL << 18U)
#define HIF_ERR_INT                         (1UL << 0U)
#define DXR_CSR_TX_PKT_LEN_ERR_INT          (1UL << 1U)
#define DXR_CSR_TX_SOF_ERR_INT              (1UL << 2U)
#define DXR_CSR_TX_DATA_ERR_INT             (1UL << 3U)
#define DXR_CSR_TX_EOF_ERR_INT              (1UL << 4U)
#define DXR_CSR_RX_PKT_LEN_ERR_INT          (1UL << 5U)
#define DXR_CSR_RX_SOF_ERR_INT              (1UL << 6U)
#define DXR_CSR_RX_DATA_ERR_INT             (1UL << 7U)
#define DXR_CSR_RX_EOF_ERR_INT              (1UL << 8U)
#define BDP_CSR_TX_RD_AXI_ERR_INT           (1UL << 9U)
#define BDP_CSR_TX_WR_AXI_ERR_INT           (1UL << 10U)
#define BDP_CSR_RX_RD_AXI_ERR_INT           (1UL << 11U)
#define BDP_CSR_RX_WR_AXI_ERR_INT           (1UL << 12U)
#define BDP_CSR_TX_AXI_ERR_INT              (1UL << 13U)
#define BDP_CSR_RX_AXI_ERR_INT              (1UL << 14U)

#define HIF_TX_FIFO_ERR_INT                         (1UL << 0U)
#define BDP_CSR_TX_RD_FIFO_OVERRUN_INT              (1UL << 1U)
#define BDP_CSR_TX_WR_FIFO_OVERRUN_INT              (1UL << 2U)
#define DXR_CSR_TX_FIFO_OVERRUN_INT                 (1UL << 3U)
#define DXR_CSR_TX_LBUF_OVERRUN_INT                 (1UL << 4U)
#define DXR_CSR_TX_SOF_CTRL_WORD_FIFO_OVERRUN_INT   (1UL << 5U)
#define BDP_DXR_CSR_TX_BD_CTRL_FIFO_OVERRUN_INT     (1UL << 6U)
#define DXR_CSR_TX_SAD_FIFO_OVERRUN_INT             (1UL << 7U)
#define BDP_CSR_TX_BVALID_FIFO_OVERRUN_INT          (1UL << 8U)
#define HIF_AXI_BDP_CSR_TX_BVALID_FIFO_OVERRUN_INT  (1UL << 9U)
#define BDP_CSR_TX_RD_FIFO_UNDERRUN_INT             (1UL << 10U)
#define BDP_CSR_TX_WR_FIFO_UNDERRUN_INT             (1UL << 11U)
#define DXR_CSR_TX_FIFO_UNDERRUN_INT                (1UL << 12U)
#define DXR_CSR_TX_LBUF_UNDERRUN_INT                (1UL << 13U)
#define DXR_CSR_TX_SOF_CTRL_WORD_FIFO_UNDERRUN_INT  (1UL << 14U)
#define BDP_DXR_CSR_TX_BD_CTRL_FIFO_UNDERRUN_INT    (1UL << 15U)
#define DXR_CSR_TX_SAD_FIFO_UNDERRUN_INT            (1UL << 16U)
#define BDP_CSR_TX_BVALID_FIFO_UNDERRUN_INT         (1UL << 17U)
#define HIF_AXI_BDP_CSR_TX_BVALID_FIFO_UNDERRUN_INT (1UL << 18U)
#define HIF_RX_FIFO_ERR_INT                         (1UL << 0U)
#define BDP_CSR_RX_RD_FIFO_OVERRUN_INT              (1UL << 1U)
#define BDP_CSR_RX_WR_FIFO_OVERRUN_INT              (1UL << 2U)
#define DXR_CSR_RX_FIFO_OVERRUN_INT                 (1UL << 3U)
#define DXR_CSR_RX_LBUF_OVERRUN_INT                 (1UL << 4U)
#define DXR_CSR_RX_SOF_CTRL_WORD_FIFO_OVERRUN_INT   (1UL << 5U)
#define DXR_CSR_RX_EOF_CTRL_WORD_FIFO_OVERRUN_INT   (1UL << 6U)
#define BDP_CSR_RX_BVALID_FIFO_OVERRUN_INT          (1UL << 7U)
#define HIF_AXI_BDP_CSR_RX_BVALID_FIFO_OVERRUN_INT  (1UL << 8U)
#define DXR_CSR_RX_BVALID_FIFO_OVERRUN_INT          (1UL << 9U)
#define HIF_AXI_DXR_CSR_RX_BVALID_FIFO_OVERRUN_INT  (1UL << 10U)
#define BDP_CSR_RX_RD_FIFO_UNDERRUN_INT             (1UL << 11U)
#define BDP_CSR_RX_WR_FIFO_UNDERRUN_INT             (1UL << 12U)
#define DXR_CSR_RX_FIFO_UNDERRUN_INT                (1UL << 13U)
#define DXR_CSR_RX_LBUF_UNDERRUN_INT                (1UL << 14U)
#define DXR_CSR_RX_SOF_CTRL_WORD_FIFO_UNDERRUN_INT  (1UL << 15U)
#define DXR_CSR_RX_EOF_CTRL_WORD_FIFO_UNDERRUN_INT  (1UL << 16U)
#define BDP_CSR_RX_BVALID_FIFO_UNDERRUN_INT         (1UL << 17U)
#define HIF_AXI_BDP_CSR_RX_BVALID_FIFO_INDERRUN_INT (1UL << 18U)
#define DXR_CSR_RX_BVALID_FIFO_UNDERRUN_INT         (1UL << 19U)
#define HIF_AXI_DXR_CSR_RX_BVALID_FIFO_UNDERRUN_INT (1UL << 20U)
#define HIF_LTC_MAX_PKT_CHN_MASTER_UP(x)            ((!!(x)) ? (1UL << 0U) : 0U)
#define HIF_LTC_MAX_PKT_CHN_HIF_OCCUPIED(x)         ((!!(x)) ? (1UL << 1U) : 0U)
#define HIF_LTC_MAX_PKT_CHN_EMAC0_OWNER(x)          ((!!(x)) ? (1UL << 4U) : 0U)
#define HIF_LTC_MAX_PKT_CHN_EMAC1_OWNER(x)          ((!!(x)) ? (1UL << 5U) : 0U)
#define HIF_LTC_MAX_PKT_CHN_EMAC2_OWNER(x)          ((!!(x)) ? (1UL << 6U) : 0U)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_hif_cfg_isr(addr_t base_va);
void pfe_hif_cfg_irq_mask(addr_t base_va);
void pfe_hif_cfg_irq_unmask(addr_t base_va);
errno_t pfe_hif_chnl_cfg_isr(addr_t base_va, uint32 channel_id, pfe_hif_chnl_event_t *events);
errno_t pfe_hif_chnl_cfg_init(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_fini(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_irq_mask(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_rx_irq_mask(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_tx_irq_mask(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_irq_unmask(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_rx_irq_unmask(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_tx_irq_unmask(addr_t base_va, uint32 channel_id);
errno_t pfe_hif_cfg_init(addr_t base_va);
void pfe_hif_cfg_fini(addr_t base_va);
uint32 pfe_hif_cfg_get_tx_fifo_fill_level(addr_t base_va);
void pfe_hif_chnl_cfg_tx_enable(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_tx_disable(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_rx_enable(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_rx_disable(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_set_rx_bd_ring_addr(addr_t base_va, uint32 channel_id, const void *rx_ring_pa);
void pfe_hif_chnl_cfg_set_tx_bd_ring_addr(addr_t base_va, uint32 channel_id, const void *tx_ring_pa);
void pfe_hif_chnl_cfg_set_rx_wb_table(addr_t base_va, uint32 channel_id, const void *wb_tbl_pa, uint32 tbl_len);
void pfe_hif_chnl_cfg_set_tx_wb_table(addr_t base_va, uint32 channel_id, const void *wb_tbl_pa, uint32 tbl_len);
uint32 pfe_hif_chnl_cfg_get_rx_bd_ring_addr(addr_t base_va, uint32 channel_id);
uint32 pfe_hif_chnl_cfg_get_rx_wb_table_addr(addr_t base_va, uint32 channel_id);
uint32 pfe_hif_chnl_cfg_get_rx_wb_table_len(addr_t base_va, uint32 channel_id);
uint32 pfe_hif_chnl_cfg_get_tx_bd_ring_addr(addr_t base_va, uint32 channel_id);
uint32 pfe_hif_chnl_cfg_get_tx_wb_table_addr(addr_t base_va, uint32 channel_id);
uint32 pfe_hif_chnl_cfg_get_tx_wb_table_len(addr_t base_va, uint32 channel_id);
bool_t pfe_hif_chnl_cfg_is_rx_dma_active(addr_t base_va, uint32 channel_id);
bool_t pfe_hif_chnl_cfg_is_tx_dma_active(addr_t base_va, uint32 channel_id);
bool_t pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(addr_t base_va, uint32 channel_id);
bool_t pfe_hif_chnl_cfg_is_tx_bdp_fifo_empty(addr_t base_va, uint32 channel_id);
errno_t pfe_hif_chnl_cfg_set_rx_irq_coalesce(addr_t base_va, uint32 channel_id, uint32 frames, uint32 cycles);
errno_t pfe_hif_chnl_cfg_get_rx_irq_coalesce(addr_t base_va, uint32 channel_id, uint32 *frames, uint32 *cycles);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_hif_chnl_cfg_get_text_stat(addr_t base_va, uint32 channel_id, char_t *buf, uint32 size, uint8 verb_level);
uint32 pfe_hif_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_hif_chnl_cfg_get_tx_cnt(addr_t base_va, uint32 channel_id);
uint32 pfe_hif_chnl_cfg_get_rx_cnt(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_set_master_up(addr_t base_va, uint32 channel_id, bool_t value);
bool_t pfe_hif_chnl_cfg_get_master_up(addr_t base_va, uint32 channel_id);
void pfe_hif_chnl_cfg_set_hif_occupied(addr_t base_va, uint32 channel_id, bool_t value);
bool_t pfe_hif_chnl_cfg_get_hif_occupied(addr_t base_va, uint32 channel_id);
errno_t pfe_hif_chnl_cfg_set_emac_timer_ownership(addr_t base_va, uint32 channel_id, pfe_ct_phy_if_id_t emac, bool_t value);
bool_t pfe_hif_chnl_cfg_get_emac_timer_ownership(addr_t base_va, uint32 channel_id, pfe_ct_phy_if_id_t emac);
uint32 pfe_hif_chnl_cfg_get_rx_bdp_rd_fifo_cnt(addr_t base_va, uint32 channel_id);
#ifdef PFE_CFG_PFE_MASTER
void pfe_hif_cfg_stop_all_chnl_dma(void);
#endif

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_HIF_CSR_H_ */


===== 文件 [69/185]: include\pfe_hif_drv.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @defgroup    dxgr_PFE_HIF_DRV HIF Driver
 * @brief       The HIF driver
 * @details     The HIF driver providing way to send and receive traffic.
 *              The driver also:
 *                  - Utilizes @link dxgr_PFE_HIF HIF instance @endlink
 *                  - Maintains RX/TX BD rings
 *                  - Handles TX confirmation events
 *                  - Allocates, distributes, and manages RX buffers,
 *                    by default, it's disableable, see NOTE.
 *                  - Handles HIF interrupts
 *
 *      NOTE:   If pfe_hif_chnl is build without internal buffering support
 *          (PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED = FALSE in pfe_hif_chnl.h),
 *          then OS driver has to implement RX buffering on its own.
 *          In general, it is requested to implement two disabled API calls:
 *              1) pfe_hif_pkt_t * pfe_hif_drv_client_receive_pkt()
 *              2) void pfe_hif_pkt_free()
 *          See linux driver for the reference.
 *
 * @addtogroup  dxgr_PFE_HIF_DRV
 * @{
 *
 * @file        pfe_hif_drv.h
 * @brief       The HIF driver header file (QNX).
 * @details     This is the HIF driver API.
 *
 */

#ifndef PFE_HIF_DRV_H_
#define PFE_HIF_DRV_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_ct.h"
#include "pfe_log_if.h"
#include "fifo.h"
#include "pfe_hif_chnl.h"

#ifdef PFE_CFG_IEEE1588_SUPPORT
#include "pfe_hif_ptp.h"
#endif /* PFE_CFG_IEEE1588_SUPPORT */

#define HIF_STATS

enum
{
    HIF_STATS_CLIENT_FULL_COUNT,
    HIF_STATS_RX_POOL_EMPTY,
    HIF_STATS_RX_FRAME_DROPS,
    HIF_STATS_TX_CONFIRMATION_DROPS,
    HIF_STATS_RX_FRAME_ETS,
    HIF_STATS_MAX_COUNT
};

/**
 * @brief   Maximum number of client's queues
 * @details Each HIF client instance contains its own RX and TX queues. The
 *          number of queues used per direction and per instance is given at
 *          instance creation time (pfe_hif_drv_client_register()) but it is
 *          limited by this (HIF_DRV_CLIENT_QUEUES_MAX) value.
 */
#define HIF_DRV_CLIENT_QUEUES_MAX   8U
/**
 * @brief   TX poll budget
 * @details Value specifies number of TX confirmations provided by TX HW
 *          resource and processed by the HIF driver in a row without
 *          interruption. Once the number of processed TX confirmations reach
 *          this value, the processing is temporarily interrupted to enable
 *          other thread do their jobs (yield).
 */
#define HIF_TX_POLL_BUDGET          128U

#if defined(PFE_CFG_MULTI_INSTANCE_SUPPORT) || defined(PFE_CFG_IEEE1588_SUPPORT)
/*  When there is no need to modify HIF TX header with every TX frame then only
    single static HIF TX header instance (client-owned) will be created and used for
    each transmission. When HIF TX header modification is needed to be done with
    every transmitted frame then multiple HIF TX headers are needed and therefore
    they will be allocated within dedicated storage. */
    #define HIF_CFG_USE_DYNAMIC_TX_HEADERS
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
#ifndef PFE_CFG_CSUM_ALL_FRAMES
/*  Enable dynamic tx headers for individual CSUM
    (on demand) calculation if it is not already enabled */
    #ifndef HIF_CFG_USE_DYNAMIC_TX_HEADERS
        #define HIF_CFG_USE_DYNAMIC_TX_HEADERS
    #endif /* HIF_CFG_USE_DYNAMIC_TX_HEADERS */
#endif /* PFE_CFG_CSUM_ALL_FRAMES */

/**
 * @brief   Maximum number of HIF clients. Right now it is set to cover all possible
 *          physical interfaces and two additional 'special' clients.
 */
#define HIF_CLIENTS_IHC_IDX                     ((uint8)PFE_PHY_IF_ID_MAX + 1U)
#define HIF_CLIENTS_AUX_IDX                     (HIF_CLIENTS_IHC_IDX + 1U)
#define HIF_CLIENTS_MAX                         (HIF_CLIENTS_AUX_IDX + 1U)

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    #define TX_BUF_FRAME_OFFSET ((uint16)(sizeof(pfe_ct_hif_tx_hdr_t)) \
                                 + (uint16)256U \
                                )
#else
    #define TX_BUF_FRAME_OFFSET ((uint16)sizeof(pfe_ct_hif_tx_hdr_t))
#endif

/**
 * @brief   HIF packet flags
 */
typedef struct
{
    union
    {
        pfe_ct_hif_rx_flags_t rx_flags;
        pfe_ct_hif_tx_flags_t tx_flags;
    } specific;
} pfe_hif_drv_flags_t;

typedef struct
{
    void *data_va;                  /*  Pointer to buffer (VA) */
    uint32 len;                   /*  Buffer length */
    /*  Internals */
    pfe_hif_drv_flags_t flags;          /*  Flags */
    pfe_ct_phy_if_id_t dst_phy;         /*  Destination physical interface */
} hif_frame_t;

enum
{
    EVENT_RX_PKT_IND,   /* Event to indicate that, packet recieved for client */
    EVENT_TXDONE_IND,       /* Event to indicate that, packet tx done for client */
    EVENT_ETS,              /* Indicates that new Egress Time Stamp is available */
    HIF_EVENT_MAX
};

typedef struct
{
    uint32 txq_num;   /* Number of TX queues */
    uint32 rxq_num;   /* Number of RX queues */
} pfe_hif_drv_client_rx_tx_count;

typedef struct
{
    fifo_t *txq_fifo;   /* FIFO for the TX queue */
    fifo_t *rxq_fifo;   /* FIFO for the RX queue */
} pfe_hif_drv_client_fifo_queue;

typedef struct pfe_hif_drv_client_tag pfe_hif_drv_client_t;
typedef struct pfe_hif_drv_tag pfe_hif_drv_t;
typedef struct pfe_hif_pkt_tag pfe_hif_pkt_t;
typedef errno_t (* pfe_hif_drv_client_event_handler)(pfe_hif_drv_client_t *client, void *arg, uint32 event, uint32 qno);

/**
 * @brief   Packet representation struct
 */
struct __attribute__((packed)) pfe_hif_pkt_tag
{
    pfe_ct_hif_tx_flags_t ets_flag;
    pfe_hif_drv_client_t *client;
    addr_t data;
    uint16 len;
    uint8 q_no;
    pfe_hif_drv_flags_t flags;
    pfe_ct_phy_if_id_t i_phy_if;
    void *ref_ptr; /* Reference pointer (keep the original mbuf pointer here) */
};

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_hif_drv_t *pfe_hif_drv_create(pfe_hif_chnl_t *channel);
void pfe_hif_drv_destroy(pfe_hif_drv_t *hif_drv);
errno_t pfe_hif_drv_init(pfe_hif_drv_t *hif_drv);
errno_t pfe_hif_drv_start(pfe_hif_drv_t *hif_drv);
void pfe_hif_drv_stop(pfe_hif_drv_t *hif_drv);
void pfe_hif_drv_exit(pfe_hif_drv_t *hif_drv);
pfe_hif_chnl_t *pfe_hif_drv_get_chnl(const pfe_hif_drv_t *hif_drv);
void pfe_hif_drv_rx_job(void *arg);
void pfe_hif_drv_tx_job(void *arg);

#ifdef PFE_CFG_MC_HIF
void pfe_hif_drv_show_ring_status(pfe_hif_drv_t *hif_drv, bool_t rx, bool_t tx);
#endif /*PFE_CFG_MC_HIF*/

/*  IHC API */
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
pfe_hif_drv_client_t * pfe_hif_drv_ihc_client_register(
        pfe_hif_drv_t *hif_drv, pfe_hif_drv_client_event_handler handler, void *priv);
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

/*  AUX API */
#ifdef PFE_CFG_MC_HIF
pfe_hif_drv_client_t * pfe_hif_drv_aux_client_register(
        pfe_hif_drv_t *hif_drv, pfe_hif_drv_client_rx_tx_count *client_queue, pfe_hif_drv_client_fifo_queue  *client_fifo_queue, pfe_hif_drv_client_event_handler handler, void *priv);
#endif /*PFE_CFG_MC_HIF*/

/*  HIF client */
pfe_hif_drv_client_t * pfe_hif_drv_client_register(
        pfe_hif_drv_t *hif_drv, pfe_ct_phy_if_id_t phy_if_id, pfe_hif_drv_client_rx_tx_count *client_queue,
        pfe_hif_drv_client_fifo_queue  *client_fifo_queue, bool_t promisc,
        pfe_hif_drv_client_event_handler handler, void *priv);
errno_t pfe_hif_drv_client_set_inject_if(pfe_hif_drv_client_t *client, pfe_ct_phy_if_id_t phy_if_id);
pfe_hif_drv_t *pfe_hif_drv_client_get_drv(const pfe_hif_drv_client_t *client);
void *pfe_hif_drv_client_get_priv(const pfe_hif_drv_client_t *client);
void pfe_hif_drv_client_unregister(pfe_hif_drv_client_t *client);
void pfe_hif_drv_client_rx_done(const pfe_hif_drv_client_t *client);
void pfe_hif_drv_client_tx_done(const pfe_hif_drv_client_t *client);
#if defined(PFE_CFG_IEEE1588_SUPPORT)
void pfe_hif_drv_client_ptp_ts_db_tick_iteration(pfe_hif_drv_client_t *client);
#endif /* PFE_CFG_IEEE1588_SUPPORT */

errno_t pfe_hif_drv_init_tx_header(pfe_hif_drv_client_t *client, pfe_ct_hif_tx_hdr_t *tx_header, const uint8 queue);
/*  Packet transmission */
errno_t pfe_hif_drv_client_xmit_pkt(pfe_hif_drv_client_t *client, uint8 queue, const hif_frame_t *const frame, void *ref_ptr);
void * pfe_hif_drv_client_receive_tx_conf(const pfe_hif_drv_client_t *client, uint32 queue);

/*  Packet reception */
bool_t pfe_hif_drv_client_has_rx_pkt(const pfe_hif_drv_client_t *client, uint32 queue);
#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
pfe_hif_pkt_t * pfe_hif_drv_client_receive_pkt(pfe_hif_drv_client_t *client, uint32 queue);
void pfe_hif_pkt_free(const pfe_hif_pkt_t *pkt);
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

/*  PTP Timestamps */
errno_t pfe_hif_drv_client_get_ts(pfe_hif_drv_client_t * const client, bool_t rx,
        uint8 type, uint16 port, uint16 seq_id, uint32 * const ts_sec, uint32 * const ts_nsec);

/**
 * @brief       Get information that IP checksum has been verified by PFE
 * @param[in]   pkt The packet
 * @return      TRUE if IP checksum has been verified and is valid
 */
static inline bool_t pfe_hif_pkt_ipv4_csum_valid(const pfe_hif_pkt_t *pkt)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != (pkt->flags.specific.rx_flags & HIF_RX_IPV4_CSUM))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Get information that UDP checksum within IP fragment has been verified by PFE
 * @param[in]   pkt The packet
 * @return      TRUE if UDP checksum has been verified and is valid
 */
static inline bool_t pfe_hif_pkt_udpv4_csum_valid(const pfe_hif_pkt_t *pkt)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != (pkt->flags.specific.rx_flags & HIF_RX_UDPV4_CSUM))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Get information that UDP checksum within ipv6 fragment has been verified by PFE
 * @param[in]   pkt The packet
 * @return      TRUE if UDP checksum has been verified and is valid
 */
static inline bool_t pfe_hif_pkt_udpv6_csum_valid(const pfe_hif_pkt_t *pkt)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != (pkt->flags.specific.rx_flags & HIF_RX_UDPV6_CSUM))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Get information that TCP checksum has been verified by PFE
 * @param[in]   pkt The packet
 * @return      TRUE if TCP checksum withing ipv4 frame has been verified and is valid
 */
static inline bool_t pfe_hif_pkt_tcpv4_csum_valid(const pfe_hif_pkt_t *pkt)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != (pkt->flags.specific.rx_flags & HIF_RX_TCPV4_CSUM))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Get information that TCP checksum has been verified by PFE
 * @param[in]   pkt The packet
 * @return      TRUE if TCP checksum has been verified and is valid
 */
static inline bool_t pfe_hif_pkt_tcpv6_csum_valid(const pfe_hif_pkt_t *pkt)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != (pkt->flags.specific.rx_flags & HIF_RX_TCPV6_CSUM))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Get information that ICMP checksum has been verified by PFE
 * @param[in]   pkt The packet
 * @return      TRUE if ICMP checksum has been verified and is valid
 */
static inline bool_t pfe_hif_pkt_icmp_csum_valid(const pfe_hif_pkt_t *pkt)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != (pkt->flags.specific.rx_flags & HIF_RX_ICMP_CSUM))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Get pointer to data buffer
 * @param[in]   pkt The packet
 * @return      Pointer to packet data
 */
static inline addr_t pfe_hif_pkt_get_data(const pfe_hif_pkt_t *pkt)
{
    addr_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pkt->data;
    }
    return ret;
}

/**
 * @brief       Get packet data length in bytes
 * @param[in]   pkt The packet
 * @return      Number of bytes in data buffer
 */
static inline uint32 pfe_hif_pkt_get_data_len(const pfe_hif_pkt_t *pkt)
{
    uint32 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pkt->len;
    }
    return ret;
}

/**
 * @brief       Get pointer to packet-related memory
 * @param[in]   pkt The packet
 * @return      Pointer to memory associated with the packet where
 *              a packet-related data can be stored.
 */
static inline void *pfe_hif_pkt_get_ref_ptr(pfe_hif_pkt_t *pkt)
{
    void *ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = &pkt->ref_ptr;
    }
    return ret;
}

/**
 * @brief       Get HIF client associated with the packet
 * @param[in]   pkt The packet
 * @return      The HIF client instance
 */
static inline pfe_hif_drv_client_t *pfe_hif_pkt_get_client(const pfe_hif_pkt_t *pkt)
{
    pfe_hif_drv_client_t *ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pkt->client;
    }
    return ret;
}

/**
 * @brief       Get ingress physical interface ID
 * @param[in]   pkt The packet
 * @return      The physical interface ID
 */
static inline pfe_ct_phy_if_id_t pfe_hif_pkt_get_ingress_phy_id(const pfe_hif_pkt_t *pkt)
{
    pfe_ct_phy_if_id_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = PFE_PHY_IF_ID_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pkt->i_phy_if;
    }
    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_HIF_DRV_H_ */

/** @}*/


===== 文件 [70/185]: include\pfe_hif_nocpy.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_HIF_NOCPY_H_
#define PUBLIC_PFE_HIF_NOCPY_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_hif_ring.h"
#include "pfe_hif_chnl.h"
#include "pfe_bmu.h"

typedef struct
{
    uint32 nothing; /* Some compilers don't support empty structs */
} pfe_hif_nocpy_cfg_t;

typedef struct pfe_hif_nocpy_tag pfe_hif_nocpy_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_hif_nocpy_t *pfe_hif_nocpy_create(addr_t base_va, const pfe_bmu_t *bmu, uint16 lmem_header_size);
pfe_hif_chnl_t *pfe_hif_nocpy_get_channel(const pfe_hif_nocpy_t *hif, uint32 channel_id);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_hif_nocpy_get_text_statistics(const pfe_hif_nocpy_t *hif, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

void pfe_hif_nocpy_destroy(pfe_hif_nocpy_t *hif);
void pfe_hif_nocpy_init_emac_timer_ownership(const pfe_hif_nocpy_t *hif);
void pfe_hif_nocpy_clear_emac_timer_ownership(const pfe_hif_nocpy_t *hif);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_HIF_NOCPY_H_ */


===== 文件 [71/185]: include\pfe_hif_nocpy_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_HIF_NOCPY_CSR_H_
#define PFE_HIF_NOCPY_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_hif_nocpy.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define HIF_NOCPY_VERSION           (0x00U)
#define HIF_NOCPY_TX_CTRL           (0x04U)
#define HIF_NOCPY_TX_CURR_BD_ADDR   (0x08U)
#define HIF_NOCPY_TX_ALLOC          (0x0cU)
#define HIF_NOCPY_TX_BDP_ADDR       (0x10U)
#define HIF_NOCPY_TX_STATUS         (0x14U)
#define HIF_NOCPY_RX_CTRL           (0x20U)
#define HIF_NOCPY_RX_BDP_ADDR       (0x24U)
#define HIF_NOCPY_RX_STATUS         (0x30U)
#define HIF_NOCPY_INT_SRC           (0x34U)
#define HIF_NOCPY_INT_EN            (0x38U)
#define HIF_NOCPY_POLL_CTRL         (0x3cU)
#define HIF_NOCPY_RX_CURR_BD_ADDR   (0x40U)
#define HIF_NOCPY_RX_ALLOC          (0x44U)
#define HIF_NOCPY_TX_DMA_STATUS     (0x48U)
#define HIF_NOCPY_RX_DMA_STATUS     (0x4cU)
#define HIF_NOCPY_RX_INQ0_PKTPTR    (0x50U)
#define HIF_NOCPY_RX_INQ1_PKTPTR    (0x54U)
#define HIF_NOCPY_TX_PORT_NO        (0x60U)
#define HIF_NOCPY_LMEM_ALLOC_ADDR   (0x64U)
#define HIF_NOCPY_CLASS_ADDR        (0x68U)
#define HIF_NOCPY_TMU_PORT0_ADDR    (0x70U)
#define HIF_NOCPY_TMU_PORT1_ADDR    (0x74U)
#define HIF_NOCPY_TMU_PORT2_ADDR    (0x7cU)
#define HIF_NOCPY_TMU_PORT3_ADDR    (0x80U)
#define HIF_NOCPY_TMU_PORT4_ADDR    (0x84U)
#define HIF_NOCPY_INT_COAL_ADDR     (0x90U)
#define HIF_NOCPY_CSR_AXI_WAIT_DONE (0x94U)
#define HIF_NOCPY_ABS_FRAME_CNT     (0x98U)

#define HIF_NOCPY_INT               (1U << 0)
#define BDP_CSR_RX_CBD_INT          (1U << 1)
#define BDP_CSR_RX_PKT_INT          (1U << 2)
#define BDP_CSR_TX_CBD_INT          (1U << 3)
#define BDP_CSR_TX_PKT_INT          (1U << 4)

#define HIF_NOCPY_TIMER_OWNERSHIP_EMAC(ID)     (1U << ((ID)+4U))

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_hif_nocpy_cfg_isr(addr_t base_va, pfe_hif_chnl_event_t *events);
void pfe_hif_nocpy_cfg_irq_mask(addr_t base_va);
void pfe_hif_nocpy_cfg_irq_unmask(addr_t base_va);
errno_t pfe_hif_nocpy_cfg_init(addr_t base_va);
void pfe_hif_nocpy_cfg_fini(addr_t base_va);
void pfe_hif_nocpy_cfg_tx_enable(addr_t base_va);
void pfe_hif_nocpy_cfg_tx_disable(addr_t base_va);
void pfe_hif_nocpy_cfg_rx_enable(addr_t base_va);
void pfe_hif_nocpy_cfg_rx_disable(addr_t base_va);
void pfe_hif_nocpy_cfg_rx_irq_mask(addr_t base_va);
void pfe_hif_nocpy_cfg_rx_irq_unmask(addr_t base_va);
void pfe_hif_nocpy_cfg_tx_irq_mask(addr_t base_va);
void pfe_hif_nocpy_cfg_tx_irq_unmask(addr_t base_va);
void pfe_hif_nocpy_cfg_set_rx_bd_ring_addr(addr_t base_va, const void *rx_ring_pa);
void pfe_hif_nocpy_cfg_set_tx_bd_ring_addr(addr_t base_va, const  void *tx_ring_pa);
uint32 pfe_hif_nocpy_cfg_get_rx_bd_ring_addr(addr_t base_va);
uint32 pfe_hif_nocpy_cfg_get_tx_bd_ring_addr(addr_t base_va);
bool_t pfe_hif_nocpy_cfg_is_rx_dma_active(addr_t base_va);
bool_t pfe_hif_nocpy_cfg_is_tx_dma_active(addr_t base_va);
uint32 pfe_hif_nocpy_chnl_cfg_get_text_stat(addr_t base_va, const char_t *buf, uint32 size, uint8 verb_level);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_hif_nocpy_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_hif_nocpy_cfg_get_tx_cnt(addr_t base_va);
uint32 pfe_hif_nocpy_cfg_get_rx_cnt(addr_t base_va);
errno_t pfe_hif_nocpy_cfg_set_emac_timer_ownership(pfe_ct_phy_if_id_t emac, bool_t value);
bool_t pfe_hif_nocpy_cfg_get_emac_timer_ownership(pfe_ct_phy_if_id_t emac);
void pfe_hif_nocpy_cfg_stop_all_chnl_dma(void);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_HIF_NOCPY_CSR_H_ */


===== 文件 [72/185]: include\pfe_hif_ptp.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_HIF_PTP_H_
#define PUBLIC_PFE_HIF_PTP_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "isa.h"

/*  Number of entries in the DB producing warning message */
#define PFE_HIF_PTP_DB_WARNING_THRESHOLD    50U

/*  Maximum allowed number of entries */
#define PFE_HIF_PTP_DB_MAX_CAPACITY         (PFE_HIF_PTP_DB_WARNING_THRESHOLD + 10U)

typedef struct
{
    uint32 ticks;     /* Timeout counter (in number of ticks). Zero means entry is aged. */
    uint16 refnum;    /* Reference to identify ETS report */
    uint8 type;       /* PTP Message type */
    bool_t rx;          /* If TRUE then entry refers to ingress message */
    uint16 port;      /* PTP Port */
    uint16 seq_id;    /* PTP Sequence ID */
    uint32 ts_sec;
    uint32 ts_nsec;
    bool_t ts_valid;
} pfe_hif_ptp_ts_db_entry_t;

typedef struct
{
    pfe_isa_t entries;
    pfe_isa_index_t entries_pool_index[PFE_HIF_PTP_DB_MAX_CAPACITY];
    pfe_hif_ptp_ts_db_entry_t entries_pool[PFE_HIF_PTP_DB_MAX_CAPACITY];
    pfe_isa_definition_t entries_isa_def;
    uint8 count;
    bool_t reported;
} pfe_hif_ptp_ts_db_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_hif_ptp_ts_db_init(pfe_hif_ptp_ts_db_t *db);
void pfe_hif_ptp_ts_db_fini(pfe_hif_ptp_ts_db_t *db);
errno_t pfe_hif_ptp_ts_db_push_msg(pfe_hif_ptp_ts_db_t *db, bool_t rx,
        uint16 refnum, uint8 type, uint16 port, uint16 seq_id);
errno_t pfe_hif_ptp_ts_db_push_ts(pfe_hif_ptp_ts_db_t *db, bool_t rx,
        uint16 refnum, uint32 ts_sec, uint32 ts_nsec);
errno_t pfe_hif_ptp_ts_db_pop(pfe_hif_ptp_ts_db_t *db,
        uint8 type, uint16 port, uint16 seq_id,
        uint32 *ts_sec, uint32 *ts_nsec, bool_t rx);
void pfe_hif_ptp_ts_db_tick_iteration(void *arg);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_HIF_PTP_H_ */


===== 文件 [73/185]: include\pfe_hif_ring.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_HIF_RING_H_
#define PUBLIC_PFE_HIF_RING_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "hal.h"

/**
 * @brief   The BD as seen by HIF
 * @details Properly pack to form the structure as expected by HIF.
 * @note    Don't use the 'aligned' attribute here since behavior
 *          is implementation-specific (due to the bitfields). Still
 *          applies that BD shall be aligned to 64-bits and in
 *          ideal case to cache line size.
 * @warning Do not touch the structure (even types) unless you know
 *          what you're doing.
 */

typedef struct __attribute__((packed))
{
    volatile uint16 seqnum; /* Not used */
    union
    {
        volatile uint16 ctrl;
        struct
        {
            volatile uint16 pkt_int_en    : 1; /* LSB */
            volatile uint16 cbd_int_en    : 1;
            volatile uint16 lifm          : 1;
            volatile uint16 last_bd       : 1;
            volatile uint16 dir           : 1;
            volatile uint16 reserved      : 10;
            volatile uint16 desc_en       : 1; /* MSB */
        } info;
    } control;
    volatile uint16 buflen;
    union
    {
        volatile uint16 rsvd;
        volatile uint16 status;   /* Due to backwards compatibility */
    } check;
    volatile uint32 data;
    volatile uint32 next;
} pfe_hif_bd_t;

/**
 * @brief   The write-back BD as seen by HIF
 * @note    Don't use the 'aligned' attribute here since behavior
 *          is implementation-specific (due to the bitfields). Still
 *          applies that BD shall be aligned to 64-bits and in
 *          ideal case to cache line size.
 * @warning Do not touch the structure (even types) unless you know
 *          what you're doing.
 */
typedef struct __attribute__((packed))
{
    union
    {
        struct
        {
            volatile uint32 ctrl: 11;
            volatile uint32 rsvd: 21;
        } ctrl;

        struct
        {
            volatile uint32 reserved      : 4;
            volatile uint32 cbd_int_en    : 1;
            volatile uint32 pkt_int_en    : 1;
            volatile uint32 lifm          : 1;
            volatile uint32 last_bd       : 1;
            volatile uint32 dir           : 1;
            volatile uint32 desc_en       : 1;
            volatile uint32 reserved1     : 1;
            volatile uint32 reserved2     : 21;
        } info;
    } control;

    volatile uint16 buflen;
    volatile uint16 seqnum;
} pfe_hif_wb_bd_t;

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief   The BD as seen by HIF NOCPY
 * @details Properly pack to form the structure as expected by HIF NOCPY.
 * @note    Don't use the 'aligned' attribute here since behavior
 *          is implementation-specific (due to the bitfields). Still
 *          applies that BD shall be aligned to 64-bits and in
 *          ideal case to cache line size.
 * @warning Do not touch the structure (even types) unless you know
 *          what you're doing.
 */
typedef struct __attribute__((packed))
{
    struct
    {
        union
        {
            volatile uint16 rx_reserved;
            volatile uint16 tx_buflen;
        } w0;

        union
        {
            volatile uint16 ctrl;
            struct
            {
                volatile uint16 cbd_int_en    : 1;
                volatile uint16 pkt_int_en    : 1;
                volatile uint16 lifm          : 1;
                volatile uint16 last_bd       : 1;    /*  Not used */
                volatile uint16 dir           : 1;
                volatile uint16 lmem_cpy      : 1;
                volatile uint16 reserved1     : 2;
                volatile uint16 pkt_xfer      : 1;
                volatile uint16 reserved2     : 6;
                volatile uint16 desc_en       : 1;
            } info;
        } w1;
    } control;

    struct
    {
        union
        {
            volatile uint16 rx_buflen;
            volatile uint16 tx_lmem_buflen;
        } w0;

        union
        {
            volatile uint16 rx_portno;
            struct
            {
                uint16 dst_buf_offset : 7;
                uint16 src_buf_offset : 9;
            } tx;
        } w1;
    } status;

    volatile uint32 data;
    volatile uint32 next;
} pfe_hif_nocpy_bd_t;
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief   The BD ring structure
 * @note    The attribute 'aligned' is here just to ensure proper alignment
 *          when instance will be created automatically without dynamic memory
 *          allocation.
 */
typedef struct __attribute__((aligned (HAL_CACHE_LINE_SIZE), packed))
{
    /*  Put often used data from beginning to improve cache locality */

    /*  Every 'enqueue' and 'dequeue' access */
    void *base_va;              /*  Ring base address (virtual) */
    void *wb_tbl_base_va;       /*  Write-back table base address (virtual) */
    uint32 length;            /*  Length of the ring (number of buffer descriptors) */

    /*  Every 'enqueue' access */
    uint32 write_idx;         /*  BD index to be written */
    union                       /* Pointer to BD to be written */
    {
        pfe_hif_bd_t *wr_bd;
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        pfe_hif_nocpy_bd_t *wr_bd_nocpy;
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    } bd_write;
    pfe_hif_wb_bd_t *wr_wb_bd;  /*  Pointer to WB BD to be written */
    bool_t is_rx;               /*  If TRUE then ring is RX ring */

    /*  Every 'dequeue' access */
    uint32 read_idx;          /*  BD index to be read */
    union                       /*  Pointer to BD to be read */
    {
        pfe_hif_bd_t *rd_bd;
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        pfe_hif_nocpy_bd_t *rd_bd_nocpy;
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    }bd_read;

    pfe_hif_wb_bd_t *rd_wb_bd;  /*  Pointer to WB BD to be read */
    bool_t heavy_data_mark;     /*  To enable getting size of heavily accessed data */

    /*  Initialization time only */
    void *base_pa;              /*  Ring base address (physical) */
    void *wb_tbl_base_pa;       /*  Write-back table base address (physical) */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    bool_t nocpy;               /*  Set when the ring belongs to HIF_NOCPY channel */
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
} pfe_hif_ring_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_hif_ring_create_mcal(pfe_hif_ring_t *ring, uint32 length, bool_t rx) __attribute__((cold));
errno_t pfe_hif_ring_create_minihif(pfe_hif_ring_t *ring, void *ring_va, void *wb_ring_va, uint32 length, bool_t rx) __attribute__((cold));
uint32 pfe_hif_ring_get_len(const pfe_hif_ring_t *ring) __attribute__((pure, hot));
errno_t pfe_hif_ring_destroy(pfe_hif_ring_t *ring) __attribute__((cold));
void *pfe_hif_ring_get_base_pa(const pfe_hif_ring_t *ring) __attribute__((pure, cold));
void *pfe_hif_ring_get_wb_tbl_pa(const pfe_hif_ring_t *ring) __attribute__((pure, cold));
uint32 pfe_hif_ring_get_wb_tbl_len(const pfe_hif_ring_t *ring) __attribute__((pure, cold));
errno_t pfe_hif_ring_enqueue_buf(pfe_hif_ring_t *ring, const void *buf_pa, uint32 length, uint32 lmem_header_size) __attribute__((hot));
errno_t pfe_hif_ring_dequeue_buf(pfe_hif_ring_t *ring, void **buf_pa, uint32 *length, bool_t *lifm) __attribute__((hot));
errno_t pfe_hif_ring_dequeue_plain(pfe_hif_ring_t *ring, bool_t *lifm) __attribute__((hot));
errno_t pfe_hif_ring_drain_buf(pfe_hif_ring_t *ring, void **buf_pa) __attribute__((cold));
void pfe_hif_ring_invalidate(const pfe_hif_ring_t *ring) __attribute__((cold));
uint32 pfe_hif_ring_get_fill_level(const pfe_hif_ring_t *ring) __attribute__((pure, hot));
void pfe_hif_ring_dump(const pfe_hif_ring_t *ring, const char_t *name) __attribute__((cold));
bool_t pfe_hif_ring_is_on_head(const pfe_hif_ring_t *ring);
errno_t pfe_hif_ring_find_wb_entry(pfe_hif_ring_t *ring, bool_t valid, uint32 *index);
void pfe_hif_ring_invalidate_direct(const pfe_hif_ring_t *ring, uint32 index);
void pfe_hif_ring_revalidate_direct(const pfe_hif_ring_t *ring, uint32 index);
errno_t pfe_hif_ring_force_index(pfe_hif_ring_t *ring, uint32 index);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_HIF_RING_H_ */


===== 文件 [74/185]: include\pfe_hm.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_HM_H
#define PFE_HM_H

#define PFE_HM_DESCRIPTION_MAX_LEN 256
#define PFE_HM_QUEUE_LEN 8

typedef enum {
    HM_INFO,
    HM_WARNING,
    HM_ERROR
} pfe_hm_type_t;

typedef enum {
    HM_EVT_NONE = 0,
    HM_EVT_RUNTIME = 1,

#ifndef PFE_CFG_PFE_SLAVE
    HM_EVT_ECC = 2,

    HM_EVT_WDT_BMU1 = 10,
    HM_EVT_WDT_BMU2 = 11,
    HM_EVT_WDT_CLASS = 12,
    HM_EVT_WDT_EMAC0_GPI = 13,
    HM_EVT_WDT_EMAC1_GPI = 14,
    HM_EVT_WDT_EMAC2_GPI = 15,
    HM_EVT_WDT_HIF_GPI = 16,
    HM_EVT_WDT_HIF_NOCPY = 17,
    HM_EVT_WDT_HIF = 18,
    HM_EVT_WDT_TLITE = 19,
    HM_EVT_WDT_UTIL_PE = 20,
    HM_EVT_WDT_EMAC0_ETGPI = 21,
    HM_EVT_WDT_EMAC1_ETGPI = 22,
    HM_EVT_WDT_EMAC2_ETGPI = 23,
    HM_EVT_WDT_EXT_GPT1 = 24,
    HM_EVT_WDT_EXT_GPT2 = 25,
    HM_EVT_WDT_LMEM = 26,
    HM_EVT_WDT_ROUTE_LMEM = 27,

    HM_EVT_EMAC_ECC_TX_FIFO_CORRECTABLE = 30,
    HM_EVT_EMAC_ECC_TX_FIFO_UNCORRECTABLE = 31,
    HM_EVT_EMAC_ECC_TX_FIFO_ADDRESS = 32,
    HM_EVT_EMAC_ECC_RX_FIFO_CORRECTABLE = 33,
    HM_EVT_EMAC_ECC_RX_FIFO_UNCORRECTABLE = 34,
    HM_EVT_EMAC_ECC_RX_FIFO_ADDRESS = 35,
    HM_EVT_EMAC_APP_TX_PARITY = 36,
    HM_EVT_EMAC_APP_RX_PARITY = 37,
    HM_EVT_EMAC_MTL_PARITY = 38,
    HM_EVT_EMAC_FSM_PARITY = 39,
    HM_EVT_EMAC_FSM_TX_TIMEOUT = 40,
    HM_EVT_EMAC_FSM_RX_TIMEOUT = 41,
    HM_EVT_EMAC_FSM_APP_TIMEOUT = 42,
    HM_EVT_EMAC_FSM_PTP_TIMEOUT = 43,
    HM_EVT_EMAC_MASTER_TIMEOUT = 44,

    HM_EVT_BUS_MASTER1 = 60,
    HM_EVT_BUS_MASTER2 = 61,
    HM_EVT_BUS_MASTER3 = 62,
    HM_EVT_BUS_MASTER4 = 63,
    HM_EVT_BUS_HGPI_READ = 64,
    HM_EVT_BUS_HGPI_WRITE = 65,
    HM_EVT_BUS_EMAC0_READ = 66,
    HM_EVT_BUS_EMAC0_WRITE = 67,
    HM_EVT_BUS_EMAC1_READ = 68,
    HM_EVT_BUS_EMAC1_WRITE = 69,
    HM_EVT_BUS_EMAC2_READ = 70,
    HM_EVT_BUS_EMAC2_WRITE = 71,
    HM_EVT_BUS_CLASS_READ = 72,
    HM_EVT_BUS_CLASS_WRITE = 73,
    HM_EVT_BUS_HIF_NOCPY_READ = 74,
    HM_EVT_BUS_HIF_NOCPY_WRITE = 75,
    HM_EVT_BUS_TMU = 76,
    HM_EVT_BUS_FET = 77,
    HM_EVT_BUS_UTIL_PE_READ = 78,
    HM_EVT_BUS_UTIL_PE_WRITE = 79,

    HM_EVT_PARITY_MASTER1 = 100,
    HM_EVT_PARITY_MASTER2 = 101,
    HM_EVT_PARITY_MASTER3 = 102,
    HM_EVT_PARITY_MASTER4 = 103,
    HM_EVT_PARITY_EMAC_CBUS = 104,
    HM_EVT_PARITY_EMAC_DBUS = 105,
    HM_EVT_PARITY_CLASS_CBUS = 106,
    HM_EVT_PARITY_CLASS_DBUS = 107,
    HM_EVT_PARITY_TMU_CBUS = 108,
    HM_EVT_PARITY_TMU_DBUS = 109,
    HM_EVT_PARITY_HIF_CBUS = 110,
    HM_EVT_PARITY_HIF_DBUS = 111,
    HM_EVT_PARITY_HIF_NOCPY_CBUS = 112,
    HM_EVT_PARITY_HIF_NOCPY_DBUS = 113,
    HM_EVT_PARITY_UPE_CBUS = 114,
    HM_EVT_PARITY_UPE_DBUS = 115,
    HM_EVT_PARITY_HRS_CBUS = 116,
    HM_EVT_PARITY_BRIDGE_CBUS = 117,
    HM_EVT_PARITY_EMAC_SLV = 118,
    HM_EVT_PARITY_BMU1_SLV = 119,
    HM_EVT_PARITY_BMU2_SLV = 120,
    HM_EVT_PARITY_CLASS_SLV = 121,
    HM_EVT_PARITY_HIF_SLV = 122,
    HM_EVT_PARITY_HIF_NOCPY_SLV = 123,
    HM_EVT_PARITY_LMEM_SLV = 124,
    HM_EVT_PARITY_TMU_SLV = 125,
    HM_EVT_PARITY_UPE_SLV = 126,
    HM_EVT_PARITY_WSP_GLOBAL_SLV = 127,
    HM_EVT_PARITY_GPT1_SLV = 128,
    HM_EVT_PARITY_GPT2_SLV = 129,
    HM_EVT_PARITY_ROUTE_LMEM_SLV = 130,

    HM_EVT_FAIL_STOP_PARITY = 140,
    HM_EVT_FAIL_STOP_WATCHDOG = 141,
    HM_EVT_FAIL_STOP_BUS = 142,
    HM_EVT_FAIL_STOP_ECC_MULTIBIT = 143,
    HM_EVT_FAIL_STOP_FW = 144,
    HM_EVT_FAIL_STOP_HOST = 145,

    HM_EVT_FW_FAIL_STOP = 150,
    HM_EVT_HOST_FAIL_STOP = 151,

    HM_EVT_BMU_FULL = 170,
    HM_EVT_BMU_FREE_ERR = 171,
    HM_EVT_BMU_MCAST = 172,
#endif

    HM_EVT_PE_STALL = 180,
    HM_EVT_PE_EXCEPTION = 181,
    HM_EVT_PE_ERROR = 182,

    HM_EVT_HIF_ERR = 190,
    HM_EVT_HIF_TX_FIFO = 191,
    HM_EVT_HIF_RX_FIFO = 192,
} pfe_hm_evt_t;

typedef enum {
    HM_SRC_UNKNOWN,
    HM_SRC_DRIVER,
    HM_SRC_WDT,
    HM_SRC_EMAC0,
    HM_SRC_EMAC1,
    HM_SRC_EMAC2,
    HM_SRC_BUS,
    HM_SRC_PARITY,
    HM_SRC_FAIL_STOP,
    HM_SRC_FW_FAIL_STOP,
    HM_SRC_HOST_FAIL_STOP,
    HM_SRC_ECC,
    HM_SRC_PE_CLASS,
    HM_SRC_PE_UTIL,
    HM_SRC_PE_TMU,
    HM_SRC_HIF,
    HM_SRC_BMU,
} pfe_hm_src_t;

typedef struct {
    pfe_hm_type_t type;
    pfe_hm_src_t src;
    pfe_hm_evt_t id;
#ifdef NXP_LOG_ENABLED
    char descr[PFE_HM_DESCRIPTION_MAX_LEN];
#endif /* NXP_LOG_ENABLED */
} pfe_hm_item_t;

typedef void (* pfe_hm_cb_t)(pfe_hm_item_t *item);

void pfe_hm_init(void);
void pfe_hm_destroy(void);
void pfe_hm_report(pfe_hm_src_t src, pfe_hm_type_t type, pfe_hm_evt_t id, const char *format, ...);
errno_t pfe_hm_get(pfe_hm_item_t *item);
#ifdef NXP_LOG_ENABLED
const char *pfe_hm_get_event_str(pfe_hm_evt_t id);
const char *pfe_hm_get_src_str(pfe_hm_src_t src);
#endif /* NXP_LOG_ENABLED */
bool_t pfe_hm_register_event_cb(pfe_hm_cb_t cb);

/* AUTOSAR compiler required at least one argument supplied in VA_ARGS */
#define pfe_hm_report_info_internal(src, id, format, ...)     pfe_hm_report((src), HM_INFO, (id), "[%s:%d] " format, __FILE__, __LINE__, __VA_ARGS__)
#define pfe_hm_report_warning_internal(src, id, format, ...)  pfe_hm_report((src), HM_WARNING, (id), "[%s:%d] " format, __FILE__, __LINE__, __VA_ARGS__)
#define pfe_hm_report_error_internal(src, id, format, ...)    pfe_hm_report((src), HM_ERROR, (id), "[%s:%d] " format, __FILE__, __LINE__, __VA_ARGS__)

#define pfe_hm_report_info(...)     pfe_hm_report_info_internal(__VA_ARGS__, "")
#define pfe_hm_report_warning(...)  pfe_hm_report_warning_internal(__VA_ARGS__, "")
#define pfe_hm_report_error(...)    pfe_hm_report_error_internal(__VA_ARGS__, "")

#endif /* PFE_HM_H */


===== 文件 [75/185]: include\pfe_host_fail_stop.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_HOST_FAIL_STOP_H_
#define PUBLIC_PFE_HOST_FAIL_STOP_H_

typedef struct pfe_host_fail_stop_tag pfe_host_fail_stop_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_host_fail_stop_t *pfe_host_fail_stop_create(addr_t cbus_base_va, addr_t host_fail_stop_base);
void pfe_host_fail_stop_destroy(pfe_host_fail_stop_t *host_fail_stop);
errno_t pfe_host_fail_stop_isr(const pfe_host_fail_stop_t *host_fail_stop);
void pfe_host_fail_stop_irq_mask(const pfe_host_fail_stop_t *host_fail_stop);
void pfe_host_fail_stop_irq_unmask(const pfe_host_fail_stop_t *host_fail_stop);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_HOST_FAIL_STOP_H_ */


===== 文件 [76/185]: include\pfe_host_fail_stop_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_HOST_FAIL_STOP_CSR_H_
#define PFE_HOST_FAIL_STOP_CSR_H_

#include "pfe_host_fail_stop.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_host_fail_stop_cfg_isr(addr_t base_va);
void pfe_host_fail_stop_cfg_irq_mask(addr_t base_va);
void pfe_host_fail_stop_cfg_irq_unmask(addr_t base_va);
void pfe_host_fail_stop_cfg_irq_unmask_all(addr_t base_va);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_HOST_FAIL_STOP_CSR_H_ */


===== 文件 [77/185]: include\pfe_hw_feature.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2021-2022, 2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_DRV_FEATURE_H
#define PFE_DRV_FEATURE_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_ct.h"

typedef struct
{
    /* Similar to pfe_ct_feature_desc_t */
    const char *name;   /* Feature name */
    const char *description;    /* Feature description */
    pfe_ct_feature_flags_t flags;
    uint8 def_val;    /* Enable/disable default value used for runtime configuration */
    uint8 val;
} pfe_hw_feature_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_hw_feature_init_all(const uint32 *cbus_base, pfe_hw_feature_t *hw_features, uint32 *hw_features_count);
errno_t pfe_hw_feature_set_val(pfe_hw_feature_t *feature, uint8 val);
errno_t pfe_hw_feature_get_name(const pfe_hw_feature_t *feature, const char **name);
errno_t pfe_hw_feature_get_desc(const pfe_hw_feature_t *feature, const char **desc);
errno_t pfe_hw_feature_get_flags(const pfe_hw_feature_t *feature, pfe_ct_feature_flags_t *flags);
errno_t pfe_hw_feature_get_def_val(const pfe_hw_feature_t *feature, uint8 *def_val);
errno_t pfe_hw_feature_get_val(const pfe_hw_feature_t *feature, uint8 *val);
bool_t pfe_hw_feature_enabled(const pfe_hw_feature_t *feature);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif


===== 文件 [78/185]: include\pfe_idex.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_IDEX_H_
#define PUBLIC_PFE_IDEX_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_hif_drv.h"
#include "pfe_hif.h"

/**
 * @brief       RPC request callback type
 * @details     To be called when IDEX has received RPC request
 * @warning     Don't block or sleep within the body
 * @param[in]   sender RPC originator identifier
 * @param[in]   id Request identifier
 * @param[in]   buf Pointer to request argument. Can be NULL.
 * @param[in]   buf_len Lenght of request argument. Can be zero.
 * @param[in]   arg Custom argument provided via pfe_idex_init()
 */
typedef void (*pfe_idex_rpc_cbk_t)(pfe_ct_phy_if_id_t sender, uint32 id, void *buf, uint16 buf_len, void *arg);

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_idex_init(pfe_hif_drv_t *hif_drv, pfe_ct_phy_if_id_t master, pfe_hif_t *hif, pfe_idex_rpc_cbk_t cbk, void *arg);
errno_t pfe_idex_rpc(pfe_ct_phy_if_id_t dst_phy, uint32 id, const void *buf, uint16 buf_len, void *resp, uint16 resp_len);
errno_t pfe_idex_master_rpc(uint32 id, const void *buf, uint16 buf_len, void *resp, uint16 resp_len);
errno_t pfe_idex_set_rpc_ret_val(errno_t retval, void *resp, uint16 resp_len);
errno_t pfe_idex_send_dummy_frame(pfe_ct_phy_if_id_t dst_phy);
void pfe_idex_down(void);
void pfe_idex_fini(void);
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
void pfe_idex_ihc_poll(void);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_IDEX_H_ */


===== 文件 [79/185]: include\pfe_if_db.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_LOG_IF_DB_H_
#define PFE_LOG_IF_DB_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "linked_list.h"
#include "pfe_ct.h"
#include "pfe_log_if.h"
#include "pfe_phy_if.h"

typedef enum
{
    PFE_IF_DB_PHY = 0,
    PFE_IF_DB_LOG,
    PFE_XXX_IF_DB_INSTANCES
} pfe_if_db_type_t;

/**
 * @brief   Interface database entry type
 */
typedef struct pfe_if_db_entry_tag pfe_if_db_entry_t;

/**
 * @brief   Interface database select criteria type
 */
typedef enum
{
    IF_DB_CRIT_ALL,             /*!< Match any entry in the DB */
    IF_DB_CRIT_BY_ID,           /*!< Match entries by interface ID */
    IF_DB_CRIT_BY_INSTANCE,     /*!< Match entries by interface instance */
    IF_DB_CRIT_BY_NAME,         /*!< Match entries by interface name */
    IF_DB_CRIT_BY_OWNER         /*!< Match entries by owner ID */
} pfe_if_db_get_criterion_t;

/**
 * @brief   Interface database instance representation type
 */
typedef struct pfe_if_db_tag pfe_if_db_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_if_db_t * pfe_if_db_create(pfe_if_db_type_t type);
void pfe_if_db_destroy(const pfe_if_db_t *db);
errno_t pfe_if_db_add(pfe_if_db_t *db, uint32 session_id, void *iface, pfe_ct_phy_if_id_t owner);
errno_t pfe_if_db_remove(pfe_if_db_t *db, uint32 session_id, pfe_if_db_entry_t *entry);
errno_t pfe_if_db_lock(uint32 *session_id);
errno_t pfe_if_db_lock_owned(uint32 owner_id);
errno_t pfe_if_db_unlock(uint32 session_id);
errno_t pfe_if_db_get_first(pfe_if_db_t *db, uint32 session_id, pfe_if_db_get_criterion_t crit, void *arg, pfe_if_db_entry_t **db_entry);
errno_t pfe_if_db_get_next(pfe_if_db_t *db, uint32 session_id, pfe_if_db_entry_t **db_entry);
pfe_phy_if_t *pfe_if_db_entry_get_phy_if(const pfe_if_db_entry_t *entry) __attribute__((pure));
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
pfe_log_if_t *pfe_if_db_entry_get_log_if(const pfe_if_db_entry_t *entry) __attribute__((pure));
#endif
errno_t pfe_if_db_get_single(const pfe_if_db_t *db, uint32 session_id, pfe_if_db_get_criterion_t crit, void *arg, pfe_if_db_entry_t **db_entry);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_LOG_IF_DB_H_ */


===== 文件 [80/185]: include\pfe_l2br.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_L2BR_H_
#define PUBLIC_PFE_L2BR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_log_if.h"
#include "pfe_l2br_table.h"
#include "Eth_43_PFE.h"

#ifdef PFE_CFG_L2BRIDGE_ENABLE
typedef struct pfe_l2br_tag pfe_l2br_t;
typedef struct pfe_l2br_domain_tag pfe_l2br_domain_t;
typedef struct pfe_l2br_static_entry_tag pfe_l2br_static_entry_t;

/**
 * @brief   Bridge domain select criteria type
 */
typedef enum
{
    L2BD_CRIT_ALL,              /*!< Match any domain within the bridge (argument is NULL) */
    L2BD_CRIT_BY_VLAN,          /*!< Match entry with VLAN equal to arg (argument is uint16) */
    L2BD_BY_PHY_IF,             /*!< Match entries containing given physical interface (argument is pfe_phy_if_t *) */
} pfe_l2br_domain_get_crit_t;

typedef enum
{
    L2BD_IF_CRIT_ALL,           /*!< Match any interface within the domain (argument is NULL) */
    L2BD_IF_BY_PHY_IF_ID,       /*!< Match entries by physical interface id (argument is pfe_phy_if_id_t) */
    L2BD_IF_BY_PHY_IF           /*!< Match entries containing given physical interface (argument is pfe_phy_if_t *) */
} pfe_l2br_domain_if_get_crit_t;

typedef enum
{
    L2SENT_CRIT_ALL,            /*!< Match any static entry (argument is NULL) */
    L2SENT_CRIT_BY_MAC,         /*!< Match static entry by mac (arg1 is NULL and arg2 is MAC) */
    L2SENT_CRIT_BY_VLAN,        /*!< Match static entry by vlan (arg1 is VLAN and arg2 is NULL) */
    L2SENT_CRIT_BY_MAC_VLAN     /*!< Match static entry by mac+vlan (arg1 is VLAN and arg2 is MAC) */
} pfe_l2br_static_ent_get_crit_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_l2br_domain_create(pfe_l2br_t *bridge, uint16 vlan);
errno_t pfe_l2br_domain_destroy(pfe_l2br_domain_t *domain);
errno_t pfe_l2br_domain_set_ucast_action(pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t hit, pfe_ct_l2br_action_t miss);
errno_t pfe_l2br_domain_set_mcast_action(pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t hit, pfe_ct_l2br_action_t miss);
errno_t pfe_l2br_domain_add_if(pfe_l2br_domain_t *domain, pfe_phy_if_t *iface, bool_t tagged);
errno_t pfe_l2br_domain_del_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface);
errno_t pfe_l2br_domain_flush_by_if(const pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface);
pfe_phy_if_t *pfe_l2br_domain_get_first_if(pfe_l2br_domain_t *domain, pfe_l2br_domain_if_get_crit_t crit, void *arg);
pfe_phy_if_t *pfe_l2br_domain_get_next_if(pfe_l2br_domain_t *domain);
errno_t pfe_l2br_domain_get_vlan(const pfe_l2br_domain_t *domain, uint16 *vlan);
errno_t pfe_l2br_domain_get_ucast_action(const pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t *hit, pfe_ct_l2br_action_t *miss);
errno_t pfe_l2br_domain_get_mcast_action(const pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t *hit, pfe_ct_l2br_action_t *miss);
bool_t pfe_l2br_domain_is_default(const pfe_l2br_domain_t *domain) __attribute__((pure));
bool_t pfe_l2br_domain_is_fallback(const pfe_l2br_domain_t *domain) __attribute__((pure));
uint32 pfe_l2br_domain_get_if_list(const pfe_l2br_domain_t *domain); __attribute__((pure))
uint32 pfe_l2br_domain_get_untag_if_list(const pfe_l2br_domain_t *domain) __attribute__((pure));

errno_t pfe_l2br_static_entry_create(pfe_l2br_t *bridge, uint16 vlan, const pfe_mac_addr_t mac, uint32 new_fw_list);
errno_t pfe_l2br_static_entry_destroy(pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent);
errno_t pfe_l2br_static_entry_replace_fw_list(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent, uint32 new_fw_list);
__attribute__((pure)) uint32 pfe_l2br_static_entry_get_fw_list(const pfe_l2br_static_entry_t* static_ent);
__attribute__((pure)) uint16 pfe_l2br_static_entry_get_vlan(const pfe_l2br_static_entry_t *static_ent);
void pfe_l2br_static_entry_get_mac(const pfe_l2br_static_entry_t *static_ent, pfe_mac_addr_t mac);
pfe_l2br_static_entry_t *pfe_l2br_static_entry_get_first(pfe_l2br_t *bridge, pfe_l2br_static_ent_get_crit_t crit, void* arg1,const void *arg2);
pfe_l2br_static_entry_t *pfe_l2br_static_entry_get_next(pfe_l2br_t *bridge);
errno_t pfe_l2br_static_entry_get_local_flag(const pfe_l2br_t *bridge, const pfe_l2br_static_entry_t* static_ent, bool_t *local);
errno_t pfe_l2br_static_entry_get_src_discard_flag(pfe_l2br_t *bridge, const pfe_l2br_static_entry_t* static_ent, bool_t *src_discard);
errno_t pfe_l2br_static_entry_get_dst_discard_flag(const pfe_l2br_t *bridge, const pfe_l2br_static_entry_t* static_ent, bool_t *dst_discard);
errno_t pfe_l2br_static_entry_set_local_flag(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent, bool_t local);
errno_t pfe_l2br_static_entry_set_src_discard_flag(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent, bool_t src_discard);
errno_t pfe_l2br_static_entry_set_dst_discard_flag(const pfe_l2br_t * bridge, pfe_l2br_static_entry_t* static_ent, bool_t dst_discard);

pfe_l2br_t *pfe_l2br_create(pfe_class_t *class, uint16 def_vlan, uint16 def_aging_time, uint16 vlan_stats_size,
                            pfe_l2br_table_t *mac_table, pfe_l2br_table_t *vlan_table);
errno_t pfe_l2br_destroy(pfe_l2br_t *bridge);
pfe_l2br_domain_t *pfe_l2br_get_default_domain(const pfe_l2br_t *bridge) __attribute__((pure));
pfe_l2br_domain_t *pfe_l2br_get_fallback_domain(const pfe_l2br_t *bridge) __attribute__((pure));
pfe_l2br_domain_t *pfe_l2br_get_first_domain(pfe_l2br_t *bridge, pfe_l2br_domain_get_crit_t crit, void *arg);
pfe_l2br_domain_t *pfe_l2br_get_next_domain(pfe_l2br_t *bridge);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_l2br_get_text_statistics(const pfe_l2br_t *bridge, char_t *buf, uint32 buf_len, uint8 verb_level);
uint32 pfe_l2br_domain_get_text_statistics(pfe_l2br_t *bridge, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

errno_t pfe_l2br_get_stats(const pfe_l2br_t *bridge, Eth_43_PFE_L2BridgeStatsType* stat, uint32 index_entry);
uint32 pfe_l2br_get_number_entries(const pfe_l2br_t *bridge);

errno_t pfe_l2br_clear_domain_stats(const pfe_l2br_t *bridge, uint8 vlan_index);
errno_t pfe_l2br_get_domain_stats(const pfe_l2br_t *bridge, pfe_ct_vlan_stats_t *stat, uint8 vlan_index);
uint8 pfe_l2br_get_vlan_stats_index(const pfe_l2br_domain_t *domain);

errno_t pfe_l2br_flush_learned(pfe_l2br_t *bridge);
errno_t pfe_l2br_flush_static(pfe_l2br_t *bridge);
errno_t pfe_l2br_flush_all(pfe_l2br_t *bridge);
pfe_l2br_table_entry_t *pfe_l2br_static_entry_get_entry(pfe_l2br_static_entry_t *static_ent);
errno_t pfe_l2br_update_vlan_hash_entry(pfe_l2br_domain_t *domain);
errno_t pfe_l2br_add_vlan_hash_entry(pfe_l2br_domain_t *domain);
errno_t pfe_l2br_delete_vlan_hash_entry(pfe_l2br_domain_t *domain);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#else
typedef void pfe_l2br_t;
typedef void pfe_l2br_domain_t;
typedef void pfe_l2br_static_entry_t;
#endif /* PFE_CFG_L2BRIDGE_ENABLE */

#endif /* PUBLIC_PFE_L2BR_H_ */


===== 文件 [81/185]: include\pfe_l2br_table.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_L2BR_TABLE_H_
#define PUBLIC_PFE_L2BR_TABLE_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_phy_if.h"

typedef enum
{
    PFE_L2BR_TABLE_INVALID,
    PFE_L2BR_TABLE_MAC2F,
    PFE_L2BR_TABLE_VLAN
} pfe_l2br_table_type_t;

/**
 * @brief   L2 bridge table select criteria type
 */
typedef enum
{
    L2BR_TABLE_CRIT_ALL,            /*!< Match any entry in the table */
    L2BR_TABLE_CRIT_VALID           /*!< Match only valid entries */
} pfe_l2br_table_get_criterion_t;

typedef struct pfe_l2br_table_tag pfe_l2br_table_t;
typedef struct
{
    pfe_l2br_table_get_criterion_t cur_crit;    /*!< Current criterion                          */
    uint32 cur_hash_addr;                     /*!< Current address within hash space          */
    uint32 cur_coll_addr;                     /*!< Current address within collision space     */
    uint32 next_coll_addr;                    /*!< Next entry address within collision space  */
    struct                                      /*!< MAC and VLAN of the current entry          */
    {
        pfe_mac_addr_t mac;
        uint16 vlan;
    } cur_macvlan;
} pfe_l2br_table_iterator_t;

/**
 * @brief   2-field MAC table entry
 */
typedef struct __attribute__((packed, aligned(4)))
{
    pfe_mac_addr_t mac;                                     /*!< [47:0]                                             */
    uint32 vlan                               : 13;       /*!< [60:48]                                            */
    uint32 action_data                        : 31;       /*!< [91:61], see pfe_ct_mac_table_result_t     */
    uint32 field_valids                       : 8;        /*!< [99:92], see pfe_mac2f_table_entry_valid_bits_t    */
    uint32 port                               : 4;        /*!< [103:100]                                          */
    uint32 col_ptr                            : 16;       /*!< [119:104]                                          */
    uint32 flags                              : 4;        /*!< [123:120], see pfe_mac2f_table_entry_flags_t       */
    uint32 padding                            : 4;        /*!< [127:124], Round up to integer number of bytes     */
} pfe_mac2f_table_entry_t;

/**
 * @brief   VLAN table entry
 */
typedef struct __attribute__((packed, aligned(4)))
{
    uint32 vlan           : 13;   /*!< [12:0]                                         */
    uint64 action_data    : 55;   /*!< [67:13], see pfe_vlan_table_action_entry_t     */
    uint32 field_valids   : 8;    /*!< [75:68], see pfe_vlan_table_entry_valid_bits_t */
    uint32 port           : 4;    /*!< [79:76]                                        */
    uint32 col_ptr        : 16;   /*!< [95:80]                                        */
    uint32 flags          : 4;    /*!< [99:96], see pfe_vlan_table_entry_flags_t      */
    uint32 padding        : 28;   /*!< [127:100], Round up to integer number of bytes */
} pfe_vlan_table_entry_t;

typedef struct
{
    union
    {
        pfe_mac2f_table_entry_t mac2f_entry;
        pfe_vlan_table_entry_t vlan_entry;
    } u;

    pfe_l2br_table_type_t type;
    bool_t action_data_set;
    bool_t mac_addr_set;
    bool_t vlan_set;
} pfe_l2br_table_entry_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_l2br_table_t *pfe_l2br_table_create(addr_t cbus_base_va, pfe_l2br_table_type_t type);
errno_t pfe_l2br_table_init(pfe_l2br_table_t *l2br);
errno_t pfe_l2br_table_flush(pfe_l2br_table_t *l2br);
errno_t pfe_l2br_table_add_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_del_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_update_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_search_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
pfe_l2br_table_iterator_t *pfe_l2br_iterator_create(pfe_l2br_table_iterator_t *loop_inst);
errno_t pfe_l2br_iterator_destroy(const pfe_l2br_table_iterator_t *inst);
errno_t pfe_l2br_table_get_first(pfe_l2br_table_t *l2br, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_get_criterion_t crit, pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_get_next(pfe_l2br_table_t *l2br, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry);

pfe_l2br_table_entry_t *pfe_l2br_table_entry_create(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_entry_destroy(const pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_entry_set_mac_addr(pfe_l2br_table_entry_t *entry, const pfe_mac_addr_t mac_addr);
errno_t pfe_l2br_table_entry_set_vlan(pfe_l2br_table_entry_t *entry, uint16 vlan);
__attribute__((pure)) uint32 pfe_l2br_table_entry_get_vlan(const pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_entry_set_action_data(pfe_l2br_table_entry_t *entry, uint64 action_data);
__attribute__((pure)) uint64 pfe_l2br_table_entry_get_action_data(const pfe_l2br_table_entry_t *entry);
errno_t pfe_l2br_table_entry_set_fresh(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, bool_t is_fresh);
bool_t pfe_l2br_table_entry_is_fresh(const pfe_l2br_table_entry_t *entry) __attribute__((pure));
errno_t pfe_l2br_table_entry_set_static(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, bool_t is_static);
bool_t pfe_l2br_table_entry_is_static(const pfe_l2br_table_entry_t *entry) __attribute__((pure));

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_l2br_table_entry_to_str(const pfe_l2br_table_entry_t *entry, char_t *buf, uint32 buf_len);
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_L2BR_TABLE_H_ */


===== 文件 [82/185]: include\pfe_l2br_table_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef HW_S32G_PFE_L2BR_TABLE_CSR_H_
#define HW_S32G_PFE_L2BR_TABLE_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#include "pfe_class_csr.h"

#define MAC2F_TABLE_HASH_ENTRIES        256U /* Must be power-of-2 */
#define MAC2F_TABLE_COLL_ENTRIES        256U
#define MAC2F_TABLE_HASH_SPACE_START    0U
#define MAC2F_TABLE_COLL_SPACE_START    MAC2F_TABLE_HASH_ENTRIES

#define HOST_MAC2F_CMD_REG              (CLASS_DAMACHASH_HOST_CMD_REG)
#define HOST_MAC2F_MAC1_ADDR_REG        (CLASS_DAMACHASH_HOST_MAC_ADDR1_REG)
#define HOST_MAC2F_MAC2_ADDR_REG        (CLASS_DAMACHASH_HOST_MAC_ADDR2_REG)
#define HOST_MAC2F_MAC3_ADDR_REG        (CLASS_DAMACHASH_HOST_MAC_ADDR3_REG)
#define HOST_MAC2F_MAC4_ADDR_REG        (CLASS_DAMACHASH_HOST_MAC_ADDR4_REG)
#define HOST_MAC2F_MAC5_ADDR_REG        (CLASS_DAMACHASH_HOST_MAC_ADDR5_REG)
#define HOST_MAC2F_ENTRY_REG            (CLASS_DAMACHASH_HOST_ENTRY_REG)
#define HOST_MAC2F_STATUS_REG           (CLASS_DAMACHASH_HOST_STATUS_REG)
#define HOST_MAC2F_DIRECT_REG           (CLASS_DAMACHASH_HOST_DIRECT)

#define HOST_MAC2F_FREE_LIST_ENTRIES    (CLASS_DAMACHASH_FREELIST_ENTRIES)
#define HOST_MAC2F_FREE_LIST_HEAD_PTR   (CLASS_DAMACHASH_FREELIST_HEAD_PTR)
#define HOST_MAC2F_FREE_LIST_TAIL_PTR   (CLASS_DAMACHASH_FREELIST_TAIL_PTR)

#define VLAN_TABLE_HASH_ENTRIES         64U /* Must be power-of-2 */
#define VLAN_TABLE_COLL_ENTRIES         64U
#define VLAN_TABLE_HASH_SPACE_START     0U
#define VLAN_TABLE_COLL_SPACE_START     VLAN_TABLE_HASH_ENTRIES

#define HOST_VLAN_CMD_REG               (CLASS_DAVLANHASH_HOST_CMD_REG)
#define HOST_VLAN_MAC1_ADDR_REG         (CLASS_DAVLANHASH_HOST_MAC_ADDR1_REG)
#define HOST_VLAN_MAC2_ADDR_REG         (CLASS_DAVLANHASH_HOST_MAC_ADDR2_REG)
#define HOST_VLAN_MAC3_ADDR_REG         (CLASS_DAVLANHASH_HOST_MAC_ADDR3_REG)
#define HOST_VLAN_MAC4_ADDR_REG         (CLASS_DAVLANHASH_HOST_MAC_ADDR4_REG)
#define HOST_VLAN_MAC5_ADDR_REG         (CLASS_DAVLANHASH_HOST_MAC_ADDR5_REG)
#define HOST_VLAN_ENTRY_REG             (CLASS_DAVLANHASH_HOST_ENTRY_REG)
#define HOST_VLAN_STATUS_REG            (CLASS_DAVLANHASH_HOST_STATUS_REG)
#define HOST_VLAN_DIRECT_REG            (CLASS_DAVLANHASH_HOST_DIRECT)

#define HOST_VLAN_FREE_LIST_ENTRIES     (CLASS_DAVLANHASH_FREELIST_ENTRIES)
#define HOST_VLAN_FREE_LIST_HEAD_PTR    (CLASS_DAVLANHASH_FREELIST_HEAD_PTR)
#define HOST_VLAN_FREE_LIST_TAIL_PTR    (CLASS_DAVLANHASH_FREELIST_TAIL_PTR)

#define STATUS_REG_CMD_DONE             (1U << 0)
#define STATUS_REG_SIG_ENTRY_NOT_FOUND  (1U << 1)
#define STATUS_REG_SIG_INIT_DONE        (1U << 2)
#define STATUS_REG_SIG_ENTRY_ADDED      (1U << 3)
#define STATUS_REG_MATCH                (1U << 4)

typedef enum
{
    L2BR_CMD_INIT = 0x1,
    L2BR_CMD_ADD = 0x2,
    L2BR_CMD_DELETE = 0x3,
    L2BR_CMD_UPDATE = 0x4,
    L2BR_CMD_SEARCH = 0x5,
    L2BR_CMD_MEM_READ = 0x6,
    L2BR_CMD_MEM_WRITE = 0x7,
    L2BR_CMD_FLUSH = 0x8
} pfe_l2br_table_cmd_t;

#endif /* HW_S32G_PFE_L2BR_TABLE_CSR_H_ */


===== 文件 [83/185]: include\pfe_log_if.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_LOG_IF_H_
#define PUBLIC_PFE_LOG_IF_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_ct.h"
#include "linked_list.h"

typedef struct pfe_log_if_tag pfe_log_if_t;

#ifndef PUBLIC_PFE_PHY_IF_H_
#include "pfe_phy_if.h"
#endif

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_log_ifs_init(void);
void pfe_log_ifs_deinit(void);
LLIST_t *pfe_log_if_get_phy_if_binding_list_entry(const pfe_log_if_t *iface);
pfe_log_if_t *pfe_log_if_from_phy_if_binding_list_entry(const LLIST_t *entry);
pfe_log_if_t *pfe_log_if_create(pfe_phy_if_t *parent, const char_t *name);
uint8 pfe_log_if_get_id(const pfe_log_if_t *iface) __attribute__((pure));
__attribute__((pure)) pfe_phy_if_t *pfe_log_if_get_parent(const pfe_log_if_t *iface);
errno_t pfe_log_if_set_next_dmem_ptr(pfe_log_if_t *iface, addr_t next_dmem_ptr);
errno_t pfe_log_if_get_next_dmem_ptr(pfe_log_if_t *iface, addr_t *next_dmem_ptr);
errno_t pfe_log_if_get_dmem_base(const pfe_log_if_t *iface, addr_t *dmem_base);
void pfe_log_if_destroy(pfe_log_if_t *iface);
errno_t pfe_log_if_set_match_or(pfe_log_if_t *iface);
errno_t pfe_log_if_set_match_and(pfe_log_if_t *iface);
bool_t pfe_log_if_is_match_or(pfe_log_if_t *iface);
errno_t pfe_log_if_set_match_rules(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rules, const pfe_ct_if_m_args_t *args);
errno_t pfe_log_if_get_match_rules(pfe_log_if_t *iface, pfe_ct_if_m_rules_t *rules, pfe_ct_if_m_args_t *args);
errno_t pfe_log_if_add_match_rule(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len);
errno_t pfe_log_if_del_match_rule(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule);
errno_t pfe_log_if_get_egress_ifs(pfe_log_if_t *iface, uint32 *egress);
errno_t pfe_log_if_set_egress_ifs(pfe_log_if_t *iface, uint32 egress);
errno_t pfe_log_if_add_egress_if(pfe_log_if_t *iface, const pfe_phy_if_t *phy_if);
errno_t pfe_log_if_del_egress_if(pfe_log_if_t *iface, const pfe_phy_if_t *phy_if);
errno_t pfe_log_if_enable(pfe_log_if_t *iface);
errno_t pfe_log_if_disable(pfe_log_if_t *iface);
bool_t pfe_log_if_is_enabled(const pfe_log_if_t *iface) __attribute__((pure));
errno_t pfe_log_if_promisc_enable(pfe_log_if_t *iface);
errno_t pfe_log_if_promisc_disable(pfe_log_if_t *iface);
bool_t pfe_log_if_is_promisc(pfe_log_if_t *iface) __attribute__((pure));
const char_t *pfe_log_if_get_name(const pfe_log_if_t *iface) __attribute__((pure));
errno_t pfe_log_if_discard_enable(pfe_log_if_t *iface);
errno_t pfe_log_if_discard_disable(pfe_log_if_t *iface);
bool_t pfe_log_if_is_discard(pfe_log_if_t *iface);
errno_t pfe_log_if_get_stats(const pfe_log_if_t *iface, pfe_ct_class_algo_stats_t *stat);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_LOG_IF_H_ */


===== 文件 [84/185]: include\pfe_mac_db.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_MAC_DB_H_
#define PUBLIC_PFE_MAC_DB_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "oal_types.h"

#include "pfe_ct.h"
#include "isa.h"

/**
 * @brief   The MAC address type
 * @details Bytes are represented as:
 *          \code
 *              pfe_mac_addr_t mac;
 *
 *              emac[0] = 0xaa;
 *              emac[1] = 0xbb;
 *              emac[2] = 0xcc;
 *              emac[3] = 0xdd;
 *              emac[4] = 0xee;
 *              emac[5] = 0xff;
 *
 *              printf("The MAC address is: %x:%x:%x:%x:%x:%x\n",
 *                      mac[0], emac[1], mac[2], mac[3], mac[4], mac[5]);
 *          \endcode
 */
typedef uint8 pfe_mac_addr_t[6];

/**
 * @brief   Possible types of MAC addresses used while getting or flushing
 */
typedef enum
{
    PFE_TYPE_UC,
    PFE_TYPE_MC,
    PFE_TYPE_BC,
    PFE_TYPE_ANY
} pfe_mac_type_t;

typedef struct
{
    pfe_mac_addr_t addr;        /*  The MAC address */
    pfe_drv_id_t owner;         /*  Identification of the driver that owns this entry */
} pfe_mac_db_list_entry_t;

/**
 * @brief   Possible rules to get or flush some sort of MAC addresses
 */
typedef enum __attribute__ ((packed))
{
    MAC_DB_CRIT_BY_TYPE = 0U,
    MAC_DB_CRIT_BY_OWNER,
    MAC_DB_CRIT_BY_OWNER_AND_TYPE,
    MAC_DB_CRIT_ALL,
    MAC_DB_CRIT_INVALID,
} pfe_mac_db_crit_t;

typedef struct
{
    pfe_isa_t mac_list;
    struct {
        pfe_mac_db_crit_t crit;
        pfe_drv_id_t owner;
        pfe_mac_type_t type;
    } crit;
    pfe_isa_index_t mac_list_idx[PFE_CFG_MAC_DB_ENTRIES_MAX];
    pfe_mac_db_list_entry_t mac_list_pool[PFE_CFG_MAC_DB_ENTRIES_MAX];
    pfe_isa_definition_t isa_def;
    uint32 next_item;
} pfe_mac_db_t;


#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_mac_db_create(pfe_mac_db_t *db);
errno_t pfe_mac_db_add_addr(pfe_mac_db_t *db, const pfe_mac_addr_t addr, pfe_drv_id_t owner);
errno_t pfe_mac_db_del_addr(pfe_mac_db_t *db, const pfe_mac_addr_t addr, pfe_drv_id_t owner);
errno_t pfe_mac_db_flush(pfe_mac_db_t *db, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner);
errno_t pfe_mac_db_get_first_addr(pfe_mac_db_t *db, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner, pfe_mac_addr_t addr);
errno_t pfe_mac_db_get_next_addr(pfe_mac_db_t *db, pfe_mac_addr_t addr);
errno_t pfe_mac_db_find_by_crit(pfe_mac_db_t *db, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner, pfe_mac_db_list_entry_t *match_entry);

/**
 * @brief       Check if given MAC address is zero
 * @param[in]   addr The address to check
 * @return      TRUE if the input address is zero
 */
static inline bool_t pfe_emac_is_zero(const pfe_mac_addr_t addr)
{
    bool_t ReVal;
    if (0x0U == ((uint32)addr[0] | addr[1] | addr[2] | addr[3] | addr[4] | addr[5]))
    {
        ReVal = TRUE;
    }
    else
    {
        ReVal = FALSE;
    }
    return ReVal;
}

/**
 * @brief       Check if given MAC address is broadcast
 * @param[in]   addr The address to check
 * @return      TRUE if the input address is broadcast
 */
static inline bool_t pfe_emac_is_broad(const pfe_mac_addr_t addr)
{
    bool_t ReVal;
    if (0xffU == (addr[0] & addr[1] & addr[2] & addr[3] & addr[4] & addr[5]))
    {
        ReVal = TRUE;
    }
    else
    {
        ReVal = FALSE;
    }
    return ReVal;
}

/**
 * @brief       Check if given MAC address is multicast
 * @param[in]   addr The address to check
 * @return      TRUE if the input address is multicast
 */
static inline bool_t pfe_emac_is_multi(const pfe_mac_addr_t addr)
{
    bool_t ReVal;
    if ((FALSE == pfe_emac_is_broad(addr)) && (0U != (addr[0] & 0x1U)))
    {
        ReVal = TRUE;
    }
    else
    {
        ReVal = FALSE;
    }
    return ReVal;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_MAC_DB_H_ */


===== 文件 [85/185]: include\pfe_minihif_drv.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *
 *  This file contains sample code only. It is not part of the production code deliverables.
 *
 * ========================================================================= */

/**
 * @defgroup    dxgr_PFE_MINIHIF_DRV miniHIF Driver
 * @brief       The attached minihif driver
 * @details     This implementation, when called, configures a HIF channel to be
 *              used by a detached minihif driver to transmit and receive through
 *              PFE.
 * @addtogroup  dxgr_PFE_MINIHIF_DRV
 * @{
 *
 * @file        pfe_hif_drv.h
 * @brief       The HIF driver header file.
 * @details     This is the attached minihif driver API.
 *
 */

#ifndef PFE_MINIHIF_DRV_H
#define PFE_MINIHIF_DRV_H


/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_cfg.h"
#include "pfe_platform_cfg.h"
#include "pfe_ct.h"
#include "oal.h"
#include "pfe_phy_if.h"
#include "pfe_hif_chnl.h"
#include "pfe_hif_ring.h"

/**
 * @brief   miniHIF driver instance representation - not to be accessed directly by user
 */
typedef struct
{
    pfe_ct_phy_if_id_t id;
    pfe_hif_chnl_t channel;
    pfe_hif_ring_t rx_ring;
    pfe_hif_ring_t tx_ring;
    bool_t rx_ring_created;
    bool_t tx_ring_created;
    bool_t init_done;
}pfe_minihif_drv_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

extern errno_t pfe_minihif_drv_create(pfe_minihif_drv_t *hif_drv, pfe_ct_phy_if_id_t id, bool_t bd_access);
extern errno_t pfe_minihif_drv_attach_ring(pfe_minihif_drv_t *hif_drv, bool_t is_rx, void *bd_base_va, void *wb_bd_base_va, uint32 length);
extern errno_t pfe_minihif_drv_init(pfe_minihif_drv_t *hif_drv);
extern errno_t pfe_minihif_drv_start_rx(pfe_minihif_drv_t *hif_drv);
extern errno_t pfe_minihif_drv_start_tx(pfe_minihif_drv_t *hif_drv);
extern pfe_ct_phy_if_id_t pfe_minihif_get_hif_id(const pfe_minihif_drv_t *hif_drv);
extern errno_t pfe_minihif_drv_stop(pfe_minihif_drv_t *hif_drv);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_MINIHIF_DRV_H */


===== 文件 [86/185]: include\pfe_mirror.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
#ifndef PFE_MIRROR_H
#define PFE_MIRROR_H

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_class.h"

typedef struct pfe_mirror_tag pfe_mirror_t;

typedef enum
{
    MIRROR_ANY,         /* Retrieve the 1st entry in the database, arg not used */
    MIRROR_BY_NAME,     /* Retrieve the entry with matching name, arg is a string (the name) */
    MIRROR_BY_PHYS_ADDR /* Retrieve the entry with matching DMEM address, arg is addr_t (the address) */
} pfe_mirror_db_crit_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_mirror_init(pfe_class_t *class);
void pfe_mirror_deinit(void);
pfe_mirror_t *pfe_mirror_get_first(pfe_mirror_db_crit_t crit, const void *arg);
pfe_mirror_t *pfe_mirror_get_next(void);
pfe_mirror_t *pfe_mirror_create(const char *name);
errno_t pfe_mirror_destroy(pfe_mirror_t *mirror);
void pfe_mirror_put(pfe_mirror_t *mirror);
void pfe_mirror_put_by_address(addr_t address);
uint32 pfe_mirror_get_address(const pfe_mirror_t *mirror);
const char * pfe_mirror_get_name(const pfe_mirror_t *mirror);
errno_t pfe_mirror_set_egress_port(pfe_mirror_t *mirror, pfe_ct_phy_if_id_t egress);
pfe_ct_phy_if_id_t pfe_mirror_get_egress_port(const pfe_mirror_t *mirror);
errno_t pfe_mirror_set_filter(pfe_mirror_t *mirror, uint32 filter_address);
uint32 pfe_mirror_get_filter(const pfe_mirror_t *mirror);
errno_t pfe_mirror_set_actions(pfe_mirror_t *mirror, pfe_ct_route_actions_t actions, const pfe_ct_route_actions_args_t *args);
errno_t pfe_mirror_get_actions(const pfe_mirror_t *mirror, pfe_ct_route_actions_t *actions, pfe_ct_route_actions_args_t *args);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_MIRROR_H */


===== 文件 [87/185]: include\pfe_parity.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2019-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_PARITY_H_
#define PUBLIC_PFE_PARITY_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


typedef struct pfe_parity_tag pfe_parity_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_parity_t *pfe_parity_create(addr_t cbus_base_va, addr_t parity_base);
void pfe_parity_destroy(pfe_parity_t *parity);
errno_t pfe_parity_isr(const pfe_parity_t *parity);
void pfe_parity_irq_mask(const pfe_parity_t *parity);
void pfe_parity_irq_unmask(const pfe_parity_t *parity);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_PARITY_H_ */


===== 文件 [88/185]: include\pfe_parity_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2019-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_PARITY_CSR_H_
#define PFE_PARITY_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#include "pfe_parity.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_parity_cfg_isr(addr_t base_va);
void pfe_parity_cfg_irq_mask(addr_t base_va);
void pfe_parity_cfg_irq_unmask(addr_t base_va);
void pfe_parity_cfg_irq_unmask_all(addr_t base_va);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_PARITY_CSR_H_ */


===== 文件 [89/185]: include\pfe_pe.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_PE_H_
#define PFE_PE_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_ct.h"

typedef enum
{
    PFE_PE_DMEM,
    PFE_PE_IMEM
} pfe_pe_mem_t;

struct pfe_pe_tag;

typedef struct
{
    uint8 pe_loaded_cnt;
    bool_t can_load_util;
    void (*pe_memset)(struct pfe_pe_tag *pe, pfe_pe_mem_t mem, uint32 val, addr_t addr, uint32 size);
    void (*pe_memcpy)(struct pfe_pe_tag *pe, pfe_pe_mem_t mem, addr_t dst_addr, const void *src_ptr, uint32 len);
} fw_load_ops_t;

/*  Processing Engine representation */
typedef struct pfe_pe_tag
{
    pfe_ct_pe_type_t type;              /* PE type */
    addr_t cbus_base_va;                /* CBUS base (virtual) */
    uint8 id;                         /* PE HW ID (0..N) */

    /*  DMEM */
    addr_t dmem_elf_base_va;            /* PE's DMEM base address (virtual, as seen by PE) */
    addr_t dmem_size;                   /* PE's DMEM region length */

    /*  IMEM */
    addr_t imem_elf_base_va;            /* PE's IMEM base address (virtual, as seen by PE) */
    addr_t imem_size;                   /* PE's IMEM size */

    /*  LMEM */
    addr_t lmem_base_addr_pa;           /* PE's LMEM base address (physical, as seen by PE) */
    addr_t lmem_size;                   /* PE's LMEM size */

    /*  DDR */
    addr_t ddr_base_addr_pa;            /* PE's DDR base address (physical, as seen by host) */
    addr_t ddr_base_addr_va;            /* PE's DDR base address (virtual) */
    addr_t ddr_size;                    /* PE's DDR size */

    /*  Indirect Access */
    addr_t mem_access_wdata;            /* PE's _MEM_ACCESS_WDATA register address (virtual) */
    addr_t mem_access_addr;             /* PE's _MEM_ACCESS_ADDR register address (virtual) */
    addr_t mem_access_rdata;            /* PE's _MEM_ACCESS_RDATA register address (virtual) */

    /* Operations to load FW */
    const fw_load_ops_t *fw_load_ops;

    /* FW Errors*/
    uint32 message_record_addr;       /* Error record storage address in DMEM */
    uint32 last_message_write_index;  /* Last seen value of write index in the record */
    void *fw_msg_section;               /* Error descriptions elf section storage */
    uint32 fw_msg_section_size;       /* Size of the above section */
    /* FW features */
    void *fw_feature_section;           /* Features descriptions elf section storage */
    uint32 fw_feature_section_size;   /* Size of the above section */
    uint32 fw_features_base;          /* Extracted base address of the features table */
    uint32 fw_features_size;          /* Number of entries in the features table */

    /*  MMap */
    pfe_ct_pe_mmap_t *mmap_data;        /* Buffer containing the memory map data */

    bool_t *miflock;                    /* Pointer to diagnostic flag (provided from PE's parent) 
                                           When TRUE then PFE memory interface is locked */

    /* Stall detection */
    uint32 counter;                   /* Latest PE counter value */
    pfe_ct_pe_sw_state_t prev_state;    /* Recently read PE state */
    bool_t stalled;                     /* Flag for current stall state */
} pfe_pe_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_pe_t * pfe_pe_create(addr_t cbus_base_va, pfe_ct_pe_type_t type, uint8 id, pfe_pe_t *pe, bool_t *miflock);
void pfe_pe_set_dmem(pfe_pe_t *pe, addr_t elf_base, addr_t len);
void pfe_pe_set_imem(pfe_pe_t *pe, addr_t elf_base, addr_t len);
void pfe_pe_set_lmem(pfe_pe_t *pe, addr_t elf_base, addr_t len);
void pfe_pe_set_iaccess(pfe_pe_t *pe, uint32 wdata_reg, uint32 rdata_reg, uint32 addr_reg);
errno_t pfe_pe_mem_default_init(pfe_pe_t *pe, uint32 pe_num);
errno_t pfe_pe_load_firmware(pfe_pe_t *pe, uint32 pe_num, const void *elf);
errno_t pfe_pe_get_mmap(const pfe_pe_t *pe, pfe_ct_pe_mmap_t *mmap);
void pfe_pe_memcpy_from_dmem_to_host_32_nolock(pfe_pe_t *pe, void *dst_ptr, addr_t src_addr, uint32 len);
void pfe_pe_memcpy_from_host_to_dmem_32(pfe_pe_t *pe, addr_t dst_addr, const void *src_ptr, uint32 len);
void pfe_pe_memcpy_from_dmem_to_host_32(pfe_pe_t *pe, void *dst_ptr, addr_t src_addr, uint32 len);
errno_t pfe_pe_gather_memcpy_from_dmem_to_host_32(pfe_pe_t *pe, sint32 pe_count, void *dst_ptr, addr_t src_addr, uint32 buffer_len, uint32 read_len);
errno_t pfe_pe_get_fw_feature_entry(pfe_pe_t *pe, uint32 id, pfe_ct_feature_desc_t **entry);
errno_t pfe_pe_get_pe_stats_nolock(pfe_pe_t *pe, uint32 addr, pfe_ct_pe_stats_t *stats);
bool_t pfe_pe_check_stalled_nolock(pfe_pe_t *pe);
errno_t pfe_pe_get_classify_stats_nolock(pfe_pe_t *pe, uint32 addr, pfe_ct_classify_stats_t *stats);
errno_t pfe_pe_get_class_algo_stats_nolock(pfe_pe_t *pe, uint32 addr, pfe_ct_class_algo_stats_t *stats);
pfe_ct_pe_sw_state_t pfe_pe_get_fw_state(pfe_pe_t *pe);

void pfe_pe_destroy(pfe_pe_t *pe, uint32 pe_num);
errno_t pfe_pe_check_mmap(const pfe_pe_t *pe);
errno_t pfe_pe_get_fw_messages_nolock(pfe_pe_t *pe);
errno_t pfe_pe_get_data_nolock(pfe_pe_t *pe, pfe_ct_buffer_t *buf);
errno_t pfe_pe_put_data_nolock(pfe_pe_t *pe, pfe_ct_buffer_t *buf);
errno_t pfe_pe_memlock_acquire_nolock(pfe_pe_t *pe);
errno_t pfe_pe_memlock_release_nolock(pfe_pe_t *pe);
void pfe_pe_lock_family(pfe_pe_t *pe);
void pfe_pe_unlock_family(pfe_pe_t *pe);
char *pfe_pe_get_fw_feature_str_base(const pfe_pe_t *pe);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_PE_H_ */


===== 文件 [90/185]: include\pfe_phy_if.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_PHY_IF_H_
#define PUBLIC_PFE_PHY_IF_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "oal_types.h"
#include "pfe_ct.h"
#include "pfe_emac.h"
#include "pfe_mac_db.h"
#include "pfe_hif_chnl.h"
#include "pfe_class.h"
#include "pfe_mirror.h"

typedef enum
{
    PFE_PHY_IF_INVALID,
    PFE_PHY_IF_EMAC,
    PFE_PHY_IF_HIF,
    PFE_PHY_IF_UTIL
} pfe_phy_if_type_t;

typedef struct pfe_phy_if_tag pfe_phy_if_t;

#ifndef PUBLIC_PFE_LOG_IF_H_
#include "pfe_log_if.h"
#endif

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_phy_if_t *pfe_phy_if_create(pfe_class_t *class, pfe_ct_phy_if_id_t id, const char_t *name);
#ifdef PFE_CFG_PFE_MASTER
bool_t pfe_phy_if_has_log_if(pfe_phy_if_t *iface, const pfe_log_if_t *log_if);
pfe_log_if_t *pfe_phy_if_get_default_log_if(const pfe_phy_if_t *iface);
errno_t pfe_phy_if_del_log_if(pfe_phy_if_t *iface, const pfe_log_if_t *log_if);
errno_t pfe_phy_if_add_log_if(pfe_phy_if_t *iface, pfe_log_if_t *log_if);
errno_t pfe_phy_if_set_op_mode(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode);
errno_t pfe_phy_if_set_flag(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag);
errno_t pfe_phy_if_clear_flag(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag);
pfe_ct_if_flags_t pfe_phy_if_get_flag(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag);
errno_t pfe_phy_if_get_flow_control(pfe_phy_if_t *iface, bool_t* tx_ena, bool_t* rx_ena);
errno_t pfe_phy_if_set_tx_flow_control(pfe_phy_if_t *iface, bool_t tx_ena);
errno_t pfe_phy_if_set_rx_flow_control(pfe_phy_if_t *iface, bool_t rx_ena);
pfe_class_t *pfe_phy_if_get_class(const pfe_phy_if_t *iface) __attribute__((pure));
errno_t pfe_phy_if_bind_emac(pfe_phy_if_t *iface, pfe_emac_t *emac);
errno_t pfe_phy_if_bind_util(pfe_phy_if_t *iface);
errno_t pfe_phy_if_bind_hif(pfe_phy_if_t *iface, pfe_hif_chnl_t *hif);
#endif /* PFE_CFG_PFE_MASTER */
pfe_emac_t *pfe_phy_if_get_emac(const pfe_phy_if_t *iface);
pfe_hif_chnl_t *pfe_phy_if_get_hif(const pfe_phy_if_t *iface);
pfe_ct_phy_if_id_t pfe_phy_if_get_id(const pfe_phy_if_t *iface) __attribute__((pure));
pfe_phy_if_type_t pfe_phy_if_get_type(const pfe_phy_if_t *iface) __attribute__((pure));
pfe_phy_if_t *pfe_phy_if_get_phy(pfe_ct_phy_if_id_t iface_id) __attribute__((pure));
const char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface) __attribute__((pure));
void pfe_phy_if_destroy(pfe_phy_if_t *iface);
errno_t pfe_phy_if_set_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t block_state);
errno_t pfe_phy_if_get_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t *block_state);
pfe_ct_if_op_mode_t pfe_phy_if_get_op_mode(pfe_phy_if_t *iface);
bool_t pfe_phy_if_is_enabled(pfe_phy_if_t *iface);
errno_t pfe_phy_if_enable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_disable(pfe_phy_if_t *iface);
bool_t pfe_phy_if_is_promisc(pfe_phy_if_t *iface);
errno_t pfe_phy_if_loadbalance_enable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_loadbalance_disable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_promisc_enable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_promisc_disable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_loopback_enable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_loopback_disable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_allmulti_enable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_allmulti_disable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_add_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner);
errno_t pfe_phy_if_del_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner);
pfe_mac_db_t *pfe_phy_if_get_mac_db(pfe_phy_if_t *iface);
errno_t pfe_phy_if_get_mac_addr_first(pfe_phy_if_t *iface, pfe_mac_addr_t addr, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner);
errno_t pfe_phy_if_get_mac_addr_next(pfe_phy_if_t *iface, pfe_mac_addr_t addr);
errno_t pfe_phy_if_flush_mac_addrs(pfe_phy_if_t *iface, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner);
errno_t pfe_phy_if_get_stats(pfe_phy_if_t *iface, pfe_ct_phy_if_stats_t *stat);
errno_t pfe_phy_if_set_rx_mirror(pfe_phy_if_t *iface, uint32 sel, const pfe_mirror_t *mirror);
errno_t pfe_phy_if_set_tx_mirror(pfe_phy_if_t *iface, uint32 sel, const pfe_mirror_t *mirror);
pfe_mirror_t *pfe_phy_if_get_tx_mirror(const pfe_phy_if_t *iface, uint32 sel);
pfe_mirror_t *pfe_phy_if_get_rx_mirror(const pfe_phy_if_t *iface, uint32 sel);
#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_phy_if_get_text_statistics(const pfe_phy_if_t *iface, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */
uint32 pfe_phy_if_get_spd(const pfe_phy_if_t *iface);
errno_t pfe_phy_if_set_spd(pfe_phy_if_t *iface, uint32 spd_addr);
errno_t pfe_phy_if_set_ftable(pfe_phy_if_t *iface, uint32 table);
uint32 pfe_phy_if_get_ftable(pfe_phy_if_t *iface);
errno_t pfe_phy_if_set_mgmt_interface(pfe_phy_if_t *iface, pfe_ct_phy_if_id_t mgmt_interface);
pfe_ct_phy_if_id_t pfe_phy_if_get_mgmt_interface(pfe_phy_if_t *iface);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_PHY_IF_H_ */


===== 文件 [91/185]: include\pfe_platform.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef SRC_PFE_PLATFORM_H_
#define SRC_PFE_PLATFORM_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_platform_cfg.h"
#include "pfe_gpi.h"
#include "pfe_bmu.h"
#include "pfe_class.h"
#if defined(PFE_CFG_RTABLE_ENABLE)
    #include "pfe_rtable.h"
#endif /* PFE_CFG_RTABLE_ENABLE */
#include "pfe_tmu.h"
#include "pfe_util.h"
#include "pfe_hif.h"
#include "pfe_hif_nocpy.h"
#include "pfe_parity.h"
#include "pfe_emac.h"
#include "pfe_l2br_table.h"
#include "pfe_l2br.h"
#include "pfe_phy_if.h"
#include "pfe_log_if.h"
#include "pfe_if_db.h"
#include "pfe_wdt.h"
#include "pfe_bus_err.h"
#include "pfe_fw_fail_stop.h"
#include "pfe_host_fail_stop.h"
#include "pfe_fail_stop.h"
#include "pfe_ecc_err.h"
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#include "fci_ownership_mask.h"
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#define GEMAC0_MAC                      { 0x00U, 0x0AU, 0x0BU, 0x0CU, 0x0DU, 0x0EU }
#define GEMAC1_MAC                      { 0x00U, 0x1AU, 0x1BU, 0x1CU, 0x1DU, 0x1EU }
#define GEMAC2_MAC                      { 0x00U, 0x2AU, 0x2BU, 0x2CU, 0x2DU, 0x2EU }

typedef enum
{
    POLLER_STATE_DISABLED,
    POLLER_STATE_ENABLED,
    POLLER_STATE_STOPPED
} pfe_poller_state_t;

typedef struct
/*  The PFE firmware data type */
{
    char_t *version;        /* free text: version */
    char_t *source;         /* free text: filename, filepath, ... etc */
    const void *class_data; /* The CLASS fw data buffer */
    void *tmu_data;         /* The TMU fw data buffer */
    uint32 tmu_size;      /* The TMU fw data size */
    const void *util_data;  /* The UTIL fw data buffer */
} pfe_fw_t;

/*  The PFE platform config */
typedef struct
{
    addr_t cbus_base;       /* PFE control bus base address */
    addr_t cbus_len;        /* PFE control bus size */
    char_t *fw_name;        /* FW name */
    pfe_fw_t *fw;           /* Required firmware, embedded */
    bool_t common_irq_mode; /* True if FPGA specific common irq is used */
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
    uint32 irq_vector_bmu;        /* BMU IRQ number */
#endif /* PFE_CFG_BMU_IRQ_ENABLED */
    pfe_hif_chnl_id_t hif_chnls_mask; /* The bitmap list of the requested HIF channels */
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    pfe_fci_owner_hif_id_t hif_fci_owner_chnls_mask; /* The bitmap list of HIF channels that are allowed to take FCI ownership */
    pfe_ct_phy_if_id_t master_if; /* Interface where master driver is located */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
    uint32 irq_vector_hif_chnls[HIF_CFG_MAX_CHANNELS];    /* HIF channels IRQ number */
    uint32 irq_vector_hif_nocpy;  /* HIF nocopy channel IRQ number */
    uint32 irq_vector_upe_gpt; /* UPE + GPT IRQ number */
    uint32 irq_vector_safety; /* Safety IRQ number */
    bool_t enable_util;         /* Shall be UTIL enabled? */
    bool_t disable_master_detect;   /* Shall be Master-detect disabled? */
    pfe_ct_phy_if_id_t local_hif; /* ID of the local interface */
#if defined(PFE_CFG_RTABLE_ENABLE)
    uint32 rtable_hash_size;  /* Size (number of entries) of hash area within routing table */
    uint32 rtable_collision_size; /* Size (number of entries) of collision area within routing table */
#endif /* PFE_CFG_RTABLE_ENABLE */
    uint16 vlan_id;   /* VLAN ID used for L2 Bridge configuration */
    uint16 vlan_stats_size;   /*VLAN stats size(number of vlan entry) used to collect info from firmware */
    pfe_emac_mii_mode_t emac_mode[3]; /* MII mode per PFE EMAC */
    bool_t g2_ordered_class_writes; /* S32G2 ordered class writes switch */
    char_t *commit_hash; /* Driver commit hash */
    char_t *driver_version; /* PFE driver version */
} pfe_platform_config_t;

typedef struct
{
    volatile bool_t probed;
    addr_t cbus_baseaddr;
    void *bmu_buffers_va;
    addr_t bmu_buffers_size;
    void *rtable_va;
    addr_t rtable_size;
    oal_irq_t *irq_global;
    pfe_poller_state_t poller_state;
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
    oal_irq_t *irq_bmu;         /* BMU IRQ */
#endif /* PFE_CFG_BMU_IRQ_ENABLED */
    uint32 hif_chnl_count;    /* Number of HIF channels */
    pfe_hif_nocpy_t *hif_nocpy; /* The HIF_NOCPY block */
    oal_irq_t *irq_hif_nocpy;   /* HIF nocopy channel IRQ */
    uint32 emac_count;
    uint32 gpi_count;
    uint32 etgpi_count;
    uint32 hgpi_count;
    uint32 bmu_count;
    uint32 class_pe_count;
    uint32 util_pe_count;
    uint32 tmu_pe_count;
    pfe_fw_t *fw;
#if defined(PFE_CFG_RTABLE_ENABLE)
    pfe_rtable_t *rtable;
#endif /* PFE_CFG_RTABLE_ENABLE */
#if defined(PFE_CFG_L2BRIDGE_ENABLE)
    pfe_l2br_table_t *mactab;
    pfe_l2br_table_t *vlantab;
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
    pfe_l2br_t *l2_bridge;
    pfe_class_t *classifier;
    pfe_tmu_t *tmu;
    pfe_util_t *util;
    pfe_bmu_t *bmu[PFE_BMU_INSTANCES];
    pfe_gpi_t *gpi[PFE_GPI_INSTANCES];
    pfe_gpi_t *etgpi[PFE_ETGPI_INSTANCES];
    pfe_gpi_t *hgpi[PFE_HGPI_INSTANCES];
    pfe_hif_t *hif;
    pfe_emac_t *emac[PFE_EMAC_INSTANCES];
    pfe_parity_t *parity;
    pfe_wdt_t   *wdt;
    pfe_bus_err_t   *bus_err;
    pfe_fw_fail_stop_t  *fw_fail_stop;
    pfe_host_fail_stop_t    *host_fail_stop;
    pfe_fail_stop_t     *fail_stop;
    pfe_ecc_err_t   *ecc_err;
    pfe_if_db_t *phy_if_db;
#ifdef PFE_CFG_PFE_MASTER
    pfe_if_db_t *log_if_db;
#endif
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    pfe_fci_owner_hif_id_t hif_fci_owner_chnls_mask;
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
    bool_t fci_created;
    uint32 pfe_version;
} pfe_platform_t;

#ifdef PFE_CFG_PFE_MASTER
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
#define ETH_43_PFE_START_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
extern volatile bool_t bDetectBmuInit;
#define ETH_43_PFE_STOP_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_BMU_IRQ_ENABLED */
#endif /* PFE_CFG_PFE_MASTER */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_platform_init(const pfe_platform_config_t *config);
errno_t pfe_platform_soft_reset(const pfe_platform_t *platform);
errno_t pfe_platform_remove(void);
pfe_platform_t *pfe_platform_get_instance(void);
pfe_phy_if_t *pfe_platform_get_phy_if_by_id(const pfe_platform_t *platform, pfe_ct_phy_if_id_t id);
#if defined(PFE_CFG_MULTI_INSTANCE_SUPPORT)
void pfe_platform_idex_rpc_cbk(pfe_ct_phy_if_id_t sender, uint32 id, void *buf, uint16 buf_len, void *arg);
#endif
errno_t pfe_platform_get_fw_versions(const pfe_platform_t *platform, pfe_ct_version_t *class_fw, pfe_ct_version_t *util_fw);
#ifdef PFE_CFG_PFE_SLAVE
void pfe_platform_destroy_ifaces(void);
#endif
void pfe_platform_remove_sw_if(void);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* SRC_PFE_PLATFORM_H_ */


===== 文件 [92/185]: include\pfe_platform_cfg.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgrPFE_PLATFORM
 * @{
 *
 * @file        pfe_platform_cfg.h
 * @brief       The PFE platform configuration file
 * @details     This file contains HW platform-specific configuration options which are usually
 *              bounded to a given hardware implementation.
 * @note        Various variants of this file should exist for various HW platforms (please
 *              keep this file clean, not containing platform-specific preprocessor switches).
 *
 */

#ifndef SRC_PFE_PLATFORM_CFG_H_
#define SRC_PFE_PLATFORM_CFG_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_cfg.h"
#include "Eth_43_PFE.h"

#define TMU_TYPE_TMU        1U
#define TMU_TYPE_TMU_LITE   2U

/**
 * @brief   Hash value for FW API compatibility check
 */
#define PFE_CFG_PFE_CT_H_MD5        92367c0e25f21f49217a9b08168ad2c8

/**
 * @brief   Number of entries of HIF Rx ring
 * @note    Must be power of 2
 */
#define PFE_HIF_RX_RING_CFG_LENGTH ETH_43_PFE_CFG_HIF_RXBD_NUM

/**
 * @brief   Number of entries of HIF Tx ring
 * @note    Must be power of 2
 */
#define PFE_HIF_TX_RING_CFG_LENGTH ETH_43_PFE_CFG_HIF_TXBD_NUM

/*
 * @brief TMU variant
 */
#define PFE_CFG_TMU_VARIANT TMU_TYPE_TMU_LITE

/*
 * @brief   Accessible memory space base (PA)
 * @details This is PFE-accessible address space base (npu2ddr+upe2hdbus AXI masters)
 * @warning Address range given by this base and PFE_CFG_DDR_MASTER_LEN must be
 *          reserved to be exclusively accessible by PFE.
 */
#define PFE_CFG_DDR_MASTER_ADDR             0x00400000ULL   /* S32G */

/*
 * @brief   Length of the PFE DDR memory
 */
#define PFE_CFG_DDR_MASTER_LEN              0x01000000ULL   /* S32G: 16MB */

/*
 * @brief   The PFE HIF IRQ ID as seen by the host
 */
#define PFE_CFG_HIF_IRQ_ID                  204 /* HIF (copy) IRQ */

/*
 * @brief   Maximum supported number of standard HIF channels
 */
#define HIF_CFG_MAX_CHANNELS                4U


/**
 * @brief   The CLASS_PE_SYS_CLK_RATIO[csr_clmode]
 * @details See the IMG-NPU Technical Reference Manual
 */
#define PFE_CFG_CLMODE                      1U  /* SYS/AXI = 250MHz, HFE = 500MHz */

/**
 * @brief   Maximum number of buffers - BMU1
 */
#define PFE_CFG_BMU1_BUF_COUNT              0x200U

/**
 * @brief   BMU1 buffer size in Bytes
 */
#define PFE_CFG_BMU1_BUF_SIZE               256U    /* 256 bytes */

#if (STD_OFF == ETH_43_PFE_SLAVE_MODE)
    /* Not used in slave driver */
    /**
     * @brief   Maximum number of logical interfaces
     * @details This is the maximum number supported by driver. Real
     *          number is limited by amount of available DMEM.
     */
    #define PFE_CFG_MAX_LOG_IFS                 256U
    /**
     * @brief   Maximum number of buffers - BMU2
     * @details Used for Rx buffers for HIF rings (shared among all clients).
     *          Used internally to pass packets among EMACs and HIFs
     */
    #define PFE_CFG_BMU2_BUF_COUNT      ETH_43_PFE_BMU2_BUF_CNT
    /**
     * @brief   BMU2 buffer size
     * @details Value = log2(size).
     *          Used internally to pass packets among EMACs and HIFs
     */
    #define PFE_CFG_BMU2_BUF_SIZE           2048U
#endif /* ETH_43_PFE_SLAVE_MODE */

/**
 * @brief   DMEM base address as defined by .elf
 */
#define PFE_CFG_CLASS_ELF_DMEM_BASE         0x20000000UL

/**
 * @brief   Size of DMEM per CLASS PE
 */
#define PFE_CFG_CLASS_DMEM_SIZE             0x00004000UL    /* 16k */

/**
 * @brief   IMEM base address as defined by .elf
 */
#define PFE_CFG_CLASS_ELF_IMEM_BASE         0x9fc00000UL

/**
 * @brief   Size of IMEM per CLASS PE
 */
#define PFE_CFG_CLASS_IMEM_SIZE             0x00008000UL    /* 32kB */

/**
 * @brief   DMEM base address as defined by .elf
 */
#define PFE_CFG_TMU_ELF_DMEM_BASE           0x00000000UL

/**
 * @brief   Size of DMEM per TMU PE
 */
#define PFE_CFG_TMU_DMEM_SIZE               0x00000800UL    /* 2kB */

/**
 * @brief   IMEM base address as defined by .elf
 */
#define PFE_CFG_TMU_ELF_IMEM_BASE           0x00010000UL

/**
 * @brief   Size of IMEM per TMU PE
 */
#define PFE_CFG_TMU_IMEM_SIZE               0x00002000UL    /* 8kB */

/**
 * @brief   DMEM base address as defined by .elf
 */
#define PFE_CFG_UTIL_ELF_DMEM_BASE          0x00000000UL

/**
 * @brief   Size of DMEM per UTIL PE
 */
#define PFE_CFG_UTIL_DMEM_SIZE              0x00002000UL

/**
 * @brief   IMEM base address as defined by .elf
 */
#define PFE_CFG_UTIL_ELF_IMEM_BASE          PFE_CFG_CLASS_ELF_IMEM_BASE

/**
 * @brief   Size of IMEM per UTIL PE
 */
#define PFE_CFG_UTIL_IMEM_SIZE              PFE_CFG_CLASS_IMEM_SIZE

/**
 * @brief   Physical CBUS base address as seen by PFE
 */
#define PFE_CFG_CBUS_PHYS_BASE_ADDR         0xc0000000U

/**
 * @brief   Physical CBUS base address as seen by CPUs
 */
#define PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU     0x46000000U

/**
 * @brief   CBUS length
 */
#define PFE_CFG_CBUS_LENGTH                 0x01000000U

/**
 * @brief   Offset in LMEM where BMU1 buffers area starts
 */
#define PFE_CFG_BMU1_LMEM_BASEADDR          0U

/**
 * @brief   Size of BMU1 buffers area in number of bytes
 */
#define PFE_CFG_BMU1_LMEM_SIZE              (PFE_CFG_BMU1_BUF_SIZE * PFE_CFG_BMU1_BUF_COUNT)

/**
 * @brief   Offset in LMEM, where PE memory area starts
 */
#define PFE_CFG_PE_LMEM_BASE                (PFE_CFG_BMU1_LMEM_BASEADDR + PFE_CFG_BMU1_LMEM_SIZE)

/**
 * @brief   Size of PE memory area in number of bytes
 */
#define PFE_CFG_PE_LMEM_SIZE                (CBUS_LMEM_SIZE - PFE_CFG_BMU1_LMEM_SIZE)

/**
 * @brief   Translates from host CPU physical address space to PFE address space
 */
#define PFE_CFG_MEMORY_PHYS_TO_PFE(p)       (p)

/**
 * @brief   Translates from PFE address space to host CPU physical address space
 */
#define PFE_CFG_MEMORY_PFE_TO_PHYS(p)       (p)

/* LMEM defines */
#define PFE_CFG_LMEM_BUF_SIZE_LN2           0x8U /*256*/
#define PFE_CFG_LMEM_BUF_SIZE               (1UL << PFE_CFG_LMEM_BUF_SIZE_LN2)

/* DDR defines */
#define PFE_CFG_DDR_HDR_SIZE                0x0200UL
#define PFE_CFG_DDR_BUF_SIZE_LN2            0xbU /*2048*/
#define PFE_CFG_DDR_BUF_SIZE                (1UL << PFE_CFG_DDR_BUF_SIZE_LN2)

/* RO defines */
#define PFE_CFG_RO_HDR_SIZE                 0x0010UL

/* Maximal count of entries within hash area of routing table */
#define PFE_CFG_RT_HASH_ENTRIES_MAX_CNT 1048576U

/**
 * @brief   Local physical interface identifier
 * @details In multi-instance environment, where multiple platform drivers
 *          can be deployed, this identifier represents the physical interface
 *          (usually HIF channel) associated with the current driver instance.
 */
#if (TRUE == ETH_43_PFE_USE_MULTIPLE_HIFS)
    #define PFE_CFG_LOCAL_IF                ETH_43_PFE_CFG_CTRLHIF(0U)/* Use any of own HIFs */
#else
    #define PFE_CFG_LOCAL_IF                ETH_43_PFE_COMMON_HIF
#endif

#if (TRUE == ETH_43_PFE_USE_MULTIPLE_HIFS)
/*  Needed by ETH_43_PFE_CFG_CTRLHIF(0U), which is LT/PB configurable.
    Must be here (end of file) to avoid a cyclic include dependency. */
    #include "Eth_PFE_LLD.h"
#endif

/* max PEs count in CLASSIFIER */
#define PFE_CLASS_PE_COUNT 8U

#endif /* SRC_PFE_PLATFORM_CFG_H_ */

/** @}*/


===== 文件 [93/185]: include\pfe_platform_rpc.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef SRC_PFE_PLATFORM_RPC_H_
#define SRC_PFE_PLATFORM_RPC_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "oal.h"
#include "pfe_ct.h"

#ifdef PFE_CFG_FCI_ENABLE
#include "fci_msg.h"
#endif /* PFE_CFG_FCI_ENABLE */

typedef uint64 pfe_platform_rpc_ptr_t;

ct_assert(sizeof(pfe_platform_rpc_ptr_t) == sizeof(uint64));

typedef enum __attribute__((packed))
{
    PFE_PLATFORM_RPC_PFE_PHY_IF_CREATE = 100U,              /* Arg: pfe_platform_rpc_pfe_phy_if_create_arg_t, Ret: None */
    /* All following PHY_IF commands have first arg struct member phy_if_id */
    PFE_PLATFORM_RPC_PFE_PHY_IF_ENABLE = 101U,              /* Arg: pfe_platform_rpc_pfe_phy_if_enable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_ID_COMPATIBLE_FIRST = PFE_PLATFORM_RPC_PFE_PHY_IF_ENABLE, /* first entry compatible with generic phy_if structure for args*/
    PFE_PLATFORM_RPC_PFE_PHY_IF_DISABLE = 102U,             /* Arg: pfe_platform_rpc_pfe_phy_if_disable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_ENABLE = 103U,      /* Arg: pfe_platform_rpc_pfe_phy_if_promisc_enable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_DISABLE = 104U,     /* Arg: pfe_platform_rpc_pfe_phy_if_promisc_disable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_ADD_MAC_ADDR = 105U,            /* Arg: pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_DEL_MAC_ADDR = 106U,            /* Arg: pfe_platform_rpc_pfe_phy_if_del_mac_addr_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_GET_OP_MODE = 109U,         /* Arg: pfe_platform_rpc_pfe_phy_if_get_op_mode_arg_t, Ret: pfe_platform_rpc_pfe_phy_if_get_op_mode_ret_t */
    PFE_PLATFORM_RPC_PFE_PHY_IF_IS_ENABLED = 110U,          /* Arg: pfe_platform_rpc_pfe_phy_if_is_enabled_arg_t, Ret: pfe_platform_rpc_pfe_phy_if_is_enabled_ret_t */
    PFE_PLATFORM_RPC_PFE_PHY_IF_IS_PROMISC = 111U,          /* Arg: pfe_platform_rpc_pfe_phy_if_is_promisc_arg_t, Ret: pfe_platform_rpc_pfe_phy_if_is_promisc_ret_t */
    PFE_PLATFORM_RPC_PFE_PHY_IF_STATS = 112U,               /* Arg: pfe_platform_rpc_pfe_phy_if_stats_arg_t, Ret: pfe_platform_rpc_pfe_phy_if_stats_ret_t */
    PFE_PLATFORM_RPC_PFE_PHY_IF_FLUSH_MAC_ADDRS = 113U,     /* Arg: pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_ENABLE = 114U,     /* Arg: pfe_platform_rpc_pfe_phy_if_allmulti_enable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_DISABLE = 115U,        /* Arg: pfe_platform_rpc_pfe_phy_if_allmulti_disable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_ENABLE = 116U,             /* Arg: pfe_platform_rpc_pfe_phy_if_loopback_enable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_DISABLE = 117U,            /* Arg: pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE = 118U,          /* Arg: pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE = 119U,         /* Arg: pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE = 120U,             /* Arg: pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t, Ret: None */
    PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE = 121U,             /* Arg: pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t, Ret: pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t */
    PFE_PLATFORM_RPC_PFE_PHY_IF_ID_COMPATIBLE_LAST = PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE, /* last entry compatible with generic phy_if structure for args*/
    PFE_PLATFORM_RPC_PFE_PHY_IF_GET_STAT_VALUE = 122U,              /* Arg: pfe_platform_rpc_pfe_phy_if_get_stat_value_arg_t, Ret: pfe_platform_rpc_pfe_phy_if_get_stat_value_ret_t */

    /* Lock for atomic operations */
    PFE_PLATFORM_RPC_PFE_IF_LOCK = 190U,                        /* Arg: None, Ret: None */
    PFE_PLATFORM_RPC_PFE_IF_UNLOCK = 191U,                  /* Arg: None, Ret: None */

#if defined(PFE_CFG_FCI_ENABLE)
    PFE_PLATFORM_RPC_PFE_FCI_PROXY = 300U,                  /* Arg: pfe_platform_rpc_pfe_fci_proxy_arg_t, Ret: pfe_platform_rpc_pfe_fci_proxy_ret_t */
#endif /* PFE_CFG_FCI_ENABLE */

    PFE_PLATFORM_RPC_MDIO_PROXY = 310U                      /* Arg: pfe_platform_rpc_mdio_proxy_arg_t, Ret: pfe_platform_rpc_mdio_proxy_ret_t */
} pfe_platform_rpc_code_t;

/* Generic phy if type */
typedef struct __attribute__((packed, aligned(4)))
{
    uint8 phy_if_id;
} pfe_platform_rpc_pfe_phy_if_generic_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_generic_t, phy_if_id));

typedef struct __attribute__((packed, aligned(4)))
{
    /*  Physical interface ID */
    pfe_ct_phy_if_id_t phy_if_id;
} pfe_platform_rpc_pfe_phy_if_create_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_create_arg_t, phy_if_id));

typedef struct __attribute__((packed, aligned(4)))
{
    /*  Boolean status */
    bool_t status;
} pfe_platform_rpc_pfe_phy_if_is_promisc_ret_t;

typedef pfe_platform_rpc_pfe_phy_if_is_promisc_ret_t pfe_platform_rpc_pfe_phy_if_is_enabled_ret_t;

typedef struct __attribute__((packed, aligned(4)))
{
    /*  Physical interface ID */
    pfe_ct_phy_if_id_t phy_if_id;
} pfe_platform_rpc_pfe_phy_if_enable_arg_t;

typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_disable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_disable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_promisc_enable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_promisc_enable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_promisc_disable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_promisc_disable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_generic_t pfe_platform_rpc_pfe_phy_if_get_op_mode_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_get_op_mode_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_generic_t pfe_platform_rpc_pfe_phy_if_is_promisc_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_is_promisc_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_generic_t pfe_platform_rpc_pfe_phy_if_is_enabled_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_is_enabled_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_generic_t pfe_platform_rpc_pfe_phy_if_stats_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_stats_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_allmulti_enable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_allmulti_enable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_allmulti_disable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_allmulti_disable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loopback_enable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loopback_enable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_enable_arg_t pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t, phy_if_id));
typedef pfe_platform_rpc_pfe_phy_if_generic_t pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t, phy_if_id));

typedef struct __attribute__((packed, aligned(4)))
{
    pfe_ct_phy_if_id_t phy_if_id;
    pfe_mac_db_crit_t crit;
    pfe_mac_type_t type;
} pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t, phy_if_id));

typedef struct __attribute__((packed, aligned(4)))
{
    /*  Physical interface ID */
    pfe_ct_phy_if_id_t phy_if_id;
    /*  MAC address */
    uint8 mac_addr[6];
} pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t, phy_if_id));

typedef pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t pfe_platform_rpc_pfe_phy_if_del_mac_addr_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_del_mac_addr_arg_t, phy_if_id));

typedef struct __attribute__((packed, aligned(4)))
{
    /* Physical interface ID */
    pfe_ct_phy_if_id_t phy_if_id;
    /* Block state */
    pfe_ct_block_state_t block_state;
} pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t, phy_if_id));

typedef struct __attribute__((packed, aligned(4)))
{
    /*  Current operation mode */
    pfe_ct_if_op_mode_t mode;
} pfe_platform_rpc_pfe_phy_if_get_op_mode_ret_t;

typedef struct __attribute__((packed, aligned(4)))
{
    /* Current block state */
    pfe_ct_block_state_t state;
} pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t;

typedef struct __attribute__((packed, aligned(4)))
{
    /*  Current phy if statistics */
    pfe_ct_phy_if_stats_t stats;
}pfe_platform_rpc_pfe_phy_if_stats_ret_t;

typedef struct __attribute__((packed, aligned(4)))
{
    /*  statistic value */
    uint32 stat_val;
} pfe_platform_rpc_pfe_phy_if_get_stat_value_ret_t;

typedef struct __attribute__((packed, aligned(4)))
{
    pfe_ct_phy_if_id_t phy_if_id;
    uint32 stat_id;
} pfe_platform_rpc_pfe_phy_if_get_stat_value_arg_t;
ct_assert_offsetof(0U == offsetof(pfe_platform_rpc_pfe_phy_if_get_stat_value_arg_t, phy_if_id));

#if defined(PFE_CFG_FCI_ENABLE)
typedef struct __attribute__((packed, aligned(4)))
{
    /*  FCI message type */
    msg_type_t type;
    /*  FCI command data */
    fci_msg_cmd_t msg_cmd;
} pfe_platform_rpc_pfe_fci_proxy_arg_t;

typedef struct __attribute__((packed, aligned(4)))
{
    /*  FCI reply data */
    fci_msg_cmd_t msg_cmd;
} pfe_platform_rpc_pfe_fci_proxy_ret_t;

#endif /* PFE_CFG_FCI_ENABLE */

/* MDIO proxy RPC operation type */
typedef enum __attribute__((packed))
{
    /* MDIO READ operation, Clause 22 */
    PFE_PLATFORM_RPC_MDIO_OP_READ_CL22 = 101U,
    /* MDIO WRITE operation, Clause 22 */
    PFE_PLATFORM_RPC_MDIO_OP_WRITE_CL22 = 102U,
    /* MDIO READ operation, Clause 45 */
    PFE_PLATFORM_RPC_MDIO_OP_READ_CL45 = 103U,
    /* MDIO WRITE operation, Clause 45 */
    PFE_PLATFORM_RPC_MDIO_OP_WRITE_CL45 = 104U
} pfe_platform_rpc_mdio_proxy_op_t;

/* MDIO proxy operation argument structure */
typedef struct __attribute__((packed, aligned(4)))
{
    /* PFE EMAC id */
    uint8 emac_id;
    /* Supported MDIO operation */
    pfe_platform_rpc_mdio_proxy_op_t op;
    /* MDIO Device Port Address: 0-31U */
    uint8 pa;
    /* MDIO Device Device Address: 0-31U */
    uint8 dev;
    /* MDIO Device Register Address: 0-65535U */
    uint16 ra;
    /* Value for WRITE operations */
    uint16 val;
} pfe_platform_rpc_mdio_proxy_arg_t;

/* Data returned by MDIO proxy READ operations */
typedef struct __attribute__((packed, aligned(4)))
{
    uint16 val;
} pfe_platform_rpc_mdio_proxy_ret_t;

#endif /* SRC_PFE_PLATFORM_RPC_H_ */


===== 文件 [94/185]: include\pfe_rtable.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_RTABLE_H_
#define PUBLIC_PFE_RTABLE_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_emac.h" /* pfe_mac_addr_t */
#include "pfe_class.h"
#include "pfe_l2br.h"
#include "pfe_phy_if.h" /* pfe_interface_t */

/**
 * @brief   Tick period for internal timer in seconds
 * @details The timer is used to sample the active routing table entries and decrement
 *          associated time-out values when entries are not being used by the firmware.
 */
#define PFE_RTABLE_CFG_TICK_PERIOD_SEC          1U

typedef struct pfe_rtable_tag pfe_rtable_t;
typedef struct pfe_rtable_entry_tag pfe_rtable_entry_t;

typedef struct
{
    union
    {
        uint8 v4[4];
    } v4;

    union
    {
        uint16 v6[8];
    } v6;

    bool_t is_ipv4;
} pfe_ip_addr_t;

typedef struct
{
    addr_t htable_base_va;              /*htable address*/
    addr_t pool_base_va;                /*pool address*/
    uint32 htable_size;               /*htable size*/
    uint32 pool_size;                 /*pool size*/
} pfe_class_table_sizes_t;


/**
 * @brief   5-tuple representation type
 */
typedef struct
{
    pfe_ip_addr_t src_ip;   /*!< Source IP address */
    pfe_ip_addr_t dst_ip;   /*!< Destination IP address */
    uint16 sport;         /*!< Source L4 port number */
    uint16 dport;         /*!< Destination L4 port number */
    uint8 proto;          /*!< Protocol identifier */
} pfe_5_tuple_t;

/**
 * @brief   Routing table select criteria type
 */
typedef enum
{
    RTABLE_CRIT_ALL,                /*!< Match any entry in the routing table. The get_first() argument is NULL. */
    RTABLE_CRIT_ALL_IPV4,           /*!< Match any entry in the routing table. The get_first() argument is NULL. */
    RTABLE_CRIT_ALL_IPV6,           /*!< Match any entry in the routing table. The get_first() argument is NULL. */
    RTABLE_CRIT_BY_DST_IF,          /*!< Match entries by destination interface. The get_first() argument is (pfe_interface_t *). */
    RTABLE_CRIT_BY_ROUTE_ID,        /*!< Match entries by route ID. The get_first() argument is (uint32 *). */
    RTABLE_CRIT_BY_5_TUPLE,         /*!< Match entries by 5-tuple. The get_first() argument is (pfe_5_tuple_t *). */
    RTABLE_CRIT_BY_ID5T,            /*!< Match entries by unique 5-tuple ID */
} pfe_rtable_get_criterion_t;

/**
 * @brief   Callback type
 * @details During entry addition one can specify a callback to be called when an entry
 *          related event occur. This is prototype of the callback.
 * @see     pfe_rtable_add_entry
 */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_rtable_t *pfe_rtable_create(pfe_class_t *class, pfe_l2br_t *bridge, pfe_class_table_sizes_t table_params);
errno_t pfe_rtable_add_entry(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
errno_t pfe_rtable_del_entry(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
void pfe_rtable_destroy(pfe_rtable_t *rtable);
uint32 pfe_rtable_get_entry_size(void);
errno_t pfe_rtable_entry_to_5t(const pfe_rtable_entry_t *entry, pfe_5_tuple_t *tuple);
errno_t pfe_rtable_entry_to_5t_out(const pfe_rtable_entry_t *entry, pfe_5_tuple_t *tuple);
pfe_rtable_entry_t *pfe_rtable_get_first(pfe_rtable_t *rtable, pfe_rtable_get_criterion_t crit, void *arg);
pfe_rtable_entry_t *pfe_rtable_get_next(pfe_rtable_t *rtable);
uint32 pfe_rtable_get_size(const pfe_rtable_t *rtable);

void pfe_rtable_entry_set_ttl_decrement(pfe_rtable_entry_t *entry);
void pfe_rtable_entry_remove_ttl_decrement(pfe_rtable_entry_t *entry);
pfe_rtable_entry_t *pfe_rtable_entry_create(void);
void pfe_rtable_entry_free(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
errno_t pfe_rtable_entry_set_5t(pfe_rtable_entry_t *entry, const pfe_5_tuple_t *tuple);
errno_t pfe_rtable_entry_set_sip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *ip_addr);
void pfe_rtable_entry_get_sip(pfe_rtable_entry_t *entry, pfe_ip_addr_t *ip_addr);
errno_t pfe_rtable_entry_set_out_sip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *output_sip);
errno_t pfe_rtable_entry_set_dip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *ip_addr);
void pfe_rtable_entry_get_dip(pfe_rtable_entry_t *entry, pfe_ip_addr_t *ip_addr);
errno_t pfe_rtable_entry_set_out_dip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *output_dip);
void pfe_rtable_entry_set_sport(pfe_rtable_entry_t *entry, uint16 sport);
uint16 pfe_rtable_entry_get_sport(const pfe_rtable_entry_t *entry);
void pfe_rtable_entry_set_out_sport(const pfe_rtable_entry_t *entry, uint16 output_sport);
void pfe_rtable_entry_set_dport(pfe_rtable_entry_t *entry, uint16 dport);
uint16 pfe_rtable_entry_get_dport(const pfe_rtable_entry_t *entry);
void pfe_rtable_entry_set_out_dport(pfe_rtable_entry_t *entry, uint16 output_dport);
void pfe_rtable_entry_set_proto(pfe_rtable_entry_t *entry, uint8 proto);
uint8 pfe_rtable_entry_get_proto(const pfe_rtable_entry_t *entry);
errno_t pfe_rtable_entry_set_dstif(pfe_rtable_entry_t *entry, const pfe_phy_if_t *iface);
void pfe_rtable_entry_set_out_mac_addrs(pfe_rtable_entry_t *entry,const pfe_mac_addr_t smac,const pfe_mac_addr_t dmac);
void pfe_rtable_entry_set_out_vlan(pfe_rtable_entry_t *entry, uint16 vlan, bool_t replace);
uint16 pfe_rtable_entry_get_out_vlan(const pfe_rtable_entry_t *entry);
pfe_ct_route_actions_t pfe_rtable_entry_get_action_flags(pfe_rtable_entry_t *entry);
void pfe_rtable_entry_set_timeout(pfe_rtable_entry_t *entry, uint32 timeout);
void pfe_rtable_entry_set_route_id(pfe_rtable_entry_t *entry, uint32 route_id);
errno_t pfe_rtable_entry_get_route_id(const pfe_rtable_entry_t *entry, uint32 *route_id);
void pfe_rtable_entry_set_refptr(pfe_rtable_entry_t *entry, void *refptr);
void *pfe_rtable_entry_get_refptr(pfe_rtable_entry_t *entry);
void pfe_rtable_entry_set_child(pfe_rtable_entry_t *entry, pfe_rtable_entry_t *child);
pfe_rtable_entry_t *pfe_rtable_entry_get_child_nolock(const pfe_rtable_entry_t *entry);
pfe_rtable_entry_t *pfe_rtable_entry_get_child(pfe_rtable_t *rtable, const pfe_rtable_entry_t *entry);
uint8 pfe_rtable_entry_get_stats_index(const pfe_rtable_entry_t *entry);

void pfe_rtable_entry_set_id5t(pfe_rtable_entry_t *entry, uint32 id5t);
errno_t pfe_rtable_entry_get_id5t(const pfe_rtable_entry_t *entry, uint32 *id5t);
errno_t pfe_rtable_entry_set_dstif_id(pfe_rtable_entry_t *entry, pfe_ct_phy_if_id_t if_id);

void pfe_rtable_do_timeouts(pfe_rtable_t *rtable);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_rtable_get_text_statistics(const pfe_rtable_t *rtable, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

errno_t pfe_rtable_get_stats(const pfe_rtable_t *rtable, pfe_ct_conntrack_stats_t *stat, uint8 conntrack_index);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_RTABLE_H_ */


===== 文件 [95/185]: include\pfe_tmu.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_TMU_H_
#define PFE_TMU_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_class.h"

#define PFE_TMU_INVALID_QUEUE       255U
#define PFE_TMU_INVALID_SCHEDULER   255U
#define PFE_TMU_INVALID_SHAPER      255U
#define PFE_TMU_INVALID_POSITION    255U

#define PFE_TMU_ERR051211_Q_OFFSET  (40U + 1U)  /* (S2+S3+8 +1) See ERR051211 errata ; extra '+1' compensates for the fact that HIF BD Rings have one permanently disabled 'terminator' BD. */
#define PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH   ((PFE_TMU_ERR051211_Q_OFFSET) + 2U) /* See ERR051211 errata ; extra '+2' is for two theoretical minimalistic HIF queues (each with one slot). */

/**
 * @brief   Scheduler disciplines
 */
typedef enum __attribute__((packed))
{
    SCHED_ALGO_PQ,      /*!< Priority Queuing */
    SCHED_ALGO_DWRR,    /*!< Deficit Weighted Round Robin */
    SCHED_ALGO_RR,      /*!< Round Robin */
    SCHED_ALGO_WRR,     /*!< Weighted Round Robin */
    SCHED_ALGO_INVALID
} pfe_tmu_sched_algo_t;

/**
 * @brief   Scheduler/Shaper rate modes
 */
typedef enum __attribute__((packed))
{
    RATE_MODE_DATA_RATE = 0,    /*!< Data rate */
    RATE_MODE_PACKET_RATE = 1,  /*!< Packet rate */
    RATE_MODE_INVALID
} pfe_tmu_rate_mode_t;

/**
 * @brief   Queue modes
 */
typedef enum __attribute__((packed))
{
    /*  Queue in tail drop mode will drop packets if fill level will exceed the 'max' value. */
    TMU_Q_MODE_TAIL_DROP,
    /*  WRED will create probability zones between 'min' and 'max' values. When fill level
        is reaching a zone, packets will be dropped as defined by probability defined by
        the zone. Drop probability below 'min' is 0%, above 'max' is 100%. */
    TMU_Q_MODE_WRED,
    /*  Default mode (turns off previous modes) */
    TMU_Q_MODE_DEFAULT,
    /*  Invalid queue mode */
    TMU_Q_MODE_INVALID
} pfe_tmu_queue_mode_t;

typedef struct pfe_tmu_tag pfe_tmu_t;
typedef struct pfe_tmu_phy_cfg_tag pfe_tmu_phy_cfg_t;

typedef struct
{
    uint32 pe_sys_clk_ratio;      /*  Clock mode ratio for sys_clk and pe_clk */
    bool_t on_g3;
} pfe_tmu_cfg_t;

typedef struct
{
    uint32 revision;
    uint32 version;
    uint32 id;
}pfe_tmu_stats_special_t;


typedef struct
{
    uint32 level;         /* Fill level*/
    uint32 drops;         /*Number of droped packets*/
    uint32 tx;            /*Transmitted packets*/
    uint32 mode;          /*< Queue mode:
                            0 == Disabled. Queue will drop all packets.
                            1 == Default. HW implementation-specific. Normally not used.
                            2 == Tail drop
                            3 == WRED */

    uint32 min;       /*< Minimum threshold. Value is specific for mode:
                            - Disabled, Default: n/a
                            - Tail drop: n/a
                            - WRED: Threshold in number of packets in the queue at which
                                    the WRED lowest drop probability zone starts.
                                    While the queue fill level is below this threshold,
                                    the drop probability is 0%. */

    uint32 max;       /*< Maximum threshold. Value is specific for mode:
                            - Disabled, Default: n/a
                            - Tail drop: The queue length in number of packets. Queue length
                                         is the number of packets the queue can accommodate
                                         before drops will occur.
                            - WRED: Threshold in number of packets in the queue at which
                                    the WRED highest drop probability zone ends.
                                    While the queue fill level is above this threshold,
                                    the drop probability is 100%. */

    uint8 zprob[32];  /*< WRED drop probabilities for all probability zones in [%].
                            The lowest probability zone is zprob[0]. Only valid for
                            mode = WRED. Value 255 means 'invalid'. Number of zones
                            per queue is implementation-specific. See Egress QoS. */
}pfe_tmu_queue_stats;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_tmu_check_queue(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue);
errno_t pfe_tmu_queue_get_fill_level(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *level);
errno_t pfe_tmu_queue_get_drop_count(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt);
errno_t pfe_tmu_queue_get_tx_count(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt);
errno_t pfe_tmu_queue_set_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, pfe_tmu_queue_mode_t mode, uint32 min, uint32 max);
pfe_tmu_queue_mode_t pfe_tmu_queue_get_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *min, uint32 *max);
errno_t pfe_tmu_queue_set_wred_prob(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 prob);
errno_t pfe_tmu_queue_get_wred_prob(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 *prob);
uint8 pfe_tmu_queue_get_wred_zones(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue);
uint8 pfe_tmu_queue_get_cnt(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy);
errno_t pfe_tmu_queue_reset_tail_drop_policy(const pfe_tmu_t *tmu);
errno_t pfe_tmu_queue_err051211_sync(const pfe_tmu_t *tmu);

errno_t pfe_tmu_check_shaper(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_enable(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_disable(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_set_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, pfe_tmu_rate_mode_t mode);
pfe_tmu_rate_mode_t pfe_tmu_shp_get_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_set_idle_slope(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, uint32 isl);
uint32 pfe_tmu_shp_get_idle_slope(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_set_limits(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, sint32 max_credit, sint32 min_credit);
errno_t pfe_tmu_shp_get_limits(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, sint32 *max_credit, sint32 *min_credit);
errno_t pfe_tmu_shp_set_position(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, uint8 pos);
uint8 pfe_tmu_shp_get_position(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp);

errno_t pfe_tmu_check_scheduler(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch);
errno_t pfe_tmu_sch_set_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, pfe_tmu_rate_mode_t mode);
pfe_tmu_rate_mode_t pfe_tmu_sch_get_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch);
errno_t pfe_tmu_sch_set_algo(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, pfe_tmu_sched_algo_t algo);
pfe_tmu_sched_algo_t pfe_tmu_sch_get_algo(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch);
uint8 pfe_tmu_sch_get_input_cnt(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch);
errno_t pfe_tmu_sch_set_input_weight(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input, uint32 weight);
uint32 pfe_tmu_sch_get_input_weight(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input);
errno_t pfe_tmu_sch_bind_queue(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input, uint8 queue);
uint8 pfe_tmu_sch_get_bound_queue(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input);
errno_t pfe_tmu_sch_bind_sch_output(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 src_sch, uint8 dst_sch, uint8 input);
uint8 pfe_tmu_sch_get_bound_sch_output(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input);

pfe_tmu_t *pfe_tmu_create(addr_t cbus_base_va, uint32 pe_num, const pfe_tmu_cfg_t *cfg, pfe_class_t *class);
void pfe_tmu_enable(const pfe_tmu_t *tmu);
void pfe_tmu_reset(const pfe_tmu_t *tmu);
void pfe_tmu_disable(const pfe_tmu_t *tmu);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_tmu_get_text_statistics(const pfe_tmu_t *tmu, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

errno_t pfe_tmu_get_special_stats(const pfe_tmu_t* tmu, pfe_tmu_stats_special_t* special_stats);
uint32 pfe_tmu_get_stat_value(const pfe_tmu_t* tmu, uint32 stat_id);
errno_t pfe_tmu_get_queue_stats(const pfe_tmu_t* tmu, uint32 phy_id, uint32 queue_id, pfe_tmu_queue_stats* queue_stats);

void pfe_tmu_destroy(const pfe_tmu_t *tmu);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_TMU_H_ */


===== 文件 [96/185]: include\pfe_tmu_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef TMU_CSR_H_
#define TMU_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#include "pfe_ct.h"

#define TMU_VERSION                 (CBUS_TMU_CSR_BASE_ADDR + 0x000U)
#define TMU_INQ_WATERMARK           (CBUS_TMU_CSR_BASE_ADDR + 0x004U)
#define TMU_PHY_INQ_PKTPTR          (CBUS_TMU_CSR_BASE_ADDR + 0x008U)
#define TMU_PHY_INQ_PKTINFO         (CBUS_TMU_CSR_BASE_ADDR + 0x00cU)
#define TMU_PHY_INQ_STAT            (CBUS_TMU_CSR_BASE_ADDR + 0x010U)
#define TMU_PHY_QUEUE_SEL           (CBUS_TMU_CSR_BASE_ADDR + 0x014U)
#define TMU_CURQ_PTR                (CBUS_TMU_CSR_BASE_ADDR + 0x018U)
#define TMU_CURQ_PKT_CNT            (CBUS_TMU_CSR_BASE_ADDR + 0x01cU)
#define TMU_CURQ_DROP_CNT           (CBUS_TMU_CSR_BASE_ADDR + 0x020U)
#define TMU_CURQ_TRANS_CNT          (CBUS_TMU_CSR_BASE_ADDR + 0x024U)
#define TMU_CURQ_QSTAT              (CBUS_TMU_CSR_BASE_ADDR + 0x028U)
#define TMU_HW_PROB_CFG_TBL0        (CBUS_TMU_CSR_BASE_ADDR + 0x02cU)
#define TMU_HW_PROB_CFG_TBL1        (CBUS_TMU_CSR_BASE_ADDR + 0x030U)
#define TMU_CURQ_DEBUG              (CBUS_TMU_CSR_BASE_ADDR + 0x034U)
#define TMU_CTRL                    (CBUS_TMU_CSR_BASE_ADDR + 0x038U)
#define TMU_BMU_INQ_ADDR            (CBUS_TMU_CSR_BASE_ADDR + 0x03cU)
#define TMU_AFULL_THRES             (CBUS_TMU_CSR_BASE_ADDR + 0x040U)
#define TMU_BMU_BUF_SIZE            (CBUS_TMU_CSR_BASE_ADDR + 0x044U)
#define TMU_MAX_BUF_CNT             (CBUS_TMU_CSR_BASE_ADDR + 0x048U)
#define TMU_TEQ_CTRL                (CBUS_TMU_CSR_BASE_ADDR + 0x04cU)
#define TMU_BMU2_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x050U)
#define TMU_DDR_DATA_OFFSET         (CBUS_TMU_CSR_BASE_ADDR + 0x054U)
#define TMU_LMEM_BUF_SIZE           (CBUS_TMU_CSR_BASE_ADDR + 0x058U)
#define TMU_LMEM_DATA_OFFSET        (CBUS_TMU_CSR_BASE_ADDR + 0x05cU)
#define TMU_LMEM_BASE_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x060U)

#define TMU_PHY0_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x064U)
#define TMU_PHY1_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x068U)
#define TMU_PHY2_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x06cU)
#define TMU_PHY3_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x070U)
#define TMU_PHY4_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x074U)
#define TMU_PHY5_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x078U)
#define TMU_PHY6_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x07cU)
#define TMU_PHY7_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x080U)
#define TMU_PHY8_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x084U)
#define TMU_PHY9_INQ_ADDR           (CBUS_TMU_CSR_BASE_ADDR + 0x088U)
#define TMU_PHY10_INQ_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x08cU)
#define TMU_PHY11_INQ_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x090U)
#define TMU_PHY12_INQ_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x094U)
#define TMU_PHY13_INQ_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x098U)
#define TMU_PHY14_INQ_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x09cU)
#define TMU_PHY15_INQ_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x0a0U)
#define TMU_PHY16_INQ_ADDR          (CBUS_TMU_CSR_BASE_ADDR + 0x0a4U)
#define TMU_PHYn_INQ_ADDR(n)        (TMU_PHY0_INQ_ADDR + ((n) * 4U)

#define TMU_PHY0_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0acU)
#define TMU_PHY1_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0b0U)
#define TMU_PHY2_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0b4U)
#define TMU_PHY3_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0b8U)
#define TMU_PHY4_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0bcU)
#define TMU_PHY5_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0c0U)
#define TMU_PHY6_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0c4U)
#define TMU_PHY7_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0c8U)
#define TMU_PHY8_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0ccU)
#define TMU_PHY9_TDQ_IIFG_CFG       (CBUS_TMU_CSR_BASE_ADDR + 0x0d0U)
#define TMU_PHY10_TDQ_IIFG_CFG      (CBUS_TMU_CSR_BASE_ADDR + 0x0d4U)
#define TMU_PHY11_TDQ_IIFG_CFG      (CBUS_TMU_CSR_BASE_ADDR + 0x0d8U)
#define TMU_PHY12_TDQ_IIFG_CFG      (CBUS_TMU_CSR_BASE_ADDR + 0x0dcU)
#define TMU_PHY13_TDQ_IIFG_CFG      (CBUS_TMU_CSR_BASE_ADDR + 0x0e0U)
#define TMU_PHY14_TDQ_IIFG_CFG      (CBUS_TMU_CSR_BASE_ADDR + 0x0e4U)
#define TMU_PHY15_TDQ_IIFG_CFG      (CBUS_TMU_CSR_BASE_ADDR + 0x0e8U)
#define TMU_PHY16_TDQ_IIFG_CFG      (CBUS_TMU_CSR_BASE_ADDR + 0x0ecU)

#define TMU_PHY0_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x0f0U)
#define TMU_PHY1_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x0f4U)
#define TMU_PHY2_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x0f8U)
#define TMU_PHY3_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x0fcU)
#define TMU_PHY4_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x100U)
#define TMU_PHY5_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x104U)
#define TMU_PHY6_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x108U)
#define TMU_PHY7_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x10cU)
#define TMU_PHY8_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x110U)
#define TMU_PHY9_TDQ_CTRL           (CBUS_TMU_CSR_BASE_ADDR + 0x114U)
#define TMU_PHY10_TDQ_CTRL          (CBUS_TMU_CSR_BASE_ADDR + 0x118U)
#define TMU_PHY11_TDQ_CTRL          (CBUS_TMU_CSR_BASE_ADDR + 0x11cU)
#define TMU_PHY12_TDQ_CTRL          (CBUS_TMU_CSR_BASE_ADDR + 0x120U)
#define TMU_PHY13_TDQ_CTRL          (CBUS_TMU_CSR_BASE_ADDR + 0x124U)
#define TMU_PHY14_TDQ_CTRL          (CBUS_TMU_CSR_BASE_ADDR + 0x128U)
#define TMU_PHY15_TDQ_CTRL          (CBUS_TMU_CSR_BASE_ADDR + 0x12cU)
#define TMU_PHY16_TDQ_CTRL          (CBUS_TMU_CSR_BASE_ADDR + 0x130U)

#define TMU_CNTX_ACCESS_CTRL        (CBUS_TMU_CSR_BASE_ADDR + 0x134U)
#define TMU_CNTX_ADDR               (CBUS_TMU_CSR_BASE_ADDR + 0x138U)
#define TMU_CNTX_DATA               (CBUS_TMU_CSR_BASE_ADDR + 0x13cU)
#define TMU_CNTX_CMD                (CBUS_TMU_CSR_BASE_ADDR + 0x140U)

#define TMU_DBG_BUS_TOP             (CBUS_TMU_CSR_BASE_ADDR + 0x144U)
#define TMU_DBG_BUS_PP0             (CBUS_TMU_CSR_BASE_ADDR + 0x148U)
#define TMU_DBG_BUS_PP1             (CBUS_TMU_CSR_BASE_ADDR + 0x14cU)
#define TMU_DBG_BUS_PP2             (CBUS_TMU_CSR_BASE_ADDR + 0x150U)
#define TMU_DBG_BUS_PP3             (CBUS_TMU_CSR_BASE_ADDR + 0x154U)
#define TMU_DBG_BUS_PP4             (CBUS_TMU_CSR_BASE_ADDR + 0x158U)
#define TMU_DBG_BUS_PP5             (CBUS_TMU_CSR_BASE_ADDR + 0x15cU)
#define TMU_DBG_BUS_PP6             (CBUS_TMU_CSR_BASE_ADDR + 0x160U)
#define TMU_DBG_BUS_PP7             (CBUS_TMU_CSR_BASE_ADDR + 0x164U)
#define TMU_DBG_BUS_PP8             (CBUS_TMU_CSR_BASE_ADDR + 0x168U)
#define TMU_DBG_BUS_PP9             (CBUS_TMU_CSR_BASE_ADDR + 0x16cU)
#define TMU_DBG_BUS_PP10            (CBUS_TMU_CSR_BASE_ADDR + 0x170U)
#define TMU_DBG_BUS_PP11            (CBUS_TMU_CSR_BASE_ADDR + 0x174U)
#define TMU_DBG_BUS_PP12            (CBUS_TMU_CSR_BASE_ADDR + 0x178U)
#define TMU_DBG_BUS_PP13            (CBUS_TMU_CSR_BASE_ADDR + 0x17cU)
#define TMU_DBG_BUS_PP14            (CBUS_TMU_CSR_BASE_ADDR + 0x180U)
#define TMU_DBG_BUS_PP15            (CBUS_TMU_CSR_BASE_ADDR + 0x184U)
#define TMU_DBG_BUS_PP16            (CBUS_TMU_CSR_BASE_ADDR + 0x188U)

#define TMU_METER_ADDR              (CBUS_TMU_CSR_BASE_ADDR + 0x190U)
#define TMU_METER_CFG0              (CBUS_TMU_CSR_BASE_ADDR + 0x194U)
#define TMU_METER_CFG1              (CBUS_TMU_CSR_BASE_ADDR + 0x198U)
#define TMU_METER_CMD               (CBUS_TMU_CSR_BASE_ADDR + 0x19cU)

#define TLITE_TDQ_PHY0_CSR_BASE_ADDR        (CBUS_TMU_CSR_BASE_ADDR + 0x1000U)
#define TLITE_TDQ_PHY1_CSR_BASE_ADDR        (CBUS_TMU_CSR_BASE_ADDR + 0x2000U)
#define TLITE_TDQ_PHY2_CSR_BASE_ADDR        (CBUS_TMU_CSR_BASE_ADDR + 0x3000U)
#define TLITE_TDQ_PHY3_CSR_BASE_ADDR        (CBUS_TMU_CSR_BASE_ADDR + 0x4000U)
#define TLITE_TDQ_PHY4_CSR_BASE_ADDR        (CBUS_TMU_CSR_BASE_ADDR + 0x5000U)
#define TLITE_TDQ_PHYn_CSR_BASE_ADDR(n)     (TLITE_TDQ_PHY0_CSR_BASE_ADDR + ((n) * 0x1000U))

#define TLITE_SCHED0_BASE_OFFSET            0x000U
#define TLITE_SCHED1_BASE_OFFSET            0x100U
#define TLITE_SCHED_OFFSET_MASK             0xfffU

#define TLITE_PHY0_SCHED0_BASE_ADDR         (TLITE_TDQ_PHY0_CSR_BASE_ADDR + TLITE_SCHED0_BASE_OFFSET)
#define TLITE_PHY0_SCHED1_BASE_ADDR         (TLITE_TDQ_PHY0_CSR_BASE_ADDR + TLITE_SCHED1_BASE_OFFSET)
#define TLITE_PHY0_SHP0_BASE_ADDR           (TLITE_TDQ_PHY0_CSR_BASE_ADDR + 0x200U)
#define TLITE_PHY0_SHP1_BASE_ADDR           (TLITE_TDQ_PHY0_CSR_BASE_ADDR + 0x300U)
#define TLITE_PHY0_SHP2_BASE_ADDR           (TLITE_TDQ_PHY0_CSR_BASE_ADDR + 0x400U)
#define TLITE_PHY0_SHP3_BASE_ADDR           (TLITE_TDQ_PHY0_CSR_BASE_ADDR + 0x500U)

#define TLITE_PHYn_SCHED0_BASE_ADDR(n)      (TLITE_TDQ_PHYn_CSR_BASE_ADDR(n) + 0x000U)
#define TLITE_PHYn_SCHED1_BASE_ADDR(n)      (TLITE_TDQ_PHYn_CSR_BASE_ADDR(n) + 0x100U)
#define TLITE_PHYn_SHP0_BASE_ADDR(n)        (TLITE_TDQ_PHYn_CSR_BASE_ADDR(n) + 0x200U)
#define TLITE_PHYn_SHP1_BASE_ADDR(n)        (TLITE_TDQ_PHYn_CSR_BASE_ADDR(n) + 0x300U)
#define TLITE_PHYn_SHP2_BASE_ADDR(n)        (TLITE_TDQ_PHYn_CSR_BASE_ADDR(n) + 0x400U)
#define TLITE_PHYn_SHP3_BASE_ADDR(n)        (TLITE_TDQ_PHYn_CSR_BASE_ADDR(n) + 0x500U)

#define TLITE_PHYn_SCHEDm_BASE_ADDR(n, m)   (TLITE_PHYn_SCHED0_BASE_ADDR(n) + ((m) * 0x100U))
#define TLITE_PHYn_SHPm_BASE_ADDR(n, m)     (TLITE_PHYn_SHP0_BASE_ADDR(n) + ((m) * 0x100U))

#define TLITE_PHYn_SCHm_CTRL(n, m)          (TLITE_PHYn_SCHEDm_BASE_ADDR(n, m) + TMU_SCH_CTRL)
#define TLITE_PHYn_SCHm_Ql_WGHT(n, m, l)    (TLITE_PHYn_SCHEDm_BASE_ADDR(n, m) + TMU_SCH_Qn_WGHT(l))
#define TLITE_PHYn_SCHm_Q_ALLOCl(n, m, l)   (TLITE_PHYn_SCHEDm_BASE_ADDR(n, m) + TMU_SCH_Q_ALLOCn(l))
#define TLITE_PHYn_SCHm_BIT_RATE(n, m)      (TLITE_PHYn_SCHEDm_BASE_ADDR(n, m) + TMU_SCH_BIT_RATE)
#define TLITE_PHYn_SCHm_POS(n, m)           (TLITE_PHYn_SCHEDm_BASE_ADDR(n, m) + TMU_SCH_POS)

#define TLITE_PHYn_SHPm_CTRL(n, m)          (TLITE_PHYn_SHPm_BASE_ADDR(n, m) + TMU_SHP_CTRL)
#define TLITE_PHYn_SHPm_WGHT(n, m)          (TLITE_PHYn_SHPm_BASE_ADDR(n, m) + TMU_SHP_WGHT)
#define TLITE_PHYn_SHPm_MAX_CREDIT(n, m)    (TLITE_PHYn_SHPm_BASE_ADDR(n, m) + TMU_SHP_MAX_CREDIT)
#define TLITE_PHYn_SHPm_CTRL2(n, m)         (TLITE_PHYn_SHPm_BASE_ADDR(n, m) + TMU_SHP_CTRL2)
#define TLITE_PHYn_SHPm_MIN_CREDIT(n, m)    (TLITE_PHYn_SHPm_BASE_ADDR(n, m) + TMU_SHP_MIN_CREDIT)
#define TLITE_PHYn_SHPm_STATUS(n, m)        (TLITE_PHYn_SHPm_BASE_ADDR(n, m) + TMU_SHP_STATUS)

#define TMU_SCH_CTRL            (0x00U)
#define TMU_SCH_Q0_WGHT         (0x20U)
#define TMU_SCH_Q1_WGHT         (0x24U)
#define TMU_SCH_Q2_WGHT         (0x28U)
#define TMU_SCH_Q3_WGHT         (0x2cU)
#define TMU_SCH_Q4_WGHT         (0x30U)
#define TMU_SCH_Q5_WGHT         (0x34U)
#define TMU_SCH_Q6_WGHT         (0x38U)
#define TMU_SCH_Q7_WGHT         (0x3cU)
#define TMU_SCH_Qn_WGHT(n)      (TMU_SCH_Q0_WGHT + ((n) * ((uint32)4U)))
#define TMU_SCH_Q_ALLOC0        (0x40U)
#define TMU_SCH_Q_ALLOC1        (0x44U)
#define TMU_SCH_Q_ALLOCn(n)     (TMU_SCH_Q_ALLOC0 + ((n) * ((uint32)4U)))
#define TMU_SCH_BIT_RATE        (0x48U)
#define TMU_SCH_POS             (0x54U)
#define TMU_SHP_CTRL            (0x00U)
#define TMU_SHP_WGHT            (0x04U)
#define TMU_SHP_MAX_CREDIT      (0x08U)
#define TMU_SHP_CTRL2           (0x0cU)
#define TMU_SHP_MIN_CREDIT      (0x10U)
#define TMU_SHP_STATUS          (0x14U)
#define TLITE_PHYS_CNT          6U
#define TLITE_PHY_QUEUES_CNT    8U
#define TLITE_SCH_INPUTS_CNT    8U
#define TLITE_SCH_CNT           2U
#define TLITE_SHP_CNT           4U
#define TLITE_SHP_INVALID_POS   0x1fU
#define TLITE_SCH_INVALID_INPUT 0xffU

#define TLITE_INQ_FIFODEPTH     256U

/* Max number of buffers in ALL queues for one phy is 255, queues are 8 */

#define TLITE_MAX_ENTRIES       (TLITE_INQ_FIFODEPTH - 1U)
#define TLITE_MAX_Q_SIZE        ((uint16)TLITE_MAX_ENTRIES / 8U)
#define TLITE_HIF_MAX_Q_SIZE    16U /* Agreed default hardcoded value for ERR051211 workaround */
#define TLITE_HIF_MAX_ENTRIES   (2U * TLITE_HIF_MAX_Q_SIZE)

/*  Implementation of the pfe_tmu_phy_cfg_t */
struct pfe_tmu_phy_cfg_tag
{
    pfe_ct_phy_if_id_t id;
    uint8 q_cnt;
    uint8 sch_cnt;
    uint8 shp_cnt;
};

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

const pfe_tmu_phy_cfg_t* pfe_tmu_cfg_get_phy_config(pfe_ct_phy_if_id_t phy);

errno_t pfe_tmu_q_cfg_get_fill_level(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *level);
errno_t pfe_tmu_q_cfg_get_drop_count(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt);
errno_t pfe_tmu_q_cfg_get_tx_count(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt);
pfe_tmu_queue_mode_t pfe_tmu_q_get_mode(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *min, uint32 *max);
errno_t pfe_tmu_q_mode_set_default(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue);
errno_t pfe_tmu_q_mode_set_tail_drop(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint16 max);
errno_t pfe_tmu_q_mode_set_wred(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint16 min, uint16 max);
errno_t pfe_tmu_q_set_wred_probability(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 prob);
errno_t pfe_tmu_q_get_wred_probability(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 *prob);
uint8 pfe_tmu_q_get_wred_zones(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue);
errno_t pfe_tmu_q_reset_tail_drop_policy(addr_t cbus_base_va);

void pfe_tmu_shp_cfg_init(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_cfg_enable(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_cfg_set_rate_mode(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp, pfe_tmu_rate_mode_t mode);
pfe_tmu_rate_mode_t pfe_tmu_shp_cfg_get_rate_mode(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_cfg_set_idle_slope(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp, uint32 isl);
uint32 pfe_tmu_shp_cfg_get_idle_slope(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp);
errno_t pfe_tmu_shp_cfg_set_limits(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp, sint32 max_credit, sint32 min_credit);
errno_t pfe_tmu_shp_cfg_get_limits(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp, sint32 *max_credit, sint32 *min_credit);
errno_t pfe_tmu_shp_cfg_set_position(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp, uint8 pos);
uint8 pfe_tmu_shp_cfg_get_position(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp);
void pfe_tmu_shp_cfg_disable(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp);

void pfe_tmu_sch_cfg_init(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch);
errno_t pfe_tmu_sch_cfg_set_rate_mode(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, pfe_tmu_rate_mode_t mode);
pfe_tmu_rate_mode_t pfe_tmu_sch_cfg_get_rate_mode(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch);
errno_t pfe_tmu_sch_cfg_set_algo(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, pfe_tmu_sched_algo_t algo);
pfe_tmu_sched_algo_t pfe_tmu_sch_cfg_get_algo(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch);
errno_t pfe_tmu_sch_cfg_set_input_weight(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input, uint32 weight);
uint32 pfe_tmu_sch_cfg_get_input_weight(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input);
errno_t pfe_tmu_sch_cfg_bind_sched_output(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 src_sch, uint8 dst_sch, uint8 input);
uint8 pfe_tmu_sch_cfg_get_bound_sched_output(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input);
errno_t pfe_tmu_sch_cfg_bind_queue(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input, uint8 queue);
uint8 pfe_tmu_sch_cfg_get_bound_queue(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input);

errno_t pfe_tmu_cfg_init(addr_t cbus_base_va, const pfe_tmu_cfg_t *cfg);
void pfe_tmu_reclaim_init(addr_t cbus_base_va);
void pfe_tmu_cfg_reset(addr_t cbus_base_va);
void pfe_tmu_cfg_enable(addr_t cbus_base_va);
void pfe_tmu_cfg_disable(addr_t cbus_base_va);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_tmu_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_tmu_cfg_get_stat_value(addr_t base_va, uint32 stat_id);
void pfe_tmu_cfg_get_special_stats(addr_t base_va, pfe_tmu_stats_special_t* special_stats);
errno_t pfe_tmu_cfg_get_queue_stats(addr_t base_va, uint32 phy_id, uint32 queue_id, pfe_tmu_queue_stats* queue_stats);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* TMU_CSR_H_ */


===== 文件 [97/185]: include\pfe_util.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef SRC_PFE_UTIL_H_
#define SRC_PFE_UTIL_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#include "pfe_ct.h"
#include "pfe_fw_feature.h"

typedef struct pfe_util_tag pfe_util_t;

typedef struct
{
    uint32 pe_sys_clk_ratio;      /*  Clock mode ratio for sys_clk and pe_clk */
    bool_t on_g3;
} pfe_util_cfg_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_util_t *pfe_util_create(addr_t cbus_base_va, uint32 pe_num, const pfe_util_cfg_t *cfg);
void pfe_util_enable(pfe_util_t *util);
void pfe_util_reset(pfe_util_t *util);
void pfe_util_disable(pfe_util_t *util);
errno_t pfe_util_default_init(pfe_util_t *util);
errno_t pfe_util_load_firmware(pfe_util_t *util, const void *elf);

void pfe_util_destroy(pfe_util_t *util);
errno_t pfe_util_get_fw_version(const pfe_util_t *util, pfe_ct_version_t *ver);
errno_t pfe_util_get_feature(pfe_util_t *util, pfe_fw_feature_t **feature, const char *name);
errno_t pfe_util_get_feature_first(pfe_util_t *util, pfe_fw_feature_t **feature);
errno_t pfe_util_get_feature_next(pfe_util_t *util, pfe_fw_feature_t **feature);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* SRC_PFE_UTIL_H_ */


===== 文件 [98/185]: include\pfe_util_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2015-2016 Freescale Semiconductor, Inc.
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef UTIL_CSR_H_
#define UTIL_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif


#define UTIL_VERSION                (CBUS_UTIL_CSR_BASE_ADDR + 0x000U)
#define UTIL_TX_CTRL                (CBUS_UTIL_CSR_BASE_ADDR + 0x004U)
#define UTIL_INQ_PKTPTR             (CBUS_UTIL_CSR_BASE_ADDR + 0x010U)

#define UTIL_HDR_SIZE               (CBUS_UTIL_CSR_BASE_ADDR + 0x014U)

#define UTIL_PE0_QB_DM_ADDR0        (CBUS_UTIL_CSR_BASE_ADDR + 0x020U)
#define UTIL_PE0_QB_DM_ADDR1        (CBUS_UTIL_CSR_BASE_ADDR + 0x024U)
#define UTIL_PE0_RO_DM_ADDR0        (CBUS_UTIL_CSR_BASE_ADDR + 0x060U)
#define UTIL_PE0_RO_DM_ADDR1        (CBUS_UTIL_CSR_BASE_ADDR + 0x064U)

#define UTIL_MEM_ACCESS_ADDR        (CBUS_UTIL_CSR_BASE_ADDR + 0x100U)
#define UTIL_MEM_ACCESS_WDATA       (CBUS_UTIL_CSR_BASE_ADDR + 0x104U)
#define UTIL_MEM_ACCESS_RDATA       (CBUS_UTIL_CSR_BASE_ADDR + 0x108U)

#define UTIL_TM_INQ_ADDR            (CBUS_UTIL_CSR_BASE_ADDR + 0x114U)
#define UTIL_PE_STATUS              (CBUS_UTIL_CSR_BASE_ADDR + 0x118U)

#define UTIL_PE_SYS_CLK_RATIO       (CBUS_UTIL_CSR_BASE_ADDR + 0x200U)
#define UTIL_AFULL_THRES            (CBUS_UTIL_CSR_BASE_ADDR + 0x204U)
#define UTIL_GAP_BETWEEN_READS      (CBUS_UTIL_CSR_BASE_ADDR + 0x208U)
#define UTIL_MAX_BUF_CNT            (CBUS_UTIL_CSR_BASE_ADDR + 0x20cU)
#define UTIL_TSQ_FIFO_THRES         (CBUS_UTIL_CSR_BASE_ADDR + 0x210U)
#define UTIL_TSQ_MAX_CNT            (CBUS_UTIL_CSR_BASE_ADDR + 0x214U)
#define UTIL_IRAM_DATA_0            (CBUS_UTIL_CSR_BASE_ADDR + 0x218U)
#define UTIL_IRAM_DATA_1            (CBUS_UTIL_CSR_BASE_ADDR + 0x21cU)
#define UTIL_IRAM_DATA_2            (CBUS_UTIL_CSR_BASE_ADDR + 0x220U)
#define UTIL_IRAM_DATA_3            (CBUS_UTIL_CSR_BASE_ADDR + 0x224U)

#define UTIL_BUS_ACCESS_ADDR        (CBUS_UTIL_CSR_BASE_ADDR + 0x228U)
#define UTIL_BUS_ACCESS_WDATA       (CBUS_UTIL_CSR_BASE_ADDR + 0x22cU)
#define UTIL_BUS_ACCESS_RDATA       (CBUS_UTIL_CSR_BASE_ADDR + 0x230U)

#define UTIL_INQ_AFULL_THRES        (CBUS_UTIL_CSR_BASE_ADDR + 0x234U)
#define UTIL_UPE_GP_REG_ADDR        (CBUS_UTIL_CSR_BASE_ADDR + 0x238U)
#define UTIL_HOST_GP_REG_ADDR       (CBUS_UTIL_CSR_BASE_ADDR + 0x23CU)
#define UTIL_MISC_REG_ADDR          (CBUS_UTIL_CSR_BASE_ADDR + 0x240U)

#define UTIL_PE_IBUS_ACCESS_PMEM    (1UL << 17U)
#define UTIL_PE_IBUS_ACCESS_DMEM    (1UL << 18U)
#define UTIL_PE_IBUS_DMEM_BASE(i)   ((((i) & 0x3) << 20U) | UTIL_PE_IBUS_ACCESS_DMEM)
#define UTIL_PE_IBUS_PMEM_BASE(i)   ((((i) & 0x3) << 20U) | UTIL_PE_IBUS_ACCESS_PMEM)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_util_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* UTIL_CSR_H_ */


===== 文件 [99/185]: include\pfe_wdt.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PUBLIC_PFE_WDT_H_
#define PUBLIC_PFE_WDT_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

typedef struct pfe_wdt_tag pfe_wdt_t;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_wdt_t *pfe_wdt_create(addr_t cbus_base_va, addr_t wdt_base);
void pfe_wdt_destroy(pfe_wdt_t *wdt);
errno_t pfe_wdt_isr(pfe_wdt_t *wdt);
void pfe_wdt_irq_mask(pfe_wdt_t *wdt);
void pfe_wdt_irq_unmask(pfe_wdt_t *wdt);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_wdt_get_text_statistics(const pfe_wdt_t *wdt, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

uint32 pfe_wdt_get_stat_value(const pfe_wdt_t* wdt, uint32 stat_id);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PUBLIC_PFE_WDT_H_ */


===== 文件 [100/185]: include\pfe_wdt_csr.h =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#ifndef PFE_WDT_CSR_H_
#define PFE_WDT_CSR_H_

/*==================================================================================================
*                                     FILE VERSION CHECK
==================================================================================================*/
#ifdef PFE_SRC_VERSION_CHECK
    #if (PFE_SRC_VERSION_CHECK != 43150440)
        #error "This header file was included from incompatible source file (different SW version)"
    #endif
#else
    #define PFE_SRC_VERSION_CHECK 43150440
#endif

#include "pfe_wdt.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t pfe_wdt_cfg_isr(addr_t base_va, addr_t cbus_base_va);
void pfe_wdt_cfg_irq_mask(addr_t base_va);
void pfe_wdt_cfg_irq_unmask(addr_t base_va);
void pfe_wdt_cfg_init(addr_t base_va);
void pfe_wdt_cfg_fini(addr_t base_va);

#if defined(PFE_CFG_TEXT_STATS)
uint32 pfe_wdt_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */
uint32 pfe_wdt_cfg_get_stat_value(addr_t base_va, uint32 stat_id);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_WDT_CSR_H_ */


===== 文件 [101/185]: src\Eth_43_PFE.c =====
/**
*   @file    Eth_43_PFE.c
*
*   @brief   AUTOSAR Eth driver interface.
*   @details This file contains implementation of the AUTOSAR Ethernet driver
*            and provides whole API except the interrupt handlers.
*
*   @addtogroup ETH_43_PFE_DRIVER
*   @{
*/
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  (c) Copyright 2006-2016 Freescale Semiconductor, Inc.
 *      Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/

#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "Eth_43_PFE.h" /* Includes also Eth_GeneralTypes.h, Eth_43_PFE_Cfg.h,
                    Eth_43_PFE_ComStack_Types.h, Dem.h, Det.h and Mcal.h */
#include "Eth_PFE_LLD.h"     /* LLD driver API */
/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define ETH_AR_RELEASE_MAJOR_VERSION_C       4
#define ETH_AR_RELEASE_MINOR_VERSION_C       4

/*==================================================================================================
*                                     FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
*                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/


/*==================================================================================================
*                                       LOCAL MACROS
==================================================================================================*/


/*==================================================================================================
*                                      LOCAL CONSTANTS
==================================================================================================*/


/*==================================================================================================
*                                      LOCAL VARIABLES
==================================================================================================*/


/*==================================================================================================
*                                      GLOBAL CONSTANTS
==================================================================================================*/


/*==================================================================================================
*                                      GLOBAL VARIABLES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/*
* @brief         State of the Eth module
* @details       Used to store state of the Ethernet controller driver i.e Eth
*                module. It is initialized to ETH_STATE_UNINIT
*/

volatile Eth_StateType Eth_43_PFE_CtrlState[ETH_43_PFE_MAXCTRLS_SUPPORTED] = {ETH_STATE_UNINIT};


#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/*
* @brief          Used for internal storage of configuration pointer
* @details        This variable is used to store the pointer to the instance
*                 of the Eth_43_PFE_ConfigType containing the configuration parameter,
*                 which is passed to the Eth_43_PFE_Init function, for the subsequent
*                 accesses.
*/
const Eth_43_PFE_ConfigType * Eth_43_PFE_InternalCfgPtr = NULL_PTR;
#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================*/
#if (STD_ON == ETH_43_PFE_ENABLE_USER_MODE_SUPPORT)
    #define Local_Macro_Eth_PFE_LLD_InitInterfaces(InternalCfgPtr)   OsIf_Trusted_Call1param(Eth_PFE_LLD_InitInterfaces, (InternalCfgPtr))
    #define Local_Macro_Eth_PFE_LLD_InitEMACs(InternalCfgPtr)        OsIf_Trusted_Call1param(Eth_PFE_LLD_InitEMACs, (InternalCfgPtr))
#else
    #define Local_Macro_Eth_PFE_LLD_InitInterfaces(InternalCfgPtr)   Eth_PFE_LLD_InitInterfaces(InternalCfgPtr)
    #define Local_Macro_Eth_PFE_LLD_InitEMACs(InternalCfgPtr)        Eth_PFE_LLD_InitEMACs(InternalCfgPtr)
#endif

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
static void check_and_configure_controller(uint8 u8CtrlCount);
static BufReq_ReturnType update_and_provide_buffer(uint8 u8CtrlIdx, uint8 Priority, Eth_BufIdxType * BufIdxPtr, uint8 **BufPtr, uint16 * LenBytePtr);

/*==================================================================================================
*                                       LOCAL FUNCTIONS
==================================================================================================*/

static void check_and_configure_controller(uint8 u8CtrlCount)
{
    if(TRUE == Eth_PFE_LLD_CheckInitializationStatus(u8CtrlCount))
    {
        if (((Std_ReturnType)E_OK) == Eth_PFE_LLD_ConfigureController(u8CtrlCount))
        {
            /* Set controller to init state */
            Eth_43_PFE_CtrlState[u8CtrlCount] = ETH_STATE_INIT;
            /* Yes, the controller is available, report as passed */
            #ifdef PFE_CFG_PFE_MASTER
                #if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
                if((uint32)STD_ON == (uint32)ETH_43_PFE_CFG_DEM_E_ACCESS_ENABLED(u8CtrlCount))
                {
                    (void)Dem_SetEventStatus((Dem_EventIdType) ETH_43_PFE_CFG_DEM_E_ACCESS(u8CtrlCount), DEM_EVENT_STATUS_PREPASSED);
                }
                #endif /*(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)*/
            #endif /*PFE_CFG_PFE_MASTER*/
        }
        else
        {
            Eth_43_PFE_CtrlState[u8CtrlCount] = ETH_STATE_UNINIT;
        }
    }
    else
    {
        Eth_43_PFE_CtrlState[u8CtrlCount] = ETH_STATE_UNINIT;
    }
}

/*==================================================================================================*/
static BufReq_ReturnType update_and_provide_buffer(uint8 u8CtrlIdx, uint8 Priority, Eth_BufIdxType * BufIdxPtr, uint8 **BufPtr, uint16 * LenBytePtr)
{
    BufReq_ReturnType eFunctionSuccess = BUFREQ_E_NOT_OK;
    uint16 u16TempLenByte; /* Avoid changes of input parameters in case of an error */
    uint8 u8QueueIdx;
#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
    uint16 oldBufLen;
    uint8* dataPtr;
    uint16 ManagementInfoLength;
    uint16 FrameLength = 0;
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API*/

    u8QueueIdx = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->EthCtrlEgressPrioToFifoIdx[Priority];
#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
    oldBufLen = *LenBytePtr;
    Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
    Eth_43_PFE_EthSwtDriverFunctionList.TxAdaptBufferLengthFunction(LenBytePtr);
    PfeDevAssert(*LenBytePtr >= oldBufLen);
    ManagementInfoLength = *LenBytePtr - oldBufLen;
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API*/
    u16TempLenByte = *LenBytePtr;
    if(TRUE == Eth_PFE_LLD_ProvideBufferDataArea(u8CtrlIdx, u8QueueIdx, BufIdxPtr, BufPtr, &u16TempLenByte))
    { /* Data space is available */
        *LenBytePtr = u16TempLenByte;
        eFunctionSuccess = BUFREQ_OK;
    }
    else
    {
        if(*LenBytePtr > u16TempLenByte)
        {
            /* Requested size is too long, do not lock buffer */
            /* Set length to maximal available payload length */
            *LenBytePtr = u16TempLenByte;
            eFunctionSuccess = BUFREQ_E_OVFL;
        }
        else
        {
            /* Data space is not available */
            eFunctionSuccess = BUFREQ_E_BUSY;
        }
    }
#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
    if (eFunctionSuccess == BUFREQ_OK)
    {
        /* dataPtr points to position of EtherType in Ethernet frame*/
        dataPtr = (uint8*)(*BufPtr - 2U);
        /* Calculate frame length */
        PfeDevAssert(*LenBytePtr >= ManagementInfoLength);
        FrameLength = *LenBytePtr - ManagementInfoLength;
        if(E_OK == \
            Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
            Eth_43_PFE_EthSwtDriverFunctionList.TxPrepareFrameFunction( \
                u8CtrlIdx, *BufIdxPtr, &dataPtr, &FrameLength ))
        {   /* Data space is available */
            /* Update pointer to the payload */
            *BufPtr = dataPtr + 2U;
            eFunctionSuccess = BUFREQ_OK;
        }
    }
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API*/
    return eFunctionSuccess;
}

/*==================================================================================================
*                                       GLOBAL FUNCTIONS
==================================================================================================*/

/*================================================================================================*/
/**
* @brief         Initializes the Ethernet Driver
* @details       Passed configuration pointer is internally stored and
*                the driver is initialized. The Ethernet controller is not
*                touched.
* @note          Function should be called only once.
* @warning       Second call can cause undefined behavior.
*                Call the Eth_SetControllerMode() and pass ETH_MODE_DOWN to
*                the CtrlMode argument before the second Eth_43_PFE_Init call to avoid
*                problems.
* @api
* @param[in]     CfgPtr Points to the implementation specific structure containing
*                the Eth driver configuration
* Compiler_Warning: this warning due to behavior of compiler depend on configs.
*/
void Eth_43_PFE_Init(const Eth_43_PFE_ConfigType * CfgPtr)
{
    uint8 u8CtrlCount = 0U;

#if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
#if STD_ON == ETH_43_PFE_PRECOMPILE_SUPPORT
    if(NULL_PTR != CfgPtr)
#else
    if(NULL_PTR == CfgPtr)
#endif
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_INIT, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else
    {
#endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
        /* Set the state to ETH_STATE_UNINIT before doing any changes to
           ensure that any preempting function (interrupt handler) will
           ensure that any preempting function (interrupt handler) will
           correctly stop its execution even if the state had been
           ETH_43_PFE_STATE_ACTIVE when the Eth_43_PFE_Init was called. */
        for (u8CtrlCount=0U; u8CtrlCount < (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG; u8CtrlCount++)
        {
            Eth_43_PFE_CtrlState[u8CtrlCount] = ETH_STATE_UNINIT;
        }
     /* Store the configuration pointer to internal global variable
        for future usage */
    #if STD_ON == ETH_43_PFE_PRECOMPILE_SUPPORT
        Eth_43_PFE_InternalCfgPtr = &Eth_43_PFE_Config;
        (void)CfgPtr;
    #else
        Eth_43_PFE_InternalCfgPtr = CfgPtr;
    #endif
        /* Reset and configure - common */
        if ((Std_ReturnType)E_OK == Eth_PFE_LLD_PlatformDrvPrepare())
        {
            #ifdef PFE_CFG_PFE_MASTER
            Eth_PFE_LLD_EMACPrepare();
            #endif

            /* Configure - per controller */
            for (u8CtrlCount = 0U; u8CtrlCount < (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG; u8CtrlCount++)
            {
                /* Try to reset the controller - per interface */
                Eth_PFE_LLD_InterfacePrepare(u8CtrlCount);
                /*  Check whether the controller is available */
                check_and_configure_controller(u8CtrlCount);
            }
            #if (defined(PFE_CFG_PFE_MASTER) && ((TRUE == PFE_CFG_HIF_IRQ_ENABLED) || (TRUE == PFE_CFG_BMU_IRQ_ENABLED)))
            Eth_PFE_LLD_bIrqInitStatus = TRUE;
            #endif
            #if defined(PFE_CFG_MULTI_INSTANCE_SUPPORT) && defined(PFE_CFG_PFE_MASTER)
            Eth_43_PFE_LLD_SetMasterUp();
            #endif
        }
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
}

/*================================================================================================*/
/**
* @brief         Shutdown the driver gracefully 
* @api
*/
void Eth_43_PFE_DeInit(void)
{
    Eth_PFE_LLD_DeInit();
    Eth_43_PFE_InternalCfgPtr = NULL_PTR;
}

/*================================================================================================*/
/**
* @brief         Enables or disables the given controller
* @warning       Disabling the controller clears all receive and transmit
*                buffers. The application should ensure that no data is lost.
* @api
* @param[in]     u8CtrlIdx Index of the controller to be enabled or disabled.
*                The index is valid within the context of the Ethernet Driver
*                only.
* @param[in]     CtrlMode Mode which shall be entered
*                - ETH_MODE_DOWN: disable the controller
*                - ETH_MODE_ACTIVE: enable the controller
* @return        Error status
* @retval        E_OK No error was detected during the function execution.
* @retval        E_NOT_OK Development error was detected and the function
*                failed.
*/
Std_ReturnType Eth_43_PFE_SetControllerMode(uint8 u8CtrlIdx, Eth_ModeType CtrlMode)
{
    Std_ReturnType u8FunctionSuccess = (Std_ReturnType)E_NOT_OK; /* Variable used to track the
                                           function execution success status */

    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_SETCONTROLLERMODE, ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_SETCONTROLLERMODE, ETH_43_PFE_E_UNINIT \
                                  );
        }
        else
        {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
            if(ETH_MODE_ACTIVE == CtrlMode)
            {
                if(TRUE == Eth_PFE_LLD_EnableController(u8CtrlIdx))
                {
                    u8FunctionSuccess = (Std_ReturnType)E_OK;
                }
            }
            else
            {
                if ((Std_ReturnType)E_OK == Eth_PFE_LLD_DisableController(u8CtrlIdx))
                {
                    u8FunctionSuccess = (Std_ReturnType)E_OK;
                }
            }

            #ifdef PFE_CFG_PFE_MASTER
            #if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
            if((uint32)STD_ON == (uint32)ETH_43_PFE_CFG_DEM_E_ACCESS_ENABLED(u8CtrlIdx))
            {
                (void)Dem_SetEventStatus   ( \
                    (Dem_EventIdType) \
                    ETH_43_PFE_CFG_DEM_E_ACCESS(u8CtrlIdx), \
                    DEM_EVENT_STATUS_PREPASSED  \
                                        );
            }
            #endif
            #endif /*PFE_CFG_PFE_MASTER*/
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT */
    return u8FunctionSuccess;
}

/*================================================================================================*/
/**
* @brief         Obtains the mode of the given controller
* @api
* @param[in]     u8CtrlIdx Index of the controller which state shall be read.
*                The index is valid within the context of the Ethernet Driver
*                only.
* @param[out]    CtrlModePtr Pointer where to store the current controller mode.
* @return        Error status
* @retval        E_OK No error was detected during the function execution.
* @retval        E_NOT_OK Development error was detected and the function
*                failed.
*/
Std_ReturnType Eth_43_PFE_GetControllerMode( \
                            uint8 u8CtrlIdx, \
                            Eth_ModeType * CtrlModePtr \
                                                    )
{
    /*  Variable used to track the function execution success status */
    Std_ReturnType u8FunctionSuccess = (Std_ReturnType)E_NOT_OK;

    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_GETCONTROLLERMODE, ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
       if(NULL_PTR == CtrlModePtr)
        {

            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_GETCONTROLLERMODE, ETH_43_PFE_E_PARAM_POINTER \
                                  );

        }
        else
        {
           if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_GETCONTROLLERMODE, ETH_43_PFE_E_UNINIT \
                                      );
            }
            else
            {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                * CtrlModePtr = Eth_PFE_LLD_CheckControllerIsActive(u8CtrlIdx);
                u8FunctionSuccess = (Std_ReturnType)E_OK;
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
    return u8FunctionSuccess;
}

/*================================================================================================*/
/**
* @brief         Obtains the physical source address used by the indexed
*                controller (the node MAC address).
* @api
* @param[in]     u8CtrlIdx Index of the controller which MAC address should be
*                read. The index is valid within the context of the Ethernet
*                Driver only.
* @param[out]    PhysAddrPtr Pointer where to store physical source address
*                (MAC address). The address in network byte order is stored into
*                6 bytes at the given memory address.
*/
void Eth_43_PFE_GetPhysAddr(uint8 u8CtrlIdx, uint8 * PhysAddrPtr)
{

    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_GETPHYSADDR, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if(NULL_PTR == PhysAddrPtr)
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_GETPHYSADDR, ETH_43_PFE_E_PARAM_POINTER \
                                  );

        }
        else
        {
           if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_GETPHYSADDR, ETH_43_PFE_E_UNINIT \
                                      );
            }
            else
            {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                Eth_PFE_LLD_GetPhysicalAddress(u8CtrlIdx, PhysAddrPtr);
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
}

/*================================================================================================*/
/**
* @brief         Set or change physical address to the defined controller.
* @api
* @param[in]     u8CtrlIdx Index of the controller which PHY address should be
*                changed. The index is valid within the context of the Ethernet
*                Driver only.
* @param[in]     PhysAddrPtr Pointer to PHY address which should be set to
*                the controller. The address is stored in 6 bytes of memory
*                in network byte order.
* @caution       This function may be called only when the controller is down.
*                Call of function Eth_43_PFE_ControllerInit change MAC address
*                to the default value!
*/
void Eth_43_PFE_SetPhysAddr(uint8 u8CtrlIdx, const uint8 * PhysAddrPtr)
{
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_SETPHYSADDR, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if(NULL_PTR == PhysAddrPtr)
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_SETPHYSADDR, ETH_43_PFE_E_PARAM_POINTER \
                                  );

        }
        else
        {
           if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_SETPHYSADDR, ETH_43_PFE_E_UNINIT \
                                      );
            }
            else
            {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                (void)Eth_PFE_LLD_SetPhysAddr(u8CtrlIdx, PhysAddrPtr);
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
}

/*================================================================================================*/
/**
* @brief         Adds or removes the specified PhysAddrPtr address to or from
*                a multicast address pool in the controller specified by CtrlIdx.
* @api
* @param[in]     u8CtrlIdx Index of the controller. The index is valid within
*                the context of the Ethernet Driver only.
* @param[in]     PhysAddrPtr Pointer to PHY address which shall be added
*                or removed to or from multicast pool.
*                The address in network byte order stored into 6 bytes of
*                memory.
* @param[in]     Action Determine whenever the defined address will be added
*                to the pool ETH_ADD_TO_FILTER or removed from it
*                ETH_REMOVE_FROM_FILTER.
* @note          Each EMAC can handle up to 8 MAC addresses with exact match. All addresses, 
*                multicast and unicast, configured in all drivers (in master-slave scenarios) are 
*                counted in that. When more than 8 addresses are configured for one EMAC, the EMAC 
*                hash table will be used for filtering. This may cause the EMAC to accept also 
*                frames with MAC addresses that were not configured (when using hash matching 
*                algorithm, all frames with same hash group will be accepted). These additional 
*                frames (with DMAC address that was not configured) will be received by master 
*                driver, unless default configuration is changed through FCI.
*/
Std_ReturnType Eth_43_PFE_UpdatePhysAddrFilter ( \
                                    uint8 u8CtrlIdx, \
                                    const uint8 * PhysAddrPtr, \
                                    Eth_FilterActionType Action \
                                                            )
{
    /*  Variable used to track the function execution success status */
    Std_ReturnType u8FunctionSuccess = (Std_ReturnType)E_NOT_OK;

    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_UPDATEADDRFILTER, ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
       if(NULL_PTR == PhysAddrPtr)
        {

            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_UPDATEADDRFILTER, ETH_43_PFE_E_PARAM_POINTER \
                                  );

        }
        else
        {
           if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_UPDATEADDRFILTER, ETH_43_PFE_E_UNINIT \
                                      );
            }
            else
            {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                u8FunctionSuccess = Eth_PFE_LLD_UpdatePhysAddrFilter(u8CtrlIdx, PhysAddrPtr, Action);
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */

    return u8FunctionSuccess;
}

/*================================================================================================*/
/**
* @brief         Provides access to a transmit buffer of the specified
*                controller.
* @warning       The application should handle possible difference between the
*                requested and granted buffer lengths. It is not necessary to
*                use whole granted buffer i.e. some space at the end may not
*                be written.
* @api
* @param[in]     u8CtrlIdx Index of the controller which buffer shall be provided.
*                The index is valid within the context of the Ethernet Driver
*                only.
* @param[in]     Priority Frame priority for transmit buffer FIFO selection.
* @param[out]    BufIdxPtr Index to the granted transmit buffer resource.
*                It uniquely identifies the buffer in all subsequent calls of
*                functions Eth_43_PFE_Transmit() and Eth_43_PFE_TxConfirmation().
* @param[out]    BufPtr Pointer to the granted buffer. This is the space where
*                the data to be transmitted shall be stored.
* @param[in,out] LenBytePtr Buffer payload length
*                - In: desired length in bytes
*                - Out: granted length in bytes
* @return        Error and buffer status
* @retval        BUFREQ_OK: Buffer was successfully granted and no error has
*                occurred.
* @retval        BUFREQ_E_NOT_OK: A development error was detected and no buffer
*                was granted.
* @retval        BUFREQ_E_BUSY: All available buffers in use therefore no
*                buffer was granted. No error has been detected.
*/
BufReq_ReturnType Eth_43_PFE_ProvideTxBuffer( \
                            uint8 u8CtrlIdx, \
                            uint8 Priority, \
                            Eth_BufIdxType * BufIdxPtr, \
                            uint8 **BufPtr, \
                            uint16 * LenBytePtr \
                                                     )
{
    /* Variable used to track function success status */
    BufReq_ReturnType eFunctionSuccess = BUFREQ_E_NOT_OK;

#if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_PROVIDETXBUFFER, ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if(NULL_PTR == BufIdxPtr)
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_PROVIDETXBUFFER, ETH_43_PFE_E_PARAM_POINTER \
                                  );
        }
        else
        {
            if(NULL_PTR == BufPtr)
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_PROVIDETXBUFFER, ETH_43_PFE_E_PARAM_POINTER \
                                      );
            }
            else
            {
                if(NULL_PTR == LenBytePtr)
                {
                    (void)Det_ReportError ( \
                        (uint8) ETH_43_PFE_MODULE_ID, \
                        ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                        ETH_43_PFE_SID_PROVIDETXBUFFER, ETH_43_PFE_E_PARAM_POINTER \
                                          );
                }
                else
                {
                    if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
                    {
                        (void)Det_ReportError ( \
                            (uint8) ETH_43_PFE_MODULE_ID, \
                            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                            ETH_43_PFE_SID_PROVIDETXBUFFER, ETH_43_PFE_E_UNINIT \
                                              );
                    }
                    else
                    {
#endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                        if (Priority <= ETH_43_PFE_MAX_TX_PRIO_NUM)
                        {
                            eFunctionSuccess = update_and_provide_buffer(u8CtrlIdx, Priority, BufIdxPtr, BufPtr, LenBytePtr);
                        }
                        else
                        {
                            eFunctionSuccess = BUFREQ_E_NOT_OK;
                        }
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
                    }
                }
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
    return eFunctionSuccess;
}

/*================================================================================================*/
/**
* @brief         Triggers transmission of a previously granted and then filled
*                transmit buffer.
* @api
* @param[in]     u8CtrlIdx Index of the controller which buffer shall be
*                transmitted. The index is valid within the context of
*                the Ethernet Driver only.
* @param[in]     BufIdx Index of the buffer resource to be transmitted.
* @param[in]     FrameType Desired value of the Ethernet frame type in the
*                frame header.
* @param[in]     TxConfirmation Activates transmission confirmation.
* @param[in]     LenByte Buffer data length in bytes (payload length).
* @param[in]     PhysAddrPtr Physical target address (MAC address) in network
*                byte order.
* @return        Error status
* @retval        E_OK No error was detected during the function execution.
* @retval        E_NOT_OK Development error was detected and the function
*                failed.
*/
Std_ReturnType Eth_43_PFE_Transmit( \
                            uint8 u8CtrlIdx, \
                            Eth_BufIdxType BufIdx, \
                            Eth_FrameType FrameType, \
                            boolean TxConfirmation, \
                            uint16 LenByte, \
                            const uint8 * PhysAddrPtr \
                                  )
{
    Std_ReturnType u8FunctionSuccess = (Std_ReturnType)E_NOT_OK;

    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    uint16 lmem_header_size;
    uint8 u8FifoIdx;
    uint32 u32BufLen;
    uint32 u32BufHdrSize;

    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ((uint8) ETH_43_PFE_MODULE_ID, ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_TRANSMIT, ETH_43_PFE_E_INV_CTRL_IDX );
    }
    else
    {
        if(NULL_PTR == PhysAddrPtr)
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_TRANSMIT, ETH_43_PFE_E_PARAM_POINTER \
                                  );
        }
        else
        {
            if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_TRANSMIT, ETH_43_PFE_E_UNINIT \
                                      );
            }
            else
            {
                if(ETH_MODE_ACTIVE != Eth_PFE_LLD_CheckControllerIsActive(u8CtrlIdx))
                {
                    (void)Det_ReportError ( \
                        (uint8) ETH_43_PFE_MODULE_ID, \
                        ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                        ETH_43_PFE_SID_TRANSMIT, ETH_43_PFE_E_INV_MODE \
                                          );
                }
                else
                {
                    u8FifoIdx = Eth_43_PFE_LLD_GetTxFifoIdx(u8CtrlIdx, BufIdx);
                    lmem_header_size = Eth_43_PFE_LLD_GetLmemHdrSize(u8CtrlIdx);
                    u32BufHdrSize = (uint32)TX_BUF_FRAME_OFFSET + lmem_header_size + (uint32)PFE_LLD_L2_HEADER_SIZE;
                    if(Eth_43_PFE_LLD_GetTxBufferSize(u8CtrlIdx, u8FifoIdx) < u32BufHdrSize)
                    {
                        NXP_LOG_ERROR("Size of TX buffer is invalid\n");
                    }
                    else
                    {
                        u32BufLen = Eth_43_PFE_LLD_GetTxBufferSize(u8CtrlIdx, u8FifoIdx)
                                  - (uint32)TX_BUF_FRAME_OFFSET - lmem_header_size - (uint32)PFE_LLD_L2_HEADER_SIZE;
                        PfeDevAssert(u32BufLen <= UINT16_MAX);
                        if((BufIdx >= ETH_43_PFE_MAX_CTRL_TX_BUF_CNT) || (LenByte > (uint16)u32BufLen))
                        {
                            (void)Det_ReportError ( \
                                (uint8) ETH_43_PFE_MODULE_ID, \
                                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                                ETH_43_PFE_SID_TRANSMIT, ETH_43_PFE_E_INV_PARAM \
                                                  );
                        }
                        else
                        {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                            u8FunctionSuccess = Eth_PFE_LLD_Transmit
                            (
                                u8CtrlIdx, BufIdx, FrameType,
                                LenByte, TxConfirmation, PhysAddrPtr
                            );
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
                        }
                    }
                }
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */

    return u8FunctionSuccess;
}

#if STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API
/*================================================================================================*/
/**
* @brief         Release a previously granted TX buffer. The transmission must not have been triggered.
* @api
* @param[in]     u8CtrlIdx Index of the controller whose buffer shall be released
*                The index is valid within the context of the Ethernet Driver only.
* @param[in]     BufIdx Index of the buffer resource to be released.
* @return        Error status
* @retval        BUFREQ_E_OK - Buffer successfully released
* @retval        BUFREQ_E_NOT_OK - Development error was detected, no buffer was released.
* @retval        BUFREQ_E_BUSY - Couldn't free the TX buffer of an un-finished transmission.
*/
BufReq_ReturnType Eth_43_PFE_ReleaseTxBuffer(uint8 u8CtrlIdx, 
                                             Eth_BufIdxType BufIdx
                                            )
{
    BufReq_ReturnType eReturnValue = BUFREQ_E_NOT_OK;

#if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    uint8 u8DetError = 0U;
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        u8DetError = ETH_43_PFE_E_INV_CTRL_IDX;
    }
    else if(BufIdx >= ETH_43_PFE_MAX_CTRL_TX_BUF_CNT)
    {
        u8DetError = ETH_43_PFE_E_INV_PARAM;
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        u8DetError = ETH_43_PFE_E_UNINIT;
    }
    else 
    {
        /* No error, keep u8DetError = 0U */
    }

    if(u8DetError != 0U)
    {
        (void)Det_ReportError((uint8)ETH_43_PFE_MODULE_ID, ETH_43_PFE_DRIVER_INSTANCE, (uint8)ETH_43_PFE_SID_RELEASETXBUFFER, u8DetError);
    }
    else
#endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
    {
        eReturnValue = Eth_PFE_LLD_ReleaseTxBuffer(u8CtrlIdx, BufIdx) ? BUFREQ_OK : BUFREQ_E_BUSY;
    }

    return eReturnValue;
}
#endif  /* STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API */

/*================================================================================================*/
/**
* @brief         Triggers frames reception notifications.
* @details       All receive buffers are checked and the first received frame is
*                passed to the EthIf module. The caller is notified whether any
*                frame was received and whether more frames are available in the
*                receive queue.
* @api
* @param[in]     u8CtrlIdx Index of the controller which shall be checked whether
*                any new frames were received. The index is valid within
*                the context of the Ethernet Driver only.
* @param[in]     FifoIdx Index of Rx Fifo where frames were received.
* @param[out]    RxStatusPtr Informs the caller whether a frame was received
*                (@c ETH_RECEIVED or @c ETH_NOT_RECEIVED) and whether more frames
*                are available in the queue (@c ETH_RECEIVED or
*                @c ETH_RECEIVED_MORE_DATA_AVAILABLE).
*/
void Eth_43_PFE_Receive(uint8 u8CtrlIdx, \
                        uint8 FifoIdx, \
                        Eth_RxStatusType *RxStatusPtr \
                       )
{
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_RECEIVE, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if(FifoIdx > (HIF_DRV_CLIENT_QUEUES_MAX - 1U))
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                 ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                 ETH_43_PFE_SID_RECEIVE, ETH_43_PFE_E_INV_PARAM \
                                  );
        }
        else
        {
            if(NULL_PTR == RxStatusPtr)
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_RECEIVE, ETH_43_PFE_E_PARAM_POINTER \
                                      );
            }
            else
            {
                if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
                {
                    (void)Det_ReportError ( \
                        (uint8) ETH_43_PFE_MODULE_ID, \
                        ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_RECEIVE, \
                        ETH_43_PFE_E_UNINIT \
                                          );
                }
                else
                {
                    if(ETH_MODE_ACTIVE != Eth_PFE_LLD_CheckControllerIsActive(u8CtrlIdx))
                    {
                        (void)Det_ReportError ( \
                            (uint8) ETH_43_PFE_MODULE_ID, \
                            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                            ETH_43_PFE_SID_RECEIVE, ETH_43_PFE_E_INV_MODE \
                                              );
                    }
                    else
                    {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                        if(FALSE == ETH_43_PFE_CFG_ENABLERXINTERRUPT(u8CtrlIdx))
                        {
                            /* Check all buffers and report them - returned error
                            status is ignored because there is no mean to report errors
                            in the AUTOSAR specification */
                            *RxStatusPtr = Eth_PFE_LLD_ReportReception(u8CtrlIdx, FifoIdx, (boolean)FALSE);
                        }
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
                    }
                }
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
}

/*================================================================================================*/
/**
* @brief         Triggers frame transmission confirmations.
* @api
* @param[in]     u8CtrlIdx Index of the controller which shall be checked whether
*                any frame transmission has finished. The index is valid within
*                the context of the Ethernet Driver only.
* @details       All transmit buffers are checked and upper layers are informed
*                about successfully transmitted frames. Buffers containing
*                transmitted frames are unlocked after the confirmation.
*/
void Eth_43_PFE_TxConfirmation(uint8 u8CtrlIdx)
{
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_TXCONFIRMATION, ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                ETH_43_PFE_SID_TXCONFIRMATION, ETH_43_PFE_E_UNINIT \
                                  );
        }
        else
        {
            if(ETH_MODE_ACTIVE != Eth_PFE_LLD_CheckControllerIsActive(u8CtrlIdx))
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_TXCONFIRMATION, ETH_43_PFE_E_INV_MODE \
                                      );
            }
            else
            {

    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
                if(FALSE == ETH_43_PFE_CFG_ENABLETXINTERRUPT(u8CtrlIdx))
                {
                    uint8 u8NumsFifo;
                    uint8 u8FifoIdx;
                    u8NumsFifo = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->EthCtrlEgressFifoCnt;
                    for(u8FifoIdx = 0U; u8FifoIdx < u8NumsFifo; u8FifoIdx ++)
                    {
                        Eth_PFE_LLD_ReportTransmission(u8CtrlIdx, u8FifoIdx);
    #if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
                        Eth_PFE_LLD_ReportTransmissionTS(u8CtrlIdx, u8FifoIdx);
    #endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */
                    }
                }
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
            }
        }
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
}

#if STD_ON == ETH_43_PFE_VERSION_INFO_API
#if STD_OFF == ETH_43_PFE_VERSION_INFO_API_MACRO
/*================================================================================================*/
/**
* @brief         Returns the version information of this module.
* @api
* @param[out]    VersionInfoPtr Pointer where to store the version information
*                of this particular module instance.
*/
void Eth_43_PFE_GetVersionInfo(Std_VersionInfoType * VersionInfoPtr)
{
    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    if(NULL_PTR == VersionInfoPtr)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_GETVERSIONINFO, ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else
    {
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT */
        VersionInfoPtr->moduleID = (uint16)ETH_43_PFE_MODULE_ID;
        VersionInfoPtr->vendorID = (uint16)ETH_43_PFE_VENDOR_ID;
        VersionInfoPtr->sw_major_version = (uint8)ETH_43_PFE_SW_MAJOR_VERSION;
        VersionInfoPtr->sw_minor_version = (uint8)ETH_43_PFE_SW_MINOR_VERSION;
        VersionInfoPtr->sw_patch_version = (uint8)ETH_43_PFE_SW_PATCH_VERSION;

    #if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
    }
    #endif /* ETH_43_PFE_DEV_ERROR_DETECT */
}
#endif /* STD_OFF == ETH_43_PFE_VERSION_INFO_API_MACRO */
#endif /* ETH_43_PFE_VERSION_INFO_API */
/*================================================================================================*/
/**
* @brief         The function checks for controller errors and lost frames. Used for polling state
*                changes. Calls EthIf_CtrlModeIndication when the controller mode changed.
* @api
*/
void Eth_43_PFE_MainFunction(void)
{
    Eth_PFE_LLD_MainFunction();
}

#if STD_ON == ETH_43_PFE_CTRLENABLE_MII
/**
 * @brief       Write specified transceiver register through the MII
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver on the MII
 * @param[in]   u8RegIdx Index of the transceiver register on the MII
 * @param[in]   u16RegVal Value to be written into the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_WriteMii(uint8 u8CtrlIdx, \
                                   uint8 u8TrcvIdx, \
                                   uint8 u8RegIdx, \
                                   uint16 u16RegVal \
                                  )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_WRITEMII, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if((u8TrcvIdx > (uint8)ETH_43_PFE_PHY_ADDR_MAX) || (u8RegIdx > (uint8)ETH_43_PFE_PHY_REG_ADDR_MII22_MAX))
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_WRITEMII, \
                ETH_43_PFE_E_INV_PARAM \
                                  );
        }
        else
        {
            if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_WRITEMII, \
                    ETH_43_PFE_E_UNINIT \
                                      );
            }
            else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
            {
                eReturnStatus = Eth_43_PFE_LLD_WriteMii(u8CtrlIdx, u8TrcvIdx, u8RegIdx, u16RegVal);
                if((Std_ReturnType)E_OK == eReturnStatus)
                {
                    Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
                    Eth_43_PFE_EthTrcvDriverFunctionList.WriteMiiIndicationFunction(u8CtrlIdx, u8TrcvIdx, u8RegIdx);
                }
            }
#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
        }
    }
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */

    return eReturnStatus;
}

/**
 * @brief       Read the specified transceiver register through the MII
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver on the MII
 * @param[in]   u8RegIdx Index of the transceiver register on the MII
 * @param[out]  pu16RegValPtr Filled with the register content of the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_ReadMii(uint8 u8CtrlIdx, \
                                  uint8 u8TrcvIdx, \
                                  uint8 u8RegIdx, \
                                  uint16 *pu16RegValPtr \
                                 )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_READMII, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if((u8TrcvIdx > (uint8)ETH_43_PFE_PHY_ADDR_MAX) || (u8RegIdx > (uint8)ETH_43_PFE_PHY_REG_ADDR_MII22_MAX))
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_READMII, \
                ETH_43_PFE_E_INV_PARAM \
                                  );
        }
        else
        {
            if(NULL_PTR == pu16RegValPtr)
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                    ETH_43_PFE_SID_READMII, ETH_43_PFE_E_PARAM_POINTER \
                                      );
            }
            else
            {
                if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
                {
                    (void)Det_ReportError ( \
                        (uint8) ETH_43_PFE_MODULE_ID, \
                        ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                        ETH_43_PFE_SID_READMII, ETH_43_PFE_E_UNINIT \
                                          );
                }
                else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
                {
                    eReturnStatus = Eth_43_PFE_LLD_ReadMii(u8CtrlIdx, u8TrcvIdx, u8RegIdx, pu16RegValPtr);
                    if((Std_ReturnType)E_OK == eReturnStatus)
                    {
                        Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
                        Eth_43_PFE_EthTrcvDriverFunctionList.ReadMiiIndicationFunction(u8CtrlIdx, u8TrcvIdx, u8RegIdx, *pu16RegValPtr);
                    }
                }
#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
            }
        }
    }
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */

    return eReturnStatus;
}

#if STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API
/**
 * @brief       Write specified transceiver register through the MII (Clause 45)
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver
 * @param[in]   u8DevIdx Index of the device within the transciever
 * @param[in]   u16RegIdx Index of the transceiver register
 * @param[in]   u16RegVal Value to be written into the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_WriteMii45(uint8 u8CtrlIdx, \
                                     uint8 u8TrcvIdx, \
                                     uint8 u8DevIdx, \
                                     uint16 u16RegIdx, \
                                     uint16 u16RegVal \
                                    )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_WRITEMII45, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if((u8TrcvIdx > (uint8)ETH_43_PFE_PHY_ADDR_MAX) || (u8DevIdx > (uint8)ETH_43_PFE_PHY_DEV_MII45_MAX))
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_WRITEMII45, \
                ETH_43_PFE_E_INV_PARAM \
                                  );
        }
        else
        {
            if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
            {
                (void)Det_ReportError ( \
                    (uint8) ETH_43_PFE_MODULE_ID, \
                    ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_WRITEMII45, \
                    ETH_43_PFE_E_UNINIT \
                                      );
            }
            else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
            {
                eReturnStatus = Eth_43_PFE_LLD_WriteMii45(u8CtrlIdx, u8TrcvIdx, u8DevIdx, u16RegIdx, u16RegVal);
                if((Std_ReturnType)E_OK == eReturnStatus)
                {
                    /*  No indication to EthTrcv due to API incompatibility (u16RegIdx Vs u8RegIdx) */
                    ;
                }
            }
#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
        }
    }
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */

    return eReturnStatus;
}

/**
 * @brief       Read the specified transceiver register through the MII (Clause 45)
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver (address)
 * @param[in]   u16RegIdx Index of the transceiver register
 * @param[in]   u8DevIdx Index of the device within the transciever
 * @param[out]  pu16RegValPtr Filled with the register content of the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_ReadMii45(uint8 u8CtrlIdx, \
                                    uint8 u8TrcvIdx, \
                                    uint8 u8DevIdx, \
                                    uint16 u16RegIdx, \
                                    uint16 *pu16RegValPtr \
                                   )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_READMII45, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else
    {
        if((u8TrcvIdx > (uint8)ETH_43_PFE_PHY_ADDR_MAX) || (u8DevIdx > (uint8)ETH_43_PFE_PHY_DEV_MII45_MAX))
        {
            (void)Det_ReportError ( \
                (uint8) ETH_43_PFE_MODULE_ID, \
                ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_READMII45, \
                ETH_43_PFE_E_INV_PARAM \
                                  );
        }
        else
        {
            if(NULL_PTR == pu16RegValPtr)
            {
                (void)Det_ReportError ( \
                        (uint8) ETH_43_PFE_MODULE_ID, \
                        ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                        ETH_43_PFE_SID_READMII45, ETH_43_PFE_E_PARAM_POINTER \
                                      );
            }
            else
            {
                if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
                {
                    (void)Det_ReportError ( \
                            (uint8) ETH_43_PFE_MODULE_ID, \
                            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
                            ETH_43_PFE_SID_READMII45, ETH_43_PFE_E_UNINIT \
                                          );
                }
                else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
                {
                    eReturnStatus = Eth_43_PFE_LLD_ReadMii45(u8CtrlIdx, u8TrcvIdx, u8DevIdx, u16RegIdx, pu16RegValPtr);
                    if((Std_ReturnType)E_OK == eReturnStatus)
                    {
                        /*  No indication to EthTrcv due to API incompatibility (u16RegIdx Vs u8RegIdx) */
                        ;
                    }
                }
#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
            }
        }
    }
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */

    return eReturnStatus;
}

#endif /* STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API */
#endif /* STD_ON == ETH_43_PFE_CTRLENABLE_MII */

#if STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT
/*================================================================================================*/
/**
 * @brief       Set the global time for the EMAC corresponding to provided controller index
 * @details     If option @ref IEEE1588ClockAttachedToGMAC or @ref IEEE1588ClockAttachedToEMAC0
 *              is enabled for underlying EMAC, this function will fail.
 * @api
 * @param[in]   u8CtrlIdx Index of the controller within the context of the Ethernet Driver
 * @param[in]   timeStampPtr Struct of time value to be configured
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_SetGlobalTime(uint8 u8CtrlIdx, const Eth_TimeStampType *timeStampPtr)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    uint8 DetectedError = (uint8)E_OK;

    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        DetectedError = ETH_43_PFE_E_INV_CTRL_IDX;
    }
    else if(NULL_PTR == timeStampPtr)
    {
        DetectedError = ETH_43_PFE_E_PARAM_POINTER;
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        DetectedError = ETH_43_PFE_E_UNINIT;
    }
    else
    {
        /* This statement is written to avoid MISRA 15.7 */
    }

    if ((uint8)E_OK != DetectedError)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_SETGLOBALTIME, DetectedError \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_SetGlobalTime(u8CtrlIdx, timeStampPtr);
    }

    return eReturnStatus;
}
/*================================================================================================*/

/**
* @brief        Allows the Time Slave to adjust the local ETH Reference clock in HW.
* @details      Only use this function when this controller is used as Time Slave.
*               If option @ref IEEE1588ClockAttachedToGMAC or @ref IEEE1588ClockAttachedToEMAC0
*               is enabled for underlying EMAC, this function will fail.
* @param[in]    u8CtrlIdx       Index of the controller which time shall be corrected
* @param[in]    timeOffsetPtr   Offset between time stamp grandmaster and time stamp by local clock.
* @param[in]    rateRatioPtr    Time elements to calculate and to modify the ratio of the frequency
*               of the grandmaster in relation to the frequency of the Local Clock.
*/
Std_ReturnType Eth_43_PFE_SetCorrectionTime (   uint8 u8CtrlIdx, \
                                                const Eth_TimeIntDiffType *timeOffsetPtr, \
                                                const Eth_RateRatioType *rateRatioPtr \
                                            )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    uint8 DetectedError = (uint8)E_OK;

    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        DetectedError = ETH_43_PFE_E_INV_CTRL_IDX;
    }
    else if((NULL_PTR == timeOffsetPtr) || (NULL_PTR == rateRatioPtr))
    {
        DetectedError = ETH_43_PFE_E_PARAM_POINTER;
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        DetectedError = ETH_43_PFE_E_UNINIT;
    }
    else
    {
        /* This statement is written to avoid MISRA 15.7 */
    }

    if ((uint8)E_OK != DetectedError)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_SETCORRECTIONTIME, DetectedError \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_SetCorrectionTime(u8CtrlIdx, timeOffsetPtr, rateRatioPtr);
    }

    return eReturnStatus;
}

/*================================================================================================*/

/**
 * @brief       Get the global time from the EMAC corresponding to provided controller index
 * @api
 * @param[in]   u8CtrlIdx Index of the controller within the context of the Ethernet Driver
 * @param[out]  timeQualPtr Pointer to quality of HW time stamp
 * @param[out]  timeStampPtr Struct of time value to be read
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_GetCurrentTime( uint8 u8CtrlIdx, \
                                          Eth_TimeStampQualType *timeQualPtr, \
                                          Eth_TimeStampType *timeStampPtr \
                                        )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    uint8 DetectedError = (uint8)E_OK;

    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        DetectedError = ETH_43_PFE_E_INV_CTRL_IDX;
    }
    else if((NULL_PTR == timeQualPtr) || (NULL_PTR == timeStampPtr))
    {
        DetectedError = ETH_43_PFE_E_PARAM_POINTER;
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        DetectedError = ETH_43_PFE_E_UNINIT;
    }
    else
    {
        /* This statement is written to avoid MISRA 15.7 */
    }

    if ((uint8)E_OK != DetectedError)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_GETCURRENTTIME, DetectedError \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        *timeQualPtr = ETH_UNCERTAIN;
        Eth_43_PFE_LLD_GetCurrentTime(u8CtrlIdx, timeQualPtr, timeStampPtr);

        if (ETH_VALID == *timeQualPtr)
        {
            eReturnStatus = (Std_ReturnType)E_OK;
        }
    }

    return eReturnStatus;
}

/*================================================================================================*/

/**
 * @brief       Activate egress time stamping on a dedicated message object
 * @api
 * @param[in]   u8CtrlIdx Index of the controller within the context of the Ethernet Driver
 * @param[in]   BufIdx Index of the buffer resource to be used
 */
void Eth_43_PFE_EnableEgressTimeStamp(uint8 u8CtrlIdx, Eth_BufIdxType BufIdx)
{
#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    uint8 DetectedError = (uint8)E_OK;

    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        DetectedError = ETH_43_PFE_E_INV_CTRL_IDX;
    }
    else if(BufIdx >= ETH_43_PFE_MAX_CTRL_TX_BUF_CNT)
    {
        DetectedError = ETH_43_PFE_E_INV_PARAM;
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        DetectedError = ETH_43_PFE_E_UNINIT;
    }
    else
    {
        /* This statement is written to avoid MISRA 15.7 */
    }

    if ((uint8)E_OK != DetectedError)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_ENABLEEGRESSTIMESTAMP, DetectedError \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        Eth_43_PFE_LLD_EnableEgressTimeStamp(u8CtrlIdx, BufIdx);
    }
}

/*================================================================================================*/

/**
 * @brief       Get the egress time stamp of the last packet sending from certain controller
 * @api
 * @param[in]   u8CtrlIdx Index of the controller within the context of the Ethernet Driver
 * @param[in]   BufIdx    Index of the buffer resource was used to be transmitted
 * @param[out]  timeQualPtr Pointer to quality of HW time stamp
 * @param[out]  timeStampPtr Struct of time value to be read
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_GetEgressTimeStamp(   uint8 u8CtrlIdx, \
                                                Eth_BufIdxType BufIdx, \
                                                Eth_TimeStampQualType *timeQualPtr, \
                                                Eth_TimeStampType *timeStampPtr \
                                            )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    uint8 DetectedError = (uint8)E_OK;

    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        DetectedError = ETH_43_PFE_E_INV_CTRL_IDX;
    }
    else if((NULL_PTR == timeQualPtr) || (NULL_PTR == timeStampPtr))
    {
        DetectedError = ETH_43_PFE_E_PARAM_POINTER;
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        DetectedError = ETH_43_PFE_E_UNINIT;
    }
    else
    {
        /* This statement is written to avoid MISRA 15.7 */
    }

    if ((uint8)E_OK != DetectedError)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_GETEGRESSTIMESTAMP, DetectedError \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        *timeQualPtr = ETH_UNCERTAIN;
        Eth_43_PFE_LLD_GetTxTimeStamp(u8CtrlIdx, BufIdx, timeQualPtr, timeStampPtr);

        if (ETH_VALID == *timeQualPtr)
        {
            eReturnStatus = (Std_ReturnType)E_OK;
        }
    }

    return eReturnStatus;
}

/*================================================================================================*/

/**
 * @brief       Get the ingress time stamp of the received packet
 * @api
 * @param[in]   u8CtrlIdx Index of the controller within the context of the Ethernet Driver
 * @param[in]   DataPtr   Pointer to the received packet
 * @param[out]  timeQualPtr Pointer to quality of HW time stamp
 * @param[out]  timeStampPtr Struct of time value to be read
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_GetIngressTimeStamp   (   uint8 u8CtrlIdx, \
                                                    const Eth_DataType *DataPtr, \
                                                    Eth_TimeStampQualType *timeQualPtr, \
                                                    Eth_TimeStampType *timeStampPtr \
                                                )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    uint8 DetectedError = (uint8)E_OK;

    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        DetectedError = ETH_43_PFE_E_INV_CTRL_IDX;
    }
    else if((NULL_PTR == DataPtr) || (NULL_PTR == timeQualPtr) || (NULL_PTR == timeStampPtr))
    {
        DetectedError = ETH_43_PFE_E_PARAM_POINTER;
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        DetectedError = ETH_43_PFE_E_UNINIT;
    }
    else
    {
        /* This statement is written to avoid MISRA 15.7 */
    }

    if ((uint8)E_OK != DetectedError)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) \
            ETH_43_PFE_SID_GETINGRESSTIMESTAMP, DetectedError \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        *timeQualPtr = ETH_UNCERTAIN;
        (void)Eth_43_PFE_LLD_GetRxTimeStamp(u8CtrlIdx, DataPtr, timeQualPtr, timeStampPtr);

        if (ETH_VALID == *timeQualPtr)
        {
            eReturnStatus = (Std_ReturnType)E_OK;
        }
    }

    return eReturnStatus;
}
#endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */

/* Can be used to export the pfe_platform instance, which might be needed by external (slave) HIF driver */
void * Eth_43_PFE_GetPlatform(void)
{
    return Eth_PFE_LLD_GetPlatform();
}

/* Should be used to initialize pfe interfaces */
void Eth_43_PFE_PreInit(const Eth_43_PFE_ConfigType * CfgPtr)
{

#if STD_ON == ETH_43_PFE_DEV_ERROR_DETECT
#if STD_ON == ETH_43_PFE_PRECOMPILE_SUPPORT
    if(NULL_PTR != CfgPtr)
#else
    if(NULL_PTR == CfgPtr)
#endif /* ETH_43_PFE_PRECOMPILE_SUPPORT */
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, (uint8) ETH_43_PFE_SID_PREINIT, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else
#endif /* ETH_43_PFE_DEV_ERROR_DETECT  */
    {
        #if STD_ON == ETH_43_PFE_PRECOMPILE_SUPPORT
            Eth_43_PFE_InternalCfgPtr = &Eth_43_PFE_Config;
            (void)CfgPtr;
        #else
            Eth_43_PFE_InternalCfgPtr = CfgPtr;
        #endif /* ETH_43_PFE_PRECOMPILE_SUPPORT */

        /* Initialize interfaces */
        Local_Macro_Eth_PFE_LLD_InitInterfaces(Eth_43_PFE_InternalCfgPtr);
        Local_Macro_Eth_PFE_LLD_InitEMACs(Eth_43_PFE_InternalCfgPtr);
    }
}

#if STD_ON == ETH_43_GET_CLASS_STATISTIC_API
/**
 * @brief       Get class statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @retval      E_OK Success
 * @retval      E_NOT_OK Not possible to allocate memory for read
 */
Std_ReturnType Eth_43_PFE_GetClassStats(pfe_ct_classify_stats_t * stat)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETCLASSSTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETCLASSSTATS, \
            ETH_43_PFE_E_UNINIT \
                              ); 
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetClassStats(stat);
    }
    return eReturnStatus;
}
#endif /* ETH_43_GET_CLASS_STATISTIC_API */

#if STD_ON == ETH_43_GET_PFE_STATISTIC_API
/**
 * @brief       Get bmu statistics from firmware
 * @api
 * @param[in]   u8BmuIndex  Bmu instance
 * @param[out]  stat Statistic structure
 * @retval      E_OK If possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_GetBmuStats(uint8 u8BmuIndex, Eth_43_PFE_BmuStatsType* stat)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETBMUSTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (PFE_BMU_INSTANCES <= u8BmuIndex)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETBMUSTATS, \
            ETH_43_PFE_E_INV_PARAM \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETBMUSTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetBmuStats(u8BmuIndex, stat);
    }
    return eReturnStatus;
}

/**
 * @brief       Get gpi statistics from firmware
 * @param[in]   u8GpiIndex  Gpi instance
 * @param[out]  stat Statistic structure
 * @retval      E_OK If possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_GetGpiStats(uint8 u8GpiIndex, Eth_43_PFE_GpiStatsType* stat)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETGPISTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (PFE_GPI_INSTANCES <= u8GpiIndex)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETGPISTATS, \
            ETH_43_PFE_E_INV_PARAM \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETGPISTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetGpiStats(u8GpiIndex, stat);
    }
    return eReturnStatus;
}

/**
 * @brief       Get wdt statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @retval      E_OK If possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_GetWdtStats(Eth_43_PFE_WdtStatsType * stat)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETWDTSTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETWDTSTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetWdtStats(stat);
    }
    return eReturnStatus;
}

/**
 * @brief       Get l2 bridge statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @retval      E_OK If possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_GetL2BridgeStats(Eth_43_PFE_L2BridgeStatsType * stat, uint32 index_entry)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETL2BRIDGESTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETL2BRIDGESTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetL2BridgeStats(stat, index_entry);
    }
    return eReturnStatus;
}

/**
 * @brief       Get l2 bridge statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @param[in]  index_vlan index of vlan
 * @retval      E_OK If possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_GetL2BridgeDomainStats(pfe_ct_vlan_stats_t* stat, uint32 index_vlan)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETL2BRIDGEDOMAINSTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETL2BRIDGEDOMAINSTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetL2BridgeDomainStats(stat, (uint8)(index_vlan & UINT8_MAX));
    }
    return eReturnStatus;
}

/**
 * @brief       Get rtable statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @param[out]  conntrack_index conntrack index
 * @retval      EOK If possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_GetRtableStats(pfe_ct_conntrack_stats_t * stat, uint8 conntrack_index)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETRTABLESTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETRTABLESTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetRtableStats(stat, conntrack_index);
    }
    return eReturnStatus;
}

/**
 * @brief       Get tmu statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @retval      EOK If possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_GetTmuStats(Eth_43_PFE_TmuStatsType * stat)
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if (NULL_PTR == stat)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTMUSTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else if (FALSE == Eth_PFE_LLD_Check_Driver_Init())
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTMUSTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_43_PFE_LLD_GetTmuStats(stat);
    }
    return eReturnStatus;
}
#endif /* ETH_43_GET_PFE_STATISTIC_API */

#if STD_ON == ETH_43_GET_COUNTER_API
/**
* @brief         Reads a list with drop counter values of the corresponding controller.
* @api
* @param[in]     u8CtrlIdx  Index of the controller
* @param[out]    CounterPtr Pointer to Eth_CounterType where to store the read drop counter values
* @return        Error status
* @retval        E_OK No error was detected during the function execution.
* @retval        E_NOT_OK Development error was detected or inaccessible to counters register
*                and the function.
* @details       Reads a list with drop counter values of the corresponding controller. The meaning
*                of these values is hardware dependent. However, the list DropCount[] shall
*                contain the following values in the given order, where the maximal possible value
*                shall denote an invalid value, e.g. if this counter is not available:
*                1. Dropped packets due to buffer overrun
*                2. Dropped packets due to CRC errors
*                3. Number of undersize packets which were less than 64 octets long (excluding
*                framing bits, but including FCS octets) and were otherwise will formed. (see IETF
*                RFC 1757)
*                4. Number of oversize packets which are longer than 1518 octets (excluding
*                framing bits, but including FCS octets) and were otherwise well formed. (see IETF
*                RFC 1757)
*                5. Number of alignment errors, i.e. packets which are received and are not an
*                integral number of octets in length and do not pass the CRC.
*                6. SQE test error according to IETF RFC1643 dot3StatsSQETestErrors
*                7. The number of inbound packets which were chosen to be discarded even
*                though no errors had been detected to prevent their being deliverable to a higher layer protocol.
*                One possible reason for discarding such a packet could be to free
*                up buffer space. (see IETF RFC 2233 ifInDiscards)
*                8. Total number of erroneous inbound packets
*                9. The number of outbound packets which were chosen to be discarded even
*                though no errors had been detected to prevent their being transmitted. One
*                possible reason for discarding such a packet could be to free up buffer space.
*                (see IETF RFC 2233 ifOutDiscards)
*                10. Total number of erroneous outbound packets
*                11. Single collision frames: A count of successfully transmitted frames on a
*                particular interface for which transmission is inhibited by exactly one collision. (see
*                IETF RFC1643 dot3StatsSingleCollisionFrames)
*                12. Multiple collision frames: A count of successfully transmitted frames on a
*                particular interface for which transmission is inhibited by more than one collision.
*                (see IETF RFC1643 dot3StatsMultipleCollisionFrames)
*                13. Number of deferred transmission: A count of frames for which the first
*                transmission attempt on a particular interface is delayed because the medium is
*                busy. (see IETF RFC1643 dot3StatsDeferredTransmissions)
*                14. Number of late collisions: The number of times that a collision is detected on
*                a particular interface later than 512 bit times into the transmission of a packet.
*                (see IETF RFC1643 dot3StatsLateCollisions)
*                15. The following positions in the list can contain hardware dependent counter
*                values
* implements     Eth_GetCounterValues_Activity
*/
Std_ReturnType Eth_43_PFE_GetCounterValues(uint8 u8CtrlIdx, \
                                            Eth_CounterType * CounterPtr
                                        )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETCOUNTERVALUE, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETCOUNTERVALUE, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else if (NULL_PTR == CounterPtr)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETCOUNTERVALUE, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_PFE_LLD_GetCounterValues(u8CtrlIdx, CounterPtr);
    }

    return eReturnStatus;
}
#endif /* STD_ON == ETH_43_GET_COUNTER_API */

#if STD_ON == ETH_43_GET_RXSTATS_API
/**
* @brief         Read the status of a controller
* @details       Returns the following list according to IETF RFC2819, where the maximal possible
*                value shall denote an invalid value, e.g. if this counter is not available:
*                1. etherStatsDropEvents
*                2. etherStatsOctets
*                3. etherStatsPkts
*                4. etherStatsBroadcastPkts
*                5. etherStatsMulticastPkts
*                6. etherStatsCrcAlignErrors
*                7. etherStatsUndersizePkts
*                8. etherStatsOversizePkts
*                9. etherStatsFragments
*                10. etherStatsJabbers
*                11. etherStatsCollisions
*                12. etherStatsPkts64Octets
*                13. etherStatsPkts65to127Octets
*                14. etherStatsPkts128to255Octets
*                15. etherStatsPkts256to511Octets
*                16. etherStatsPkts512to1023Octets
*                17. etherStatsPkts1024to1518Octets
* @api
* @param[in]     CtrlIdx Index of the controller which shall be read the status register.
* @param[out]    RxStatsPtr Pointer to 32 bit long memory space to be filled with
*                the list values according to IETF RFC 2819 (Remote Network
*                Monitoring Management Information Base).
* @return        Error status
* @retval        E_OK No error was detected during the function execution.
* @retval        E_NOT_OK Development error was detected or inaccessible to counters register
*                and the function.
* implements     Eth_GetRxStats_Activity
*/
Std_ReturnType Eth_43_PFE_GetRxStats(uint8 u8CtrlIdx, \
                                            Eth_RxStatsType * RxStatsPtr
                                        )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETRXSTATS, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETRXSTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else if (NULL_PTR == RxStatsPtr)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETRXSTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_PFE_LLD_GetRxStats(u8CtrlIdx, RxStatsPtr);
    }

    return eReturnStatus;
}
#endif /* STD_ON == ETH_43_GET_RXSTATS_API */

#if STD_ON == ETH_43_GET_TXSTATS_API
/**
* @brief         Return the list of Transmission Statistics.
* @param[in]     CtrlIdx Index of controller within the context of the Ethernet Driver.
* @param[out]    TxStatsPtr Pointer to 32 bit long memory space to be filled with
*                the list values according to IETF RFC 1213
* @details       Return the list of Transmission Statistics out of IETF RFC 1213
*                defined within Eth_TxStatsType, where the maximal possible value shall
*                denote an invalid value.
*                e.g. this counter is not available..
* @return        The search status
* @retval        E_OK Success
* @retval        E_NOT_OK Tx-statistics could not be obtained.
* implements     Eth_GetTxStats_Activity
*/
Std_ReturnType Eth_43_PFE_GetTxStats(uint8 u8CtrlIdx, \
                                            Eth_TxStatsType * TxStatsPtr
                                        )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTXSTATS, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTXSTATS, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else if (NULL_PTR == TxStatsPtr)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTXSTATS, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_PFE_LLD_GetTxStats(u8CtrlIdx, TxStatsPtr);
    }

    return eReturnStatus;
}
#endif /* STD_ON == ETH_43_GET_TXSTATS_API */

#if STD_ON == ETH_43_GET_TXERROR_COUNTER_API
/**
* @brief         Return the list of Transmission Statistics.
* @param[in]     CtrlIdx Index of controller within the context of the Ethernet Driver.
* @param[out]    TxErrorCounterValuesPtr List of values to read statistic error counter values for transmission.
* @details       Return the list of Transmission Error Counters out of IETF RFC1213 and RFC1643
*                defined within Eth_TxErrorCounterValuesType, where the maximal possible value shall
*                denote an invalid value.
*                e.g. this counter is not available.
* @return        The search status
* @retval        E_OK Success
* @retval        E_NOT_OK Tx-statistics could not be obtained.
* implements     Eth_GetTxErrorCounterValues_Activity
*/
Std_ReturnType Eth_43_PFE_GetTxErrorCounterValues(uint8 u8CtrlIdx, \
                                            Eth_TxErrorCounterValuesType * TxErrorCounterValuesPtr
                                        )
{
    Std_ReturnType eReturnStatus = (Std_ReturnType)E_NOT_OK;

#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
    if(u8CtrlIdx >= (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTXERRORCOUNTERVALUE, \
            ETH_43_PFE_E_INV_CTRL_IDX \
                              );
    }
    else if(ETH_STATE_INIT != Eth_43_PFE_CtrlState[u8CtrlIdx])
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTXERRORCOUNTERVALUE, \
            ETH_43_PFE_E_UNINIT \
                              );
    }
    else if (NULL_PTR == TxErrorCounterValuesPtr)
    {
        (void)Det_ReportError ( \
            (uint8) ETH_43_PFE_MODULE_ID, \
            ETH_43_PFE_DRIVER_INSTANCE, \
            (uint8) ETH_43_PFE_SID_GETTXERRORCOUNTERVALUE, \
            ETH_43_PFE_E_PARAM_POINTER \
                              );
    }
    else
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
    {
        eReturnStatus = Eth_PFE_LLD_GetTxErrorCounterValues(u8CtrlIdx, TxErrorCounterValuesPtr);
    }

    return eReturnStatus;
}
#endif /* STD_ON == ETH_43_GET_TXERROR_COUNTER_API */

#if (STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER)
/**
 * @brief       Disables a HIF channel and flushes its cached RX BDs
 * @details     The function is intended for assisting a slave driver to recover from crash. It:
 *              - disables the HIF channel, so it will no longer receive normal traffic,
 *              - flushes cached Rx buffer descriptors from the HIF channel. During this process
 *                the PFE HW needs write access to buffers and buffer descriptor memory which was previously
 *                configured by the crashed driver.
 * @note        This function can only be used for HIF channel of a slave driver which is no longer running.
 * @note        This function is available only on master driver, only if option 
 *              "Enable PFE Channel BD Flush API" is enabled.
 * @param[in]   DestHifChnl Physical interface ID of the HIF used by the slave driver which has crashed.
 * @retval      E_OK Flushing was successfull and is complete
 * @retval      E_NOT_OK Flushing has failed
 * @retval      ETH_43_PFE_E_AGAIN Another call of this function is needed to continue the flush 
 *              (due to limit configured in option PfeChannelBdFlushMaxBdCount)
 */
Std_ReturnType Eth_43_PFE_ChannelBdFlushRx(pfe_ct_phy_if_id_t DestHifChnl)
{
    Std_ReturnType eReturnStatus;
    eReturnStatus = Eth_PFE_LLD_ChannelBdFlushRx(DestHifChnl);
    return eReturnStatus;
}
#endif /* STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#ifdef __cplusplus
}
#endif
/** @} */


===== 文件 [102/185]: src\Eth_43_PFE_Irq.c =====
/**
 *  @file    Eth_43_PFE_Irq.c
 *
 *  @brief    AUTOSAR Eth driver interrupt handlers
 *  @details  Implementation of interrupt handling routines for the Ethernet
 *            Driver.
 *
 *  @addtogroup ETH_43_PFE_DRIVER
 *  @{
 */
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  (c) Copyright 2006-2016 Freescale Semiconductor, Inc.
 *      Copyright 2017-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/

#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "Eth_43_PFE.h" /* Includes also Eth_GeneralTypes.h, Eth_43_PFE_Cfg.h,
                    Eth_43_PFE_ComStack_Types.h, Dem.h, Det.h and Mcal.h */
#include "Eth_PFE_LLD.h"     /* LowLevelDriver API */
#include "Eth_43_PFE_Irq.h"     /* Own interface */
#include "oal_irq.h"            /* Callbacks */
#include "pfe_cbus.h"
#include "pfe_hif_csr.h"
#include "pfe_hif_nocpy_csr.h"
#include "pfe_bmu_csr.h"

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define ETH_AR_RELEASE_MAJOR_VERSION_C       4
#define ETH_AR_RELEASE_MINOR_VERSION_C       4

/*==================================================================================================
*                                     FILE VERSION CHECKS
==================================================================================================*/
#if STD_ON == ETH_43_PFE_DEM_EVENT_DETECT
    #ifndef DISABLE_MCAL_INTERMODULE_ASR_CHECK
        /* Check if current file and Dem header file are of the same version */
        #if ((ETH_AR_RELEASE_MAJOR_VERSION_C != DEM_AR_RELEASE_MAJOR_VERSION) || \
             (ETH_AR_RELEASE_MINOR_VERSION_C != DEM_AR_RELEASE_MINOR_VERSION))
            #error "AutoSar Version Numbers of Eth_43_PFE_Irq.c and Dem.h are different"
        #endif
    #endif /* DISABLE_MCAL_INTERMODULE_ASR_CHECK */
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

#ifndef DISABLE_MCAL_INTERMODULE_ASR_CHECK
    /* Check if current file and DET header file are of the same version */
    #if (ETH_43_PFE_DEV_ERROR_DETECT == STD_ON)
        #if ((ETH_AR_RELEASE_MAJOR_VERSION_C != DET_AR_RELEASE_MAJOR_VERSION) || \
             (ETH_AR_RELEASE_MINOR_VERSION_C != DET_AR_RELEASE_MINOR_VERSION))
            #error "AutoSar Version Numbers of Eth_43_PFE_Irq.c and Det.h are different"
        #endif
    #endif
#endif /* DISABLE_MCAL_INTERMODULE_ASR_CHECK */

/*==================================================================================================
*                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/


/*==================================================================================================
*                                       LOCAL MACROS
==================================================================================================*/


/*==================================================================================================
*                                      LOCAL CONSTANTS
==================================================================================================*/
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
#define ETH_43_PFE_START_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"
static const addr_t cbus_hif_int_en_var_addr[5] = 
{
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_EN(0),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_EN(1),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_EN(2),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_EN(3),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_NOCPY_BASE_ADDR + HIF_NOCPY_INT_EN
};

static const addr_t cbus_hif_int_src_var_addr[5] = 
{
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_SRC(0),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_SRC(1),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_SRC(2),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR + HIF_CHn_INT_SRC(3),
    PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_NOCPY_BASE_ADDR + HIF_NOCPY_INT_SRC
};
#define ETH_43_PFE_STOP_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"
#endif

/*==================================================================================================
*                                      LOCAL VARIABLES
==================================================================================================*/


/*==================================================================================================
*                                      GLOBAL CONSTANTS
==================================================================================================*/


/*==================================================================================================
*                                      GLOBAL VARIABLES
==================================================================================================*/


/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#if ((TRUE == PFE_CFG_HIF_IRQ_ENABLED) || (TRUE == PFE_CFG_BMU_IRQ_ENABLED))
static inline bool_t oal_irq_check_driver_init_status(void);
#endif
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
static inline bool_t oal_irq_detect_hif_spurious_interrupt(oal_irq_idx_t idx);
static inline void oal_irq_clear_hif_interrupt_status_flag(const addr_t int_src_var_addr);
#endif
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
static inline void oal_irq_detect_handle_bmu_spurious_interrupt(bool_t *bDetectSpuriousIsrBmu1, bool_t *bDetectSpuriousIsrBmu2);
static inline void oal_irq_clear_bmu_interrupt_status_flag(void);
#endif

/*==================================================================================================
*                                       LOCAL FUNCTIONS
==================================================================================================*/
#if ((TRUE == PFE_CFG_HIF_IRQ_ENABLED) || (TRUE == PFE_CFG_BMU_IRQ_ENABLED))
static inline bool_t oal_irq_check_driver_init_status(void)
{/* HIS_COMF check suppression comment */
    const bool_t init_status = (Eth_PFE_LLD_bIrqInitStatus != (boolean)FALSE) ? TRUE : FALSE;
    return init_status;
}
#endif

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
/* Check whether hif interrupts are spurious interrupts or not */
static inline bool_t oal_irq_detect_hif_spurious_interrupt(oal_irq_idx_t idx)
{
    bool_t bRet = FALSE;
    uint32 int_en;
    uint32 int_src;

    int_en = hal_read32(cbus_hif_int_en_var_addr[idx]);
    int_src = hal_read32(cbus_hif_int_src_var_addr[idx]);

    if (0U == (int_en & int_src))
    {
        bRet = TRUE;
    }
    return bRet;
}

/* Clear interrupt status flag for hif */
static inline void oal_irq_clear_hif_interrupt_status_flag(const addr_t int_src_var_addr)
{
    uint32 interrupt_src;

    /* Get interrupt status flag */
    interrupt_src = hal_read32(int_src_var_addr);
    /* Write 1 to clear */
    hal_write32(interrupt_src, int_src_var_addr);
}
#endif

#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
/* Check whether the bmu interrupts are spurious interrupts or not.
   If spurious interrupts are detected, interrupt status flags will be cleared */
static inline void oal_irq_detect_handle_bmu_spurious_interrupt(bool_t *bDetectSpuriousIsrBmu1, bool_t *bDetectSpuriousIsrBmu2)
{
    uint32 int_en;
    uint32 int_src;

    int_en = hal_read32(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU1_BASE_ADDR + BMU_INT_ENABLE);
    int_src = hal_read32(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU1_BASE_ADDR + BMU_INT_SRC);
    if (0U == (int_en & int_src))
    {
        /* Write 1 to clear */
        hal_write32(int_src, PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU1_BASE_ADDR + BMU_INT_SRC);
        *bDetectSpuriousIsrBmu1 = TRUE;
    }

    int_en = hal_read32(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU2_BASE_ADDR + BMU_INT_ENABLE);
    int_src = hal_read32(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU2_BASE_ADDR + BMU_INT_SRC);
    if (0U == (int_en & int_src))
    {
        /* Write 1 to clear */
        hal_write32(int_src, PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU2_BASE_ADDR + BMU_INT_SRC);
        *bDetectSpuriousIsrBmu2 = TRUE;
    }
}

/* Clear interrupt status flag for bmu */
static inline void oal_irq_clear_bmu_interrupt_status_flag(void)
{
    uint32 interrupt_src;

    /* Get triggered interrupts of bmu1 */
    interrupt_src = hal_read32(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU1_BASE_ADDR + BMU_INT_SRC);
    /* Write 1 to clear */
    hal_write32(interrupt_src, PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU1_BASE_ADDR + BMU_INT_SRC);
    /* Get triggered interrupts of bmu2 */
    interrupt_src = hal_read32(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU2_BASE_ADDR + BMU_INT_SRC);
    /* Write 1 to clear */
    hal_write32(interrupt_src, PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_BMU2_BASE_ADDR + BMU_INT_SRC);
}
#endif

/*==================================================================================================
*                                       GLOBAL FUNCTIONS
==================================================================================================*/
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
/* Either put these handlers to HW vector table or call from AUTOSAR OS ISR handlers */
/**
* @brief        Interrupt handler for HIF0 channel IRQ
* @details      This interrupt is shared between all interfaces that are connected through HIF0.
*               It handles both received frames and Tx confirmations. Also it should handle
*               all other channel interrupts (out of buffers, high Rx watermark), which is not
*               supported in this version.
* @note         In current version this interrupt must be enabled, otherwise receptions and Tx
*               confirmations will not work. This limitation will be removed in next versions.
*/
#if (TRUE == ETH_43_PFE_USINGHIF0)
ISR(Eth_43_PFE_HifIrqHdlr_0)
{
    bool_t bDriverInitStatus;

    bDriverInitStatus = oal_irq_check_driver_init_status();

    if (TRUE == bDriverInitStatus)
    {
        if (FALSE == oal_irq_detect_hif_spurious_interrupt(Eth_43_PFE_IRQ_IDX_HIF0))
        {
            oal_irq_common_handler(Eth_43_PFE_IRQ_IDX_HIF0);
        }
        else
        {
            /* If the spurious interrupt is detected, the ISR shall only clear interrupt status flag and return immediately */
            oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF0]);
        }
    }
    else
    {
        /* If the driver was not initialized, the ISR shall only clear interrupt status flag and return immediately */
        oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF0]);
    }
}
#endif /* ETH_43_PFE_USINGHIF0 */
#if (TRUE == ETH_43_PFE_USINGHIF1)
ISR(Eth_43_PFE_HifIrqHdlr_1)
{
    bool_t bDriverInitStatus;

    bDriverInitStatus = oal_irq_check_driver_init_status();

    if (TRUE == bDriverInitStatus)
    {
        if (FALSE == oal_irq_detect_hif_spurious_interrupt(Eth_43_PFE_IRQ_IDX_HIF1))
        {
            oal_irq_common_handler(Eth_43_PFE_IRQ_IDX_HIF1);
        }
        else
        {
            /* If the spurious interrupt is detected, the ISR shall only clear interrupt status flag and return immediately */
            oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF1]);
        }
    }
    else
    {
        /* If the driver was not initialized, the ISR shall only clear interrupt status flag and return immediately */
        oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF1]);
    }
}
#endif /* ETH_43_PFE_USINGHIF1 */
#if (TRUE == ETH_43_PFE_USINGHIF2)
ISR(Eth_43_PFE_HifIrqHdlr_2)
{
    bool_t bDriverInitStatus;

    bDriverInitStatus = oal_irq_check_driver_init_status();

    if (TRUE == bDriverInitStatus)
    {
        if (FALSE == oal_irq_detect_hif_spurious_interrupt(Eth_43_PFE_IRQ_IDX_HIF2))
        {
            oal_irq_common_handler(Eth_43_PFE_IRQ_IDX_HIF2);
        }
        else
        {
            /* If the spurious interrupt is detected, the ISR shall only clear interrupt status flag and return immediately */
            oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF2]);
        }
    }
    else
    {
        /* If the driver was not initialized, the ISR shall only clear interrupt status flag and return immediately */
        oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF2]);
    }
}
#endif /* ETH_43_PFE_USINGHIF2 */
#if (TRUE == ETH_43_PFE_USINGHIF3)
ISR(Eth_43_PFE_HifIrqHdlr_3)
{
    bool_t bDriverInitStatus;

    bDriverInitStatus = oal_irq_check_driver_init_status();

    if (TRUE == bDriverInitStatus)
    {
        if (FALSE == oal_irq_detect_hif_spurious_interrupt(Eth_43_PFE_IRQ_IDX_HIF3))
        {
            oal_irq_common_handler(Eth_43_PFE_IRQ_IDX_HIF3);
        }
        else
        {
            /* If the spurious interrupt is detected, the ISR shall only clear interrupt status flag and return immediately */
            oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF3]);
        }
    }
    else
    {
        /* If the driver was not initialized, the ISR shall only clear interrupt status flag and return immediately */
        oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIF3]);
    }
}
#endif /* ETH_43_PFE_USINGHIF3 */
#if (TRUE == ETH_43_PFE_USINGHIF_NOCPY)
ISR(Eth_43_PFE_HifNoCpyIrqHdlr)
{
    bool_t bDriverInitStatus;

    bDriverInitStatus = oal_irq_check_driver_init_status();

    if (TRUE == bDriverInitStatus)
    {
        if (FALSE == oal_irq_detect_hif_spurious_interrupt(Eth_43_PFE_IRQ_IDX_HIFNOCPY))
        {
            oal_irq_common_handler(Eth_43_PFE_IRQ_IDX_HIFNOCPY);
        }
        else
        {
            /* If the spurious interrupt is detected, the ISR shall only clear interrupt status flag and return immediately */
            oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIFNOCPY]);
        }
    }
    else
    {
        /* If the driver was not initialized, the ISR shall only clear interrupt status flag and return immediately */
        oal_irq_clear_hif_interrupt_status_flag(cbus_hif_int_src_var_addr[Eth_43_PFE_IRQ_IDX_HIFNOCPY]);
    }
}
#endif /* ETH_43_PFE_USINGHIF_NOCPY */
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
/**
* @brief        Interrupt handler for BMUs
* @details      This interrupt is shared between both BMUs.
* @note         In current version this interrupt shall be enabled. An option to disable this
*               interrupt will be added in next versions.
*/
ISR(Eth_43_PFE_BmuIrqHdlr)
{
    bool_t bDriverInitStatus;
    bool_t bDetectSpuriousIsrBmu1 = FALSE;
    bool_t bDetectSpuriousIsrBmu2 = FALSE;

    bDriverInitStatus = oal_irq_check_driver_init_status();

    if (TRUE == bDriverInitStatus)
    {
        oal_irq_detect_handle_bmu_spurious_interrupt(&bDetectSpuriousIsrBmu1, &bDetectSpuriousIsrBmu2);
        if ((FALSE == bDetectSpuriousIsrBmu1) || (FALSE == bDetectSpuriousIsrBmu2))
        {
            oal_irq_common_handler(Eth_43_PFE_IRQ_IDX_BMU);
        }
    }
    else
    {
        if (TRUE == bDetectBmuInit)
        {
            /* If the driver was not initialized and interrupt has not happened from BMU initialization, the ISR shall only clear interrupt status flag and return immediately */
            oal_irq_clear_bmu_interrupt_status_flag();
        }
        else
        {
            /* In case of interrupt occured during BMU initialization, handling interrupt normally */
            oal_irq_common_handler(Eth_43_PFE_IRQ_IDX_BMU);
        }
    }
}
#endif /* PFE_CFG_BMU_IRQ_ENABLED */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
/*================================================================================================*/

#ifdef __cplusplus
}
#endif
/** @} */


===== 文件 [103/185]: src\Eth_PFE_LLD.c =====
/**
*   @file    Eth_PFE_LLD.c
*
*    @brief            Interface between MCAL Eth driver layers and common platform driver for PFE.
*
*   @addtogroup ETH_43_PFE_DRIVER
*   @{
*/
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  (c) Copyright 2006-2016 Freescale Semiconductor, Inc.
 *      Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/

#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "Eth_43_PFE.h" /* Includes also Eth_GeneralTypes.h, Eth_43_PFE_Cfg.h,
                    Eth_43_PFE_ComStack_Types.h, Dem.h, Det.h and Mcal.h */
#include "SchM_Eth_43_PFE.h" /* RTE module header for critical sections protection */

#include "oal.h"
#include "pfe_hif_drv.h"
#include "pfe_hif.h"
#include "pfe_idex.h"
#include "Eth_PFE_LLD.h" /* Own interface */

#include "pfe_platform_cfg.h"
#include "pfe_platform.h" /* Platform driver, includes also all other headers
                             needed for platform driver. */
/* Note Soc_Ips.h is included through Reg_eSys.h - Mcal.h - Eth_43_PFE_Cfg.h - Eth_43_PFE.h */
#include "EthIf_Cbk.h" /* EthIf callbacks to be called from Eth driver */
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_emac_csr.h"
#include "pfe_hif_csr.h"
#include "pfe_tmu_csr.h"
#include "pfe_gpi_csr.h"
#include "pfe_bmu_csr.h"
#include "pfe_global_wsp.h"

#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
    #include "EthSwt.h"
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API */

#if (TRUE == PFE_CFG_SHARED_REG_VIA_MCU)
    #include "Mcu.h"
#endif

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/

#define ETH_AR_RELEASE_MAJOR_VERSION_C       4
#define ETH_AR_RELEASE_MINOR_VERSION_C       4

/*==================================================================================================
*                                     FILE VERSION CHECKS
==================================================================================================*/
#ifndef DISABLE_MCAL_INTERMODULE_ASR_CHECK
    /* Check if current file and StdRegMacros header file are of the same version */
    #if ((ETH_AR_RELEASE_MAJOR_VERSION_C != ETHIF_AR_RELEASE_MAJOR_VERSION) || \
         (ETH_AR_RELEASE_MINOR_VERSION_C != ETHIF_AR_RELEASE_MINOR_VERSION))
        #error "AutoSar Version Numbers of Eth_PFE_LLD.c and EthIf_Cbk.h are different"
    #endif
#endif /* DISABLE_MCAL_INTERMODULE_ASR_CHECK */

/*==================================================================================================
*                                       LOCAL MACROS
==================================================================================================*/
#define DRIVER_COMMIT_HASH      "1063f6712b7dc471e6fb808e6742566c443b61cb"
#define PFE_DRIVER_VERSION      "1.5.0"

/*Size of a descriptor*/
#define HIF_HEADER_SIZE 16U
#define IS_POWER_OF_2(n) ((n) && !((n) & ((n) - 1U)))

/* S32 GPR registers*/
#if defined(PFE_CFG_PFE_MASTER) && (FALSE == PFE_CFG_SHARED_REG_VIA_MCU)
    #define S32G_GPR_BASE                   (0x4007CA00U)
    #define PFE_EMACX_INTF_SEL_OFF          (0x4U)
    #define PFE_EMACX_SET(emac, intf)       ((intf) << (4U * (emac)))
#endif

#define PFE_EMAC_SGMII                  (0U)    /* GMII to Serdes PHY */
#define PFE_EMAC_MII                    (1U)    /* MII to PADs */
#define PFE_EMAC_RGMII                  (2U)    /* RGMII to PADs */
#define PFE_EMAC_RMII                   (9U)    /* RMII to PADs */
#define PFE_INGRESS_MAX_FRAME_SIZE      (1518U) /* Ingress max frame size without vlan tag */

#define HIF_INT_SRC_HIF_ERR_INT             (1UL << 16U)
#define HIF_INT_SRC_HIF_TX_FIFO_ERR_INT     (1UL << 17U)
#define HIF_INT_SRC_HIF_RX_FIFO_ERR_INT     (1UL << 18U)

#define SCH0_ID                 (0U)
#define SCH1_ID                 (1U)
/* Position 9-16 correspond to input 0-7 of Scheduler 0 */
#define SHP_POS_COR_SCH0        {9U, 10U, 11U, 12U, 13U, 14U, 15U, 16U}
/* Position 1-8 correspond to input 0-7 of Scheduler 1 */
#define SHP_POS_COR_SCH1        {1U, 2U, 3U, 4U, 5U, 6U, 7U, 8U}

#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
#define MAX_DEM_FRAME_ERRORS    (ETH_43_PFE_NUMBER_OF_DEM_IDS)
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

#if (STD_ON == ETH_43_PFE_ENABLE_USER_MODE_SUPPORT)
    #define Local_Macro_hal_ip_ready_set(on)    OsIf_Trusted_Call1param(hal_ip_ready_set, (on))
    #define Local_Macro_hal_ip_ready_get()      OsIf_Trusted_Call_Return(hal_ip_ready_get)
#else
    #define Local_Macro_hal_ip_ready_set(on)    hal_ip_ready_set(on)
    #define Local_Macro_hal_ip_ready_get()      hal_ip_ready_get()
#endif

#define INVALID_TX_INDEX 0xFFFFU

/* Buffer status, WAIT_CONF, WAIT_TS and TO_REPORT can be set simultaneously (as in bitfield) */
#define TX_BUF_FREE         0U
#define TX_BUF_PROVIDED     1U
#define TX_BUF_FAILED       2U
#define TX_BUF_WAIT_CONF    4U
#define TX_BUF_WAIT_TS      8U
#define TX_BUF_TO_REPORT    16U

/* Temporary workaround for AAVB-8200 until AAVB-4234 is implemented in FW */
#define IS_RECEIVE_MALFORMED_ALLOWED  ((ETH_43_PFE_ENABLE_OFFLOAD_CSUM_IPV4 != STD_ON) \
                                    || (ETH_43_PFE_ENABLE_OFFLOAD_CSUM_TCP  != STD_ON) \
                                    || (ETH_43_PFE_ENABLE_OFFLOAD_CSUM_UDP  != STD_ON) \
                                    || (ETH_43_PFE_ENABLE_OFFLOAD_CSUM_ICMP != STD_ON))

#define ETHERTYPE_IPV4 0x0800U
#define ETHERTYPE_IPV6 0x86DDU
#define ETH_FRAME_MACDST_IDX     0U
#define ETH_FRAME_MACSRC_IDX     6U
#define ETH_FRAME_ETHERTYPE_IDX 12U
#define ETH_FRAME_PAYLOAD_IDX   14U
#define ETH_FRAME_VLANTAG_LEN_MAX 8U
/*==================================================================================================
*                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/
#ifdef PFE_CFG_PFE_MASTER
/* data shared to ConfigureSchedulerAndShaper callees */
typedef struct 
{
    pfe_ct_phy_if_id_t emac_id;
    const Eth_43_PFE_CtrlCfgType *pcfg;
    boolean is_queue_used[TLITE_PHY_QUEUES_CNT];
    boolean is_input_used[TLITE_SCH_CNT][TLITE_SCH_INPUTS_CNT];
} ConfigureSchedulerAndShaper_StateType;
#endif

/*  This is the driver representation of PFE device */
typedef struct
{
    boolean                 bStarted;
    uint8                   u8CtrlIdx;
    pfe_platform_t          *prPlatform;
    pfe_hif_drv_t           *prHifDrv;
    pfe_hif_chnl_t          *prHifChnl;
    pfe_ct_phy_if_id_t      HifId;
    oal_irq_t               *prHifChnlIRQ;
    pfe_phy_if_t            *prPhyIf;
    pfe_hif_drv_client_t    *prClient;
    pfe_mac_addr_t          au8MacAddr;
    boolean                 bInterfacePrepared;
#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
    Eth_BufIdxType          TSQueue[ETH_43_PFE_MAX_TXFIFO_CNT][ETH_43_PFE_MAX_FIFO_TX_BUF_CNT];
    uint16                  u16TSQueueRead[ETH_43_PFE_MAX_TXFIFO_CNT];
    uint16                  u16TSQueueWrite[ETH_43_PFE_MAX_TXFIFO_CNT];
#endif
} trPfeDev;

typedef struct
{
    addr_t Addr;           /* Where the pool starts in memory */
    uint32 u32Size;        /* Size of the pool in memory */
    uint32 u32BufSize;
    uint16 u16BufNumber;
    uint16 u16IndexOffset; /* Offset between index within this pool and index within controller */
    uint16 u16GetIdx;      /* Where to look for next free buffer (index within this pool) */
} trTxBufPool;

typedef struct
{
    addr_t                  BufAddr;
    uint8                   u8Status;
    uint8                   u8Fifo;
    trTxMeta                rMeta;
#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
    Eth_PFE_LLD_trTxTsRef   rTsRef;
    Eth_TimeStampQualType   TimeQual;
    Eth_TimeStampType       TimeStamp;
#endif
} trTxBufControl;

#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
typedef enum
{
    ETH_43_PFE_E_RX_FRAMES_LOST    = 0U,
    ETH_43_PFE_E_CRC               = 1U,
    ETH_43_PFE_E_UNDERSIZEFRAME    = 2U,
    ETH_43_PFE_E_OVERSIZEFRAME     = 3U,
    ETH_43_PFE_E_ALIGNMENT         = 4U,
    ETH_43_PFE_E_SINGLECOLLISION   = 5U,
    ETH_43_PFE_E_MULTIPLECOLLISION = 6U,
    ETH_43_PFE_E_LATECOLLISION     = 7U,
    ETH_43_PFE_NUMBER_OF_DEM_IDS   = 8U
} ErrorIdType;
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

/*==================================================================================================
*                                     GLOBAL VARIABLES
==================================================================================================*/
#if ((TRUE == PFE_CFG_HIF_IRQ_ENABLED) || (TRUE == PFE_CFG_BMU_IRQ_ENABLED))
/*  Used in ISRs to check whether interrupts were initialized and can be executed.
    The value is based on driver init/deinint progress:
      - in single instance (or master) mode it is set when driver initialization is done
        (just before master-up flag is set),
      - in slave mode it is set after hif driver is initialized, before RPC is needed. 
      - In all modes the value is cleared before the hif driver is destroyed .*/
#define ETH_43_PFE_START_SEC_VAR_CLEARED_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
volatile boolean Eth_PFE_LLD_bIrqInitStatus = FALSE;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
#endif

/*==================================================================================================
*                                      LOCAL CONSTANTS
==================================================================================================*/
#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
#define ETH_43_PFE_START_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"
static const uint32 u32StatId[MAX_DEM_FRAME_ERRORS] =
{
    RX_FIFO_OVERFLOW_PACKETS,
    RX_CRC_ERROR_PACKETS,
    RX_UNDERSIZE_PACKETS_GOOD,
    RX_OVERSIZE_PACKETS_GOOD,
    RX_ALIGNMENT_ERROR_PACKETS,
    TX_SINGLE_COLLISION_GOOD_PACKETS,
    TX_MULTIPLE_COLLISION_GOOD_PACKETS,
    TX_LATE_COLLISION_PACKETS
};
#define ETH_43_PFE_STOP_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

/*==================================================================================================
*                                        LOCAL VARIABLES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"

/*  It should be static, but it is not to avoid issues with memory mapping in some compilers */
VAR_ALIGN(uint8 auTxBufMem[ETH_43_PFE_MAX_TXBUF_POOLSZ], 8U)

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*  Describes buffer memory split to fifos and buffers */
static trTxBufPool aarTxBufPool[ETH_43_PFE_MAXCTRLS_SUPPORTED][ETH_43_PFE_MAX_TXFIFO_CNT];

/*  All runtime information about buffers is collected in this table.
    It is indexed by controller index and buffer index.
    Function Eth_PFE_LLD_ProvideBufferDataArea should get buf index range
    from aarTxBufPool and then search this table for free buffer. */
static trTxBufControl aarTxBuf[ETH_43_PFE_MAXCTRLS_SUPPORTED][ETH_43_PFE_MAX_CTRL_TX_BUF_CNT];

/*  Written sequentially by Transmit, readed sequentially by TxConfirmation
    (releasing based on confirmation from BD, not waiting for timestamps).
    Transmit function will pass pointer to record from this queue as ref_ptr,
    that is why we need to store also the u8CtrlIdx here.  */
Eth_PFE_LLD_trTxRefData arTxReqQueue[ETH_43_PFE_MAXCTRLS_SUPPORTED][ETH_43_PFE_MAX_CTRL_TX_BUF_CNT];

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_16
#include "Eth_43_PFE_MemMap.h"

uint16 u16TxQueueWrite[ETH_43_PFE_MAXCTRLS_SUPPORTED]; /* Increment only in Transmit */
uint16 u16TxQueueRead[ETH_43_PFE_MAXCTRLS_SUPPORTED];  /* Increment only in TxConf */

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_16
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"

/*  Driver objects common for all interfaces (for all pfe_drv instances) */
static pfe_platform_t *ptrPlatform = NULL_PTR;

#define ETH_43_PFE_STOP_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

static pfe_platform_config_t rPlatformCfg =
{
    .cbus_base = PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU,       /* PFE control bus base address */
    .cbus_len = PFE_CFG_CBUS_LENGTH,                    /* PFE control bus size */
    .fw_name = NULL_PTR,
    .fw = NULL_PTR,                                     /* Required firmware, embedded */
    .common_irq_mode = FALSE,                           /* True if FPGA specific common irq is used */
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
    .irq_vector_bmu = 194U,                             /* BMU IRQ number */
#endif /* PFE_CFG_BMU_IRQ_ENABLED */
#ifdef PFE_CFG_HIF_NOCPY_SUPPORT
    .hif_chnls_mask = (pfe_hif_chnl_id_t)HIF_CHNL_INVALID,
#else
    .hif_chnls_mask = (pfe_hif_chnl_id_t)(1U << (ETH_43_PFE_COMMON_HIF - PFE_PHY_IF_ID_HIF0)),
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    .hif_fci_owner_chnls_mask = FCI_OWNER_HIF_INVALID,
    .master_if = PFE_CFG_MASTER_IF,
#endif
    .irq_vector_hif_chnls = {190U, 191U, 192U, 193U},   /* HIF channels IRQ number */
    .irq_vector_hif_nocpy = 195U,                       /* HIF nocopy channel IRQ number */
    .irq_vector_upe_gpt = 0U,
    .irq_vector_safety = 0U,
    .enable_util = FALSE,
    .disable_master_detect = FALSE,
    .local_hif = PFE_PHY_IF_ID_INVALID,                  /* Will be set at runtime */
#if defined(PFE_CFG_RTABLE_ENABLE)
    .rtable_hash_size = PFE_CFG_RT_HASH_SIZE,
    .rtable_collision_size = PFE_CFG_RT_COLLISION_SIZE,
#endif /* PFE_CFG_RTABLE_ENABLE */
    .vlan_id = 0U,
    .vlan_stats_size = 0U,
    .emac_mode = {EMAC_MODE_INVALID, EMAC_MODE_INVALID, EMAC_MODE_INVALID},
    .commit_hash = DRIVER_COMMIT_HASH,
    .driver_version = PFE_DRIVER_VERSION
};

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"

static pfe_hif_chnl_t *prCommonHifChnl = NULL_PTR;
static oal_irq_t *prCommonChnlIRQ = NULL_PTR;
static pfe_hif_drv_t *prCommonHifDrv = NULL_PTR;

#ifdef PFE_CFG_RTABLE_ENABLE
/* usage scope: Eth_PFE_LLD_MainFunction */
/* Routing table timer ticks, used for rtable entries timeout update */
static uint32 u32RtrTimeoutTimeMs = 0U;
#endif /* PFE_CFG_RTABLE_ENABLE */

#define ETH_43_PFE_STOP_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*  All PFE driver interfaces */
static trPfeDev arPfeInterface[ETH_43_PFE_MAXCTRLS_SUPPORTED];

/**
* @brief         Mode of the ETH controllers
* @details       Stores the last known mode of the ETH controller.
*                Used in "Eth_MainFunction" to track mode changes and report them back to EthIf.
*                Only "Eth_SetControllerMode" can trigger mode changes.
*/
static Eth_ModeType eSavedMode[ETH_43_PFE_MAXCTRLS_SUPPORTED];

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
#define ETH_43_PFE_START_SEC_VAR_CLEARED_32
#include "Eth_43_PFE_MemMap.h"
static uint32 u32DemErrorCounters[ETH_43_PFE_MAXCTRLS_SUPPORTED][MAX_DEM_FRAME_ERRORS];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_32
#include "Eth_43_PFE_MemMap.h"
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static Std_ReturnType UpdatePhysAddrFilter_AddBroad(const trPfeDev *prPfeDev);
static Std_ReturnType UpdatePhysAddrFilter_RemoveBroad(const trPfeDev *prPfeDev);
static Std_ReturnType UpdatePhysAddrFilter_Close(const trPfeDev *prPfeDev);
static Std_ReturnType UpdatePhysAddrFilter_AddMulti(const trPfeDev *prPfeDev, const uint8 * PhysAddrPtr);
static Std_ReturnType UpdatePhysAddrFilter_RemoveMulti(const trPfeDev *prPfeDev, const uint8 *PhysAddrPtr);

static uint8 ReportReception_GetBypassVLANTag(Eth_FrameType FrameType);
static void ReportReception_ProcessPacket(uint8 u8CtrlIdx, uint8 u8FifoIdx, const pfe_hif_pkt_t *RxPacket);
static boolean IsRxChecksumValidIpV4(const pfe_hif_pkt_t *RxPacket, uint8 Protocol);
static boolean IsRxChecksumValidIpV6(const pfe_hif_pkt_t *RxPacket, uint8 Protocol);
static boolean IsRxChecksumValid(const pfe_hif_pkt_t *RxPacket, const uint8 *pEtherType);

static void ClientEventHdlr_RX(uint8 u8ClientIdx, uint8 u8QueueIdx);
static void ClientEventHdlr_TX(uint8 u8ClientIdx, uint8 u8QueueIdx);
#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
static void ClientEventHdlr_ETS(uint8 u8ClientIdx, uint8 u8QueueIdx);
#endif
static errno_t ClientEventHdlr
(
    pfe_hif_drv_client_t *prClient,
    void *pvArg,
    uint32 u32Event,
    uint32 u32QueueIdx
);
static void DestroyHifDrv(oal_irq_t *prIRQ, pfe_hif_drv_t *prHifDrv);
#if defined(PFE_CFG_PFE_MASTER) && IS_RECEIVE_MALFORMED_ALLOWED
static Std_ReturnType PlatformDrvPrepare_EnRxMalformed(void);
#endif
static Std_ReturnType PlatformDrvPrepare_EnablePhyIf(void);
static Std_ReturnType PlatformDrvPrepare_ShutdownConfigInit(void);

#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
static Std_ReturnType TxReqSwt(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx, uint8 *dataPtr, uint16 *pLength);
#endif

#ifdef PFE_CFG_PFE_SLAVE
static Std_ReturnType PlatformDrvPrepare_SlaveWaitForIpReady(void);
#endif
static Std_ReturnType ConfigureTxBuffers(void);
#ifndef PFE_CFG_HIF_NOCPY_SUPPORT
static errno_t InitializeTxHeaders(const uint8 u8CtrlIdx, pfe_hif_drv_client_t *client);
#endif
static boolean GetTxBuffer(const uint8 u8CtrlIdx, const uint8 u8FifoIdx, Eth_BufIdxType * const pBufIdx);
static void ReleaseTxBuffer(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx);
static void ReleaseAllCtrlTxBuffers(const uint8 u8CtrlIdx);
static void *TxReqQueueWrite(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx);
static Eth_PFE_LLD_trTxRefData *TxReqQueueRead(const uint8 u8CtrlIdx);
static void TxReqQueueDelete(const uint8 u8CtrlIdx);
static errno_t TxReqTrigger(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx, uint16 Length);
static void TxReqFailed(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx);
#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
static void TxReqTsQueueWrite(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx);
static void InterfacePrepare_InitTSQueue(trPfeDev *prPfeDev);
static Std_ReturnType EmacTsAdjustRatio(uint8 u8CtrlIdx, pfe_emac_t *prEmac, const Eth_RateRatioType *pRateRatioPtr);
static errno_t GetTxTimeStamp
(
    uint8 u8CtrlIdx,
    Eth_BufIdxType BufIdx,
    Eth_TimeStampQualType *timeQualPtr,
    Eth_TimeStampType *timeStampPtr
);
#endif
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
static bool_t  CommonHifChnlISR(void *arg);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
static boolean CreateHifDrv(pfe_ct_phy_if_id_t HifId, uint32 u32IrqVector, pfe_hif_chnl_t **pprHifChnl, oal_irq_t **pprIRQ, pfe_hif_drv_t **pprHifDrv);
static pfe_hif_drv_t* CreateHifDrv_Init(pfe_hif_chnl_t *prHifChnl, oal_irq_t * prIRQ);
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
static oal_irq_t* CreateHifDrv_Isr(uint32 u32IrqVector, pfe_hif_chnl_t *prHifChnl);
#endif
#ifdef PFE_CFG_PFE_MASTER
static errno_t ConfigureSchedulerAndShaper(uint8 u8CtrlIdx);
static errno_t ConfigureSchedulerAndShaper_MapUnusedInputs(ConfigureSchedulerAndShaper_StateType *pstate, uint8 u8SchIdx);
static errno_t ConfigureSchedulerAndShaper_SetRateModeAlgo(const ConfigureSchedulerAndShaper_StateType *pstate, uint8 u8SchIdx, const Eth_43_PFE_SchedulerCfgType *pSch);
static errno_t ConfigureSchedulerAndShaper_SetSchedulerInput(ConfigureSchedulerAndShaper_StateType *pstate, uint8 u8SchIdx, const Eth_43_PFE_SchedulerCfgType *pSch, const Eth_43_PFE_SchedulerInputInfoCfgType *pSchInput);
static errno_t ConfigureSchedulerAndShaper_SetShaper(ConfigureSchedulerAndShaper_StateType *pstate, uint8 u8SchIdx, const Eth_43_PFE_SchedulerInputInfoCfgType *pSchInput);
static errno_t ConfigureSchedulerAndShaper_SetFifo(ConfigureSchedulerAndShaper_StateType *pstate, uint8 u8SchIdx, const Eth_43_PFE_SchedulerInputInfoCfgType *pSchInput, uint8 u8FifoIdx);
static errno_t Eth_PFE_LLD_EMACPrepare_Config(const pfe_phy_if_t *prEmac, const Eth_43_PFE_EmacCfg *pEmacCfg);
static errno_t InterfacePrepare_MasterConfigEMAC(const trPfeDev *prPfeDev);
static errno_t InterfacePrepare_InitEmacMasterRx(const trPfeDev *prPfeDev);
static errno_t InterfacePrepare_InitEmacMasterLink(const trPfeDev *prPfeDev);
static void SetSingleEmacMode(uint8 u8EmacIdx, uint8 u8MiiMode);
#else
static errno_t InterfacePrepare_SlaveConfigEMAC(const trPfeDev *prPfeDev);
#endif /* PFE_CFG_PFE_MASTER */
static boolean EnableController_Aux(trPfeDev *prPfeDev, pfe_hif_drv_client_rx_tx_count *pclient_queue, pfe_hif_drv_client_fifo_queue *pclient_fifo_queue);
static boolean EnableController_HifEmac(trPfeDev *prPfeDev, pfe_hif_drv_client_rx_tx_count *pclient_queue, pfe_hif_drv_client_fifo_queue *pclient_fifo_queue);
static boolean EnableController_Common(const trPfeDev *prPfeDev);

#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
static boolean DetectErrorsAndLostFrame(uint8 u8CtrlIdx, ErrorIdType errorId);
static void CheckDemStatus(uint8 u8CtrlIdx, uint32 demConfig, ErrorIdType errorId, uint32 demId);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
static void Eth_PFE_LLD_ResetGlobalVar(void);
static boolean Eth_PFE_LLD_DetectHardReset(void);
static void Eth_PFE_LLD_ShutdownDriver(void);
#if (STD_ON == ETH_43_GET_COUNTER_API) || \
    (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT) || \
    (STD_ON == ETH_43_GET_RXSTATS_API) || \
    (STD_ON == ETH_43_GET_TXSTATS_API) || \
    (STD_ON == ETH_43_GET_TXERROR_COUNTER_API)
static pfe_emac_t *Eth_PFE_LLD_GetEmacInstanceByControllerId(uint8 u8CtrlIdx);
#endif
#if (STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER)
static Std_ReturnType ChannelBdFlushRxPrepare(pfe_ct_phy_if_id_t DestHifChnl);
static Std_ReturnType ChannelBdFlushRxExecute(pfe_ct_phy_if_id_t DestHifChnl);
#endif /*(STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER)*/

/*==================================================================================================
*                                        LOCAL FUNCTIONS
==================================================================================================*/

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
/**
 * @brief        Common HIF channel interrupt service routine
 * @details      Manage common HIF channel interrupt. Always runs in a thread context.
 * @details      See the oal_irq_handler_t
 */
static bool_t  CommonHifChnlISR(void *arg)
{
    pfe_hif_chnl_t *chnl = (pfe_hif_chnl_t *)arg;
    bool_t handled = FALSE;

    /*    Disable HIF channel interrupts */
    pfe_hif_chnl_irq_mask(chnl);

    /*    Call HIF channel ISR */
    if (EOK == pfe_hif_chnl_isr(chnl))
    {
        handled = TRUE;
    }

    /*    Re-enable HIF channel IRQ */
    pfe_hif_chnl_irq_unmask(chnl);

    return handled;
}
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

/*  Auxiliary function to create and initialize HIF driver */
static pfe_hif_drv_t* CreateHifDrv_Init(pfe_hif_chnl_t *prHifChnl, oal_irq_t * prIRQ)
{
    pfe_hif_drv_t *result = NULL_PTR;
    pfe_hif_drv_t *prHifDrv = pfe_hif_drv_create(prHifChnl);

    if (NULL_PTR == prHifDrv)
    {
        NXP_LOG_ERROR("Could not get HIF driver instance\n");
    }
    else if (EOK != pfe_hif_drv_init(prHifDrv))
    {
        NXP_LOG_ERROR("pfe_hif_drv_init() failed\n");
    }
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#if (defined(PFE_CFG_PFE_SLAVE) && (TRUE == PFE_CFG_HIF_IRQ_ENABLED))
    else if(FALSE == (Eth_PFE_LLD_bIrqInitStatus = TRUE))
    {   /* ^^^ This is to keep the flow and set Eth_PFE_LLD_bIrqInitStatus=TRUE at the very last place just before issuing a very first IDEX RPC command */
        ;
    }
#endif
    /*  We need to start here to be able to configure master
        during initialization */
    else if (EOK != pfe_hif_drv_start(prHifDrv))
    {
        NXP_LOG_ERROR("HIF driver start failed\n");
    }
    else if (EOK != pfe_idex_init(prHifDrv, rPlatformCfg.master_if, ptrPlatform->hif, &pfe_platform_idex_rpc_cbk, (void *)ptrPlatform))
    {
        NXP_LOG_ERROR("Can't initialize IDEX\n");
    }
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
    else
    {
        result = prHifDrv;
    }

    if(result == NULL_PTR) 
    {
        DestroyHifDrv(prIRQ, prHifDrv);
    }

    return result;
}

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
/*  Auxiliary function to register an ISR handler */
static oal_irq_t* CreateHifDrv_Isr(uint32 u32IrqVector, pfe_hif_chnl_t *prHifChnl)
{
    oal_irq_t * prIRQ;
    PfeDevAssert(u32IrqVector <= INT32_MAX);
    prIRQ = oal_irq_create(
                (sint32)u32IrqVector,
                (oal_irq_flags_t)0,
                NULL_PTR /* irq name is unused in oal_irq_create */
                );

    if (NULL_PTR == prIRQ)
    {
        NXP_LOG_ERROR("Could not create HIF IRQ\n");
    }
    /*  Install IRQ handler */
    else
    {
        if (EOK != oal_irq_add_handler(prIRQ, (oal_irq_handler_t)&CommonHifChnlISR, prHifChnl, NULL_PTR))
        {
            NXP_LOG_ERROR("Could not add IRQ handler\n");
            oal_irq_destroy(prIRQ);
            prIRQ = NULL_PTR;
        }
    }

    return prIRQ;
}
#endif

/*  Auxiliary function to get hif chnl, interrupt and drv */
static boolean CreateHifDrv(pfe_ct_phy_if_id_t HifId, uint32 u32IrqVector, pfe_hif_chnl_t **pprHifChnl, oal_irq_t **pprIRQ, pfe_hif_drv_t **pprHifDrv)
{
    boolean bRetVal = FALSE;
    pfe_hif_chnl_t *prHifChnl;
    pfe_hif_drv_t *prHifDrv = NULL_PTR;
    oal_irq_t *prIRQ = NULL_PTR;

    /*  Get HIF channel. This one will be common for all logical interfaces. */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if (HifId == PFE_PHY_IF_ID_HIF_NOCPY)
    {
        prHifChnl = pfe_hif_nocpy_get_channel(ptrPlatform->hif_nocpy, PFE_HIF_CHNL_NOCPY_ID);
    }
    else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    {
        prHifChnl = pfe_hif_get_channel(ptrPlatform->hif, pfe_hif_chnl_from_phy_id(HifId));
    }

    if (NULL_PTR == prHifChnl)
    {
        NXP_LOG_ERROR("Can't get HIF channel instance\n");
    }
    else
    {
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
        prIRQ = CreateHifDrv_Isr(u32IrqVector, prHifChnl);
        if(NULL_PTR != prIRQ)
#else
        (void)u32IrqVector;
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
        {
            /*  Create HIF driver for the channel */
            prHifDrv = CreateHifDrv_Init(prHifChnl, prIRQ);
            if(NULL_PTR != prHifDrv)
            {
                /*  Now particular channel interrupt source can be enabled */
                /*  Everything is OK */
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
                pfe_hif_chnl_irq_unmask(prHifChnl);
                *pprIRQ = prIRQ;
#else
                (void)pprIRQ;
#endif
                *pprHifChnl = prHifChnl;
                *pprHifDrv = prHifDrv;
                bRetVal = TRUE;
            }
        }
    }

    return bRetVal;
}

/*  Auxiliary function to destroy hif interrupt and drv */
static void DestroyHifDrv(oal_irq_t *prIRQ, pfe_hif_drv_t *prHifDrv)
{
    if (NULL_PTR != prHifDrv)
    {
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        pfe_idex_fini();
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
        pfe_hif_drv_destroy(prHifDrv);
    }
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
    if (NULL_PTR != prIRQ)
    {
        oal_irq_destroy(prIRQ);
    }
#else
    (void)prIRQ;
#endif
    /* No need to destroy prHifChnl */
    return;
}

/*================================================================================================*/
/**
* @brief         Configures all transmit buffers
* @details       Based on selected configuration, this function splits the buffer memory
*                among all controllers and their Tx queues. It initializes one aarTxBufPool
*                structure for each queue, which can be used to get or return Tx buffers
*                and to calculate buffer address based on buffer index and vice versa.
*                The function initializes all aarTxBuf records as well.
*/
static Std_ReturnType ConfigureTxBuffers(void)
{
    Std_ReturnType RetVal = E_OK;
    trTxBufPool *prPool;
    addr_t Addr = (addr_t)&auTxBufMem;
    uint8 u8Ctrl;
    uint8 u8Fifo;
    uint16 u16Buff;
    uint8 u8NumFifo;
    uint16 u16IndexOffset;

    for (u8Ctrl = 0U; u8Ctrl < ETH_43_PFE_NUM_CONTROLLER_CFG; u8Ctrl++)
    {
        u16IndexOffset = 0U;
        u8NumFifo = Eth_43_PFE_InternalCfgPtr->pController[u8Ctrl]->EthCtrlEgressFifoCnt;
        for (u8Fifo = 0U; u8Fifo < u8NumFifo; u8Fifo++)
        {
            prPool = &aarTxBufPool[u8Ctrl][u8Fifo];
            prPool->Addr = Addr;
            prPool->u32BufSize =
                Eth_43_PFE_InternalCfgPtr->pController[u8Ctrl]->pEgressCfg[u8Fifo].EthCtrlConfigEgressFifoMemLenByte;
            prPool->u16BufNumber =
                Eth_43_PFE_InternalCfgPtr->pController[u8Ctrl]->pEgressCfg[u8Fifo].EthCtrlConfigEgressFifoBufTotal;
            prPool->u32Size = prPool->u32BufSize * prPool->u16BufNumber;
            prPool->u16IndexOffset = u16IndexOffset;
            prPool->u16GetIdx = 0U;
            PfeDevAssert(prPool->u32Size <= (UINT32_MAX - Addr));
            PfeDevAssert(prPool->u16BufNumber <= (UINT16_MAX - u16IndexOffset));
            /* Initialize aarTxBuf */
            for (u16Buff = 0U; u16Buff < prPool->u16BufNumber; u16Buff++)
            {
                aarTxBuf[u8Ctrl][u16Buff + u16IndexOffset].BufAddr = Addr + (prPool->u32BufSize * u16Buff);
                aarTxBuf[u8Ctrl][u16Buff + u16IndexOffset].u8Fifo = u8Fifo;
                aarTxBuf[u8Ctrl][u16Buff + u16IndexOffset].u8Status = TX_BUF_FREE;
            }
            Addr += prPool->u32Size;
            u16IndexOffset += prPool->u16BufNumber;
        }
        /* Initialize Tx request queue */
        for (u16Buff = 0U; u16Buff < ETH_43_PFE_MAX_CTRL_TX_BUF_CNT; u16Buff++)
        {
            arTxReqQueue[u8Ctrl][u16Buff].u8CtrlIdx = u8Ctrl;
            arTxReqQueue[u8Ctrl][u16Buff].u16BufIdx = INVALID_TX_INDEX;
        }
        u16TxQueueWrite[u8Ctrl] = 0U;
        u16TxQueueRead[u8Ctrl] = 0U;
    }
    return RetVal;
}

#ifndef PFE_CFG_HIF_NOCPY_SUPPORT
/**
* @brief         Configures all transmit Tx headers
* @details       This function initializes the Tx header at the beginning of each Tx buffer
* @param[in]     u8CtrlIdx Interface (controller) to be configured
* @param[in]     client Client Instance
* @retval        EOK if success, ENOENT otherwise
*/
static errno_t InitializeTxHeaders(const uint8 u8CtrlIdx, pfe_hif_drv_client_t *client)
{
    errno_t ret = EOK;
    boolean bFail = FALSE;
    trTxBufPool *prPool;
    uint8 u8Fifo;
    uint16 u16Buff;
    uint8 u8NumFifo;
    uint8 u8Queue;
    uint16 u16IndexOffset;
    pfe_ct_hif_tx_hdr_t *pTxHeader;

    u16IndexOffset = 0U;
    u8NumFifo = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->EthCtrlEgressFifoCnt;
    for (u8Fifo = 0U; u8Fifo < u8NumFifo; u8Fifo++)
    {
        prPool = &aarTxBufPool[u8CtrlIdx][u8Fifo];
        PfeDevAssert(u16IndexOffset <= (UINT16_MAX - prPool->u16BufNumber));
        for (u16Buff = 0U; u16Buff < prPool->u16BufNumber; u16Buff++)
        {
            pTxHeader = (pfe_ct_hif_tx_hdr_t *)aarTxBuf[u8CtrlIdx][u16Buff + u16IndexOffset].BufAddr;
            u8Queue = aarTxBuf[u8CtrlIdx][u16Buff + u16IndexOffset].u8Fifo;
            ret = pfe_hif_drv_init_tx_header(client, pTxHeader, u8Queue);
            if (EOK != ret)
            {
                bFail = TRUE;
            }
        }
        u16IndexOffset += prPool->u16BufNumber;
    }
    if (TRUE == bFail)
    {
        ret = ENOENT;
    }

    return ret;
}
#endif
/*================================================================================================*/
/* Searches one free buf control record (and for NOCPY also gets buffer from BMU) */
static boolean GetTxBuffer(const uint8 u8CtrlIdx, const uint8 u8FifoIdx, Eth_BufIdxType * const pBufIdx)
{
    boolean bFound = FALSE;
    trTxBufPool *const prBufPool = &aarTxBufPool[u8CtrlIdx][u8FifoIdx];
    const uint16 u16IdxOff = prBufPool->u16IndexOffset;
    const uint16 u16BufNum = prBufPool->u16BufNumber;
    uint16 u16Idx;
    
    PfeDevAssert(u16BufNum != 0u);
    oal_mutex_lock(PFE_TX_BUFFER_POOL_MUTEX);
    u16Idx = prBufPool->u16GetIdx;
    do /* Search for a free buffer control record */
    {
        const Eth_BufIdxType bufIdx = (uint32)u16Idx + u16IdxOff;
        PfeDevAssert(bufIdx < ETH_43_PFE_MAX_CTRL_TX_BUF_CNT);
        if (TX_BUF_FREE == aarTxBuf[u8CtrlIdx][bufIdx].u8Status)
        {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            /* Try to get buffer from BMU */
            aarTxBuf[u8CtrlIdx][bufIdx].BufAddr =
                        (addr_t)pfe_hif_chnl_bmu_alloc_buf_va(arPfeInterface[u8CtrlIdx].prHifChnl);
            if (NULL_ADDR != aarTxBuf[u8CtrlIdx][bufIdx].BufAddr)
#endif
            {
                /* Success */
                aarTxBuf[u8CtrlIdx][bufIdx].u8Status = TX_BUF_PROVIDED;
                *pBufIdx = bufIdx;
                bFound = TRUE;
                /* Update GetIdx */
                if (prBufPool->u16GetIdx == u16Idx)
                {
                    if (prBufPool->u16GetIdx >= (u16BufNum-1U))
                    {   /* wrap */
                        prBufPool->u16GetIdx = 0U;
                    }
                    else
                    {
                        prBufPool->u16GetIdx++;
                    }
                }
            }
            break;
        }
        /* Search backwards to minimize out-of-order allocations and search time in future */
        if (0U == u16Idx)
        {
            u16Idx = u16BufNum;
        }
        u16Idx--;
    } while (u16Idx != prBufPool->u16GetIdx);
    oal_mutex_unlock(PFE_TX_BUFFER_POOL_MUTEX);
    return bFound;
}

/*================================================================================================*/
static void ReleaseTxBuffer(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (TX_BUF_PROVIDED == aarTxBuf[u8CtrlIdx][BufIdx].u8Status)
        {
            addr_t BufAddr = aarTxBuf[u8CtrlIdx][BufIdx].BufAddr;
            (void)pfe_hif_chnl_bmu_free_buf(arPfeInterface[u8CtrlIdx].prHifChnl, BufAddr);
        }
#endif
        aarTxBuf[u8CtrlIdx][BufIdx].u8Status = TX_BUF_FREE;
}

/*================================================================================================*/
static void ReleaseAllCtrlTxBuffers(const uint8 u8CtrlIdx)
{
    for(Eth_BufIdxType BufIdx = 0U; BufIdx < ETH_43_PFE_MAX_CTRL_TX_BUF_CNT; BufIdx++)
    {
        ReleaseTxBuffer(u8CtrlIdx, BufIdx);
    }
}

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
/*================================================================================================*/
static void TxReqTsQueueWrite(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{            
    trPfeDev *prPfeDev = &arPfeInterface[u8CtrlIdx];
    uint8 u8FifoIdx = Eth_43_PFE_LLD_GetTxFifoIdx(u8CtrlIdx, BufIdx);

    oal_mutex_lock(PFE_TS_QUEUE_WRITE_MUTEX);
    /* Add this buffer to TS queue (no need to check if queue is full, there is always enough space) */
    prPfeDev->TSQueue[u8FifoIdx][prPfeDev->u16TSQueueWrite[u8FifoIdx]] = BufIdx;
    if(prPfeDev->u16TSQueueWrite[u8FifoIdx] >= (ETH_43_PFE_MAX_FIFO_TX_BUF_CNT - 1U))
    {   /* Wrap */
        prPfeDev->u16TSQueueWrite[u8FifoIdx] = 0U;
    }
    else
    {
        prPfeDev->u16TSQueueWrite[u8FifoIdx]++;
    }

    oal_mutex_unlock(PFE_TS_QUEUE_WRITE_MUTEX);
}
#endif

#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
/*================================================================================================*/
static Std_ReturnType TxReqSwt(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx, uint8* dataPtr, uint16 *pLength)
{
    /* dataPtr points to position of EtherType in Ethernet frame */
    Std_ReturnType u8FunctionSuccess = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
        Eth_43_PFE_EthSwtDriverFunctionList.TxProcessFrameFunction(u8CtrlIdx, BufIdx, &dataPtr, pLength);
    if ((Std_ReturnType)E_OK == u8FunctionSuccess)
    {
        /* Finish to process frame */
        u8FunctionSuccess = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
        Eth_43_PFE_EthSwtDriverFunctionList.TxFinishedIndicationFunction(u8CtrlIdx, BufIdx);
    }

    return u8FunctionSuccess;
}
#endif

/*================================================================================================*/
static errno_t TxReqTrigger(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx, uint16 Length)
{
    uint8 u8FifoIdx = Eth_43_PFE_LLD_GetTxFifoIdx(u8CtrlIdx, BufIdx);
    void *pvDataVA = (void *)aarTxBuf[u8CtrlIdx][BufIdx].BufAddr;
    void *pvRefPtr = TxReqQueueWrite(u8CtrlIdx, BufIdx);
    hif_frame_t frame;
    frame.flags.specific.tx_flags = (pfe_ct_hif_tx_flags_t)0U;
    frame.data_va = pvDataVA;
    frame.len = (uint32)Length + (uint32)sizeof(pfe_ct_hif_tx_hdr_t);
    frame.dst_phy = PFE_PHY_IF_ID_INVALID;

    return  pfe_hif_drv_client_xmit_pkt(
                     arPfeInterface[u8CtrlIdx].prClient, 
                     u8FifoIdx, 
                     &frame,
                     pvRefPtr);
}

/*================================================================================================*/
static void TxReqFailed(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{
    const trTxMeta *prTxMeta = NULL_PTR;
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    /* Free the buffer */
    addr_t BufAddr = aarTxBuf[u8CtrlIdx][BufIdx].BufAddr;
    (void)pfe_hif_chnl_bmu_free_buf(arPfeInterface[u8CtrlIdx].prHifChnl, BufAddr);
#endif
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
    prTxMeta = Eth_PFE_LLD_GetTxBufMeta(u8CtrlIdx, BufIdx);
    /* Report the failure. There will be no interrupt generated, so it is reported here. */
    if(TRUE == prTxMeta->bDoTxIndication)
    {
        /*    Disable HIF channel interrupts */
        pfe_hif_chnl_irq_mask(arPfeInterface[u8CtrlIdx].prHifChnl);
        EthIf_TxConfirmation(ETH_43_PFE_CFG_CTRLIDXINETHIF(u8CtrlIdx), BufIdx, E_NOT_OK);
        /*    Re-enable HIF channel IRQ */
        pfe_hif_chnl_irq_unmask(arPfeInterface[u8CtrlIdx].prHifChnl);
    }
    aarTxBuf[u8CtrlIdx][BufIdx].u8Status = TX_BUF_FREE;
#else
    /* Failure will be reported when polling function is called */
    aarTxBuf[u8CtrlIdx][BufIdx].u8Status = TX_BUF_FAILED;
    (void)prTxMeta;
#endif /* interrupt_enabled */
}

/*================================================================================================*/
/* Adds BufIdx to Tx Request Queue (at write index) and returns pointer to the new record, which
   can be used as ref_ptr for pfe_hif_drv_client_xmit_pkt */
static void *TxReqQueueWrite(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{
    PfeDevAssert(BufIdx < ETH_43_PFE_MAX_CTRL_TX_BUF_CNT);
    /* There is enough room in arTxReqQueue to fit all Tx buffers => no need to check if record is free */
    oal_mutex_lock(PFE_TX_REQ_QUEUE_WRITE_MUTEX);
    Eth_PFE_LLD_trTxRefData *prRefPtr = &arTxReqQueue[u8CtrlIdx][u16TxQueueWrite[u8CtrlIdx]];
    if (u16TxQueueWrite[u8CtrlIdx] >= (ETH_43_PFE_MAX_CTRL_TX_BUF_CNT - 1U))
    {
        u16TxQueueWrite[u8CtrlIdx] = 0U;
    }
    else
    {
        u16TxQueueWrite[u8CtrlIdx]++;
    }
    prRefPtr->u16BufIdx = (uint16)BufIdx;
    oal_mutex_unlock(PFE_TX_REQ_QUEUE_WRITE_MUTEX);
    return (void *)prRefPtr;
}

/*================================================================================================*/
/* Provides record from Tx Request Queue at read index */
static Eth_PFE_LLD_trTxRefData *TxReqQueueRead(const uint8 u8CtrlIdx)
{
    Eth_PFE_LLD_trTxRefData *prRefPtr = &arTxReqQueue[u8CtrlIdx][u16TxQueueRead[u8CtrlIdx]];
    return prRefPtr;
}

/*================================================================================================*/
/* Deletes record from Tx Request Queue at read index */
static void TxReqQueueDelete(const uint8 u8CtrlIdx)
{
    arTxReqQueue[u8CtrlIdx][u16TxQueueRead[u8CtrlIdx]].u16BufIdx = INVALID_TX_INDEX;
    if (u16TxQueueRead[u8CtrlIdx] >= (ETH_43_PFE_MAX_CTRL_TX_BUF_CNT - 1U))
    {
        u16TxQueueRead[u8CtrlIdx] = 0U;
    }
    else
    {
        u16TxQueueRead[u8CtrlIdx]++;
    }
}

/*================================================================================================*/
static void ClientEventHdlr_RX(uint8 u8ClientIdx, uint8 u8QueueIdx)
{
    /* Only call the handler here if the interrupt mode is enabled */
    if(TRUE == ETH_43_PFE_CFG_ENABLERXINTERRUPT(u8ClientIdx))
    {
        if(ETH_STATE_INIT == Eth_43_PFE_CtrlState[u8ClientIdx])
        {
            /*  Return value is not needed in interrupt mode */
            (void)Eth_PFE_LLD_ReportReception(u8ClientIdx, u8QueueIdx, (boolean)TRUE);
        }
    }
}

/*================================================================================================*/
static void ClientEventHdlr_TX(uint8 u8ClientIdx, uint8 u8QueueIdx)
{
    /* Only call the handler here if the interrupt mode is enabled */
    if(TRUE == ETH_43_PFE_CFG_ENABLETXINTERRUPT(u8ClientIdx))
    {
        if(ETH_STATE_INIT == Eth_43_PFE_CtrlState[u8ClientIdx])
        {
            if(ETH_MODE_ACTIVE == Eth_PFE_LLD_CheckControllerIsActive(u8ClientIdx))
            {
                /*  Return value is not needed in interrupt mode */
                Eth_PFE_LLD_ReportTransmission(u8ClientIdx, u8QueueIdx);
            }
        }
    }
}

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
/*================================================================================================*/
static void ClientEventHdlr_ETS(uint8 u8ClientIdx, uint8 u8QueueIdx)
{
    /* Only call the handler here if the interrupt mode is enabled */
    if(TRUE == ETH_43_PFE_CFG_ENABLETXINTERRUPT(u8ClientIdx))
    {
        if(ETH_STATE_INIT == Eth_43_PFE_CtrlState[u8ClientIdx])
        {
            Eth_PFE_LLD_ReportTransmissionTS(u8ClientIdx, u8QueueIdx);
        }
    }
}
#endif

/*================================================================================================*/
/**
 * @brief       HIF client event handler
 * @details     Called by HIF when client-related event happens (packet received, packet
 *              transmitted).
 * @note        Running within context of HIF driver worker thread.
 */
static errno_t ClientEventHdlr(pfe_hif_drv_client_t *prClient, void *pvArg, uint32 u32Event, uint32 u32QueueIdx)
{
    errno_t RetValue = EOK;
    const trPfeDev *prPfeDev = (const trPfeDev *)pvArg;
    uint8 u8ClientIdx = prPfeDev->u8CtrlIdx;
    PfeDevAssert(u32QueueIdx <= UINT8_MAX);

    (void)prClient;
    switch(u32Event)
    {
        case EVENT_RX_PKT_IND: /* New packet(s) received */
            ClientEventHdlr_RX(u8ClientIdx, (uint8)u32QueueIdx);
            break;
        case EVENT_TXDONE_IND: /* New Tx confirmation(s) */
            ClientEventHdlr_TX(u8ClientIdx, (uint8)u32QueueIdx);
            break;
#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
        case EVENT_ETS: /* New egress timestamp(s) available, generate confirmation(s) for timestamped frames */
            ClientEventHdlr_ETS(u8ClientIdx, (uint8)u32QueueIdx);
            break;
#endif /*ETH_43_PFE_GLOBALTIME_SUPPORT*/
        default:
            /*Do Nothing*/
            break;
    }
    return RetValue;
}

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
/*================================================================================================*/
static errno_t GetTxTimeStamp(uint8 u8CtrlIdx, \
                              Eth_BufIdxType BufIdx, \
                              Eth_TimeStampQualType *timeQualPtr, \
                              Eth_TimeStampType *timeStampPtr \
                             )
{
    errno_t RetVal = ENOENT;
    const Eth_PFE_LLD_trTxTsRef *rTsRef;

    if (NULL_PTR != arPfeInterface[u8CtrlIdx].prClient)
    {
        rTsRef = Eth_PFE_LLD_GetTxBufTsRef(u8CtrlIdx, BufIdx);
        /* Get timestamp */
        RetVal = pfe_hif_drv_client_get_ts
        (
            arPfeInterface[u8CtrlIdx].prClient, FALSE,
            rTsRef->u8MessageType, rTsRef->u16SourcePortID, rTsRef->u16SequenceID,
            &(timeStampPtr->seconds), &(timeStampPtr->nanoseconds)
        );

        if (EOK == RetVal)
        {
            timeStampPtr->secondsHi = 0U;
            *timeQualPtr = ETH_VALID;
        }
        else
        {
            *timeQualPtr = ETH_INVALID; /* General failure */
        }
    }
    return RetVal;
}
#endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */

#ifdef PFE_CFG_PFE_MASTER
/*================================================================================================*/
static errno_t ConfigureSchedulerAndShaper_SetFifo(ConfigureSchedulerAndShaper_StateType *pstate,
                                                   uint8 u8SchIdx,
                                                   const Eth_43_PFE_SchedulerInputInfoCfgType *pSchInput,
                                                   uint8 u8FifoIdx
                                                  )
{
    errno_t ret = EOK;

    /* Connect queue to scheduler input */
    ret = pfe_tmu_sch_bind_queue(ptrPlatform->tmu, pstate->emac_id, u8SchIdx, pSchInput->u8Input, u8FifoIdx);
    if(EOK != ret)
    {
        NXP_LOG_ERROR("Failed to connect queue to scheduler input\n");
    }
    else 
    {
        pstate->is_queue_used[u8FifoIdx] = TRUE;
    }

    return ret;
}

/*================================================================================================*/
static errno_t ConfigureSchedulerAndShaper_SetShaper(ConfigureSchedulerAndShaper_StateType *pstate,
                                                     uint8 u8SchIdx,
                                                     const Eth_43_PFE_SchedulerInputInfoCfgType *pSchInput
                                                    )
{
    /* shaper lookup */
    errno_t ret = ENODEV;
    const Eth_43_PFE_ShaperCfgType *pShp = NULL;
    for(uint8 u8Shp = 0u; u8Shp < pstate->pcfg->EthCtrlShaperCnt; u8Shp++) {
        if(pSchInput->u8InputIdx == pstate->pcfg->pShpCfg[u8Shp].u8ShpIdx) 
        {
            pShp = &pstate->pcfg->pShpCfg[u8Shp];
            ret = pfe_tmu_shp_enable(ptrPlatform->tmu, pstate->emac_id, pShp->u8ShpIdx);
            break;
        }
    }

    if(EOK != ret)
    {
        NXP_LOG_ERROR("Failed to enable shaper\n");
    }
    else 
    {
        const sint64 neg_min_credit = -(sint64)pShp->s32MinCredit;
        PfeDevAssert(neg_min_credit <= 0);
        ret = pfe_tmu_shp_set_limits(ptrPlatform->tmu, pstate->emac_id, pShp->u8ShpIdx, pShp->s32MaxCredit, (sint32)neg_min_credit);
        if(EOK != ret)
        {
            NXP_LOG_ERROR("Failed to set shaper credit limits\n");
        }
        else 
        {
            const uint8 aShpPos[TLITE_SCH_CNT][TLITE_SCH_INPUTS_CNT] = {SHP_POS_COR_SCH0, SHP_POS_COR_SCH1};
            uint8 u8TempShpPos = aShpPos[u8SchIdx][pSchInput->u8Input];
            ret = pfe_tmu_shp_set_position(ptrPlatform->tmu, pstate->emac_id, pShp->u8ShpIdx, u8TempShpPos);
            if(EOK != ret)
            {
                NXP_LOG_ERROR("Failed to set shaper position\n");
            }
            else 
            {
                ret = pfe_tmu_shp_set_idle_slope(ptrPlatform->tmu, pstate->emac_id, pShp->u8ShpIdx , pShp->u32IdleSlope);
                if(EOK != ret)
                {
                    NXP_LOG_ERROR("Failed to set shaper idle slope\n");
                }
                else {
                    ret = ConfigureSchedulerAndShaper_SetFifo(pstate, u8SchIdx, pSchInput, pShp->u8FifoIdx);
                }
            }
        }
    }

    return ret;
}

/*================================================================================================*/
static errno_t ConfigureSchedulerAndShaper_SetSchedulerInput(ConfigureSchedulerAndShaper_StateType *pstate,
                                                             uint8 u8SchIdx,
                                                             const Eth_43_PFE_SchedulerCfgType *pSch,
                                                             const Eth_43_PFE_SchedulerInputInfoCfgType *pSchInput
                                                            )
{
    errno_t ret = EOK;

    /* Set scheduler input weight */
    if ((SCHED_ALGO_WRR == pSch->SchAlgo) || (SCHED_ALGO_DWRR == pSch->SchAlgo))
    {
        ret = pfe_tmu_sch_set_input_weight(ptrPlatform->tmu, pstate->emac_id, u8SchIdx, pSchInput->u8Input, pSchInput->u32Weight);
        if(EOK != ret)
        {
            NXP_LOG_ERROR("Failed to set scheduler input weight\n");
        }
    }

    if(EOK == ret)
    {
        if (IS_FIFO == pSchInput->SchInputType)
        {
            /* Connect queue to scheduler input */
            ret = ConfigureSchedulerAndShaper_SetFifo(pstate, u8SchIdx, pSchInput, pSchInput->u8InputIdx);
        }
        else if (IS_SHAPER == pSchInput->SchInputType)
        {
            ret = ConfigureSchedulerAndShaper_SetShaper(pstate, u8SchIdx, pSchInput);
        }
        else /* IS_SHEDULER */
        {
            /* Bind scheduler 0 to scheduler 1 */
            ret = pfe_tmu_sch_bind_sch_output(ptrPlatform->tmu, pstate->emac_id, SCH0_ID, u8SchIdx, pSchInput->u8Input);
            if(EOK != ret)
            {
                NXP_LOG_ERROR("Failed to connect scheduler 0  to scheduler 1\n");
            }
        }
    }

    if(EOK == ret)
    {
        pstate->is_input_used[u8SchIdx][pSchInput->u8Input] = TRUE;
    }

    return ret;
}

/*================================================================================================*/
static errno_t ConfigureSchedulerAndShaper_SetRateModeAlgo(const ConfigureSchedulerAndShaper_StateType *pstate,
                                                           uint8 u8SchIdx,
                                                           const Eth_43_PFE_SchedulerCfgType *pSch
                                                          )
{
    errno_t ret = EOK;

    /* Set scheduler rate mode */
    ret = pfe_tmu_sch_set_rate_mode(ptrPlatform->tmu, pstate->emac_id, u8SchIdx, pSch->SchRateMode);
    if(EOK != ret)
    {
        NXP_LOG_ERROR("Failed to set scheduler rate mode\n");
    }
    else {
        /* Set scheduler algorithm */
        ret = pfe_tmu_sch_set_algo(ptrPlatform->tmu, pstate->emac_id, u8SchIdx, pSch->SchAlgo);
        if(EOK != ret)
        {
            NXP_LOG_ERROR("Failed to set scheduler algorithm\n");
        }
    }

    return ret;
}

/*================================================================================================*/
static errno_t ConfigureSchedulerAndShaper_MapUnusedInputs(ConfigureSchedulerAndShaper_StateType *pstate,
                                                           uint8 u8SchIdx
                                                          )
{
    errno_t ret = EOK;
#if (defined(PFE_CFG_MULTI_INSTANCE_SUPPORT) || (TRUE == PFE_CFG_EGRESS_PRIO_BY_FW))
    /* In multi instance mode, or when egress priority is set by firmware,
        we don't disable unused queues, because all queues are potentially
        used by firmware or by slaves.
        For example, the SSH server on the Linux slave expects all queues to be enabled */
    uint8 u8Fifo = 0u;
#else 
    /* Single instance mode and egress priority set by application,
        disable queues not configured in tresos */
    uint8 u8Fifo = PFE_TMU_INVALID_QUEUE;
#endif

    for (uint8 u8SchInput = 0U; u8SchInput < TLITE_SCH_INPUTS_CNT; u8SchInput++)
    {
        /* find unused scheduler input */
        if(!pstate->is_input_used[u8SchIdx][u8SchInput])
        {
            /* find an unused queue */
            while((u8Fifo < TLITE_PHY_QUEUES_CNT) && pstate->is_queue_used[u8Fifo]) 
            {
                u8Fifo++;
            }

            if(u8Fifo < TLITE_PHY_QUEUES_CNT)
            {
                pstate->is_queue_used[u8Fifo] = TRUE;
            }
            else {
                u8Fifo = PFE_TMU_INVALID_QUEUE;
            }

            ret = pfe_tmu_sch_bind_queue(ptrPlatform->tmu, pstate->emac_id, u8SchIdx, u8SchInput, u8Fifo);
            if(EOK != ret)
            {
                NXP_LOG_ERROR("Failed to connect queue to scheduler input\n");
                break;
            }
        }
    }

    return ret;
}

/*================================================================================================*/
static errno_t ConfigureSchedulerAndShaper(uint8 u8CtrlIdx)
{
    errno_t ret = EOK;
    ConfigureSchedulerAndShaper_StateType state = {
        .pcfg = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx],
        .emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx),
        .is_input_used = {{FALSE}},
        .is_queue_used = {FALSE}
    };

    for (uint8 u8Sch = 0U; (u8Sch < state.pcfg->EthCtrlSchedulerCnt) && (EOK == ret); u8Sch++)
    {
        const Eth_43_PFE_SchedulerCfgType *pSch = &state.pcfg->pSchCfg[u8Sch];
        uint8 sch_idx = pSch->IsLastSch ? SCH1_ID : SCH0_ID;
        const Eth_43_PFE_SchedulerInputInfoCfgType *pSchInput = pSch->pSchInputInfoCfg;
        uint8 u8SchInputCnt = pSch->SchInputCnt;

        ret = ConfigureSchedulerAndShaper_SetRateModeAlgo(&state, sch_idx, pSch);

        for (uint8 u8SchInput = 0U; (u8SchInput < u8SchInputCnt) && (EOK == ret); u8SchInput++)
        {
            ret = ConfigureSchedulerAndShaper_SetSchedulerInput(&state, sch_idx, pSch, &pSchInput[u8SchInput]);
        }
    }
    
    if(EOK == ret) 
    {
        ret = ConfigureSchedulerAndShaper_MapUnusedInputs(&state, SCH1_ID);
        if(EOK == ret) {
            ret = ConfigureSchedulerAndShaper_MapUnusedInputs(&state, SCH0_ID);
        }
    }

    return ret;
}

/*================================================================================================*/
/* Auxiliary function to write single EMAC mode to register PFE_EMACX_INTF_SEL.
   In case of direct access, the register must be previously cleared. */
static void SetSingleEmacMode(uint8 u8EmacIdx, uint8 u8MiiMode)
{
#if (TRUE == PFE_CFG_SHARED_REG_VIA_MCU)
    static const SharedSettings_Ip_ParameterIdentifierType RegTable[ETH_43_PFE_NUM_EMAC] = 
    {
        SHARED_SETTINGS_IP_EMAC0_ID,
        SHARED_SETTINGS_IP_EMAC1_ID,
        SHARED_SETTINGS_IP_EMAC2_ID
    };

    Mcu_SetSharedIpSetting(RegTable[u8EmacIdx], (uint32)u8MiiMode);
    Mcu_TriggerHardwareUpdate();
#else
    *(uint32 *)(uintptr_t)(S32G_GPR_BASE + PFE_EMACX_INTF_SEL_OFF) |= (uint32)PFE_EMACX_SET(u8EmacIdx, (uint32)u8MiiMode);
#endif /* PFE_CFG_SHARED_REG_VIA_MCU */
}

#endif /* PFE_CFG_PFE_MASTER */

#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
/**
* @brief         Detect controller errors and frame lost
* @param[in]     u8CtrlIdx Index of controller
* @param[in]     errorId error id
* @retval        TRUE Detect errors
* @retval        FALSE Not detect errors
*/
static boolean DetectErrorsAndLostFrame(uint8 u8CtrlIdx, ErrorIdType errorId)
{
    boolean ret = FALSE;
    uint32 u32OldCount = 0U;
    uint32 u32Stat = 0U;
    pfe_emac_t *prEmac = NULL_PTR;

    u32Stat = u32StatId[errorId];
    prEmac = Eth_PFE_LLD_GetEmacInstanceByControllerId(u8CtrlIdx);
    if (NULL_PTR != prEmac)
    {
        u32OldCount = u32DemErrorCounters[u8CtrlIdx][errorId];
        u32DemErrorCounters[u8CtrlIdx][errorId] = pfe_emac_get_stat_value(prEmac, u32Stat);
        if (u32DemErrorCounters[u8CtrlIdx][errorId] > u32OldCount)
        {
            ret = TRUE;
        }
    }

    return ret;
}

/**
* @brief         Check controller errors and frame lost
* @param[in]     u8CtrlIdx Index of controller
* @param[in]     demConfig enable/disable the DEM error
* @param[in]     errorId error id
* @param[in]     demId ID of DEM error
*/
static void CheckDemStatus(uint8 u8CtrlIdx, uint32 demConfig, ErrorIdType errorId, uint32 demId)
{
    /* Check Dem event ON or OFF */
    if ((uint32)STD_ON == demConfig)
    {
        PfeDevAssert(demId < UINT16_MAX);
        if (DetectErrorsAndLostFrame(u8CtrlIdx, errorId))
        {
            (void)Dem_SetEventStatus((Dem_EventIdType)demId, DEM_EVENT_STATUS_PREFAILED);
        }
        else
        {
            (void)Dem_SetEventStatus((Dem_EventIdType)demId, DEM_EVENT_STATUS_PREPASSED);
        }
    }
}
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

/**
* @brief         Reset global variables used by the driver to the default values
*/
static void Eth_PFE_LLD_ResetGlobalVar(void)
{
#ifdef PFE_CFG_RTABLE_ENABLE
    /* usage scope: Eth_PFE_LLD_MainFunction */
    /* Routing table timer ticks, used for rtable entries timeout update */
    u32RtrTimeoutTimeMs = 0U;
#endif /* PFE_CFG_RTABLE_ENABLE */
}


/**
* @brief         Detect the hard reset
*/
static boolean Eth_PFE_LLD_DetectHardReset(void)
{
    errno_t ret;
    boolean bRetVal = FALSE;
    pfe_hif_chnl_t *prHifChnl;

    if (NULL_PTR != ptrPlatform)
    {
        /*  Get HIF channel */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (PFE_CFG_LOCAL_IF == PFE_PHY_IF_ID_HIF_NOCPY)
        {
            prHifChnl = pfe_hif_nocpy_get_channel(ptrPlatform->hif_nocpy, PFE_HIF_CHNL_NOCPY_ID);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            prHifChnl = pfe_hif_get_channel(ptrPlatform->hif, pfe_hif_chnl_from_phy_id(PFE_CFG_LOCAL_IF));
        }

        if (NULL_PTR == prHifChnl)
        {
            NXP_LOG_WARNING("Can't get HIF channel instance\n");
        }
        else
        {
            ret = pfe_hif_chnl_inspect_hw_state(prHifChnl);
            if (EOK == ret)
            {
                bRetVal = TRUE;
            }
            else
            {
                /* Enable RX */
                if (EOK != pfe_hif_chnl_rx_enable(prHifChnl))
                {
                    NXP_LOG_WARNING("Couldn't enable RX\n");
                }
                /* Enable TX */
                if (EOK != pfe_hif_chnl_tx_enable(prHifChnl))
                {
                    NXP_LOG_WARNING("Couldn't enable TX\n");
                }
                /* Enable the channel interrupts */
                pfe_hif_chnl_rx_irq_unmask(prHifChnl);
                pfe_hif_chnl_tx_irq_unmask(prHifChnl);
            }
        }
    }

    return bRetVal;
}

/**
* @brief         Shutdown the driver if it was initialized before
*/
static void Eth_PFE_LLD_ShutdownDriver(void)
{
    uint8 u8Ctr;
    pfe_phy_if_t *prHif = NULL_PTR;
    boolean bDetectHardReset;
    
    bDetectHardReset = Eth_PFE_LLD_DetectHardReset();
    if (TRUE == bDetectHardReset)
    {
        /* Remove software components that need to be sync with HW status in ReInit/DeInit sequence */
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
        if (NULL_PTR != prCommonChnlIRQ)
        {
            oal_irq_destroy(prCommonChnlIRQ);
        }
#endif
        pfe_platform_remove_sw_if();

        if (EOK == pfe_platform_remove())
        {
            ptrPlatform = NULL_PTR;
        }
        else
        {
            NXP_LOG_WARNING("Unable to remove the PFE platform\n");
        }
    }
    else
    {
        /* Make sure the HW is shut down */
        /* In case it was previously initialized, it MUST be deinitialized */
        for (u8Ctr = 0U; u8Ctr < ETH_43_PFE_NUM_CONTROLLER_CFG; u8Ctr++)
        {
            if (NULL_PTR != arPfeInterface[u8Ctr].prClient)
            {
                if ((Std_ReturnType)E_OK != Eth_PFE_LLD_DisableController(u8Ctr))
                {
                    NXP_LOG_WARNING("Unable to disable controller %u\n", (uint_t)u8Ctr);
                }
            }
            eSavedMode[u8Ctr]  = ETH_MODE_DOWN;
        }
        if(NULL_PTR != ptrPlatform)
        {
            /* Get the physical interface for our HIF channel */
            prHif = pfe_platform_get_phy_if_by_id(ptrPlatform, PFE_CFG_LOCAL_IF);
            if (NULL_PTR != prHif)
            {
                /* Disable HIF physical interfaces, this is required to flush BDP RX FIFO */
                if(EOK != pfe_phy_if_disable(prHif))
                {
                    NXP_LOG_WARNING("Failed to disable physical interface for the HIF\n");
                }
            }
        }
#ifdef PFE_CFG_PFE_SLAVE
        /* For slaves, the interface destroy process is done over RPC.
           It should be completed before destroying the hif driver */
        pfe_platform_destroy_ifaces();
#endif /* PFE_CFG_PFE_SLAVE */
#if ((TRUE == PFE_CFG_HIF_IRQ_ENABLED) || (TRUE == PFE_CFG_BMU_IRQ_ENABLED))
        /* In next called function we loose ability to process HIF interrupt */
        Eth_PFE_LLD_bIrqInitStatus = FALSE;
#endif
        DestroyHifDrv(prCommonChnlIRQ, prCommonHifDrv);
        prCommonHifDrv = NULL_PTR;
        if (NULL_PTR != ptrPlatform)
        {
            /* Shutdown the HW. Can be called multiple times. */
            if (EOK == pfe_platform_remove())
            {
                ptrPlatform = NULL_PTR;
            }
            else
            {
                NXP_LOG_WARNING("Unable to remove the PFE platform\n");
            }
        }
        Eth_PFE_LLD_ResetGlobalVar();
    }
}

/**
* @brief         Get EMAC instance associated to controller
*/
#if (STD_ON == ETH_43_GET_COUNTER_API) || \
    (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT) || \
    (STD_ON == ETH_43_GET_RXSTATS_API) || \
    (STD_ON == ETH_43_GET_TXSTATS_API) || \
    (STD_ON == ETH_43_GET_TXERROR_COUNTER_API)
static pfe_emac_t *Eth_PFE_LLD_GetEmacInstanceByControllerId(uint8 u8CtrlIdx)
{
    pfe_emac_t *prEmac = NULL_PTR;
    pfe_ct_phy_if_id_t emac_id;

    /*assign interface*/
    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];
    }
    return prEmac;
}
#endif /* (STD_ON == ETH_43_GET_COUNTER_API) ||
        * (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT) ||
        * (STD_ON == ETH_43_GET_RXSTATS_API) ||
        * (STD_ON == ETH_43_GET_TXSTATS_API) ||
        * (STD_ON == ETH_43_GET_TXERROR_COUNTER_API) */

#if (STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER)
static Std_ReturnType ChannelBdFlushRxPrepare(pfe_ct_phy_if_id_t DestHifChnl)
{
    Std_ReturnType Ret = E_NOT_OK;
    uint32 tx_bd_ring_addr;
    uint32 rx_bd_ring_addr;

    if (NULL_PTR == ptrPlatform)
    {
        NXP_LOG_ERROR("ChannelBdFlushRx: Platform not available");
    }
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
    else if(NULL_PTR == prCommonHifDrv)
    {
        NXP_LOG_ERROR("ChannelBdFlushRx: Hif driver not available");
    }
#endif
    else
    {
        const pfe_hif_chnl_t *const chnl = pfe_hif_get_channel_phy(ptrPlatform->hif, DestHifChnl);
        pfe_phy_if_t *const pSlaveHifPhyIf = pfe_phy_if_get_phy(DestHifChnl);

        if(chnl == NULL_PTR)
        {
            NXP_LOG_ERROR("ChannelBdFlushRx: Not a HIF channel");
        }
        else if(NULL_PTR == pSlaveHifPhyIf)
        {
            NXP_LOG_ERROR("ChannelBdFlushRx: PhyIf instance not available");
        }
        else if(EOK != pfe_phy_if_disable(pSlaveHifPhyIf))
        {
            NXP_LOG_ERROR("ChannelBdFlushRx: Failed to disable PhyIf");
        }
        else
        {
            /* Reading Rx and Tx BD Ring adresses and if one of them is zero BD flush is not performed*/
            tx_bd_ring_addr = pfe_hif_chnl_cfg_get_tx_bd_ring_addr(chnl->cbus_base_va, chnl->id);
            rx_bd_ring_addr = pfe_hif_chnl_cfg_get_rx_bd_ring_addr(chnl->cbus_base_va, chnl->id);
            if((0U != tx_bd_ring_addr) && (0U != rx_bd_ring_addr))
            {
                /* Unlock the if_db in case it was locked by slave driver on DestHifChnl */
                (void)pfe_if_db_unlock(DestHifChnl);
                /* Enable the Rx DMA in case it was disabled on DestHifChnl */
                pfe_hif_chnl_cfg_rx_enable(chnl->cbus_base_va, chnl->id);
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
                /* Release local Tx BDs - avoid failing due to them being full */
                pfe_hif_drv_tx_job(prCommonHifDrv);
#endif
                Ret = E_OK;
            }
        }
    }
    return Ret;
}

static Std_ReturnType ChannelBdFlushRxExecute(pfe_ct_phy_if_id_t DestHifChnl)
{
    uint32 u32BDpCnt;
    uint32 u32BDpCntReal;
    uint32 u32SafetyLoopCnt;
    Std_ReturnType Ret = E_OK;
    const pfe_hif_chnl_t *const chnl = pfe_hif_get_channel_phy(ptrPlatform->hif, DestHifChnl);
    PfeDevAssert(chnl != NULL_PTR);

    /* Read the number of BDs to be flushed */
    u32BDpCnt = pfe_hif_chnl_cfg_get_rx_bdp_rd_fifo_cnt(chnl->cbus_base_va, chnl->id);
    u32BDpCntReal = u32BDpCnt;
#if (ETH_43_PFE_CHANNEL_BD_FLUSH_MAX_TICK_COUNT > 0U)
    /* Apply user configured limit of frames to send in one function call */
    if (u32BDpCnt > ETH_43_PFE_CHANNEL_BD_FLUSH_MAX_TICK_COUNT)
    {
        u32BDpCnt = ETH_43_PFE_CHANNEL_BD_FLUSH_MAX_TICK_COUNT;
        Ret = ETH_43_PFE_E_AGAIN;
    }
#endif
    NXP_LOG_DEBUG("ChannelBdFlushRx: Sending %u dummy frames to HIF%u", (uint_t)u32BDpCnt, (uint_t)(chnl->id));
    while(0U != u32BDpCnt)
    {
        /* Flush an Rx BD from destination HIF */
        if(EOK == pfe_idex_send_dummy_frame(DestHifChnl))
        {
            u32BDpCnt--;
            u32BDpCntReal--;
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
            /* Release our Tx BDs (using the time we would otherwise spend waiting) */
            pfe_hif_drv_tx_job(prCommonHifDrv);
#endif
            /* Wait for the packet to be received on the slave HIF */
            u32SafetyLoopCnt = 0U;
            while(pfe_hif_chnl_cfg_get_rx_bdp_rd_fifo_cnt(chnl->cbus_base_va, chnl->id) > u32BDpCntReal)
            {
                if(u32SafetyLoopCnt > ETH_43_PFE_CHANNEL_BD_FLUSH_TIMEOUT_COUNTER)
                {   /* Safety timeout has been exceeded */
                    Ret = E_NOT_OK;
                    NXP_LOG_ERROR("ChannelBdFlushRx: Timeout. Pending %u frames", (uint_t)u32BDpCntReal);
                    u32BDpCnt = 0U; /* To exit all loops */
                    break;
                }
                u32SafetyLoopCnt++;
            }
        }
        else
        {
            Ret = E_NOT_OK;
            NXP_LOG_ERROR("ChannelBdFlushRx: Failed to send a frame");
            break;
        }
    }

    /* disable slave HIF after BD flush is finished */
    pfe_hif_chnl_cfg_rx_disable(chnl->cbus_base_va, chnl->id);
    pfe_hif_chnl_cfg_tx_disable(chnl->cbus_base_va, chnl->id);

    return Ret;
}
#endif /* (STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER) */

/*==================================================================================================
*                                       GLOBAL FUNCTIONS
==================================================================================================*/
trTxMeta *Eth_PFE_LLD_GetTxBufMeta(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{
    return &aarTxBuf[u8CtrlIdx][BufIdx].rMeta;
}

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
/*================================================================================================*/
Eth_PFE_LLD_trTxTsRef *Eth_PFE_LLD_GetTxBufTsRef(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{
    return &aarTxBuf[u8CtrlIdx][BufIdx].rTsRef;
}
#endif

/*================================================================================================*/
/**
* @brief         Configures PFE interface based on provided configuration structure
* @note          This function has to be called before first PFE clocks reach PFE IP or partition
*                reset has to be performed to sample the register.
*/
void Eth_PFE_LLD_InitInterfaces(const Eth_43_PFE_ConfigType *cfgPtr)
{
#ifdef PFE_CFG_PFE_SLAVE
    (void)cfgPtr;
#else
    uint8 u8CtrlCount;
    uint8 u8MiiMode = 0U;

#if (FALSE == PFE_CFG_SHARED_REG_VIA_MCU)
    /* In case of direct access, clear the register first */
    *(uint32 *)(uintptr_t)(S32G_GPR_BASE + PFE_EMACX_INTF_SEL_OFF) = 0U;
#endif /* PFE_CFG_SHARED_REG_VIA_MCU */

    /* Decode PFE cfg to g2 platform serdes */
    for (u8CtrlCount = 0U; u8CtrlCount < (uint8)ETH_43_PFE_NUM_CONTROLLER_CFG; u8CtrlCount++)
    {
        const pfe_ct_phy_if_id_t PhyIf = cfgPtr->pController[u8CtrlCount]->EthCtrlPhyIfID;
        uint8 u8EmacIdx;
        
        switch(PhyIf)
        {
            case PFE_PHY_IF_ID_EMAC0:
                u8EmacIdx = 0U;
                break;
            case PFE_PHY_IF_ID_EMAC1:
                u8EmacIdx = 1U;
                break;
            case PFE_PHY_IF_ID_EMAC2:
                u8EmacIdx = 2U;
                break;
            default:
                u8EmacIdx = 3U; /* Not EMAC, set invalid index */
                break;
        }

        if(u8EmacIdx < 3U) /* Only configure for EMACs, valid indexes */
        {
            switch (cfgPtr->pController[u8CtrlCount]->EthCtrlMiiType)
            {
                case EMAC_MODE_MII:
                    u8MiiMode = PFE_EMAC_MII;
                    break;
                case EMAC_MODE_RMII:
                    u8MiiMode = PFE_EMAC_RMII;
                    break;
                case EMAC_MODE_SGMII:
                    u8MiiMode = PFE_EMAC_SGMII;
                    break;
                case EMAC_MODE_RGMII:
                    u8MiiMode = PFE_EMAC_RGMII;
                    break;
                default:
                    u8MiiMode = PFE_EMAC_SGMII; /* Same as register default */
                    break;
            }
            SetSingleEmacMode(u8EmacIdx, u8MiiMode);
        }
    }
#endif
}

/*================================================================================================*/
/**
* @brief         Configures EMAC based on provided configuration structure
* @note          This function has to be called before first PFE clocks reach PFE IP or partition
*                reset has to be performed to sample the register.
*/
void Eth_PFE_LLD_InitEMACs(const Eth_43_PFE_ConfigType * cfgPtr)
{
#ifdef PFE_CFG_PFE_SLAVE
    (void)cfgPtr;
#else
    uint8 u8EmacIdx = 0U;

    /* Set EthCtrlMiiType to corresponding EMACs */
    for (u8EmacIdx = 0U; u8EmacIdx < (uint8)ETH_43_PFE_NUM_EMAC; u8EmacIdx++)
    {
        switch (cfgPtr->emac[u8EmacIdx].EthCtrlMiiType)
        {
            case EMAC_MODE_MII:
                SetSingleEmacMode(u8EmacIdx, PFE_EMAC_MII);
                break;
            case EMAC_MODE_RMII:
                SetSingleEmacMode(u8EmacIdx, PFE_EMAC_RMII);
                break;
            case EMAC_MODE_SGMII:
                SetSingleEmacMode(u8EmacIdx, PFE_EMAC_SGMII);
                break;
            case EMAC_MODE_RGMII:
                SetSingleEmacMode(u8EmacIdx, PFE_EMAC_RGMII);
                break;
            default:
                /* Do nothing */
                break;
        }
    }
#endif
}

#ifdef PFE_CFG_PFE_SLAVE
/*================================================================================================*/
static Std_ReturnType PlatformDrvPrepare_SlaveWaitForIpReady(void)
{
    Std_ReturnType result = E_NOT_OK;
    uint32 slave_tmout = PFE_CFG_SLAVE_HIF_MASTER_UP_TMOUT;
    boolean is_ip_ready = Local_Macro_hal_ip_ready_get();

    NXP_LOG_INFO("Wait for IP-ready ...\n");
    while(!is_ip_ready)
    {
        oal_time_usleep(1000U);
        is_ip_ready = Local_Macro_hal_ip_ready_get();

        /* Decrement only for slave_tmout > 0 */
        if(slave_tmout != 0u)
        {
            slave_tmout--;
            if(slave_tmout == 0u)
            {
                break;
            }
        }
    }

    if(is_ip_ready)
    {
        NXP_LOG_INFO("Detected IP-ready\n");
        result = E_OK;
    }
    else
    {
        NXP_LOG_RAW_ERROR("Detection IP-ready timeouted\n");
        result = E_NOT_OK;
#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_DRIVER_RUNTIME_ERR_IP_READY, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
    }

    return result;
}
#endif /* PFE_CFG_PFE_SLAVE */

#if defined(PFE_CFG_PFE_MASTER) && IS_RECEIVE_MALFORMED_ALLOWED
/*================================================================================================*/
static Std_ReturnType PlatformDrvPrepare_EnRxMalformed(void)
{
    Std_ReturnType result = E_NOT_OK;
    pfe_fw_feature_t *receive_malformed;

    /* Get receive_malformed feature */
    if (EOK != pfe_class_get_feature(ptrPlatform->classifier, &receive_malformed, "receive_malformed"))
    {
        NXP_LOG_ERROR("Unable to get feature\n");
    }
    /* Enable receive_malformed feature */
    else if (EOK != pfe_fw_feature_set_val(receive_malformed, 1U))
    {
        NXP_LOG_ERROR("Enable receive_malformed feature failed\n");
    }
    else {
        result = E_OK;
    }

    return result;
}
#endif    /* master, receive malformed */

/*================================================================================================*/
static Std_ReturnType PlatformDrvPrepare_EnablePhyIf(void)
{
    Std_ReturnType result  = E_NOT_OK;
    /*  Get the physical interface for our HIF channel */
    pfe_phy_if_t *prHif = pfe_platform_get_phy_if_by_id(ptrPlatform, PFE_CFG_LOCAL_IF);

    if (NULL_PTR == prHif)
    {
        NXP_LOG_ERROR("Can't get physical interface for the HIF\n");
    }
    else
    {
        /* Enable HIF physical interfaces */
        if (EOK != pfe_phy_if_enable(prHif))
        {
            NXP_LOG_ERROR("Failed to enable physical interface for the HIF\n");
        }
        else
        {
            result = E_OK;
        }
    }

    return result;
}

/*================================================================================================*/
static Std_ReturnType PlatformDrvPrepare_ShutdownConfigInit(void)
{
    Std_ReturnType retVal = E_OK;

#ifdef PFE_CFG_PFE_MASTER
    pfe_fw_t rFirmware;
    rFirmware.class_data = PFE_CLASS_FW_BINARY;
#endif /* PFE_CFG_PFE_MASTER */

    /* Shutdown the driver if it was initialized before */
    Eth_PFE_LLD_ShutdownDriver();
    
    /*  Initialize the platform driver */
#ifdef PFE_CFG_PFE_MASTER
    rPlatformCfg.fw = &rFirmware;
#endif

#ifdef ETH_43_PFE_COMMON_HIF
    rPlatformCfg.local_hif = ETH_43_PFE_COMMON_HIF;
#else
    rPlatformCfg.local_hif = ETH_43_PFE_CFG_CTRLHIF(0U);
#endif
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    /* Initialize fci onwership */
    rPlatformCfg.hif_fci_owner_chnls_mask = pfe_fci_owner_hif_from_phy_id(ETH_43_PFE_COMMON_HIF);
#ifdef PFE_CFG_HIF0_OWNERSHIP
    rPlatformCfg.hif_fci_owner_chnls_mask |= FCI_OWNER_HIF_0;
#endif /* PFE_CFG_HIF0_OWNERSHIP */
#ifdef PFE_CFG_HIF1_OWNERSHIP
    rPlatformCfg.hif_fci_owner_chnls_mask |= FCI_OWNER_HIF_1;
#endif /* PFE_CFG_HIF1_OWNERSHIP */
#ifdef PFE_CFG_HIF2_OWNERSHIP
    rPlatformCfg.hif_fci_owner_chnls_mask |= FCI_OWNER_HIF_2;
#endif /* PFE_CFG_HIF2_OWNERSHIP */
#ifdef PFE_CFG_HIF3_OWNERSHIP
    rPlatformCfg.hif_fci_owner_chnls_mask |= FCI_OWNER_HIF_3;
#endif /* PFE_CFG_HIF3_OWNERSHIP */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#ifdef PFE_CFG_G2_ORDERED_CLASS_WRITES
    rPlatformCfg.g2_ordered_class_writes = TRUE;
#else
    rPlatformCfg.g2_ordered_class_writes = FALSE;
#endif

    /*  Initialize Tx buffer pools */
    retVal = ConfigureTxBuffers();

    if(retVal == (Std_ReturnType)E_OK)
    {
        if(EOK != pfe_platform_init(&rPlatformCfg)) {
            retVal = E_NOT_OK;
            NXP_LOG_ERROR("Unable to initialize the platform\n");
        }
        else
        {
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#ifdef PFE_CFG_PFE_MASTER
            /* Set IP-ready */
            Local_Macro_hal_ip_ready_set(TRUE);
#endif /* PFE_CFG_PFE_MASTER */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
            ptrPlatform = pfe_platform_get_instance();
            /*  Get the PFE instance pointer */
            if (NULL_PTR == ptrPlatform)
            {
                retVal = E_NOT_OK;
                NXP_LOG_ERROR("Could not get PFE platform instance\n");
            }
        }
    }

    return retVal;
}

/**
* @brief         Prepares and initializes common part of PFE drivers
* @details       Prepares cache, memory management, main mutex, loads firmware and initializes
*                platform driver, HIF driver and FCI driver.
* @retval        E_NOT_OK The Platform drivers are not prepared
* @retval        E_OK The Platform drivers are initialized successfully
*/
Std_ReturnType Eth_PFE_LLD_PlatformDrvPrepare(void)
{
    Std_ReturnType retVal = E_OK;

    NXP_LOG_INFO("Driver commit hash: %s\n", rPlatformCfg.commit_hash);
    NXP_LOG_INFO("Driver version: %s\n", rPlatformCfg.driver_version);

#ifdef PFE_CFG_PFE_MASTER
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
    bDetectBmuInit = FALSE;
#endif /* PFE_CFG_BMU_IRQ_ENABLED */
#endif /* PFE_CFG_PFE_MASTER */

#ifdef PFE_CFG_PFE_SLAVE
    retVal = PlatformDrvPrepare_SlaveWaitForIpReady();
    if (retVal != (Std_ReturnType)E_NOT_OK)
    {
        retVal = PlatformDrvPrepare_ShutdownConfigInit();
    }
#else 
    retVal = PlatformDrvPrepare_ShutdownConfigInit();
#endif /* PFE_CFG_PFE_SLAVE */

#if defined(PFE_CFG_PFE_MASTER) && IS_RECEIVE_MALFORMED_ALLOWED
    /* Get receive_malformed feature */
    if (retVal != (Std_ReturnType)E_NOT_OK)
    {
        retVal = PlatformDrvPrepare_EnRxMalformed();
    }
#endif /* PFE_CFG_PFE_MASTER, receive malformed */

    /*  Get HIF driver instance */
    if (retVal != (Std_ReturnType)E_NOT_OK)
    {
        if (FALSE == CreateHifDrv(  PFE_CFG_LOCAL_IF,
                                    (PFE_CFG_LOCAL_IF == PFE_PHY_IF_ID_HIF_NOCPY) 
                                    ? rPlatformCfg.irq_vector_hif_nocpy
                                    : rPlatformCfg.irq_vector_hif_chnls[ETH_43_PFE_COMMON_HIF - PFE_PHY_IF_ID_HIF0],
                                    &prCommonHifChnl,
                                    &prCommonChnlIRQ,
                                    &prCommonHifDrv
                                 )
        )
        {
            prCommonHifDrv = NULL_PTR;
            retVal = E_NOT_OK;
            NXP_LOG_ERROR("Failed to create hif driver\n");
        }
    }
    if(retVal != (Std_ReturnType)E_NOT_OK)
    {
        retVal = PlatformDrvPrepare_EnablePhyIf();
    }

    return retVal;
}

/*================================================================================================*/
/**
* @brief         Shutdown the driver gracefully 
*/
void Eth_PFE_LLD_DeInit(void)
{
    uint8 u8Ctr;
    boolean bDrvInitialized = FALSE;

    /* Check if the driver was initialized before */
    bDrvInitialized = Eth_PFE_LLD_Check_Driver_Init();
    if (FALSE == bDrvInitialized)
    {
        NXP_LOG_INFO("The driver instance has not been initialized. No action was taken to shut down the driver\n");
    }
    else
    {
        /* Set the state to ETH_STATE_UNINIT before doing any changes to
           ensure that any preempting function (interrupt handler) will
           correctly stop its execution even if the state had been
           ETH_43_PFE_STATE_ACTIVE when the Eth_43_PFE_DeInit was called. */
        for (u8Ctr = 0U; u8Ctr < ETH_43_PFE_NUM_CONTROLLER_CFG; u8Ctr++)
        {
            Eth_43_PFE_CtrlState[u8Ctr] = ETH_STATE_UNINIT;
        }

        /* Shutdown the driver */
        Eth_PFE_LLD_ShutdownDriver();
    }
}

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
/*================================================================================================*/
static void InterfacePrepare_InitTSQueue(trPfeDev *prPfeDev)
{
    uint8 u8FifoCnt;
    uint16 u16BufCnt;
    uint8 u8FifoNum = Eth_43_PFE_InternalCfgPtr->pController[prPfeDev->u8CtrlIdx]->EthCtrlEgressFifoCnt;
    
    for (u8FifoCnt = 0u; u8FifoCnt < u8FifoNum; u8FifoCnt++)
    {
        prPfeDev->u16TSQueueRead[u8FifoCnt] = 0U;
        prPfeDev->u16TSQueueWrite[u8FifoCnt] = 0U;
        for (u16BufCnt = 0U; u16BufCnt < ETH_43_PFE_MAX_FIFO_TX_BUF_CNT; u16BufCnt++)
        {
            prPfeDev->TSQueue[u8FifoCnt][u16BufCnt] = INVALID_TX_INDEX;
        }
    }
}
#endif

#ifdef PFE_CFG_PFE_MASTER
/*================================================================================================*/
static errno_t InterfacePrepare_InitEmacMasterRx(const trPfeDev *prPfeDev)
{
    errno_t res = EOK;

    /* Configure promiscuous mode */
    if(TRUE == ETH_43_PFE_CFG_PROMISCUOUS(prPfeDev->u8CtrlIdx))
    {
        if (EOK != pfe_phy_if_promisc_enable(prPfeDev->prPhyIf))
        {
            NXP_LOG_ERROR("Failed to enable promiscuous mode on EMAC\n");
            res = EINVAL;
        }
    }
    else
    {
        if (EOK != pfe_phy_if_promisc_disable(prPfeDev->prPhyIf))
        {
            NXP_LOG_ERROR("Failed to disable promiscuous mode on EMAC\n");
            res = EINVAL;
        }
    }
    /*  Add controller's configured MAC address */
    if (EOK == res)
    {
        res = pfe_phy_if_add_mac_addr(prPfeDev->prPhyIf, prPfeDev->au8MacAddr, rPlatformCfg.local_hif);
        if (EEXIST == res)
        {
            res = EOK;
        }
        if (EOK != res)
        {
            NXP_LOG_ERROR("Failed to set MAC address to EMAC%hhu\n", prPfeDev->u8CtrlIdx);
            res = EINVAL;
        }
    }
    /* Direct frames from EMAC to our HIF */
    if (EOK == res)
    {
        pfe_log_if_t *prLogIf = pfe_phy_if_get_default_log_if(prPfeDev->prPhyIf);
        
        if (NULL_PTR == prLogIf)
        {
            NXP_LOG_ERROR("Failed to get default log_if interface for (%s)\n", pfe_phy_if_get_name(prPfeDev->prPhyIf));
            res = EINVAL;
        }
        else if (EOK != pfe_log_if_set_egress_ifs(prLogIf, ((uint32)1U << (uint8)prPfeDev->HifId)))
        {
            NXP_LOG_ERROR("Can't set egress interface (%s)\n", pfe_log_if_get_name(prLogIf));
            res = EINVAL;
        }
        else
        {
            ; /* All done */
        }
    }
    return res;
}

/*================================================================================================*/
static errno_t InterfacePrepare_MasterConfigEMAC(const trPfeDev *prPfeDev)
{
    errno_t res;

    /* FIXME AAVB-9597 - delete this call of InterfacePrepare_InitEmacMasterLink */
    res = InterfacePrepare_InitEmacMasterLink(prPfeDev);
    /* Configure MAC addresses and direct Rx traffic to our HIF */
    if(EOK == res)
    {
        res = InterfacePrepare_InitEmacMasterRx(prPfeDev);
    }
    /* Optionally configure loopback mode on associated EMAC */
    if((EOK == res) && (TRUE == ETH_43_PFE_CFG_EMAC_LOOPBACK(prPfeDev->u8CtrlIdx)))
    {
        res = pfe_phy_if_loopback_enable(prPfeDev->prPhyIf);
        if (EOK != res)
        {
            NXP_LOG_ERROR("EMAC loopback enable failed\n");
        }
    }
    /* Configure traffic schedulling and shaping */
    if(EOK == res)
    {
        res = ConfigureSchedulerAndShaper(prPfeDev->u8CtrlIdx);
        if (EOK != res)
        {
            NXP_LOG_ERROR("Failed to configure scheduler and shaper");
        }
    }
    return res;
}

/*================================================================================================*/
static errno_t InterfacePrepare_InitEmacMasterLink(const trPfeDev *prPfeDev)
{
    /* FIXME AAVB-9597 - delete this function */
    errno_t res = EINVAL;
    const pfe_emac_t *prPfeEmac = pfe_phy_if_get_emac(prPfeDev->prPhyIf);

    if (NULL_PTR == prPfeEmac)
    {
        NXP_LOG_ERROR("Can't get EMAC instance from physical interface.\n");
    }
    else if (EOK != pfe_emac_set_link_speed(prPfeEmac, ETH_43_PFE_CFG_LINKSPEED(prPfeDev->u8CtrlIdx)))
    {
        NXP_LOG_ERROR("Could not set EMAC link speed.\n");
    }
    else if (EOK != pfe_emac_set_link_duplex(prPfeEmac, ETH_43_PFE_CFG_LINKDUPLEX(prPfeDev->u8CtrlIdx)))
    {
        NXP_LOG_ERROR("Could not set EMAC link duplex.\n");
    }
    else
    {
        res = EOK;
    }

    return res;
}

#else /* not PFE_CFG_PFE_MASTER */
/*================================================================================================*/
static errno_t InterfacePrepare_SlaveConfigEMAC(const trPfeDev *prPfeDev)
{
    errno_t res;

    /*  Add controller's configured MAC address */
    res = pfe_phy_if_add_mac_addr(prPfeDev->prPhyIf, prPfeDev->au8MacAddr, rPlatformCfg.local_hif);
    if (EEXIST == res)
    {
        res = EOK;
    }
    if (EOK != res)
    {
        NXP_LOG_ERROR("Failed to set MAC address to EMAC%hhu\n", prPfeDev->u8CtrlIdx);
        res = EINVAL;
    }

    return res;
}
#endif /* PFE_CFG_PFE_MASTER */

/*================================================================================================*/
/**
* @brief         Configuration of one instance of interface
* @details       Configures one interface (e.g. hardware Ethernet port), in MCAL known as
*                "controller instance" (here the situation is different than MCAL assumes,
*                there is one controller with multiple interfaces, while MCAL assumes multiple
*                controllers with one interface each).
* @param[in]     u8CtrlIdx Interface (controller) to be configured
*/
void Eth_PFE_LLD_InterfacePrepare(uint8 u8CtrlIdx)
{
    if (NULL_PTR == ptrPlatform)
    {
        NXP_LOG_ERROR("Platform driver not prepared\n");
    }
    else if (NULL_PTR == prCommonHifDrv)
    {
        NXP_LOG_ERROR("Common HIF driver not prepared\n");
    }
    else
    {   /* Basic checks passed */
        trPfeDev *prPfeDev = &(arPfeInterface[u8CtrlIdx]);
        prPfeDev->bInterfacePrepared = FALSE;

        (void)autolibc_memcpy(prPfeDev->au8MacAddr, ETH_43_PFE_CFG_MACADDRESS(u8CtrlIdx), 6U);

        prPfeDev->u8CtrlIdx = u8CtrlIdx;
        prPfeDev->bStarted = FALSE;
        prPfeDev->prClient = NULL_PTR; /* Always initialize as it is used for checks */
#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
        InterfacePrepare_InitTSQueue(prPfeDev);
#endif
        /*  Get components */
        prPfeDev->prPlatform = ptrPlatform;
        prPfeDev->HifId = ETH_43_PFE_COMMON_HIF;
        prPfeDev->prHifChnl = prCommonHifChnl;
        prPfeDev->prHifChnlIRQ = prCommonChnlIRQ;
        prPfeDev->prHifDrv = prCommonHifDrv;

        if (PFE_CTRL_TYPE_AUX == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
        {   /* AUX interface */
            prPfeDev->prPhyIf = NULL_PTR;
            /* AUX done, the final result will be checked in next function */
            prPfeDev->bInterfacePrepared = TRUE;
        }
        else
        {   /* EMAC or HIF */
            pfe_ct_phy_if_id_t temp_phy_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);

            /* Get EMAC/HIF to attach to this controller */
            prPfeDev->prPhyIf = pfe_platform_get_phy_if_by_id(ptrPlatform, temp_phy_id);
            if (NULL_PTR == prPfeDev->prPhyIf)
            {
                NXP_LOG_ERROR("Could not get EMAC/HIF %u\n", (uint_t)temp_phy_id);
            }
            else
            {
                if (PFE_CTRL_TYPE_HIF == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
                {   /* HIF interface (hif0-hif3, hifnocpy) */
                    /* HIF done, the final result will be checked in next function */
                    prPfeDev->bInterfacePrepared = TRUE;
                }
                else
                {   /* EMAC interface */
#ifdef PFE_CFG_PFE_MASTER
                    if (EOK == InterfacePrepare_MasterConfigEMAC(prPfeDev))
#else
                    if (EOK == InterfacePrepare_SlaveConfigEMAC(prPfeDev))
#endif
                    {
                        /* EMAC done, the final result will be checked in next function */
                        prPfeDev->bInterfacePrepared = TRUE;
                    }
                }
            }
        }
    }
}

#ifdef PFE_CFG_PFE_MASTER
/*================================================================================================*/
static errno_t Eth_PFE_LLD_EMACPrepare_Config(const pfe_phy_if_t *prEmac, const Eth_43_PFE_EmacCfg *pEmacCfg)
{
    errno_t res = EINVAL;
    const pfe_emac_t *prPfeEmac = pfe_phy_if_get_emac(prEmac);

    if (NULL_PTR == prPfeEmac)
    {
        NXP_LOG_ERROR("Can't get EMAC instance from physical interface.\n");
    }
    else if (EOK != pfe_emac_set_link_speed(prPfeEmac, pEmacCfg->EthCtrlSpeed))
    {
        NXP_LOG_ERROR("Could not set EMAC link speed.\n");
    }
    else if (EOK != pfe_emac_set_link_duplex(prPfeEmac, pEmacCfg->EthCtrlDuplex))
    {
        NXP_LOG_ERROR("Could not set EMAC link duplex.\n");
    }
    else 
    {
        res = EOK;
    }

    return res;
}

/*================================================================================================*/
/**
* @brief         General Configuration for all instances of EMAC
* @details       Configures all EMACs
*/
void Eth_PFE_LLD_EMACPrepare(void)
{
    uint8 u8EmacIdx;
    const pfe_phy_if_t *prEmac;
    const pfe_ct_phy_if_id_t emac_ids[] = {PFE_PHY_IF_ID_EMAC0, PFE_PHY_IF_ID_EMAC1, PFE_PHY_IF_ID_EMAC2};

    for (u8EmacIdx = 0U; u8EmacIdx < (uint8)ETH_43_PFE_NUM_EMAC; u8EmacIdx++)
    {
        if (EMAC_SPEED_INVALID != ((Eth_43_PFE_InternalCfgPtr->emac[u8EmacIdx])).EthCtrlSpeed)
        {
            /* Normal interface */
            prEmac = pfe_platform_get_phy_if_by_id(ptrPlatform, emac_ids[u8EmacIdx]);
            if (NULL_PTR == prEmac)
            {
                NXP_LOG_ERROR("Could not get EMAC %u\n", (uint_t)(u8EmacIdx));
            }
            else if(EOK == Eth_PFE_LLD_EMACPrepare_Config(prEmac, &Eth_43_PFE_InternalCfgPtr->emac[u8EmacIdx]))
            {
                break; /* config failed */
            }
            else 
            {
                /* ok */
            }
        }
    }
}
#endif

/*================================================================================================*/
/**
* @brief         Configures the controller
* @details       Function
*                -# enables/disables Received frame interrupts
*                -# enables/disables Transmitted frame interrupts
*                -# clears MAC addresses hash tables
*                -# configures the controller MAC address
*                -# configures the MII
*                -# configures RCR and TCR registers
*                -# configures the maximal received frame length
*                -# configures all other registers including unused ones
*                   to prevent corrupted values staying there forever
* @param[in]     u8CtrlIdx Index of controller which will be configured
* @note          The controller is ready for use after the function finishes
*                however the buffers configuration must be still done.
*/
Std_ReturnType Eth_PFE_LLD_ConfigureController(const uint8 u8CtrlIdx)
{
    Std_ReturnType Status = E_NOT_OK;
#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
    uint32 u32Count;
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

    /* Everything is done, just check initialization status */
    if (TRUE == arPfeInterface[u8CtrlIdx].bInterfacePrepared)
    {
        Status = E_OK;
    }

#if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        for (u32Count = 0U; u32Count < (uint32)MAX_DEM_FRAME_ERRORS; u32Count++)
        {
            u32DemErrorCounters[u8CtrlIdx][u32Count] = 0U;
        }
    }
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

    return Status;
}

/*================================================================================================*/
/* Check whether the driver was initialized before */
/**
* @brief         Check whether the driver was initialized before
* @details       This function is intended to check whether the driver was initialized or not by reading Eth_43_PFE_CtrlState.
* @retval        TRUE Driver was initialized
* @retval        FALSE Driver was not initialized
*/
boolean Eth_PFE_LLD_Check_Driver_Init(void)
{
    uint8 u8CtrlIdx;
    boolean bDrvInitialized = FALSE;

    /* Check if the driver was initialized before */
    for (u8CtrlIdx = 0U; u8CtrlIdx < ETH_43_PFE_NUM_CONTROLLER_CFG; u8CtrlIdx++)
    {
        if (ETH_STATE_INIT == Eth_43_PFE_CtrlState[u8CtrlIdx])
        {
            bDrvInitialized = TRUE;
            break;
        }
    }
    return bDrvInitialized;
}

/*================================================================================================*/
/**
* @brief         Checks whether the interface was successfully connected to platform driver
* @details

* @param[in]     u8CtrlIdx Interface to be checked
* @return        Controller accessibility
* @retval        TRUE Interface is accessible.
* @retval        FALSE Interface access failed.
*/
boolean Eth_PFE_LLD_CheckInitializationStatus(const uint8 u8CtrlIdx)
{
    boolean bControllerAvailable = FALSE;

    if ((PFE_CTRL_TYPE_AUX == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
         || (PFE_CTRL_TYPE_HIF == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx)))
    {
        if (TRUE == arPfeInterface[u8CtrlIdx].bInterfacePrepared)
        {
            bControllerAvailable = TRUE;
        }
    }
    else  /* PFE_CTRL_TYPE_EMAC */
    {   
        if (NULL_PTR == arPfeInterface[u8CtrlIdx].prPhyIf)
        {
            NXP_LOG_ERROR("Physical interface not created, u8CtrlIdx=%hhu\n", u8CtrlIdx);
        }
        else if (FALSE == arPfeInterface[u8CtrlIdx].bInterfacePrepared)
        {
            NXP_LOG_ERROR("Function Eth_PFE_LLD_InterfacePrepare failed, u8CtrlIdx=%hhu\n", u8CtrlIdx);
        }
        else
        {
            bControllerAvailable = TRUE;
        }
    }

    return bControllerAvailable;
}

/*================================================================================================*/
static boolean EnableController_InitFifos(const Eth_43_PFE_CtrlCfgType *pCtrlCfg)
{
    boolean bResult = TRUE;
    uint32 ii;
    uint32 fifoDepth;
    fifo_t *tFifo;
    void **vpData;

    /* initialize TX FIFOs */
    tFifo = pCtrlCfg->pEgressCfg->EthCtrlConfigEgressFifo;
    vpData = pCtrlCfg->pEgressCfg->EthCtrlConfigEgressFifoData;
    fifoDepth = RXTX_FIFO_ALIGNED_DEPTH(pCtrlCfg->EthCtrlEgressFifoDepth);

    for (ii = 0U; ii < pCtrlCfg->EthCtrlEgressFifoCnt; ii++)
    {
        if (NULL_PTR == fifo_create(pCtrlCfg->EthCtrlEgressFifoDepth, tFifo, vpData))
        {
            bResult = FALSE;
            break;
        }
        tFifo++;
        vpData += fifoDepth;
    }

    /* initialize RX FIFOs */
    if(TRUE == bResult)
    {
        tFifo = pCtrlCfg->pIngressCfg->EthCtrlConfigIngressFifo;
        vpData = pCtrlCfg->pIngressCfg->EthCtrlConfigIngressFifoData;
        fifoDepth = RXTX_FIFO_ALIGNED_DEPTH(pCtrlCfg->EthCtrlIngressFifoDepth);

        for (ii = 0U; ii < ETH_43_PFE_MAX_RXFIFO_CONFIG; ii++)
        {
            if (NULL_PTR == fifo_create(pCtrlCfg->EthCtrlIngressFifoDepth, tFifo, vpData))
            {
                bResult = FALSE;
                break;
            }
            tFifo++;
            vpData += fifoDepth;
        }
    }

    return bResult;
}

/*================================================================================================*/
static boolean EnableController_Common(const trPfeDev *prPfeDev)
{
    boolean bResult = TRUE;
    (void)prPfeDev;
#ifndef PFE_CFG_MULTI_INSTANCE_SUPPORT
    if (EOK != pfe_hif_drv_start(prPfeDev->prHifDrv))
    {
        NXP_LOG_ERROR("HIF driver start failed\n");
        bResult = FALSE;
    }
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#ifndef PFE_CFG_HIF_NOCPY_SUPPORT
    if(TRUE == bResult)
    {
        if (EOK != InitializeTxHeaders(prPfeDev->u8CtrlIdx, prPfeDev->prClient))
        {
            NXP_LOG_ERROR("Initialize TX headers failed\n");
            bResult = FALSE;
        }
    }
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

    return bResult;
}

/*================================================================================================*/
static boolean EnableController_Aux(trPfeDev *prPfeDev, pfe_hif_drv_client_rx_tx_count *pclient_queue, pfe_hif_drv_client_fifo_queue *pclient_fifo_queue)
{
    boolean bResult = FALSE;

    /*  Connect to HIF */
    prPfeDev->prClient = pfe_hif_drv_aux_client_register(
                                                    prPfeDev->prHifDrv,
                                                    pclient_queue,
                                                    pclient_fifo_queue,
                                                    &ClientEventHdlr,
                                                    (void *)prPfeDev
                                            );
    if(NULL_PTR != prPfeDev->prClient)
    {
        if(TRUE == EnableController_Common(prPfeDev))
        {
            bResult = TRUE;
            prPfeDev->bStarted = TRUE;
            NXP_LOG_INFO("AUX interface (Controller %hhu) was started\n", prPfeDev->u8CtrlIdx);
        }
    }

    return bResult;
}

/*================================================================================================*/
static boolean EnableController_HifEmac(trPfeDev *prPfeDev, pfe_hif_drv_client_rx_tx_count *pclient_queue, pfe_hif_drv_client_fifo_queue *pclient_fifo_queue)
{
    boolean bResult = FALSE;

    /*  Connect to HIF */
    prPfeDev->prClient = pfe_hif_drv_client_register(
                                                    prPfeDev->prHifDrv, /* HIF Driver instance */
                                                    pfe_phy_if_get_id(prPfeDev->prPhyIf),/* Physical interface */
                                                    pclient_queue,       /* TX/RX Queue Count */
                                                    pclient_fifo_queue,  /* TX/RX Queue FIFO */
                                                    (ETH_43_PFE_CFG_ACCEPTALLTRAFFIC(prPfeDev->u8CtrlIdx) != FALSE),
                                                    &ClientEventHdlr,   /* Client's event handler */
                                                    (void *)prPfeDev    /* Meta data */
                                                    );
    if(NULL_PTR != prPfeDev->prClient)
    {
        if(EOK != pfe_hif_drv_client_set_inject_if(prPfeDev->prClient, pfe_phy_if_get_id(prPfeDev->prPhyIf)))
        {
            NXP_LOG_ERROR("Can't set inject interface\n");
        }
        else
        {
            if(TRUE == EnableController_Common(prPfeDev))
            {
                bResult = TRUE;
                NXP_LOG_INFO("Controller %hhu was started\n", prPfeDev->u8CtrlIdx);
            }
        }
    }

    prPfeDev->bStarted = bResult;

    return bResult;
}
/*================================================================================================*/
/*================================================================================================*/
/**
* @brief         Starts the controller
* @param[in]     u8CtrlIdx Index of controller which will be enabled
* @details       Function enables the controller after that it activates receive
*                and transmit buffer descriptors rings.
* @retval        TRUE Successfully enabled
* @retval        FALSE Failed to enable
*/
boolean Eth_PFE_LLD_EnableController(const uint8 u8CtrlIdx)
{
    boolean bResult;
    trPfeDev *prPfeDev = &(arPfeInterface[u8CtrlIdx]);
    const Eth_43_PFE_CtrlCfgType *pCtrlCfg;

    /* Check initialization results */
    bResult = prPfeDev->bInterfacePrepared;

    if((TRUE == bResult) && (FALSE == prPfeDev->bStarted))
    {
        pCtrlCfg = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx];

        /* initialize FIFOs */
        bResult = EnableController_InitFifos(pCtrlCfg);

        if(TRUE == bResult)
        {
            pfe_hif_drv_client_rx_tx_count client_queue = {
                .txq_num = pCtrlCfg->EthCtrlEgressFifoCnt, /* Number of TX queues */
                .rxq_num = ETH_43_PFE_MAX_RXFIFO_CONFIG    /* Number of RX queues */
            };
            pfe_hif_drv_client_fifo_queue client_fifo_queue = {
                .txq_fifo = pCtrlCfg->pEgressCfg->EthCtrlConfigEgressFifo,  /* TX Queue FIFO */
                .rxq_fifo = pCtrlCfg->pIngressCfg->EthCtrlConfigIngressFifo /* RX Queue FIFO */
            };

            if(PFE_CTRL_TYPE_AUX == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
            {
                bResult = EnableController_Aux(prPfeDev, &client_queue, &client_fifo_queue);
            }
            else if(PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
            {
                if(FALSE == EnableController_HifEmac(prPfeDev, &client_queue, &client_fifo_queue))
                {
                    bResult = FALSE;
                }
                else
                {
                    bResult = (EOK == pfe_phy_if_enable(prPfeDev->prPhyIf)) ? TRUE : FALSE;
                }
            }
            else /* PFE_CTRL_TYPE_HIF */
            {
                bResult = EnableController_HifEmac(prPfeDev, &client_queue, &client_fifo_queue);
            }
        }
    }

    return bResult;
}

/*================================================================================================*/
/**
* @brief         Stops the controller
* @details       Stops receiver, disables transmit, processes remaining buffers from queues (if any).
*                All pending Tx confirmations are reported before this function returns.
* @param[in]     u8CtrlIdx Index of controller which will be disabled
*/
Std_ReturnType Eth_PFE_LLD_DisableController(const uint8 u8CtrlIdx)
{
    trPfeDev *prPfeDev = &(arPfeInterface[u8CtrlIdx]);
    Std_ReturnType RetVal = E_OK;

    prPfeDev->bStarted = FALSE;

    if(NULL_PTR != prPfeDev->prClient)
    {
        /* In polling mode do Rx job to release buffers from HIF ring */
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
        pfe_hif_drv_rx_job((void *)prPfeDev->prHifDrv);
        /*  Note that here is a race condition as new packet can be received now,
            but it does not matter as it will be discarded later anyway */
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
        /* Automatically releases remaining Rx and Tx buffers in client queues: */
        pfe_hif_drv_client_unregister(prPfeDev->prClient);
        prPfeDev->prClient = NULL_PTR;
    }
    /* Release all remaining Tx buffers (previously provided but not sent) */
    ReleaseAllCtrlTxBuffers(u8CtrlIdx);

    return RetVal;
}

/*================================================================================================*/
/**
* @brief         Check whether the controller is running
* @details       Function checks the ECR[ETHER_EN] bit to determine whether
*                the controller has been stopped or whether it is running.
* @param[in]     u8CtrlIdx Index of controller which will be checked active Status
* @return        The current controller mode.
* @retval        ETH_MODE_ACTIVE The controller is running.
* @retval        ETH_MODE_DOWN The controller is stopped.
*/
Eth_ModeType Eth_PFE_LLD_CheckControllerIsActive(const uint8 u8CtrlIdx)
{
    Eth_ModeType eReturnValue; /* Return value holder */

    if(TRUE == arPfeInterface[u8CtrlIdx].bStarted)
    {
        eReturnValue = ETH_MODE_ACTIVE;
    }
    else
    {
        eReturnValue = ETH_MODE_DOWN;
    }
    return eReturnValue;
}
/*================================================================================================*/
/**
* @brief         Provides the controllers MAC address
* @param[in]     u8CtrlIdx Index of controller to get PhysAddress
* @param[out]    pu8PhysAddr Pointer to array where 6 bytes of physical address will be written
*/
void Eth_PFE_LLD_GetPhysicalAddress
(
    const uint8 u8CtrlIdx,
    uint8 * pu8PhysAddr
)
{
    (void)autolibc_memcpy(pu8PhysAddr, arPfeInterface[u8CtrlIdx].au8MacAddr, 6U);
}
/*================================================================================================*/
/**
* @brief         Update physical address of the controller.
* @param[in]     pPhysAddrPtr Pointer to MAC address which should set to
*                controller. The address in network byte order stored into 6
*                bytes of memory.
* @param[in]     u8CtrlIdx Index of controller to set the PhysAddr
* @caution       Call of function Eth_43_PFE_Init changes the MAC address
*                to the default (from config set) value!
*/
boolean Eth_PFE_LLD_SetPhysAddr ( \
                    const uint8 u8CtrlIdx, \
                    const uint8 * pPhysAddrPtr \
                                              )
{
    boolean bReturnStatus = FALSE;
    errno_t res;
    trPfeDev *prPfeDev = &(arPfeInterface[u8CtrlIdx]);

    if(0 == autolibc_memcmp(prPfeDev->au8MacAddr, pPhysAddrPtr, 6u))
    {
        /* If the new MAC address is the same as already set in PFE platform, no need to do anything */
        bReturnStatus = TRUE;
    }
    else
    {
        if((PFE_CTRL_TYPE_AUX == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
        || (PFE_CTRL_TYPE_HIF == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx)))
        {
            /* Just update in driver */
            (void)autolibc_memcpy(prPfeDev->au8MacAddr, pPhysAddrPtr, 6U);
            bReturnStatus = TRUE;
        }
        else /* PFE_CTRL_TYPE_EMAC */
        { 
            /* First, delete previous MAC address from PFE platform */
            /* Note: the function Eth_43_PFE_Init should have always set a MAC address if it succeeded */
            if(EOK == pfe_phy_if_del_mac_addr(prPfeDev->prPhyIf, prPfeDev->au8MacAddr, rPlatformCfg.local_hif))
            {
                /* Then, add the new MAC address to the PFE platform */
                res = pfe_phy_if_add_mac_addr(prPfeDev->prPhyIf, pPhysAddrPtr, rPlatformCfg.local_hif);
                if((EOK == res) || (EEXIST == res))
                {
                    /* If the MAC address is successfully added, update the local value au8MacAddr */
                    (void)autolibc_memcpy(prPfeDev->au8MacAddr, pPhysAddrPtr, 6U);
                    bReturnStatus = TRUE;
                }
                else
                {
                    bReturnStatus = FALSE;
                }
            }
            else
            {
                bReturnStatus = FALSE;
            }
        }
    }
    return bReturnStatus;
}

/*================================================================================================*/
static Std_ReturnType UpdatePhysAddrFilter_AddBroad(const trPfeDev *prPfeDev)
{
    Std_ReturnType u8ReturnStatus = E_NOT_OK;

    /* Enable ALLMULTI mode. */
    if (EOK != pfe_phy_if_allmulti_enable(prPfeDev->prPhyIf))
    {
        NXP_LOG_ERROR("Failed to enable ALLMULTI mode\n");
    }
    else
    {
        u8ReturnStatus = E_OK;
    }

    return u8ReturnStatus;
}

/*================================================================================================*/
static Std_ReturnType UpdatePhysAddrFilter_RemoveBroad(const trPfeDev *prPfeDev)
{
    Std_ReturnType u8ReturnStatus = E_NOT_OK;

    if (EOK != pfe_phy_if_allmulti_disable(prPfeDev->prPhyIf))
    {
        NXP_LOG_ERROR("Failed to disable ALLMULTI mode\n");
    }
    else
    {
        u8ReturnStatus = E_OK;
    }

    return u8ReturnStatus;
}

/*================================================================================================*/
static Std_ReturnType UpdatePhysAddrFilter_Close(const trPfeDev *prPfeDev)
{
    Std_ReturnType u8ReturnStatus = E_NOT_OK;

    if (EOK != pfe_phy_if_allmulti_disable(prPfeDev->prPhyIf))
    {
        NXP_LOG_ERROR("Failed to disable ALLMULTI mode\n");
    }
    else if (EOK != pfe_phy_if_flush_mac_addrs( prPfeDev->prPhyIf, MAC_DB_CRIT_BY_OWNER_AND_TYPE, 
                                                PFE_TYPE_MC, rPlatformCfg.local_hif ))
    {
        NXP_LOG_ERROR("Failed to remove multicast addresses from phy_if\n");
    }
    else
    {
        u8ReturnStatus = E_OK;
    }

    return u8ReturnStatus;
}

/*================================================================================================*/
static Std_ReturnType UpdatePhysAddrFilter_AddMulti(const trPfeDev *prPfeDev, const uint8 * PhysAddrPtr)
{
    Std_ReturnType u8ReturnStatus = E_OK;
    errno_t res;

    /* Add new MAC address */
    res = pfe_phy_if_add_mac_addr(prPfeDev->prPhyIf, PhysAddrPtr, rPlatformCfg.local_hif);
    if ((EOK != res) && (EEXIST != res))
    {
        NXP_LOG_ERROR("Failed to add new MAC address\n");
        u8ReturnStatus = E_NOT_OK;
    }

    return u8ReturnStatus;
}

/*================================================================================================*/
static Std_ReturnType UpdatePhysAddrFilter_RemoveMulti(const trPfeDev *prPfeDev, const uint8 *PhysAddrPtr)
{
    Std_ReturnType u8ReturnStatus = E_NOT_OK;

    /* Delete MAC address */
    if (EOK != pfe_phy_if_del_mac_addr(prPfeDev->prPhyIf, PhysAddrPtr, rPlatformCfg.local_hif))
    {
        NXP_LOG_ERROR("Failed to delete MAC address\n");
    }
    else
    {
        u8ReturnStatus = E_OK;
    }

    return u8ReturnStatus;
}

/*================================================================================================*/
/**
* @brief         Adds or removes the specified PhysAddrPtr address to or from
*                a multicast address pool in the controller specified by u8CtrlIdx.
* @param[in]     u8CtrlIdx Index of controller to be transferred (AUX and HIF are not supported)
* @param[in]     PhysAddrPtr Pointer to PHY address which shall be added
*                or removed to or from multicast pool.
*                The address in network byte order stored into 6 bytes of
*                memory.
* @param[in]     Action Determine whenever the defined address will be added
*                to the pool ETH_ADD_TO_FILTER or removed from it
*                ETH_REMOVE_FROM_FILTER.
*/
Std_ReturnType Eth_PFE_LLD_UpdatePhysAddrFilter ( \
                                    uint8 u8CtrlIdx, \
                                    const uint8 * PhysAddrPtr, \
                                    Eth_FilterActionType Action \
                                              )
{
    Std_ReturnType u8ReturnStatus = E_NOT_OK;
    trPfeDev *prPfeDev = &(arPfeInterface[u8CtrlIdx]);

    if (PFE_CTRL_TYPE_AUX == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        NXP_LOG_WARNING("AUX interface is not supported\n");
        u8ReturnStatus = E_NOT_OK;
    }
    else if (PFE_CTRL_TYPE_HIF == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        NXP_LOG_WARNING("HIF interface is not supported\n");
        u8ReturnStatus = E_NOT_OK;
    }
    else /* PFE_CTRL_TYPE_EMAC */
    {
        if (pfe_emac_is_broad(PhysAddrPtr))
        {
            /* Completely opens the physical address filter. */
            if (ETH_ADD_TO_FILTER == Action)
            {
                /* Enable ALLMULTI mode. */
                u8ReturnStatus = UpdatePhysAddrFilter_AddBroad(prPfeDev);
            }
            else /* Don't allow pass all multicast addresses. */
            {
                /* Disable ALLMULTI mode. */
                u8ReturnStatus = UpdatePhysAddrFilter_RemoveBroad(prPfeDev);
            }
        }
        else if (pfe_emac_is_zero(PhysAddrPtr))
        {
            /* Completely closes the physical address filter. */
            if (ETH_ADD_TO_FILTER == Action)
            {
                u8ReturnStatus = UpdatePhysAddrFilter_Close(prPfeDev);
            }
        }
        else if (pfe_emac_is_multi(PhysAddrPtr))
        {
            /* Adds a multicast address to the physical address filter. */
            if (ETH_ADD_TO_FILTER == Action)
            {
                u8ReturnStatus = UpdatePhysAddrFilter_AddMulti(prPfeDev, PhysAddrPtr);
            }
            else  /* Removes a multicast address from the physical address filter. */
            {
                u8ReturnStatus = UpdatePhysAddrFilter_RemoveMulti(prPfeDev, PhysAddrPtr);
            }
        }
        else
        {
            NXP_LOG_RAW_ERROR("The parameter is not a multicast address or a special address (all-0 or all-F)\n");
#if(STD_ON == ETH_43_PFE_DEV_ERROR_DETECT)
            (void)Det_ReportError((uint8)ETH_43_PFE_MODULE_ID, ETH_43_PFE_DRIVER_INSTANCE, (uint8)ETH_43_PFE_SID_UPDATEADDRFILTER, ETH_43_PFE_E_INV_PARAM);
#endif /* STD_ON == ETH_43_PFE_DEV_ERROR_DETECT */
        }
    }

    return u8ReturnStatus;
}

/*================================================================================================*/
/**
* @brief         Finds empty Tx buffer and prepares it for loading with data
* @param[in]     u8CtrlIdx Index of controller from which the buffer shall be provided
* @param[in]     u8QueuIdx Index of Tx queue from which the buffer shall be provided
* @param[out]    pBufIdx Pointer to variable, where the granted buffer index will be written.
* @param[out]    pData Pointer to variable, where the pointer to provided data buffer will be written.
* @param[in,out] pLength Buffer length
* @retval        TRUE An empty buffer was found and granted.
* @retval        FALSE There is no sufficiently big empty buffer available at the moment.
*/
boolean Eth_PFE_LLD_ProvideBufferDataArea \
( \
    const uint8 u8CtrlIdx, \
    const uint8 u8QueuIdx, \
    Eth_BufIdxType * const pBufIdx, \
    uint8 **pData, \
    uint16 * const pLength \
)
{
    uint8 *pBuffer = NULL;
    Eth_BufIdxType BufIdx;
    sint32 s32BufLen;
    boolean bRetVal = FALSE;
    trTxMeta *prTxMeta;
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    pfe_ct_hif_tx_hdr_t *pTxHeader;
    uint8 u8Queue;
    errno_t ret;
    trPfeDev *prPfeDev = &(arPfeInterface[u8CtrlIdx]);
    uint16 lmem_header_size = pfe_hif_chnl_get_lmem_hdr_size(arPfeInterface[u8CtrlIdx].prHifChnl);
#else
    uint16 lmem_header_size = 0U;
#endif
    const uint32 tx_buffer_size = Eth_43_PFE_LLD_GetTxBufferSize(u8CtrlIdx, u8QueuIdx);
    PfeDevAssert(tx_buffer_size < (uint32)INT32_MAX);
    s32BufLen = (sint32)tx_buffer_size
              - (sint32)TX_BUF_FRAME_OFFSET - (sint32)lmem_header_size - (sint32)PFE_LLD_L2_HEADER_SIZE;
    if((sint32)(*pLength) <= s32BufLen)
    {
        if(TRUE == GetTxBuffer(u8CtrlIdx, u8QueuIdx, &BufIdx))
        {
            pBuffer = (uint8 *)aarTxBuf[u8CtrlIdx][BufIdx].BufAddr;
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            /* Initialize Tx header after the tx buffer has been assigned by BMU */
            u8Queue = aarTxBuf[u8CtrlIdx][BufIdx].u8Fifo;
            pTxHeader = (pfe_ct_hif_tx_hdr_t *)&pBuffer[lmem_header_size + 256U];
            ret = pfe_hif_drv_init_tx_header(prPfeDev->prClient, pTxHeader, u8Queue);
            if (EOK != ret)
            {
                 NXP_LOG_ERROR("Failed to initialize tx header when using HIF_NOCPY\n");
            }
#endif
            *pData = &pBuffer[TX_BUF_FRAME_OFFSET + PFE_LLD_L2_HEADER_SIZE + lmem_header_size];
            /* TS request is disabled unless Eth_43_PFE_LLD_EnableEgressTimeStamp is called */
            prTxMeta = Eth_PFE_LLD_GetTxBufMeta(u8CtrlIdx, BufIdx);
            prTxMeta->bDoTS = FALSE;
            *pBufIdx = BufIdx;
            bRetVal = TRUE;
        }
    }
    /* Return available payload length */
    *pLength = (uint16)s32BufLen;

    return bRetVal;
}

/*================================================================================================*/
/**
* @brief         Get the value of LMEM Header size used by the HW.
* @param[in]     u8CtrlIdx Index of the controller.
* @retval        The size of LMEM Header.
*/
uint16 Eth_43_PFE_LLD_GetLmemHdrSize(const uint8 u8CtrlIdx)
{
    uint16 lmem_header_size;

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    lmem_header_size = pfe_hif_chnl_get_lmem_hdr_size(arPfeInterface[u8CtrlIdx].prHifChnl);
#else
    lmem_header_size = 0U;
#endif

    (void)u8CtrlIdx;

    return lmem_header_size;
}

/*================================================================================================*/
/**
* @brief         Get Tx Fifo index of the given Tx buffer.
* @param[in]     u8CtrlIdx Index of the controller which the given Tx buffer is belong to.
* @param[in]     BufIdx Index of the Tx buffer.
* @retval        Fifo index of the given Tx buffer.
*/
uint8 Eth_43_PFE_LLD_GetTxFifoIdx(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{
    return aarTxBuf[u8CtrlIdx][BufIdx].u8Fifo;
}

/*================================================================================================*/
/**
* @brief         Get Tx buffer size of the given Tx Fifo.
* @param[in]     u8CtrlIdx Index of the controller which the given Tx Fifo is belong to.
* @param[in]     u8FifoIdx Index of the Tx Fifo.
* @retval        Tx buffer size of the given Tx Fifo.
*/
uint32 Eth_43_PFE_LLD_GetTxBufferSize(const uint8 u8CtrlIdx, const uint8 u8FifoIdx)
{
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    (void)u8CtrlIdx;
    (void)u8FifoIdx;
    return PFE_CFG_BMU2_BUF_SIZE;
#else
    return aarTxBufPool[u8CtrlIdx][u8FifoIdx].u32BufSize;
#endif
}

#if STD_ON == ETH_43_PFE_RELEASE_TX_BUFFER_API
/*================================================================================================*/
/**
* @brief         Release Tx buffer
* @param[in]     u8CtrlIdx Index of controller which will be relesed
* @param[in]     BufIdx DA Index of the buffer to be released
* @retval        TRUE - Buffer successfully released
* @retval        FALSE - Buffer was busy - not released
*/
boolean Eth_PFE_LLD_ReleaseTxBuffer(const uint8 u8CtrlIdx, const Eth_BufIdxType BufIdx)
{
    boolean res = FALSE;
    const uint8 status = aarTxBuf[u8CtrlIdx][BufIdx].u8Status;

    if((status == TX_BUF_FREE) || (status == TX_BUF_PROVIDED))
    {
        ReleaseTxBuffer(u8CtrlIdx, BufIdx);
        res = TRUE;
    }
     
    return res;
}
#endif

/*================================================================================================*/
/**
* @brief         Triggers the transmission of the given buffer
* @param[in]     u8CtrlIdx Index of controller which will be triggered the transmission
* @param[in]     BufIdx DA Index of the buffer to be transmitted
* @param[in]     u16Type Type or length field value in the 802.3 frame header
* @param[in]     u16Length Payload length
* @param[in]     bConfirm Selects whether the frame transmission shall
*                be confirmed or not
* @param[in]     pDest Frame destination address
* @details       Function decrements the buffer address in the transmit buffer
*                descriptor assigned to the given DA by 14 bytes in order to get
*                the frame header beginning. The frame header is constructed
*                using the given destination address and type or length field
*                values. The source address is added by ENET natively.
*
*                - The Lock and bit is cleared if the transmission
*                  confirmation is disabled and buffer will become empty
*                  after the transmission.
*                - Transmitted bit (user bit 2) is set and Lock is bit left set
*                  if the transmission confirmation is enabled. Then the buffer
*                  will stay locked after the transmission but it can be
*                  recognized as already transmitted  because of the set
*                  Transmitted bit. Such buffer cannot be used until it is
*                  confirmed and bits are cleared.
*
*                The Ready bit is set to trigger the buffer transmission and the
*                controller is notified about the new buffer by a write into the
*                TDAR register.
*/
Std_ReturnType Eth_PFE_LLD_Transmit
(
    const uint8 u8CtrlIdx,
    const Eth_BufIdxType BufIdx,
    const Eth_FrameType u16Type,
    const uint16 u16Length,
    const boolean bConfirm,
    const uint8 *pDest
)
{
    Std_ReturnType RetVal = E_NOT_OK;
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    const uint16 lmem_header_size = pfe_hif_chnl_get_lmem_hdr_size(arPfeInterface[u8CtrlIdx].prHifChnl);
#else
    const uint16 lmem_header_size = 0U;
#endif
    const uint8 *apu8MacAddr = arPfeInterface[u8CtrlIdx].au8MacAddr;
    trTxMeta *prTxMeta = Eth_PFE_LLD_GetTxBufMeta(u8CtrlIdx, BufIdx);
    uint8 u8NewBufStatus = TX_BUF_WAIT_CONF | TX_BUF_TO_REPORT;
    uint16 u16frameLength = (uint16)(((uint32)u16Length + PFE_LLD_L2_HEADER_SIZE) & UINT16_MAX);
    uint8  *framePtr = (uint8 *)(uint32)(((uint64)aarTxBuf[u8CtrlIdx][BufIdx].BufAddr + TX_BUF_FRAME_OFFSET + lmem_header_size) & UINT32_MAX);

    if (TX_BUF_PROVIDED != aarTxBuf[u8CtrlIdx][BufIdx].u8Status)
    {
        NXP_LOG_ERROR("Attempted to transmit buffer with wrong status\n");
        if(TRUE == bConfirm)
        {
            EthIf_TxConfirmation(ETH_43_PFE_CFG_CTRLIDXINETHIF(u8CtrlIdx), BufIdx, E_NOT_OK);
        }
    }
    else
    {
        /*  Update TX metadata */
        prTxMeta->bDoTxIndication = bConfirm;
        prTxMeta->bDoTS = prTxMeta->bDoTS && bConfirm; /* No way to report timestamp without confirnation enabled */

        /*  Fill in Ethernet header */
        (void)autolibc_memcpy(&framePtr[ETH_FRAME_MACDST_IDX], pDest, 6u);
        (void)autolibc_memcpy(&framePtr[ETH_FRAME_MACSRC_IDX], apu8MacAddr, 6u);
        framePtr[ETH_FRAME_ETHERTYPE_IDX]    = (uint8)(u16Type >> 8);
        framePtr[ETH_FRAME_ETHERTYPE_IDX+1u] = (uint8)(u16Type & 0xFFU);

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
        aarTxBuf[u8CtrlIdx][BufIdx].TimeQual = ETH_INVALID;
        /*  Check TS request */
        if (TRUE == prTxMeta->bDoTS)
        {
            TxReqTsQueueWrite(u8CtrlIdx, BufIdx);
            u8NewBufStatus |= TX_BUF_WAIT_TS;
        }
#endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */

#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
        if ((Std_ReturnType)E_OK == TxReqSwt(u8CtrlIdx, BufIdx, &framePtr[ETH_FRAME_ETHERTYPE_IDX], &u16frameLength))
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API*/
        {
            errno_t Status = EOK;
            /* MUST update BufStatus before writing to TxReqQueue */
            aarTxBuf[u8CtrlIdx][BufIdx].u8Status = u8NewBufStatus;
            Status = TxReqTrigger(u8CtrlIdx, BufIdx, u16frameLength);
            if(EOK != Status)
            {
                NXP_LOG_ERROR("Transmission has failed (%d)\n", Status);
                TxReqFailed(u8CtrlIdx, BufIdx);
            }
            else 
            {
                RetVal = E_OK;
            }
        }
    }

    return RetVal;
}

/*================================================================================================*/
static boolean IsRxChecksumValidIpV4(const pfe_hif_pkt_t *RxPacket, uint8 Protocol)
{
    boolean checksum_valid = TRUE;

#if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_IPV4)
    /* Check if IPv4 checksum has been verified and is valid */
    if (pfe_hif_pkt_ipv4_csum_valid(RxPacket) == FALSE)
    {   /* Checksum mismatch, shall be discarded */
        checksum_valid = FALSE;
    }
#endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_IPV4 */
    /* Check for Protocol */
#if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_UDP)
    /* Check if L4 Protocol of received frame is UDP */
    if(Protocol == 0x11U)
    {   /* Check if UDP checksum has been verified and is valid */
        if (pfe_hif_pkt_udpv4_csum_valid(RxPacket) == FALSE)
        {   /* Checksum mismatch, shall be discarded */
            checksum_valid = FALSE;
        }
    }
#endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_UDP */
#if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_TCP)
    /* Check if L4 Protocol of received frame is TCP */
    if(Protocol == 0x06U)
    {   /* Check if TCP checksum has been verified and is valid */
        if (pfe_hif_pkt_tcpv4_csum_valid(RxPacket) == FALSE)
        {   /* Checksum mismatch, shall be discarded */
            checksum_valid = FALSE;
        }
    }
#endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_TCP */
#if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_ICMP)
    if(Protocol == 0x01U)
    {   /* Check if ICMP checksum has been verified and is valid */
        if (pfe_hif_pkt_icmp_csum_valid(RxPacket) == FALSE)
        {   /* Checksum mismatch, shall be discarded */
            checksum_valid = FALSE;
        }
    }
#endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_ICMP */

    /* avoid 'unused' parameter warning */
    (void)RxPacket;
    (void)Protocol;

    return checksum_valid;
}

/*================================================================================================*/
static boolean IsRxChecksumValidIpV6(const pfe_hif_pkt_t *RxPacket, uint8 Protocol)
{
    boolean checksum_valid = TRUE;

    /* Check for Protocol */
#if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_UDP)
    /* Check if L4 Protocol of received frame is UDP */
    if(Protocol == 0x11U)
    {   /* Check if UDP checksum has been verified and is valid */
        if (pfe_hif_pkt_udpv6_csum_valid(RxPacket) == FALSE)
        {   /* Checksum mismatch, shall be discarded */
            checksum_valid = FALSE;
        }
    }
#endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_UDP */
#if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_TCP)
    /* Check if L4 Protocol of received frame is TCP */
    if(Protocol == 0x06U)
    {   /* Check if TCP checksum has been verified and is valid */
        if (pfe_hif_pkt_tcpv6_csum_valid(RxPacket) == FALSE)
        {   /* Checksum mismatch, shall be discarded */
            checksum_valid = FALSE;
        }
    }
#endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_TCP */
#if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_ICMP)
    if(Protocol == 0x3AU)
    {   /* Check if ICMP checksum has been verified and is valid */
        if (pfe_hif_pkt_icmp_csum_valid(RxPacket) == FALSE)
        {   /* Checksum mismatch, shall be discarded */
            checksum_valid = FALSE;
        }
    }
#endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_ICMP */

    /* avoid 'unused' parameter warning */
    (void)RxPacket;
    (void)Protocol;

    return checksum_valid;
}

/*================================================================================================*/
static boolean IsRxChecksumValid(const pfe_hif_pkt_t *RxPacket, const uint8 *pEtherType)
{
    boolean checksum_valid = TRUE;
    Eth_FrameType EtherType = (Eth_FrameType)pu8_to_be16(pEtherType);

    if(EtherType == ETHERTYPE_IPV4) 
    {
        const uint8 Protocol = pEtherType[11];
        checksum_valid = IsRxChecksumValidIpV4(RxPacket, Protocol);
    }
    else if(EtherType == ETHERTYPE_IPV6) 
    {
        const uint8 Protocol = pEtherType[8];
        checksum_valid = IsRxChecksumValidIpV6(RxPacket, Protocol);
    }
    else 
    {
        checksum_valid = TRUE;
    }

    return checksum_valid;
}

/*================================================================================================*/
static uint8 ReportReception_GetBypassVLANTag(Eth_FrameType FrameType)
{
    uint8 BypassVLANTag = 0; /* BypassVLANTag */

    if (FrameType == 0x88A8U)
    {   /*It's a VLAN Double-Tagged Frame. Look for frame type*/
        BypassVLANTag = 8U;
    }
    else if (FrameType == 0x8100U)
    {   /*It's a VLAN Tagged Frame. Look for frame type*/
        BypassVLANTag = 4U;
    }
    else
    {   /*Frame type acquired*/
        BypassVLANTag = 0U;
    }

    return BypassVLANTag;
}

/*================================================================================================*/
static void ReportReception_ProcessPacket(uint8 u8CtrlIdx, uint8 u8FifoIdx, const pfe_hif_pkt_t *RxPacket)
{
    uint8 *pFrame;
    uint32 u32DataLen;
    Eth_DataType * pPayloadPtr;
    Eth_FrameType FrameType; /* EtherType */
    uint8 BypassVLANTag = 0; /* BypassVLANTag */
    boolean IsBroadcast;
    uint8 * SrcAddrPtr; /* Pointer to source address */
    boolean IsMgmtFrameOnlyPtr = FALSE;
    uint16 FrameLength = 0;
#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
    Eth_BufIdxType BufIdx = 0;
    uint8*  DataPtr;
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API */
    /* Suppress compiler warning for unused function parameter */
    (void) u8FifoIdx;
    /* Parse Ethernet frame and determine frame type */
    pFrame = (uint8 *)(uint32)(((uint64)pfe_hif_pkt_get_data(RxPacket) + HIF_HEADER_SIZE) & UINT32_MAX);
    FrameType = (Eth_FrameType)pu8_to_be16(&pFrame[ETH_FRAME_ETHERTYPE_IDX]);
    BypassVLANTag = ReportReception_GetBypassVLANTag(FrameType);

    if(TRUE == IsRxChecksumValid(RxPacket, &pFrame[ETH_FRAME_ETHERTYPE_IDX + BypassVLANTag])) 
    {
        /* Whole packet successfully received */
        /* Get whole Ethernet frame without HIF header */
        FrameLength = (uint16)(pfe_hif_pkt_get_data_len(RxPacket) & 0xFFFFU);
        PfeDevAssert(FrameLength >= HIF_HEADER_SIZE);
        FrameLength -= HIF_HEADER_SIZE;

        /* Check if received frame is jumbo frame */
        if(FrameLength > (PFE_INGRESS_MAX_FRAME_SIZE + BypassVLANTag))
        {
            FrameLength = PFE_INGRESS_MAX_FRAME_SIZE + BypassVLANTag;
        }

#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
        DataPtr = &pFrame[ETH_FRAME_ETHERTYPE_IDX + BypassVLANTag];
        (void)Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
        Eth_43_PFE_EthSwtDriverFunctionList.RxProcessFrameFunction( u8CtrlIdx, \
                                        BufIdx, \
                                        &DataPtr,\
                                        &FrameLength, \
                                        &IsMgmtFrameOnlyPtr\
                                        );
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API */
        /* Parse Ethernet header */
        static const uint8 mac_broadcast[6] = {0xFFU, 0xFFU, 0xFFU, 0xFFU, 0xFFU, 0xFFU};
        IsBroadcast = (0 == autolibc_memcmp(&pFrame[ETH_FRAME_MACDST_IDX], mac_broadcast, sizeof(mac_broadcast)));
        SrcAddrPtr = &pFrame[ETH_FRAME_MACSRC_IDX];
        /* Get payload - strip Ethernet header and CRC */
        pPayloadPtr = (Eth_DataType *)&pFrame[PFE_LLD_L2_HEADER_SIZE];
        PfeDevAssert(FrameLength >= PFE_LLD_L2_HEADER_SIZE);
        u32DataLen = ((uint32)FrameLength - PFE_LLD_L2_HEADER_SIZE);
        /* Pass to upper layer */
        if (FALSE == IsMgmtFrameOnlyPtr)
        {
            EthIf_RxIndication( ETH_43_PFE_CFG_CTRLIDXINETHIF(u8CtrlIdx), \
                                FrameType, IsBroadcast, SrcAddrPtr, \
                                pPayloadPtr, (uint16)u32DataLen \
                            );
        }
#if (STD_ON == ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API)
        (void)Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->
        Eth_43_PFE_EthSwtDriverFunctionList.RxFinishedIndicationFunction(u8CtrlIdx, u8FifoIdx);
#endif /* ETH_43_PFE_SWT_MANAGEMENT_SUPPORT_API */
    }
    pfe_hif_pkt_free(RxPacket);
}

/*================================================================================================*/
/**
* @brief         Reports received frames to the upper layer
* @param[in]     u8CtrlIdx Index of the controller to report receptions
* @param[in]     bIrq Selects between the poll driven and interrupt driven
*                mode (algorithm). The value TRUE means interrupt driven mode.
* @note          The function reports all found frames in the interrupt driven
*                mode. In the poll driven mode it reports only the first found
*                frame signals whether there is at least another frame to be
*                received (in the next call).
* @return        In the poll driven mode signalizes whether a frame has been
*                reported to the EthIf module and whether another frame is
*                available. It shall be ignored in the interrupt driven mode.
* @retval        ETH_RECEIVED Only one frame received
* @retval        ETH_NOT_RECEIVED No frame received
* @retval        ETH_RECEIVED_MORE_DATA_AVAILABLE More frames received
*                frame was discarded.
*/
Eth_RxStatusType Eth_PFE_LLD_ReportReception(const uint8 u8CtrlIdx, uint8 u8FifoIdx, const boolean bIrq)
{
    Eth_RxStatusType RetVal = ETH_NOT_RECEIVED;
    const pfe_hif_pkt_t *RxPacket;
    pfe_hif_drv_client_t *prClient = arPfeInterface[u8CtrlIdx].prClient;
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
    trPfeDev *prPfeDev = &arPfeInterface[u8CtrlIdx];
    /* Do Rx job in polling mode */
    pfe_hif_drv_rx_job((void *)prPfeDev->prHifDrv);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

    do
    {
        RxPacket = pfe_hif_drv_client_receive_pkt(prClient, u8FifoIdx);
        if(NULL_PTR != RxPacket)
        {   /* Process the packet */
            ReportReception_ProcessPacket(u8CtrlIdx, u8FifoIdx, RxPacket);
            RetVal = ETH_RECEIVED;
        }
    } while((TRUE == bIrq) && (NULL_PTR != RxPacket)); /* In IRQ mode process all */

    /* Re-enable interrupt + DMA */
    pfe_hif_drv_client_rx_done(prClient);

    /* In polling mode check if next Rx frame is available */
    if((FALSE == bIrq) && (ETH_RECEIVED == RetVal))
    {
        /* Only check if there is another one */
        if(TRUE == pfe_hif_drv_client_has_rx_pkt(prClient, u8FifoIdx))
        {
            RetVal = ETH_RECEIVED_MORE_DATA_AVAILABLE;
        }
    }


    return RetVal;
}

/*================================================================================================*/
/**
* @brief        Confirms transmission of all transmitted buffers that are not waiting for timestamp
* @param[in]    u8CtrlIdx Index of the controller to report transmissions
* @param[in]    u8FifoIdx Tx FIFO index
* @details      Function examines all transmit buffers whether some of them
*               have been already sent and whether they should be confirmed. EthIf_TxConfirmation 
*               is called for each such buffer except buffers waiting for timestamp.
*/
void Eth_PFE_LLD_ReportTransmission(const uint8 u8CtrlIdx, const uint8 u8FifoIdx)
{
    const pfe_hif_drv_client_t *prClient = arPfeInterface[u8CtrlIdx].prClient;
    const trTxMeta *prTxMeta;
    const Eth_PFE_LLD_trTxRefData *prRefData;
    Eth_BufIdxType BufIdx;
    uint8 u8BufStatus;
    Std_ReturnType Status;
    bool_t bStillSearching = TRUE;
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
    trPfeDev *prPfeDev = &arPfeInterface[u8CtrlIdx];
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
    /* Do Tx job in polling mode */
    pfe_hif_drv_tx_job((void *)prPfeDev->prHifDrv);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

    /* Repeat as long as there is some confirmation */
    while(TRUE)
    {
        prRefData = (Eth_PFE_LLD_trTxRefData *)pfe_hif_drv_client_receive_tx_conf(prClient, u8FifoIdx);
        if (NULL_PTR == prRefData)
        {
            break;
        }
        else
        {
            BufIdx = prRefData->u16BufIdx;
            aarTxBuf[u8CtrlIdx][BufIdx].u8Status &= (uint8)(~TX_BUF_WAIT_CONF & 0xFFU);
        }
    }
    pfe_hif_drv_client_tx_done(prClient);

    /* Process Tx request queue */
    while(TRUE == bStillSearching)
    {
        prRefData = TxReqQueueRead(u8CtrlIdx);
        BufIdx = prRefData->u16BufIdx;
        if(INVALID_TX_INDEX == BufIdx)
        {
            /* Queue is empty */
            bStillSearching = FALSE;
        }
        else
        {
            u8BufStatus = aarTxBuf[u8CtrlIdx][BufIdx].u8Status;
            if(0U == (TX_BUF_WAIT_CONF & u8BufStatus))
            {
                /* Buffer confirmed or failed -> ready to be removed from TxReqQueue */
                TxReqQueueDelete(u8CtrlIdx);
                if((TX_BUF_TO_REPORT == u8BufStatus) || (TX_BUF_FAILED == u8BufStatus))
                {
                    /* Buffer also ready to be reported and released */
                    prTxMeta = Eth_PFE_LLD_GetTxBufMeta(u8CtrlIdx, BufIdx);
                    if(TRUE == prTxMeta->bDoTxIndication)
                    {
                        Status = (TX_BUF_FAILED == u8BufStatus) ? E_NOT_OK : E_OK;
                        oal_mutex_lock(PFE_ETHIF_TXCONFIR_API_MUTEX_00);
                        EthIf_TxConfirmation( ETH_43_PFE_CFG_CTRLIDXINETHIF(u8CtrlIdx), BufIdx, Status);
                        oal_mutex_unlock(PFE_ETHIF_TXCONFIR_API_MUTEX_00);
                    }
                    aarTxBuf[u8CtrlIdx][BufIdx].u8Status = TX_BUF_FREE;
                }
            }
            else
            {
                /* Buffer not confirmed yet */
                bStillSearching = FALSE;
            }
        }
    }
}

#if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
/*================================================================================================*/
/**
* @brief        Function gets all received Tx timestamps and confirms transmission of buffers
*               which were waiting only for timestamp
* @param[in]    u8CtrlIdx Index of the controller to report transmissions
* @param[in]    u8FifoIdx Tx FIFO index
* @details      The timestamps are stored in runtime buffer data structure. Buffer is not reported
*               if it still waits for Tx confirmation. In that case it will be reported in function
*               Eth_PFE_LLD_ReportTransmission.
*/
void Eth_PFE_LLD_ReportTransmissionTS(const uint8 u8CtrlIdx, const uint8 u8FifoIdx)
{
    Eth_BufIdxType BufIdx;
    uint8 u8BufStatus;
    errno_t Error;
    bool_t bContinue = TRUE;
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
    trPfeDev *prPfeDev = &arPfeInterface[u8CtrlIdx];
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
    /* Do Rx job in polling mode */
    pfe_hif_drv_rx_job((void *)prPfeDev->prHifDrv);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

    do
    {
        /* Enter exclusive area to protect the read-out of the TS queue */
        oal_mutex_lock(PFE_TS_QUEUE_READ_MUTEX);

        /* Get next buffer index from TS queue */
        BufIdx = arPfeInterface[u8CtrlIdx].TSQueue[u8FifoIdx][arPfeInterface[u8CtrlIdx].u16TSQueueRead[u8FifoIdx]];
        if(INVALID_TX_INDEX == BufIdx)
        {   /* The queue is empty */
            bContinue = FALSE;
        }
        else
        {
            /* Try to get timestamp from database, store it to runtime buffer data */
            Error = GetTxTimeStamp(u8CtrlIdx, BufIdx, \
                                   &aarTxBuf[u8CtrlIdx][BufIdx].TimeQual, \
                                   &aarTxBuf[u8CtrlIdx][BufIdx].TimeStamp \
                                  );
            if (EAGAIN == Error)
            {   /* No more timestamps to process */
                bContinue = FALSE;
            }
            else
            {
                /* Remove the buffer from TS queue */
                arPfeInterface[u8CtrlIdx].TSQueue[u8FifoIdx][arPfeInterface[u8CtrlIdx].u16TSQueueRead[u8FifoIdx]] = INVALID_TX_INDEX;
                if(arPfeInterface[u8CtrlIdx].u16TSQueueRead[u8FifoIdx] >= (ETH_43_PFE_MAX_FIFO_TX_BUF_CNT - 1U))
                {   /* wrap */
                    arPfeInterface[u8CtrlIdx].u16TSQueueRead[u8FifoIdx] = 0U;
                }
                else
                {
                    arPfeInterface[u8CtrlIdx].u16TSQueueRead[u8FifoIdx]++;
                }

                if(ENOENT == Error)
                {
                    NXP_LOG_WARNING("Requested egress timestamp was not provided on controller %hhu\n", u8CtrlIdx);
                }
                
                /* Check if we should also report the buffer here */
                u8BufStatus = aarTxBuf[u8CtrlIdx][BufIdx].u8Status;
                if((TX_BUF_WAIT_TS | TX_BUF_TO_REPORT) == u8BufStatus)
                {
                    /* Yes, we were waiting only for the timestamp */
                    oal_mutex_lock(PFE_ETHIF_TXCONFIR_API_MUTEX_01);
                    EthIf_TxConfirmation(ETH_43_PFE_CFG_CTRLIDXINETHIF(u8CtrlIdx), BufIdx, E_OK);
                    oal_mutex_unlock(PFE_ETHIF_TXCONFIR_API_MUTEX_01);

                    /* Return buffer to pool */
                    aarTxBuf[u8CtrlIdx][BufIdx].u8Status = TX_BUF_FREE;
                }
                else
                {
                    /* Otherwise it will be reported when we get Tx confirmation */
                    aarTxBuf[u8CtrlIdx][BufIdx].u8Status &= (uint8)(~TX_BUF_WAIT_TS & 0xFFU);
                }
            }
        }
        oal_mutex_unlock(PFE_TS_QUEUE_READ_MUTEX);
    }
    while (TRUE == bContinue);
}
#endif /*ETH_43_PFE_GLOBALTIME_SUPPORT*/

#ifdef PFE_CFG_PFE_MASTER
/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_ECC(void)
{
    if (NULL != ptrPlatform->ecc_err)
    {
        pfe_ecc_err_irq_mask(ptrPlatform->ecc_err);
        (void)pfe_ecc_err_isr(ptrPlatform->ecc_err);
        pfe_ecc_err_irq_unmask(ptrPlatform->ecc_err);
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_WDG(void)
{
    if (NULL != ptrPlatform->wdt)
    {
        pfe_wdt_irq_mask(ptrPlatform->wdt);
        (void)pfe_wdt_isr(ptrPlatform->wdt);
        pfe_wdt_irq_unmask(ptrPlatform->wdt);
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_EMAC(void)
{
    for (uint32 i = 0; i < ptrPlatform->emac_count; i++)
    {
        if (NULL != ptrPlatform->emac[i])
        {
            pfe_emac_irq_mask(ptrPlatform->emac[i]);
            (void)pfe_emac_isr(ptrPlatform->emac[i]);
            pfe_emac_irq_unmask(ptrPlatform->emac[i]);
        }
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_BUS(void)
{
    if (NULL != ptrPlatform->bus_err)
    {
        pfe_bus_err_irq_mask(ptrPlatform->bus_err);
        (void)pfe_bus_err_isr(ptrPlatform->bus_err);
        pfe_bus_err_irq_unmask(ptrPlatform->bus_err);
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_PARITY(void)
{
    if (NULL != ptrPlatform->parity)
    {
        pfe_parity_irq_mask(ptrPlatform->parity);
        (void)pfe_parity_isr(ptrPlatform->parity);
        pfe_parity_irq_unmask(ptrPlatform->parity);
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_FAILSTOP(void)
{
    /* Fail Stop (HW)*/
    if (NULL != ptrPlatform->fail_stop)
    {
        pfe_fail_stop_irq_mask(ptrPlatform->fail_stop);
        (void)pfe_fail_stop_isr(ptrPlatform->fail_stop);
        pfe_fail_stop_irq_unmask(ptrPlatform->fail_stop);
    }

    /* Fail Stop (FW) */
    if (NULL != ptrPlatform->fw_fail_stop)
    {
        pfe_fw_fail_stop_irq_mask(ptrPlatform->fw_fail_stop);
        (void)pfe_fw_fail_stop_isr(ptrPlatform->fw_fail_stop);
        pfe_fw_fail_stop_irq_unmask(ptrPlatform->fw_fail_stop);
    }

    /* Fail Stop (SW) */
    if (NULL != ptrPlatform->host_fail_stop)
    {
        pfe_host_fail_stop_irq_mask(ptrPlatform->host_fail_stop);
        (void)pfe_host_fail_stop_isr(ptrPlatform->host_fail_stop);
        pfe_host_fail_stop_irq_unmask(ptrPlatform->host_fail_stop);
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_BMU(void)
{
    for (uint32 i = 0; i < ptrPlatform->bmu_count; i++)
    {
        if (NULL != ptrPlatform->bmu[i])
        {
            pfe_bmu_irq_mask(ptrPlatform->bmu[i]);
            (void)pfe_bmu_isr(ptrPlatform->bmu[i]);
            pfe_bmu_irq_unmask(ptrPlatform->bmu[i]);
        }
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_CLASS(void)
{
    if (NULL != ptrPlatform->classifier)
    {
        pfe_class_irq_mask(ptrPlatform->classifier);
        (void)pfe_class_isr(ptrPlatform->classifier);
        pfe_class_irq_unmask(ptrPlatform->classifier);
    }
}

/*================================================================================================*/
static void Eth_PFE_LLD_PollerFunction_HIF(void)
{
    if (NULL != ptrPlatform->hif)
    {
        pfe_hif_irq_mask(ptrPlatform->hif);
        (void)pfe_hif_isr(ptrPlatform->hif);
        pfe_hif_irq_unmask(ptrPlatform->hif);
    }
}

/**
* @brief        Get errors from interrupt sources and report to Heath Monitor.
* @details      The function checks for errors by polling interrupt sources
*               and report to Health Monitor
* @return       N/A
*/
static void Eth_PFE_LLD_PollerFunction(void)
{
    /* Polling all interrupt sources and report errors to Health Monitor */

    /* PFE ECC */
    Eth_PFE_LLD_PollerFunction_ECC();

    /* PFE Watchdog */
    Eth_PFE_LLD_PollerFunction_WDG();

    /* EMAC */
    Eth_PFE_LLD_PollerFunction_EMAC();

    /* Bus */
    Eth_PFE_LLD_PollerFunction_BUS();

    /* Parity */
    Eth_PFE_LLD_PollerFunction_PARITY();

    /* Fail Stop (HW, FW, SW)*/
    Eth_PFE_LLD_PollerFunction_FAILSTOP();

    /* BMU */
    Eth_PFE_LLD_PollerFunction_BMU();

    /* Classifier */
    Eth_PFE_LLD_PollerFunction_CLASS();

    /* HIF */
    Eth_PFE_LLD_PollerFunction_HIF();
}
#endif /* PFE_CFG_PFE_MASTER */

/*================================================================================================*/
/**
* @brief        Get errors and lost frames.
* @details      The function checks for controller errors and lost frames.
*               Used for polling state changes. Calls EthIf_CtrlModeIndication when
*               the controller mode changed.
*/
void Eth_PFE_LLD_MainFunction(void)
{
    if(NULL_PTR != ptrPlatform)
    {
        Eth_ModeType eCurrentMode;
        uint8 u8EthIfCtrlIdx;
        uint8 u8CtrlIdx;
    #if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
        uint8 u8FifoIdx;
        uint8 u8NumsFifo;
    #endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */
    #if (PFE_CFG_DEM_CHECK_SKIPPING != 0U)
        static uint8 u8DemCheckSkipping = 0U;
    #endif /* PFE_CFG_DEM_CHECK_SKIPPING */

    #ifdef PFE_CFG_RTABLE_ENABLE
        if (u32RtrTimeoutTimeMs < (PFE_RTABLE_CFG_TICK_PERIOD_SEC * 1000U - ETH_43_PFE_CFG_MAIN_FCN_PERIOD_MS))
        {
            u32RtrTimeoutTimeMs += ETH_43_PFE_CFG_MAIN_FCN_PERIOD_MS;
        }
        else
        {
            pfe_rtable_do_timeouts(ptrPlatform->rtable);
            u32RtrTimeoutTimeMs -= PFE_RTABLE_CFG_TICK_PERIOD_SEC * 1000U - ETH_43_PFE_CFG_MAIN_FCN_PERIOD_MS;
        }
    #endif /* PFE_CFG_RTABLE_ENABLE */

        for (u8CtrlIdx=0U; u8CtrlIdx<ETH_43_PFE_NUM_CONTROLLER_CFG; u8CtrlIdx++)
        {
            u8EthIfCtrlIdx = ETH_43_PFE_CFG_CTRLIDXINETHIF(u8CtrlIdx);
            eCurrentMode = Eth_PFE_LLD_CheckControllerIsActive(u8CtrlIdx);
            if (eSavedMode[u8CtrlIdx] != eCurrentMode)
            {
                eSavedMode[u8CtrlIdx] = eCurrentMode;
                EthIf_CtrlModeIndication(u8EthIfCtrlIdx, eCurrentMode);
            }

        #if (STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        #if (PFE_CFG_DEM_CHECK_SKIPPING != 0U)
            if(0U == u8DemCheckSkipping)
        #endif /* PFE_CFG_DEM_CHECK_SKIPPING */
            {
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_FRAMELOST_ENABLED(u8CtrlIdx), ETH_43_PFE_E_RX_FRAMES_LOST,    ETH_43_PFE_CFG_DEM_E_FRAMELOST(u8CtrlIdx));
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_CRC_ENABLED(u8CtrlIdx),       ETH_43_PFE_E_CRC,               ETH_43_PFE_CFG_DEM_E_CRC(u8CtrlIdx));
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_UNDERSIZE_ENABLED(u8CtrlIdx), ETH_43_PFE_E_UNDERSIZEFRAME,    ETH_43_PFE_CFG_DEM_E_UNDERSIZE(u8CtrlIdx));
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_OVERSIZE_ENABLED(u8CtrlIdx),  ETH_43_PFE_E_OVERSIZEFRAME,     ETH_43_PFE_CFG_DEM_E_OVERSIZE(u8CtrlIdx));
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_ALIGN_ENABLED(u8CtrlIdx),     ETH_43_PFE_E_ALIGNMENT,         ETH_43_PFE_CFG_DEM_E_ALIGN(u8CtrlIdx));
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_1COL_ENABLED(u8CtrlIdx),      ETH_43_PFE_E_SINGLECOLLISION,   ETH_43_PFE_CFG_DEM_E_1COL(u8CtrlIdx));
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_MCOL_ENABLED(u8CtrlIdx),      ETH_43_PFE_E_MULTIPLECOLLISION, ETH_43_PFE_CFG_DEM_E_MCOL(u8CtrlIdx));
                CheckDemStatus(u8CtrlIdx, ETH_43_PFE_CFG_DEM_E_LCOL_ENABLED(u8CtrlIdx),      ETH_43_PFE_E_LATECOLLISION,     ETH_43_PFE_CFG_DEM_E_LCOL(u8CtrlIdx));
            }
        #endif /* ETH_43_PFE_DEM_EVENT_DETECT */
 
        #if (STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT)
            /* Only call the handler here if the interrupt mode is enabled */
            if(TRUE == ETH_43_PFE_CFG_ENABLETXINTERRUPT(u8CtrlIdx))
            {
                u8NumsFifo = Eth_43_PFE_InternalCfgPtr->pController[u8CtrlIdx]->EthCtrlEgressFifoCnt;
                for(u8FifoIdx = 0U; u8FifoIdx < u8NumsFifo; u8FifoIdx++)
                {
                    Eth_PFE_LLD_ReportTransmissionTS(u8CtrlIdx, u8FifoIdx);
                }
            }
            /* Check for lost egress timestamps */
            pfe_hif_drv_client_ptp_ts_db_tick_iteration(arPfeInterface[u8CtrlIdx].prClient);
        #endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */

        #ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        #if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
            pfe_hif_drv_tx_job((void *)arPfeInterface[u8CtrlIdx].prHifDrv);
            pfe_hif_drv_rx_job((void *)arPfeInterface[u8CtrlIdx].prHifDrv);
            pfe_idex_ihc_poll();
        #endif /* PFE_CFG_HIF_IRQ_ENABLED */
        #endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
        }
        #ifdef PFE_CFG_PFE_MASTER
        #if (PFE_CFG_DEM_CHECK_SKIPPING != 0U)
        if(0U == u8DemCheckSkipping)
        #endif /* PFE_CFG_DEM_CHECK_SKIPPING */
        {
            /* Poll interrupt sources for errors and report to heath monitor */
            Eth_PFE_LLD_PollerFunction();
        }
        #endif /* PFE_CFG_PFE_MASTER */
        #if (PFE_CFG_DEM_CHECK_SKIPPING != 0U)
        if(u8DemCheckSkipping < PFE_CFG_DEM_CHECK_SKIPPING)
        {
            u8DemCheckSkipping++;
        }
        else
        {
            u8DemCheckSkipping = 0U;
        }
        #endif /* PFE_CFG_DEM_CHECK_SKIPPING */
    }
}

#if STD_ON == ETH_43_PFE_CTRLENABLE_MII
/**
 * @brief       Write specified transceiver register through the MII (Clause 22)
 * @note        Not supported on AUX interface
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver on the MII
 * @param[in]   u8RegIdx Index of the transceiver register on the MII
 * @param[in]   u16RegVal Value to be written into the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_LLD_WriteMii(uint8 u8CtrlIdx, \
                                            uint8 u8TrcvIdx, \
                                            uint8 u8RegIdx, \
                                            uint16 u16RegVal
                                        )
{
    Std_ReturnType RetVal = E_NOT_OK;
    pfe_emac_t *prEmac = NULL_PTR;
    uint32 u32Key = 0U;
    pfe_ct_phy_if_id_t emac_id;

    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];

#ifdef PFE_CFG_PFE_MASTER
        /* Lock the MDIO bus */
        if (EOK != pfe_emac_mdio_lock(prEmac, &u32Key))
        {
            NXP_LOG_ERROR("Lock the MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
        /*  Clause 22 */
        if (EOK == pfe_emac_mdio_write22(prEmac, u8TrcvIdx, u8RegIdx, u16RegVal, u32Key))
        {
            RetVal = E_OK;
        }
#ifdef PFE_CFG_PFE_MASTER
        /* Unlock the locked MDIO bus */
        if (EOK != pfe_emac_mdio_unlock(prEmac, u32Key))
        {
            NXP_LOG_ERROR("Unlock the locked MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
    }

    return RetVal;
}

/**
 * @brief       Read the specified transceiver register through the MII (Clause 22)
 * @note        Not supported on AUX interface
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver on the MII
 * @param[in]   u8RegIdx Index of the transceiver register on the MII
 * @param[out]  pu16RegValPtr Filled with the register content of the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_LLD_ReadMii(uint8 u8CtrlIdx, \
                                            uint8 u8TrcvIdx, \
                                            uint8 u8RegIdx, \
                                            uint16 * pu16RegValPtr
                                        )
{
    Std_ReturnType RetVal = E_NOT_OK;
    pfe_emac_t *prEmac = NULL_PTR;
    uint32 u32Key = 0U;
    pfe_ct_phy_if_id_t emac_id;

    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];
#ifdef PFE_CFG_PFE_MASTER
        /* Lock the MDIO bus */
        if (EOK != pfe_emac_mdio_lock(prEmac, &u32Key))
        {
            NXP_LOG_ERROR("Lock the MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
        /*  Clause 22 */
        if (EOK == pfe_emac_mdio_read22(prEmac, u8TrcvIdx, u8RegIdx, pu16RegValPtr, u32Key))
        {
            RetVal = E_OK;
        }
#ifdef PFE_CFG_PFE_MASTER
        /* Unlock the locked MDIO bus */
        if (EOK != pfe_emac_mdio_unlock(prEmac, u32Key))
        {
            NXP_LOG_ERROR("Unlock the locked MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
    }

    return RetVal;
}

#if STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API
/**
 * @brief       Write specified transceiver register through the MII (Clause 45)
 * @note        Not supported on AUX interface
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver (address)
 * @param[in]   u8DevIdx Index of the device within the transciever
 * @param[in]   u16RegIdx Index of the transciever register
 * @param[in]   u16RegVal Value to be written into the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_LLD_WriteMii45(uint8 u8CtrlIdx, \
                                         uint8 u8TrcvIdx, \
                                         uint8 u8DevIdx, \
                                         uint16 u16RegIdx, \
                                         uint16 u16RegVal
                                        )
{
    Std_ReturnType RetVal = E_NOT_OK;
    pfe_emac_t *prEmac = NULL_PTR;
    uint32 u32Key = 0U;
    pfe_ct_phy_if_id_t emac_id;

    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];

#ifdef PFE_CFG_PFE_MASTER
        /* Lock the MDIO bus */
        if (EOK != pfe_emac_mdio_lock(prEmac, &u32Key))
        {
            NXP_LOG_ERROR("Lock the MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
        /*  Clause 45 */
        if (EOK == pfe_emac_mdio_write45(prEmac, u8TrcvIdx, u8DevIdx, u16RegIdx, u16RegVal, u32Key))
        {
            RetVal = E_OK;
        }
#ifdef PFE_CFG_PFE_MASTER
        /* Unlock the locked MDIO bus */
        if (EOK != pfe_emac_mdio_unlock(prEmac, u32Key))
        {
            NXP_LOG_ERROR("Unlock the locked MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
    }

    return RetVal;
}

/**
 * @brief       Read the specified transceiver register through the MII (Clause 45)
 * @note        Not supported on AUX interface
 * @api
 * @param[in]   u8CtrlIdx Index of the controller withing the context of the Ethernet Driver
 * @param[in]   u8TrcvIdx Index of the transceiver (address)
 * @param[in]   u8DevIdx Index of the device within the transciever
 * @param[in]   u16RegIdx Index of the transciever register
 * @param[out]  pu16RegValPtr Filled with the register content of the indexed register
 * @retval      E_OK Service accepted
 * @retval      E_NOT_OK Service denied
 */
Std_ReturnType Eth_43_PFE_LLD_ReadMii45(uint8 u8CtrlIdx, \
                                            uint8 u8TrcvIdx, \
                                            uint8 u8DevIdx, \
                                            uint16 u16RegIdx, \
                                            uint16 * pu16RegValPtr
                                        )
{
    Std_ReturnType RetVal = E_NOT_OK;
    pfe_emac_t *prEmac = NULL_PTR;
    uint32 u32Key = 0U;
    pfe_ct_phy_if_id_t emac_id;

    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];
#ifdef PFE_CFG_PFE_MASTER
        /* Lock the MDIO bus */
        if (EOK != pfe_emac_mdio_lock(prEmac, &u32Key))
        {
            NXP_LOG_ERROR("Lock the MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
        /*  Clause 45 */
        if (EOK == pfe_emac_mdio_read45(prEmac, u8TrcvIdx, u8DevIdx, u16RegIdx, pu16RegValPtr, u32Key))
        {
            RetVal = E_OK;
        }
#ifdef PFE_CFG_PFE_MASTER
        /* Unlock the locked MDIO bus */
        if (EOK != pfe_emac_mdio_unlock(prEmac, u32Key))
        {
            NXP_LOG_ERROR("Unlock the locked MDIO bus failed\n");
        }
#endif /* PFE_CFG_PFE_MASTER */
    }

    return RetVal;
}
#endif /* STD_ON == ETH_43_PFE_CTRL_USE_45_MDIO_API*/
#endif /* STD_OFF == ETH_43_PFE_CTRLENABLE_MII */

#if STD_ON == ETH_43_PFE_GLOBALTIME_SUPPORT
/* Set Global Time  *******************************************************************************/
Std_ReturnType Eth_43_PFE_LLD_SetGlobalTime(uint8 u8CtrlIdx, const Eth_TimeStampType *pTimeStampPtr)
{
    Std_ReturnType RetVal = E_NOT_OK;
    pfe_emac_t *prEmac = NULL_PTR;
    pfe_ct_phy_if_id_t emac_id;

    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];
        if (EOK == pfe_emac_set_ts_time(prEmac, pTimeStampPtr->seconds, pTimeStampPtr->nanoseconds, pTimeStampPtr->secondsHi))
        {
#ifdef PFE_CFG_EMAC0_PPS0_ENABLE
            if(PFE_PHY_IF_ID_EMAC0 == emac_id)
            {
                pfe_emac_pps0_resync(prEmac);
            }
#endif
            RetVal = E_OK;
        }
    }

    return RetVal;
}

/* Get Current Time  *****************************************************************************/
void Eth_43_PFE_LLD_GetCurrentTime  (   uint8 u8CtrlIdx, \
                                        Eth_TimeStampQualType *timeQualPtr, \
                                        Eth_TimeStampType *timeStampPtr \
                                    )
{
    pfe_emac_t *prEmac = NULL_PTR;
    pfe_ct_phy_if_id_t emac_id;

    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];

        if (EOK == pfe_emac_get_ts_time (   prEmac, \
                                            &(timeStampPtr->seconds), \
                                            &(timeStampPtr->nanoseconds), \
                                            &(timeStampPtr->secondsHi) \
                                        ) \
           )
        {
            *timeQualPtr = ETH_VALID;
        }
    }
}


/* helper function to adjust frequency ratio  *******************************************************************/
static Std_ReturnType EmacTsAdjustRatio(uint8 u8CtrlIdx, pfe_emac_t *prEmac, const Eth_RateRatioType *pRateRatioPtr)
{
    Std_ReturnType RetVal = E_OK;

    const uint64 u64RemoteTime = ((uint64)pRateRatioPtr->OriginTimeStampDelta.diff.seconds * 1000000000ULL)
                    + pRateRatioPtr->OriginTimeStampDelta.diff.nanoseconds;

    const uint64 u64LocalTime  = ((uint64)pRateRatioPtr->IngressTimeStampDelta.diff.seconds * 1000000000ULL)
                    + pRateRatioPtr->IngressTimeStampDelta.diff.nanoseconds;

    if ((u64RemoteTime != 0ULL) && (u64LocalTime != 0ULL))
    {
        bool_t bIsPositive;
        uint64 u64Diff;
        uint64 u64ChngFreqPPB; /* Frequency change in part per billion */
        if (u64RemoteTime > u64LocalTime)
        {
            bIsPositive = TRUE;
            u64Diff = u64RemoteTime - u64LocalTime;
            u64ChngFreqPPB = u64Diff * 1000000000ULL / u64LocalTime;
        }
        else
        {
            bIsPositive = FALSE;
            u64Diff = u64LocalTime - u64RemoteTime;
            u64ChngFreqPPB = u64Diff * 1000000000ULL / u64RemoteTime;
        }

        if ((u64Diff > 18446744073ULL) || (u64ChngFreqPPB > 0xFFFFFFFFU))
        {
            NXP_LOG_ERROR("Global time rate correction is too big %hhu\n", u8CtrlIdx);
            RetVal = E_NOT_OK;
        }
        else 
        {
            if(EOK != pfe_emac_set_ts_freq_adjustment(prEmac, (uint32)u64ChngFreqPPB, bIsPositive))
            {
                RetVal = E_NOT_OK;
            }
        }

    }
    return RetVal;
}

/**
* @brief        Allows the Time Slave to adjust the local ETH Reference clock in HW.
* @details      Only use this function when this controller used as Time Slave.
*
* @param[in]    u8CtrlIdx         Index of the controller which time shall be corrected
* @param[in]    pTimeOffsetPtr Offset between time stamp grandmaster and time stamp by local
*               clock.
* @param[in]    pRateRatioPtr  Time elements to calculate and to modify the ratio of the frequency
*               of the grandmaster in relation to the frequency of the Local Clock
*/
Std_ReturnType Eth_43_PFE_LLD_SetCorrectionTime (   uint8 u8CtrlIdx, \
                                                    const Eth_TimeIntDiffType *pTimeOffsetPtr, \
                                                    const Eth_RateRatioType *pRateRatioPtr \
                                                )
{
    Std_ReturnType RetVal = E_OK;
    pfe_emac_t *prEmac = NULL_PTR;
    pfe_ct_phy_if_id_t emac_id;

    if (PFE_CTRL_TYPE_EMAC == ETH_43_PFE_CFG_CTRLTYPE(u8CtrlIdx))
    {
        emac_id = ETH_43_PFE_CFG_CTRLPHYIFID(u8CtrlIdx);
        prEmac = ptrPlatform->emac[emac_id];

        if ((pTimeOffsetPtr->diff.seconds != 0U) || (pTimeOffsetPtr->diff.nanoseconds != 0U))
        {
            if (EOK != pfe_emac_adjust_ts_time(prEmac, pTimeOffsetPtr->diff.seconds, pTimeOffsetPtr->diff.nanoseconds, (pTimeOffsetPtr->sign != FALSE)))
            {
                RetVal = E_NOT_OK;
            }
            else 
            {
                /* system time adjusted */
#ifdef PFE_CFG_EMAC0_PPS0_ENABLE
                if(PFE_PHY_IF_ID_EMAC0 == emac_id) {
                    pfe_emac_pps0_resync(prEmac);
                }
#endif
            }
        }

        if ((Std_ReturnType)E_OK == RetVal)
        {
            RetVal = EmacTsAdjustRatio(u8CtrlIdx, prEmac, pRateRatioPtr);
        }
    }
    else
    {
        RetVal = E_NOT_OK;
    }

    return RetVal;
}


/* Enable Egress Timestamp *****************************************************************/
void Eth_43_PFE_LLD_EnableEgressTimeStamp(uint8 u8CtrlIdx, Eth_BufIdxType BufIdx)
{
    trTxMeta *prTxMeta = Eth_PFE_LLD_GetTxBufMeta(u8CtrlIdx, BufIdx);

    prTxMeta->bDoTS = TRUE;
}

/*  Get the timestamp from pfe_hif_drv_client
    DataPtr points to Ethernet frame payload (buffer + 14 for header) */
errno_t Eth_43_PFE_LLD_GetRxTimeStamp(uint8 u8CtrlIdx, \
                                    const Eth_DataType *DataPtr, \
                                    Eth_TimeStampQualType *timeQualPtr, \
                                    Eth_TimeStampType *timeStampPtr \
                                )
{
    uint8 *pu8Packet = (uint8 *)DataPtr;
    oal_util_ptp_header_t *pu8PtpHead = NULL_PTR;
    errno_t RetVal = ENOENT;

    if (NULL_PTR != arPfeInterface[u8CtrlIdx].prClient)
    {
        /* Find PTP header */
        if(EOK != oal_util_parse_ptp(pu8Packet - 14U, 106U, &pu8PtpHead))
        {
            pu8PtpHead = NULL_PTR;
        }
        if(NULL_PTR == pu8PtpHead)
        {
            NXP_LOG_ERROR("Unrecognized PTP frame\n");
            *timeQualPtr = ETH_INVALID; /* General failure */
        }
        else
        {
            uint8 PtpMsgType;
            uint16 PtpSrcPortId;
            uint16 PtpSeqId;
            /* Parse PTP values */
            PtpMsgType = pu8PtpHead->byte1.messageType;
            PtpSrcPortId = oal_ntohs(pu8PtpHead->sourcePortID);
            PtpSeqId = oal_ntohs(pu8PtpHead->sequenceID);
            /* Get timestamp */
            RetVal = pfe_hif_drv_client_get_ts
            (
                arPfeInterface[u8CtrlIdx].prClient, TRUE,
                PtpMsgType, PtpSrcPortId, PtpSeqId,
                &(timeStampPtr->seconds), &(timeStampPtr->nanoseconds)
            );

            if (EOK == RetVal)
            {
                timeStampPtr->secondsHi = 0U;
                *timeQualPtr = ETH_VALID;
            }
            else
            {
                *timeQualPtr = ETH_INVALID; /* General failure */
            }
        }
    }
    return RetVal;
}

/* Callback to get Tx timestamp from function EthIf_TxConfirmation.
   The timestamp was already obtained from pfe_hif_drv_client and is temporarily available
   in arPfeInterface[u8CtrlIdx].TimeStamp */
void Eth_43_PFE_LLD_GetTxTimeStamp( uint8 u8CtrlIdx, \
                                    Eth_BufIdxType BufIdx, \
                                    Eth_TimeStampQualType *timeQualPtr, \
                                    Eth_TimeStampType *timeStampPtr \
                                  )
{
    *timeQualPtr = aarTxBuf[u8CtrlIdx][BufIdx].TimeQual;
    *timeStampPtr = aarTxBuf[u8CtrlIdx][BufIdx].TimeStamp;
}
#endif /* ETH_43_PFE_GLOBALTIME_SUPPORT */


/**
 * @brief       Can be used to export the platform instance, which might be needed by external HIF driver
 */
void * Eth_PFE_LLD_GetPlatform(void)
{
    return ptrPlatform;
}

#if STD_ON == ETH_43_GET_CLASS_STATISTIC_API
/**
 * @brief       Get class statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @retval      E_OK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetClassStats(pfe_ct_classify_stats_t * stat)
{
    Std_ReturnType retVal = E_NOT_OK;

    if (NULL_PTR != ptrPlatform)
    {
        if(EOK == pfe_class_get_stats(ptrPlatform->classifier, stat))
        {
            retVal = E_OK;
        }
    }
    return retVal;
}
#endif /* ETH_43_GET_CLASS_STATISTIC_API */

#if STD_ON == ETH_43_GET_PFE_STATISTIC_API
/**
 * @brief       Get bmu statistics from firmware
 * @api
 * @param[in]   u8BmuIndex Bmu instance
 * @param[out]  stat Statistic structure
 * @retval      E_OK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetBmuStats(uint8 u8BmuIndex, Eth_43_PFE_BmuStatsType * stat)
{
    Std_ReturnType retVal = E_NOT_OK;
    uint8 i;
    uint32 reg_value;
    pfe_bmu_stats_special_t special_stats = {0};

    if (NULL_PTR != ptrPlatform)
    {
        if (unlikely(PFE_BMU_INSTANCES <= u8BmuIndex))
        {
            NXP_LOG_ERROR("BMU index out of range\n");
        }
        else
        {
            stat->bmu_debug_bus = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_DEBUG_BUS);
            stat->buff_base = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_UCAST_BASEADDR);
            stat->buff_remain = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_REM_BUF_CNT);
            stat->buff_allocated = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_CURR_BUF_CNT);
            stat->low_watermark = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_LOW_WATERMARK);
            stat->high_watermark = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_HIGH_WATERMARK);
            stat->irq_threshold = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_THRES) & 0xFFFFU;
            stat->free_error_add = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_FREE_ERROR_ADDR);
            stat->irq_source = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_INT_SRC);
            stat->irq_enable = pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], BMU_INT_ENABLE);

            for(i = 0; i < PFE_BMU_NUMBER_MAX_MAS_BUFF_CNT; i++)
            {
                reg_value =  pfe_bmu_get_stat_value(ptrPlatform->bmu[u8BmuIndex], (4UL*i) + BMU_MAS0_BUF_CNT);
                stat->master_buf_count[i] = reg_value;
            }

            if(EOK == pfe_bmu_get_special_stats(ptrPlatform->bmu[u8BmuIndex], &special_stats))
            {
                stat->revision = special_stats.revision;
                stat->version = special_stats.version;
                stat->id = special_stats.id;
                stat->free_error_cnt = special_stats.free_error_cnt;
                stat->active_buff = special_stats.active_buff;
                stat->buff_size = special_stats.buff_size;
            }
            else
            {
                stat->revision = PFE_INVALID_STAT;
                stat->version = PFE_INVALID_STAT;
                stat->id = PFE_INVALID_STAT;
                stat->free_error_cnt = PFE_INVALID_STAT;
                stat->active_buff = PFE_INVALID_STAT;
                stat->buff_size = PFE_INVALID_STAT;
            }
            retVal = E_OK;
        }
    }
    return retVal;
}

/**
 * @brief       Get Gpi statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @param[in]   u8GpiIndex Instance index GPI
 * @retval      E_OK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetGpiStats(uint8 u8GpiIndex , Eth_43_PFE_GpiStatsType * stat)
{
    Std_ReturnType retVal = E_NOT_OK;
    pfe_gpi_special_stats_t special_stats = {0};

    if (NULL_PTR != ptrPlatform)
    {
        if (unlikely(PFE_GPI_INSTANCES <= u8GpiIndex))
        {
            NXP_LOG_ERROR("Gpi index out of range\n");
        }
        else
        {
            stat->fifo_debug = pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_FIFO_DEBUG);
            stat->tx_debug_reg1 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_TX_DBUG_REG1);
            stat->tx_debug_reg2 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_TX_DBUG_REG2);
            stat->tx_debug_reg3 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_TX_DBUG_REG3);
            stat->tx_debug_reg4 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_TX_DBUG_REG4);
            stat->tx_debug_reg5 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_TX_DBUG_REG5);
            stat->tx_debug_reg6 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_TX_DBUG_REG6);
            stat->rx_debug_reg1 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_RX_DBUG_REG1);
            stat->rx_debug_reg2 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_RX_DBUG_REG2);

            stat->fifo_status =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],GPI_FIFO_STATUS);

            stat->iqos_queue_status =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_QUEUE_STATUS);
            stat->iqos_class_drop_cnt =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_STAT_CLASS_DROP_CNT);
            stat->iqos_lmem_drop_cnt =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_STAT_LMEM_QUEUE_DROP_CNT);
            stat->iqos_dmem_drop_cnt =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_STAT_DMEM_QUEUE_DROP_CNT);
            stat->iqos_rxf_drop_cnt =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_STAT_RXF_QUEUE_DROP_CNT);
            if(EOK != pfe_gpi_shp_get_drop_cnt(ptrPlatform->gpi[u8GpiIndex], 0, &stat->iqos_shp0_drop_cnt))
            {
                stat->iqos_shp0_drop_cnt = PFE_INVALID_STAT;
            }
            if(EOK != pfe_gpi_shp_get_drop_cnt(ptrPlatform->gpi[u8GpiIndex], 1, &stat->iqos_shp1_drop_cnt))
            {
                stat->iqos_shp1_drop_cnt = PFE_INVALID_STAT;
            } 
            stat->iqos_manage_pkts =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_STAT_MANAGED_PACKET_CNT);
            stat->iqos_unmanage_pkts =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_STAT_UNMANAGED_PACKET_CNT);
            stat->iqos_reserved_pkts =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex],CSR_IGQOS_STAT_RESERVED_PACKET_CNT);
            stat->tx_underrun =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex], GPI_FIFO_STATUS);

            stat->aseq_length =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex], GPI_DTX_ASEQ);
            stat->enable_reg_1588 =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex], GPI_EMAC_1588_TIMESTAMP_EN);
            stat->overrun_drop_cnt =  pfe_gpi_get_stat_value(ptrPlatform->gpi[u8GpiIndex], GPI_OVERRUN_DROPCNT);

            if(EOK == pfe_gpi_get_special_stats(ptrPlatform->gpi[u8GpiIndex], &special_stats))
            {
                stat->revision = special_stats.revision;
                stat->version = special_stats.version;
                stat->id = special_stats.id;
                stat->tx_fifo_packets = special_stats.tx_fifo_packets;
                stat->rx_fifo_packets = special_stats.rx_fifo_packets;
                stat->tx_fifo_level = special_stats.tx_fifo_level;
                stat->rx_fifo_level = special_stats.rx_fifo_level;
            }
            else
            {
                stat->revision = PFE_INVALID_STAT;
                stat->version = PFE_INVALID_STAT;
                stat->id = PFE_INVALID_STAT;
                stat->tx_fifo_packets = PFE_INVALID_STAT;
                stat->rx_fifo_packets = PFE_INVALID_STAT;
                stat->tx_fifo_level = PFE_INVALID_STAT;
                stat->rx_fifo_level = PFE_INVALID_STAT;
            }
            retVal = E_OK;
        }
    }
    return retVal;
}

/**
 * @brief       Get wdt statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @retval      E_OK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetWdtStats(Eth_43_PFE_WdtStatsType * stat)
{
    Std_ReturnType retVal = E_NOT_OK;

    if (NULL_PTR != ptrPlatform)
    {
        stat->wdp_version = pfe_wdt_get_stat_value(ptrPlatform->wdt, WSP_VERSION);
        stat->wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_INT_EN);
        stat->class_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, CLASS_WDT_INT_EN);
        stat->upe_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, UPE_WDT_INT_EN);
        stat->hgpi_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, HGPI_WDT_INT_EN);
        stat->hif_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, HIF_WDT_INT_EN);
        stat->tlite_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, TLITE_WDT_INT_EN);
        stat->hncpy_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, HNCPY_WDT_INT_EN);
        stat->bmu1_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, BMU1_WDT_INT_EN);
        stat->bmu2_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, BMU2_WDT_INT_EN);
        stat->emac0_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, EMAC0_WDT_INT_EN);
        stat->emac1_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, EMAC1_WDT_INT_EN);
        stat->emac2_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, EMAC2_WDT_INT_EN);
        stat->ext_gpt_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, EXT_GPT_WDT_INT_EN);
        stat->lmem_wdt_int_en = pfe_wdt_get_stat_value(ptrPlatform->wdt, LMEM_WDT_INT_EN);
        stat->wdt_int_src = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_INT_SRC);
        stat->wdt_timer_val_upe = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_UPE);
        stat->wdt_timer_val_bmu = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_BMU);
        stat->wdt_timer_val_hif = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_HIF);
        stat->wdt_timer_val_tlite = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_TLITE);
        stat->wdt_timer_val_hif_ncpy = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_HIF_NCPY);
        stat->wdt_timer_val_class = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_CLASS);
        stat->wdt_timer_val_gpi = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_GPI);
        stat->wdt_timer_val_gpt = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_GPT);
        stat->wdt_timer_val_lmem = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_LMEM);
        stat->wdt_timer_val_route_lmem = pfe_wdt_get_stat_value(ptrPlatform->wdt, WDT_TIMER_VAL_ROUTE_LMEM);
        stat->wsp_dbug_bus1_g3 = pfe_wdt_get_stat_value(ptrPlatform->wdt, WSP_DBUG_BUS1_G3);
        stat->wsp_dbug_bus1 = pfe_wdt_get_stat_value(ptrPlatform->wdt, WSP_DBUG_BUS1);
        retVal = E_OK;
    }
    return retVal;
}

/**
 * @brief       Get l2 bridge statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @param[in]   index_entry index of required entry
 * @retval      E_OK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetL2BridgeStats(Eth_43_PFE_L2BridgeStatsType * stat, uint32 index_entry)
{
    Std_ReturnType retVal = E_NOT_OK;
#ifdef PFE_CFG_L2BRIDGE_ENABLE
    uint32 number_entry;

    if (NULL_PTR != ptrPlatform)
    {
        number_entry = pfe_l2br_get_number_entries(ptrPlatform->l2_bridge);
        if (unlikely(index_entry >= number_entry))
        {
            NXP_LOG_ERROR("Entry index out of range\n");
        }
        else
        {
            if(EOK == pfe_l2br_get_stats(ptrPlatform->l2_bridge, stat, index_entry))
            {
                retVal = E_OK;
            }
        }
    }
#else
    (void)stat;
    (void)index_entry;
#endif /* PFE_CFG_L2BRIDGE_ENABLE */

    return retVal;
}

/**
 * @brief       Get l2 bridge domain statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @param[in]   index_vlan index of VLAN
 * @retval      E_OK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetL2BridgeDomainStats(pfe_ct_vlan_stats_t* stat, uint8 index_vlan)
{
    Std_ReturnType retVal = E_NOT_OK;

#ifdef PFE_CFG_L2BRIDGE_ENABLE
    if (NULL_PTR != ptrPlatform)
    {
        if(EOK == pfe_l2br_get_domain_stats(ptrPlatform->l2_bridge, stat, index_vlan))
        {
            retVal = E_OK;
        }
    }
#else
    (void)stat;
    (void)index_vlan;
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
    
    return retVal;
}

/**
 * @brief       Get rtable statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @param[in]   conntrack_index index of conntrack stat
 * @retval      EOK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetRtableStats(pfe_ct_conntrack_stats_t * stat, uint8 conntrack_index)
{
    Std_ReturnType retVal = E_NOT_OK;

#ifdef PFE_CFG_RTABLE_ENABLE
    if (NULL_PTR != ptrPlatform)
    {
        if (EOK == pfe_rtable_get_stats(ptrPlatform->rtable, stat, conntrack_index))
        {
            retVal = E_OK;
        }
    }
#else
    (void)stat;
    (void)conntrack_index;
#endif
        
    return retVal;
}

/**
 * @brief       Get tmu statistics from firmware
 * @api
 * @param[out]  stat Statistic structure
 * @retval      EOK if possible to get statistics, otherwise E_NOT_OK
 */
Std_ReturnType Eth_43_PFE_LLD_GetTmuStats(Eth_43_PFE_TmuStatsType * stat)
{
    uint32 i, j;
    Std_ReturnType retVal = E_NOT_OK;
    pfe_tmu_stats_special_t special_stats = {0};
    pfe_tmu_queue_stats queue_stats = {0};

    if (NULL_PTR != ptrPlatform)
    {
        stat->tmu_phy_inq_pktptr = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_PHY_INQ_PKTPTR);
        stat->tmu_phy_inq_pktinfo = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_PHY_INQ_PKTINFO);
        stat->tmu_phy_inq_stat = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_PHY_INQ_STAT);
        stat->tmu_dbg_bus_stop = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_DBG_BUS_TOP);
        stat->tmu_dbg_bus_pp0 = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_DBG_BUS_PP0);
        stat->tmu_dbg_bus_pp1 = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_DBG_BUS_PP1);
        stat->tmu_dbg_bus_pp2 = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_DBG_BUS_PP2);
        stat->tmu_dbg_bus_pp3 = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_DBG_BUS_PP3);
        stat->tmu_dbg_bus_pp4 = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_DBG_BUS_PP4);
        stat->tmu_dbg_bus_pp5 = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_DBG_BUS_PP5);
        stat->ctrl = pfe_tmu_get_stat_value(ptrPlatform->tmu, TMU_CTRL);

        if(EOK == pfe_tmu_get_special_stats(ptrPlatform->tmu, &special_stats))
        {
            stat->version = special_stats.version;
            stat->id = special_stats.id;
            stat->revision = special_stats.version;
        }
        else
        {
            stat->version = PFE_INVALID_STAT;
            stat->id = PFE_INVALID_STAT;
            stat->revision = PFE_INVALID_STAT;
        }
        
        for(i = 0; i < TLITE_PHYS_CNT; i++)
        {
            for(j = 0; j < TLITE_PHY_QUEUES_CNT; j++)
            {
                if (EOK == pfe_tmu_get_queue_stats(ptrPlatform->tmu, i, j, &queue_stats))
                {
                    stat->aQueue[i][j] = queue_stats;
                }
                else
                {
                    stat->aQueue[i][j].mode = PFE_INVALID_STAT;
                    stat->aQueue[i][j].min = PFE_INVALID_STAT;
                    stat->aQueue[i][j].max = PFE_INVALID_STAT;
                    stat->aQueue[i][j].level = PFE_INVALID_STAT;
                    stat->aQueue[i][j].drops = PFE_INVALID_STAT;
                    stat->aQueue[i][j].tx = PFE_INVALID_STAT;

                    (void)autolibc_memset(stat->aQueue[i][j].zprob, (sint32)(PFE_INVALID_STAT & 0xFFU), sizeof(stat->aQueue[i][j].zprob)/sizeof(stat->aQueue[i][j].zprob[0]));
                }
            }
        }
        retVal = E_OK;
    }
    return retVal;
}
#endif /* ETH_43_GET_PFE_STATISTIC_API */

#if STD_ON == ETH_43_GET_COUNTER_API
/**
* @brief         Reads a list with drop counter values of the corresponding controller.
* @note          Not supported on AUX interface (returns structure filled by invalid values).
* @param[in]     u8CtrlIdx Index of controller within the context of the Ethernet Driver.
* @param[out]    CounterPtr Counter values according to IETF RFC 1757, RFC 1643 and RFC 2233.
* @details       Reads a list with drop counter values of the corresponding controller.
*                The meaning of these values is described at Eth_CounterType.
*/
Std_ReturnType Eth_PFE_LLD_GetCounterValues(uint8 u8CtrlIdx, \
                                            Eth_CounterType * CounterPtr
                                        )
{
    pfe_emac_t *prEmac = NULL_PTR;

    prEmac = Eth_PFE_LLD_GetEmacInstanceByControllerId(u8CtrlIdx);
    /* Only EMAC interfaces has statistics, return invalid values for other interfaces */
    if (NULL_PTR == prEmac)
    {
        CounterPtr->DropPktBufOverrun = 0xFFFFFFFFU;
        CounterPtr->DropPktCrc        = 0xFFFFFFFFU;
        CounterPtr->UndersizePkt      = 0xFFFFFFFFU;
        CounterPtr->OversizePkt       = 0xFFFFFFFFU;
        CounterPtr->AlgnmtErr         = 0xFFFFFFFFU;
        CounterPtr->SqeTestErr        = 0xFFFFFFFFU;
        CounterPtr->DiscInbdPkt       = 0xFFFFFFFFU;
        CounterPtr->ErrInbdPkt        = 0xFFFFFFFFU;
        CounterPtr->DiscOtbdPkt       = 0xFFFFFFFFU;
        CounterPtr->ErrOtbdPkt        = 0xFFFFFFFFU;
        CounterPtr->SnglCollPkt       = 0xFFFFFFFFU;
        CounterPtr->MultCollPkt       = 0xFFFFFFFFU;
        CounterPtr->DfrdPkt           = 0xFFFFFFFFU;
        CounterPtr->LatCollPkt        = 0xFFFFFFFFU;
        CounterPtr->HwDepCtr0         = 0xFFFFFFFFU;
        CounterPtr->HwDepCtr1         = 0xFFFFFFFFU;
        CounterPtr->HwDepCtr2         = 0xFFFFFFFFU;
        CounterPtr->HwDepCtr3         = 0xFFFFFFFFU; 
    }
    else
    {
        /* Maximal possible value shall denote an invalid value (e.g. counter not available) */
        const uint32 tx_count_good_bad = pfe_emac_get_stat_value(prEmac, TX_PACKET_COUNT_GOOD_BAD);
        const uint32 tx_count_good     = pfe_emac_get_stat_value(prEmac, TX_PACKET_COUNT_GOOD);
        PfeDevAssert(tx_count_good_bad >= tx_count_good);
        CounterPtr->ErrOtbdPkt        = tx_count_good_bad - tx_count_good;

        CounterPtr->DropPktBufOverrun = pfe_emac_get_stat_value(prEmac, RX_FIFO_OVERFLOW_PACKETS);
        CounterPtr->DropPktCrc        = pfe_emac_get_stat_value(prEmac, RX_CRC_ERROR_PACKETS);
        CounterPtr->UndersizePkt      = pfe_emac_get_stat_value(prEmac, RX_UNDERSIZE_PACKETS_GOOD);
        CounterPtr->OversizePkt       = pfe_emac_get_stat_value(prEmac, RX_OVERSIZE_PACKETS_GOOD);
        CounterPtr->AlgnmtErr         = pfe_emac_get_stat_value(prEmac, RX_ALIGNMENT_ERROR_PACKETS);
        CounterPtr->SqeTestErr        = 0xFFFFFFFFU;
        CounterPtr->DiscInbdPkt       = pfe_emac_get_stat_value(prEmac, RX_FIFO_OVERFLOW_PACKETS);
        CounterPtr->ErrInbdPkt        = 0xFFFFFFFFU;
        CounterPtr->DiscOtbdPkt       = pfe_emac_get_stat_value(prEmac, TX_UNDERFLOW_ERROR_PACKETS);
        CounterPtr->SnglCollPkt       = pfe_emac_get_stat_value(prEmac, TX_SINGLE_COLLISION_GOOD_PACKETS);
        CounterPtr->MultCollPkt       = pfe_emac_get_stat_value(prEmac, TX_MULTIPLE_COLLISION_GOOD_PACKETS);
        CounterPtr->DfrdPkt           = pfe_emac_get_stat_value(prEmac, TX_DEFERRED_PACKETS);
        CounterPtr->LatCollPkt        = pfe_emac_get_stat_value(prEmac, TX_LATE_COLLISION_PACKETS);
        CounterPtr->HwDepCtr0         = 0xFFFFFFFFU;
        CounterPtr->HwDepCtr1         = 0xFFFFFFFFU;
        CounterPtr->HwDepCtr2         = 0xFFFFFFFFU;
        CounterPtr->HwDepCtr3         = 0xFFFFFFFFU;
    }

    return E_OK;
}
#endif /* STD_ON == ETH_43_GET_COUNTER_API */

#if STD_ON == ETH_43_GET_RXSTATS_API
/**
* @brief         Return the list of Receive Statistics.
* @note          Not supported on AUX interface (returns structure filled by invalid values).
* @param[in]     u8CtrlIdx Index of controller within the context of the Ethernet Driver.
* @param[out]    RxStats List of values according to IETF RFC 2819.
* @details       RxStats List of values according to IETF RFC 2819, where the maximal possible value shall
*                denote an invalid value.
*                e.g. if this counter is not available.
*/
Std_ReturnType Eth_PFE_LLD_GetRxStats(uint8 u8CtrlIdx, \
                                            Eth_RxStatsType * RxStatsPtr
                                        )
{
    pfe_emac_t *prEmac = NULL_PTR;

    prEmac = Eth_PFE_LLD_GetEmacInstanceByControllerId(u8CtrlIdx);
    if (NULL_PTR == prEmac)
    {
        /* Only EMAC interfaces has statistics, return invalid values for other interfaces */
        RxStatsPtr->RxStatsDropEvents           = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsOctets               = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts                 = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsBroadcastPkts        = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsMulticastPkts        = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsCrcAlignErrors       = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsUndersizePkts        = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsOversizePkts         = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsFragments            = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsJabbers              = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsCollisions           = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts64Octets         = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts65to127Octets    = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts128to255Octets   = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts256to511Octets   = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts512to1023Octets  = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts1024to1518Octets = 0xFFFFFFFFU;
        RxStatsPtr->RxUnicastFrames             = 0xFFFFFFFFU;
    }
    else
    {
        /* Maximal possible value shall denote an invalid value (e.g. counter not available) */
        const uint32 rx_crc_err = pfe_emac_get_stat_value(prEmac, RX_CRC_ERROR_PACKETS);
        const uint32 rx_align_err = pfe_emac_get_stat_value(prEmac, RX_ALIGNMENT_ERROR_PACKETS);
        RxStatsPtr->RxStatsCrcAlignErrors       = (rx_crc_err > (UINT32_MAX-rx_align_err)) ? UINT32_MAX : rx_align_err + rx_crc_err; /* saturated sum */

        RxStatsPtr->RxStatsDropEvents           = pfe_emac_get_stat_value(prEmac, RX_FIFO_OVERFLOW_PACKETS);
        RxStatsPtr->RxStatsOctets               = pfe_emac_get_stat_value(prEmac, RX_OCTET_COUNT_GOOD_BAD);
        RxStatsPtr->RxStatsPkts                 = pfe_emac_get_stat_value(prEmac, RX_PACKETS_COUNT_GOOD_BAD);
        RxStatsPtr->RxStatsBroadcastPkts        = pfe_emac_get_stat_value(prEmac, RX_BROADCAST_PACKETS_GOOD);
        RxStatsPtr->RxStatsMulticastPkts        = pfe_emac_get_stat_value(prEmac, RX_MULTICAST_PACKETS_GOOD);
        RxStatsPtr->RxStatsUndersizePkts        = pfe_emac_get_stat_value(prEmac, RX_UNDERSIZE_PACKETS_GOOD);
        RxStatsPtr->RxStatsOversizePkts         = pfe_emac_get_stat_value(prEmac, RX_OVERSIZE_PACKETS_GOOD);
        RxStatsPtr->RxStatsFragments            = pfe_emac_get_stat_value(prEmac, RX_RUNT_ERROR_PACKETS);
        RxStatsPtr->RxStatsJabbers              = pfe_emac_get_stat_value(prEmac, RX_JABBER_ERROR_PACKETS);
        RxStatsPtr->RxStatsCollisions           = 0xFFFFFFFFU;
        RxStatsPtr->RxStatsPkts64Octets         = pfe_emac_get_stat_value(prEmac, RX_64OCTETS_PACKETS_GOOD_BAD);
        RxStatsPtr->RxStatsPkts65to127Octets    = pfe_emac_get_stat_value(prEmac, RX_65TO127OCTETS_PACKETS_GOOD_BAD);
        RxStatsPtr->RxStatsPkts128to255Octets   = pfe_emac_get_stat_value(prEmac, RX_128TO255OCTETS_PACKETS_GOOD_BAD);
        RxStatsPtr->RxStatsPkts256to511Octets   = pfe_emac_get_stat_value(prEmac, RX_256TO511OCTETS_PACKETS_GOOD_BAD);
        RxStatsPtr->RxStatsPkts512to1023Octets  = pfe_emac_get_stat_value(prEmac, RX_512TO1023OCTETS_PACKETS_GOOD_BAD);
        RxStatsPtr->RxStatsPkts1024to1518Octets = pfe_emac_get_stat_value(prEmac, RX_1024TOMAXOCTETS_PACKETS_GOOD_BAD);
        RxStatsPtr->RxUnicastFrames             = pfe_emac_get_stat_value(prEmac, RX_UNICAST_PACKETS_GOOD);
    }
    return E_OK;
}
#endif /* STD_ON == ETH_43_GET_RXSTATS_API */

#if STD_ON == ETH_43_GET_TXSTATS_API
/**
* @brief         Return the list of Transmission Statistics.
* @note          Not supported on AUX interface (returns structure filled by invalid values).
* @param[in]     u8CtrlIdx Index of controller within the context of the Ethernet Driver.
* @param[out]    TxStats List of the controller within the context of the Ethernet Driver.
* @details       Return the list of Transmission Sratistics out of IETF RFC1213
*                defined with Eth_TxStatsType, where the maximal possible value shall
*                denote an invalid value.
*                e.g. this counter is not available..
*/
Std_ReturnType Eth_PFE_LLD_GetTxStats(uint8 u8CtrlIdx, \
                                            Eth_TxStatsType * TxStatsPtr
                                        )
{
    pfe_emac_t *prEmac = NULL_PTR;

    prEmac = Eth_PFE_LLD_GetEmacInstanceByControllerId(u8CtrlIdx);
    /* Only EMAC interfaces has statistics, return invalid values for other interface */
    if (NULL_PTR == prEmac)
    {

        TxStatsPtr->TxNumberOfOctets  = 0xFFFFFFFFU;
        TxStatsPtr->TxNUcastPkts      = 0xFFFFFFFFU;
        TxStatsPtr->TxUniCastPkts     = 0xFFFFFFFFU;
    }
    else
    {
        const uint32 tx_mc_good_bad = pfe_emac_get_stat_value(prEmac, TX_MULTICAST_PACKETS_GOOD_BAD);
        const uint32 tx_bc_good_bad = pfe_emac_get_stat_value(prEmac, TX_BROADCAST_PACKETS_GOOD_BAD);
        TxStatsPtr->TxNUcastPkts      = (tx_bc_good_bad > (UINT32_MAX-tx_mc_good_bad)) ? UINT32_MAX : tx_mc_good_bad + tx_bc_good_bad; /* saturated sum */

        TxStatsPtr->TxNumberOfOctets  = pfe_emac_get_stat_value(prEmac, TX_OCTET_COUNT_GOOD_BAD);
        TxStatsPtr->TxUniCastPkts     = pfe_emac_get_stat_value(prEmac, TX_UNICAST_PACKETS_GOOD_BAD); 
    }
    return E_OK;
}
#endif /* STD_ON == ETH_43_GET_TXSTATS_API */

#if STD_ON == ETH_43_GET_TXERROR_COUNTER_API
/**
* @brief         Return the list of Transmission Statistics.
* @note          Not supported on AUX interface (returns structure filled by invalid values).
* @param[in]     u8CtrlIdx Index of controller within the context of the Ethernet Driver.
* @param[out]    Eth_TxErrorCounterValuesType List of values to read statistic error values for transmiision.
* @details       Return the list of Transmission Error Counters out of IETF RFC1213 and RFC1643
*                defined with Eth_TxErrorCounterValuesType, where the maximal possible value shall
*                denote an invalid value.
*                e.g. this counter is not available..
*/
Std_ReturnType Eth_PFE_LLD_GetTxErrorCounterValues(uint8 u8CtrlIdx, \
                                            Eth_TxErrorCounterValuesType * TxErrorCounterValuesPtr
                                        )
{
    pfe_emac_t *prEmac = NULL_PTR;

    prEmac = Eth_PFE_LLD_GetEmacInstanceByControllerId(u8CtrlIdx);
    /* Only EMAC interfaces has statistics, return invalid values for other interface */
    if (NULL_PTR == prEmac)
    {
        TxErrorCounterValuesPtr->TxDroppedNoErrorPkts = 0xFFFFFFFFU;
        TxErrorCounterValuesPtr->TxDroppedErrorPkts   = 0xFFFFFFFFU;
        TxErrorCounterValuesPtr->TxDeferredTrans      = 0xFFFFFFFFU;
        TxErrorCounterValuesPtr->TxSingleCollision    = 0xFFFFFFFFU;
        TxErrorCounterValuesPtr->TxMultipleCollision  = 0xFFFFFFFFU;
        TxErrorCounterValuesPtr->TxLateCollision      = 0xFFFFFFFFU;
        TxErrorCounterValuesPtr->TxExcessiveCollison  = 0xFFFFFFFFU;
    }
    else
    {
        const uint32 tx_count_good_bad = pfe_emac_get_stat_value(prEmac, TX_PACKET_COUNT_GOOD_BAD);
        const uint32 tx_count_good     = pfe_emac_get_stat_value(prEmac, TX_PACKET_COUNT_GOOD);
        PfeDevAssert(tx_count_good_bad >= tx_count_good);
        TxErrorCounterValuesPtr->TxDroppedErrorPkts   = tx_count_good_bad - tx_count_good;

        TxErrorCounterValuesPtr->TxDroppedNoErrorPkts = pfe_emac_get_stat_value(prEmac, TX_UNDERFLOW_ERROR_PACKETS);
        TxErrorCounterValuesPtr->TxDeferredTrans      = pfe_emac_get_stat_value(prEmac, TX_DEFERRED_PACKETS);
        TxErrorCounterValuesPtr->TxSingleCollision    = pfe_emac_get_stat_value(prEmac, TX_SINGLE_COLLISION_GOOD_PACKETS);
        TxErrorCounterValuesPtr->TxMultipleCollision  = pfe_emac_get_stat_value(prEmac, TX_MULTIPLE_COLLISION_GOOD_PACKETS);
        TxErrorCounterValuesPtr->TxLateCollision      = pfe_emac_get_stat_value(prEmac, TX_LATE_COLLISION_PACKETS);
        TxErrorCounterValuesPtr->TxExcessiveCollison  = pfe_emac_get_stat_value(prEmac, TX_EXCESSIVE_COLLISION_PACKETS);
    }
    return E_OK;
}
#endif /* STD_ON == ETH_43_GET_TXERROR_COUNTER_API */

#if (STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER)
/*================================================================================================*/
Std_ReturnType Eth_PFE_LLD_ChannelBdFlushRx(pfe_ct_phy_if_id_t DestHifChnl)
{
    Std_ReturnType Ret = E_NOT_OK;

    if(E_OK == ChannelBdFlushRxPrepare(DestHifChnl))
    {
        Ret = ChannelBdFlushRxExecute(DestHifChnl);
    }

    return Ret;
}
#endif /* (STD_ON == ETH_43_PFE_CHANNEL_BD_FLUSH_API) && defined(PFE_CFG_PFE_MASTER) */

/*================================================================================================*/
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#ifdef PFE_CFG_PFE_MASTER
/**
* @brief         Set master detect flags in all HIF channels.
*/
void Eth_43_PFE_LLD_SetMasterUp(void)
{
    if (TRUE == pfe_hif_get_master_detect_cfg(ptrPlatform->hif))
    {
        /* Set Master detect flags for all HIF channels */
        pfe_hif_set_master_up(ptrPlatform->hif);
    }
}
#endif /* PFE_CFG_PFE_MASTER */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#ifdef __cplusplus
}
#endif
/** @} */


===== 文件 [104/185]: src\autolibc.c =====
/**
 *  @file             autolibc.c
 *  @brief            Custom implementation of some standard functions from libc
 *  @note             Functions are safe, as far as given pointers (with respect
 *                    to their lengths) point to valid memory ranges and strings
 *                    (except for strncpy) are zero terminated. Also avoid arrays
 *                    occupying last 4 bytes of address space (0xFFFFFFFB to
 *                    0xFFFFFFFF). Some functions (strlen, strcpy...) are in some
 *                    cases reading up to 3 bytes behind terminating nul byte.
 *  @details          This module provides some of standard functions usually
 *                    provided by a compiler library set. Module is intended to
 *                    provide only functions necessary for compilation of other
 *                    modules. All functions here are optimized for 32-bit PPC.
 */
/*==============================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright (c) 2012-2016 Freescale Semiconductor Inc.
 *  Copyright 2016-2018, 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==============================================================================*/
/*==============================================================================
==============================================================================*/

/*==============================================================================
                               MISRA VIOLATIONS
==============================================================================*/

#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==============================================================================
                                INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==============================================================================*/
#include "pfe_cfg.h"
#include "oal.h"

#include "autolibc.h"

/*==============================================================================
                             FILE VERSION CHECKS
==============================================================================*/

/*==============================================================================
                                 LOCAL MACROS
==============================================================================*/
/* WARNING, all OPT_LENGTHs must be at least 3 not to cause errors */
#define MEMCPY_OPT_LENGTH   (0x00000009u)  /* 9B optimal length for non-aligned data */
#define MEMMOVE_OPT_LENGTH  (0x00000008u)  /* 8B optimal length for non-aligned data */
#define MEMSET_OPT_LENGTH   (0x00000007u)  /* 7B optimal length for non-aligned data */
#define MEMCMP_OPT_LENGTH   (0x0000001Au)  /* 26B optimal length for non-aligned data */

/*==============================================================================
                  LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==============================================================================*/

/*==============================================================================
                               LOCAL CONSTANTS
==============================================================================*/

/*==============================================================================
                               LOCAL VARIABLES
==============================================================================*/

/*==============================================================================
                               GLOBAL CONSTANTS
==============================================================================*/

/*==============================================================================
                               GLOBAL VARIABLES
==============================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==============================================================================
                           LOCAL FUNCTION PROTOTYPES
==============================================================================*/
static inline bool_t test_u32_for_null(uint32 u32Num);
static inline sint32 memcmp8_aux(const void *pcoavMemA1, const void *pcoavMemB1, uint32 u32Size1);
static inline sint32 memcmp16_aux(const void *pcoavMemA, const void *pcoavMemB, uint32 u32Size);
static inline sint32 memcmp32_aux(const void *pcoavMemA, const void *pcoavMemB, uint32 u32Size);
static inline void memcpy8_aux(uint8 *pau8Dest, const uint8 *pcoau8Source, uint32 u32Length2);
static inline void memcpy8_backwards_aux(uint8 *dest_end, const uint8 *dest_start, const uint8 *src_end);
static inline void memcpy16_backwards_aux(uint8 *dest_end, const uint8 *dest_start, const uint8 *src_end);
static inline void memcpy32_backwards_aux(uint8 *dest_end, const uint8 *dest_start, const uint8 *src_end);
static inline sint32 strcmp8_aux(const uint8 *pcoau8StrA, const uint8 *pcoau8StrB);
static inline sint32 strcmp16_aux(const uint8 *pcoau8StrA6, const uint8 *pcoau8StrB6);
static inline sint32 strcmp32_aux(const uint8 *pcoau8StrA6, const uint8 *pcoau8StrB6);
static inline sint32 strcmp16_aligned_aux(const uint16 *pcoau16StrA6, const uint16 *pcoau16StrB6);
static inline sint32 strcmp32_aligned_aux(const uint32 *pcoau32StrA6, const uint32 *pcoau32StrB6);


/*==============================================================================
                                LOCAL FUNCTIONS
==============================================================================*/

/* Function returns TRUE when u32 number contains NUL byte */
static inline bool_t test_u32_for_null(uint32 u32Num)
{
    bool_t result = FALSE;
    if ( (0U == (u32Num & 0xFF000000U)) || \
        (0U == (u32Num & 0x00FF0000U)) || \
        (0U == (u32Num & 0x0000FF00U)) || \
        (0U == (u32Num & 0x000000FFU)))
    {
        result = TRUE;
    }
    return result;
}

/* Compares two memory blocks byte by byte. This function is version of memcmp
 * not optimized to compare long blocks of memory. It is intended to be called
 * from memcmp function to compare very short parts of long blocks. */
static inline sint32 memcmp8_aux( const void *pcoavMemA1,
                               const void *pcoavMemB1,
                               uint32 u32Size1
                             )
{
    const uint8 *pcoau8MemA1 = (const uint8 *)pcoavMemA1;
    const uint8 *pcoau8MemB1 = (const uint8 *)pcoavMemB1;
    uint32 u32Ctr1;
    sint32 s32Result1 = 0;

    for ( u32Ctr1=0U; u32Ctr1 < u32Size1; u32Ctr1++ )
    {
        s32Result1 =(sint32)pcoau8MemA1[u32Ctr1]-(sint32)pcoau8MemB1[u32Ctr1];
        if ( s32Result1 != 0 )
        {
            break;
        }
    }
    return s32Result1;
}

/* Functions compares two blocks of memory, expects pointers alignment on 4B,
 * u32Size must be greater than 4 */
static inline sint32 memcmp32_aux(const void *pcoavMemA,
                                       const void *pcoavMemB,
                                       uint32 u32Size)
{
    uint32 cur_idx = 0U;
    const uint8 *a8 = (const uint8*)pcoavMemA;
    const uint8 *b8 = (const uint8*)pcoavMemB;
    sint32 s32Result = 0;

    PfeDevAssert(u32Size >= MEMCMP_OPT_LENGTH);

    /* Compare first unaligned bytes (if any) */
    for (; 0U != ((uaddr_t)(&a8[cur_idx]) & 3U); cur_idx++ )
    {
        s32Result = (sint32)a8[cur_idx] - (sint32)b8[cur_idx];
        if (s32Result != 0)
        {
            break;
        }
    }

    if ( 0 == s32Result )
    {
        /* Compare word aligned part */
        const uint32 *a32 = (const uint32*) ( &a8[cur_idx] );
        const uint32 *b32 = (const uint32*) ( &b8[cur_idx] );
        for (; cur_idx < (u32Size - 3U); cur_idx += 4U)
        {
            if (*a32 != *b32)
            {
                s32Result = memcmp8_aux((const void*) a32, (const void *) b32, 4U);
                break; 
            }
            a32++;
            b32++;
        }

        /* Compare last unaligned part (if any) */
        if (0 == s32Result)
        {
            s32Result = memcmp8_aux(&a8[cur_idx], &b8[cur_idx], u32Size - cur_idx);
        }
    }
    return s32Result;
}

/* Functions compares two blocks of memory, expects pointers alignment on 2B,
 * u32Size must be greater than 2 */
static inline sint32 memcmp16_aux(const void *pcoavMemA, const void *pcoavMemB, uint32 u32Size)
{
    uint32 cur_idx = 0U;
    const uint8 *a8 = (const uint8*)pcoavMemA;
    const uint8 *b8 = (const uint8*)pcoavMemB;
    sint32 s32Result = 0;

    PfeDevAssert(u32Size >= MEMCMP_OPT_LENGTH);

    /* Compare first unaligned byte (if any) */
    if ( 0U != ((uaddr_t)a8 & 1U) )
    {
        s32Result = (sint32)*a8 - (sint32)*b8;
        cur_idx++;
    }
    
    if (0 == s32Result)
    {
        /* Compare halfword aligned part */
        const uint16 *a16 = (const uint16*) ( &a8[cur_idx] );
        const uint16 *b16 = (const uint16*) ( &b8[cur_idx] );
        for (; cur_idx < (u32Size - 1U); cur_idx += 2U)
        {
            if (*a16 != *b16)
            {
                s32Result = memcmp8_aux((const void*) a16, (const void *) b16, 2U);
                break; 
            }
            a16++;
            b16++;
        }

        /* Compare last unaligned part (if any) */
        if ((0 == s32Result) && (cur_idx < u32Size))
        {
            s32Result = (sint32)a8[cur_idx] - (sint32)b8[cur_idx];
        }
    }

    return s32Result;
}

/* Copies data from one memory region to another one byte by byte. 
 * It is intended to be called from autolibc_memcpy function */
static inline void memcpy8_aux(uint8 *pau8Dest, const uint8 *pcoau8Source, uint32 u32Length2)
{
    for (uint32 u32Ctr2 = 0U; u32Ctr2 < u32Length2; u32Ctr2++)
    {
        pau8Dest[u32Ctr2] = pcoau8Source[u32Ctr2];
    }    
}

/* Copy backwards, start from src_end, dest_end and decrement until dest_start is reached.
 * _end address is not included. */
static inline void memcpy8_backwards_aux(uint8 *dest_end, const uint8 *dest_start, const uint8 *src_end)
{
    uint8 *dest = dest_end;
    const uint8 *src = src_end;
    
    while (dest > dest_start) /* pointers to same array */
    {
        dest--;
        src--;
        *dest = *src;

    }
}

/* Copy backwards, start from src_end, dest_end and decrement until dest_start is reached.
 * _end address is not included. Expects pointers alignment on 4B, dest_end - dest_start > 4. */
static inline void memcpy32_backwards_aux(uint8 *dest_end, const uint8 *dest_start, const uint8 *src_end)
{
    uint8 *dest = dest_end;
    const uint8 *src = src_end;

    /* align the end of Dst to uint32 size, copy bytes (if any) */
    while ( 0U != ((uaddr_t)dest & 3U) )
    { /* 0 != (address % 4U), address not aligned to 4 */
        dest--;
        src--;
        *dest = *src;
    }

    /* copy integer aligned part of data by whole integers */
    uint32 *pu32AfterDst4 = (uint32*)dest;
    const uint32 *pcou32AfterSrc4 = (const uint32*)src;
    while ( (uaddr_t)pu32AfterDst4 >= ((uaddr_t)dest_start + 4U) )
    { /* --AfterDst >= FirstDst, syntax above prevents underflow */
        pu32AfterDst4--;
        pcou32AfterSrc4--;
        *pu32AfterDst4 = *pcou32AfterSrc4;
    }

    /* copy the remaining unaligned bytes on the beginning (if any) */
    dest = (uint8*)pu32AfterDst4;
    src = (const uint8*)pcou32AfterSrc4;
    while ( dest > dest_start ) /* pointers to same array */
    {
        dest--;
        src--;
        *dest = *src;
    }    
}

/* Copy backwards, start from src_end, dest_end and decrement until dest_start is reached.
 * _end address is not included. Expects pointers alignment on 2B, dest_end - dest_start > 2. */
static inline void memcpy16_backwards_aux(uint8 *dest_end, const uint8 *dest_start, const uint8 *src_end)
{
    uint8 *dest = dest_end;
    const uint8 *src = src_end;

    if ( 0U != ((uaddr_t)dest & 1U) )
    { /* 0 != (address % 4U), address not aligned to 4 */
        dest--;
        src--;
        *dest = *src;
    }
    /* Move 2B-aligned part of data by 2 bytes */
    uint16 *pu16AfterDst4 = (uint16*)dest;
    const uint16 *pcou16AfterSrc4 = (const uint16*)src;
    while ( (uaddr_t)pu16AfterDst4 >= ((uaddr_t)dest_start + 2U) )
    { /* --AfterDst >= FirstDst, syntax above prevents underflow */
        pu16AfterDst4--;
        pcou16AfterSrc4--;
        *pu16AfterDst4 = *pcou16AfterSrc4;
    }
    /* move the remaining unaligned bytes on the beginning (if any) */
    dest = (uint8*)pu16AfterDst4;
    src = (const uint8*)pcou16AfterSrc4;
    if ( dest > dest_start ) /* pointers to same array */
    {
        dest--;
        src--;
        *dest = *src;
    }
}

/* Helper function for strcmp, it walks through by 1 B */
static inline sint32 strcmp8_aux(const uint8 *pcoau8StrA, const uint8 *pcoau8StrB)
{
    uint32 u32Ctr = 0U;

    while (0U != (pcoau8StrA[u32Ctr]))
    {
        if ( pcoau8StrA[u32Ctr] != pcoau8StrB[u32Ctr] )
        {
            /* strings not same, not matching bytes */
            break;
        }
        u32Ctr++;
    }

    return ((sint32)pcoau8StrA[u32Ctr] - (sint32)pcoau8StrB[u32Ctr]);
}

/* Helper function for strcmp32_aux, compares word aligned part of strings */
static inline sint32 strcmp32_aligned_aux(const uint32 *pcoau32StrA6, const uint32 *pcoau32StrB6)
{
    sint32 s32Result6 = 0;
    uint32 u32Ctr6 = 0U;
    bool_t finished = FALSE;

    /* The loop is running till zero byte or non-matching bytes are found. */
    while (TRUE)
    {
        if (pcoau32StrA6[u32Ctr6] != pcoau32StrB6[u32Ctr6])
        { /* there is at least 1 not matching byte */
            /* accessing by bytes again */
            const uint8 *str_a = (const uint8*)&pcoau32StrA6[u32Ctr6];
            const uint8 *str_b = (const uint8*)&pcoau32StrB6[u32Ctr6];
            for (uint32 u32LittleCtr6=0U; u32LittleCtr6 < 4U; u32LittleCtr6++ )
            {
                s32Result6 = (sint32)str_a[u32LittleCtr6] \
                                - (sint32)str_b[u32LittleCtr6];
                if ((s32Result6 != 0) || (0U == str_a[u32LittleCtr6]))
                {
                    finished = TRUE;
                    break;
                }
            }
        }
        else
        { /* integers are identical */
            /* need check for '\0' byte in one of integers */
            if (test_u32_for_null(pcoau32StrA6[u32Ctr6]) == TRUE)
            {
                finished = TRUE; /* string end found, strings are identical */
            }
        }

        if (finished == TRUE)
        {
            break;
        }

        u32Ctr6++;
    }

    return s32Result6;
}

/* Helper function for strcmp, it walks through by 4 B */
static inline sint32 strcmp32_aux(const uint8 *pcoau8StrA6, const uint8 *pcoau8StrB6)
{
    sint32 s32Result6 = 0;
    uint32 u32Ctr6 = 0U;
    bool_t finished = FALSE;
    const uint8 *str_a = pcoau8StrA6;
    const uint8 *str_b = pcoau8StrB6;


    /* first unaligned bytes */
    while ( 0U != ((uaddr_t)(&str_a[u32Ctr6]) & 3U) )
    { /* 0 != (address % 4U), address not aligned to 4 */
        s32Result6 = (sint32)str_a[u32Ctr6] - (sint32)str_b[u32Ctr6];
        if ((s32Result6 != 0) || (0U == str_a[u32Ctr6]))
        {
            finished = TRUE;
            break;
        }
        u32Ctr6++;
    }

    if (finished == FALSE)
    {
        /* integer aligned part of strings */
        const uint32 *pcoau32StrA6 = (const uint32*)(&str_a[u32Ctr6]);
        const uint32 *pcoau32StrB6 = (const uint32*)(&str_b[u32Ctr6]);
        s32Result6 = strcmp32_aligned_aux(pcoau32StrA6, pcoau32StrB6);
    }

    return s32Result6;
}

/* Helper function for strcmp16_aux, compares word aligned part of strings */
static inline sint32 strcmp16_aligned_aux(const uint16 *pcoau16StrA6, const uint16 *pcoau16StrB6)
{
    sint32 s32Result6 = 0;
    uint32 u32Ctr6 = 0U;
    bool_t finished = FALSE;

    while (TRUE)
    {
        if ( pcoau16StrA6[u32Ctr6] != pcoau16StrB6[u32Ctr6] )
        { /* there is at least 1 not matching byte */
            /* accessing by bytes again */
            const uint8 *str_a = (const uint8*)&pcoau16StrA6[u32Ctr6];
            const uint8 *str_b = (const uint8*)&pcoau16StrB6[u32Ctr6];

            for (uint32 u32LittleCtr6=0U; u32LittleCtr6 < 2U; u32LittleCtr6++ )
            {
                s32Result6 = (sint32)str_a[u32LittleCtr6] \
                                - (sint32)str_b[u32LittleCtr6];
                if ((s32Result6 != 0) || (0U == str_a[u32LittleCtr6]) )
                {
                    finished = TRUE;
                    break;
                }
            }
        }
        else
        { /* integers are identical */
            /* need check for '\0' byte in one of integers */
            if ( ( 0U == (pcoau16StrA6[u32Ctr6] & 0xFF00U) ) || \
                ( 0U == (pcoau16StrA6[u32Ctr6] & 0x00FFU) )
                )
            {
                finished = TRUE; /* string end found, strings are identical */
            }
        }
        if (finished == TRUE)
        {
            break;
        }
        u32Ctr6++;
    }

    return s32Result6;
}

/* Helper function for strcmp, it walks through by 4 B */
static inline sint32 strcmp16_aux(const uint8 *pcoau8StrA6, const uint8 *pcoau8StrB6)
{
    sint32 s32Result6 = 0;
    uint32 u32Ctr6 = 0U;
    bool_t finished = FALSE;
    const uint8 *str_a = pcoau8StrA6;
    const uint8 *str_b = pcoau8StrB6;

    /* first unaligned byte */
    if ( 0U != ((uaddr_t)(&str_a[u32Ctr6]) & 1U) )
    { /* 0 != (address % 2U), address not aligned to 2 */
        s32Result6 = (sint32)str_a[u32Ctr6] - (sint32)str_b[u32Ctr6];
        if ((s32Result6 != 0) || (0U == str_a[u32Ctr6]))
        {
            finished = TRUE;
        }
        u32Ctr6++;
    }

    if (finished == FALSE)
    {
        /* integer aligned part of strings */
        const uint16 *pcoau16StrA6 = (const uint16*)(&str_a[u32Ctr6]);
        const uint16 *pcoau16StrB6 = (const uint16*)(&str_b[u32Ctr6]);
        s32Result6 = strcmp16_aligned_aux(pcoau16StrA6, pcoau16StrB6);
    }

    return s32Result6;
}

/*==============================================================================
                                GLOBAL FUNCTIONS
==============================================================================*/

/**
* @brief Copies data from one memory region to another one.
* @details Function copies data from one memory region to another one. Memory
*          regions must not overlap and the size of destination region must be
*          greater than or equal to size of the source region.
*          Copy operation is optimized for any alignment of source or
*          destination data.
* @param[out] pavDest2 Copy destination
* @param[in] pcoavSource2 Source data pointer
* @param[in] u32Length2 Number of bytes to be copied
* @note Function does not handle overlap and overflow.
*/
void *autolibc_memcpy(void *pavDest2, const void *pcoavSource2, uint32 u32Length2)
{
    /* BYTE pointers */
    uint8 *dest = (uint8 *)pavDest2;
    const uint8 *src = (const uint8 *)pcoavSource2;

    /* too short for optimizations, copy along 1B */
    if ( u32Length2 < MEMCPY_OPT_LENGTH )
    {
        memcpy8_aux(dest, src, u32Length2);
    }
    else
    {   /* optimized copying */
        uint32 cur_idx = 0U;
        /* Compute offset between pointers. We are only interested in last 2 bits, so uint8 is enough */
        const uint8 u8ShiftDif = (uint8)(((uaddr_t)pavDest2 - (uaddr_t)pcoavSource2) & 3U);

        /* Check whether offset between pointers is multiple of 4 (last 2 bits are zero) */
        if ( 0U == u8ShiftDif )
        {   /* copy first unaligned part of bytes (if any) */
            for (; 0U != ((uaddr_t)(&dest[cur_idx]) & 3U); cur_idx++)
            {
                dest[cur_idx] = src[cur_idx];
            }

            /* copy word aligned part of data */
            uint32 *dest_aligned32 = (uint32 *)(&dest[cur_idx]);       
            const uint32 *src_aligned32 = (const uint32 *)(&src[cur_idx]);
            for (; cur_idx < (u32Length2 - 3U); cur_idx += 4U)
            {
                *dest_aligned32 = *src_aligned32;
                dest_aligned32++;
                src_aligned32++;
            }

            /* copy the last unaligned bytes (if any) */
            for (; cur_idx < u32Length2; cur_idx++)
            {
                dest[cur_idx] = src[cur_idx];
            }    
        }
        /* Check whether offset between pointers is multiple of 2 (last 1 bit is zero) */
        else if ( 0U == (u8ShiftDif & 1U) )
        {   /* copy first unaligned  byte (if any) */
            if ( 0U != ((uaddr_t)(&dest[cur_idx]) & 1U) )
            {
                dest[cur_idx] = src[cur_idx];
                cur_idx++;
            }

            /* copy halfword aligned part of data */
            uint16 *dest_aligned16 = (uint16 *)(&dest[cur_idx]);       
            const uint16 *src_aligned16 = (const uint16 *)(&src[cur_idx]);
            for (; cur_idx < (u32Length2 - 1U); cur_idx += 2U)
            {
                *dest_aligned16 = *src_aligned16;
                dest_aligned16++;
                src_aligned16++;
            }
            
            /* copy the last unaligned bytes (if any) */
            if (cur_idx < u32Length2)
            {
                dest[cur_idx] = src[cur_idx];

            }            
        }
        /* any other shifting */
        else
        {
            /* copying along 1B */
            memcpy8_aux(dest, src, u32Length2);
        }
    }
    return pavDest2;
}

/**
* @brief Fills the memory block with a given byte value.
* @details Function writes a given byte value into all bytes in a given
*          memory area. Uses optimized algorithm and handles all alignment
*          of destination buffer.
* @param[out] pavDest3 Beginning of the memory block to be filled
* @param[in] s32Fill3 Value to be used as fill
* @param[in] u32Length3 Number of bytes to be filled
* @return Pointer to the filled block.
*/
void *autolibc_memset(void *pavDest3, sint32 s32Fill3, uint32 u32Length3)
{
    uint32 cur_idx = 0U;
    uint8 u8Fill3 = 0U;
    uint8  *dest = (uint8 *)pavDest3;

    /* MISRA and CERC C compliant way how to convert s32 to u8 */
    const sint64 s64Fill3 = (sint64)s32Fill3 - INT32_MIN;
    u8Fill3 = (uint8)(((uint32)s64Fill3) & 0xFFu);

    /* too short for optimizations */
    if ( u32Length3 < MEMSET_OPT_LENGTH )
    {
        for (cur_idx = 0U; cur_idx < u32Length3; cur_idx++)
        {
            dest[cur_idx] = u8Fill3;
        }
    }
    /* optimized code */
    else
    {
        /* write first unaligned part of bytes (if any) */
        while ( 0U != ((uaddr_t)(&dest[cur_idx]) & 3U) )
        { /* set first unaligned bytes */
            dest[cur_idx] = u8Fill3;
            cur_idx++;
        }

        /* write word aligned part of data */
        uint32 *dest_aligned32 = (uint32 *)(&dest[cur_idx]);
        const uint32 u32_fill = 0x01010101U * u8Fill3;
        for (; cur_idx < (u32Length3 - 3U); cur_idx += 4U)
        {
            *dest_aligned32 = u32_fill;
            dest_aligned32++;
        }

        /* write the last unaligned bytes (if any) */
        for (; cur_idx < u32Length3; cur_idx++)
        {
            dest[cur_idx] = u8Fill3;
        }        
    }
    return pavDest3;
}

/**
* @brief Copies one memory area to another one
* @details Function copies data from one memory region to another. It handles
*          overlap of areas. It does not use any temporary buffer.
*          This function handles different alignment of source and destination
*          buffer.
* @param[out] pavDest4 Destination area
* @param[in] pcoavSource4 Source area
* @param[in] u32Length4 Number of bytes to be copied
* @return Pointer to the pavDest4 area.
*/
void *autolibc_memmove(void *pavDest4, const void *pcoavSource4, uint32 u32Length4)
{
    /* Pointers for optimized, reversed (end to beginning) copying */
    uint8       *pu8FirstDst4;
    const uint8 *pcou8FirstSrc4;
    /* BYTE pointers */
    uint8       *pu8AfterDst4;
    const uint8 *pcou8AfterSrc4;
    uint8  u8ShiftDif;

    /* Temporary spaces cannot be used because malloc is not available */
    if (pavDest4 == pcoavSource4)
    {   /* Both buffers are same */
        ; /* Nothing to copy, it is already done */
    }
    else if ( pavDest4 < pcoavSource4 )
    {   /* Source start possibly overlaps the destination end which means the
           start of the pcoavSource4 could be overwritten. It is save to copy
           from the beginning, which is what autolibc_memcpy does. */
        /* MISRA NOTE: the return value does not contain error information */
        (void)autolibc_memcpy( pavDest4, pcoavSource4, u32Length4);
    }
    else
    {   /* Destination start possibly overlaps the end of source which means
           the end of the source could be overwritten. It is safe to copy from
           the end. */
        pu8FirstDst4 = (uint8 *)pavDest4;
        pcou8FirstSrc4 = (const uint8 *)pcoavSource4;
        pu8AfterDst4 = &pu8FirstDst4[u32Length4];
        pcou8AfterSrc4 = &pcou8FirstSrc4[u32Length4];

        /* Explanation:
           Copying from end to beginning (reversed).
           The pointers named FirstDst and FirstSrc are classic pointers
           to beginnings of data to be copied. They are not used for copying.
           They are used to keep lowest accessible address for comparisons.
           The pointers named AfterDst and AfterSrc both point to next address
           after data to be copied, it is always pre-decremented before each
           copy. They are used to copy.
        */
        /* Safety:
           Assuming both given data areas are valid.
           First optimized loop iterates at most 3 times, writing at most 3
           bytes. It is working with at least 3 bytes long data, so
           lower boundary of data to be copied cannot be broken there.
           In all other loops we are in every iteration checking we will not be
           writing before the FirstDst address.
           All the time we are writing before "AfterDst" address. This
           address is decremented only, sure not to underflow. This ensures that
           we will not break the upper boundary of data to be copied.
        */

        /* too short for optimizations, move along 1B */
        if ( u32Length4 < MEMMOVE_OPT_LENGTH )
        {
            memcpy8_backwards_aux(pu8AfterDst4, pu8FirstDst4, pcou8AfterSrc4);
        }
        /* optimized copying */
        else
        {
            /* warning - conversion to smaller type (lost of higher bytes) - required behaviour here */
            u8ShiftDif = (uint8)((uaddr_t)pavDest4 - (uaddr_t)pcoavSource4);
            /* Check whether offset between pointers is multiple of 4 (last 2 bits are zero) */
            if ( 0U == (u8ShiftDif & 3U) )
            {   /* move along 4B */
                memcpy32_backwards_aux(pu8AfterDst4, pu8FirstDst4, pcou8AfterSrc4);
            }
            /* 2B shift between destination and source data addresses */
            else if ( 0U == (u8ShiftDif & 1U) )
            {
                /* move along 2B */
                memcpy16_backwards_aux(pu8AfterDst4, pu8FirstDst4, pcou8AfterSrc4);
            }
            /* any other shifting */
            else
            {   /* move along 1B */
                memcpy8_backwards_aux(pu8AfterDst4, pu8FirstDst4, pcou8AfterSrc4);
            }
        }
    }
    /* Note - no special copy process is needed when buffers do not overlap
       because overlap handling process copies also non-overlapping data - so
       actual overlap is not checked but only the type of possible overlap which
       determines how (from which end) to copy the data. */
    return pavDest4;
}
/**
* @brief Compares two memory blocks
* @details Function returns difference between the first not matching characters
*          or zero if data in blocks are identical. Compare operation is optimized
*          for all alignment of source or destination memory blocks.
*
* @param[in] pcoavMemA5 The first block to be compared
* @param[in] pcoavMemB5 The second block to be compared
* @param[in] u32Size5 Number of bytes to be compared
* @return 0 if both blocks are equal, difference (pcoavMemA5[] - pcoavMemB5[])
*         of first unmatching byte otherwise.
*/
sint32 autolibc_memcmp( const void *pcoavMemA5, const void *pcoavMemB5, uint32 u32Size5 )
{
    sint32 s32Result5;
    uint8 u8ShiftDif;

    /* too short for optimizations */
    if (u32Size5 < MEMCMP_OPT_LENGTH )
    {
        s32Result5 = memcmp8_aux(pcoavMemA5, pcoavMemB5, u32Size5);
    }
    /* optimized comparing */
    else
    {
        /* In this optimizations aligning by first string */
        u8ShiftDif = (uint8)(((uaddr_t)pcoavMemB5-(uaddr_t)pcoavMemA5) & 3U);
        /* Check whether offset between pointers is multiple of 4 (last 2 bits are zero) */
        if ( 0U == u8ShiftDif )
        {
            /* comparing along 4B */
            s32Result5 = memcmp32_aux(pcoavMemA5, pcoavMemB5, u32Size5);
        }
        /* 2B shift between destination and source data addresses */
        else if ( 0U == (u8ShiftDif & 1U) )
        {
            /* comparing along 2B */
            s32Result5 = memcmp16_aux(pcoavMemA5, pcoavMemB5, u32Size5);
        }
        /* any other shifting */
        else
        {
            s32Result5 = memcmp8_aux( pcoavMemA5, pcoavMemB5, u32Size5 );
        }
    }
    return s32Result5;
}

/**
* @brief Copies given number of string characters into another string
* @details Function copies given number of characters from the source string
*          into the destination string. If the source string is shorter than the
*          requested characters number then the remaining characters in the
*          destination string are set to the null character. If source string is
*          longer than requested characters number then the destination string
*          will not contain the terminating null character. This operation is
*          optimized for all alignment of source or destination string.
*
* @note Destination string size should be long enough to fit in given number of
*       characters.
* @param[out] pszDest7 Destination string
* @param[in] pcoszSrc7 Source string
* @param[in] u32Length7 Number of characters to be copied
* return Pointer to the destination string
*/
char_t *autolibc_strncpy(char_t *pszDest7, const char_t *pcoszSrc7, uint32 u32Length7)
{
    uint32 u32Ctr7 = 0U;

    for (u32Ctr7 = 0U; u32Ctr7 < u32Length7; u32Ctr7++)
    {
        if ('\0' == pcoszSrc7[u32Ctr7] )
        {
            break;
        }
        else
        {
            pszDest7[u32Ctr7] = pcoszSrc7[u32Ctr7];
        }
    }

    /* Fill the rest of the destination string with zeros */
    while ( u32Ctr7 < u32Length7 )
    {
        pszDest7[u32Ctr7] = '\0';
        u32Ctr7++;
    }

    return pszDest7;
}

/**
* @brief Copies string characters into another string
* @details Function copies characters from the source string
*          into the destination string.
*
* @param[out] pszDest Destination string
* @param[in]  pcoszSrc Source string
* return Pointer to the destination string
*/
char_t *autolibc_strcpy(char_t *pszDest, const char_t *pcoszSrc)
{
    uint32 u32Ctr = 0U;

    do
    {
        /* copying along 1B */
        pszDest[u32Ctr] = pcoszSrc[u32Ctr];
    } while(0U != (uint8)(pcoszSrc[u32Ctr++]));
    return pszDest;
}

/**
* @brief Compares two strings
* @details Function returns difference between the first not matching characters
*          or zero if strings are identical. This operation is optimized for all
*          alignment of source or destination string.
* @param[in] pcoszStrA6 The first string to compare
* @param[in] pcoszStrB6 The second string to compare
* @return Result of (*pcoszStrA6 - *pcoszStrB6) when the not matching character is
*         found. Value 0 means that both strings are equal.
* @note In some cases reading up to 3 bytes behind terminating null byte.
*/
sint32 autolibc_strcmp(const char_t *pcoszStrA6, const char_t *pcoszStrB6)
{

    sint32 s32Result6 = 0;
    /* BYTE pointers */
    const uint8 *pcoau8StrA6 = (const uint8*)pcoszStrA6;
    const uint8 *pcoau8StrB6 = (const uint8*)pcoszStrB6;

    uint8  u8ShiftDif = (uint8)(((uaddr_t)pcoszStrB6 - (uaddr_t)pcoszStrA6) & 3U);
    /* Check whether offset between pointers is multiple of 4 (last 2 bits are zero) */
    if ( 0U == u8ShiftDif )
    {   /* comparing along 4B */
        s32Result6 =  strcmp32_aux(pcoau8StrA6, pcoau8StrB6);
    }
    else if ( 0U == (u8ShiftDif & 1U) )
    {   /* Compare along 2B */
        s32Result6 =  strcmp16_aux(pcoau8StrA6, pcoau8StrB6);
    }
    /* any other shifting */
    else
    {
        s32Result6 =  strcmp8_aux(pcoau8StrA6, pcoau8StrB6);
    }

    return s32Result6;
}

/**
* @brief Computes length of the string.
* @details Function searches for the null character and counts bytes until it
*          finds it.
* @param[in] pcozsStr8 String to determine the length for.
* @return String length.
* @note In some cases reading up to 3 bytes behind terminating null byte.
*/
uint32 autolibc_strlen(const char_t pcozsStr8[])
{
    uint32 u32Length8 = 0U;
    while ( pcozsStr8[u32Length8] != '\0' )
    {
        u32Length8++;
    }
    return u32Length8;   /* HIS_COMF check suppression comment */
}

/**
* @brief Computes length of the string.
* @details Function searches for the null character and counts bytes until it
*          finds it or stops after u32Strsz characters is exhausted
* @param[in] pcozsStr8 String to determine the length for.
* @param[in] u32Strsz maximum number of characters search through
* @return String length or u32Strsz when null character not found
* @note In some cases reading up to 3 bytes behind terminating null byte.
*/
uint32 autolibc_strnlen(const char_t pcozsStr8[], uint32 u32Strsz)
{
    uint32 u32Length8 = 0U;

    if(NULL_PTR != pcozsStr8)
    {
        while((u32Length8 < u32Strsz) && (pcozsStr8[u32Length8] != '\0'))
        {
            u32Length8++;   /* HIS_COMF check suppression comment */
        }
    }

    return u32Length8;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


#ifdef __cplusplus
}
#endif


===== 文件 [105/185]: src\blalloc.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */


/*
* Block allocator
* This module partitions the memory pool into blocks (chunks) of a fixed size and provides one or more
* chunks to satisfy the request.
* The allocator maintains a map of free/used chunks in a form of 2-bit array where each 2-bits represent
* one chunk. The value encoding is the following:
* 00 - unused chunk ready to be provided
* 01 - used chunk
* 11 - used chunk, last in the region
* 10 - reserved
* There are dummy bits at the end of the bit array to have integral number of bytes.
* The dummy bits are always set.
*
* Note to "2-bit": the term 2-bit is used to refer to the pair of bits representing a single chunk. There
* are 4 2-bits in the byte.
*/


/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440


/*==================================================================================================
                                         INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "oal.h"
#include "blalloc.h"
/*==================================================================================================
                                            CHECKS
==================================================================================================*/

/*==================================================================================================
                                        LOCAL MACROS
==================================================================================================*/
#define CHUNKS_IN_BYTE BLALLOC_CFG_CHUNKS_IN_BYTE
#define CHUNK_BITS_COUNT (8U / CHUNKS_IN_BYTE)

#define USED_CHUNK 0x01U
#define LAST_USED_CHUNK 0x03U

#define CHUNK_TEST_MASK 0xC0U
#define CHUNK_TEST_SHIFT ((CHUNKS_IN_BYTE - 1U) * CHUNK_BITS_COUNT)
#define ALL_CHUNKS_USED ((USED_CHUNK << 6U) | (USED_CHUNK << 4U) | (USED_CHUNK << 2U) | (USED_CHUNK << 0U))
#define ALL_CHUNKS_USED_LAST ((LAST_USED_CHUNK << 6U) | (LAST_USED_CHUNK << 4U) | (LAST_USED_CHUNK << 2U) | (LAST_USED_CHUNK << 0U))

#define SUM_WRAP_U32(A,B) ((uint32)((((uint64)(A) & UINT32_MAX) + (B)) & UINT32_MAX))
#define UDIV32_ROUND_UP(N,D) ((((uint64)(N) & UINT32_MAX) + (D) - 1U) / (D))

/**
 * @brief A temporary define used to determine context size in blalloc_create(). 
 * Total size: 
 *  Set according to the FW DMEM physical size (16 kB) for possible FW upgrade. 
 *  
 *  Calculated as:
 *      sizeof(blalloc_t) + (0x4000 >> PFE_CLASS_HEAP_CHUNK_SIZE) / CHUNKS_IN_BYTE
 *  Meaning:
 *      sizeof(blalloc_t) + Size of DMEM / chunk size (B) / number of chunkinfo per byte
 *  In values:
 *      28 + ((0x4000 / 16) / (8/2)) = 28 + 256 = 284
 * 
 */
#define PFE_CLASS_HEAP_CHUNK_SIZE               (4U)
#define BLALLOC_T_STATIC_ALLOCATION_SIZE_B      (sizeof(blalloc_t) + ((0x4000U >> PFE_CLASS_HEAP_CHUNK_SIZE) / CHUNKS_IN_BYTE))
/*==================================================================================================
                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/

/*==================================================================================================
                                       LOCAL CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       LOCAL VARIABLES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"
__attribute__((aligned(16))) static uint8 blalloc_create_context_static[BLALLOC_T_STATIC_ALLOCATION_SIZE_B];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"


/*==================================================================================================
                                       GLOBAL CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       GLOBAL VARIABLES
==================================================================================================*/

/*==================================================================================================
                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static void set_bits(uint8 *bytes, uint32 offset, uint32 count);
static void clear_bits(uint8 *bytes, uint32 offset, uint32 count);
static inline uint32 chunks_count(const blalloc_t *ctx, const uint32 size);
static inline uint32 chunks_alignment(const blalloc_t *ctx, const uint32 align);
static inline uint32 calculate_offset(const blalloc_t *ctx);
static inline void chunks_mark(blalloc_t *ctx, const uint32 size, const uint32 offset, const uint32 count);

/*==================================================================================================
                                       LOCAL FUNCTIONS
==================================================================================================*/
/*
* @brief Marks the given count ouf chunks as used, marks the last one as the last one
* @param[in] bytes Array containing the chunk information
* @param[in] offset Index of the first chunk to mark as used
* @param[in] count Number of chunks to mark as used
*/
static void set_bits(uint8 *bytes, uint32 offset, uint32 count)
{
    uint_t first_chunk = offset;
    uint_t first_byte = offset / CHUNKS_IN_BYTE;
    uint_t last_chunk = SUM_WRAP_U32(offset, count - 1U);
    uint_t last_byte = last_chunk / CHUNKS_IN_BYTE;
    uint_t i;


    for(i = first_byte; i <= last_byte; i++)
    {
        uint8 mask = 0xFFU;

        if(i == first_byte)
        {   /* Some bits in the first byte (before the first chunk) shall not be affected */
            /* Do not modify bits before the first chunk - set their mask to 0 */
            mask = (uint8)(mask & (0xFFU >> ((first_chunk % CHUNKS_IN_BYTE) * CHUNK_BITS_COUNT)));
        }

        if(i == last_byte)
        {
            if(0U != ((uint32)(((uint64)offset + count) % CHUNKS_IN_BYTE)))
            {   /* Some bits in last byte (after last chunk) shall not be affected */
                uint_t shift = ((CHUNKS_IN_BYTE - ((count + offset) % CHUNKS_IN_BYTE)) * CHUNK_BITS_COUNT);
                mask &= 0xFFU << shift;
                bytes[i] |= LAST_USED_CHUNK << shift;
            }
            else
            {   /* All bits shall be affected - the last chunk is the last one in the last byte */
                ;/* shift = 0; mask &= 0xFFU; which does not have any effect */
                bytes[i] |= LAST_USED_CHUNK;
            }

        }
        bytes[i] |= ALL_CHUNKS_USED & mask;
    }
}

/*
* @brief Marks given count of chunks as unused (inverse function to set_bits())
* @param[in] bytes Array containing the chunk information
* @param[in] offset Index of the first chunk to mark as unused
* @param[in] count Number of chunks to mark as unused
*/
static void clear_bits(uint8 *bytes, uint32 offset, uint32 count)
{
    uint_t first_chunk = offset;
    uint_t first_byte = offset / CHUNKS_IN_BYTE;
    uint_t last_chunk = SUM_WRAP_U32(offset, count - 1U);
    uint_t last_byte = last_chunk / CHUNKS_IN_BYTE;
    uint_t i;

    /* The algorithm is the same as in set_bits() with two modifications:
       1, we do not mark the last chunk
       2, the mask is at the end inverted and ANDed to the byte instead of ORing it
    */

    for(i = first_byte; i <= last_byte; i++)
    {
        uint8 mask = 0xFFU;

        if(i == first_byte)
        {   /* Some bits in the first byte (before the first chunk) shall not be affected */
            /* Do not modify bits before the first chunk - set their mask to 0 */
            mask = (uint8)(mask & (0xFFU >> ((first_chunk % CHUNKS_IN_BYTE) * CHUNK_BITS_COUNT)));
        }

        if(i == last_byte)
        {
            if(0U != (uint32)(((uint64)offset + count) % CHUNKS_IN_BYTE))
            {   /* Some bits in last byte (after last chunk) shall not be affected */
                uint_t shift = ((CHUNKS_IN_BYTE - ((count + offset) % CHUNKS_IN_BYTE)) * CHUNK_BITS_COUNT);
                mask &= 0xFFU << shift;
            }
            else
            {   /* All bits shall be affected - the last chunk is the last one in the last byte */
                ;/* shift = 0; mask &= 0xFFU; which does not have any effect */

            }

        }
        bytes[i] &= ~mask;
    }
}

/**
 * @brief Calculate number of chunks
 * @param[in] ctx Context instance
 * @param[in] size Size of the memory to be allocated
 * @return Number of chunks to allocate
 */
static inline uint32 chunks_count(const blalloc_t *ctx, const uint32 size)
{
    /* How many chunks do we need? */
    PfeDevAssert(((uint32)1U << ctx->chunk_size) > 0U);
    const uint32 sizemask = ((uint32)1U << ctx->chunk_size) - (uint32)1U;

    PfeDevAssert((SIZE_MAX - size) >= sizemask);
    /* Round size toward the nearest multiple of chunk size
       - causes sizes less than a chunk to allocate one chunk (value 0 is not considered as it is stupid)
       - Translate size to chunks count */
    const uint32 size_rounded = ((size + sizemask) & ~sizemask) >> ctx->chunk_size;

    return size_rounded;
}

/**
 * @brief Calculate needed alignment
 * @param[in] ctx Context instance
 * @param[in] size Size of the memory to be allocated
 * @return Needed memory alignment
 */
static inline uint32 chunks_alignment(const blalloc_t *ctx, const uint32 align)
{
    PfeDevAssert(((uint32)1U << ctx->chunk_size) > 0U);
    const uint32 sizemask = ((uint32)1U << ctx->chunk_size) - (uint32)1U;

    PfeDevAssert((SIZE_MAX - align) >= sizemask);
    uint32 align_temp = (align + sizemask) >> ctx->chunk_size;

    if(0U == align_temp)
    {   /* Prevent division by 0 in case of align = 0 and chunk_size = 0 (1 byte) */
        align_temp = 1U;
    }

    return align_temp;
}

/**
 * @brief Calculate offset of first chunk of the examined area
 * @param[in] ctx Context instance
 * @return First chunk of the examined area
 */
static uint32 calculate_offset(const blalloc_t *ctx)
{
    PfeDevAssert(ctx->start_srch >= (ctx->start_srch % CHUNKS_IN_BYTE));
    uint32 offset = ctx->start_srch - (ctx->start_srch % CHUNKS_IN_BYTE);
    return offset;
}

/**
 * @brief Mark found chunks
 * @param[in] ctx Context instance
 * @param[in] size Size of the memory to be allocated
 * @param[in] offset Starting chunk of the examined area
 * @param[in] count Number of chunks
 */
static inline void chunks_mark(blalloc_t *ctx, const uint32 size, const uint32 offset, const uint32 count)
{
    /* Lock all chunks we have found */
    set_bits(ctx->chunkinfo, offset, count);

    /* Did we use the first known empty chunk */
    if(ctx->start_srch == offset)
    {   /* First known empty chunk is no longer empty */
        /* Start next search following the memory we have provided just now */
        PfeDevAssert((SIZE_MAX - ctx->start_srch) >= count);
        ctx->start_srch += count;
    }

    PfeDevAssert((SIZE_MAX - ctx->allocated) >= (count << ctx->chunk_size));
    ctx->allocated += count << ctx->chunk_size;

    PfeDevAssert((SIZE_MAX - ctx->requested) >= size);
    ctx->requested += size;
}

/*==================================================================================================
                                       GLOBAL FUNCTIONS
==================================================================================================*/
/**
 * @brief Allocates and initializes a context to be used with the other API.
 * Will be removed in AAVB-5861!
 * This function should only be used for the FW heap and the size of the context is fixed according to DMEM heap size, defined in the FW binary.
 * @param[in] size  Size of the memory (should be multiple of chunk_size - cannot provide less than a chunk).
 * @param[in] chunk_size Provided memory smallest size (configured as 2 to power of the provided value)
 * @return pointer to internal context or NULL in case of failure
 */
blalloc_t *blalloc_create(uint32 size, uint32 chunk_size)
{
    blalloc_t *ctx;
    /* Number of bytes needed to store information about all chunks
       Round up to the nearest multiple of N and then divide by N is achieved by ((x + (N-1)) / N) */
    uint_t chunkinfo_size = (uint_t)UDIV32_ROUND_UP((uint64)size >> chunk_size, CHUNKS_IN_BYTE);

    if(0U == (size >> chunk_size))
    {   /* Memory not large enough to contain at least 1 chunk */
        NXP_LOG_ERROR("Size of memory is less than a chunk\n");
        ctx = NULL_PTR;
    }
    else
    {
        if(sizeof(blalloc_create_context_static) < (sizeof(blalloc_t) + chunkinfo_size))
        {
            /* Memory allocation failure - insufficient buffer size */
            NXP_LOG_ERROR("Failed to allocate memory\n");
            ctx = NULL_PTR;
        }
        else
        {
            /* Provide local static context memory for internal structure + array of bytes which will have
               2 bits for each chunk => number of chunks / 4 and then rounded up;
               Number of chunks is equal to size >> chunk_size. */
            ctx = (blalloc_t *)blalloc_create_context_static;
        
            /* Clear the whole context */
            (void)autolibc_memset(ctx, 0, sizeof(blalloc_t));

            /* Remember the input data */
            ctx->size = size;
            ctx->chunk_size = chunk_size;

            /* Init pointer to chunkinfo memory (behind the structure) */
            ctx->chunkinfo = (uint8 *)(ctx + 1U); /* Adds 1 struct size */

            if(EOK != blalloc_init(ctx))
            {
                ctx = NULL_PTR;
            }
            else
            {
                ctx->status = BL_DYNAMIC;
            }
        }
    }
    return ctx;
}

/**
 * @brief Finalize and release block allocator instance
 * @param[in] ctx Context instance
 */
void blalloc_destroy(blalloc_t *ctx)
{
    if (BL_DYNAMIC != ctx->status)
    {
        NXP_LOG_ERROR("Attempt to destroy static instance\n");
    }
    else
    {
        /* If some memory has not been returned it will be leaked */
        blalloc_fini(ctx);
    }
}

/**
 * @brief   Initialize static block allocator instance
 * @param[in] ctx Context instance
 * @return EOK if success, error code otherwise
 */
errno_t blalloc_init(blalloc_t *ctx)
{
    errno_t ret;
    uint_t chunkinfo_size = (uint_t)UDIV32_ROUND_UP((uint64)ctx->size >> ctx->chunk_size, CHUNKS_IN_BYTE);

    if(0U == (ctx->size >> ctx->chunk_size))
    {
        NXP_LOG_ERROR("Size of memory is less than a chunk\n");
        ret = EINVAL;
    }
    else
    {
        oal_mutex_lock(PFE_BLALLOC_MUTEX_00);

        /* Clear the chunkinfo storage */
        (void)autolibc_memset(ctx->chunkinfo, 0, chunkinfo_size);

        ctx->start_srch = 0U;
        ctx->status = BL_STATIC;

        /* Mark dummy chunks at the end (if any) as used to prevent their allocation */
        if(0U != ((ctx->size >> ctx->chunk_size) % CHUNKS_IN_BYTE))
        {
            /* Calculate the remainder after division by CHUNKS_IN_BYTE which are used chunks in the byte
               shift ALL_CHUNKS_USED_LAST to right by the calculated number of used chunks so their positions
               will be replaced by 0s leaving the value only in unused positions */
            const uint_t used_chunks = (uint_t)((((ctx->size >> ctx->chunk_size) % CHUNKS_IN_BYTE) * CHUNK_BITS_COUNT) & (uint_t)UINT8_MAX);
            PfeDevAssert(chunkinfo_size > 0U);
            ctx->chunkinfo[chunkinfo_size - 1U] |= (uint8)(((uint32)ALL_CHUNKS_USED_LAST >> used_chunks) & (uint32)UINT8_MAX);
        }
        oal_mutex_unlock(PFE_BLALLOC_MUTEX_00);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief Finalize block allocator instance
 * @param[in] ctx Context instance
 */
void blalloc_fini(blalloc_t *ctx)
{
    ctx->status = BL_INVALID;
}

/**
 * @brief     Allocates the memory
 * @param[in] ctx Context
 * @param[in] size Size of the memory to be allocated.
 * @param[in] align Required memory alignment; values are rounded toward nearest upper multiple of the chunk size.
 *                  It is expected that only multiples of chunk size are used - rounding is a side effect of
 *                  used algorithm.
 * @param[out] addr Allocated memory offset from the memory base
 * @return EOK on success or ENOMEM on failure.
 */
errno_t blalloc_alloc_offs(blalloc_t *ctx, uint32 size, uint32 align, addr_t *addr)
{
    uint_t i,j;
    uint32 needed; /* Needed number of unused chunks to satisfy the memory request */
    uint32 found;  /* Number of unused chunks in the examined area including the starting one */
    uint32 offset; /* Starting chunk of the examined area */
    uint32 align_temp = align;
    errno_t ret;
    bool_t exit_quick = FALSE;
    const uint_t chunkinfo_size = (uint_t)UDIV32_ROUND_UP((uint64)ctx->size >> ctx->chunk_size, CHUNKS_IN_BYTE);

    needed = chunks_count(ctx, size);
    align_temp = chunks_alignment(ctx, align);
    found = 0U;

    /* Set initial search position */
    offset = calculate_offset(ctx);

    oal_mutex_lock(PFE_BLALLOC_MUTEX_01);
    /* Go through all bytes in ctx->chunkinfo starting from the one containing first known chunk */
    for(i = (ctx->start_srch / CHUNKS_IN_BYTE); i < chunkinfo_size; i++)
    {
        uint8 bits = ctx->chunkinfo[i];
        /* Go through all 2-bits (chunks) in the current byte */
        for(j = 0U; j < CHUNKS_IN_BYTE; j++)
        {
            /* Check if the chunk is in use */
            if(0U == (bits & CHUNK_TEST_MASK))
            {   /* Not in use */
                /* Check alignment if it can be the starting chunk */
                if(0U != (offset % align_temp))
                {   /* This offset would not lead to a needed alignment */

                    /* We increment the offset to try the next one if it is not properly
                       aligned. Note that we do not increment offset in the other branch
                       therefore it remains aligned all the time we are in the "chunk not in use"
                       branch and therefore we are only incrementing the number of found unused
                       chunks once we found the aligned (first) chunk. */
                    offset++;   /* Next chunk could be start */
                    found = 0U; /* We do not have any chunks found */
                }
                else
                {   /* Chunk can be used as a starting one */
                    /* We do not increment the offset therefore it will stay aligned
                       and this branch will be always executed */
                    /* Increment number of unused chunks in a row */
                    found++;
                }
            }
            else
            {   /* Row has ended (if it started before) and we have not reached required number
                   of chunks, start from scratch */
                /* Skip the chunks already examined because the row starting on these chunks
                   cannot be longer - it will also end here */
                PfeDevAssert((SIZE_MAX - offset) >= (found + 1U));
                offset += found + 1U; /* Next chunk could be start */
                found = 0U;           /* We do not have any chunks found */
            }
            /* Do we have enough chunks in the row? */
            if(found == needed)
            {   /* We got the requested size */
                chunks_mark(ctx, size, offset, needed);

                /* Return the chunk offset */
                *addr = offset << ctx->chunk_size;
                ret = EOK;
                exit_quick = TRUE;
                break;
            }
            /* Test the next 2-bit */
            bits <<= CHUNK_BITS_COUNT;
        }
        if(TRUE == exit_quick)
        {
            break;
        }
    }
    if(TRUE != exit_quick)
    {
        /* Failed */
        NXP_LOG_ERROR("Allocation of %u bytes aligned at %u chunks failed\n",(uint_t)size,(uint_t)align_temp);
        ret = ENOMEM;
    }
    /* Do not forget to unlock spinlock */
    oal_mutex_unlock(PFE_BLALLOC_MUTEX_01);
    return ret;
}

/**
 * @brief Deallocates the memory previously allocated by blalloc_alloc_offs
 * @param[in] ctx Context
 * @param[in] offset Memory offset as returned by the allocation function
 */
void blalloc_free_offs(blalloc_t *ctx, addr_t offset)
{
    uint_t first_chunk = offset >> ctx->chunk_size;
    uint_t first_byte = (first_chunk) / CHUNKS_IN_BYTE;
    uint_t max_byte = (uint_t)UDIV32_ROUND_UP((uint64)ctx->size >> ctx->chunk_size, CHUNKS_IN_BYTE);

    /* How many chunk records to skip in the 1st byte */
    uint_t first_shift = first_chunk % CHUNKS_IN_BYTE;
    uint_t count = 0U;
    uint8 byte;
    uint8 chunk;
    uint_t i,j;
    bool_t exit_quick = FALSE;

    /* Check if chunk is free already or not */
    byte = ctx->chunkinfo[first_byte];
    chunk = (uint8)(((uint32)byte << (first_shift * CHUNK_BITS_COUNT)) & CHUNK_TEST_MASK);
    if(chunk == 0x0U)
    {
        NXP_LOG_WARNING("blalloc_free_offs called on an already empty area\n");
    }
    else
    {
        oal_mutex_lock(PFE_BLALLOC_MUTEX_03);
        if((ctx->start_srch) > first_chunk)
        {   /* We have new first known empty chunk, remember it */
            ctx->start_srch = first_chunk;
        }

        for(i = first_byte; i < max_byte; i++)
        {
            byte = ctx->chunkinfo[i];
            for(j = first_shift; j < CHUNKS_IN_BYTE; j++)
            {
                /* Count the chunks tested */
                PfeDevAssert(SIZE_MAX > count);
                count++;
                /* Get the chunk bits to the position for testing (most left) */
                chunk = (uint8)(((uint32)byte << (j * CHUNK_BITS_COUNT)) & CHUNK_TEST_MASK);
                /* Test the chunk bits */
                if((LAST_USED_CHUNK << CHUNK_TEST_SHIFT) == chunk)
                {   /* This is the last chunk */
                    clear_bits(ctx->chunkinfo, first_chunk, count);
                    exit_quick = TRUE;
                    break;
                }
                /* If needed we could add some checks here */
            }
            if(TRUE == exit_quick)
            {
                break;
            }
            /* From the 1st iteration we do not need initial shift -
               it may be valid only for the first byte */
            first_shift = 0U;
        }
        if(FALSE == exit_quick)
        {
            /* We should never get here */
            NXP_LOG_ERROR("Internal memory corrupted\n");
        }
    }
    oal_mutex_unlock(PFE_BLALLOC_MUTEX_03);
}

#if defined(PFE_CFG_TEXT_STATS)
/**
* @brief Reads the memory usage statistics in a text form
* @param[in] ctx Context
* @param[out] buf Output text buffer
* @param[in] buf_len Size of the output text buffer
* @param[in] verb_level Verbosity lever
* @return Number of characters written into the buffer.
*/
uint32 blalloc_get_text_statistics(const blalloc_t *ctx, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint_t i, j;               /* Counters */
    uint_t prev = 0U;          /* Did the used chunk precede this chunk? 1 = yes */
    uint_t unused_chunks = 0U; /* Count of used chunks */
    uint_t used_chunks = 0U;   /* Count of unused chunks */
    uint_t fragments = 0U;     /* Count of holes between chunks */
    uint32 len = 0U;         /* Number of characters written into the buf */
    uint_t byte_count = ((ctx->size >> ctx->chunk_size) + 3U) >> 2U;

    /* Go through all bytes in chunkinfo */
    for(i = 0U; i < byte_count; i++)
    {
        uint8 bits = ctx->chunkinfo[i];

        if(verb_level > 0U)
        {   /* Detailed information requested */
            /* After each 32 bytes (and at start) print out a new line and address */
            if(0U == (i % 32U))
            {
                len += oal_util_snprintf(buf + len, buf_len - len, "\n0x%05x: ", i * 4U * (1U << ctx->chunk_size));
            }
            /* Print current chunkinfo byte */
            len += oal_util_snprintf(buf + len, buf_len - len, "%02x", bits);
        }

        /* Go through all 2-bits in the current byte */
        for(j = 0U; j < CHUNKS_IN_BYTE; j++)
        {
            if(0U == (bits & CHUNK_TEST_MASK))
            {   /* Chunk not in use */
                unused_chunks++;
                if(prev != 0U)
                {   /* Previous chunk was in use */
                    fragments++; /* Increment number of holes between chunks */
                }
                prev = 0U;
            }
            else
            {   /* Chunk in use */
                used_chunks++;
                prev = 1U;
            }
            /* Check the next 2-bit */
            bits <<= CHUNK_BITS_COUNT;
        }
    }
    /* Print out the information */
    len += oal_util_snprintf(buf + len, buf_len - len, "\n"); /* End previous output */
    len += oal_util_snprintf(buf + len, buf_len - len, "Free  memory %u bytes (%u chunks)\n", unused_chunks * ((uint_t)1U << ctx->chunk_size), unused_chunks);
    len += oal_util_snprintf(buf + len, buf_len - len, "Used  memory %u bytes (%u chunks)\n", used_chunks * ((uint_t)1U << ctx->chunk_size), used_chunks);
    len += oal_util_snprintf(buf + len, buf_len - len, "Total memory %u bytes (%u chunks)\n", (uint_t)ctx->size, byte_count * CHUNKS_IN_BYTE);
    len += oal_util_snprintf(buf + len, buf_len - len, "Chunk size   %u bytes\n", (1U << ctx->chunk_size));
    len += oal_util_snprintf(buf + len, buf_len - len, "Fragments    %u\n", fragments);
    len += oal_util_snprintf(buf + len, buf_len - len, "Dummy chunks %u\n", (uint_t)((byte_count * CHUNKS_IN_BYTE) - (ctx->size >> ctx->chunk_size)));
    if(verb_level > 0U)
    {   /* Detailed information requested */
        len += oal_util_snprintf(buf + len, buf_len - len, "1st free chunk  %u\n", (uint_t)ctx->start_srch);
        len += oal_util_snprintf(buf + len, buf_len - len, "Bytes requested %u (cumulative)\n", (uint_t)ctx->requested);
        len += oal_util_snprintf(buf + len, buf_len - len, "Bytes allocated %u (cumulative)\n", (uint_t)ctx->allocated);
    }
    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [106/185]: src\elf.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup dxgr_ELF
 * @{
 *
 * @file            elf.c
 * @version         0.0.0.0
 *
 * @brief           The ELF module. Module for loading executable ELF files.
 *
 */
/*==================================================================================================
==================================================================================================*/

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==================================================================================================
                                         MISRA VIOLATIONS
==================================================================================================*/

/*==================================================================================================
                                         INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==================================================================================================*/

#include "pfe_cfg.h"
#include "oal.h"

#include "elf_cfg.h"
#include "elf.h"

#include "hal.h"

/*==================================================================================================
                                      FILE VERSION CHECKS
==================================================================================================*/
#if (FALSE == ELF_CFG_ELF64_SUPPORTED) && (FALSE == ELF_CFG_ELF32_SUPPORTED)
    #error Either ELF32, ELF64, or both must be enabled.
#endif

/*==================================================================================================
                                        LOCAL MACROS
==================================================================================================*/
#define ELF64_HEADER_SIZE 64U
#define ELF32_HEADER_SIZE 52U
#define SHN_UNDEF       0U    /* Undefined/Not present */

/*==================================================================================================
                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/
enum
{
    ELF_Type_Relocatable = 1U,
    ELF_Type_Executable = 2U,
    ELF_Type_Shared = 3U,
    ELF_Type_Core = 4U,
};

enum
{
    PT_NULL      = 0U,
    PT_LOAD      = 1U, /* Loadable segment */
    PT_DYNAMIC   = 2U,
    PT_INTERP    = 3U,
    PT_NOTE      = 4U,
    PT_SHLIB     = 5U,
    PT_PHDR      = 6U,
    PT_LOPROC    = 7U,
    PT_HIPROC    = 8U,
    PT_GNU_STACK = 9U,
};

/*==================================================================================================
                                       LOCAL CONSTANTS
==================================================================================================*/
#if TRUE == ELF_CFG_SECTION_PRINT_ENABLED
  #ifdef NXP_LOG_ENABLED /*  Debug message support */

    #if TRUE == ELF_CFG_SECTION_TABLE_USED

    #define ETH_43_PFE_START_SEC_CONST_8
    #include "Eth_43_PFE_MemMap.h"

    static const sint8 aacSTypes[17][9] =
    {
        "NULL    ",
        "PROGBITS",
        "SYMTAB  ",
        "STRTAB  ",
        "RELA    ",
        "HASH    ",
        "DYNAMIC ",
        "NOTE    ",
        "NOBITS  ",
        "REL     ",
        "SHLIB   ",
        "DYNSYM  ",
        "LOPROC  ",
        "HIPROC  ",
        "LOUSER  ",
        "HIUSER  ",
        "UNDEFINE",
    };

    #define ETH_43_PFE_STOP_SEC_CONST_8
    #include "Eth_43_PFE_MemMap.h"
    #define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
    #include "Eth_43_PFE_MemMap.h"

    static const struct shf_flags_strings
    {
        uint32 u32Flag;
        char_t   *szString;
    } ShT_Flags_Strings[] =
    {
        {0x1U,       "WRITE"},
        {0x2U,       "ALLOC"},
        {0x4U,       "EXECINSTR"},
        {0x10U,      "MERGE"},
        {0x20U,      "STRINGS"},
        {0x40U,      "INFO_LINK"},
        {0x80U,      "LINK_ORDER"},
        {0x100U,     "OS_NONCONFORMING"},
        {0x200U,     "GROUP"},
        {0x400U,     "TLS"},
        {0x0ff00000U,"MASKOS"},
        {0xf0000000U,"MASKPROC"},
        {0x4000000U, "ORDERED"},
        {0x8000000U, "EXCLUDE"},
    };

    #define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
    #include "Eth_43_PFE_MemMap.h"
    #define ETH_43_PFE_START_SEC_CONST_32
    #include "Eth_43_PFE_MemMap.h"

    static const uint32 u32ShT_Flags_Strings_Count = sizeof(ShT_Flags_Strings) / sizeof(struct shf_flags_strings);

    #define ETH_43_PFE_STOP_SEC_CONST_32
    #include "Eth_43_PFE_MemMap.h"

    #endif /* ELF_CFG_SECTION_TABLE_USED */
    #if TRUE == ELF_CFG_PROGRAM_TABLE_USED

    #define ETH_43_PFE_START_SEC_CONST_8
    #include "Eth_43_PFE_MemMap.h"

    static const sint8 aacPTypes[11][10] =
    {
        "NULL     ",
        "LOAD     ",
        "DYNAMIC  ",
        "INTERP   ",
        "NOTE     ",
        "SHLIB    ",
        "PHDR     ",
        "LOPROC   ",
        "HIPROC   ",
        "GNU_STACK",
        "UNDEFINED",
    };

    #define ETH_43_PFE_STOP_SEC_CONST_8
    #include "Eth_43_PFE_MemMap.h"

    #endif /* ELF_CFG_PROGRAM_TABLE_USED */
  #endif /* NXP_LOG_ENABLED */
#endif /* ELF_CFG_SECTION_PRINT_ENABLED */

/*==================================================================================================
                                       LOCAL VARIABLES
==================================================================================================*/

/*==================================================================================================
                                       GLOBAL CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       GLOBAL VARIABLES
==================================================================================================*/

/*==================================================================================================
                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* GENERAL */
static bool_t LoadFileData(const ELF_File_t *pElfFile, uint32 u32Offset, uint32 u32Size, void *pvDestMem);
static bool_t CheckElfVersion(ELF_File_t *pElfFile);
/* ELF64 */
#if TRUE == ELF_CFG_ELF64_SUPPORTED
    static bool_t ELF64_LoadTables(ELF_File_t *pElfFile);
    static void ELF64_HeaderSwitchEndianness(Elf64_Ehdr *prElf64Header);
    static bool_t ELF64_Load(ELF_File_t *pElfFile,uint32 *u32NamesSectionOffset,uint32 *u32NamesSectionSize);

    #if TRUE == ELF_CFG_PROGRAM_TABLE_USED
        static bool_t ELF64_ProgSectFindNext( ELF_File_t *pElfFile, uint32 *pu32ProgIdx,
                                               uint64 *pu64LoadVAddr, uint64 *pu64LoadPAddr, uint64 *pu64Length
                                             );
        static bool_t ELF64_ProgSectLoad( const ELF_File_t *pElfFile,
                                           uint32 u32ProgIdx, addr_t AccessAddr, addr_t AllocSize
                                         );
    #endif
    #if TRUE == ELF_CFG_SECTION_TABLE_USED
        static bool_t ELF64_SectFindName( const ELF_File_t *pElfFile, const char_t *szSectionName,
                                           uint32 *pu32SectIdx, uint64 *pu64LoadAddr, uint64 *pu64Length
                                         );
        static bool_t ELF64_SectLoad( const ELF_File_t *pElfFile,
                                       uint32 u32SectIdx, addr_t AccessAddr, addr_t AllocSize
                                     );
    #endif
    #if TRUE == ELF_CFG_SECTION_PRINT_ENABLED
        static void ELF64_PrintSections(const ELF_File_t *pElfFile);
    #endif /* ELF_CFG_SECTION_PRINT_ENABLED */
#endif /* ELF_CFG_ELF64_SUPPORTED */
/* ELF32 */
#if TRUE == ELF_CFG_ELF32_SUPPORTED
    static bool_t ELF32_LoadTables(ELF_File_t *pElfFile);
    static void ELF32_HeaderSwitchEndianness(Elf32_Ehdr *prElf32Header);
    static bool_t ELF32_Load(ELF_File_t *pElfFile,uint32 *u32NamesSectionOffset,uint32 *u32NamesSectionSize);

    #if TRUE == ELF_CFG_PROGRAM_TABLE_USED
        static bool_t ELF32_ProgSectFindNext( ELF_File_t *pElfFile, uint32 *pu32ProgIdx,
                                               uint64 *pu64LoadVAddr, uint64 *pu64LoadPAddr, uint64 *pu64Length
                                             );
        static bool_t ELF32_ProgSectLoadActual(const ELF_File_t *pElfFile, uint32 u32ProgIdx, addr_t AccessAddr);
        static bool_t ELF32_ProgSectLoad( const ELF_File_t *pElfFile,
                                           uint32 u32ProgIdx, addr_t AccessAddr, addr_t AllocSize
                                         );
    #endif
    #if TRUE == ELF_CFG_SECTION_TABLE_USED
        static bool_t ELF32_SectFindName( const ELF_File_t *pElfFile, const char_t *szSectionName,
                                           uint32 *pu32SectIdx, uint64 *pu64LoadAddr, uint64 *pu64Length
                                         );
        static bool_t ELF32_SectLoad( const ELF_File_t *pElfFile,
                                       uint32 u32SectIdx, addr_t AccessAddr, addr_t AllocSize
                                     );
    #endif
    #if TRUE == ELF_CFG_SECTION_PRINT_ENABLED
        static void ELF32_PrintSections(const ELF_File_t *pElfFile);
    #endif /* ELF_CFG_SECTION_PRINT_ENABLED */
#endif /* ELF_CFG_ELF32_SUPPORTED */

static uint32 buf_read(const void *src_buf, uint32 u32Offset, void *dst_buf, uint32 nbytes);
static void ELF_FreePtr(ELF_File_t *pElfFile);
static bool_t ELF_LoadTables(ELF_File_t *pElfFile, uint32 *u32NamesSectionOffset, uint32 *u32NamesSectionSize);

/*==================================================================================================
                                       LOCAL FUNCTIONS
==================================================================================================*/
/*================================================================================================*/
/**
* @brief        Purpose of this function is to implement the operations and checks only once.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @param[in]    u32Offset Offset within file.
* @param[in]    u32Size Number of bytes to load.
* @param[out]   pvDestMem Data from file are written here.
* @retval       TRUE Succeeded
* @retval       FALSE Failed
*/
/* Purpose of this function is to implement all the operations and checks only once */
static bool_t LoadFileData(const ELF_File_t *pElfFile, uint32 u32Offset, uint32 u32Size, void *pvDestMem)
{
    bool_t bSuccess = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pElfFile) || (NULL == pvDestMem)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bSuccess = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (u32Size != buf_read(pElfFile->pvData, u32Offset, pvDestMem, u32Size))
        {
            NXP_LOG_ERROR("LoadFileData: Reading program header failed\n");
        }
        /* DONE */
        else
        {
            bSuccess = TRUE;
        }
    }
    return bSuccess;
}

/*================================================================================================*/
/**
* @brief        Purpose of this function is to check elf file version format.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @retval       TRUE Succeeded
* @retval       FALSE Failed
*/
static bool_t CheckElfVersion(ELF_File_t *pElfFile)
{
    return (TRUE == ((0x7FU  != pElfFile->Header.e_ident[EI_MAG0]) ||
            ((uint8)'E' != pElfFile->Header.e_ident[EI_MAG1]) ||
            ((uint8)'L' != pElfFile->Header.e_ident[EI_MAG2]) ||
            ((uint8)'F' != pElfFile->Header.e_ident[EI_MAG3]) ||
            (1U           != pElfFile->Header.e_ident[EI_VERSION]))) ? FALSE: TRUE;
}

#if TRUE == ELF_CFG_ELF32_SUPPORTED
/*================================================================================================*/
static bool_t ELF32_LoadTables(ELF_File_t *pElfFile)
{
    bool_t bProgStatus = TRUE;
    bool_t bSectStatus = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pElfFile))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bSectStatus = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
  #if TRUE == ELF_CFG_PROGRAM_TABLE_USED
        bProgStatus = FALSE;
        /* === Load program header from file ============================================ */
        /* Check integrity */
        if(sizeof(Elf32_Phdr) != pElfFile->Header.r32.e_phentsize)
        {
            NXP_LOG_ERROR("ELF32_LoadTables: Unexpected progam header entry size\n");
        }
        /* All checkes passed */
        else
        {
            /* Save the pointer */
            pElfFile->arProgHead32 = (Elf32_Phdr *)(((uint8*)pElfFile->pvData) + pElfFile->Header.r32.e_phoff);
            bProgStatus = TRUE;
        }
  #endif /* ELF_CFG_PROGRAM_TABLE_USED */
  #if TRUE == ELF_CFG_SECTION_TABLE_USED
#endif

#if TRUE == ELF_CFG_SECTION_TABLE_USED
        /* === Load section header from file ============================================ */
        if (FALSE == bProgStatus)
        {
            ; /* Loading the other table failed, this will abort. */
        }
        /* Check integrity */
        else if (sizeof(Elf32_Shdr) != pElfFile->Header.r32.e_shentsize)
        {
            NXP_LOG_ERROR("ELF32_LoadTables: Unexpected section header entry size\n");
        }
        else /* All checkes passed */
        {
            /* Save the pointer */
            pElfFile->arSectHead32 = (Elf32_Shdr *)(((uint8*)pElfFile->pvData) + pElfFile->Header.r32.e_shoff);
            bSectStatus = TRUE;
        }
  #else /* ELF_CFG_SECTION_TABLE_USED */
        bSectStatus = bProgStatus;
  #endif /* ELF_CFG_SECTION_TABLE_USED */
    }
    return bSectStatus;
}

/*================================================================================================*/
static void ELF32_HeaderSwitchEndianness(Elf32_Ehdr *prElf32Header)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == prElf32Header))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        prElf32Header->e_type       = ENDIAN_SW_2B(prElf32Header->e_type);
        prElf32Header->e_machine    = ENDIAN_SW_2B(prElf32Header->e_machine);
        prElf32Header->e_version    = ENDIAN_SW_4B(prElf32Header->e_version);
        prElf32Header->e_entry      = ENDIAN_SW_4B(prElf32Header->e_entry);
        prElf32Header->e_phoff      = ENDIAN_SW_4B(prElf32Header->e_phoff);
        prElf32Header->e_shoff      = ENDIAN_SW_4B(prElf32Header->e_shoff);
        prElf32Header->e_flags      = ENDIAN_SW_4B(prElf32Header->e_flags);
        prElf32Header->e_ehsize     = ENDIAN_SW_2B(prElf32Header->e_ehsize);
        prElf32Header->e_phentsize  = ENDIAN_SW_2B(prElf32Header->e_phentsize);
        prElf32Header->e_phnum      = ENDIAN_SW_2B(prElf32Header->e_phnum);
        prElf32Header->e_shentsize  = ENDIAN_SW_2B(prElf32Header->e_shentsize);
        prElf32Header->e_shnum      = ENDIAN_SW_2B(prElf32Header->e_shnum);
        prElf32Header->e_shstrndx   = ENDIAN_SW_2B(prElf32Header->e_shstrndx);
    }
}

static bool_t ELF32_Load(ELF_File_t *pElfFile,uint32 *u32NamesSectionOffset,uint32 *u32NamesSectionSize)
{
    bool_t    bRetVal = FALSE;

    ELF32_HeaderSwitchEndianness(&(pElfFile->Header.r32));

    if ((uint16)ELF_Type_Executable != pElfFile->Header.r32.e_type)
    {
        NXP_LOG_ERROR("ELF_Open: Only executable ELFs are supported\n");
    }
    else if (FALSE == ELF32_LoadTables(pElfFile))
    {
        NXP_LOG_ERROR("ELF_Open: Failed to load tables\n");
    }
    else
#if TRUE == ELF_CFG_SECTION_TABLE_USED
    {
        /* Look for section names section */
        if ((pElfFile->Header.r32.e_shstrndx == SHN_UNDEF)
            || (pElfFile->Header.r32.e_shstrndx >= pElfFile->Header.r32.e_shnum)
            || (0U == ENDIAN_SW_4B(pElfFile->arSectHead32[pElfFile->Header.r32.e_shstrndx].sh_size))
            )
        {
            NXP_LOG_ERROR("ELF_Open: Section names not found\n");
        }
        else
        {

            *u32NamesSectionOffset = ENDIAN_SW_4B(pElfFile->arSectHead32[pElfFile->Header.r32.e_shstrndx].sh_offset);
            *u32NamesSectionSize = ENDIAN_SW_4B(pElfFile->arSectHead32[pElfFile->Header.r32.e_shstrndx].sh_size);
            bRetVal = TRUE;
        }
    }
#else  /* ELF_CFG_SECTION_TABLE_USED */
    {
        bRetVal = TRUE;
    }
#endif /* ELF_CFG_SECTION_TABLE_USED */

    return bRetVal;
}

  #if TRUE == ELF_CFG_PROGRAM_TABLE_USED
/*================================================================================================*/
static bool_t ELF32_ProgSectFindNext( ELF_File_t *pElfFile, uint32 *pu32ProgIdx,
                                       uint64 *pu64LoadVAddr, uint64 *pu64LoadPAddr, uint64 *pu64Length
                                     )
{
    bool_t bRetVal = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* Check prerequisities */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arProgHead32)))
    {
        NXP_LOG_ERROR("ELF32_ProgSectFindNext: Failed - elf not opened!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Find a record having RAM area */
        while (pElfFile->u32ProgScanIdx < pElfFile->Header.r32.e_phnum)
        {
            if (((uint32)PT_LOAD == ENDIAN_SW_4B(pElfFile->arProgHead32[pElfFile->u32ProgScanIdx].p_type)) /* Has RAM area */
                && (0U != ENDIAN_SW_4B(pElfFile->arProgHead32[pElfFile->u32ProgScanIdx].p_memsz))      /* Size != 0 */
                )
            {   /* Match found */
                /* Set returned values */
                if (NULL != pu32ProgIdx)
                {
                    *pu32ProgIdx = pElfFile->u32ProgScanIdx;
                }
                if (NULL != pu64LoadVAddr)
                {
                    *pu64LoadVAddr = ENDIAN_SW_4B((uint64)pElfFile->arProgHead32[pElfFile->u32ProgScanIdx].p_vaddr);
                }
                if (NULL != pu64LoadPAddr)
                {
                    *pu64LoadPAddr = ENDIAN_SW_4B((uint64)pElfFile->arProgHead32[pElfFile->u32ProgScanIdx].p_paddr);
                }
                if (NULL != pu64Length)
                {
                    *pu64Length = ENDIAN_SW_4B((uint64)pElfFile->arProgHead32[pElfFile->u32ProgScanIdx].p_memsz);
                }
                bRetVal = TRUE;
                pElfFile->u32ProgScanIdx++;
                break;
            }
            else
            {
                pElfFile->u32ProgScanIdx++;
            }
        }
    }

    return bRetVal;
}

/*================================================================================================*/
static bool_t ELF32_ProgSectLoadActual(const ELF_File_t *pElfFile, uint32 u32ProgIdx, addr_t AccessAddr)
{
    bool_t bSuccess = FALSE;

    /* p_filesz bytes of data at the beginning of the memory area shall be copied from file
       the rest up to p_memsz bytes shal be set to 0
    */
    if (0U != ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_filesz))
    {   /* Read from file */
        if (FALSE == LoadFileData(pElfFile, /* pElfFile, */
            ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_offset), /* u32Offset, */
            ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_filesz), /* u32Size, */
            (void *)AccessAddr /* pvDestMem */
        )
            )
        {
            NXP_LOG_ERROR("ELF32_ProgSectLoad: Failed to load section from file\n");
        }
        else
        {   /* Reading done */
            bSuccess = TRUE;
        }
    }
    else
    {   /* Reading skipped */
        bSuccess = TRUE;
    }

    /* Pad rest with zeros */
    if ((TRUE == bSuccess)
     && (ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_memsz) > ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_filesz))
        )
    {
        (void)autolibc_memset((void *)(AccessAddr + ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_filesz)),
                0,
                ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_memsz) - ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_filesz)
              );
    }

    return bSuccess;
}

/*================================================================================================*/
static bool_t ELF32_ProgSectLoad(const ELF_File_t *pElfFile, uint32 u32ProgIdx,
                                   addr_t AccessAddr, addr_t AllocSize
                                 )
{
    bool_t bSuccess = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* CHECK */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arProgHead32)))
    {
        NXP_LOG_ERROR("ELF32_ProgSectLoad: Failed - elf not loaded!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    if (u32ProgIdx >= pElfFile->Header.r32.e_phnum)
    {
        NXP_LOG_ERROR("ELF32_ProgSectLoad: Invalid program index: %u\n", (uint_t)u32ProgIdx);
    }
    else if ((uint32)PT_LOAD != ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_type))
    {
        NXP_LOG_ERROR("ELF32_ProgSectLoad: This section has no associated RAM area\n");
    }
    else if (AllocSize < ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_memsz))
    {
        NXP_LOG_ERROR("ELF32_ProgSectLoad: Section does not fit to allocated memory\n");
    }
    else if (ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_filesz) > ENDIAN_SW_4B(pElfFile->arProgHead32[u32ProgIdx].p_memsz))
    {
        NXP_LOG_ERROR("ELF32_ProgSectLoad: Section size mismatch.\n");
    }
    /* LOAD */
    else
    {   /* All OK */
        bSuccess = ELF32_ProgSectLoadActual(pElfFile, u32ProgIdx, AccessAddr);
    }
    return bSuccess;
}
  #endif /* ELF_CFG_PROGRAM_TABLE_USED */

  #if TRUE == ELF_CFG_SECTION_TABLE_USED

/*================================================================================================*/
static bool_t ELF32_SectFindName( const ELF_File_t *pElfFile, const char_t *szSectionName,
                                   uint32 *pu32SectIdx, uint64 *pu64LoadAddr, uint64 *pu64Length
                                 )
{
    bool_t bRetVal = FALSE;
    bool_t bFound = FALSE;
    uint32 SectIdx;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* Check prerequisites */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arSectHead32) || (NULL == pElfFile->acSectNames)))
    {
        NXP_LOG_ERROR("ELF32_SectFindName: Failed - elf not opened!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Search section table */
        for (SectIdx = 0U; SectIdx < pElfFile->Header.r32.e_shnum; SectIdx++)
        {
            if (0 == autolibc_strcmp((char_t *)(pElfFile->acSectNames + ENDIAN_SW_4B(pElfFile->arSectHead32[SectIdx].sh_name)), szSectionName))
            {   /* Found */
                if (NULL != pu32SectIdx)
                {
                    *pu32SectIdx = SectIdx;
                }
                if (NULL != pu64Length)
                {
                    *pu64Length = ENDIAN_SW_4B((uint64)pElfFile->arSectHead32[SectIdx].sh_size);
                }
                if (NULL != pu64LoadAddr)
                {
                    *pu64LoadAddr = ENDIAN_SW_4B((uint64)pElfFile->arSectHead32[SectIdx].sh_addr);
                }
                bFound = TRUE;
                bRetVal = TRUE;
                break;
            }
        }
        if (FALSE == bFound)
        {
            NXP_LOG_INFO("ELF32_SectFindName: Section %s not found\n", szSectionName);
        }
    }

    return bRetVal;
}

/*================================================================================================*/
static bool_t ELF32_SectLoad(const ELF_File_t *pElfFile, uint32 u32SectIdx, addr_t AccessAddr, addr_t AllocSize)
{
    bool_t bSuccess = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* CHECK */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arSectHead32)))
    {
        NXP_LOG_ERROR("ELF32_SectLoad: Failed - elf not loaded!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    if (u32SectIdx >= pElfFile->Header.r32.e_shnum)
    {
        NXP_LOG_ERROR("ELF32_SectLoad: Invalid section index: %u\n", (uint_t)u32SectIdx);
    }
    else if (AllocSize < ENDIAN_SW_4B(pElfFile->arSectHead32[u32SectIdx].sh_size))
    {
        NXP_LOG_ERROR("ELF32_SectLoad: Section does not fit to allocated memory\n");
    }
    /* LOAD */
    else
    {   /* All OK */
        if ((uint32)SHT_NOBITS == ENDIAN_SW_4B(pElfFile->arSectHead32[u32SectIdx].sh_type))
        {   /* Fill with zeros */
            (void)autolibc_memset((void *)AccessAddr, 0, ENDIAN_SW_4B(pElfFile->arSectHead32[u32SectIdx].sh_size));
            bSuccess = TRUE;
        }
        else
        {   /* Copy from file */
            if (FALSE == LoadFileData(pElfFile, /* pElfFile, */
                                      ENDIAN_SW_4B(pElfFile->arSectHead32[u32SectIdx].sh_offset), /* u32Offset, */
                                      ENDIAN_SW_4B(pElfFile->arSectHead32[u32SectIdx].sh_size), /* u32Size, */
                                      (void *)AccessAddr /* pvDestMem */
                                      )
            )
            {
                NXP_LOG_ERROR("ELF32_SectLoad: Failed to load section from file\n");
            }
            else
            {   /* Reading done */
                bSuccess = TRUE;
            }
        }
    }
    return bSuccess;
}
  #endif /* ELF_CFG_SECTION_TABLE_USED */
  #if TRUE == ELF_CFG_SECTION_PRINT_ENABLED

/*================================================================================================*/
static void ELF32_PrintSections(const ELF_File_t *pElfFile)
{
#ifdef NXP_LOG_ENABLED /*  Debug message support */
    uint32 SectIdx;
    uint32 ProgIdx;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* Check prerequisities */
    if ((NULL == pElfFile)
  #if TRUE == ELF_CFG_SECTION_TABLE_USED
     || (NULL == pElfFile->arSectHead32)
     || (NULL == pElfFile->acSectNames)
  #endif /* ELF_CFG_SECTION_TABLE_USED */
  #if TRUE == ELF_CFG_PROGRAM_TABLE_USED
     || (NULL == pElfFile->arProgHead32)
  #endif /* ELF_CFG_PROGRAM_TABLE_USED */
      )
    {
        NXP_LOG_ERROR("NXP_LOG_INFOSections: Failed - elf not opened!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if TRUE == ELF_CFG_SECTION_TABLE_USED
        /* Search section table */
        NXP_LOG_INFO("\n");
        NXP_LOG_INFO("File contains %hu sections:\n", pElfFile->Header.r32.e_shnum);
        NXP_LOG_INFO("     SectionName    Type        FileOffset    FileSize      LoadAddress   Flags\n");
        for (SectIdx = 0U; SectIdx < pElfFile->Header.r32.e_shnum; SectIdx++)
        {
            uint32 u32Type = ENDIAN_SW_4B(pElfFile->arSectHead32[SectIdx].sh_type);
            uint32 u32FlagIdx;

            if (u32Type >= 16U)
            {
                u32Type = 16U; /* Undefined */
            }
            NXP_LOG_INFO("%16s", pElfFile->acSectNames + ENDIAN_SW_4B(pElfFile->arSectHead32[SectIdx].sh_name));
            NXP_LOG_INFO("%12s    0x%08x    0x%08x    0x%08x    ",
                        aacSTypes[u32Type],
                        (uint_t)ENDIAN_SW_4B(pElfFile->arSectHead32[SectIdx].sh_offset),
                        (uint_t)ENDIAN_SW_4B(pElfFile->arSectHead32[SectIdx].sh_size),
                        (uint_t)ENDIAN_SW_4B(pElfFile->arSectHead32[SectIdx].sh_addr)
                      );
            /* Now print flags on separate line: */
            for (u32FlagIdx = 0U; u32FlagIdx<u32ShT_Flags_Strings_Count; u32FlagIdx++)
            {
                if (0U != (ShT_Flags_Strings[u32FlagIdx].u32Flag & ENDIAN_SW_4B(pElfFile->arSectHead32[SectIdx].sh_flags)))
                {
                    NXP_LOG_INFO("%s, ", ShT_Flags_Strings[u32FlagIdx].szString);
                }
            }
            NXP_LOG_INFO("\n");
        }
#endif /* ELF_CFG_SECTION_TABLE_USED */
#if TRUE == ELF_CFG_PROGRAM_TABLE_USED
        /* Search program table */
        NXP_LOG_INFO("\n");
        NXP_LOG_INFO("File contains %hu program sections:\n", pElfFile->Header.r32.e_phnum);
        NXP_LOG_INFO("Idx Type        FileOffset         FileSize           "
                   "LoadVirtAddress    LoadPhysAddress    MemorySize         \n"
                  );
        for (ProgIdx = 0U; ProgIdx < pElfFile->Header.r32.e_phnum; ProgIdx++)
        {
            /* Try to find the name of the section in section header */
            uint32 u32Type = ENDIAN_SW_4B(pElfFile->arProgHead32[ProgIdx].p_type);

            if (u32Type >= 10U)
            {
                u32Type = 10U; /* Undefined */
            }

            /* Print program header data */
            NXP_LOG_INFO("%3u %s   0x%08x         0x%08x         0x%08x         0x%08x         0x%08x",
                        (uint_t)ProgIdx,
                        aacPTypes[u32Type],
                        (uint_t)ENDIAN_SW_4B(pElfFile->arProgHead32[ProgIdx].p_offset),
                        (uint_t)ENDIAN_SW_4B(pElfFile->arProgHead32[ProgIdx].p_filesz),
                        (uint_t)ENDIAN_SW_4B(pElfFile->arProgHead32[ProgIdx].p_vaddr),
                        (uint_t)ENDIAN_SW_4B(pElfFile->arProgHead32[ProgIdx].p_paddr),
                        (uint_t)ENDIAN_SW_4B(pElfFile->arProgHead32[ProgIdx].p_memsz)
                      );
            NXP_LOG_INFO("\n");
        }
#endif /* ELF_CFG_PROGRAM_TABLE_USED */
        NXP_LOG_INFO("\n");
    }
#else
    /* Do nothing */
    (void)pElfFile;
#endif /* NXP_LOG_ENABLED */

}
  #endif /* ELF_CFG_SECTION_PRINT_ENABLED */
#endif /* ELF_CFG_ELF32_SUPPORTED */

#if TRUE == ELF_CFG_ELF64_SUPPORTED
/*================================================================================================*/
static bool_t ELF64_LoadTables(ELF_File_t *pElfFile)
{
    bool_t bProgStatus = TRUE;
    bool_t bSectStatus = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pElfFile))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bSectStatus = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
  #if TRUE == ELF_CFG_PROGRAM_TABLE_USED
        bProgStatus = FALSE;
        /* === Load program header from file ============================================ */
        /* Check integrity */
        if (sizeof(Elf64_Phdr) != pElfFile->Header.r64.e_phentsize)
        {
            NXP_LOG_ERROR("ELF64_LoadTables: Unexpected program header entry size\n");
        }
        else /* All checks passed */
        {
            /* Save the pointer */
            pElfFile->arProgHead64 = (Elf64_Phdr *)(((uint8*)pElfFile->pvData) + pElfFile->Header.r64.e_phoff);
            bProgStatus = TRUE;
        }
  #endif /* ELF_CFG_PROGRAM_TABLE_USED */
  #if TRUE == ELF_CFG_SECTION_TABLE_USED
        /* === Load section header from file ============================================ */
        if (FALSE == bProgStatus)
        {
            ; /* Loading the other table failed, this will abort. */
        }
        /* Check integrity */
        else if (sizeof(Elf64_Shdr) != pElfFile->Header.r64.e_shentsize)
        {
            NXP_LOG_ERROR("ELF64_LoadTables: Unexpected section header entry size\n");
        }
        else /* All checks passed */
        {
            /* Save the pointer */
            pElfFile->arSectHead64 = (Elf64_Shdr *)(((uint8*)pElfFile->pvData) + pElfFile->Header.r64.e_shoff);
            bSectStatus = TRUE;
        }
  #else /* ELF_CFG_SECTION_TABLE_USED */
        bSectStatus = bProgStatus;
  #endif /* ELF_CFG_SECTION_TABLE_USED */
    }
    return bSectStatus;
}

/*================================================================================================*/
static void ELF64_HeaderSwitchEndianness(Elf64_Ehdr *prElf64Header)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == prElf64Header))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        prElf64Header->e_type       = ENDIAN_SW_2B(prElf64Header->e_type);
        prElf64Header->e_machine    = ENDIAN_SW_2B(prElf64Header->e_machine);
        prElf64Header->e_version    = ENDIAN_SW_4B(prElf64Header->e_version);
        prElf64Header->e_entry      = ENDIAN_SW_8B(prElf64Header->e_entry);
        prElf64Header->e_phoff      = ENDIAN_SW_8B(prElf64Header->e_phoff);
        prElf64Header->e_shoff      = ENDIAN_SW_8B(prElf64Header->e_shoff);
        prElf64Header->e_flags      = ENDIAN_SW_4B(prElf64Header->e_flags);
        prElf64Header->e_ehsize     = ENDIAN_SW_2B(prElf64Header->e_ehsize);
        prElf64Header->e_phentsize  = ENDIAN_SW_2B(prElf64Header->e_phentsize);
        prElf64Header->e_phnum      = ENDIAN_SW_2B(prElf64Header->e_phnum);
        prElf64Header->e_shentsize  = ENDIAN_SW_2B(prElf64Header->e_shentsize);
        prElf64Header->e_shnum      = ENDIAN_SW_2B(prElf64Header->e_shnum);
        prElf64Header->e_shstrndx   = ENDIAN_SW_2B(prElf64Header->e_shstrndx);
    }
}

static bool_t ELF64_Load(ELF_File_t *pElfFile,uint32 *u32NamesSectionOffset,uint32 *u32NamesSectionSize)
{
    bool_t    bRetVal = FALSE;

    ELF64_HeaderSwitchEndianness(&(pElfFile->Header.r64));

    if ((uint16)ELF_Type_Executable != pElfFile->Header.r64.e_type)
    {
        NXP_LOG_ERROR("ELF_Open: Only executable ELFs are supported\n");
    }
    else if (FALSE == ELF64_LoadTables(pElfFile))
    {
        NXP_LOG_ERROR("ELF_Open: Failed to load tables\n");
    }
    else
#if TRUE == ELF_CFG_SECTION_TABLE_USED
    {
        /* Look for section names section */
        if ((pElfFile->Header.r64.e_shstrndx == SHN_UNDEF)
            || (pElfFile->Header.r64.e_shstrndx >= pElfFile->Header.r64.e_shnum)
            || (0U == ENDIAN_SW_8B(pElfFile->arSectHead64[pElfFile->Header.r64.e_shstrndx].sh_size))
            )
        {
            NXP_LOG_ERROR("ELF_Open: Section names not found\n");
        }
        else
        {
            *u32NamesSectionOffset = (uint32)ENDIAN_SW_8B(pElfFile->arSectHead64[pElfFile->Header.r64.e_shstrndx].sh_offset);
            *u32NamesSectionSize = (uint32)ENDIAN_SW_8B(pElfFile->arSectHead64[pElfFile->Header.r64.e_shstrndx].sh_size);
            bRetVal = TRUE;
        }
    }
#else  /* ELF_CFG_SECTION_TABLE_USED */
    {
        bRetVal = TRUE;
    }
#endif /* ELF_CFG_SECTION_TABLE_USED */

    return bRetVal;
}

#if TRUE == ELF_CFG_PROGRAM_TABLE_USED
/*================================================================================================*/
static bool_t ELF64_ProgSectFindNext( ELF_File_t *pElfFile, uint32 *pu32ProgIdx,
                                       uint64 *pu64LoadVAddr, uint64 *pu64LoadPAddr, uint64 *pu64Length
                                     )
{
    bool_t bRetVal = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* Check prerequisities */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arProgHead64)))
    {
        NXP_LOG_ERROR("ELF64_ProgSectFindNext: Failed - elf not opened!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Find a record having RAM area */
        while (pElfFile->u32ProgScanIdx < pElfFile->Header.r64.e_phnum)
        {
            if (((uint32)PT_LOAD == ENDIAN_SW_4B(pElfFile->arProgHead64[pElfFile->u32ProgScanIdx].p_type)) /* Has RAM area */
                 && (0U != ENDIAN_SW_8B(pElfFile->arProgHead64[pElfFile->u32ProgScanIdx].p_memsz))      /* Size != 0 */
                )
            {   /* Match found */
                /* Set returned values */
                if (NULL != pu32ProgIdx)
                {
                    *pu32ProgIdx = pElfFile->u32ProgScanIdx;
                }
                if (NULL != pu64LoadVAddr)
                {
                    *pu64LoadVAddr = ENDIAN_SW_8B(pElfFile->arProgHead64[pElfFile->u32ProgScanIdx].p_vaddr);
                }
                if (NULL != pu64LoadPAddr)
                {
                    *pu64LoadPAddr = ENDIAN_SW_8B(pElfFile->arProgHead64[pElfFile->u32ProgScanIdx].p_paddr);
                }
                if (NULL != pu64Length)
                {
                    *pu64Length = ENDIAN_SW_8B(pElfFile->arProgHead64[pElfFile->u32ProgScanIdx].p_memsz);
                }
                bRetVal = TRUE;
                pElfFile->u32ProgScanIdx++;
                break;
            }
            else
            {
                pElfFile->u32ProgScanIdx++;
            }
        }
    }

    return bRetVal;
}

/*================================================================================================*/
static bool_t ELF64_ProgSectLoad(const ELF_File_t *pElfFile, uint32 u32ProgIdx,
                                   addr_t AccessAddr, addr_t AllocSize
                                 )
{
    bool_t bSuccess = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* CHECK */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arProgHead64)))
    {
        NXP_LOG_ERROR("ELF64_ProgSectLoad: Failed - elf not loaded!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    if (u32ProgIdx >= pElfFile->Header.r64.e_phnum)
    {
        NXP_LOG_ERROR("ELF64_ProgSectLoad: Invalid program index: %u\n", (uint_t)u32ProgIdx);
    }
    else if ((uint32)PT_LOAD != ENDIAN_SW_4B(pElfFile->arProgHead64[u32ProgIdx].p_type))
    {
        NXP_LOG_ERROR("ELF64_ProgSectLoad: This section has no associated RAM area\n");
    }
    else if (AllocSize < ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_memsz))
    {
        NXP_LOG_ERROR("ELF64_ProgSectLoad: Section does not fit to allocated memory\n");
    }
    else if (ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_filesz) > ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_memsz))
    {
        NXP_LOG_ERROR("ELF64_ProgSectLoad: Section size mishmash.\n");
    }
    /* LOAD */
    else
    {   /* All OK */
        /* p_filesz bytes of data at the beginning of the memory area shall be copied from file
        the rest up to p_memsz bytes shall be set to 0
        */
        if (0U != ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_filesz))
        {   /* Read from file */
            if (FALSE == LoadFileData(pElfFile, /* pElfFile, */
                (uint32)ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_offset), /* u32Offset, */
                (uint32)ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_filesz), /* u32Size, */
                (void *)AccessAddr /* pvDestMem */
                                      )
                )
            {
                NXP_LOG_ERROR("ELF64_ProgSectLoad: Failed to load section from file\n");
            }
            else
            {   /* Reading done */
                bSuccess = TRUE;
            }
        }
        else
        {   /* Reading skipped */
            bSuccess = TRUE;
        }

        /* Pad rest with zeros */
        if ((TRUE == bSuccess)
            && (ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_memsz) > ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_filesz))
            )
        {
            if (sizeof(addr_t) < sizeof(uint64))
            {
                    NXP_LOG_WARNING("ELF64_ProgSectLoad: addr_t size is not sufficient (%u < %u)", (uint_t)sizeof(addr_t), (uint_t)sizeof(uint64));
            }

            (void)autolibc_memset((void *)(AccessAddr + (addr_t)ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_filesz)),
                0,
                (uint32)ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_memsz) - (uint32)ENDIAN_SW_8B(pElfFile->arProgHead64[u32ProgIdx].p_filesz)
            );
        }
    }
    return bSuccess;
}
#endif /* ELF_CFG_PROGRAM_TABLE_USED */

#if TRUE == ELF_CFG_SECTION_TABLE_USED
/*================================================================================================*/
static bool_t ELF64_SectFindName(const ELF_File_t *pElfFile, const char_t *szSectionName,
                                   uint32 *pu32SectIdx, uint64 *pu64LoadAddr, uint64 *pu64Length
                                 )
{
    bool_t bRetVal = FALSE;
    bool_t bFound = FALSE;
    uint32 SectIdx;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* Check prerequisites */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arSectHead64) || (NULL == pElfFile->acSectNames)))
    {
        NXP_LOG_ERROR("ELF64_SectFindName: Failed - elf not opened!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Search section table */
        for (SectIdx = 0U; SectIdx < pElfFile->Header.r64.e_shnum; SectIdx++)
        {
            if (0 == autolibc_strcmp((char_t *)(pElfFile->acSectNames + ENDIAN_SW_4B(pElfFile->arSectHead64[SectIdx].sh_name)), szSectionName))
            {   /* Found */
                if (NULL != pu32SectIdx)
                {
                    *pu32SectIdx = SectIdx;
                }
                if (NULL != pu64Length)
                {
                    *pu64Length = ENDIAN_SW_8B(pElfFile->arSectHead64[SectIdx].sh_size);
                }
                if (NULL != pu64LoadAddr)
                {
                    *pu64LoadAddr = ENDIAN_SW_8B(pElfFile->arSectHead64[SectIdx].sh_addr);
                }
                bFound = TRUE;
                bRetVal = TRUE;
                break;
            }
        }
        if (FALSE == bFound)
        {
            NXP_LOG_ERROR("ELF64_SectFindName: Section %s not found\n", szSectionName);
        }
    }

    return bRetVal;
}

/*================================================================================================*/
static bool_t ELF64_SectLoad(const ELF_File_t *pElfFile, uint32 u32SectIdx, addr_t AccessAddr, addr_t AllocSize)
{
    bool_t bSuccess = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* CHECK */
    if (unlikely((NULL == pElfFile) || (NULL == pElfFile->arSectHead64)))
    {
        NXP_LOG_ERROR("ELF64_SectLoad: Failed - elf not loaded!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    if (u32SectIdx >= pElfFile->Header.r64.e_shnum)
    {
        NXP_LOG_ERROR("ELF64_SectLoad: Invalid section index: %u\n", (uint_t)u32SectIdx);
    }
    else if (AllocSize < ENDIAN_SW_8B(pElfFile->arSectHead64[u32SectIdx].sh_size))
    {
        NXP_LOG_ERROR("ELF64_SectLoad: Section does not fit to allocated memory\n");
    }
    /* LOAD */
    else
    {   /* All OK */
        if ((uint32)SHT_NOBITS == ENDIAN_SW_4B(pElfFile->arSectHead64[u32SectIdx].sh_type))
        {   /* Fill with zeros */
            (void)autolibc_memset((void *)AccessAddr, 0, (uint32)ENDIAN_SW_8B(pElfFile->arSectHead64[u32SectIdx].sh_size));
            bSuccess = TRUE;
        }
        else
        {   /* Copy from file */
            if (FALSE == LoadFileData(pElfFile, /* pElfFile, */
                                       (uint32)ENDIAN_SW_8B(pElfFile->arSectHead64[u32SectIdx].sh_offset), /* u32Offset, */
                                       (uint32)ENDIAN_SW_8B(pElfFile->arSectHead64[u32SectIdx].sh_size), /* u32Size, */
                                       (void *)AccessAddr /* pvDestMem */
                                      )
                )
            {
                NXP_LOG_ERROR("ELF64_SectLoad: Failed to load section from file\n");
            }
            else
            {   /* Reading done */
                bSuccess = TRUE;
            }
        }
    }
    return bSuccess;
}
#endif /* ELF_CFG_SECTION_TABLE_USED */

#if TRUE == ELF_CFG_SECTION_PRINT_ENABLED
/*================================================================================================*/
static void ELF64_PrintSections(const ELF_File_t *pElfFile)
{
#ifdef NXP_LOG_ENABLED /*  Debug message support */
    uint32 SectIdx;
    uint32 ProgIdx;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    /* Check prerequisites */
    if (unlikely((NULL == pElfFile)
#if TRUE == ELF_CFG_SECTION_TABLE_USED
        || (NULL == pElfFile->arSectHead64)
        || (NULL == pElfFile->acSectNames)
#endif /* ELF_CFG_SECTION_TABLE_USED */
#if TRUE == ELF_CFG_PROGRAM_TABLE_USED
        || (NULL == pElfFile->arProgHead64)
#endif /* ELF_CFG_PROGRAM_TABLE_USED */
        ))
    {
        NXP_LOG_ERROR("NXP_LOG_INFOSections: Failed - elf not opened!\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if TRUE == ELF_CFG_SECTION_TABLE_USED
        /* Search section table */
        NXP_LOG_INFO("\n");
        NXP_LOG_INFO("File contains %hu sections:\n", pElfFile->Header.r64.e_shnum);
        NXP_LOG_INFO("     SectionName Type     FileOffset         FileSize           LoadAddress        Flags\n");
        for (SectIdx = 0U; SectIdx < pElfFile->Header.r64.e_shnum; SectIdx++)
        {
            uint32 u32Type = ENDIAN_SW_4B(pElfFile->arSectHead64[SectIdx].sh_type);
            uint32 u32FlagIdx;

            if (u32Type >= 16U)
            {
                u32Type = 16U; /* Undefined */
            }
            NXP_LOG_INFO("%16s ", pElfFile->acSectNames + ENDIAN_SW_4B(pElfFile->arSectHead64[SectIdx].sh_name));
            NXP_LOG_INFO("%s 0x%016"PRINT64"x 0x%016"PRINT64"x 0x%016"PRINT64"x ",
                        aacSTypes[u32Type],
                        ENDIAN_SW_8B(pElfFile->arSectHead64[SectIdx].sh_offset),
                        ENDIAN_SW_8B(pElfFile->arSectHead64[SectIdx].sh_size),
                        ENDIAN_SW_8B(pElfFile->arSectHead64[SectIdx].sh_addr)
            );
            /* Now print flags on separate line: */
            for (u32FlagIdx = 0U; u32FlagIdx<u32ShT_Flags_Strings_Count; u32FlagIdx++)
            {
                if (0U != (ShT_Flags_Strings[u32FlagIdx].u32Flag & ENDIAN_SW_8B(pElfFile->arSectHead64[SectIdx].sh_flags)))
                {
                    NXP_LOG_INFO("%s, ", ShT_Flags_Strings[u32FlagIdx].szString);
                }
            }
            NXP_LOG_INFO("\n");
        }
#endif /* ELF_CFG_SECTION_TABLE_USED */
#if TRUE == ELF_CFG_PROGRAM_TABLE_USED
        /* Search program table */
        NXP_LOG_INFO("\n");
        NXP_LOG_INFO("File contains %hu program sections:\n", pElfFile->Header.r64.e_phnum);
        NXP_LOG_INFO("Idx Type      FileOffset         FileSize           "
                   "LoadVirtAddress    LoadPhysAddress    MemorySize         \n"
        );
        for (ProgIdx = 0U; ProgIdx < pElfFile->Header.r64.e_phnum; ProgIdx++)
        {
            /* Try to find the name of the section in section header */
            uint32 u32Type = ENDIAN_SW_4B(pElfFile->arProgHead64[ProgIdx].p_type);

            if (u32Type >= 10U)
            {
                u32Type = 10U; /* Undefined */
            }

            /* Print program header data */
            NXP_LOG_INFO("%u %s 0x%016"PRINT64"x 0x%016"PRINT64"x 0x%016"PRINT64"x 0x%016"PRINT64"x 0x%016"PRINT64"x",
                (uint_t)ProgIdx,
                        aacPTypes[u32Type],
                        ENDIAN_SW_8B(pElfFile->arProgHead64[ProgIdx].p_offset),
                        ENDIAN_SW_8B(pElfFile->arProgHead64[ProgIdx].p_filesz),
                        ENDIAN_SW_8B(pElfFile->arProgHead64[ProgIdx].p_vaddr),
                        ENDIAN_SW_8B(pElfFile->arProgHead64[ProgIdx].p_paddr),
                        ENDIAN_SW_8B(pElfFile->arProgHead64[ProgIdx].p_memsz)
                      );
            NXP_LOG_INFO("\n");
        }
#endif /* ELF_CFG_PROGRAM_TABLE_USED */
        NXP_LOG_INFO("\n");
    }
#else
    /* Do nothing */
    (void)pElfFile;
#endif /* NXP_LOG_ENABLED */

}
#endif /* ELF_CFG_SECTION_PRINT_ENABLED */
#endif /* ELF_CFG_ELF64_SUPPORTED */

/*================================================================================================*/
static uint32 buf_read(const void *src_buf, uint32 u32Offset, void *dst_buf, uint32 nbytes)
{
    uint32 u32i = 0U;
    const uint8 *pu8src = (const uint8 *)((addr_t)src_buf + u32Offset);
    uint8 *pu8dst = (uint8 *)dst_buf;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == src_buf) || (NULL == dst_buf)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        u32i = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (u32i = 0U; u32i < nbytes; u32i++)
        {
            *pu8dst = *pu8src;
            pu8dst++;
            pu8src++;
        }
    }
    return u32i;
}

static bool_t ELF_LoadTables(ELF_File_t *pElfFile, uint32 *u32NamesSectionOffset, uint32 *u32NamesSectionSize)
{
    bool_t bRetVal = FALSE;

    if (TRUE == pElfFile->bIs64Bit)
    {   /* Loading 64-bit ELF */
#if TRUE == ELF_CFG_ELF64_SUPPORTED
        bRetVal = ELF64_Load(pElfFile, u32NamesSectionOffset, u32NamesSectionSize);
#else /* ELF_CFG_ELF64_SUPPORTED */
        NXP_LOG_ERROR("Support for Elf64 was not compiled\n");
#endif /* ELF_CFG_ELF64_SUPPORTED */
    }
    else
    {   /* Loading 32-bit ELF */
#if TRUE == ELF_CFG_ELF32_SUPPORTED
        bRetVal = ELF32_Load(pElfFile, u32NamesSectionOffset, u32NamesSectionSize);
#else /* ELF_CFG_ELF32_SUPPORTED */
        NXP_LOG_ERROR("Support for Elf32 was not compiled\n");
#endif /* ELF_CFG_ELF32_SUPPORTED */
    }

    return bRetVal;
}
/*================================================================================================*/
static void ELF_FreePtr(ELF_File_t *pElfFile)
{
    if (NULL != pElfFile->arProgHead64)
    {
        pElfFile->arProgHead64 = NULL;
    }
    if (NULL != pElfFile->arSectHead64)
    {
        pElfFile->arSectHead64 = NULL;
    }
    if (NULL != pElfFile->arProgHead32)
    {
        pElfFile->arProgHead32 = NULL;
    }
    if (NULL != pElfFile->arSectHead32)
    {
        pElfFile->arSectHead32 = NULL;
    }
    if (NULL != pElfFile->acSectNames)
    {
        pElfFile->acSectNames = NULL;
    }
    if (NULL != pElfFile->pvData)
    {
        pElfFile->pvData = NULL;
    }
}
/*==================================================================================================
                                       GLOBAL FUNCTIONS
==================================================================================================*/
/*================================================================================================*/
/**
* @brief        Checks whether file is ELF, and initializes the pElfFile structure.
* @details      It also handles file format and loads all tables handling their endianness.
* @param[out]   pElfFile Structure holding all informations about opened ELF file.
* @param[in]    pvFile Pointer to the file content.
* @retval       TRUE Succeeded
* @retval       FALSE Failed
*/
bool_t ELF_Open(ELF_File_t *pElfFile, const void *pvFile)
{
    bool_t    bRetVal = FALSE;
    uint32     u32NamesSectionOffset = 0U;
    uint32     u32NamesSectionSize = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pElfFile) || (NULL == pvFile)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bRetVal = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Init File info */
        pElfFile->arProgHead64 = NULL;
        pElfFile->arSectHead64 = NULL;
        pElfFile->arProgHead32 = NULL;
        pElfFile->arSectHead32 = NULL;
        pElfFile->acSectNames = NULL;
        pElfFile->pvData = NULL;

        if (ELF64_HEADER_SIZE != buf_read(pvFile, 0,(void *)&(pElfFile->Header.r64), ELF64_HEADER_SIZE))
        {
            NXP_LOG_ERROR("ELF_Open: Failed to read ELF header\n");
        }
        /* Check file type */
        else if (TRUE != CheckElfVersion(pElfFile))
        {
            NXP_LOG_ERROR("ELF_Open: This is not ELF version 1\n");
        }
        else /* So far SUCCESS */
        {
            pElfFile->pvData = pvFile;
            pElfFile->bIs64Bit = ELF_Is64bit(pElfFile);
            pElfFile->u32ProgScanIdx = 0U;
            /* Load tables */
            bRetVal = ELF_LoadTables(pElfFile, &u32NamesSectionOffset, &u32NamesSectionSize);
        }

#if TRUE == ELF_CFG_SECTION_TABLE_USED
        /* === Load section names from file ============================================= */
        if (TRUE == bRetVal)
        {
            /* Save the section name pointer */
            pElfFile->acSectNames = (((sint8 *)pElfFile->pvData) + u32NamesSectionOffset);
            bRetVal = TRUE;
        }
#endif /* ELF_CFG_SECTION_TABLE_USED */

        /* === Check overall status and possibly clean-up ================================= */
        if(FALSE == bRetVal)
        {   /* In case of failure free the memory now */
            ELF_FreePtr(pElfFile);
        }
    }

    return bRetVal;
}

/*================================================================================================*/
/**
* @brief        Closes previously opened ELF file and frees previously allocated memory for headers.
* @param[in,out] pElfFile Structure holding all informations about opened ELF file.
*/
void ELF_Close(ELF_File_t *pElfFile)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pElfFile))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ELF_FreePtr(pElfFile);
    }
}

#if TRUE == ELF_CFG_PROGRAM_TABLE_USED
/*================================================================================================*/
/**
* @brief        Finds next section in program table which shall be loaded into RAM.
* @details      Function provides section index and informations needed for memory allocation.
*               Once the memory is allocated, the index shall be passed to function ELF_ProgSectLoad.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @param[out]   pu32ProgIdx Index which shall be passed to function ELF_ProgSectLoad.
* @param[out]   pu64LoadVAddr Returns the (virtual) address the data shall be loaded at.
* @param[out]   pu64LoadPAddr Returns the physical address the data shall be loaded at. This is
*               used when the physical address is important, usually just virtual address is used.
* @param[out]   pu64Length Length of the section in memory.
* @retval       TRUE Succeeded
* @retval       FALSE Failed
*/
/*  */
bool_t ELF_ProgSectFindNext(ELF_File_t *pElfFile, uint32 *pu32ProgIdx,
                              uint64 *pu64LoadVAddr, uint64 *pu64LoadPAddr, uint64 *pu64Length
                            )
{
    bool_t bRetVal = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pElfFile) || (NULL == pu32ProgIdx) || (NULL == pu64LoadVAddr) || (NULL == pu64LoadPAddr) || (NULL == pu64Length)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bRetVal = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == pElfFile->bIs64Bit)
        {
            #if TRUE == ELF_CFG_ELF64_SUPPORTED
            bRetVal = ELF64_ProgSectFindNext(pElfFile, pu32ProgIdx, pu64LoadVAddr, pu64LoadPAddr, pu64Length);
            #endif /* ELF_CFG_ELF64_SUPPORTED */
        }
        else
        {
            #if TRUE == ELF_CFG_ELF32_SUPPORTED
            bRetVal = ELF32_ProgSectFindNext(pElfFile, pu32ProgIdx, pu64LoadVAddr, pu64LoadPAddr, pu64Length);
            #endif /* ELF_CFG_ELF32_SUPPORTED */
        }
    }
    return bRetVal;
}

/*================================================================================================*/
/**
* @brief        Loads a program section from file to given memory buffer.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @param[in]    u32ProgIdx Section index obtained from function ELF_ProgSectFindNext.
* @param[in]    AccessAddr Address of allocated memory the data will be written to.
* @param[in]    AllocSize Size of the allocated memory.
* @retval       TRUE Succeeded
* @retval       FALSE Failed
*/
bool_t ELF_ProgSectLoad(const ELF_File_t *pElfFile, uint32 u32ProgIdx, addr_t AccessAddr, addr_t AllocSize)
{
    bool_t bRetVal = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pElfFile))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bRetVal = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != (ELF_NAMED_SECT_IDX_FLAG & u32ProgIdx))
        {
            NXP_LOG_ERROR("ELF_ProgSectLoad: Expecting index from function ELF_ProgSectFindNext\n");
            bRetVal = FALSE;
        }
        else if (TRUE == pElfFile->bIs64Bit)
        {
#if TRUE == ELF_CFG_ELF64_SUPPORTED
            bRetVal = ELF64_ProgSectLoad(pElfFile, u32ProgIdx, AccessAddr, AllocSize);
#endif /* ELF_CFG_ELF64_SUPPORTED */
        }
        else
        {
#if TRUE == ELF_CFG_ELF32_SUPPORTED
            bRetVal = ELF32_ProgSectLoad(pElfFile, u32ProgIdx, AccessAddr, AllocSize);
#endif /* ELF_CFG_ELF32_SUPPORTED */
        }
    }
    return bRetVal;
}
#endif /* ELF_CFG_PROGRAM_TABLE_USED */

#if TRUE == ELF_CFG_SECTION_TABLE_USED
/*================================================================================================*/
/**
* @brief        Finds section with matching name in section table.
* @warning      Use of functions ELF_SectFindName and ELF_SectLoad provides alternative way of
*               loading binary. Usually it is better to use functions ELF_ProgSectFindNext
*               and ELF_ProgSectLoad instead.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @param[in]    szSectionName Zero terminated string with exact section name. For example ".bss".
* @param[out]   pu32SectIdx Index which shall be passed to function ELF_SectLoad.
* @param[out]   pu64LoadAddr The address the section data shall be loaded at.
* @param[out]   pu64Length Length of the section in memory.
* @retval       TRUE Succeeded
* @retval       FALSE Failed
*/
bool_t ELF_SectFindName(const ELF_File_t *pElfFile, const char_t *szSectionName,
                          uint32 *pu32SectIdx, uint64 *pu64LoadAddr, uint64 *pu64Length
                        )
{
    bool_t bRetVal = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pElfFile) || (NULL == szSectionName) || (NULL == pu32SectIdx)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bRetVal = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == pElfFile->bIs64Bit)
        {
#if TRUE == ELF_CFG_ELF64_SUPPORTED
            bRetVal = ELF64_SectFindName(pElfFile, szSectionName, pu32SectIdx, pu64LoadAddr, pu64Length);
#endif /* ELF_CFG_ELF64_SUPPORTED */
        }
        else
        {
#if TRUE == ELF_CFG_ELF32_SUPPORTED
            bRetVal = ELF32_SectFindName(pElfFile, szSectionName, pu32SectIdx, pu64LoadAddr, pu64Length);
#endif /* ELF_CFG_ELF32_SUPPORTED */
        }

        /* Set the highest bit in the index to make sure that this index is not used in wrong load function. */
        *pu32SectIdx |= ELF_NAMED_SECT_IDX_FLAG; /* Safe since the ELF index is 16-bit only. */
    }
    return bRetVal;
}

/*================================================================================================*/
/**
* @brief        Loads a named section from file to given memory buffer.
* @warning      Only sections with ALLOC flag shall be loaded for execution.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
* @param[in]    u32SectIdx Section index obtained from function ELF_SectFindName.
* @param[in]    AccessAddr Address of allocated memory the data will be written to.
* @param[in]    AllocSize Size of the allocated memory.
* @retval       TRUE Succeeded
* @retval       FALSE Failed
*/
bool_t ELF_SectLoad(const ELF_File_t *pElfFile, uint32 u32SectIdx, addr_t AccessAddr, addr_t AllocSize)
{
    bool_t bRetVal = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pElfFile))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bRetVal = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U == (ELF_NAMED_SECT_IDX_FLAG & u32SectIdx))
        {
            NXP_LOG_ERROR("ELF_SectLoad: Expecting index from function ELF_SectFindName\n");
            bRetVal = FALSE;
        }
        else if (TRUE == pElfFile->bIs64Bit)
        {
            #if TRUE == ELF_CFG_ELF64_SUPPORTED
            bRetVal = ELF64_SectLoad(pElfFile, (~(uint32)ELF_NAMED_SECT_IDX_FLAG) & u32SectIdx, AccessAddr, AllocSize);
            #endif /* ELF_CFG_ELF64_SUPPORTED */
        }
        else
        {
            #if TRUE == ELF_CFG_ELF32_SUPPORTED
            bRetVal = ELF32_SectLoad(pElfFile, (~(uint32)ELF_NAMED_SECT_IDX_FLAG) & u32SectIdx, AccessAddr, AllocSize);
            #endif /* ELF_CFG_ELF32_SUPPORTED */
        }
    }

    return bRetVal;
}
#endif /* ELF_CFG_SECTION_TABLE_USED */

#if TRUE == ELF_CFG_SECTION_PRINT_ENABLED
/*================================================================================================*/
/**
* @brief        Writes sections and program sections to console.
* @details      This function is intended mainly for debugging purposes. It is not needed for
*               loading. Disable this function in configuration if it is not needed.
* @param[in]    pElfFile Structure holding all informations about opened ELF file.
*/
void ELF_PrintSections(const ELF_File_t *pElfFile)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pElfFile))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == pElfFile->bIs64Bit)
        {
            #if TRUE == ELF_CFG_ELF64_SUPPORTED
            ELF64_PrintSections(pElfFile);
            #endif /* ELF_CFG_ELF64_SUPPORTED */
        }
        else
        {
            #if TRUE == ELF_CFG_ELF32_SUPPORTED
            ELF32_PrintSections(pElfFile);
            #endif /* ELF_CFG_ELF32_SUPPORTED */
        }
    }
}
#endif /* ELF_CFG_SECTION_PRINT_ENABLED */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/


===== 文件 [107/185]: src\fci.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "fci_internal.h"
#include "fci.h"
#include "fci_fp.h"
#include "fci_fp_db.h"
#include "fci_fw_features.h"
#include "fci_mirror.h"
#ifdef PFE_CFG_RTABLE_ENABLE
#include "fci_rt_db.h" /* The 'routes' database */
#endif /* PFE_CFG_RTABLE_ENABLE */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#include "pfe_idex.h" /* The RPC provider */
#include "pfe_platform_rpc.h" /* The RPC codes and data structures */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#ifdef PFE_CFG_FCI_ENABLE

/*==================================================================================================
*                                     GLOBAL VARIABLES
==================================================================================================*/

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* Global variable used across all fci files */
fci_t context = {0};

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       A container for function parameters. It is utilized to comply with HIS_PARAM metric.
 */
typedef struct
{
    fci_msg_t *p_msg;
    fci_msg_t *p_rep_msg;
    bool_t fci_floating_lock;
    bool_t bCheckRet;
} fci_vars_t;

/*==================================================================================================
*                                       LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
static errno_t fci_init_param_validate(fci_t *fci_context, const char_t *const identifier);
#ifdef PFE_CFG_PFE_MASTER
static void fci_init_context_info( fci_t *fci_context, fci_init_info_t *info);
static errno_t execute_fci_cmd(fci_msg_t *msg, uint16 *fci_ret, uint32 **reply_buf_ptr, uint32 **reply_buf_len_ptr);
#ifdef  PFE_CFG_MULTI_INSTANCE_SUPPORT
static errno_t fci_authorize_and_lock( uint32 **reply_buf_len_ptr, bool_t *floating_lock, uint16 *fci_ret, bool_t *fci_cmd_execute, pfe_ct_phy_if_id_t sender_phy_if_id);
static errno_t fci_check_credentials(fci_vars_t *vars, uint16 *fci_ret, uint32 **reply_buf_len_ptr, uint16 **reply_retval_ptr);
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
#endif /* defined(PFE_CFG_PFE_MASTER) */

/*==================================================================================================
*                                       LOCAL FUNCTIONS
==================================================================================================*/

/**
 * @brief       Validate input param to fci_init()
 * @param[in]   fci_context FCI context
 * @param[in]   identifier Text to be used to identify namespace node associated with
 *              the context
 * @retval      EOK Success
 * @retval      EINVAL invalid argument received
 */
static errno_t fci_init_param_validate(fci_t *fci_context, const char_t *const identifier)
{
    errno_t err = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == identifier) || unlikely(NULL == fci_context))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == fci_context->fci_initialized)
        {
            NXP_LOG_ERROR("FCI has already been initialized!\n");
            err = EINVAL;
        }
        else
        {
            (void)autolibc_memset(fci_context, 0, sizeof(fci_t));

            fci_context->log_if_db_initialized = FALSE;
            fci_context->phy_if_db_initialized = FALSE;
#ifdef PFE_CFG_RTABLE_ENABLE
            fci_context->rt_db_initialized = FALSE;
            fci_context->rtable_initialized = FALSE;
#endif /* PFE_CFG_RTABLE_ENABLE */
            fci_context->tmu_initialized = FALSE;
            fci_context->hm_cb_registered = FALSE;
            fci_context->is_some_client = FALSE;
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
            fci_context->fci_owner_initialized = FALSE;
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
        }
    }
    (void)identifier;

    return err;
}

#ifdef PFE_CFG_PFE_MASTER

/**
 * @brief           Execute  fci command
 * @param[inout]    msg message buffer pointer
 * @param[inout]    fci_ret fci command return value
 * @param[inout]    reply_buf_len_ptr pointer to the reply buffer length pointer
 * @param[inout]    reply_retval_ptr pointer to the reply retval pointer
 * @retval          EOK if success, error code otherwise
 */
static errno_t execute_fci_cmd(fci_msg_t *msg, uint16 *fci_ret, uint32 **reply_buf_ptr, uint32 **reply_buf_len_ptr)
{
    errno_t ret = EOK;
    fci_t *fci_context = (fci_t *)&context;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fci_context))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (msg->msg_cmd.code)
        {
            case FPP_CMD_DATA_BUF_PUT:
            {
                pfe_ct_buffer_t buf = {0};
                fpp_buf_cmd_t *fci_buf = (fpp_buf_cmd_t *)msg->msg_cmd.payload;

                if (sizeof(buf.payload) < fci_buf->len)
                {
                    NXP_LOG_WARNING("Put buffer is too small\n");
                    ret = EINVAL;
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
                else
                {
                    buf.flags = 1;
                    buf.len = fci_buf->len;
                    (void)autolibc_memcpy(&buf.payload, fci_buf->payload, fci_buf->len);

                    ret = pfe_class_put_data(fci_context->class, &buf);
                    if (EOK != ret)
                    {
                        NXP_LOG_DEBUG("pfe_class_buf_put() failed: %d\n", ret);
                        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    }
                }

                break;
            }

            case FPP_CMD_IF_LOCK_SESSION:
            case FPP_CMD_IF_UNLOCK_SESSION:
            {
                ret = fci_interfaces_session_cmd(msg->msg_cmd.code, fci_ret);
                break;
            }

            case FPP_CMD_LOG_IF:
            {
                /* Process 'interface' commands (add/del/update/query/...) */
                ret = fci_interfaces_log_cmd(msg, fci_ret, (fpp_log_if_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_PHY_IF:
            {
                /* Process 'interface' commands (add/del/update/query/...) */
                ret = fci_interfaces_phy_cmd(msg, fci_ret, (fpp_phy_if_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_IF_MAC:
            {
                /* Process 'MAC address of interface' commands (add/del/query) */
                ret = fci_interfaces_mac_cmd(msg, fci_ret, (fpp_if_mac_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_IP_ROUTE:
            {
                #ifdef PFE_CFG_RTABLE_ENABLE
                /* Process 'route' commands (add/del/update/query/...) */
                oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                ret = fci_routes_cmd(msg, fci_ret, (fpp_rt_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                #else
                NXP_LOG_WARNING("Routing is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif

                break;
            }

            case FPP_CMD_IPV4_SET_TIMEOUT:
            {
                #ifdef PFE_CFG_RTABLE_ENABLE
                /* Update default timeouts for connections */
                oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                ret = fci_connections_ipv4_timeout_cmd(msg, fci_ret, (fpp_timeout_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                #else
                NXP_LOG_WARNING("Routing is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif

                break;
            }

            case FPP_CMD_IPV4_CONNTRACK:
            {
                #ifdef PFE_CFG_RTABLE_ENABLE
                /* Process 'ipv4 connection' commands (add/del/updated/query/...) */
                oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                ret = fci_connections_ipv4_ct_cmd(msg, fci_ret, (fpp_ct_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                #else
                NXP_LOG_WARNING("Routing is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif

                break;
            }

            case FPP_CMD_IPV6_CONNTRACK:
            {
                #ifdef PFE_CFG_RTABLE_ENABLE
                /* Process 'ipv6 connection' commands (add/del/updated/query/...) */
                oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                ret = fci_connections_ipv6_ct_cmd(msg, fci_ret, (fpp_ct6_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                #else
                NXP_LOG_WARNING("Routing is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif

                break;
            }

            case FPP_CMD_IPV4_RESET:
            {
                #ifdef PFE_CFG_RTABLE_ENABLE
                /* Remove all IPv4 routes, including connections */
                oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                fci_routes_drop_all_ipv4();
                oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                #else
                NXP_LOG_WARNING("Routing is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif

                break;
            }

            case FPP_CMD_IPV6_RESET:
            {
                #ifdef PFE_CFG_RTABLE_ENABLE
                /* Remove all IPv6 routes, including connections */
                oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                fci_routes_drop_all_ipv6();
                oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_00);
                #else
                NXP_LOG_WARNING("Routing is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif

                break;
            }

            case FPP_CMD_L2_BD:
            {
                #ifdef PFE_CFG_L2BRIDGE_ENABLE
                /* Manage L2 bridge domains */
                ret = fci_l2br_domain_cmd(msg, fci_ret, (fpp_l2_bd_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                #else
                NXP_LOG_WARNING("L2bridge mode is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif
                break;
            }

            case FPP_CMD_L2_STATIC_ENT:
            {
                #ifdef PFE_CFG_L2BRIDGE_ENABLE
                /* Manage L2 bridge domains */
                ret = fci_l2br_static_entry_cmd(msg, fci_ret, (fpp_l2_static_ent_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                #else
                NXP_LOG_WARNING("L2bridge mode is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif
                break;
            }

            case FPP_CMD_FP_TABLE:
            {
                ret = fci_fp_table_cmd(msg, fci_ret, (fpp_fp_table_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_FP_RULE:
            {
                ret = fci_fp_rule_cmd(msg, fci_ret, (fpp_fp_rule_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_FW_FEATURE:
            {
                ret = fci_fw_features_cmd(msg, fci_ret, (fpp_fw_features_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_FW_FEATURE_ELEMENT:
            {
                ret = fci_fw_features_element_cmd(msg, fci_ret, (fpp_fw_features_element_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_QOS_QUEUE:
            {
                ret = fci_qos_queue_cmd(msg, fci_ret, (fpp_qos_queue_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_QOS_SCHEDULER:
            {
                ret = fci_qos_scheduler_cmd(msg, fci_ret, (fpp_qos_scheduler_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_QOS_SHAPER:
            {
                ret = fci_qos_shaper_cmd(msg, fci_ret, (fpp_qos_shaper_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_MIRROR:
            {
                ret = fci_mirror_cmd(msg,fci_ret, (fpp_mirror_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }
            case FPP_CMD_QOS_POLICER:
            {
                ret = fci_qos_policer_cmd(msg, fci_ret, (fpp_qos_policer_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_QOS_POLICER_FLOW:
            {
                ret = fci_qos_policer_flow_cmd(msg, fci_ret, (fpp_qos_policer_flow_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_QOS_POLICER_WRED:
            {
                ret = fci_qos_policer_wred_cmd(msg, fci_ret, (fpp_qos_policer_wred_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_QOS_POLICER_SHP:
            {
                ret = fci_qos_policer_shp_cmd(msg, fci_ret, (fpp_qos_policer_shp_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            case FPP_CMD_L2_FLUSH_ALL:
            case FPP_CMD_L2_FLUSH_LEARNED:
            case FPP_CMD_L2_FLUSH_STATIC:
            {
                #ifdef PFE_CFG_L2BRIDGE_ENABLE
                ret = fci_l2br_flush_cmd(msg->msg_cmd.code, fci_ret);
                #else
                NXP_LOG_WARNING("L2bridge mode is disabled\n");
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                #endif
                break;
            }

            case FPP_CMD_FCI_OWNERSHIP_LOCK:
            case FPP_CMD_FCI_OWNERSHIP_UNLOCK:
            {
                NXP_LOG_WARNING("Received FCI ownership command: 0x%x. It is not supported in standalone mode.\n", (uint_t)msg->msg_cmd.code);
                *fci_ret = FPP_ERR_FCI_OWNERSHIP_NOT_ENABLED;
                break;
            }

            case FPP_CMD_TIMER_LOCK:
            {
                ret = fci_timer_owner_lock_cmd(msg, fci_ret, (fpp_timer_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }
            case FPP_CMD_TIMER_UNLOCK:
            {
                ret = fci_timer_owner_unlock_cmd(msg, fci_ret, (fpp_timer_cmd_t *)*reply_buf_ptr, *reply_buf_len_ptr);
                break;
            }

            default:
            {
                NXP_LOG_WARNING("Unknown CMD code received: 0x%x\n", (uint_t)msg->msg_cmd.code);
                ret = EINVAL;
                *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                break;
            }
        }
    }
    return ret;
}

/**
 * @brief       Initialize fci_context structure
 * @param[in]   fci_context Pointer to the fci_context structure
 * @param[in]   info Additional FCI endpoint configuration or NULL if not required
 */

static void fci_init_context_info( fci_t *fci_context, fci_init_info_t *info)
{
/*    Initialize the Flexible Parser databases */
    fci_fp_db_init();
    if (NULL != info)
    {
        fci_context->class = info->class;

        /*    Initialize the physical interface database */
        if (NULL != info->phy_if_db)
        {
            fci_context->phy_if_db = info->phy_if_db;
            fci_context->phy_if_db_initialized = TRUE;
        }

        /*    Initialize the logical interface database */
        if (NULL != info->log_if_db)
        {
            fci_context->log_if_db = info->log_if_db;
            fci_context->log_if_db_initialized = TRUE;
        }

        /*    Initialize the TMU  */
        if (NULL != info->tmu)
        {
            fci_context->tmu = info->tmu;
            fci_context->tmu_initialized = TRUE;
        }

#ifdef PFE_CFG_RTABLE_ENABLE
        /*    Initialize the route database */
        fci_rt_db_init(&fci_context->route_db);
        fci_context->rt_db_initialized = TRUE;

        /*    Store the routing table and bridge reference */
        if (NULL != info->rtable)
        {
            fci_context->rtable = info->rtable;
            fci_context->rtable_initialized = TRUE;
        }
#endif /* PFE_CFG_RTABLE_ENABLE */

#ifdef PFE_CFG_L2BRIDGE_ENABLE
        if (NULL != info->l2_bridge)
        {
            fci_context->l2_bridge = info->l2_bridge;
            fci_context->l2_bridge_initialized = TRUE;
        }
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
    }
}


#ifdef  PFE_CFG_MULTI_INSTANCE_SUPPORT
/**
 * @brief           Authorize fci command and get floating lock
 * @param[inout]    reply_buf_len_ptr pointer to the reply buffer length pointer
 * @param[inout]    floating_lock floating lock identifier
 * @param[inout]    fci_ret fci command return value
 * @param[inout]    fci_cmd_execute fci command execute variable
 * @param[in]       sender_phy_if_id  sender phy id value
 * @retval          EOK if success, error code otherwise
 */
static errno_t fci_authorize_and_lock( uint32 **reply_buf_len_ptr, bool_t *floating_lock, uint16 *fci_ret, bool_t *fci_cmd_execute, pfe_ct_phy_if_id_t sender_phy_if_id)
{
    /* Authorization - check if sender is matching current FCI owner lock holder */
    errno_t ret = fci_owner_authorize(sender_phy_if_id, fci_cmd_execute);
    if ((EOK == ret) && (FALSE == *fci_cmd_execute))
    {
        /* Do not execute not authorized command and try to get floating FCI ownership */
        ret = fci_owner_get_floating_lock(sender_phy_if_id, fci_ret, floating_lock);
        if (EOK == ret)
        {
            /* Execute FCI command as we have got the floating FCI owner lock */
            *fci_cmd_execute = *floating_lock;
        }
    }
    if ((EOK == ret) && (FALSE == *fci_cmd_execute))
    {
        /* Clear reply buf len as FCI command is not going to be executed */
        **reply_buf_len_ptr = 0;
    }

    return ret;
}

/**
 * @brief           Checking credentials before fci command execution
 * @param[inout]    vars pointer to the fci_vars_t structure
 * @param[inout]    fci_ret fci command return value
 * @param[inout]    reply_buf_len_ptr pointer to the reply buffer length pointer
 * @param[inout]    reply_retval_ptr pointer to the reply retval pointer
 * @retval          EOK if success, error code otherwise
 */
static errno_t fci_check_credentials(fci_vars_t *vars, uint16 *fci_ret, uint32 **reply_buf_len_ptr, uint16 **reply_retval_ptr)
{
    pfe_ct_phy_if_id_t sender_phy_if_id = PFE_PHY_IF_ID_INVALID;
    bool_t fci_cmd_execute = FALSE;
    /* Get mutex when handling FCI Ownership */
    errno_t ret = fci_owner_mutex_lock();

    if (EOK == ret)
    {
        /* Authentication - get validated sender's HIF */
        ret = fci_sender_get_phy_if_id(vars->p_msg->msg_cmd.sender, &sender_phy_if_id);
        if (EOK == ret)
        {
            if ((FPP_CMD_FCI_OWNERSHIP_LOCK == vars->p_msg->msg_cmd.code) ||
                (FPP_CMD_FCI_OWNERSHIP_UNLOCK == vars->p_msg->msg_cmd.code))
            {
                /* Handle FCI lock/unlock commands */
                ret = fci_owner_session_cmd(sender_phy_if_id, vars->p_msg->msg_cmd.code, fci_ret);
            }
            else
            {
                ret = fci_authorize_and_lock(reply_buf_len_ptr, &vars->fci_floating_lock, fci_ret, &fci_cmd_execute, sender_phy_if_id);
            }
        }
        /* fci_owner_mutex_unlock overrides ret, so set internal failure here */
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }

        /* Release FCI Ownership mutex if the floating FCI lock was not granted */
        if (FALSE == vars->fci_floating_lock)
        {
            ret = fci_owner_mutex_unlock();
        }
    }
    if (EOK != ret)
    {
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
    }

    /* Exit fci_process_ipc_message if: */
    /*     1) Handled FCI lock/unlock command */
    /*     2) Current sender is not authorized to execute FCI command due to missing Ownership / lock */
    /*     3) An internal error occurred */
    if (FALSE == fci_cmd_execute)
    {
        /* Inform client about command execution status */
#if (FALSE == FCI_CFG_FORCE_LEGACY_API)
        /* We're adding another 4 bytes at the beginning of the FCI message payload area */
        PfeDevAssert(**reply_buf_len_ptr < sizeof(fci_msg_cmd_t));
        vars->p_rep_msg->msg_cmd.length = **reply_buf_len_ptr + 4U;
#else
        /* Pass reply buffer length as is. First 4 bytes will be overwritten by the return value. */
        vars->p_rep_msg->msg_cmd.length = **reply_buf_len_ptr;
#endif /* FCI_CFG_FORCE_LEGACY_API */
        *reply_retval_ptr = (uint16 *)vars->p_rep_msg->msg_cmd.payload;
        **reply_retval_ptr = *fci_ret;
        vars->bCheckRet = TRUE;
    }
    if (TRUE != vars->bCheckRet)
    {
        NXP_LOG_DEBUG("Process FCI message (type=0x%02x, code=0x%02x, sender=0x%02x)\n", (uint_t)vars->p_msg->type, (uint_t)vars->p_msg->msg_cmd.code, (uint_t)sender_phy_if_id);
    }

    return ret;
}
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
#endif /*defined(PFE_CFG_PFE_MASTER)*/

/*==================================================================================================
*                                       GLOBAL FUNCTIONS
==================================================================================================*/

/**
 * @brief       Process FCI IPC message
 * @details     Interpret the IPC message and perform related configuration/management actions.
 *              Generate response in form of fci_msg_t to be sent back to FCI client.
 * @param[in]   msg The input message from FCI client
 * @param[out]  rep_msg The reply message
 * @return      EOK if success, error code otherwise
 */
errno_t fci_process_ipc_message(fci_msg_t *msg, fci_msg_t *rep_msg)
{
#if !defined(PFE_CFG_PFE_MASTER)
    /* Slave FCI proxy support */

    errno_t ret = EOK; /* Return value */
    pfe_platform_rpc_pfe_fci_proxy_arg_t proxy_cmd = {msg->type, msg->msg_cmd};
    pfe_platform_rpc_pfe_fci_proxy_ret_t proxy_rep = {0};

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == rep_msg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_DEBUG("Send FCI proxy message (type=0x%02x, code=0x%02x)\n", (uint_t)msg->type, (uint_t)msg->msg_cmd.code);
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_FCI_PROXY, &proxy_cmd, (uint16)sizeof(proxy_cmd), &proxy_rep, (uint16)sizeof(proxy_rep));
        rep_msg->msg_cmd = proxy_rep.msg_cmd;
    }
#else
    /* Normal FCI processing */
    errno_t ret = EOK; /* Return value */
    uint16 fci_ret = FPP_ERR_OK; /* FCI command return value */
    uint32 *reply_buf_ptr = NULL;
    uint32 *reply_buf_len_ptr = NULL;
    uint16 *reply_retval_ptr = NULL;
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    fci_vars_t passed_vars = { .p_msg = msg, .p_rep_msg = rep_msg, .fci_floating_lock = FALSE, .bCheckRet = FALSE };
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == rep_msg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if (FALSE == FCI_CFG_FORCE_LEGACY_API)
        /*  Allocate space for return value ( + padding) by skipping first 4 bytes */
        reply_buf_ptr = ((uint32 *)&rep_msg->msg_cmd.payload[4]);
        reply_buf_len_ptr = &rep_msg->msg_cmd.length;

        /*  Available reply buffer is 4 bytes less than maximum FCI message payload length */
        *reply_buf_len_ptr = FCI_CFG_MAX_CMD_PAYLOAD_LEN - 4U;
#else
        /*  Don't allocate space for return value. First 4 bytes of payload buffer will be overwritten... */
        reply_buf_ptr = rep_msg->msg_cmd.payload;
        reply_buf_len_ptr = &rep_msg->msg_cmd.length;
        *reply_buf_len_ptr = FCI_CFG_MAX_CMD_PAYLOAD_LEN;
#endif /* FCI_CFG_FORCE_LEGACY_API */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        /* HANDLE FCI OWNERSHIP */
        if (FCI_MSG_CMD == msg->type)
        {
            ret = fci_check_credentials(&passed_vars, &fci_ret, &reply_buf_len_ptr, &reply_retval_ptr);
        }
        if(TRUE != passed_vars.bCheckRet)
#else
        NXP_LOG_DEBUG("Process FCI message (type=0x%02x, code=0x%02x)\n", (uint_t)msg->type, (uint_t)msg->msg_cmd.code);
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
        {
            switch (msg->type)
            {
                case FCI_MSG_CMD:
                {
                    ret = execute_fci_cmd(msg, &fci_ret, &reply_buf_ptr, &reply_buf_len_ptr);
                    
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
                    if (TRUE == passed_vars.fci_floating_lock)
                    {
                        /* Release floating FCI ownership lock */
                        ret = fci_owner_clear_floating_lock();
                        if (EOK != ret)
                        {
                            fci_ret = FPP_ERR_INTERNAL_FAILURE;
                        }

                        ret = fci_owner_mutex_unlock();
                        if (EOK != ret)
                        {
                            fci_ret = FPP_ERR_INTERNAL_FAILURE;
                        }
                    }
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

                    /* Inform client about command execution status */
#if (FALSE == FCI_CFG_FORCE_LEGACY_API)
                    /* We're adding another 4 bytes at the beginning of the FCI message payload area */
                    rep_msg->msg_cmd.length = *reply_buf_len_ptr + 4U;
#else
                    /* Pass reply buffer length as is. First 4 bytes will be overwritten by the return value. */
                    rep_msg->msg_cmd.length = *reply_buf_len_ptr;
#endif /* FCI_CFG_FORCE_LEGACY_API */
                    reply_retval_ptr = (uint16 *)rep_msg->msg_cmd.payload;
                    *reply_retval_ptr = (uint16)fci_ret;

                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("Unknown message type\n");
                    ret = EINVAL;
                    break;
                }
            }
        }
    }
#endif /* PFE_CFG_PFE_MASTER */
    return ret;
}

/**
 * @brief       Create and start FCI endpoint
 * @param[in]   info Additional FCI endpoint configuration or NULL if not required
 * @param[in]   identifier Text to be used to identify namespace node associated with
 *              the context
 * @retval      EOK Success
 * @retval      EINVAL invalid argument received
 * @retval      ENOMEM initialization failed
 */
errno_t fci_init(fci_init_info_t *info, const char_t *const identifier)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t err = EOK;

    err = fci_init_param_validate(fci_context, identifier);
    if (EINVAL != err)
    {
        /*  Create communication core */
        err = fci_core_init(identifier);
        if (EOK != err)
        {
            NXP_LOG_ERROR("Could not create FCI core\n");
            fci_fini();
        }
        else
        {
#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
            /*  Initialize FCI ownership */
            err = fci_owner_init(info);
            if (EOK == err)
            {
                fci_context->fci_owner_initialized = TRUE;
            }
            if (EOK != err)
            {
                fci_fini();
            }
            else
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
            {
                fci_init_context_info(fci_context, info);
            }
#else  /* PFE_CFG_PFE_MASTER */
            (void)info;
#endif /* PFE_CFG_PFE_MASTER */

            if (EOK == fci_hm_cb_register())
            {
                fci_context->hm_cb_registered = TRUE;
            }

            fci_context->default_timeouts.timeout_tcp = 5U * 24U * 60U * 60U;   /* 5 days */
            fci_context->default_timeouts.timeout_udp = 300U;                   /* 5 min */
            fci_context->default_timeouts.timeout_other = 240U;                 /* 4 min */
            fci_context->fci_initialized = TRUE;
        }
    }

    return err;
}

/**
 * @brief       Destroy FCI context
 */
void fci_fini(void)
{
    fci_t *fci_context = (fci_t *)&context;
#ifdef PFE_CFG_PFE_MASTER
    uint32 session_id = 0U;
#endif /* PFE_CFG_PFE_MASTER */

    if (TRUE == fci_context->fci_initialized)
    {

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_RTABLE_ENABLE
        /* Drop all content of RT DB (needs operational endpoint; may send FCI events) */
        if (TRUE == fci_context->rt_db_initialized)
        {
            oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_01);
            fci_routes_drop_all();
            oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_01);
        }
#endif /* PFE_CFG_RTABLE_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */

        /* Deregister HM callback function */
        if (TRUE == fci_context->hm_cb_registered)
        {
            (void)fci_hm_cb_deregister();
            fci_context->hm_cb_registered = FALSE;
            fci_context->is_some_client = FALSE;
        }

        /*  Shut down the endpoint */
        if (NULL != fci_context->core)
        {
            fci_core_fini();
            fci_context->core = NULL;
        }

    #ifdef PFE_CFG_PFE_MASTER
        (void)pfe_if_db_lock(&session_id);
        /*    Shutdown the logical IF DB */
        if (TRUE == fci_context->log_if_db_initialized)
        {
            /* Freeing of the DB is handled by platfrom driver*/
            fci_context->log_if_db = NULL;
            fci_context->log_if_db_initialized = FALSE;
        }

        /*  Shutdown the physical IF DB */
        if (TRUE == fci_context->phy_if_db_initialized)
        {
            /* Freeing of the DB is handled by platfrom driver*/
            fci_context->phy_if_db = NULL;
            fci_context->phy_if_db_initialized = FALSE;
        }
        (void)pfe_if_db_unlock(session_id);

#ifdef PFE_CFG_RTABLE_ENABLE
        /*    Shutdown the RT DB (paranoia clean) */
        if (TRUE == fci_context->rt_db_initialized)
        {
            oal_mutex_lock(PFE_FCI_CONTEXT_DB_MUTEX_01);
            fci_routes_drop_all();
            oal_mutex_unlock(PFE_FCI_CONTEXT_DB_MUTEX_01);

            fci_context->rt_db_initialized = FALSE;
        }

        /*    Invalidate the routing table */
        fci_context->rtable = NULL;
        fci_context->rtable_initialized = FALSE;
#endif /* PFE_CFG_RTABLE_ENABLE */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        if (TRUE == fci_context->fci_owner_initialized)
        {
            fci_context->fci_owner_initialized = FALSE;
        }
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
    #endif /* PFE_CFG_PFE_MASTER */

        (void)autolibc_memset(fci_context, 0, sizeof(fci_t));
        fci_context->fci_initialized = FALSE;
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */


===== 文件 [108/185]: src\fci_connections.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_connections.c
 * @brief       Connection management functions.
 * @details     All IP connections related functionality provided by the FCI should be
 *              implemented within this file.
 *
 *              Uni- and bi-directional connections are supported. Uni-directional creates
 *              routing table entry in original direction only. Bi-directional adds also
 *              the opposite direction so adding a bi-directional entry results in addition
 *              of two routing table entries.
 *
 *              Packet modifications are applied according to routing rules:
 *              - Source MAC address of forwarded packet is changed to MAC address associated with
 *                egress interface (fci_if_db_entry_t).
 *              - Destination MAC address is changed to the one provided by route (fci_rt_db_entry_t).
 *              - Source/Destination IP and Source/Destination ports are changed according to user's
 *                request (fpp_ct_cmd_t/fpp_ct6_cmd_t).
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"

#include "fci_internal.h"
#include "fci.h"

#include "oal_util_net.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE
#ifdef PFE_CFG_RTABLE_ENABLE

/*  IP address conversion */

#define FCI_CONNECTIONS_CFG_MAX_STR_LEN     128U

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static void fci_connections_ipv4_cmd_to_5t(const fpp_ct_cmd_t *ct_cmd, pfe_5_tuple_t *tuple);
static void fci_connections_ipv4_cmd_to_5t_rep(const fpp_ct_cmd_t *ct_cmd, pfe_5_tuple_t *tuple);
static void fci_connections_ipv6_cmd_to_5t(const fpp_ct6_cmd_t *ct6_cmd, pfe_5_tuple_t *tuple);
static void fci_connections_ipv6_cmd_to_5t_rep(const fpp_ct6_cmd_t *ct6_cmd, pfe_5_tuple_t *tuple);
static pfe_rtable_entry_t *fci_connections_create_entry(const fci_rt_db_entry_t *route,
                                const pfe_5_tuple_t *tuple, const pfe_5_tuple_t *tuple_rep);
static errno_t fci_connections_ipv4_cmd_to_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
static errno_t fci_connections_ipv4_cmd_to_rep_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
static errno_t fci_connections_ipv6_cmd_to_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
static errno_t fci_connections_ipv6_cmd_to_rep_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface);
static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len);
static void create_entry_check_nat(pfe_rtable_entry_t **new_entry, const pfe_5_tuple_t *tuple, const pfe_5_tuple_t *tuple_rep);
static errno_t ipvx_ct_check_args_clear_buf(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len);
static errno_t ipvx_ct_register(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret);
static uint16 ipvx_ct_register_get_rtable_entries(bool_t ipv6,
                                                    const fci_msg_t *msg,
                                                    pfe_rtable_entry_t **entry,
                                                    pfe_rtable_entry_t **rep_entry);
static errno_t ipvx_ct_register_add_entry(void *client, uint16 *fci_ret, pfe_rtable_entry_t **entry, pfe_rtable_entry_t **rep_entry);
static errno_t ipvx_ct_register_add_rep_entry(uint16 *fci_ret, pfe_rtable_entry_t **entry, pfe_rtable_entry_t **rep_entry);
static errno_t ipvx_ct_deregister(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret);
static errno_t ipvx_ct_update(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret);
static void ipvx_ct_compile_fci_reply_basic(bool_t ipv6, void *reply_buf, pfe_rtable_entry_t *entry);
static void ipvx_ct_compile_fci_reply_replydir(bool_t ipv6, void *reply_buf, pfe_rtable_entry_t *entry);
static void ipvx_ct_compile_fci_reply_nat_modifications_ipv4(   fpp_ct_cmd_t *ct_reply,
                                                                pfe_ct_route_actions_t actions,
                                                                const pfe_5_tuple_t *tuple);
static void ipvx_ct_compile_fci_reply_nat_modifications_ipv6(   fpp_ct6_cmd_t *ct_reply,
                                                                pfe_ct_route_actions_t actions,
                                                                const pfe_5_tuple_t *tuple);
static void ipvx_ct_compile_fci_reply(  bool_t ipv6,
                                        pfe_rtable_entry_t *entry,
                                        void *reply_buf,
                                        uint32 *reply_len);
static void ipvx_ct_query(bool_t ipv6, uint16 *fci_ret, void *reply_buf, uint32 *reply_len);
static void ipvx_ct_query_cont(bool_t ipv6, uint16 *fci_ret, void *reply_buf, uint32 *reply_len);

#if (PFE_CFG_VERBOSITY_LEVEL >= 8)
#ifdef NXP_LOG_ENABLED
static char_t * fci_connections_ipv4_cmd_to_str(fpp_ct_cmd_t *ct_cmd);
static char_t * fci_connections_ipv6_cmd_to_str(fpp_ct6_cmd_t *ct6_cmd);
static char_t * fci_connections_entry_to_str(pfe_rtable_entry_t *entry);
static char_t * fci_connections_build_str(bool_t ipv6, uint8 *sip, uint8 *dip, uint16 *sport, uint16 *dport,
                                    uint8 *sip_out, uint8 *dip_out, uint16 *sport_out, uint16 *dport_out, uint8 *proto);
static void ipvx_prepare_debug_snippets(bool_t ipv6, const fci_msg_t *msg, const char **const ret_ip, const char **const ret_cntk_info);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#define ETH_43_PFE_START_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"

/* usage scope: fci_connections_build_str */
static char_t fci_connections_build_str_buf[FCI_CONNECTIONS_CFG_MAX_STR_LEN];

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"
#define ETH_43_PFE_START_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"

/* usage scope: fci_connections_entry_to_str */
static char_t * const fci_connections_entry_to_str_err_str = "Entry-to-string conversion failed";

#define ETH_43_PFE_STOP_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Convert CT (IPv4) command to string representation
 * @param[in]   ct_cmd The command
 * @return      Pointer to memory where the output string is located
 */
static char_t * fci_connections_ipv4_cmd_to_str(fpp_ct_cmd_t *ct_cmd)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ct_cmd))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        return NULL;
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    return fci_connections_build_str(FALSE,
                                        (uint8 *)&ct_cmd->saddr,
                                        (uint8 *)&ct_cmd->daddr,
                                        &ct_cmd->sport,
                                        &ct_cmd->dport,
                                        (uint8 *)&ct_cmd->daddr_reply,
                                        (uint8 *)&ct_cmd->saddr_reply,
                                        &ct_cmd->dport_reply,
                                        &ct_cmd->sport_reply,
                                        (uint8 *)&ct_cmd->protocol);
}

/**
 * @brief       Convert CT (IPv6) command to string representation
 * @param[in]   ct_cmd The command
 * @return      Pointer to memory where the output string is located
 */
static char_t * fci_connections_ipv6_cmd_to_str(fpp_ct6_cmd_t *ct6_cmd)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ct6_cmd))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        return NULL;
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    return fci_connections_build_str(TRUE,
                                            (uint8 *)&ct6_cmd->saddr,
                                            (uint8 *)&ct6_cmd->daddr,
                                            &ct6_cmd->sport,
                                            &ct6_cmd->dport,
                                            (uint8 *)&ct6_cmd->daddr_reply,
                                            (uint8 *)&ct6_cmd->saddr_reply,
                                            &ct6_cmd->dport_reply,
                                            &ct6_cmd->sport_reply,
                                            (uint8 *)&ct6_cmd->protocol);
}

/**
 * @brief       Build string from given values
 * @param[in]   ipv6 TRUE if IPv6 values, FALSE for IPv4
 * @param[in]   sip SIP
 * @param[in]   dip DIP
 * @param[in]   sport SPORT
 * @param[in]   dport DPORT
 * @param[in]   sip_out Output SIP
 * @param[in]   dip_out Output DIP
 * @param[in]   sport_out Output SPORT
 * @param[in]   dport_out Output DPORT
 * @param[in]   proto Protocol
 * @return      Pointer to buffer with the output string
 */
static char_t * fci_connections_build_str(bool_t ipv6, uint8 *sip, uint8 *dip, uint16 *sport, uint16 *dport,
                                    uint8 *sip_out, uint8 *dip_out, uint16 *sport_out, uint16 *dport_out, uint8 *proto)
{
    uint32 ipv_flag = (TRUE == ipv6) ? AF_INET6 : AF_INET;
    uint8 ip_addr_len = (TRUE == ipv6) ? 16U : 4U;
    uint32 len = 0U;
    char_t sip_str[32+7+1]; /* 1111:1111:1111:1111:1111:1111:1111:1111 */
    char_t sip_out_str[32+7+1]; /* 1111:1111:1111:1111:1111:1111:1111:1111 */
    char_t dip_str[32+7+1]; /* 1111:1111:1111:1111:1111:1111:1111:1111 */
    char_t dip_out_str[32+7+1]; /* 1111:1111:1111:1111:1111:1111:1111:1111 */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == sip) || (NULL == dip) || (NULL == sport) || (NULL == dport)
            || (NULL == sip_out) || (NULL == dip_out) || (NULL == sport_out) || (NULL == dport_out)
                || (NULL == proto)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        return NULL;
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    oal_util_net_inet_ntop(ipv_flag, sip, sip_str, sizeof(sip_str));
    oal_util_net_inet_ntop(ipv_flag, dip, dip_str, sizeof(dip_str));
    oal_util_net_inet_ntop(ipv_flag, sip_out, sip_out_str, sizeof(sip_out_str));
    oal_util_net_inet_ntop(ipv_flag, dip_out, dip_out_str, sizeof(dip_out_str));

    if (0 != autolibc_memcmp(sip, sip_out, ip_addr_len))
    {
        /*  SIP need to be changed to SIP_OUT */
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tSIP: %s --> %s\n", sip_str, sip_out_str);
    }
    else
    {
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tSIP: %s\n", sip_str);
    }

    if (0 != autolibc_memcmp(dip, dip_out, ip_addr_len))
    {
        /*  DIP need to be changed to DIP_OUT */
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tDIP: %s --> %s\n", dip_str, dip_out_str);
    }
    else
    {
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tDIP: %s\n", dip_str);
    }

    if (*sport != *sport_out)
    {
        /*  SPORT need to be changed to DPORT_REPLY */
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tSPORT: %d --> %d\n", oal_ntohs(*sport), oal_ntohs(*sport_out));
    }
    else
    {
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tSPORT: %d\n", oal_ntohs(*sport));
    }

    if (*dport != *dport_out)
    {
        /*  DPORT need to be changed to SPORT_REPLY */
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tDPORT: %d --> %d\n", oal_ntohs(*dport), oal_ntohs(*dport_out));
    }
    else
    {
        len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len,
                            "\t\tDPORT: %d\n", oal_ntohs(*dport));
    }

    /*  Last line. Shall not contain EOL character. */
    len += nxp_snprintf(fci_connections_build_str_buf + len, FCI_CONNECTIONS_CFG_MAX_STR_LEN - len, "\t\tPROTO: %d", *proto);

    return fci_connections_build_str_buf;
}

/**
 * @brief       Convert routing table entry to a string representation
 * @param[in]   entry The entry
 * @return      Pointer to memory where the output string is located
 */
static char_t * fci_connections_entry_to_str(pfe_rtable_entry_t *entry)
{
    pfe_5_tuple_t tuple;
    pfe_5_tuple_t tuple_out;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        return NULL;
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    if (EOK != pfe_rtable_entry_to_5t(entry, &tuple))
    {
        return fci_connections_entry_to_str_err_str;
    }

    if (EOK != pfe_rtable_entry_to_5t_out(entry, &tuple_out))
    {
        return fci_connections_entry_to_str_err_str;
    }

    tuple.sport = oal_htons(tuple.sport);
    tuple.dport = oal_htons(tuple.dport);
    tuple_out.sport = oal_htons(tuple_out.sport);
    tuple_out.dport = oal_htons(tuple_out.dport);

    if (tuple.src_ip.is_ipv4)
    {
        return fci_connections_build_str(FALSE,
                                            (uint8 *)&tuple.src_ip.v4,
                                            (uint8 *)&tuple.dst_ip.v4,
                                            &tuple.sport,
                                            &tuple.dport,
                                            (uint8 *)&tuple_out.src_ip.v4,
                                            (uint8 *)&tuple_out.dst_ip.v4,
                                            &tuple_out.sport,
                                            &tuple_out.dport,
                                            (uint8 *)&tuple.proto);
    }
    else
    {
        return fci_connections_build_str(TRUE,
                                            (uint8 *)&tuple.src_ip.v6,
                                            (uint8 *)&tuple.dst_ip.v6,
                                            &tuple.sport,
                                            &tuple.dport,
                                            (uint8 *)&tuple_out.src_ip.v6,
                                            (uint8 *)&tuple_out.dst_ip.v6,
                                            &tuple_out.sport,
                                            &tuple_out.dport,
                                            (uint8 *)&tuple.proto);
    }
}

/* This "offloaded" preparation of debug text snippets allows to achieve better HIS metrics in fci_connections_ipvx_ct_cmd(). */
static void ipvx_prepare_debug_snippets(bool_t ipv6, const fci_msg_t *msg, const char **const ret_ip, const char **const ret_cntk_info)
{
    if (TRUE == ipv6)
    {
        *ret_ip = "IPv6";
        *ret_cntk_info = fci_connections_ipv6_cmd_to_str((fpp_ct6_cmd_t *)(msg->msg_cmd.payload));
    }
    else
    {
        *ret_ip = "IPv4";
        *ret_cntk_info = fci_connections_ipv4_cmd_to_str((fpp_ct_cmd_t *)(msg->msg_cmd.payload));
    }
}
#endif /* NXP_LOG_ENABLED */
#endif /* PFE_CFG_VERBOSITY_LEVEL */

/**
 * @brief       Convert CT command (IPv4) to 5 tuple representation
 * @param[in]   ct_cmd The command
 * @param[out]  tuple Pointer to location where output shall be written
 */
static void fci_connections_ipv4_cmd_to_5t(const fpp_ct_cmd_t *ct_cmd, pfe_5_tuple_t *tuple)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct_cmd) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(tuple, 0, sizeof(pfe_5_tuple_t));

        (void)autolibc_memcpy(&tuple->src_ip.v4, &ct_cmd->saddr, 4);
        (void)autolibc_memcpy(&tuple->dst_ip.v4, &ct_cmd->daddr, 4);
        tuple->src_ip.is_ipv4 = TRUE;
        tuple->dst_ip.is_ipv4 = TRUE;
        tuple->sport = oal_ntohs(ct_cmd->sport);
        tuple->dport = oal_ntohs(ct_cmd->dport);
        tuple->proto = (uint8)(oal_ntohs(ct_cmd->protocol) & UINT8_MAX);
    }
}

/**
 * @brief       Convert CT command (IPv4) to reply 5 tuple representation
 * @param[in]   ct_cmd The command
 * @param[out]  tuple Pointer to location where output shall be written
 */
static void fci_connections_ipv4_cmd_to_5t_rep(const fpp_ct_cmd_t *ct_cmd, pfe_5_tuple_t *tuple)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct_cmd) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(tuple, 0, sizeof(pfe_5_tuple_t));

        (void)autolibc_memcpy(&tuple->src_ip.v4, &ct_cmd->saddr_reply, 4);
        (void)autolibc_memcpy(&tuple->dst_ip.v4, &ct_cmd->daddr_reply, 4);
        tuple->src_ip.is_ipv4 = TRUE;
        tuple->dst_ip.is_ipv4 = TRUE;
        tuple->sport = oal_ntohs(ct_cmd->sport_reply);
        tuple->dport = oal_ntohs(ct_cmd->dport_reply);
        tuple->proto = (uint8)(oal_ntohs(ct_cmd->protocol) & UINT8_MAX);
    }
}

/**
 * @brief       Convert CT command (IPv6) to 5 tuple representation
 * @param[in]   ct6_cmd The command
 * @param[out]  tuple Pointer to location where output shall be written
 */
static void fci_connections_ipv6_cmd_to_5t(const fpp_ct6_cmd_t *ct6_cmd, pfe_5_tuple_t *tuple)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct6_cmd) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(tuple, 0, sizeof(pfe_5_tuple_t));

        (void)autolibc_memcpy(&tuple->src_ip.v6, &ct6_cmd->saddr[0], 16);
        (void)autolibc_memcpy(&tuple->dst_ip.v6, &ct6_cmd->daddr[0], 16);
        tuple->src_ip.is_ipv4 = FALSE;
        tuple->dst_ip.is_ipv4 = FALSE;
        tuple->sport = oal_ntohs(ct6_cmd->sport);
        tuple->dport = oal_ntohs(ct6_cmd->dport);
        tuple->proto = (uint8)(oal_ntohs(ct6_cmd->protocol) & UINT8_MAX);
    }
}

/**
 * @brief       Convert CT command (IPv6) to reply 5 tuple representation
 * @param[in]   ct_cmd The command
 * @param[out]  tuple Pointer to location where output shall be written
 */
static void fci_connections_ipv6_cmd_to_5t_rep(const fpp_ct6_cmd_t *ct6_cmd, pfe_5_tuple_t *tuple)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct6_cmd) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(tuple, 0, sizeof(pfe_5_tuple_t));

        (void)autolibc_memcpy(&tuple->src_ip.v6, &ct6_cmd->saddr_reply[0], 16);
        (void)autolibc_memcpy(&tuple->dst_ip.v6, &ct6_cmd->daddr_reply[0], 16);
        tuple->src_ip.is_ipv4 = FALSE;
        tuple->dst_ip.is_ipv4 = FALSE;
        tuple->sport = oal_ntohs(ct6_cmd->sport_reply);
        tuple->dport = oal_ntohs(ct6_cmd->dport_reply);
        tuple->proto = (uint8)(oal_ntohs(ct6_cmd->protocol) & UINT8_MAX);
    }
}

static void create_entry_check_nat(pfe_rtable_entry_t **new_entry, const pfe_5_tuple_t *tuple, const pfe_5_tuple_t *tuple_rep)
{
    /*  Check if SRC IP NAT is requested */
    if (0 != autolibc_memcmp(&tuple->src_ip, &tuple_rep->dst_ip, sizeof(pfe_ip_addr_t)))
    {
        /*  SADDR need to be changed to DADDR_REPLY */
        if (EOK != pfe_rtable_entry_set_out_sip(*new_entry, &tuple_rep->dst_ip))
        {
            NXP_LOG_WARNING("Couldn't set output SIP\n");
            pfe_rtable_entry_free(NULL_PTR, *new_entry);
            *new_entry = NULL;
        }
    }

    if (NULL != *new_entry)
    {
        /*  Check if DST IP NAT is requested */
        if (0 != autolibc_memcmp(&tuple->dst_ip, &tuple_rep->src_ip, sizeof(pfe_ip_addr_t)))
        {
            /*  DADDR need to be changed to SADDR_REPLY */
            if (EOK != pfe_rtable_entry_set_out_dip(*new_entry, &tuple_rep->src_ip))
            {
                NXP_LOG_WARNING("Couldn't set output DIP\n");
                pfe_rtable_entry_free(NULL_PTR, *new_entry);
                *new_entry = NULL;
            }
        }

        if (NULL != *new_entry)
        {
            /*  Check if SRC PORT translation is requested */
            if (tuple->sport != tuple_rep->dport)
            {
                /*  SPORT need to be changed to DPORT_REPLY */
                pfe_rtable_entry_set_out_sport(*new_entry, tuple_rep->dport);
            }

            /*  Check if DST PORT translation is requested */
            if (tuple->dport != tuple_rep->sport)
            {
                /*  DPORT need to be changed to SPORT_REPLY */
                pfe_rtable_entry_set_out_dport(*new_entry, tuple_rep->sport);
            }
        }
    }
}

/**
 * @brief       Create routing table entry from given inputs
 * @details     Function creates new routing table entry and adjusts its properties according
 *              to given input values. The setup includes NAT configuration using differences
 *              between 'tuple' and 'tuple_rep' values. NAT then corresponds with given FCI
 *              commands (see documentation of FPP_CMD_IPV4_CONNTRACK and FPP_CMD_IPV6_CONNTRACK).
 * @param[in]   route Route to be used to create the entry. MAC address from route is used as
 *                    destination MAC address of forwarded packets.
 * @param[in]   tuple Original flow direction
 * @param[in]   tuple_rep Reply flow direction
 * @return      The routing table entry instance to be inserted into routing table or NULL if failed
 */
static pfe_rtable_entry_t *fci_connections_create_entry(const fci_rt_db_entry_t *route,
                                                            const pfe_5_tuple_t *tuple, const pfe_5_tuple_t *tuple_rep)
{
    pfe_rtable_entry_t *new_entry;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == route) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        new_entry = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Create new entry */
        new_entry = pfe_rtable_entry_create();
        if (NULL == new_entry)
        {
            NXP_LOG_ERROR("Couldn't create routing table entry\n");
        }
        else
        {
            /*  Set 5-tuple */
            if (EOK != pfe_rtable_entry_set_5t(new_entry, tuple))
            {
                NXP_LOG_WARNING("Can't set 5 tuple\n");
                pfe_rtable_entry_free(NULL_PTR, new_entry);
                new_entry = NULL;
            }
            else
            {
                /*  Set properties */
                (void)pfe_rtable_entry_set_dstif(new_entry, route->iface);
                pfe_rtable_entry_set_timeout(new_entry, fci_connections_get_default_timeout(tuple->proto));
                /*  Set route ID (network endian) */
                pfe_rtable_entry_set_route_id(new_entry, route->id);
                /*  Set ttl decrement by default */
                pfe_rtable_entry_set_ttl_decrement(new_entry);

                /*  Change MAC addresses */
                pfe_rtable_entry_set_out_mac_addrs(new_entry, route->src_mac, route->dst_mac);

                create_entry_check_nat(&new_entry, tuple, tuple_rep);
            }
        }
    }

    return new_entry;
}

/**
 * @brief       Convert CT command (IPv4) to a new routing table entry
 * @param[in]   ct_cmd The command
 * @param[out]  entry Pointer to memory where pointer to the new entry shall be written
 * @param[out]  iface Pointer where target interface instance shall be written
 * @return      EOK if success, error code otherwise
 */
static errno_t fci_connections_ipv4_cmd_to_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_rt_db_entry_t *route;
    pfe_5_tuple_t tuple_buf, tuple_rep_buf;
    pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct_cmd) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check if original direction is enabled */
        if (0U != (oal_ntohs(ct_cmd->flags) & CTCMD_FLAGS_ORIG_DISABLED))
        {
            /*  Original direction is disabled */
            *entry = NULL;
            *iface = NULL;
            ret = EOK;
        }
        else
        {
            /*  Get route */
            route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct_cmd->route_id);
            if (NULL == route)
            {
                NXP_LOG_WARNING("No such route (0x%x)\n", (uint_t)ct_cmd->route_id);
                ret = EINVAL;
            }
            else
            {
                /*  Get 5 tuples */
                fci_connections_ipv4_cmd_to_5t(ct_cmd, tuple);
                fci_connections_ipv4_cmd_to_5t_rep(ct_cmd, tuple_rep);

                /*  Create new entry for flow given by the 'tuple' */
                *entry = fci_connections_create_entry(route, tuple, tuple_rep);
                if (NULL == *entry)
                {
                    NXP_LOG_WARNING("Couldn't create routing rule\n");
                    ret = EINVAL;
                }
                else
                {
                    if (0U != ct_cmd->vlan)
                    {
                        pfe_rtable_entry_set_out_vlan(*entry, oal_ntohs(ct_cmd->vlan), TRUE);
                    }

                    /*  Return interface */
                    *iface = route->iface;
                    ret = EOK;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Convert CT command (IPv4) to a new routing table entry (reply direction)
 * @param[in]   ct_cmd The command
 * @param[out]  entry Pointer to memory where pointer to the new entry shall be written. NULL indicates
 *              that the reply direction is not requested.
 * @param[out]  iface Pointer where target interface instance shall be written. NULL indicates that the reply
 *              direction is not requested.
 * @return      EOK if success, error code otherwise
 */
static errno_t fci_connections_ipv4_cmd_to_rep_entry(const fpp_ct_cmd_t *ct_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_rt_db_entry_t *route;
    pfe_5_tuple_t tuple_buf, tuple_rep_buf;
    pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct_cmd) || (NULL == entry) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check if reply direction is enabled */
        if (0U != (oal_ntohs(ct_cmd->flags) & CTCMD_FLAGS_REP_DISABLED))
        {
            /*  Reply direction is disabled */
            *entry = NULL;
            *iface = NULL;
            ret = EOK;
        }
        else
        {
            /*  Get route */
            route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct_cmd->route_id_reply);
            if (NULL == route)
            {
                NXP_LOG_WARNING("No such route (0x%x)\n", (uint_t)oal_ntohl(ct_cmd->route_id_reply));
                ret = EINVAL;
            }
            else
            {
                /*  Get 5 tuples. Reply entries are created using 'reply' values of CT commands. */
                fci_connections_ipv4_cmd_to_5t(ct_cmd, tuple_rep);
                fci_connections_ipv4_cmd_to_5t_rep(ct_cmd, tuple);

                /*  Create new entry for flow given by the 'tuple' */
                *entry = fci_connections_create_entry(route, tuple, tuple_rep);
                if (NULL == *entry)
                {
                    NXP_LOG_WARNING("Couldn't create 'reply' routing rule\n");
                    ret = EINVAL;
                }
                else
                {
                    if (0U != ct_cmd->vlan_reply)
                    {
                        pfe_rtable_entry_set_out_vlan(*entry, oal_ntohs(ct_cmd->vlan_reply), TRUE);
                    }

                    /*  Return interface */
                    *iface = route->iface;
                    ret = EOK;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Convert CT command (IPv6) to a new routing table entry
 * @param[in]   ct6_cmd The command
 * @param[out]  entry Pointer to memory where pointer to the new entry shall be written
 * @param[out]  iface Pointer where target interface instance shall be written
 * @return      EOK if success, error code otherwise
 */
static errno_t fci_connections_ipv6_cmd_to_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_rt_db_entry_t *route;
    pfe_5_tuple_t tuple_buf, tuple_rep_buf;
    pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct6_cmd) || (NULL == entry) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Check if original direction is enabled */
        if (0U != (oal_ntohs(ct6_cmd->flags) & CTCMD_FLAGS_ORIG_DISABLED))
        {
            /*  Original direction is disabled */
            *entry = NULL;
            ret = EOK;
        }
        else
        {
            /*  Get route */
            route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct6_cmd->route_id);
            if (NULL == route)
            {
                NXP_LOG_WARNING("No such route (0x%x)\n", (uint_t)ct6_cmd->route_id);
                ret = EINVAL;
            }
            else
            {
                /*  Get 5 tuples */
                fci_connections_ipv6_cmd_to_5t(ct6_cmd, tuple);
                fci_connections_ipv6_cmd_to_5t_rep(ct6_cmd, tuple_rep);

                /*  Create new entry for flow given by the 'tuple' */
                *entry = fci_connections_create_entry(route, tuple, tuple_rep);
                if (NULL == *entry)
                {
                    NXP_LOG_WARNING("Couldn't create routing rule\n");
                    ret =  EINVAL;
                }
                else
                {
                    if (0U != ct6_cmd->vlan)
                    {
                        pfe_rtable_entry_set_out_vlan(*entry, oal_ntohs(ct6_cmd->vlan), TRUE);
                    }

                    /*  Return interface */
                    *iface = route->iface;
                    ret = EOK;
                }
            }
        }
    }
    return ret;
}

/**
 * @brief       Convert CT command (IPv6) to a new routing table entry (reply direction)
 * @param[in]   ct_cmd The command
 * @param[out]  entry Pointer to memory where pointer to the new entry shall be written. NULL indicates
 *              that the reply direction is not requested.
 * @param[out]  iface Pointer where target interface instance shall be written. NULL indicates that the
 *              reply direction is not requested.
 * @return      EOK if success, error code otherwise
 */
static errno_t fci_connections_ipv6_cmd_to_rep_entry(const fpp_ct6_cmd_t *ct6_cmd, pfe_rtable_entry_t **entry, pfe_phy_if_t **iface)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_rt_db_entry_t *route;
    pfe_5_tuple_t tuple_buf, tuple_rep_buf;
    pfe_5_tuple_t *tuple = &tuple_buf, *tuple_rep = &tuple_rep_buf;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ct6_cmd) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Check if reply direction is enabled */
        if (0U != (oal_ntohs(ct6_cmd->flags) & CTCMD_FLAGS_REP_DISABLED))
        {
            /*  Reply direction is disabled */
            *entry = NULL;
            *iface = NULL;
            ret = EOK;
        }
        else
        {
            /*  Get route */
            route = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_BY_ID, (const void *)&ct6_cmd->route_id_reply);
            if (NULL == route)
            {
                NXP_LOG_WARNING("No such route (0x%x)\n", (uint_t)oal_ntohl(ct6_cmd->route_id_reply));
                ret = EINVAL;
            }
            else
            {
                /*  Get 5 tuples. Reply entries are created using 'reply' values of CT commands. */
                fci_connections_ipv6_cmd_to_5t(ct6_cmd, tuple_rep);
                fci_connections_ipv6_cmd_to_5t_rep(ct6_cmd, tuple);

                /*  Create new entry for flow given by the 'tuple' */
                *entry = fci_connections_create_entry(route, tuple, tuple_rep);
                if (NULL == *entry)
                {
                    NXP_LOG_WARNING("Couldn't create 'reply' routing rule\n");
                    ret = EINVAL;
                }
                else
                {
                    if (0U != ct6_cmd->vlan_reply)
                    {
                        pfe_rtable_entry_set_out_vlan(*entry, oal_ntohs(ct6_cmd->vlan_reply), TRUE);
                    }

                    /*  Return interface */
                    *iface = route->iface;
                    ret = EOK;
                }
            }
        }
    }

    return ret;
}

/* Auxiliary function for fci_connections_ipvx_ct_cmd: check args validity, check fci_context and clear reply buffer */
static errno_t ipvx_ct_check_args_clear_buf(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        const uint32 reply_len_required = ipv6 ? sizeof(fpp_ct6_cmd_t) : sizeof(fpp_ct_cmd_t);
        if (*reply_len < reply_len_required)
        {
            NXP_LOG_DEBUG("Buffer length does not match expected value (fpp_ct_cmd_t or fpp_ct6_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, reply_len_required);
        }
    }

    (void) msg;
    (void) fci_ret;
    return ret; 
}

/* Get new routing table entry in forward and reply direction. Returns fci_ret
 * FPP_ERR_WRONG_COMMAND_PARAM if cannot conver command to valied entry, FPP_ERR_OK othervise. */
static uint16 ipvx_ct_register_get_rtable_entries(bool_t ipv6,
                                                    const fci_msg_t *msg,
                                                    pfe_rtable_entry_t **entry,
                                                    pfe_rtable_entry_t **rep_entry)
{
    const fpp_ct_cmd_t *ct_cmd = (fpp_ct_cmd_t *)(msg->msg_cmd.payload);
    const fpp_ct6_cmd_t *ct6_cmd = (fpp_ct6_cmd_t *)(msg->msg_cmd.payload);
    uint16 fci_ret = FPP_ERR_OK;
    pfe_phy_if_t *phy_if = NULL;
    errno_t result = EOK;

    /*  Get new routing table entry in forward direction */
    if (TRUE == ipv6)
    {
        result = fci_connections_ipv6_cmd_to_entry(ct6_cmd, entry, &phy_if);
    }
    else
    {
        result = fci_connections_ipv4_cmd_to_entry(ct_cmd, entry, &phy_if);
    }

    if (EINVAL == result)
    {
        NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Couldn't convert command to valid entry\n");
        fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
    }
    else
    {
        /*  Get new routing table entry in reply direction */
        if (TRUE == ipv6)
        {
            result = fci_connections_ipv6_cmd_to_rep_entry(ct6_cmd, rep_entry, &phy_if);
        }
        else
        {
            result = fci_connections_ipv4_cmd_to_rep_entry(ct_cmd, rep_entry, &phy_if);
        }

        if (EINVAL == result)
        {
            NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Couldn't convert command to valid entry (reply direction)\n");
            fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        }
    }

    (void) phy_if;
    return fci_ret;
}

/* Add entry into routing table */
static errno_t ipvx_ct_register_add_entry(void *client, uint16 *fci_ret, pfe_rtable_entry_t **entry, pfe_rtable_entry_t **rep_entry)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    /*  Remember that there is an associated entry */
    pfe_rtable_entry_set_child(*entry, *rep_entry);
    pfe_rtable_entry_set_refptr(*entry, client);

    ret = pfe_rtable_add_entry(fci_context->rtable, *entry);
    if (EEXIST == ret)
    {
        NXP_LOG_WARNING("FPP_CMD_IPVx_CONNTRACK: Entry already added\n");
        *fci_ret = FPP_ERR_RT_ENTRY_ALREADY_REGISTERED;
        if (EOK != pfe_rtable_del_entry(fci_context->rtable, *entry))
        {
            NXP_LOG_WARNING("Can't remove route entry\n");
        }

        pfe_rtable_entry_free(fci_context->rtable, *entry);
        *entry = NULL;

        if (NULL != *rep_entry)
        {
            if (EOK != pfe_rtable_del_entry(fci_context->rtable, *rep_entry))
            {
                NXP_LOG_WARNING("Can't remove route entry\n");
            }

            pfe_rtable_entry_free(fci_context->rtable, *rep_entry);
            *rep_entry = NULL;
        }
    }
    else if (EOK != ret)
    {
        NXP_LOG_WARNING("FPP_CMD_IPVx_CONNTRACK: Can't add entry: %d\n", ret);
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        if (EOK != pfe_rtable_del_entry(fci_context->rtable, *entry))
        {
            NXP_LOG_WARNING("Can't remove route entry\n");
        }

        pfe_rtable_entry_free(fci_context->rtable, *entry);
        *entry = NULL;

        if (NULL != *rep_entry)
        {
            if (EOK != pfe_rtable_del_entry(fci_context->rtable, *rep_entry))
            {
                NXP_LOG_WARNING("Can't remove route entry\n");
            }

            pfe_rtable_entry_free(fci_context->rtable, *rep_entry);
            *rep_entry = NULL;
        }
    }
    else
    {
        NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry added\n");
        *fci_ret = FPP_ERR_OK;
    }

    return ret;
}

/* Add reply entry into routing table */
static errno_t ipvx_ct_register_add_rep_entry(uint16 *fci_ret, pfe_rtable_entry_t **entry, pfe_rtable_entry_t **rep_entry)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;

    ret = pfe_rtable_add_entry(fci_context->rtable, *rep_entry);
    if (EEXIST == ret)
    {
        NXP_LOG_WARNING("FPP_CMD_IPVx_CONNTRACK: Reply entry already added\n");
    }
    else if (EOK != ret)
    {
        NXP_LOG_WARNING("FPP_CMD_IPVx_CONNTRACK: Can't add reply entry: %d\n", ret);
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        if (NULL != *entry)
        {
            if (EOK != pfe_rtable_del_entry(fci_context->rtable, *entry))
            {
                NXP_LOG_WARNING("Can't remove route entry\n");
            }

            pfe_rtable_entry_free(fci_context->rtable, *entry);
            *entry = NULL;
        }

        if (EOK != pfe_rtable_del_entry(fci_context->rtable, *rep_entry))
        {
            NXP_LOG_WARNING("Can't remove route entry\n");
        }

        pfe_rtable_entry_free(fci_context->rtable, *rep_entry);
        *rep_entry = NULL;
    }
    else
    {
        NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry added (reply direction)\n");
        *fci_ret = FPP_ERR_OK;
    }

    return ret;
}

/* Process FCI conntrack command action FPP_ACTION_REGISTER */
static errno_t ipvx_ct_register(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret)
{
    errno_t ret = EOK;
    pfe_rtable_entry_t *entry = NULL_PTR, *rep_entry = NULL_PTR;

    *fci_ret = ipvx_ct_register_get_rtable_entries(ipv6, msg, &entry, &rep_entry);
    if (FPP_ERR_OK == *fci_ret)
    {
    /*  Add entry into the routing table */
        if (NULL_PTR != entry)
        {
            ret = ipvx_ct_register_add_entry(msg->client, fci_ret, &entry, &rep_entry);
        }

        /*  Add entry also for reply direction if requested */
        if (NULL_PTR != rep_entry)
        {
            ret = ipvx_ct_register_add_rep_entry(fci_ret, &entry, &rep_entry);
        }
    }
    return ret;
}

/* Process FCI conntrack command action FPP_ACTION_DEREGISTER */
static errno_t ipvx_ct_deregister(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_rtable_entry_t *entry = NULL_PTR, *rep_entry = NULL_PTR;
    errno_t ret = EOK;
    pfe_5_tuple_t tuple;
    *fci_ret = FPP_ERR_OK;

    if (TRUE == ipv6)
    {
        const fpp_ct6_cmd_t *ct6_cmd = (const fpp_ct6_cmd_t *)(msg->msg_cmd.payload);
        fci_connections_ipv6_cmd_to_5t(ct6_cmd, &tuple);
    }
    else
    {
        const fpp_ct_cmd_t *ct_cmd = (const fpp_ct_cmd_t *)(msg->msg_cmd.payload);
        fci_connections_ipv4_cmd_to_5t(ct_cmd, &tuple);
    }

    entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_BY_5_TUPLE, (void *)&tuple);

    /*  Delete the entries from table */
    if (NULL_PTR != entry)
    {
        /*  Get associated entry */
        rep_entry = pfe_rtable_entry_get_child(fci_context->rtable, entry);

        ret = pfe_rtable_del_entry(fci_context->rtable, entry);
        if (EOK != ret)
        {
            /* Notify rtable module we are done working with this rtable entry */
            pfe_rtable_entry_free(fci_context->rtable, entry);
            NXP_LOG_WARNING("Can't remove route entry: %d\n", ret);
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        }
        else
        {
            /*  Release all entry-related resources */
            NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry removed\n");
            pfe_rtable_entry_free(fci_context->rtable, entry);
            
            /*  Delete also the reply direction */
            if (NULL_PTR != rep_entry)
            {
                ret = pfe_rtable_del_entry(fci_context->rtable, rep_entry);
                if (EOK != ret)
                {
                    /* Notify rtable module we are done working with this rtable entry */
                    pfe_rtable_entry_free(fci_context->rtable, rep_entry);
                    NXP_LOG_WARNING("Can't remove reply route entry: %d\n", ret);
                    *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                }
                else
                {
                    /*  Release all entry-related resources */
                    NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry removed (reply direction)\n");
                    pfe_rtable_entry_free(fci_context->rtable, rep_entry);
                }
            }
        }
    }
    else
    {
        NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry not found\n");
        *fci_ret = FPP_ERR_CT_ENTRY_NOT_FOUND;
    }

    return ret;
}

/* Process FCI conntrack command action FPP_ACTION_UPDATE */
static errno_t ipvx_ct_update(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_rtable_entry_t *entry = NULL_PTR;
    errno_t ret = EOK;
    pfe_5_tuple_t tuple;
    const fpp_ct6_cmd_t *ct6_cmd = NULL_PTR;
    const fpp_ct_cmd_t *ct_cmd = NULL_PTR;

    NXP_LOG_INFO("UPDATED conntrack, only TTL decrement flag will be updated\n");

    if (TRUE == ipv6)
    {
        ct6_cmd = (const fpp_ct6_cmd_t *)(msg->msg_cmd.payload);
        fci_connections_ipv6_cmd_to_5t(ct6_cmd, &tuple);
    }
    else
    {
        ct_cmd = (const fpp_ct_cmd_t *)(msg->msg_cmd.payload);
        fci_connections_ipv4_cmd_to_5t(ct_cmd, &tuple);
    }

    entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_BY_5_TUPLE, (void *)&tuple);

    if (NULL_PTR != entry)
    {
        if (TRUE == ipv6)
        {
            if ((oal_ntohs(ct6_cmd->flags) & CTCMD_FLAGS_TTL_DECREMENT) != 0U)
            {
                pfe_rtable_entry_set_ttl_decrement(entry);
            }
            else
            {
                pfe_rtable_entry_remove_ttl_decrement(entry);
            }
        }
        else
        {
            if ((oal_ntohs(ct_cmd->flags) & CTCMD_FLAGS_TTL_DECREMENT) != 0U)
            {
                pfe_rtable_entry_set_ttl_decrement(entry);
            }
            else
            {
                pfe_rtable_entry_remove_ttl_decrement(entry);
            }
        }

        /* Notify rtable module we are done working with this rtable entry */
        pfe_rtable_entry_free(fci_context->rtable, entry);

        *fci_ret = FPP_ERR_OK;
        ret = EOK;

    }
    else
    {
        NXP_LOG_DEBUG("FPP_CMD_IPVx_CONNTRACK: Entry not found\n");
        *fci_ret = FPP_ERR_CT_ENTRY_NOT_FOUND;
        ret = EEXIST;
    }

    return ret;
}

/* Compile NAT modifications for FCI reply for query request (IPV4) */
static void ipvx_ct_compile_fci_reply_nat_modifications_ipv4(   fpp_ct_cmd_t *ct_reply,
                                                                pfe_ct_route_actions_t actions,
                                                                const pfe_5_tuple_t *tuple)
{
    if (0U != ((uint32)actions & (uint32)RT_ACT_DEC_TTL))
    {
        ct_reply->flags |= oal_htons(CTCMD_FLAGS_TTL_DECREMENT);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_SIP_ADDR))
    {
        (void)autolibc_memcpy(&ct_reply->daddr_reply, &tuple->src_ip.v4, 4);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_DIP_ADDR))
    {
        (void)autolibc_memcpy(&ct_reply->saddr_reply, &tuple->dst_ip.v4, 4);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_SPORT))
    {
        ct_reply->dport_reply = oal_htons(tuple->sport);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_DPORT))
    {
        ct_reply->sport_reply = oal_htons(tuple->dport);
    }
}

/* Compile NAT modifications for FCI reply for query request (IPV6) */
static void ipvx_ct_compile_fci_reply_nat_modifications_ipv6(   fpp_ct6_cmd_t *ct6_reply,
                                                                pfe_ct_route_actions_t actions,
                                                                const pfe_5_tuple_t *tuple)
{
    if (0U != ((uint32)actions & (uint32)RT_ACT_DEC_TTL))
    {
        ct6_reply->flags |= oal_htons(CTCMD_FLAGS_TTL_DECREMENT);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_SIP_ADDR))
    {
        (void)autolibc_memcpy(ct6_reply->daddr_reply, &tuple->src_ip.v6, 16);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_DIP_ADDR))
    {
        (void)autolibc_memcpy(ct6_reply->saddr_reply, &tuple->dst_ip.v6, 16);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_SPORT))
    {
        ct6_reply->dport_reply = oal_htons(tuple->sport);
    }

    if (0U != ((uint32)actions & (uint32)RT_ACT_CHANGE_DPORT))
    {
        ct6_reply->sport_reply = oal_htons(tuple->dport);
    }
}

/* Compile FCI reply for query request */
static void ipvx_ct_compile_fci_reply_basic(bool_t ipv6, void *reply_buf, pfe_rtable_entry_t *entry)
{
    const fci_t *fci_context = (fci_t *)&context;
    fpp_ct6_cmd_t *ct6_reply = (fpp_ct6_cmd_t *)(reply_buf);
    fpp_ct_cmd_t *ct_reply = (fpp_ct_cmd_t *)(reply_buf);
    pfe_ct_conntrack_stats_t stats = {0U};
    pfe_ip_addr_t sip = {0U}, dip = {0U};
    uint32 route_id = 0U;
    uint16 vlan;
    
    /*  Prepare statistics data */
    errno_t ret = pfe_rtable_get_stats(fci_context->rtable, &stats, pfe_rtable_entry_get_stats_index(entry));
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Failed to get routing entry statistics: %d", ret);
    }

    /*  Build reply structure */
    pfe_rtable_entry_get_sip(entry, &sip);
    pfe_rtable_entry_get_dip(entry, &dip);
    (void)pfe_rtable_entry_get_route_id(entry, &route_id);
    vlan = pfe_rtable_entry_get_out_vlan(entry);

    if (TRUE == ipv6)
    {
        (void)autolibc_memcpy(ct6_reply->saddr, &sip.v6, 16);
        (void)autolibc_memcpy(ct6_reply->daddr, &dip.v6, 16);
        ct6_reply->sport = oal_htons(pfe_rtable_entry_get_sport(entry));
        ct6_reply->dport = oal_htons(pfe_rtable_entry_get_dport(entry));
        ct6_reply->vlan = oal_htons(vlan);
        (void)autolibc_memcpy(ct6_reply->saddr_reply, ct6_reply->daddr, 16);
        (void)autolibc_memcpy(ct6_reply->daddr_reply, ct6_reply->saddr, 16);
        ct6_reply->sport_reply = ct6_reply->dport;
        ct6_reply->dport_reply = ct6_reply->sport;
        ct6_reply->protocol = oal_ntohs(pfe_rtable_entry_get_proto(entry));
        ct6_reply->flags = 0U;
        ct6_reply->route_id = route_id;
        ct6_reply->stats.hit = oal_htonl(stats.hit);
        ct6_reply->stats.hit_bytes = oal_htonl(stats.hit_bytes);
    }
    else
    {
        (void)autolibc_memcpy(&ct_reply->saddr, &sip.v4, 4);
        (void)autolibc_memcpy(&ct_reply->daddr, &dip.v4, 4);
        ct_reply->sport = oal_htons(pfe_rtable_entry_get_sport(entry));
        ct_reply->dport = oal_htons(pfe_rtable_entry_get_dport(entry));
        ct_reply->vlan = oal_htons(vlan);
        (void)autolibc_memcpy(&ct_reply->saddr_reply, &ct_reply->daddr, 4);
        (void)autolibc_memcpy(&ct_reply->daddr_reply, &ct_reply->saddr, 4);
        ct_reply->sport_reply = ct_reply->dport;
        ct_reply->dport_reply = ct_reply->sport;
        ct_reply->protocol = oal_ntohs(pfe_rtable_entry_get_proto(entry));
        ct_reply->flags = 0U;
        ct_reply->route_id = route_id;
        ct_reply->stats.hit = oal_htonl(stats.hit);
        ct_reply->stats.hit_bytes = oal_htonl(stats.hit_bytes);
    }
}

/* Compile FCI reply (reply direction) for query request */
static void ipvx_ct_compile_fci_reply_replydir(bool_t ipv6, void *reply_buf, pfe_rtable_entry_t *entry)
{
    const fci_t *fci_context = (fci_t *)&context;
    fpp_ct6_cmd_t *ct6_reply = (fpp_ct6_cmd_t *)(reply_buf);
    fpp_ct_cmd_t *ct_reply = (fpp_ct_cmd_t *)(reply_buf);
    pfe_ct_conntrack_stats_t stats = {0U};
    uint16 vlan;
    pfe_rtable_entry_t *rep_entry;

    /*  Check if reply direction does exist */
    rep_entry = pfe_rtable_entry_get_child(fci_context->rtable, entry);
    if (NULL == rep_entry)
    {
        /*  This means that entry in 'reply' direction has not been requested
            so the appropriate flag shall be set to indicate that. */
        if (TRUE == ipv6)
        {
            ct6_reply->flags |= oal_htons(CTCMD_FLAGS_REP_DISABLED);
        }
        else
        {
            ct_reply->flags |= oal_htons(CTCMD_FLAGS_REP_DISABLED);
        }
    }
    else
    {
        /*  Prepare reply direction statistics data */
        errno_t ret = pfe_rtable_get_stats(fci_context->rtable, &stats, pfe_rtable_entry_get_stats_index(rep_entry));
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Failed to get reply routing entry statistics: %d", ret);
        }

        /*  Prepare reply direction vlan data */
        vlan = pfe_rtable_entry_get_out_vlan(rep_entry);
        if (TRUE == ipv6)
        {
            ct6_reply->vlan_reply = oal_htons(vlan);
            ct6_reply->stats_reply.hit = oal_htonl(stats.hit);
            ct6_reply->stats_reply.hit_bytes = oal_htonl(stats.hit_bytes);
        }
        else
        {
            ct_reply->vlan_reply = oal_htons(vlan);
            ct_reply->stats_reply.hit = oal_htonl(stats.hit);
            ct_reply->stats_reply.hit_bytes = oal_htonl(stats.hit_bytes);
        }

        pfe_rtable_entry_free(fci_context->rtable, rep_entry);
    }
}

/* Compile FCI reply for query request */
static void ipvx_ct_compile_fci_reply(  bool_t ipv6,
                                        pfe_rtable_entry_t *entry,
                                        void *reply_buf,
                                        uint32 *reply_len)
{
    fpp_ct6_cmd_t *ct6_reply = (fpp_ct6_cmd_t *)(reply_buf);
    fpp_ct_cmd_t *ct_reply = (fpp_ct_cmd_t *)(reply_buf);
    pfe_5_tuple_t tuple;

    /*  Set the reply length */
    if (TRUE == ipv6)
    {
        *reply_len = sizeof(fpp_ct6_cmd_t);
    }
    else
    {
        *reply_len = sizeof(fpp_ct_cmd_t);
    }
    
    ipvx_ct_compile_fci_reply_basic(ipv6, reply_buf, entry);
    ipvx_ct_compile_fci_reply_replydir(ipv6, reply_buf, entry);

    /*
        Check if some modifications (NAT) are enabled. If so, update the
        'reply' direction values as defined by the FCI API. Note that
        modification are enabled when entry is being added. See
        FPP_ACTION_REGISTER and fci_connections_create_entry().
    */
    const pfe_ct_route_actions_t actions = pfe_rtable_entry_get_action_flags(entry);
    if (EOK != pfe_rtable_entry_to_5t_out(entry, &tuple))
    {
        NXP_LOG_ERROR("Couldn't get output tuple\n");
    }
    if (TRUE == ipv6)
    {
        ipvx_ct_compile_fci_reply_nat_modifications_ipv6(ct6_reply, actions, &tuple);
    }
    else
    {
        ipvx_ct_compile_fci_reply_nat_modifications_ipv4(ct_reply, actions, &tuple);
    }
}

/* Process FCI conntrack command action FPP_ACTION_QUERY */
static void ipvx_ct_query(bool_t ipv6, uint16 *fci_ret, void *reply_buf, uint32 *reply_len)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_rtable_entry_t *entry = NULL_PTR;

    pfe_rtable_get_criterion_t crit = (TRUE == ipv6) ? RTABLE_CRIT_ALL_IPV6 : RTABLE_CRIT_ALL_IPV4;

    entry = pfe_rtable_get_first(fci_context->rtable, crit, NULL);
    if (NULL_PTR == entry)
    {
        *fci_ret = FPP_ERR_CT_ENTRY_NOT_FOUND;
    }
    else
    {
        ipvx_ct_compile_fci_reply(ipv6, entry, reply_buf, reply_len);
        *fci_ret = FPP_ERR_OK;

        /* Notify rtable module we are done working with this rtable entry */
        pfe_rtable_entry_free(fci_context->rtable, entry);
    }
}

/* Process FCI conntrack command action FPP_ACTION_QUERY_CONT */
static void ipvx_ct_query_cont(bool_t ipv6, uint16 *fci_ret, void *reply_buf, uint32 *reply_len)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_rtable_entry_t *entry = NULL_PTR;

    entry = pfe_rtable_get_next(fci_context->rtable);
    if (NULL_PTR == entry)
    {
        *fci_ret = FPP_ERR_CT_ENTRY_NOT_FOUND;
    }
    else
    {
        ipvx_ct_compile_fci_reply(ipv6, entry, reply_buf, reply_len);
        *fci_ret = FPP_ERR_OK;

        /* Notify rtable module we are done working with this rtable entry */
        pfe_rtable_entry_free(fci_context->rtable, entry);
    }
}




/**
 * @brief           Process FPP_CMD_IPV4_CONNTRACK/FPP_CMD_IPV6_CONNTRACK commands
 * @param[in]       ipv6 If TRUE then message carries FPP_CMD_IPV6_CONNTRACK. Else it contains FPP_CMD_IPV4_CONNTRACK.
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_ct_cmd_t/fpp_ct6_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with route DB protected against concurrent accesses.
 */
static errno_t fci_connections_ipvx_ct_cmd(bool_t ipv6, const fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len)
{
    errno_t ret = EOK;

    ret = ipvx_ct_check_args_clear_buf(ipv6, msg, fci_ret, reply_buf, reply_len);
    if (EOK == ret)
    {
        fpp_ct_cmd_t *ct_cmd = (fpp_ct_cmd_t *)(msg->msg_cmd.payload);

    #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
    #ifdef NXP_LOG_ENABLED
        const char *debug_ip = "";
        const char *debug_cntk_info = "";
        ipvx_prepare_debug_snippets(ipv6, msg, &debug_ip, &debug_cntk_info);
    #endif /* NXP_LOG_ENABLED */
    #endif /* PFE_CFG_VERBOSITY_LEVEL */

        switch (ct_cmd->action)
        {
            case FPP_ACTION_REGISTER:
            #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
                NXP_LOG_DEBUG("Attempt to register %s connection:\n%s\n", debug_ip, debug_cntk_info);
            #endif /* PFE_CFG_VERBOSITY_LEVEL */

                ret = ipvx_ct_register(ipv6, msg, fci_ret);
                break;

            case FPP_ACTION_DEREGISTER:
            #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
                NXP_LOG_DEBUG("Attempt to deregister %s connection:\n%s\n", debug_ip, debug_cntk_info);
            #endif /* PFE_CFG_VERBOSITY_LEVEL */

                ret = ipvx_ct_deregister(ipv6, msg, fci_ret);
                break;

            case FPP_ACTION_UPDATE:
            #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
                NXP_LOG_DEBUG("Attempt to update %s connection:\n%s\n", debug_ip, debug_cntk_info);
            #endif /* PFE_CFG_VERBOSITY_LEVEL */

                ret = ipvx_ct_update(ipv6, msg, fci_ret);
                break;

            case FPP_ACTION_QUERY:
                ipvx_ct_query(ipv6, fci_ret, reply_buf, reply_len);
                ret = EOK;
                break;

            case FPP_ACTION_QUERY_CONT:
                ipvx_ct_query_cont(ipv6, fci_ret, reply_buf, reply_len);
                ret = EOK;
                break;

            default:
                NXP_LOG_WARNING("Connection Command: Unknown action received: 0x%x\n", ct_cmd->action);
                *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                break;
        }
    }
    return ret;
}

/**
 * @brief           Process FPP_CMD_IPV4_CONNTRACK command
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_ct_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with route DB protected against concurrent accesses.
 * @note            Input values passed via fpp_ct_cmd_t are in __NETWORK__ endian format.
 */
errno_t fci_connections_ipv4_ct_cmd(const fci_msg_t *msg, uint16 *fci_ret, fpp_ct_cmd_t *reply_buf, uint32 *reply_len)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = fci_connections_ipvx_ct_cmd(FALSE, msg, fci_ret, (void *)reply_buf, reply_len);
    }
    return ret;
}

/**
 * @brief           Process FPP_CMD_IPV6_CONNTRACK command
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_ct6_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with route DB protected against concurrent accesses.
 * @note            Input values passed via fpp_ct_cmd_t are in __NETWORK__ endian format.
 */
errno_t fci_connections_ipv6_ct_cmd(const fci_msg_t *msg, uint16 *fci_ret, fpp_ct6_cmd_t *reply_buf, uint32 *reply_len)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = fci_connections_ipvx_ct_cmd(TRUE, msg, fci_ret, (void *)reply_buf, reply_len);
    }
    return ret;
}

/**
 * @brief           Process FPP_CMD_IPV4_SET_TIMEOUT commands
 * @param[in]       msg FCI message containing the FPP_CMD_IPV4_SET_TIMEOUT command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_ct_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with route DB protected against concurrent accesses.
 * @note            Since command and the function name refers to IPv4, all connections including IPv6 are
 *                  being updated. This is because of the legacy implementation and missing the dedicated
 *                  FPP_CMD_IPV6_SET_TIMEOUT command.
 */
errno_t fci_connections_ipv4_timeout_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_timeout_cmd_t *reply_buf, uint32 *reply_len)
{
    const fci_t *fci_context = (fci_t *)&context;
    fpp_timeout_cmd_t *timeout_cmd;
    pfe_rtable_entry_t *entry = NULL;
    uint8 proto;
    uint32 timeout;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_timeout_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_timeout_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_timeout_cmd_t));

            timeout_cmd = (fpp_timeout_cmd_t *)(msg->msg_cmd.payload);

            /*  Update FCI-wide defaults applicable for new connections */
            if (EOK != fci_connections_set_default_timeout((uint8)(oal_ntohs(timeout_cmd->protocol) & UINT8_MAX), oal_ntohl(timeout_cmd->timeout_value1)))
            {
                NXP_LOG_WARNING("Can't set default timeout\n");
            }
            else
            {
                NXP_LOG_DEBUG("Default timeout for protocol %u set to %u seconds\n", (uint_t)oal_ntohs(timeout_cmd->protocol), (uint_t)oal_ntohl(timeout_cmd->timeout_value1));
            }

            /*  Update existing connections */
            entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_ALL, NULL);
            while (NULL != entry)
            {
                proto = pfe_rtable_entry_get_proto(entry);
                timeout = fci_connections_get_default_timeout(proto);
                pfe_rtable_entry_set_timeout(entry, timeout);

                /* Notify rtable module we are done working with this rtable entry */
                pfe_rtable_entry_free(fci_context->rtable, entry);
                
                entry = pfe_rtable_get_next(fci_context->rtable);
            }

            *fci_ret = FPP_ERR_OK;
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Remove a single connection, inform clients
 * @param[in]   entry The routing table entry to be removed
 * @note        Function is only called within the FCI worker thread context.
 * @note        Must run with route DB protected against concurrent accesses.
 */
errno_t fci_connections_drop_one(pfe_rtable_entry_t *entry)
{
    const fci_t *fci_context = (fci_t *)&context;
    fpp_ct_cmd_t *ct_cmd = NULL;
    fpp_ct6_cmd_t *ct6_cmd = NULL;
    fci_msg_t msg;
    fci_core_client_t *client;
    pfe_5_tuple_t tuple = {0U};
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_rtable_entry_to_5t(entry, &tuple);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Can't convert entry to 5 tuple: %d\n", ret);
        }
        else
        {
            (void)autolibc_memset(&msg, 0, sizeof(fci_msg_t));
            msg.type = FCI_MSG_CMD;

            if (TRUE == tuple.src_ip.is_ipv4)
            {
        #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
                /*  IPv4 */
                NXP_LOG_DEBUG("Removing IPv4 connection:\n%s\n", fci_connections_entry_to_str(entry));
        #endif /* PFE_CFG_VERBOSITY_LEVEL */

                client = (fci_core_client_t *)pfe_rtable_entry_get_refptr(entry);
                if (NULL != client)
                {
                    msg.msg_cmd.code = FPP_CMD_IPV4_CONNTRACK;
                    ct_cmd = (fpp_ct_cmd_t *)msg.msg_cmd.payload;
                    ct_cmd->action = FPP_ACTION_REMOVED;

                    (void)autolibc_memcpy(&ct_cmd->saddr, &tuple.src_ip.v4, 4);
                    (void)autolibc_memcpy(&ct_cmd->daddr, &tuple.dst_ip.v4, 4);
                    ct_cmd->sport = oal_htons(tuple.sport);
                    ct_cmd->dport = oal_htons(tuple.dport);
                    ct_cmd->protocol = oal_htons(tuple.proto);

                    ret = fci_core_client_send(client, &msg, NULL);
                    if (EOK != ret)
                    {
                        NXP_LOG_WARNING("Could not notify FCI client\n");
                    }
                }
                else
                {
                    ; /*    No client ID, notification not required */
                }
            }
            else
            {
        #if (PFE_CFG_VERBOSITY_LEVEL >= 8)
                /*  IPv6 */
                NXP_LOG_DEBUG("Removing IPv6 connection:\n%s\n", fci_connections_entry_to_str(entry));
        #endif /* PFE_CFG_VERBOSITY_LEVEL */

                client = (fci_core_client_t *)pfe_rtable_entry_get_refptr(entry);
                if (NULL != client)
                {
                    msg.msg_cmd.code = FPP_CMD_IPV6_CONNTRACK;
                    ct6_cmd = (fpp_ct6_cmd_t *)msg.msg_cmd.payload;
                    ct6_cmd->action = FPP_ACTION_REMOVED;

                    (void)autolibc_memcpy(&ct6_cmd->saddr[0], &tuple.src_ip.v6, 16);
                    (void)autolibc_memcpy(&ct6_cmd->daddr[0], &tuple.dst_ip.v6, 16);
                    ct6_cmd->sport = oal_htons(tuple.sport);
                    ct6_cmd->dport = oal_htons(tuple.dport);
                    ct6_cmd->protocol = oal_htons(tuple.proto);

                    ret = fci_core_client_send(client, &msg, NULL);
                    if (EOK != ret)
                    {
                        NXP_LOG_WARNING("Could not notify FCI client\n");
                    }
                }
                else
                {
                    ; /*    No client ID, notification not required */
                }
            }

            /*  Remove entry from the routing table */
            ret = pfe_rtable_del_entry(fci_context->rtable, entry);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Fatal: Can't remove rtable entry = memory leak\n");
            }
            else
            {
                ; /* Release (deallocation) of the entry is done by the caller. */
            }
        }
    }

    return ret;
}

/**
 * @brief       Remove all connections, inform clients, resolve dependencies
 * @note        Function is only called within the FCI worker thread context.
 * @note        Must run with route DB protected against concurrent accesses.
 */
void fci_connections_drop_all(void)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_rtable_entry_t *entry = NULL;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_DEBUG("Removing all connections\n");

        entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_ALL, NULL);
        while (NULL != entry)
        {
            ret = fci_connections_drop_one(entry);
            if (EOK != ret)
            {
                NXP_LOG_WARNING("Couldn't properly drop a connection: %d\n", ret);
            }

            /*	Release the entry */
            pfe_rtable_entry_free(fci_context->rtable, entry);

            entry = pfe_rtable_get_next(fci_context->rtable);
        }
    }
}

/**
 * @brief       Update default timeout value for connections
 * @param       ip_proto IP protocol number for which the timeout shall be set
 * @param       timeout The timeout value in seconds
 * @return      EOK if success, error code otherwise
 */
errno_t fci_connections_set_default_timeout(uint8 ip_proto, uint32 timeout)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (ip_proto)
        {
            case 6U:
            {
                fci_context->default_timeouts.timeout_tcp = timeout;
                break;
            }

            case 17U:
            {
                fci_context->default_timeouts.timeout_udp = timeout;
                break;
            }

            default:
            {
                fci_context->default_timeouts.timeout_other = timeout;
                break;
            }
        }
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get default timeout value for connections
 * @param[in]   ip_proto IP protocol number
 * @return      Timeout value in seconds for entries matching given protocol
 */
uint32 fci_connections_get_default_timeout(uint8 ip_proto)
{
    const fci_t *fci_context = (fci_t *)&context;
    uint32 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (ip_proto)
        {
            case 6U:
            {
                ret = fci_context->default_timeouts.timeout_tcp;
                break;
            }

            case 17U:
            {
                ret = fci_context->default_timeouts.timeout_udp;
                break;
            }

            default:
            {
                ret = fci_context->default_timeouts.timeout_other;
                break;
            }
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_RTABLE_ENABLE */
#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */

/** @}*/


===== 文件 [109/185]: src\fci_core_autosar.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_core_autosar.c
 * @brief       The AUTOSAR-specific FCI core component. Full description can be
 *              found within the fci_core.h.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==============================================================================
                                INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==============================================================================*/
#include "pfe_cfg.h"
#include "oal.h"
#include "fci.h"
#include "fci_internal.h"
#include "fci_core.h"
#include "fifo.h"

#ifdef PFE_CFG_FCI_ENABLE

/*==============================================================================
                  LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==============================================================================*/
typedef struct
{
    fci_msg_t items[FCI_CFG_MSG_FIFO_DEPTH];
    uint8 read;
    uint8 write;
    uint8 len;
} fci_msg_mng_t;

/*
 *  AUTOSAR-specific FCI client representation type (fci_core_client_t)
 */
struct fci_core_client_tag
{
    fci_msg_mng_t *msg_fifo;
    bool_t initialized;

    /*
     * This should be a generic endpoint identifier applicable for linux/qnx/asr/...
     */
};

/*
 *  AUTOSAR-specific FCI core representation type (fci_core_t)
 */
struct fci_core_tag
{
    fci_core_client_t client;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*==============================================================================
                               LOCAL VARIABLES
==============================================================================*/
/* FCI FIFO */
static fci_msg_mng_t fci_msg_fifo;
/* FCI core type singleton */
static fci_core_t fci_core;

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==============================================================================
                           LOCAL FUNCTION PROTOTYPES
==============================================================================*/
static errno_t fci_core_msg_fifo_put(fci_msg_mng_t *msg_fifo, fci_msg_t *msg);
static errno_t fci_core_msg_fifo_get(fci_msg_mng_t *msg_fifo, fci_msg_t *msg);

/*==============================================================================
                                LOCAL FUNCTIONS
==============================================================================*/
/**
 * @brief       Put FCI message to client message fifo
 *
 * @param[in]   msg_fifo Pointer to FCI client message fifo
 * @param[in]   msg Pointer to FCI client message
 * @returns     EOK if suceeded, EOVERFLOW otherwise
 */
static errno_t fci_core_msg_fifo_put(fci_msg_mng_t *msg_fifo, fci_msg_t *msg)
{
    errno_t ret = EOVERFLOW;

    oal_mutex_lock(PFE_FCI_FIFO_MUTEX_00);

    if (msg_fifo->len < FCI_CFG_MSG_FIFO_DEPTH)
    {
        (void)autolibc_memcpy(&(msg_fifo->items[msg_fifo->write]), msg, sizeof(fci_msg_t));
        msg_fifo->len++;
        msg_fifo->write++;
        if(msg_fifo->write >= FCI_CFG_MSG_FIFO_DEPTH)
        {
            msg_fifo->write = 0U;
        }
        ret = EOK;
    }

    oal_mutex_unlock(PFE_FCI_FIFO_MUTEX_00);

    return ret;
}

/**
 * @brief       Get FCI message from FCI client message fifo
 *
 * @param[in]   msg_fifo Pointer to FCI client message fifo
 * @param[in]   msg Pointer to FCI client message
 * @returns     EOK if suceeded, ENOENT otherwise
 */
static errno_t fci_core_msg_fifo_get(fci_msg_mng_t *msg_fifo, fci_msg_t *msg)
{
    errno_t ret = ENOENT;

    oal_mutex_lock(PFE_FCI_FIFO_MUTEX_01);

    if (0U != msg_fifo->len)
    {
        (void)autolibc_memcpy(msg, &(msg_fifo->items[msg_fifo->read]), sizeof(fci_msg_t));
        msg_fifo->len--;
        msg_fifo->read++;
        if(msg_fifo->read >= FCI_CFG_MSG_FIFO_DEPTH)
        {
            msg_fifo->read = 0U;
        }
        ret = EOK;
    }

    oal_mutex_unlock(PFE_FCI_FIFO_MUTEX_01);

    return ret;
}

/*==============================================================================
                                GLOBAL FUNCTIONS
==============================================================================*/
/*
     Create FCI core instance
*/
errno_t fci_core_init(const char_t *const id)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == id))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#else
    (void)id;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(context.core != NULL)
        {
            NXP_LOG_ERROR("FCI_CORE has already been initialized\n");
            ret = EINVAL;
        }
        else
        {
            (void)autolibc_memset(&fci_core, 0, sizeof(fci_core_t));

            fci_core.client.msg_fifo = &fci_msg_fifo;
            (void)autolibc_memset(fci_core.client.msg_fifo, 0, sizeof(fci_msg_mng_t));
            fci_core.client.initialized = TRUE;

            context.core = &fci_core;
            ret = EOK;
        }
    }

    return ret;
}

/*
     Destroy FCI core
*/
void fci_core_fini(void)
{
    fci_core_t *core = (fci_core_t *)context.core;
    fci_msg_t msg;
    errno_t ret;

    (void)autolibc_memset(&msg, 0, sizeof(msg));
    msg.type = FCI_MSG_CMD;
    msg.msg_cmd.code = FPP_CMD_ENDPOINT_SHUTDOWN;

    if (NULL != core)
    {
        ret = fci_core_client_send_broadcast(&msg, NULL);
        /*  Notify listeners */
        if (EOK != ret)
        {
            NXP_LOG_WARNING("fci_core_client_send_broadcast() failed: %d\n", ret);
        }

        (void)autolibc_memset(fci_core.client.msg_fifo, 0, sizeof(fci_msg_mng_t));
        fci_core.client.initialized = FALSE;
        core = NULL;
    }
}

/*
    Send message to FCI client
*/
errno_t fci_core_client_send(fci_core_client_t *client, fci_msg_t *msg, fci_msg_t *rep)
{
    errno_t err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else
#else
    (void)client;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* This function is not needed in MCAL implementation */
        (void)msg;
        (void)rep;
        err = EOK;
    }

    return err;
}

/*
    Send asynchronous message to all registered FCI clients
*/
errno_t fci_core_client_send_broadcast(fci_msg_t *msg, fci_msg_t *rep)
{
    fci_core_t *core = (fci_core_t *)context.core;
    errno_t err = EEXIST;
    (void)rep;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == core))
    {
        NXP_LOG_RAW_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_RAW_ERROR("Context not initialized\n");
        err = EPERM;
    }
    else
#else
    /*  this function could be called from a callback even after the FCI module was destroyed */
    if (unlikely(NULL == core))
    {
        NXP_LOG_RAW_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        msg->type = FCI_MSG_CORE_CLIENT_BROADCAST; /* message type is changed back to FCI_MSG_CMD in core thread */

        if (TRUE == core->client.initialized)
        {
            err = fci_core_msg_fifo_put(core->client.msg_fifo, msg);
            if (unlikely(EOK != err))
            {
                NXP_LOG_WARNING("FCI client messages storage is full, no further messages will be stored.\n");
            }
        }
        else
        {
            NXP_LOG_RAW_ERROR("FCI core client has not been initialized yet\n");
        }
    }

    return err;
}

/*
    Get a message from the FIFO (called by the FCI client)
    Returns NULL when the FIFO is empty, an error code on error
    or the message from the FIFO.
*/
errno_t fci_core_client_get_msg(fci_msg_t *msg)
{
    fci_core_t *core = (fci_core_t *)context.core;
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == core))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == core->client.initialized)
        {
            ret = fci_core_msg_fifo_get(core->client.msg_fifo, msg);
        }
        else
        {
            NXP_LOG_RAW_ERROR("FCI core client has not been initialized yet\n");
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
/** @}*/


===== 文件 [110/185]: src\fci_fp.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "fci_fp_db.h"
#include "pfe_fp.h"
#include "fci_msg.h"
#include "fci.h"
#include "fci_internal.h"
#include "pfe_class.h"
#include "fci_fp.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                       LOCAL FUNCTIONS PROTOTYPES
==================================================================================================*/

static void fci_fp_construct_rule_reply(fpp_fp_rule_props_t *r, fci_fp_rule_info_t *rules, char *next_rule);
static uint16 set_fci_ret(errno_t ret);
static uint16 set_rule_reply(errno_t ret, fci_fp_rule_info_t *rule, char **next_rule, fpp_fp_rule_props_t *r,  uint32 *reply_len);
static errno_t register_rule(fpp_fp_rule_cmd_t *fp_cmd, uint16 *fci_ret);
#if defined(PFE_CFG_NULL_ARG_CHECK)
static errno_t null_arg_check(fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len);
#endif /* PFE_CFG_NULL_ARG_CHECK */


/*==================================================================================================
*                                       LOCAL FUNCTIONS
==================================================================================================*/

/**
* @brief Constructs a query reply with specified rule parameters in the specified buffer
* @param[in] r Buffer where to construct the query reply
* @param[in] rules Structure containing the rules
* @param[in] next_rule Value of the next_rule parameter of the replied rule
*/
static void fci_fp_construct_rule_reply(fpp_fp_rule_props_t *r, fci_fp_rule_info_t *rules, char *next_rule)
{
    (void)autolibc_strncpy((char_t *)r->rule_name, rules->rule_name, 15);
    r->data = rules->data;
    r->mask = rules->mask;
    r->offset = rules->offset;
    if(NULL != next_rule)
    {
        (void)autolibc_strncpy((char_t *)r->next_rule_name, next_rule, 15);
    }
    if(((uint8)rules->flags & (uint8)FP_FL_ACCEPT) != 0U)
    {
        /*  Ensure correct endianess */
        r->match_action = FP_ACCEPT;
    }
    else if(((uint8)rules->flags & (uint8)FP_FL_REJECT) != 0U)
    {
        r->match_action = FP_REJECT;
    }
    else
    {
        r->match_action = FP_NEXT_RULE;
    }
    if(((uint8)rules->flags & (uint8)FP_FL_INVERT) != 0U)
    {
        r->invert = TRUE;
    }
    else
    {
        r->invert = FALSE;
    }

    if(((uint8)rules->flags & (uint8)FP_FL_L3_OFFSET) != 0U)
    {
        r->offset_from = FP_OFFSET_FROM_L3_HEADER;
    }
    else if(((uint8)rules->flags & (uint8)FP_FL_L4_OFFSET) != 0U)
    {
        r->offset_from = FP_OFFSET_FROM_L4_HEADER;
    }
    else
    {
        r->offset_from = FP_OFFSET_FROM_L2_HEADER;
    }
}

#if defined(PFE_CFG_NULL_ARG_CHECK)
/**
 * @brief           Auxiliary function to check for NULL arguments
 * @param[in]       msg FCI message containing the FPP_CMD_FP_TABLE command
 * @param[in]       fci_ret FCI command return value
 * @param[in]       reply_buf Pointer to a buffer where function will construct command reply (fpp_fp_table_cmd_t)
 * @param[in]       reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
static errno_t null_arg_check(fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len)
{
    errno_t ret=EOK;
    const fci_t *fci_context = (fci_t *)&context;

    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
    {
        /*MISRA required*/
    }

    return ret;
}
#endif /* PFE_CFG_NULL_ARG_CHECK */

/**
 * @brief           Auxiliary function to check ret value and set fci_ret value
 * @param[in]       ret error code to evaluate
 * @return          FPP_ERR_OK if success, FPP_ERR_WRONG_COMMAND_PARAM otherwise
 */
static uint16 set_fci_ret(errno_t ret)
{
    uint16 fci_ret;

    if(EOK == ret)
    {
        fci_ret = FPP_ERR_OK;
    }
    else
    {
        fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
    }

    return fci_ret;
}

/**
 * @brief           Auxiliary function to check ret value and construct reply
 * @param[in]       ret error code to evaluate
 * @param[in]       rule Structure containing the rules
 * @param[in]       reply_buf Pointer to a buffer where function will construct command reply (fpp_fp_table_cmd_t)
 * @param[inout]    next_rule Value of the next_rule parameter of the replied rule
 * @param[in]       reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          FPP_ERR_OK if success, FPP_ERR_WRONG_COMMAND_PARAM otherwise
 */
static uint16 set_rule_reply(errno_t ret, fci_fp_rule_info_t *rule, char **next_rule, fpp_fp_rule_props_t *r,  uint32 *reply_len)
{
    uint16 fci_ret;

    if(EOK == ret)
    {
        fci_fp_construct_rule_reply(r, rule, *next_rule);
        fci_ret = FPP_ERR_OK;
        *reply_len = sizeof(fpp_fp_table_cmd_t);
    }
    else
    {
        fci_ret = FPP_ERR_FP_RULE_NOT_FOUND;
    }

    return fci_ret;
}

/**
 * @brief           Prepare data for rule
 * @param[in]       fp_cmd fp command rule table pointer
 * @param[out]      fci_ret FCI command return value
 * @return          EOK if success, error code otherwise
 */
static errno_t register_rule(fpp_fp_rule_cmd_t *fp_cmd, uint16 *fci_ret)
{
    errno_t ret = EOK;
    pfe_ct_fp_flags_t flags = FP_FL_NONE;

    switch(fp_cmd->r.match_action)
    {
        case FP_ACCEPT:
            flags |= FP_FL_ACCEPT;
            break;
        case FP_REJECT:
            flags |= FP_FL_REJECT;
            break;
        case FP_NEXT_RULE:
            break;
        default:
            NXP_LOG_WARNING("Impossible happened\n");
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
            ret = EINVAL;
            break;
    }
    if(EOK == ret)
    {
        switch(fp_cmd->r.offset_from)
        {
            case FP_OFFSET_FROM_L2_HEADER:
                break;
            case FP_OFFSET_FROM_L3_HEADER:
                flags |= FP_FL_L3_OFFSET;
                break;
            case FP_OFFSET_FROM_L4_HEADER:
                flags |= FP_FL_L4_OFFSET;
                break;
            default:
                NXP_LOG_WARNING("Impossible happened\n");
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = EINVAL;
                break;
        }
        if(EOK == ret)
        {
            if(0U != fp_cmd->r.invert)
            {
                flags |= FP_FL_INVERT;
            }

            ret = fci_fp_db_create_rule((char_t *)fp_cmd->r.rule_name, fp_cmd->r.data, fp_cmd->r.mask,
                                    fp_cmd->r.offset, flags,
                                    (char_t *)fp_cmd->r.next_rule_name);
            *fci_ret = set_fci_ret(ret);
        }
    }

    return ret;
}


/*==================================================================================================
*                                       GLOBAL FUNCTIONS
==================================================================================================*/

/**
 * @brief           Processes FPP_CMD_FP_TABLE commands
 * @param[in]       msg FCI message containing the FPP_CMD_FP_TABLE command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_fp_table_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with domain DB protected against concurrent accesses.
 */
errno_t fci_fp_table_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fp_table_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_fp_table_cmd_t *fp_cmd;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    ret = null_arg_check(msg, fci_ret, (void*) reply_buf, reply_len);
    if (likely(EOK == ret))
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Important to initialize to avoid buffer overflows */
        if (*reply_len < sizeof(fpp_fp_table_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_fp_table_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            fp_cmd = (fpp_fp_table_cmd_t *)(msg->msg_cmd.payload);
            switch (fp_cmd->action)
            {
                case FPP_ACTION_REGISTER:
                {
                    ret = fci_fp_db_create_table((char_t *)fp_cmd->table_info.t.table_name);
                    *fci_ret = set_fci_ret(ret);
                    break;
                }
                case FPP_ACTION_DEREGISTER:
                {
                    ret = fci_fp_db_destroy_table((char_t *)fp_cmd->table_info.t.table_name, FALSE);
                    *fci_ret = set_fci_ret(ret);
                    break;
                }
                case FPP_ACTION_USE_RULE:
                {
                    ret = fci_fp_db_add_rule_to_table((char_t *)fp_cmd->table_info.t.table_name, (char_t *)fp_cmd->table_info.t.rule_name, oal_ntohs(fp_cmd->table_info.t.position));
                    *fci_ret = set_fci_ret(ret);
                    break;
                }
                case FPP_ACTION_UNUSE_RULE:
                {
                    ret = fci_fp_db_remove_rule_from_table((char_t *)fp_cmd->table_info.t.rule_name);
                    *fci_ret = set_fci_ret(ret);
                    break;
                }
                case FPP_ACTION_QUERY:
                {
                    fci_fp_rule_info_t rule = {0};
                    char *next_rule = NULL_PTR;

                    ret = fci_fp_db_get_table_first_rule((char_t *)fp_cmd->table_info.t.table_name, &rule, &next_rule);
                    *fci_ret = set_rule_reply(ret, &rule, &next_rule, &reply_buf->table_info.r, reply_len);
                    break;
                }
                case FPP_ACTION_QUERY_CONT:
                {
                    fci_fp_rule_info_t rule = {0};
                    char *next_rule = NULL_PTR;

                    ret = fci_fp_db_get_table_next_rule((char_t *)fp_cmd->table_info.t.table_name, &rule, &next_rule);
                    *fci_ret = set_rule_reply(ret, &rule, &next_rule, &reply_buf->table_info.r, reply_len);
                    break;
                }
                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_L2_BD: Unknown action received: 0x%x\n", fp_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           Processes FPP_CMD_FP_RULE commands
 * @param[in]       msg FCI message containing the FPP_CMD_FP_RULE command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_fp_rule_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with domain DB protected against concurrent accesses.
 */
errno_t fci_fp_rule_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fp_rule_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_fp_rule_cmd_t *fp_cmd;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    ret = null_arg_check(msg, fci_ret, (void*) reply_buf, reply_len);
    if (likely(EOK == ret))
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_fp_rule_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_fp_rule_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;

            fp_cmd = (fpp_fp_rule_cmd_t *)(msg->msg_cmd.payload);
            switch (fp_cmd->action)
            {
                case FPP_ACTION_REGISTER:
                {
                    ret = register_rule(fp_cmd,fci_ret);
                    break;
                }
                case FPP_ACTION_DEREGISTER:
                {
                    ret = fci_fp_db_destroy_rule((char_t*)fp_cmd->r.rule_name);
                    *fci_ret = set_fci_ret(ret);
                    break;
                }
                case FPP_ACTION_QUERY:
                {
                    fci_fp_rule_info_t rule = {0};
                    char *next_rule = NULL_PTR;

                    ret = fci_fp_db_get_first_rule(&rule, &next_rule);
                    *fci_ret = set_rule_reply(ret, &rule, &next_rule, &reply_buf->r, reply_len);
                    break;
                }
                case FPP_ACTION_QUERY_CONT:
                {
                    fci_fp_rule_info_t rule = {0};
                    char *next_rule = NULL_PTR;

                    ret = fci_fp_db_get_next_rule(&rule, &next_rule);
                    *fci_ret = set_rule_reply(ret, &rule, &next_rule, &reply_buf->r, reply_len);
                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_L2_BD: Unknown action received: 0x%x\n", fp_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [111/185]: src\fci_fp_db.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "pfe_ct.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "fci_fp_db.h"
#include "pfe_fp.h"
#include "fci.h"
#include "Eth_43_PFE_Cfg.h"
#include "isa.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE

/* rule names should not exceed this length including terminating 0 */
#define FCI_FP_RULE_NAME_LENGTH 16

/**
* @brief Flexible parser rule representation
*/
typedef struct
{
    /* Maintenance */
    char_t name[FCI_FP_RULE_NAME_LENGTH];    /* Unique ID */
    pfe_isa_index_t chained_prev_rule_idx;  /* Previous rule linked to the table */
    pfe_isa_index_t chained_next_rule_idx;  /* Next rule linked to the table */
    uint8 position;        /* Position in the table */
    fci_fp_table_t *table;   /* Link to the table the rule belongs */
    /* Data */
    char_t next_rule[FCI_FP_RULE_NAME_LENGTH]; /* Name of the next linked rule */
    uint32 data;           /* Data to match */
    uint32 mask;           /* Mask to match */
    uint16 offset;         /* Data offset to get data */
    pfe_ct_fp_flags_t flags; /* Flags configuring the rule */
} fci_fp_rule_t;

/**
* @brief Criterion for rule database search
*/
typedef enum
{
    FP_RULE_CRIT_ALL,
    FP_RULE_CRIT_NAME,
} fci_fp_rule_criterion_t;

/**
* @brief Argument (requested value) for rule database
*/
typedef union
{
    char_t name[FCI_FP_RULE_NAME_LENGTH];
} fci_fp_rule_criterion_arg_t;

/**
* @brief Database of flexible parser rules
*/
typedef struct
{
    /* Rules database */
    pfe_isa_t rules;
    pfe_isa_index_t rules_pool_index[PFE_CFG_FCI_FP_MAX_RULES];
    fci_fp_rule_t rules_pool[PFE_CFG_FCI_FP_MAX_RULES];
    /* Searching */
    fci_fp_rule_criterion_t cur_crit;
    fci_fp_rule_criterion_arg_t cur_crit_arg;
    uint32 next_item;
} fci_fp_rule_db_t;

/**
* @brief Flexible parser table representation
*/
struct fci_fp_table_tag
{
    char_t name[FCI_FP_TABLE_NAME_LENGTH]; /* Table identifier */
    uint16 rule_count;       /* Number of rules in the table */
    uint32 dmem_addr;        /* Address where the table was written into DMEM */
    pfe_class_t *class;
    pfe_isa_index_t rules_chain_1st_idx;  /* Chained list of rules in the table, valid only if rule_count > 0 */
    /* Searching */
    fci_fp_rule_criterion_t cur_crit;
    fci_fp_rule_criterion_arg_t cur_crit_arg;
    pfe_isa_index_t iter_next_rule_idx;    /* next rule to examine in get first / get next */
    uint16 iter_count;              /* rules left to examine in get first / get next */
};

/**
* @brief Database of flexible parser tables
*/
typedef struct
{
    /* Tables database */
    pfe_isa_t tables;
    pfe_isa_index_t tables_pool_index[FCI_MAX_TABLES];
    fci_fp_table_t tables_pool[FCI_MAX_TABLES];
    /* Searching */
    fci_fp_table_criterion_t cur_crit;
    fci_fp_table_criterion_arg_t cur_crit_arg;
    uint32 next_item;
} fci_fp_table_db_t;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

static fci_fp_rule_db_t fci_fp_rule_db;
static fci_fp_table_db_t fci_fp_table_db;

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/* FCI flexible parser tables storage ISA properties definition */
static const pfe_isa_definition_t fci_fp_table_db_tables_isa_def =
{
    .item_count = FCI_MAX_TABLES,
    .item_size = (uint32)sizeof(fci_fp_table_t),
    .flags = { .ordered = ISA_FLAG_ANY_ORDER },
    .item_indexes = fci_fp_table_db.tables_pool_index,
    .items = fci_fp_table_db.tables_pool
};
/* FCI flexible parser rules storage ISA properties definition */
static const pfe_isa_definition_t fci_fp_rule_db_rules_isa_def =
{
    .item_count = PFE_CFG_FCI_FP_MAX_RULES,
    .item_size = (uint8)sizeof(fci_fp_rule_t),
    .flags = { .ordered = ISA_FLAG_ANY_ORDER },
    .item_indexes = fci_fp_rule_db.rules_pool_index,
    .items = fci_fp_rule_db.rules_pool
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static bool_t fci_fp_match_rule_by_criterion(fci_fp_rule_criterion_t crit, const fci_fp_rule_criterion_arg_t *arg, const fci_fp_rule_t *rule);
static fci_fp_rule_t *fci_fp_rule_get_first_common(fci_fp_rule_db_t *db, fci_fp_rule_criterion_t crit, void *arg);
static fci_fp_rule_t *fci_fp_rule_get_first_table(fci_fp_table_t *fp_table, fci_fp_rule_criterion_t crit, void *arg);
static fci_fp_rule_t *fci_fp_rule_get_next_common(fci_fp_rule_db_t *db);
static fci_fp_rule_t *fci_fp_rule_get_next_table(fci_fp_table_t *fp_table);
static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, const fci_fp_table_criterion_arg_t *arg, const fci_fp_table_t *fp_table);
static fci_fp_table_t *fci_fp_table_get_first(fci_fp_table_db_t *db, fci_fp_table_criterion_t crit, void *arg);
static errno_t allocate_table_storage(char_t *name, fpp_fp_rule_props_t *rule_props, pfe_ct_fp_flags_t flags, char_t *next_rule);
static errno_t write_rules_to_table(fci_fp_table_t *fp_table, pfe_class_t *class, char_t *table_name);
static void add_rule_to_position(fci_fp_rule_t *rule, fci_fp_table_t *fp_table, uint16 position);

#if defined(PFE_CFG_TEXT_STATS)
static uint32 fci_fp_print_table(const fci_fp_table_t *fp_table, char_t *buf, uint32 buf_len, uint8 verb_level);
static errno_t fci_fp_get_rule_pos_in_table(const fci_fp_table_t *fp_table, fci_fp_rule_t *rule, uint8 *pos);
static uint32 fci_fp_print_rule(fci_fp_rule_t *rule, char_t *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

static fci_fp_table_t *fci_fp_table_get_next(fci_fp_table_db_t *db);
static void fci_fp_unlink_rule_from_chain(fci_fp_rule_t *fp_rule);

/**
 * @brief Get first rule for the FP table
 * @param[in] fp_table pointer to FP table
 * @return Pointer to first rule
 */
static inline fci_fp_rule_t *fci_fp_table_1st_rule(const fci_fp_table_t *fp_table)
{
    return &fci_fp_rule_db.rules_pool[fp_table->rules_chain_1st_idx];
}

/**
 * @brief Get previous sibling rule
 * @param[in] fp_rule pointer to FP rule
 * @return Pointer to previous rule
 */
static inline fci_fp_rule_t *fci_fp_rule_prev_sibling(const fci_fp_rule_t *fp_rule)
{
    return &fci_fp_rule_db.rules_pool[fp_rule->chained_prev_rule_idx];
}

/**
 * @brief Get next sibling rule
 * @param[in] fp_rule pointer to FP rule
 * @return Pointer to next rule
 */
static inline fci_fp_rule_t *fci_fp_rule_next_sibling(const fci_fp_rule_t *fp_rule)
{
    return &fci_fp_rule_db.rules_pool[fp_rule->chained_next_rule_idx];
}

/**
 * @brief Get pool index to the rule
 * @param[in] fp_rule pointer to rule in the rule pool
 * @return Index of the rule
 */
static inline pfe_isa_index_t fci_fp_get_rule_index(const fci_fp_rule_t *fp_rule)
{
    return (pfe_isa_index_t)(fp_rule - fci_fp_rule_db.rules_pool);
}

/**
 * @brief Unlink the rule from the chain
 * @param[in] fp_rule pointer to rule in the rule pool
 */
static void fci_fp_unlink_rule_from_chain(fci_fp_rule_t *fp_rule)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == fp_rule))
    {
        NXP_LOG_ERROR("fp_rule isn't expected to be NULL here !\n");
    }
    else if(unlikely(NULL_PTR == fp_rule->table))
    {
        NXP_LOG_ERROR("fp_rule->table isn't expected to be NULL here !\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_isa_index_t index = fci_fp_get_rule_index(fp_rule);
        /* next sibling rule */
        fci_fp_rule_t *fp_rule_next = fci_fp_rule_next_sibling(fp_rule);
        /* previous sibling rule */
        fci_fp_rule_t *fp_rule_prev = fci_fp_rule_prev_sibling(fp_rule);

        if(index == fp_rule->table->rules_chain_1st_idx)
        {
            /* this rule is the 1st in the table */
            fp_rule->table->rules_chain_1st_idx = fci_fp_get_rule_index(fp_rule_next);
            /* make next rule previous chain unlinked */
            fp_rule_next->chained_prev_rule_idx = fci_fp_get_rule_index(fp_rule_next);
        }
        else
        {
            if(fp_rule != fp_rule_prev)
            {
                /* the rule has previous sibling */
                if(fp_rule != fp_rule_next)
                {
                    /* the rule has next sibling */
                    fp_rule_prev->chained_next_rule_idx = fci_fp_get_rule_index(fp_rule_next);
                }
                else
                {
                    /* the rule hasn't next sibling */
                    fp_rule_prev->chained_next_rule_idx = fci_fp_get_rule_index(fp_rule_prev);
                }
            }
            if(fp_rule != fp_rule_next)
            {
                /* the rule has next sibling */
                if(fp_rule != fp_rule_prev)
                {
                    /* the rule has previous sibling */
                    fp_rule_next->chained_prev_rule_idx = fci_fp_get_rule_index(fp_rule_prev);
                }
                else
                {
                    /* the rule hasn't previous sibling */
                    fp_rule_next->chained_prev_rule_idx = fci_fp_get_rule_index(fp_rule_next);
                }
            }
        }

        /* chained values will point to ourself after unlinking */
        fp_rule->chained_next_rule_idx = index;
        fp_rule->chained_prev_rule_idx = index;

        /* decrease number rules for the table */
        fp_rule->table->rule_count--;

        /* this rule doesn't relate to any table anymore */
        fp_rule->table = NULL_PTR;
    }
}

/**
 * @brief        Match rule using given criterion
 * @param[in]    crit Selects criterion
 * @param[in]    arg Criterion argument
 * @param[in]    rule The rule to be matched
 * @retval       TRUE Rule matches the criterion
 * @retval       FALSE Rule does not match the criterion
 */
static bool_t fci_fp_match_rule_by_criterion(fci_fp_rule_criterion_t crit, const fci_fp_rule_criterion_arg_t *arg, const fci_fp_rule_t *rule)
{
    bool_t match;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rule) || (NULL == arg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (crit)
        {
            case FP_RULE_CRIT_ALL:
            {
                match = TRUE;
                break;
            }
            case FP_RULE_CRIT_NAME:
            {
                if(0 == autolibc_strcmp(arg->name, rule->name))
                {
                    match = TRUE;
                }
                else
                {
                    match = FALSE;
                }
                break;
            }
            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                match = FALSE;
                break;
            }
        }
    }
    return match;
}

/**
 * @brief        Get first rule from the database matching given criterion
 * @details      Intended to be used with fci_fp_rule_get_next
 * @param[in]    db The rules database instance
 * @param[in]    crit Get criterion
 * @param[in]    arg Pointer to criterion argument. Every value shall to be in HOST endian format. Strings are copied into internal memory.
 * @return       The matching rule or NULL if not found
 */
static fci_fp_rule_t *fci_fp_rule_get_first_common(fci_fp_rule_db_t *db, fci_fp_rule_criterion_t crit, void *arg)
{
    fci_fp_rule_t *rule = NULL_PTR;
    bool_t cur_crit_remember_success = TRUE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else if (unlikely((FP_RULE_CRIT_ALL != crit) && (NULL_PTR == arg)))
    {
        /*  All criterions except FP_RULE_CRIT_ALL require non-NULL argument */
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*    Remember criterion and argument for possible subsequent fci_fp_rule_get_next() calls */
        db->cur_crit = crit;
        switch(db->cur_crit)
        {
            case FP_RULE_CRIT_ALL:
                break;

            case FP_RULE_CRIT_NAME:
            {
                (void)autolibc_strncpy(db->cur_crit_arg.name, (char_t *)arg, sizeof(db->cur_crit_arg.name));
                if(db->cur_crit_arg.name[sizeof(db->cur_crit_arg.name) - 1U] != '\0')
                {
                    /* could not copy the whole string into destination ! */
                    cur_crit_remember_success = FALSE;
                }
                break;
            }
            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                cur_crit_remember_success = FALSE;
                break;
            }
        }
        if (TRUE == cur_crit_remember_success)
        {
            db->next_item = 0U;
            rule = fci_fp_rule_get_next_common(db);
        }
    }

    return rule;
}

/**
 * @brief        Get first rule from the table matching given criterion
 * @details      Intended to be used with fci_fp_rule_get_next
 * @param[in]    fp_table The FP table instance
 * @param[in]    crit Get criterion
 * @param[in]    arg Pointer to criterion argument. Every value shall to be in HOST endian format. Strings are copied into internal memory.
 * @return       The matching rule or NULL if not found
 */
static fci_fp_rule_t *fci_fp_rule_get_first_table(fci_fp_table_t *fp_table, fci_fp_rule_criterion_t crit, void *arg)
{
    fci_fp_rule_t *rule = NULL_PTR;
    bool_t cur_crit_remember_success = TRUE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == fp_table))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else if (unlikely((FP_RULE_CRIT_ALL != crit) && (NULL_PTR == arg)))
    {
        /*  All criterions except FP_RULE_CRIT_ALL require non-NULL argument */
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*    Remember criterion and argument for possible subsequent fci_fp_rule_get_next() calls */
        fp_table->cur_crit = crit;
        switch(fp_table->cur_crit)
        {
            case FP_RULE_CRIT_ALL:
                break;

            case FP_RULE_CRIT_NAME:
            {
                (void)autolibc_strncpy(fp_table->cur_crit_arg.name, (char_t *)arg, sizeof(fp_table->cur_crit_arg.name));
                if(fp_table->cur_crit_arg.name[sizeof(fp_table->cur_crit_arg.name) - 1U] != '\0')
                {
                    /* could not copy the whole string into destination ! */
                    cur_crit_remember_success = FALSE;
                }
                break;
            }
            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                cur_crit_remember_success = FALSE;
                break;
            }
        }
        if (TRUE == cur_crit_remember_success)
        {
            fp_table->iter_count = 0U;
            fp_table->iter_next_rule_idx = fp_table->rules_chain_1st_idx;
            rule = fci_fp_rule_get_next_table(fp_table);
        }

    }

    return rule;
}

/**
 * @brief        Get next rule from the database
 * @details      Intended to be used with fci_fp_rule_get_first.
 * @param[in]    db The rules database instance
 * @return       The rule matching criterion set by fci_fp_rule_get_first or NULL if not found
 */
static fci_fp_rule_t *fci_fp_rule_get_next_common(fci_fp_rule_db_t *db)
{
    fci_fp_rule_t *rule = NULL_PTR;
    bool_t match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* rules global database */
        while (db->next_item < fci_fp_rule_db.rules.occupied_items_count)
        {
            rule = (fci_fp_rule_t *)isa_item(&fci_fp_rule_db.rules, db->next_item);

            /* Remember current item to know where to start later */
            db->next_item++;

            if (NULL_PTR != rule)
            {
                match = fci_fp_match_rule_by_criterion(db->cur_crit, &db->cur_crit_arg, rule);
                if (TRUE == match)
                {
                    break;
                }
            }
        }

        if (FALSE == match)
        {
            rule = NULL_PTR;
        }
    }

    return rule;
}

/**
 * @brief        Get next rule from the table
 * @details      Intended to be used with fci_fp_rule_get_first.
 * @param[in]    fp_table The table instance
 * @return       The rule matching criterion set by fci_fp_rule_get_first or NULL if not found
 */
static fci_fp_rule_t *fci_fp_rule_get_next_table(fci_fp_table_t *fp_table)
{
    fci_fp_rule_t *rule = NULL_PTR;
    bool_t match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == fp_table))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        while (fp_table->iter_count < fp_table->rule_count)
        {
            rule = &fci_fp_rule_db.rules_pool[fp_table->iter_next_rule_idx];
            fp_table->iter_next_rule_idx = rule->chained_next_rule_idx;
            /* consume this rule */
            fp_table->iter_count++;

            match = fci_fp_match_rule_by_criterion(fp_table->cur_crit, &fp_table->cur_crit_arg, rule);
            if (TRUE == match)
            {
                break;
            }
        }

        if (FALSE == match)
        {
            rule = NULL_PTR;
        }
    }

    return rule;
}

/**
 * @brief        Match table using given criterion
 * @param[in]    crit Selects criterion
 * @param[in]    arg Criterion argument
 * @param[in]    fp_table The table to be matched
 * @retval       TRUE Table matches the criterion
 * @retval       FALSE Table does not match the criterion
 */
static bool_t fci_fp_match_table_by_criterion(fci_fp_table_criterion_t crit, const fci_fp_table_criterion_arg_t *arg, const fci_fp_table_t *fp_table)
{
    bool_t match;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == fp_table) || (NULL == arg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (crit)
        {
            case FP_TABLE_CRIT_ALL:
            {
                match = TRUE;
                break;
            }
            case FP_TABLE_CRIT_NAME:
            {
                if(0 == autolibc_strcmp(arg->name, fp_table->name))
                {
                    match = TRUE;
                }
                else
                {
                    match = FALSE;
                }
                break;
            }
            case FP_TABLE_CRIT_ADDRESS:
            {
                if(arg->address == fp_table->dmem_addr)
                {
                    match = TRUE;
                }
                else
                {
                    match = FALSE;
                }
                break;
            }
            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                match = FALSE;
                break;
            }
        }
    }
    return match;
}
/**
 * @brief        Get first table from the database matching given criterion
 * @details      Intended to be used with fci_fp_table_get_next
 * @param[in]    db The tables database instance
 * @param[in]    crit Get criterion
 * @param[in]    arg Pointer to criterion argument. Every value shall to be in HOST endian format. Strings are copied into internal memory.
 * @return       The matching table or NULL if not found
 */
static fci_fp_table_t *fci_fp_table_get_first(fci_fp_table_db_t *db, fci_fp_table_criterion_t crit, void *arg)
{
    fci_fp_table_t *fp_table = NULL_PTR;
    bool_t cur_crit_remember_success = TRUE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else if (unlikely((FP_TABLE_CRIT_ALL != crit) && (NULL_PTR == arg)))
    {
        /*  All criterions except FP_TABLE_CRIT_ALL require non-NULL argument */
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Invalidate memory used by previous search (if any) */
        if(FP_TABLE_CRIT_NAME == db->cur_crit)
        {
            db->cur_crit_arg.name[0U] = '\0';
        }
        /*    Remember criterion and argument for possible subsequent fci_fp_table_get_next() calls */
        db->cur_crit = crit;
        switch(crit)
        {
            case FP_TABLE_CRIT_ALL:
            {
                break;
            }
            case FP_TABLE_CRIT_NAME:
            {
                /* Copy the string */
                (void)autolibc_strncpy(db->cur_crit_arg.name, (char_t *)arg, sizeof(db->cur_crit_arg.name));
                if(db->cur_crit_arg.name[sizeof(db->cur_crit_arg.name) - 1U] != '\0')
                {
                    /* count not copy the whole string into destination */
                    cur_crit_remember_success = FALSE;
                }
                break;
            }
            case FP_TABLE_CRIT_ADDRESS:
            {
                db->cur_crit_arg.address = *(uint32 *)arg;
                break;
            }
            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                cur_crit_remember_success = FALSE;
                break;
            }
        }

        if (TRUE == cur_crit_remember_success)
        {
            /* Get first matching table */
            db->next_item = 0U;
            fp_table = fci_fp_table_get_next(db);
        }
    }

    return fp_table;
}


/**
 * @brief        Get next table from the database
 * @details      Intended to be used with fci_fp_rule_get_first.
 * @param[in]    db The rules database instance
 * @return       The table matching criterion set by fci_fp_rule_get_first or NULL if not found
 */
static fci_fp_table_t *fci_fp_table_get_next(fci_fp_table_db_t *db)
{
    fci_fp_table_t *fp_table = NULL_PTR;
    bool_t match;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        match = FALSE;

        while (db->next_item < db->tables.occupied_items_count)
        {
            /*  Get data */
            fp_table = (fci_fp_table_t *)isa_item(&db->tables, db->next_item);

            /*  Remember current item to know where to start later */
            db->next_item++;

            if (NULL_PTR != fp_table)
            {
                if (TRUE == fci_fp_match_table_by_criterion(db->cur_crit, &db->cur_crit_arg, fp_table))
                {
                    match = TRUE;
                    break;
                }
            }
        }

        if (TRUE != match)
        {
            fp_table = NULL_PTR;
        }
    }

    return fp_table;
}

/**
* @brief Returns the position of the rule within a table
* @param[in] fp_table Table to determine postion of the rule within
* @param[in] rule Rule which position within the table shall be determined
* @param[out] pos Determined rule position
* @return EOK on success, ENOENT if rule is not part of the table.
*/
static errno_t fci_fp_get_rule_pos_in_table(const fci_fp_table_t *fp_table, fci_fp_rule_t *rule, uint8 *pos)
{
    uint16 i;
    const fci_fp_rule_t *rule_item;
    errno_t ret = ENOENT;

    rule_item = fci_fp_table_1st_rule(fp_table);
    for (i = 0U; i < fp_table->rule_count; i++)
    {
        if(rule_item == rule)
        {
            *pos = i;
            ret = EOK;
            break;
        }
        rule_item = fci_fp_rule_next_sibling(rule_item);
    }
    return ret;
}

/**
* @brief Writes rules to the table
* @param[in] fp_table Pointer to the table
* @param[in] classifier Classifier which DMEM shall be written
* @param[in] table Table which shall be written
* @return Either EOK or an error code.
*/
static errno_t write_rules_to_table(fci_fp_table_t *fp_table, pfe_class_t *class, char_t *table_name)
{
    fci_fp_rule_t *rule;
    pfe_ct_fp_rule_t rule_buf;
    fci_fp_rule_t *next_rule;
    uint16 i;
    uint8 pos;
    errno_t ret = EOK;

    (void) table_name; /*suppress DIAB compiler warning*/

    /* Write rules into the table */
    rule = fci_fp_table_1st_rule(fp_table);
    for (i = 0U; i < fp_table->rule_count; i++)
    {
        rule_buf.data = rule->data;
        rule_buf.mask = rule->mask;
        rule_buf.offset = rule->offset;
        rule_buf.flags = rule->flags;
        if(rule->next_rule[0U] != '\0')
        {   /* Next rule is specified */
            /* Convert next_rule name to position in the table */
            next_rule = fci_fp_rule_get_first_table(fp_table, FP_RULE_CRIT_NAME, rule->next_rule);
            if(NULL_PTR == next_rule)
            {   /* Failed - cannot proceed */
                NXP_LOG_WARNING("Referenced rule \"%s\" is not part of the table \"%s\"\n", rule->next_rule, table_name);
                pfe_fp_destroy_table(class, fp_table->dmem_addr);
                fp_table->dmem_addr = 0U;
                ret = ENOENT;
            }
            else if(EOK != fci_fp_get_rule_pos_in_table(fp_table, next_rule, &pos))
            {   /* Failed - cannot proceed */
                NXP_LOG_WARNING("Referenced rule \"%s\" is not part of the table \"%s\"\n", rule->next_rule, table_name);
                pfe_fp_destroy_table(class, fp_table->dmem_addr);
                fp_table->dmem_addr = 0U;
                ret = ENOENT;
            }
            else
            {
                /*Do nothing - Avoid MISRA rule 15.7 */
            }
            if (EOK != ret)
            {
                break;
            }
            rule_buf.next_idx = pos;
        }
        else
        {   /* Next rule is not used */
            rule_buf.next_idx = 0xFFU; /* If used it will cause FW internal check to detect it */
        }
        (void)pfe_fp_table_write_rule(class, fp_table->dmem_addr, &rule_buf, i);

        rule = fci_fp_rule_next_sibling(rule);
    }

    return ret;
}

/**
* @brief Allocates a flexible parser rule
* @param[in] name Name of the rule (unique identifier)
* @param[in] rule_props Rule properties pointer
* @param[in] flags Flags describing the rule - see pfe_ct_fp_flags_t
* @param[in] next_rule Name of the rule to be examined next if none of flags FP_FL_ACCEPT | FP_FL_REJECT is set
* @return Either EOK or an error code.
*/
static errno_t allocate_table_storage(char_t *name, fpp_fp_rule_props_t *rule_props, pfe_ct_fp_flags_t flags, char_t *next_rule)
{
    errno_t ret = EINVAL;
    bool_t ignore_next_rule = FALSE;
    fci_fp_rule_t *rule = NULL_PTR;

    if((0U != ((uint8)flags & ((uint8)FP_FL_ACCEPT | (uint8)FP_FL_REJECT))) && (NULL_PTR != next_rule))
    {   /* Ignored argument */
        NXP_LOG_WARNING("Next rule is ignored with these flags: 0x%x\n", flags);
        ignore_next_rule = TRUE;
    }
    /* Check that the name is unique in our database */
    if(NULL_PTR != fci_fp_rule_get_first_common(&fci_fp_rule_db, FP_RULE_CRIT_NAME, name))
    {   /* Rule with same name found in database */
        NXP_LOG_WARNING("Rule with name \"%s\" already exists\n", name);
        ret = EEXIST;
    }
    else
    {
        /* Allocate table item storage */
        rule = (fci_fp_rule_t *)isa_reserve(&fci_fp_rule_db.rules);
        if(NULL_PTR == rule)
        {
            NXP_LOG_ERROR("No ISA item for the rule\n");
            ret = ENOMEM;
        }
        else
        {
            /* Initialize */
            (void)autolibc_memset(rule, 0, sizeof(fci_fp_rule_t));
            /* Store the input parameters */
            (void)autolibc_strncpy(rule->name, name, sizeof(rule->name));
            if((NULL_PTR != next_rule) && (FALSE == ignore_next_rule))
            {   /* Just store the next rule name, no validation yet because rule may be added later */
                (void)autolibc_strncpy(rule->next_rule, next_rule, sizeof(rule->next_rule));
            }
            else
            {
                rule->next_rule[0U] = '\0';
            }
            /* set chaining values to unchained */
            rule->chained_next_rule_idx = fci_fp_get_rule_index(rule);
            rule->chained_prev_rule_idx = rule->chained_next_rule_idx;
            rule->data = rule_props->data;
            rule->mask = rule_props->mask;
            rule->offset = rule_props->offset;
            rule->flags = flags;
            ret = EOK;
        }
    }

    return ret;
}

/**
* @brief Auxiliary function to add a rule into a table at given position
* @param[in] rule Rule to be added
* @param[in] fp_table Table where the rule shall be added
* @param[in] position Position where to place rule. Either fci_fp_RULE_POSITION_LAST, fci_fp_RULE_POSITION_FIRST,
*            or an integer in range 0 to 255 describing the position.
*/
static void add_rule_to_position(fci_fp_rule_t *rule, fci_fp_table_t *fp_table, uint16 position)
{
    fci_fp_rule_t *head_rule;
    uint32 i = 0U; /* Start search from position 0 */

    /* head_rule is at position 0 */
    head_rule = fci_fp_table_1st_rule(fp_table);
    if(position == FCI_FP_RULE_POSITION_FIRST)
    {   /* Insert as the first one */
        rule->chained_next_rule_idx = fp_table->rules_chain_1st_idx;
        fp_table->rules_chain_1st_idx = fci_fp_get_rule_index(rule);
        head_rule->chained_prev_rule_idx = fp_table->rules_chain_1st_idx;
    }
    else
    {
        /* position > FCI_FP_RULE_POSITION_FIRST && position <= FCI_FP_RULE_POSITION_LAST */
        /* Table not empty - need to handle position request */
        bool_t added = FALSE;
        /* find desired position */
        for (i = 1U; i < fp_table->rule_count; i++)
        {
            if (position == i)
            {   /* Insert at specified position */
                /* next sibling of head rule */
                fci_fp_rule_t *head_rule_next = fci_fp_rule_next_sibling(head_rule);

                if (head_rule != head_rule_next)
                {
                    /* head_rule has next sibling, re-link to rule being added */
                    rule->chained_next_rule_idx = head_rule->chained_next_rule_idx;
                    head_rule_next->chained_prev_rule_idx = fci_fp_get_rule_index(rule);
                }
                else
                {
                    /* head_rule hasn't next sibling, nothing to do ! */
                }

                added = TRUE;
                break;
            }
            head_rule = fci_fp_rule_next_sibling(head_rule);
        }

        /* FCI_FP_RULE_POSITION_LAST or append at the end */
        if(FALSE == added)
        {   /* The requested position has not been found - add at the end */
            NXP_LOG_WARNING("Position %u does not exist, adding at %u\n", (uint_t)position, (uint_t)i);
        }

        /* Add as the last one */
        rule->chained_prev_rule_idx = fci_fp_get_rule_index(head_rule);
        head_rule->chained_next_rule_idx = fci_fp_get_rule_index(rule);
    }
}

/**
* @brief Initializes the module
*/
void fci_fp_db_init(void)
{
    (void)autolibc_memset(&fci_fp_rule_db, 0, sizeof(fci_fp_rule_db_t));
    (void)autolibc_memset(&fci_fp_table_db, 0, sizeof(fci_fp_table_db_t));
    /* create rules ISA */
    isa_init(&fci_fp_rule_db.rules, &fci_fp_rule_db_rules_isa_def);
    /* create tables ISA */
    isa_init(&fci_fp_table_db.tables, &fci_fp_table_db_tables_isa_def);
}

/**
* @brief Crates a flexible parser rule
* @param[in] name Name of the rule (unique identifier)
* @param[in] data Expected value of the data (network endian)
* @param[in] mask Mask to be applied on the data (network endian)
* @param[in] offset Offset of the data to be compared (network endian)
* @param[in] flags Flags describing the rule - see pfe_ct_fp_flags_t
* @param[in] next_rule Name of the rule to be examined next if none of flags FP_FL_ACCEPT | FP_FL_REJECT is set
* @return Either EOK or an error code.
*/
errno_t fci_fp_db_create_rule(char_t *name, uint32 data, uint32 mask, uint16 offset, pfe_ct_fp_flags_t flags, char_t *next_rule)
{
    errno_t ret;
    uint32 length;
    fpp_fp_rule_props_t rule_props = {0};

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* check name for validity */
        length = autolibc_strnlen(name, sizeof(((fci_fp_rule_t*)0)->name));
        if((sizeof(((fci_fp_rule_t*)0)->name) <= length) || (0U == length))
        {
            NXP_LOG_WARNING("Rule name string length is invalid\n");
            ret = EINVAL;
        }
        else
        {
            length = autolibc_strnlen(next_rule, sizeof(((fci_fp_rule_t*)0)->next_rule));
            if((NULL_PTR != next_rule) && ((sizeof(((fci_fp_rule_t*)0)->next_rule) <= length)))
            {
                NXP_LOG_WARNING("Next rule string length is invalid\n");
                ret = EINVAL;
            }
            else
            {
                if((0U == ((uint8)flags & ((uint8)FP_FL_ACCEPT | (uint8)FP_FL_REJECT))) && (NULL_PTR == next_rule))
                {   /* If flags are not FP_FL_REJECT and not FP_FL_ACCEPT we need the next rule name */
                    NXP_LOG_WARNING("Flags FP_FL_ACCEPT and FP_FL_REJECT are not set but next rule is not defined (NULL)\n");
                    ret = EINVAL;
                }
                else if(((uint8)FP_FL_ACCEPT | (uint8)FP_FL_REJECT) == ((uint8)flags & ((uint8)FP_FL_ACCEPT | (uint8)FP_FL_REJECT)))
                {   /* Cannot do both Accept and Reject action */
                    NXP_LOG_WARNING("Both flags FP_FL_ACCEPT and FP_FL_REJECT are set\n");
                    ret = EINVAL;
                }
                else
                {
                    rule_props.data = data;
                    rule_props.mask = mask;
                    rule_props.offset = offset;
                    ret = allocate_table_storage(name, &rule_props, flags, next_rule);
                }
            }
        }
    }
    return ret;
}

/**
* @brief Destroys a flexible parser rule
* @param[in] name Name of the table to destroy
* @return EOK or an error code.
*/
errno_t fci_fp_db_destroy_rule(char_t *name)
{
  fci_fp_rule_t *rule = NULL;
  errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(NULL == name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Find the rule */
        rule = fci_fp_rule_get_first_common(&fci_fp_rule_db, FP_RULE_CRIT_NAME, name);
        if(NULL == rule)
        {   /* No such rule */
            NXP_LOG_WARNING("Rule with name \"%s\" does not exist\n", name);
            ret = ENOENT;
        }
        else
        {
            /* Check that the rule is not in use */
            if(NULL != rule->table)
            {   /* Still in use */
                NXP_LOG_WARNING("Rule \"%s\" is in use in table \"%s\"\n", name, rule->table->name);
                ret = EACCES;
            }
            else
            {
                /* Remove/Free the rule instance in ISA */
                (void)isa_release(&fci_fp_rule_db.rules, rule);
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
* @brief Creates a flexible parser rules table
* @param[in] name Name of the table - unique identifier
* @return EOK or an error code.
*/
errno_t fci_fp_db_create_table(char_t *name)
{
    fci_fp_table_t  *fp_table;
    errno_t         ret;
    uint32        length;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(NULL_PTR == name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret =  EINVAL;
    }
    else
#endif
    {
        /* check name for validity */
        length = autolibc_strnlen(name, sizeof(fp_table->name));
        if((sizeof(fp_table->name) <= length) || (0U == length))
        {
            NXP_LOG_WARNING("Table name string is invalid\n");
            ret = EINVAL;
        }
        else
        {
            /* Check that the name is unique in our database */
            if(NULL_PTR != fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, name))
            {   /* Rule with same name found in database */
                NXP_LOG_WARNING("Table with name \"%s\" already exists\n", name);
                ret = EEXIST;
            }
            else
            {
                /* Allocate table item storage */
                fp_table = (fci_fp_table_t *)isa_reserve(&fci_fp_table_db.tables);
                if(NULL_PTR == fp_table)
                {
                    NXP_LOG_ERROR("No ISA item for the table\n");
                    ret = ENOMEM;
                }
                else
                {
                    /* Initialize */
                    (void)autolibc_memset(fp_table, 0, sizeof(fci_fp_table_t));
                    (void)autolibc_strncpy(fp_table->name, name, sizeof(fp_table->name));
                    ret = EOK;
                }
            }
        }
    }
    return ret;

}

/**
* @brief Destroys a flexible parser rules table
* @param[in] name Name of the table to destroy
* @param[in] force If set to TRUE the table is destroyed even if it is still in use.
* @return EOK or an error code.
*/
errno_t fci_fp_db_destroy_table(char_t *name, bool_t force)
{
    fci_fp_table_t *fp_table;
    fci_fp_rule_t *rule;
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(NULL_PTR == name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Find the table */
        fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, name);
        if(NULL_PTR == fp_table)
        {
            NXP_LOG_WARNING("Table with name \"%s\" does not exist\n", name);
            ret = ENOENT;
        }
        else
        {
            /* Check that the table is not in use */
            if(0U != fp_table->dmem_addr)
            {   /* Table is still in use */
                if(FALSE == force)
                {   /* No override */
                    NXP_LOG_WARNING("Table \"%s\" is in use\n", name);
                    ret = EACCES;
                }
                else
                {   /* Override (and ride to hell) */
                    NXP_LOG_WARNING("Table \"%s\" is in use\n", name);
                    fp_table->dmem_addr = 0U;
                }
            }
            if(EOK == ret)
            {
                /* Unlink all rules in the table if there are any */
                while (0U < fp_table->rule_count)
                {
                    rule = fci_fp_table_1st_rule(fp_table);
                    fci_fp_unlink_rule_from_chain(rule);
                }

                /* Remove/Free the table instance in ISA */
                (void)isa_release(&fci_fp_table_db.tables, fp_table);
            }
        }
    }
    return ret;
}

/**
* @brief Adds a rule into a table at given position
* @param[in] table_name Table where the rule shall be added
* @param[in] rule_name Rule which shall be added into a table.
* @param[in] position Position where to place rule. Either fci_fp_RULE_POSITION_LAST, fci_fp_RULE_POSITION_FIRST,
*            or an integer in range 0 to 255 describing the position.
* @note Single rule can belong to only one table.
* @return Either EOK or an error code.
*/
errno_t fci_fp_db_add_rule_to_table(char_t *table_name, char_t *rule_name, uint16 position)
{
    fci_fp_table_t *fp_table;
    fci_fp_rule_t *rule;
    errno_t ret = EINVAL; /* Invalid value */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if((NULL_PTR == table_name) || (NULL_PTR == rule_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Check that the rule does exist */
        rule = fci_fp_rule_get_first_common(&fci_fp_rule_db, FP_RULE_CRIT_NAME, rule_name);
        if(NULL_PTR == rule)
        {
            NXP_LOG_WARNING("Rule \"%s\" does not exist\n", rule_name);
            ret = ENOENT;
        }
        else
        {
            /* Check that the rule does not belong to any other table */
            if(NULL_PTR != rule->table)
            {
                NXP_LOG_WARNING("Rule \"%s\" is already part of the table \"%s\"\n", rule_name, rule->table->name);
                ret = EACCES;
            }
            else
            {
                /* Check that the table does exist */
                fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
                if(NULL_PTR == fp_table)
                {
                    NXP_LOG_WARNING("Table \"%s\" does not exist\n", table_name);
                    ret = ENOENT;
                }
                else
                {
                    /* Add rule into the table */
                    if(0U == fp_table->rule_count)
                    {   /* Empty list - ignore position */
                        if((position != FCI_FP_RULE_POSITION_FIRST) && (position != FCI_FP_RULE_POSITION_LAST))
                        {
                            NXP_LOG_WARNING("Adding into an empty table position %u ignored\n", position);
                        }
                        else
                        {
                        /* Do nothing */
                        }
                        fp_table->rules_chain_1st_idx = fci_fp_get_rule_index(rule);
                    }
                    else
                    {
                        add_rule_to_position(rule, fp_table, position);
                    }
                    rule->table = fp_table;
                    fp_table->rule_count += 1U;
                    ret = EOK;
                }
            }
        }
    }
    return ret;
}

/**
* @brief Removes the rule from a table
* @param[in] rule_name Rule to be removed from the table
* @details Each rule knows which table it belongs therefore the table reference is not needed.
* @return EOK or error code.
*/
errno_t fci_fp_db_remove_rule_from_table(char_t *rule_name)
{
    fci_fp_rule_t *rule;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == rule_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Check that the rule does exist */
        rule = fci_fp_rule_get_first_common(&fci_fp_rule_db, FP_RULE_CRIT_NAME, rule_name);
        if(NULL_PTR == rule)
        {
            NXP_LOG_WARNING("Rule \"%s\" does not exist\n", rule_name);
            ret = ENOENT;
        }
        else
        {
            /* Check that the rule is in a table */
            if(NULL_PTR != rule->table)
            {   /* Rule in a table - remove it */
                fci_fp_unlink_rule_from_chain(rule);
            }
            else
            {   /* Rule not in a table */
                NXP_LOG_WARNING("Rule \"%s\" is not part of any table\n", rule_name);
            }
            ret = EOK;
        }
    }
    return ret;
}

/**
* @brief Returns table address in the DMEM
* @param[in] table Table instance which DMEM address shall be returned.
* @return DMEM address of the table or 0 if table has not been written into DMEM yet.
*/
uint32 fci_fp_db_get_table_dmem_addr(char_t *table_name)
{
    const fci_fp_table_t *fp_table;
    uint32 retval;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(NULL == table_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        retval = 0U;
    }
    else
#endif
    {
        fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
        if(NULL == fp_table)
        {
            NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
            retval = 0U;
        }
        else
        {
            retval = fp_table->dmem_addr;
        }
    }
    return retval;
}

/**
* @brief Writes flexible parser table into DMEM of all PEs in given Classifier
* @param[in] classifier Classifier which DMEM shall be written
* @param[in] table Table which shall be written
* @details Function allocates the DMEM to write the table and writes the table into
*          this memory. Use the function fci_fp_db_get_table_dmem_addr to obtain the
*          table address.
* @return Either EOK or an error code.
*/
errno_t fci_fp_db_push_table_to_hw(pfe_class_t *class, char_t *table_name)
{
    fci_fp_table_t *fp_table;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if((NULL_PTR == class)||(NULL_PTR == table_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Get the table */
        fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
        if(NULL_PTR == fp_table)
        {
            NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
            ret = ENOENT;
        }
        else
        {

            fp_table->dmem_addr = pfe_fp_create_table(class, fp_table->rule_count);
            fp_table->class = class;
            if(0U == fp_table->dmem_addr)
            {
                NXP_LOG_ERROR("Cannot write the table");
                ret = EFAULT;
            }
            else
            {
                ret = write_rules_to_table(fp_table, class, table_name);
            }
        }
    }
    return ret;
}

/**
* @brief Removes table from the DMEM in PEs when it is no longer in use
* @param[in] table_name Name of the table to be removed
* @warning Remove the table only if there are no references to it
* @details Removal of unused tables from the DMEM is needed to avoid depletion of the
*          DMEM memory pool.
* @return EOK or an error code.
*/
errno_t fci_fp_db_pop_table_from_hw(char_t *table_name)
{
    fci_fp_table_t *fp_table;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(NULL == table_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Get the table */
        fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
        if(NULL == fp_table)
        {
            NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
            ret = ENOENT;
        }
        else
        {

            /* Free the DMEM */
            pfe_fp_destroy_table(fp_table->class, fp_table->dmem_addr);
            /* Clear the references to DMEM */
            fp_table->dmem_addr = 0U;
            fp_table->class = NULL;
            ret = EOK;
        }
    }
    return ret;
}

/**
* @brief Returns name of the table being written at given DMEM address
* @param[in] addr Address to find the table
* @param[out] table_name Returned table name
* @return EOK or an error code
*/
errno_t fci_fp_db_get_table_from_addr(uint32 addr, char_t **table_name)
{
    const fci_fp_table_t *fp_table;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(NULL == table_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if(0U == addr)
        {   /* 0 is not valid table address, used as no-address */
            ret = EINVAL;
        }
        else
        {
            fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_ADDRESS, &addr);
            if(NULL == fp_table)
            {
                NXP_LOG_WARNING("Table with address 0x%x not found\n", (uint_t)addr);
                ret = ENOENT;
            }
            else
            {
                *table_name = (char_t *)fp_table->name;
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
 * @brief       Get first DB entry (table) matching the criterion
 * @param[in]   crit The criterion
 * @parma[in]   arg The criterion argument
 * @return      FP table instance or NULL if not found
 */
fci_fp_table_t *fci_fp_db_get_first(fci_fp_table_criterion_t crit, void *arg)
{
    return fci_fp_table_get_first(&fci_fp_table_db, crit, arg);
}

/**
* @brief Returns parameters of the first rule in the database
* @details Function is intended to start query of all rules in the database (by FCI).
* @param[out] rule_info the First rule data got from database
* @param[out] next_rule Name of the next rule (if any)
* @return EOK or an error code.
*/
errno_t fci_fp_db_get_first_rule(fci_fp_rule_info_t *rule_info, char_t **next_rule)
{
    fci_fp_rule_t *rule;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if((NULL_PTR == rule_info) || (NULL_PTR == next_rule))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        rule = fci_fp_rule_get_first_common(&fci_fp_rule_db, FP_RULE_CRIT_ALL, NULL_PTR);
        if(NULL_PTR == rule)
        {
            ret = ENOENT;
        }
        else
        {
            rule_info->rule_name = rule->name;
            rule_info->data = rule->data;
            rule_info->mask = rule->mask;
            rule_info->offset = rule->offset;
            rule_info->flags = rule->flags;
            *next_rule = rule->next_rule;
            ret = EOK;
        }
    }
    return ret;
}

/**
* @brief Returns parameters of the next rule in the database
* @details Function is intended to continue query of all rules in the database (by FCI).
* @param[out] rule_info the Next rule data got from database
* @param[out] next_rule Name of the next rule (if any)
* @return EOK or an error code.
*/
errno_t fci_fp_db_get_next_rule(fci_fp_rule_info_t *rule_info, char_t **next_rule)
{
    fci_fp_rule_t *rule;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if((NULL_PTR == rule_info) || (NULL_PTR == next_rule))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        rule = fci_fp_rule_get_next_common(&fci_fp_rule_db);
        if(NULL_PTR == rule)
        {
            ret = ENOENT;
        }
        else
        {
            rule_info->rule_name = rule->name;
            rule_info->data = rule->data;
            rule_info->mask = rule->mask;
            rule_info->offset = rule->offset;
            rule_info->flags = rule->flags;
            *next_rule = rule->next_rule;
            ret = EOK;
        }
    }
    return ret;
}

/**
* @brief Returns parameters of the first rule in the table
* @details Function is intended to start query of all rules in the table (by FCI).
* @param[in]  table_name Name of the table to query
* @param[out] rule_info the First rule data got from table
* @param[out] next_rule Name of the next rule (if any)
* @return EOK or an error code.
*/
errno_t fci_fp_db_get_table_first_rule(char_t *table_name, fci_fp_rule_info_t *rule_info, char_t **next_rule)
{
    fci_fp_table_t *fp_table;
    fci_fp_rule_t *rule;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if((NULL_PTR == table_name) || (NULL_PTR == rule_info) || (NULL_PTR == next_rule))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Get the table */
        fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
        if(NULL_PTR == fp_table)
        {
            NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
            ret = ENOENT;
        }
        else
        {
            /* Get the first rule */
            rule = fci_fp_rule_get_first_table(fp_table, FP_RULE_CRIT_ALL, NULL_PTR);
            if(NULL_PTR == rule)
            {
                ret = ENOENT;
            }
            else
            {
                rule_info->rule_name = rule->name;
                rule_info->data = rule->data;
                rule_info->mask = rule->mask;
                rule_info->offset = rule->offset;
                rule_info->flags = rule->flags;
                *next_rule = rule->next_rule;
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
* @brief Returns parameters of the next rule in the table
* @details Function is intended to start query of all rules in the table (by FCI).
* @param[in]  table_name Name of the table to query
* @param[out] rule_info the Next rule data got from table
* @param[out] next_rule Name of the next rule (if any)
* @return EOK or an error code.
*/
errno_t fci_fp_db_get_table_next_rule(char_t *table_name, fci_fp_rule_info_t *rule_info, char_t **next_rule)
{
    fci_fp_table_t *fp_table;
    fci_fp_rule_t *rule;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if((NULL == table_name) || (NULL == rule_info) || (NULL == next_rule))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Get the table */
        fp_table = fci_fp_table_get_first(&fci_fp_table_db, FP_TABLE_CRIT_NAME, table_name);
        if(NULL == fp_table)
        {
            NXP_LOG_WARNING("Table \"%s\" not found\n", table_name);
            ret = ENOENT;
        }
        else
        {
            /* Get the rule */
            rule = fci_fp_rule_get_next_table(fp_table);
            if(NULL == rule)
            {
                ret = ENOENT;
            }
            else
            {
                rule_info->rule_name = rule->name;
                rule_info->data = rule->data;
                rule_info->mask = rule->mask;
                rule_info->offset = rule->offset;
                rule_info->flags = rule->flags;
                *next_rule = rule->next_rule;
                ret = EOK;
            }
        }
    }
    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)

/**
* @brief Prints a rule in a human readable form
* @param[in] rule Rule to be printed
* @param[in] buf Buffer where to put the output
* @param[in] len Size of the buffer
* @param[in] verb_level Verbosity level
* @return Number of characters written into the buffer
*/
static uint32 fci_fp_print_rule(fci_fp_rule_t *rule, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;
    (void)verb_level;

    len += oal_util_snprintf(buf + len, buf_len - len, "%s = {", rule->name);
    /* Conditions */
    if((uint8)FP_FL_INVERT == ((uint8)rule->flags & (uint8)FP_FL_INVERT))
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "!");
    }
    len += oal_util_snprintf(buf + len, buf_len - len, "(0x%x & 0x%x == ", rule->data, rule->mask);
    if((uint8)FP_FL_L4_OFFSET == ((uint8)rule->flags & (uint8)FP_FL_L4_OFFSET))
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "frame[L4 header + %u] & 0x%x)", rule->offset, rule->mask);
    }
    if((uint8)FP_FL_L3_OFFSET == ((uint8)rule->flags & (uint8)FP_FL_L3_OFFSET))
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "frame[L3 header + %u] & 0x%x)", rule->offset, rule->mask);
    }
    else
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "frame[%u] & 0x%x)", rule->offset, rule->mask);
    }
    /* Consequences */
    if((uint8)FP_FL_REJECT == ((uint8)rule->flags & (uint8)FP_FL_REJECT))
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "? REJECT : use next rule");
    }
    else if((uint8)FP_FL_ACCEPT == ((uint8)rule->flags & (uint8)FP_FL_ACCEPT))
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "? ACCEPT : use next rule");
    }
    else
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "? use rule %s : use next rule", rule->next_rule);
    }
    len += oal_util_snprintf(buf + len, buf_len - len, "}\n");
    return len;
}

/**
* @brief Prints table rules in a human readable form
* @param[in] table Table to be printed
* @param[in] buf Buffer where to put the output
* @param[in] len Size of the buffer
* @param[in] verb_level Verbosity level
* @return Number of characters written into the buffer
*/
static uint32 fci_fp_print_table(const fci_fp_table_t *fp_table, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint16 i;
    uint32 len;
    fci_fp_rule_t *rule;

    len = oal_util_snprintf(buf, buf_len, "%s = {\n", fp_table->name);
    rule = fci_fp_table_1st_rule(fp_table);
    for (i = 0U; i < fp_table->rule_count; i++)
    {
        len += fci_fp_print_rule(rule, buf + len, buf_len - len, verb_level);
        rule = fci_fp_rule_next_sibling(rule);
    }

    len += oal_util_snprintf(buf + len, buf_len - len, "\n}\n");
    return len;
}

/**
* @brief Prints all tables in a human readable form
* @param[in] table Table to be printed
* @param[in] buf Buffer where to put the output
* @param[in] len Size of the buffer
* @param[in] verb_level Verbosity level
* @return Number of characters written into the buffer
*/
uint32 fci_fp_print_tables(char_t *buf, uint32 buf_len, uint8 verb_level)
{
    const fci_fp_table_t *fp_table;
    uint32 len = 0U;
    uint32 ii;
    const pfe_isa_t *isa = &fci_fp_table_db.tables;

    for (ii = 0U; ii < isa->occupied_items_count; ii++)
    {
        fp_table = (fci_fp_table_t *)isa_item(isa, ii);
        len += fci_fp_print_table(fp_table, buf + len, buf_len - len, verb_level);
    }
    return len;
}

uint32 pfe_fp_get_text_statistics(pfe_fp_t *temp, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    const fci_fp_table_t *fp_table;
    pfe_ct_class_flexi_parser_stats_t c_stats;
    pfe_ct_class_flexi_parser_stats_t c_stats_sum;
    uint32 len = 0U;
    uint32 pe_idx;
    uint32 num_of_pes;
    uint32 ii;
    const pfe_isa_t *isa = &fci_fp_table_db.tables;

    (void)temp;

    for (ii = 0U; ii < isa->occupied_items_count; ii++)
    {
        fp_table = (fci_fp_table_t *)isa_item(isa, ii);
        num_of_pes = pfe_class_get_num_of_pes(fp_table->class);
        len += oal_util_snprintf(buf + len, buf_len - len, "%s = {\n", fp_table->name);
        if (fp_table->dmem_addr != 0U)
        {
            (void)autolibc_memset(&c_stats_sum, 0, sizeof(pfe_ct_class_flexi_parser_stats_t));

            for(pe_idx = 0U; pe_idx < num_of_pes; pe_idx++)
            {
                (void)autolibc_memset(&c_stats, 0, sizeof(pfe_ct_class_flexi_parser_stats_t));
                (void)pfe_fp_table_get_statistics(fp_table->class, pe_idx, fp_table->dmem_addr, &c_stats);
                pfe_class_flexi_parser_stats_endian(&c_stats);
                pfe_class_sum_flexi_parser_stats(&c_stats_sum, &c_stats);
            }

            len += pfe_class_fp_stat_to_str(&c_stats_sum, buf + len, buf_len - len, verb_level);
        }
        else
        {
            len += oal_util_snprintf(buf + len, buf_len - len, "Table not enabled in Firmware\n");
        }

        len += oal_util_snprintf(buf + len, buf_len - len, "\n}\n");
    }

    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [112/185]: src\fci_fw_features.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "fci_fp_db.h"
#include "fci_msg.h"
#include "fci.h"
#include "fci_internal.h"
#include "oal.h"
#include "pfe_feature_mgr.h"
#include "fci_fw_features.h"
#include "oal_util.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t fci_internal_read_fw_feature(const char *feature_name, uint16 *fci_ret, fpp_fw_features_cmd_t *reply_buf, uint32 *reply_len);
static errno_t fci_internal_read_fw_feature_element_init(errno_t *element_cmd_ret, fpp_fw_features_element_cmd_t  *fp_cmd, uint16 *fci_ret,  char **feature_name, uint32 *reply_len);
static errno_t fci_internal_mng_fw_feat_elmnt_act_update(fpp_fw_features_element_cmd_t *fp_cmd, uint16 *fci_ret, const char *feature_name);
static errno_t fci_internal_mng_fw_feat_elmnt_act_query(fpp_fw_features_element_cmd_t *fp_cmd,uint16 *fci_ret, const char *feature_name, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len);
static errno_t fci_internal_mng_fw_feat_elmnt_act_query_cont(fpp_fw_features_element_cmd_t *fp_cmd,uint16 *fci_ret, const char *feature_name, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len);
static errno_t fci_internal_read_fw_feature_table_element(fpp_fw_features_element_cmd_t *fp_cmd, uint16 *fci_ret, const char *table_el_name, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len);
#if defined(PFE_CFG_NULL_ARG_CHECK)
static bool_t null_arg_check(fci_msg_t *msg, uint16 *fci_ret, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len);
#endif /* PFE_CFG_NULL_ARG_CHECK */

/**
 * @brief           Processes FPP_CMD_FW_FEATURES commands
 * @param[in]       msg FCI message containing the FPP_CMD_FP_FEATURES command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_fw_features_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with domain DB protected against concurrent accesses.
 */
errno_t fci_fw_features_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fw_features_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_fw_features_cmd_t *fp_cmd;
    const char *feature_name;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == msg) || (NULL_PTR == fci_ret) || (NULL_PTR == reply_buf) || (NULL_PTR == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {

        *fci_ret = FPP_ERR_OK;

        /* Important to initialize to avoid buffer overflows */
        if (*reply_len < sizeof(fpp_fw_features_cmd_t))
        {

            /*  Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_fw_features_cmd_t)\n");
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            (void)autolibc_memset(reply_buf, 0, sizeof(*reply_buf));
            fp_cmd = (fpp_fw_features_cmd_t *)(msg->msg_cmd.payload);

            switch (fp_cmd->action)
            {
                case FPP_ACTION_UPDATE:
                {
                    ret = pfe_feature_mgr_set_val(fp_cmd->name, fp_cmd->val);
                    if(EOK != ret)
                    {
                        if (EFAULT == ret)
                        {
                            /*  FCI command try to change value of an ignore state feature. Respond with FCI error code. */
                            *fci_ret = FPP_ERR_FW_FEATURE_NOT_AVAILABLE;
                        }
                        else
                        {
                            /*  FCI command requested nonexistent entity. Respond with FCI error code. */
                            *fci_ret = FPP_ERR_FW_FEATURE_NOT_FOUND;
                        }
                        ret = EOK;
                    }

                    break;
                }

                case FPP_ACTION_QUERY:
                {
                    ret = pfe_feature_mgr_get_first(&feature_name);
                    if(ret != EOK)
                    {
                        /*  End of the query process (no more entities to report). Respond with FCI error code. */
                        *fci_ret = FPP_ERR_FW_FEATURE_NOT_FOUND;
                        ret = EOK;
                    }
                    else
                    {
                        ret = fci_internal_read_fw_feature(feature_name, fci_ret, reply_buf, reply_len);                        

                    }
                    break;

                }
                case FPP_ACTION_QUERY_CONT:
                {
                    ret = pfe_feature_mgr_get_next(&feature_name);
                    if(ret != EOK)
                    {
                        /*  End of the query process (no more entities to report). Respond with FCI error code. */
                        *fci_ret = FPP_ERR_FW_FEATURE_NOT_FOUND;
                        ret = EOK;
                    }
                    else
                    {
                        ret = fci_internal_read_fw_feature(feature_name, fci_ret, reply_buf, reply_len);
                    }
                    break;
                }

                default:
                {
                    /*  Unknown action. Respond with FCI error code. */
                    NXP_LOG_WARNING("FPP_CMD_FW_FEATURE: Unknown action received: 0x%x\n", fp_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    ret = EOK;
                    break;
                }
            }
        }
    }

    return ret;
}


#if defined(PFE_CFG_NULL_ARG_CHECK)
/**
 * @brief           Helper function for NULL argument check
 */
static bool_t null_arg_check(fci_msg_t *msg, uint16 *fci_ret, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len)
{
    bool_t ret_val = FALSE;

    ret_val = ((NULL_PTR == msg) || (NULL_PTR == fci_ret) || (NULL_PTR == reply_buf) || (NULL_PTR == reply_len));

    return ret_val;
}
#endif /* PFE_CFG_NULL_ARG_CHECK */


/**
 * @brief           Processes FPP_CMD_FW_FEATURE_ELEMENT commands
 * @param[in]       msg FCI message containing the FPP_CMD_FW_FEATURE_ELEMENT command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_fw_features_element_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with domain DB protected against concurrent accesses.
 */
errno_t fci_fw_features_element_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_fw_features_element_cmd_t *fp_cmd;
    char *feature_name;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(TRUE == null_arg_check(msg, fci_ret, reply_buf, reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fp_cmd = (fpp_fw_features_element_cmd_t *)(msg->msg_cmd.payload);
        feature_name = fp_cmd->fw_feature_name;

        if (EOK == fci_internal_read_fw_feature_element_init(&ret, fp_cmd, fci_ret, &feature_name, reply_len))
        {
            /* No data written to reply buffer (yet) */
            *reply_len = 0U;
            (void)autolibc_memset(reply_buf, 0, sizeof(*reply_buf));

            switch (fp_cmd->action)
            {
                case FPP_ACTION_UPDATE:
                {
                    ret = fci_internal_mng_fw_feat_elmnt_act_update(fp_cmd, fci_ret, feature_name);
                    break;
                }
                case FPP_ACTION_QUERY:
                {
                    ret = fci_internal_mng_fw_feat_elmnt_act_query(fp_cmd, fci_ret, feature_name, reply_buf, reply_len);
                    break;
                }
                case FPP_ACTION_QUERY_CONT:
                {
                    ret = fci_internal_mng_fw_feat_elmnt_act_query_cont(fp_cmd, fci_ret, feature_name, reply_buf, reply_len);
                    break;
                }
                default:
                {
                    /*      Unknown action. Respond with FCI error code. */
                    NXP_LOG_WARNING("FPP_CMD_FW_FEATURE: Unknown action received: 0x%x\n", fp_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    ret = EOK;
                    break;
                }
            }
        }
    }

    return ret;
}


/**
 * @brief           Helper for check condition before process FPP_CMD_FW_FEATURES commands
 * @param[out]      feature_name Firmware feature name
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_fw_features_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          FCI command return value
 */
static errno_t fci_internal_read_fw_feature(const char *feature_name, uint16 *fci_ret, fpp_fw_features_cmd_t *reply_buf, uint32 *reply_len)
{
    errno_t ret = EOK;
    const char *str;

    ret = pfe_feature_mgr_get_val(feature_name, &reply_buf->val);
    if (EOK == ret)
    {
        ret = pfe_feature_mgr_get_def_val(feature_name, &reply_buf->def_val);
    }
    if (EOK == ret)
    {
        ret = pfe_feature_mgr_get_variant(feature_name, &reply_buf->flags);
    }
    if (EOK == ret)
    {
        (void)autolibc_strncpy(reply_buf->name, feature_name, FPP_FEATURE_NAME_SIZE);
        reply_buf->name[FPP_FEATURE_NAME_SIZE - 1U] = '\0';
        ret = pfe_feature_mgr_get_desc(feature_name, &str);
    }

    if (EOK == ret)
    {
        (void)autolibc_strncpy(reply_buf->desc, str, FPP_FEATURE_DESC_SIZE);
        reply_buf->desc[FPP_FEATURE_NAME_SIZE - 1U] = '\0';
        *reply_len = sizeof(fpp_fw_features_cmd_t);
        *fci_ret = FPP_ERR_OK;
    }
    else
    {
        /*  Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
        *reply_len = sizeof(fpp_fw_features_cmd_t);
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
    }

    return ret;
}
/**
 * @brief           Helper for check condition before process FPP_CMD_FW_FEATURE_ELEMENT commands
 * @param[out]      element_cmd_ret return value for caller function
 * @param[in]       fp_cmd the FPP_CMD_FW_FEATURE_ELEMENT command
 * @param[out]      fci_ret FCI command return value
 * @param[in,out]   feature_name name of requested feature
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
static errno_t fci_internal_read_fw_feature_element_init(errno_t *element_cmd_ret, fpp_fw_features_element_cmd_t  *fp_cmd, uint16 *fci_ret,  char **feature_name, uint32 *reply_len)

{
    errno_t ret = EOK;
    
    if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        *element_cmd_ret = EPERM;
        ret = EPERM;
    }
    else
    {
        *fci_ret = FPP_ERR_OK;

        /* Important to initialize to avoid buffer overflows */
        if (*reply_len < sizeof(fpp_fw_features_element_cmd_t))
        {
            /*      Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_fw_features_element_cmd_t)\n");
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            *element_cmd_ret = EINVAL;
            ret = EINVAL;
        }
        else
        {
            if ('\0' == fp_cmd->fw_feature_name[0])
            {
                NXP_LOG_WARNING("Feature invalid name (fpp_fw_features_element_cmd_t)\n");
                *fci_ret = FPP_ERR_FW_FEATURE_NOT_FOUND;
                *element_cmd_ret = EOK;
                ret = EEXIST;
            }
            else
            {
                if (('u' == (*feature_name)[0]) && ('_' == (*feature_name)[1]))
                {
                    *feature_name += 2;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           Helper for manage FPP_ACTION_UPDATE of FPP_CMD_FW_FEATURE_ELEMENT commands
 * @param[in]       fp_cmd the FPP_CMD_FW_FEATURE_ELEMENT command
 * @param[out]      fci_ret FCI command return value
 * @param[in]       feature_name name of requested feature
 * @return          EOK if success, error code otherwise
 */
static errno_t fci_internal_mng_fw_feat_elmnt_act_update(fpp_fw_features_element_cmd_t *fp_cmd, uint16 *fci_ret, const char *feature_name)
{
    errno_t ret = EOK;
    if (pfe_feature_mgr_is_available(feature_name))
    {
        ret = pfe_feature_mgr_table_set_val(fp_cmd->fw_feature_name, (pfe_table_type_t) fp_cmd->group, fp_cmd->element_name, fp_cmd->index, (uint8 *)fp_cmd->payload);
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_FW_FEATURE_ELEMENT_NOT_FOUND;
        }
    }
    else
    {
        *fci_ret = FPP_ERR_FW_FEATURE_NOT_AVAILABLE;
    }
    ret = EOK;

    return ret;
}


/**
 * @brief           Helper function for function fci_fw_features_element_cmd case FPP_ACTION_QUERY
 */
static errno_t fci_internal_mng_fw_feat_elmnt_act_query(fpp_fw_features_element_cmd_t *fp_cmd,uint16 *fci_ret, const char *feature_name, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len)
{
    const char *table_el_name;
    errno_t ret = EOK;

    if (pfe_feature_mgr_is_available(feature_name))
    {
        if ('\0' == fp_cmd->element_name[0])
        {
            ret = pfe_feature_mgr_table_first(fp_cmd->fw_feature_name, (pfe_table_type_t) fp_cmd->group, &table_el_name);
            if (ret != EOK)
            {
                /*      End of the query process (no more entities to report). Respond with FCI error code. */
                *fci_ret = FPP_ERR_FW_FEATURE_ELEMENT_NOT_FOUND;
                ret = EOK;
            }
            else
            {
                ret = fci_internal_read_fw_feature_table_element(fp_cmd, fci_ret, table_el_name, reply_buf, reply_len);
                if (ret != EOK)
                {
                /*      Internal problem. */
                    *reply_len = sizeof(fpp_fw_features_element_cmd_t);
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
            }
        }
        else
        {
            ret = fci_internal_read_fw_feature_table_element(fp_cmd, fci_ret, fp_cmd->element_name, reply_buf, reply_len);
            if (ret != EOK)
            {
                *reply_len = sizeof(fpp_fw_features_element_cmd_t);
                *fci_ret = FPP_ERR_FW_FEATURE_ELEMENT_NOT_FOUND;
                ret = EOK;
            }
        }
    }
    else
    {
        *fci_ret = FPP_ERR_FW_FEATURE_NOT_AVAILABLE;
        ret = EOK;
    }

    return ret;
}


/**
 * @brief           Helper function for function fci_fw_features_element_cmd case FPP_ACTION_QUERY_CONT
 */
static errno_t fci_internal_mng_fw_feat_elmnt_act_query_cont(fpp_fw_features_element_cmd_t *fp_cmd,uint16 *fci_ret, const char *feature_name, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len)
{
    const char *table_el_name;
    errno_t ret = EOK;

    if (pfe_feature_mgr_is_available(feature_name))
    {
        ret = pfe_feature_mgr_table_next(fp_cmd->fw_feature_name, (pfe_table_type_t) fp_cmd->group, &table_el_name);
        if(ret != EOK)
        {
            /*      End of the query process (no more entities to report). Respond with FCI error code. */
            *fci_ret = FPP_ERR_FW_FEATURE_ELEMENT_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            ret = fci_internal_read_fw_feature_table_element(fp_cmd, fci_ret, table_el_name, reply_buf, reply_len);
            if (ret != EOK)
            {
                /*      Internal problem. */
                *reply_len = sizeof(fpp_fw_features_element_cmd_t);
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
        }
    }
    else
    {
        *fci_ret = FPP_ERR_FW_FEATURE_NOT_AVAILABLE;
        ret = EOK;
    }

    return ret;
}


/**
 * @brief           Read data helper for FPP_CMD_FW_FEATURE_ELEMENT commands
 * @param[in]       fp_cmd the FPP_CMD_FW_FEATURE_ELEMENT command
 * @param[out]      fci_ret FCI command return value
 * @param[in]       table_el_name table element name to read
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_fw_features_element_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
static errno_t fci_internal_read_fw_feature_table_element(fpp_fw_features_element_cmd_t *fp_cmd, uint16 *fci_ret, const char *table_el_name, fpp_fw_features_element_cmd_t *reply_buf, uint32 *reply_len)
{
    errno_t ret = EOK;

    ret = pfe_feature_mgr_table_get_size(fp_cmd->fw_feature_name, (pfe_table_type_t) fp_cmd->group, table_el_name, &reply_buf->unit_size);
    if (ret == EOK)
    {
        ret = pfe_feature_mgr_table_get_multiplicity(fp_cmd->fw_feature_name, (pfe_table_type_t) fp_cmd->group, table_el_name, &reply_buf->count);
    }
    if (ret == EOK)
    {
        ret = pfe_feature_mgr_table_get_payload(fp_cmd->fw_feature_name, (pfe_table_type_t) fp_cmd->group, table_el_name, (uint8 *)reply_buf->payload);
    }
    if(EOK == ret)
    {
        (void)autolibc_strncpy(reply_buf->element_name, table_el_name, FPP_FEATURE_NAME_SIZE);
        (void)autolibc_strncpy(reply_buf->fw_feature_name, fp_cmd->fw_feature_name, FPP_FEATURE_NAME_SIZE);
        reply_buf->element_name[FPP_FEATURE_NAME_SIZE - 1U] = '\0';
        reply_buf->fw_feature_name[FPP_FEATURE_NAME_SIZE - 1U] = '\0';
        *reply_len = sizeof(fpp_fw_features_element_cmd_t);
        *fci_ret = FPP_ERR_OK;
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [113/185]: src\fci_hm.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_hm.c
 * @brief       Health Monitor management functions.
 * @details     All Health Monitor-related functionality provided by the FCI should be
 *              implemented within this file.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "pfe_hm.h"

#include "fci_internal.h"
#include "fci.h"

#ifdef PFE_CFG_FCI_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief      Callback from Health Monitor (HM) module. Intended for sending of FPP_CMD_HEALTH_MONITOR_EVENT.
 * @details    This callback is used by FCI as a notification of some HM activity.
 *             Function parameter is not utilized. A full search through HM database is done instead, 
 *             to make sure all existing HM items were reported.
 * @param[in]  unused  Health Monitor item as reported by HM module.
 *                     Not needed in this callback, but required by HM callback function signature.
 */
static void fci_hm_cb(pfe_hm_item_t *unused)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret;
    pfe_hm_item_t item;
    fci_msg_t msg;
    fpp_health_monitor_cmd_t hm_event = {0};
    uint8 u8LoopCnt = 0U;

    (void)unused;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_RAW_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        msg.type = FCI_MSG_CMD;
        msg.msg_cmd.code = FPP_CMD_HEALTH_MONITOR_EVENT;
        msg.msg_cmd.length = sizeof(fpp_health_monitor_cmd_t);
        msg.msg_cmd.sender = 0U;
        msg.client = NULL;

        /* Consume items from HM database and send FCI event for each of them. */
        do
        {
            if (FALSE == fci_context->is_some_client) /* Consume only if there is someone to send data to. */
            {
                ret = EPERM;
                NXP_LOG_DEBUG("No client to send data to.\n");
            }
            else
            {
                ret = pfe_hm_get(&item);
                if (EOK != ret)
                {
                    NXP_LOG_DEBUG("No more items in HM database\n");
                }
                else
                {
                    hm_event.action = 0U;
                    hm_event.id = oal_htons(item.id);
                    hm_event.type = (uint8)item.type;
                    hm_event.src = (uint8)item.src;
#ifdef NXP_LOG_ENABLED
                    (void)autolibc_strncpy(hm_event.desc, pfe_hm_get_event_str(item.id), (FPP_HEALTH_MONITOR_DESC_SIZE-1U));
#endif /* NXP_LOG_ENABLED */
                    {
                        /* Indented code block needed because ct_assert() otherwise causes
                         * compilation error 'ISO C90 forbids mixed declarations and code' */
                        ct_assert(sizeof(msg.msg_cmd.payload) >= sizeof(fpp_health_monitor_cmd_t));
                        (void)autolibc_memcpy(msg.msg_cmd.payload, &hm_event, sizeof(fpp_health_monitor_cmd_t));
                    }
                    ret = fci_core_client_send_broadcast(&msg, NULL);
                    u8LoopCnt++;
                }
            }
        }
        while ((EOK == ret) && (u8LoopCnt < PFE_HM_QUEUE_LEN));

#ifdef NXP_LOG_ENABLED
        if (u8LoopCnt >= PFE_HM_QUEUE_LEN)
        {
            NXP_LOG_WARNING("It already has too many events reported, and we exit intentionally\n");
        }
#endif /* NXP_LOG_ENABLED */
    }
}

/**
 * @brief  Read HM items from HM database and send FCI event for each reported HM item.
 */
void fci_hm_send_events(void)
{
    fci_hm_cb(NULL);
}

/**
 * @brief   Register FCI callback in Health Monitor module. This needs to be called during FCI init.
 * @return  EOK if success, error code otherwise.
 */
errno_t fci_hm_cb_register(void)
{
    errno_t ret = EINVAL;

    if (TRUE == pfe_hm_register_event_cb(fci_hm_cb))
    {
       ret = EOK;
    }

    return ret;
}

/**
 * @brief   Deregister FCI callback from Health Monitor module. This needs to be called during FCI fini.
 * @return  EOK if success, error code otherwise.
 */
errno_t fci_hm_cb_deregister(void)
{
    return EOK; /* HM module currently does not support callback deregistration. */
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */


===== 文件 [114/185]: src\fci_interfaces.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_interfaces.c
 * @brief       Ethernet interfaces management functions.
 * @details     All interfaces-related functionality provided by the FCI should be
 *              implemented within this file. This includes commmands dedicated
 *              to register and unregister interface to/from the FCI.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "pfe_platform_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "fci_internal.h"
#include "fci_fp_db.h"
#include "fci.h"
#include "pfe_mirror.h"
#include "pfe_feature_mgr.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t fci_interfaces_get_arg_info(fpp_if_m_args_t *m_arg, pfe_ct_if_m_rules_t rule, void **offset, uint32 *size, uint32 *fp_table_addr);
static errno_t fci_interfaces_destroy_fptables(const fpp_if_m_rules_t match, const pfe_ct_if_m_args_t* args);
static errno_t fci_interfaces_log_cmd_param_validate(fci_msg_t *msg, uint16 *fci_ret, fpp_log_if_cmd_t *reply_buf, uint32 *reply_len, const fci_t *fci_context);
static bool_t null_arg_check(fpp_if_m_args_t *m_arg, void **offset, uint32 *size);
static errno_t fp_table_addr_check(uint32 *fp_table_addr);
static errno_t mac_cmd__set_fci_ret_based_on_get_mac_addr_ret(uint16 *fci_ret, errno_t ret);
static errno_t mac_cmd__get_phy_if(uint16 *fci_ret, fpp_if_mac_cmd_t *if_mac_cmd, pfe_phy_if_t **phy_if);
static errno_t phy_cmd__fpp_action_update__set_mirrors(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if);
static errno_t phy_cmd__fpp_action_update__get_phy_if_and_set_mode(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t **phy_if);
static errno_t phy_cmd__fpp_action_update__set_flags_aux1(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch);
static errno_t phy_cmd__fpp_action_update__set_flags_aux2(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch);
static errno_t phy_cmd__fpp_action_update__set_flags_aux3(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch);
static errno_t phy_cmd__fpp_action_update__set_flags(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch);
static void phy_cmd__fpp_action_update__set_ftable(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if);
static errno_t phy_cmd__fpp_action_update__set_ptp_mgmt_if(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if);
static errno_t phy_cmd__fpp_action_query_cont__part2(uint16 *fci_ret, fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t *phy_if, bool_t *break_switch);
static errno_t phy_cmd__fpp_action_query_cont__part1(uint16 *fci_ret, pfe_if_db_entry_t *entry, fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t **phy_if, bool_t *break_switch);
static void phy_cmd__fpp_action_query_cont__stats_and_flags(fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t *phy_if, pfe_ct_phy_if_stats_t stats);
static void phy_cmd__fpp_action_query_cont__mirrors(fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t *phy_if);
static uint32 push_table_and_get_addr(char_t *table_name);
static void evaluate_ret_error(uint16 *fci_ret, errno_t ret, pfe_log_if_t *log_if, const char *log_message, const uint16 fci_val);
static void evaluate_ret_warning(uint16 *fci_ret, errno_t ret, const char *log_message, const uint16 fci_val);
static errno_t log_cmd__fpp_action_update__set_flags(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t *log_if);
static errno_t log_cmd__fpp_action_register(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd);
static errno_t log_cmd__fpp_action_deregister(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd);
static errno_t log_cmd__fpp_action_update(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, uint32 *reply_len);
static errno_t phy_cmd__fpp_action_update(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd);
static errno_t log_cmd__fpp_action_update__prepare_data(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t **log_if, pfe_ct_if_m_args_t *args, bool_t *break_switch);
static errno_t log_cmd__fpp_action_update__update_fp_tables(uint16 *fci_ret, uint32 *fp_table_destroy, char *fp_table_ifcmd, PFE_PTR(pfe_ct_fp_table_t) *fp0_table_args, bool_t *break_switch);
static void log_cmd__fpp_action_update__update_rules(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t *log_if);
static void log_cmd__fpp_action_update__destroy_fp_table(uint32 fp_table_destroy);
static void log_cmd__fpp_action_update__update_egress(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t *log_if);
static errno_t log_cmd__fpp_action_query_cont__stats_and_flags(fpp_log_if_cmd_t *reply_buf, pfe_log_if_t *log_if);
static void log_cmd__fpp_action_query_cont__rules(fpp_log_if_cmd_t *reply_buf, pfe_log_if_t *log_if);
static errno_t log_cmd__fpp_action_query_cont(uint16 *fci_ret, pfe_if_db_entry_t *entry, fpp_log_if_cmd_t *reply_buf, uint32 *reply_len);
static void log_cmd__fpp_action_query_cont__egress_and_rules(fpp_log_if_cmd_t *reply_buf, pfe_log_if_t *log_if);
static errno_t mac_cmd__fpp_action_register(uint16 *fci_ret, fpp_if_mac_cmd_t *if_mac_cmd, pfe_phy_if_t *phy_if, pfe_drv_id_t sender_phy_if_id);
static errno_t mac_cmd__fpp_action_deregister(uint16 *fci_ret, fpp_if_mac_cmd_t *if_mac_cmd, pfe_phy_if_t *phy_if, pfe_drv_id_t sender_phy_if_id);
static errno_t mac_cmd__fpp_action_query__finish_and_set_length(uint16 *fci_ret, fpp_if_mac_cmd_t *reply_buf, uint32 *reply_len, pfe_phy_if_t *phy_if);

/**
 * @brief           Null argument check
 */
static bool_t null_arg_check(fpp_if_m_args_t *m_arg, void **offset, uint32 *size)
{
    return (bool_t) ((NULL == m_arg) || (NULL == offset) || (NULL == size));/* */
}

/**
 * @brief           Null table pointer check
 */
static errno_t fp_table_addr_check(uint32 *fp_table_addr)
{
    errno_t retval = EOK;

    if(0U == *fp_table_addr) /* */
    {
        retval = ENOENT;
    }

    return retval;
}

/**
 * @brief           FPP_CMD_IF_MAC + FPP_ACTION_QUERY/_QUERY_CONT : Subroutine to set fci_ret based on return value of get_mac_addr_first()/_next().
 */
static errno_t mac_cmd__set_fci_ret_based_on_get_mac_addr_ret(uint16 *fci_ret, errno_t ret)
{
    if (EOK != ret)
    {
        if (ENOENT == ret)
        {
            /* FCI command attempted to register already registered entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_MAC_NOT_FOUND;
            ret = EOK;
        }
        if (EINVAL == ret)
        {
            /* FCI command requested unfulfillable action. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_IF_MAC + FPP_ACTION_QUERY/_QUERY_CONT : Subroutine to write rest of response data into the query response buffer (and to set response length).
 */
static errno_t mac_cmd__fpp_action_query__finish_and_set_length(uint16 *fci_ret, fpp_if_mac_cmd_t *reply_buf, uint32 *reply_len, pfe_phy_if_t *phy_if)
{
    errno_t  ret = EOK;

    if ((uint16)FPP_ERR_OK == *fci_ret)
    {
        /* Store phy_if name into reply message */
        (void)autolibc_strncpy(reply_buf->name, pfe_phy_if_get_name(phy_if), (uint32)IFNAMSIZ - 1U);

        /* Set reply length and return OK */
        *reply_len = sizeof(fpp_if_mac_cmd_t);
        *fci_ret = FPP_ERR_OK;
        ret = EOK;
    }

    return ret;
}

/**
 * @brief           FPP_CMD_IF_MAC : General subroutine to get phy_if.
 */
static errno_t mac_cmd__get_phy_if(uint16 *fci_ret, fpp_if_mac_cmd_t *if_mac_cmd, pfe_phy_if_t **phy_if)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    pfe_if_db_entry_t *entry = NULL;

    /*  Preparation: get the requested interface */
    ret = pfe_if_db_get_single(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_mac_cmd->name, &entry);

    if (EOK != ret)
    {
        /* DB not locked or locked by some other FCI user.*/
        /* FCI command requested unfulfillable action. Respond with FCI error code. */
        NXP_LOG_WARNING("Incorrect session ID detected\n");
        *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
        ret = EOK;
    }
    else
    {
        /* Check if entry is not NULL and get physical interface */
        if (NULL != entry)
        {
            *phy_if = pfe_if_db_entry_get_phy_if(entry);
        }

        /* Check if the entry exists */
        if (NULL == *phy_if)
        {
            /* Parent physical interface doesn't exist or cannot be extracted from the entry. */
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to update mirror objects of phy_if.
 */
static errno_t phy_cmd__fpp_action_update__set_mirrors(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if)
{
    uint32 i;
    errno_t ret = EOK;
    pfe_mirror_t *mirror = NULL;

    for(i = 0U; i < (uint32)FPP_MIRRORS_CNT; i++)
    {
        /* RX */
        if('\0' == if_cmd->rx_mirrors[i][0])
        {   /* Mirror is disabled */
            if (EOK != pfe_phy_if_set_rx_mirror(phy_if, i, NULL))
            {
                NXP_LOG_ERROR("Configures the selected RX mirror failed\n");
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
                break;
            }
        }
        else
        {   /* Mirror is enabled and to be configured */
            /* Get requested mirror handle */
            mirror = pfe_mirror_get_first(MIRROR_BY_NAME, if_cmd->rx_mirrors[i]);
            if(NULL == mirror)
            {
                /* FCI command requested nonexistent entity. Respond with FCI error code. */
                NXP_LOG_WARNING("Mirror %s cannot be found\n", if_cmd->rx_mirrors[i]);
                *fci_ret = FPP_ERR_MIRROR_NOT_FOUND;
                ret = EOK;
                break;
            }
            /* Set the mirror */
            if (EOK != pfe_phy_if_set_rx_mirror(phy_if, i, mirror))
            {
                /*  Notify mirror module we are done working with the mirror instance. */
                pfe_mirror_put(mirror);
                mirror = NULL;

                NXP_LOG_ERROR("Configures the selected RX mirror failed\n");
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
                break;
            }
            /*  Notify mirror module we are done working with the mirror instance. */
            pfe_mirror_put(mirror);
            mirror = NULL;

        }
        /* TX */
        if('\0' == if_cmd->tx_mirrors[i][0])
        {   /* Mirror is disabled */
            if (EOK != pfe_phy_if_set_tx_mirror(phy_if, i, NULL))
            {
                NXP_LOG_ERROR("Configures the selected TX mirror failed\n");
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
                break;
            }
        }
        else
        {   /* Mirror is enabled and to be configured */
            /* Get requested mirror handle */
            mirror = pfe_mirror_get_first(MIRROR_BY_NAME, if_cmd->tx_mirrors[i]);
            if(NULL == mirror)
            {
                /* FCI command requested nonexistent entity. Respond with FCI error code. */
                NXP_LOG_WARNING("Mirror %s cannot be found\n", if_cmd->rx_mirrors[i]);
                *fci_ret = FPP_ERR_MIRROR_NOT_FOUND;
                ret = EOK;
                break;
            }
            /* Set the mirror */
            if (EOK != pfe_phy_if_set_tx_mirror(phy_if, i, mirror))
            {
                /*  Notify mirror module we are done working with the mirror instance. */
                pfe_mirror_put(mirror);
                mirror = NULL;

                NXP_LOG_ERROR("Configures the selected TX mirror failed\n");
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
                break;
            }
            /*  Notify mirror module we are done working with the mirror instance. */
            pfe_mirror_put(mirror);
            mirror = NULL;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to get phy_if object. Also set mode and blocking state of the phy_if.
 */
static errno_t phy_cmd__fpp_action_update__get_phy_if_and_set_mode(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t **phy_if)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EINVAL;
    pfe_if_db_entry_t *entry = NULL;

    /* Get the requested interface */
    ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);

    if(EOK != ret)
    {
        NXP_LOG_WARNING("Incorrect session ID detected\n");
        *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
    }
    else
    {
        /* Check if entry is not NULL and get physical interface */
        if(NULL != entry)
        {
            *phy_if = pfe_if_db_entry_get_phy_if(entry);
        }

        /* Check if the entry exits*/
        if((NULL == entry) || (NULL == *phy_if))
        {
            /* Interface doesn't exist or couldn't be extracted from the entry */
            *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        }
        else
        {
            /*  Set the interface block state - use the fact the enumerations
                have same values */
            ret = pfe_phy_if_set_block_state(*phy_if, (pfe_ct_block_state_t)if_cmd->block_state);
            if(EOK != ret)
            {
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
            }
            else
            {
                /* Set the interface mode */
                ret = pfe_phy_if_set_op_mode(*phy_if, (pfe_ct_if_op_mode_t)(if_cmd->mode));
                if(EOK != ret)
                {
                    *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to update interface flags of phy_if. Part 1 of 3.
 */
static errno_t phy_cmd__fpp_action_update__set_flags_aux1(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch)
{
    errno_t ret = EOK;
    bool_t flag_in_cmd;
    bool_t flag_in_drv;

    /*  Enable/Disable */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_ENABLED))
    {
        ret = pfe_phy_if_enable(phy_if);
    }
    else
    {
        ret = pfe_phy_if_disable(phy_if);
    }

    if(EOK != ret)
    {
        NXP_LOG_ERROR("ENABLE flag wasn't updated correctly on %s\n",  pfe_phy_if_get_name(phy_if));
        *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
    }

    /* promisc */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_PROMISC))
    {
        ret = pfe_phy_if_promisc_enable(phy_if);
    }
    else
    {
        ret = pfe_phy_if_promisc_disable(phy_if);
    }

    if(EOK != ret)
    {
        NXP_LOG_ERROR("PROMISC flag wasn't updated correctly on %s\n",  pfe_phy_if_get_name(phy_if));
        *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
    }

    /*  VLAN conformance check */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_VLAN_CONF_CHECK))
    {
        flag_in_cmd = TRUE;
        ret = pfe_phy_if_set_flag(phy_if, IF_FL_VLAN_CONF_CHECK);
    }
    else
    {
        flag_in_cmd = FALSE;
        ret = pfe_phy_if_clear_flag(phy_if, IF_FL_VLAN_CONF_CHECK);
    }

    if(EOK != ret)
    {
        flag_in_drv = (IF_FL_NONE != pfe_phy_if_get_flag(phy_if, IF_FL_VLAN_CONF_CHECK));

        if (EPERM == ret)
        {
            if(flag_in_cmd == flag_in_drv)
            {
                /* Unavailable feature and FCI command didn't modify it. Continue through. */
                ret = EOK;
            }
            else
            {
                /* Unavailable feature and FCI command tried to modify it. Respond with FCI error code. */
                *fci_ret = FPP_ERR_FW_FEATURE_NOT_AVAILABLE;
                ret = EOK;
                *break_switch = TRUE;
            }
        }
        else
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("VLAN_CONF_CHECK flag wasn't updated correctly on %s\n",  pfe_phy_if_get_name(phy_if));
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            *break_switch = TRUE;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to update interface flags of phy_if. Part 2 of 3.
 */
static errno_t phy_cmd__fpp_action_update__set_flags_aux2(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch)
{
    errno_t ret = EOK;
    bool_t flag_in_cmd;
    bool_t flag_in_drv;
    
    /*  PTP conformance check */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_PTP_CONF_CHECK))
    {
        flag_in_cmd = TRUE;
        ret = pfe_phy_if_set_flag(phy_if, IF_FL_PTP_CONF_CHECK);
    }
    else
    {
        flag_in_cmd = FALSE;
        ret = pfe_phy_if_clear_flag(phy_if, IF_FL_PTP_CONF_CHECK);
    }

    if(EOK != ret)
    {
        flag_in_drv = (IF_FL_NONE != pfe_phy_if_get_flag(phy_if, IF_FL_PTP_CONF_CHECK));

        if (EPERM == ret)
        {
            if(flag_in_cmd == flag_in_drv)
            {
                /* Unavailable feature and FCI command didn't modify it. Continue through. */
                ret = EOK;
            }
            else
            {
                /* Unavailable feature and FCI command tried to modify it. Respond with FCI error code. */
                *fci_ret = FPP_ERR_FW_FEATURE_NOT_AVAILABLE;
                ret = EOK;
                *break_switch = TRUE;
            }
        }
        else
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("PTP_CONF_CHECK flag wasn't updated correctly on %s\n",  pfe_phy_if_get_name(phy_if));
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            *break_switch = TRUE;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to update interface flags of phy_if. Part 3 of 3.
 */
static errno_t phy_cmd__fpp_action_update__set_flags_aux3(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch)
{
    errno_t ret = EOK;

    /*  PTP promiscuous mode */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_PTP_PROMISC))
    {
        ret = pfe_phy_if_set_flag(phy_if, IF_FL_PTP_PROMISC);
    }
    else
    {
        ret = pfe_phy_if_clear_flag(phy_if, IF_FL_PTP_PROMISC);
    }

    if(EOK != ret)
    {
        /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
        NXP_LOG_ERROR("PTP_PROMISC flag wasn't updated correctly on %s\n",  pfe_phy_if_get_name(phy_if));
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        *break_switch = TRUE;
    }
    else
    {
        /* Fast-Forward of ingress TCP SYN, RST, FIN */
        if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_FF_ALL_TCP))
        {
            ret = pfe_phy_if_set_flag(phy_if, IF_FL_FF_ALL_TCP);
        }
        else
        {
            ret = pfe_phy_if_clear_flag(phy_if, IF_FL_FF_ALL_TCP);
        }

        if(EOK != ret)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("FF_ALL_TCP flag wasn't updated correctly on %s",  pfe_phy_if_get_name(phy_if));
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            *break_switch = TRUE;
        }
        else
        {
            /*  QinQ support control */
            if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_ALLOW_Q_IN_Q))
            {
                ret = pfe_phy_if_set_flag(phy_if, IF_FL_ALLOW_Q_IN_Q);
            }
            else
            {
                ret = pfe_phy_if_clear_flag(phy_if, IF_FL_ALLOW_Q_IN_Q);
            }

            if(EOK != ret)
            {
                NXP_LOG_ERROR("ALLOW_Q_IN_Q flag wasn't updated correctly on %s\n",  pfe_phy_if_get_name(phy_if));
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
            }

            /*  TTL discard control */
            if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_DISCARD_TTL))
            {
                ret = pfe_phy_if_set_flag(phy_if, IF_FL_DISCARD_TTL);
            }
            else
            {
                ret = pfe_phy_if_clear_flag(phy_if, IF_FL_DISCARD_TTL);
            }

            if(EOK != ret)
            {
                NXP_LOG_ERROR("DISCARD_TTL flag wasn't updated correctly on %s\n",  pfe_phy_if_get_name(phy_if));
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
            }
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to update interface flags of phy_if.
 */
static errno_t phy_cmd__fpp_action_update__set_flags(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if, bool_t *break_switch)
{
    errno_t ret = EINVAL;

    ret = phy_cmd__fpp_action_update__set_flags_aux1(fci_ret, if_cmd, phy_if, break_switch);

    if(FALSE == *break_switch)
    {
        ret = phy_cmd__fpp_action_update__set_flags_aux2(fci_ret, if_cmd, phy_if, break_switch);

        if(FALSE == *break_switch)
        {
            ret = phy_cmd__fpp_action_update__set_flags_aux3(fci_ret, if_cmd, phy_if, break_switch);
        }
    }

    return ret;
}

/**
 * @brief           Pushes table to HW and returns the address
 */
static uint32 push_table_and_get_addr(char_t *table_name)
{
    const fci_t *fci_context = (fci_t *)&context;
    uint32 addr = 0U;

    addr = fci_fp_db_get_table_dmem_addr(table_name);
    if (0U == addr)
    {
        (void)fci_fp_db_push_table_to_hw(fci_context->class, table_name);
        addr = fci_fp_db_get_table_dmem_addr(table_name);
    }

    return addr;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to update Flexible Filter of phy_if.
 * @details         Flexible Filter of phy_if is a Flexible Parser table employed as a traffic filter.
 */
static void phy_cmd__fpp_action_update__set_ftable(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if)
{
    uint32 addr = 0U;
    char_t *name;
    errno_t ret = EOK;

    /*  Flexible Filter */
    if (0U != autolibc_strlen((char_t *)if_cmd->ftable))
    {
        /*  Validate table */
        if (NULL == fci_fp_db_get_first(FP_TABLE_CRIT_NAME, (void *)if_cmd->ftable))
        {
            /*  Table not found */
            NXP_LOG_WARNING("%s: FP table %s not found\n", pfe_phy_if_get_name(phy_if), if_cmd->ftable);
        }
        else
        {
            /*  If not already done, write the table to HW */
            addr = push_table_and_get_addr((char_t *)if_cmd->ftable);

            /*  Assign the table to the physical interface */
            ret = pfe_phy_if_set_ftable(phy_if, addr);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("%s: Could not set filter table: %d\n", pfe_phy_if_get_name(phy_if), ret);
                *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
            }
        }
    }
    else
    {
        /*  Disable the filter. Get table entry from DB first. */
        addr = pfe_phy_if_get_ftable(phy_if);
        if (EOK == fci_fp_db_get_table_from_addr(addr, &name))
        {
            /* Delete the table from DMEM - no longer in use, copy is in database */
            (void)fci_fp_db_pop_table_from_hw(name);
        }

        /*  Assign NULL-table to the physical interface */
        ret = pfe_phy_if_set_ftable(phy_if, 0U);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("%s: Could not set filter table: %d\n", pfe_phy_if_get_name(phy_if), ret);
            *fci_ret = FPP_ERR_IF_OP_UPDATE_FAILED;
        }
    }

}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE : Subroutine to update PTP management interface of phy_if.
 */
static errno_t phy_cmd__fpp_action_update__set_ptp_mgmt_if(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd, pfe_phy_if_t *phy_if)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_if_db_entry_t *mgmt_entry = NULL;
    pfe_phy_if_t *mgmt_if = NULL;
    errno_t ret = EOK;

    /* PTP mgmt interface */
    if ('\0' == if_cmd->ptp_mgmt_if[0])
    {
        /* Disable mgmt interface */
        ret = pfe_phy_if_set_mgmt_interface(phy_if, PFE_PHY_IF_ID_INVALID);
        if (EOK != ret)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("%s: Could not disable mgmt interface\n", pfe_phy_if_get_name(phy_if));
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
    }
    else
    {
        ret = pfe_if_db_get_single(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->ptp_mgmt_if, &mgmt_entry);
        if (EOK != ret)
        {
            /* FCI command requested unfulfillable action. Respond with FCI error code. */
            NXP_LOG_WARNING("Incorrect session ID detected\n");
            *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
            ret = EOK;
        }
        else
        {
            /* Check if entry is not NULL and get physical interface */
            if (NULL != mgmt_entry)
            {
                mgmt_if = pfe_if_db_entry_get_phy_if(mgmt_entry);
            }
            /* Check if the entry exists */
            if ((NULL == mgmt_entry) || (NULL == mgmt_if))
            {
                /* FCI command requested nonexistent entity. Respond with FCI error code. */
                *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
                ret = EOK;
            }
            else
            {
                /* Enable mgmt interface and set its target physical interface */
                ret = pfe_phy_if_set_mgmt_interface(phy_if, pfe_phy_if_get_id(mgmt_if));
                if (EOK != ret)
                {
                    /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                    NXP_LOG_ERROR("%s: Could not set new mgmt interface %s\n", pfe_phy_if_get_name(phy_if), pfe_phy_if_get_name(mgmt_if));
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_QUERY_CONT : Subroutine to write interface Flexible Filter info and PTP management interface info into query response buffer.
 */
static errno_t phy_cmd__fpp_action_query_cont__part2(uint16 *fci_ret, fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t *phy_if, bool_t *break_switch)
{
    const fci_t *fci_context = (fci_t *)&context;
    uint32 addr = 0U;
    char_t *name;
    pfe_ct_phy_if_id_t mgmt_if_id = PFE_PHY_IF_ID_INVALID;
    pfe_if_db_entry_t *mgmt_entry = NULL;
    pfe_phy_if_t *mgmt_if = NULL;
    errno_t  ret = EOK;

    /*  Get filter info */
    addr = pfe_phy_if_get_ftable(phy_if);
    if (0U != addr)
    {
        ret = fci_fp_db_get_table_from_addr(addr, &name);
        if (EOK == ret)
        {
            (void)autolibc_strncpy(reply_buf->ftable, name, sizeof(reply_buf->ftable) - 1U);
        }
        else
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("Can't get table name from DB: %d\n", ret);
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            *break_switch = TRUE;
        }
    }
    else
    {
        (void)autolibc_memset(reply_buf->ftable, 0, sizeof(reply_buf->ftable));
    }

    if(FALSE == *break_switch)
    {
        /* Get PTP mgmt interface */
        mgmt_if_id = pfe_phy_if_get_mgmt_interface(phy_if);
        if (PFE_PHY_IF_ID_INVALID <= mgmt_if_id)
        {
            (void)autolibc_memset(reply_buf->ptp_mgmt_if, 0, sizeof(reply_buf->ptp_mgmt_if));
        }
        else
        {
            ret = pfe_if_db_get_single(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_ID, (void*)mgmt_if_id, &mgmt_entry);
            if (EOK != ret)
            {
                /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                NXP_LOG_WARNING("Incorrect session ID detected\n");
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                *break_switch = TRUE;
            }
            else
            {
                /* Check if entry is not NULL and get physical interface */
                if (NULL != mgmt_entry)
                {
                    mgmt_if = pfe_if_db_entry_get_phy_if(mgmt_entry);
                }
                /* Check if the entry exists */
                if ((NULL == mgmt_entry) || (NULL == mgmt_if))
                {
                    /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                    NXP_LOG_ERROR("Unexpected NULL mgmt_if\n");
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    *break_switch = TRUE;
                }
                else
                {
                    (void)autolibc_strncpy(reply_buf->ptp_mgmt_if, pfe_phy_if_get_name(mgmt_if), (uint32)IFNAMSIZ-1U);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_QUERY_CONT : Subroutine to write interface statistics and interface flags into query response buffer.
 */
static void phy_cmd__fpp_action_query_cont__stats_and_flags(fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t *phy_if, pfe_ct_phy_if_stats_t stats)
{
    /* Copy the phy if statistics to reply */
    (void)autolibc_memcpy(&reply_buf->stats, &stats, sizeof(reply_buf->stats));

    /* Store phy_if name */
    (void)autolibc_strncpy(reply_buf->name, pfe_phy_if_get_name(phy_if), (uint32)IFNAMSIZ-1U);

    /* Store phy_if id */
    reply_buf->id = oal_htonl(pfe_phy_if_get_id(phy_if));

    reply_buf->flags |= (TRUE == pfe_phy_if_is_promisc(phy_if)) ? oal_htonl(FPP_IF_PROMISC) : 0U;
    reply_buf->flags |= (TRUE == pfe_phy_if_is_enabled(phy_if)) ? oal_htonl(FPP_IF_ENABLED) : 0U;
    reply_buf->flags |= ((uint32)IF_FL_NONE != (uint32)pfe_phy_if_get_flag(phy_if, IF_FL_VLAN_CONF_CHECK)) ? oal_htonl(FPP_IF_VLAN_CONF_CHECK) : 0U;
    reply_buf->flags |= ((uint32)IF_FL_NONE != (uint32)pfe_phy_if_get_flag(phy_if, IF_FL_PTP_CONF_CHECK)) ? oal_htonl(FPP_IF_PTP_CONF_CHECK) : 0U;
    reply_buf->flags |= ((uint32)IF_FL_NONE != (uint32)pfe_phy_if_get_flag(phy_if, IF_FL_PTP_PROMISC)) ? oal_htonl(FPP_IF_PTP_PROMISC) : 0U;
    reply_buf->flags |= ((uint32)IF_FL_NONE != (uint32)pfe_phy_if_get_flag(phy_if, IF_FL_FF_ALL_TCP)) ? oal_htonl(FPP_IF_FF_ALL_TCP) : 0U;
    reply_buf->flags |= ((uint32)IF_FL_NONE != (uint32)pfe_phy_if_get_flag(phy_if, IF_FL_ALLOW_Q_IN_Q)) ? oal_htonl(FPP_IF_ALLOW_Q_IN_Q) : 0U;
    reply_buf->flags |= ((uint32)IF_FL_NONE != (uint32)pfe_phy_if_get_flag(phy_if, IF_FL_DISCARD_TTL)) ? oal_htonl(FPP_IF_DISCARD_TTL) : 0U;

    /* Get the mode - use the fact enums have same values */
    reply_buf->mode = (fpp_phy_if_op_mode_t) pfe_phy_if_get_op_mode(phy_if);
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_QUERY_CONT : Subroutine to write interface mirrors into query response buffer.
 */
static void phy_cmd__fpp_action_query_cont__mirrors(fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t *phy_if)
{
    uint32 i;
    pfe_mirror_t *mirror = NULL;
    const char *str;

    for(i = 0U; i < (uint32)FPP_MIRRORS_CNT; i++)
    {
        /* RX */
        mirror = pfe_phy_if_get_rx_mirror(phy_if, i);
        if(NULL != mirror)
        {
            str = pfe_mirror_get_name(mirror);
            if(NULL != str)
            {
                (void)autolibc_strncpy(&reply_buf->rx_mirrors[i][0], str, 16);
                reply_buf->rx_mirrors[i][15] = '\0'; /* Ensure correct string end */
            }
            else
            {
                NXP_LOG_WARNING("Could not obtain mirror name\n");
            }
        }
        /*  Notify mirror module we are done working with the mirror instance. This releases the reference obtained from pfe_phy_if_get_rx_mirror(). */
        pfe_mirror_put(mirror);
        mirror = NULL;

        /* TX */
        mirror = pfe_phy_if_get_tx_mirror(phy_if, i);
        if(NULL != mirror)
        {
            str = pfe_mirror_get_name(mirror);
            if(NULL != str)
            {
                (void)autolibc_strncpy(&reply_buf->tx_mirrors[i][0], str, 16);
                reply_buf->tx_mirrors[i][15] = '\0'; /* Ensure correct string end */
            }
            else
            {
                NXP_LOG_WARNING("Could not obtain mirror name\n");
            }
        }
        /*  Notify mirror module we are done working with the mirror instance. This releases the reference obtained from pfe_phy_if_get_tx_mirror(). */
        pfe_mirror_put(mirror);
        mirror = NULL;
    }
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_QUERY_CONT : part 1
 */
static errno_t phy_cmd__fpp_action_query_cont__part1(uint16 *fci_ret, pfe_if_db_entry_t *entry, fpp_phy_if_cmd_t *reply_buf, pfe_phy_if_t **phy_if, bool_t *break_switch)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_ct_phy_if_stats_t stats = { 0 };
    pfe_ct_block_state_t block_state;
    errno_t ret = EOK;

    if (NULL == entry)
    {
        ret = pfe_if_db_get_next(fci_context->phy_if_db, fci_context->if_session_id, &entry);
        if(EOK != ret)
        {
            ret = EOK;
            *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
            *break_switch = TRUE;
        }

        if((FALSE == *break_switch) && (NULL == entry))
        {
            ret = EOK;
            *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
            *break_switch = TRUE;
        }
    }
    if(FALSE == *break_switch)
    {
        *phy_if = pfe_if_db_entry_get_phy_if(entry);
        if (NULL == *phy_if)
        {
            NXP_LOG_DEBUG("Was not possible to resolve DB entry to phy_if");
            *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
            *break_switch = TRUE;
        }
        else
        {
            ret = pfe_phy_if_get_stats(*phy_if, &stats);
            if(EOK != ret)
            {
                NXP_LOG_ERROR("Could not get interface statistics\n");
                *break_switch = TRUE;
            }
            else
            {
                phy_cmd__fpp_action_query_cont__stats_and_flags(reply_buf, *phy_if, stats);
                /* Get the block state */
                (void)pfe_phy_if_get_block_state(*phy_if, &block_state);
                /* Use the fact that the enums have same values */
                reply_buf->block_state = (fpp_phy_if_block_state_t)block_state;
                phy_cmd__fpp_action_query_cont__mirrors(reply_buf, *phy_if);
            }
        }
    }

    return ret;
}

/**
 * @brief           Get offset and size of the rule
 * @details         Errors are handled in platform driver
 * @param[in]       m_args pointer to the argument structure
 * @param[in]       rule single rule. See pfe_ct_if_m_rules_t
 * @param[in,out]   offset is set based on the rule to the structure m_arg
 * @param[in,out]   size of the underlying type in the struct based on the rule
 */
static errno_t fci_interfaces_get_arg_info(fpp_if_m_args_t *m_arg, pfe_ct_if_m_rules_t rule, void **offset, uint32 *size, uint32 *fp_table_addr)
{
    errno_t retval = EOK; /* Function return value */
    uint32 table_addr;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(null_arg_check(m_arg, offset, size)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        retval = EINVAL;
    }
    else
#else
        (void)(null_arg_check);
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (rule)
        {
            case IF_MATCH_VLAN:
            {
                *size = sizeof(m_arg->vlan);
                *offset = &m_arg->vlan;
                break;
            }

            case IF_MATCH_PROTO:
            {
                *size = sizeof(m_arg->proto);
                *offset = &m_arg->proto;
                break;
            }

            case IF_MATCH_SPORT:
            {
                *size = sizeof(m_arg->sport);
                *offset = &m_arg->sport;
                break;
            }

            case IF_MATCH_DPORT:
            {
                *size = sizeof(m_arg->dport);
                *offset = &m_arg->dport;
                break;
            }

            case IF_MATCH_SIP6:
            {
                *size = sizeof(m_arg->ipv.v6.sip);
                *offset = &m_arg->ipv.v6.sip;
                break;
            }

            case IF_MATCH_DIP6:
            {
                *size = sizeof(m_arg->ipv.v6.dip);
                *offset = &m_arg->ipv.v6.dip;
                break;
            }

            case IF_MATCH_SIP:
            {
                *size = sizeof(m_arg->ipv.v4.sip);
                *offset = &m_arg->ipv.v4.sip;
                break;
            }

            case IF_MATCH_DIP:
            {
                *size = sizeof(m_arg->ipv.v4.dip);
                *offset = &m_arg->ipv.v4.dip;
                break;
            }

            case IF_MATCH_ETHTYPE:
            {
                *size = sizeof(m_arg->ethtype);
                *offset = &m_arg->ethtype;
                break;
            }

            case IF_MATCH_FP0:
            {
                /* Get the table address in the HW */
                table_addr = fci_fp_db_get_table_dmem_addr(m_arg->fp_table0);
                *fp_table_addr = oal_htonl(table_addr);
                retval = fp_table_addr_check(fp_table_addr);
                *offset = fp_table_addr;
                *size = sizeof(uint32);
                break;
            }

            case IF_MATCH_FP1:
            {
                /* Get the table address in the HW */
                table_addr = fci_fp_db_get_table_dmem_addr(m_arg->fp_table1);
                *fp_table_addr = oal_htonl(table_addr);
                retval = fp_table_addr_check(fp_table_addr);
                *offset = fp_table_addr;
                *size = sizeof(uint32);
                break;
            }

            case IF_MATCH_SMAC:
            {
                *size = sizeof(m_arg->smac);
                *offset = &m_arg->smac;
                break;
            }

            case IF_MATCH_DMAC:
            {
                *size = sizeof(m_arg->dmac);
                *offset = &m_arg->dmac;
                break;
            }

            case IF_MATCH_HIF_COOKIE:
            {
                *size = sizeof(m_arg->hif_cookie);
                *offset = &m_arg->hif_cookie;
                break;
            }

            default:
            {
                *size = 0U;
                *offset = NULL;
                break;
            }
        }
    }
    return retval;
}

/**
 * @brief           Destroy FP tables if they are used.
 *                  Auxiliary function for logical interface processing.
 * @param[in]       match   Match rules of a logical interface.
 * @param[in]       args    Match rule arguments of a logical interface.
 * @return          EOK if success, error code otherwise
 */
static errno_t fci_interfaces_destroy_fptables(const fpp_if_m_rules_t match, const pfe_ct_if_m_args_t* args)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == args)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        char_t *table_name = NULL;

        if((uint32)FPP_IF_MATCH_FP0 == ((uint32)match & (uint32)FPP_IF_MATCH_FP0))
        {   /* A flexible parser table was dropped - it needs to be destroyed if it existed */
            if(0U != args->fp0_table)
            {   /* Table existed */
                (void)fci_fp_db_get_table_from_addr(args->fp0_table, &table_name);
                (void)fci_fp_db_pop_table_from_hw(table_name);
            }
        }
        if((uint32)FPP_IF_MATCH_FP1 == ((uint32)match & (uint32)FPP_IF_MATCH_FP1))
        {   /* A flexible parser table was dropped - it needs to be destroyed if it existed */
            if(0U != args->fp1_table)
            {   /* Table existed */
                (void)fci_fp_db_get_table_from_addr(args->fp1_table, &table_name);
                (void)fci_fp_db_pop_table_from_hw(table_name);
            }
        }
        ret = EOK;
    }
    return ret;
}

/**
 * @brief           Process interface atomic session related commands
 * @param[in]       msg FCI cmd code
 * @param[out]      fci_ret FCI return code
 * @return          EOK if success, error code otherwise
 */
errno_t fci_interfaces_session_cmd(uint32 code, uint16 *fci_ret)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fci_ret))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch(code)
        {
            case FPP_CMD_IF_LOCK_SESSION:
            {
                *fci_ret = FPP_ERR_OK;
                if (EOK != pfe_if_db_lock(&fci_context->if_session_id))
                {
                    *fci_ret = FPP_ERR_IF_RESOURCE_ALREADY_LOCKED;
                    NXP_LOG_DEBUG("DB lock failed\n");
                }
                break;
            }
            case FPP_CMD_IF_UNLOCK_SESSION:
            {
                *fci_ret = FPP_ERR_OK;
                if (EOK != pfe_if_db_unlock(fci_context->if_session_id))
                {
                    *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
                    NXP_LOG_DEBUG("DB unlock failed due to incorrect session ID\n");
                }
                break;
            }
            default:
            {
                NXP_LOG_WARNING("Unknown Interface Session Command Received\n");
                *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                break;
            }
        }
    }
    return ret;
}

/**
 * @brief           validate parameter processing FPP_CMD_LOG_IF commands
 * @param[in]       msg FCI message containing the FPP_CMD_LOG_IF command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_log_if_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @param[in,out]   fci_context fci context
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with interface DB session lock.
 */
static errno_t fci_interfaces_log_cmd_param_validate(fci_msg_t *msg, uint16 *fci_ret, fpp_log_if_cmd_t *reply_buf, uint32 *reply_len, const fci_t *fci_context)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len) || (NULL == fci_context)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_log_if_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_if_cmd_t)\n");
            ret = EINVAL;
        }
    }

    (void)msg;
    (void)fci_ret;
    (void)reply_buf;
    (void)fci_context;

    return ret;
}

/**
 * @brief           Auxiliary function evaluate return value and set fci_ret value, sets nxp log error
 */
static void evaluate_ret_error(uint16 *fci_ret, errno_t ret, pfe_log_if_t *log_if, const char *log_message, const uint16 fci_val)
{
    if( NULL != log_if)
    {
        if(EOK != ret)
        {
            NXP_LOG_ERROR("%s %s\n", log_message, pfe_log_if_get_name(log_if));
            *fci_ret = fci_val;
        }
    }
    else
    {
        if(EOK != ret)
        {
            NXP_LOG_ERROR("%s \n", log_message);
            *fci_ret = fci_val;
        }
    }
}

/**
 * @brief           Auxiliary function evaluate return value and set fci_ret value, sets nxp log warning
 */
static void evaluate_ret_warning(uint16 *fci_ret, errno_t ret, const char *log_message, const uint16 fci_val)
{
    if(EOK != ret)
    {
        NXP_LOG_WARNING("%s \n", log_message);
       *fci_ret = fci_val;
    }
    (void) log_message;      /*suppress compiler warning*/
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_UPDATE : Subroutine to update (set) flags of log_if.
 */
static errno_t log_cmd__fpp_action_update__set_flags(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t *log_if)
{
    errno_t ret = EOK;

    /* AND/OR rules */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_MATCH_OR))
    {
        ret = pfe_log_if_set_match_or(log_if);
    }
    else
    {
        ret = pfe_log_if_set_match_and(log_if);
    }

    evaluate_ret_error( fci_ret, ret, log_if, "AND/OR flag wasn't updated correctly on", FPP_ERR_IF_OP_UPDATE_FAILED);

    /* enable/disable */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_ENABLED))
    {
        ret = pfe_log_if_enable(log_if);
    }
    else
    {
        ret = pfe_log_if_disable(log_if);
    }

    evaluate_ret_error( fci_ret, ret, log_if, "ENABLE flag wasn't updated correctly on", FPP_ERR_IF_OP_UPDATE_FAILED);

    /* promisc */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_PROMISC))
    {
        ret = pfe_log_if_promisc_enable(log_if);
    }
    else
    {
        ret = pfe_log_if_promisc_disable(log_if);
    }

    evaluate_ret_error( fci_ret, ret, log_if, "PROMISC flag wasn't updated correctly on", FPP_ERR_IF_OP_UPDATE_FAILED);

    /* discard */
    if(0U != (oal_ntohl(if_cmd->flags) & (uint32)FPP_IF_DISCARD))
    {
        ret = pfe_log_if_discard_enable(log_if);
    }
    else
    {
        ret = pfe_log_if_discard_disable(log_if);
    }

    evaluate_ret_error( fci_ret, ret, log_if, "DISCARD flag wasn't updated correctly on", FPP_ERR_IF_OP_UPDATE_FAILED);

    return ret;
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_REGISTER
 */
static errno_t log_cmd__fpp_action_register(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_if_db_entry_t *entry = NULL;
    pfe_log_if_t *log_if = NULL;
    pfe_phy_if_t *phy_if = NULL;
    errno_t ret = EINVAL;

    /* Get the intended parent physical interface */
    ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->parent_name, &entry);
    if(EOK != ret)
    {
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
    }
    else
    {
        phy_if = pfe_if_db_entry_get_phy_if(entry);
        if(NULL == phy_if)
        {
            *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
            ret = ENOENT;
        }
        else
        {
            /* Create the logical interface */
            log_if = pfe_log_if_create(phy_if, if_cmd->name);
            if(NULL == log_if)
            {
                *fci_ret = FPP_ERR_IF_OP_CANNOT_CREATE;
                ret = ENOENT;
            }
            else
            {
                /* Add the interface into the database */
                ret = pfe_if_db_add(fci_context->log_if_db, fci_context->if_session_id, log_if, pfe_phy_if_get_id(phy_if));
                if(EOK != ret)
                {
                    pfe_log_if_destroy(log_if);
                    *fci_ret = FPP_ERR_IF_OP_CANNOT_CREATE;
                }
                else
                {
                    NXP_LOG_INFO("Added logical interface %s to physical interface %s\n", if_cmd->name, if_cmd->parent_name);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_DEREGISTER
 */
static errno_t log_cmd__fpp_action_deregister(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_if_db_entry_t *entry = NULL;
    pfe_log_if_t *log_if = NULL;
    pfe_ct_if_m_args_t args;
    pfe_ct_if_m_rules_t rules;
    errno_t ret = EINVAL;

    ret = pfe_if_db_get_first(fci_context->log_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);

    if(EOK != ret)
    {
        NXP_LOG_WARNING("Incorrect session ID detected\n");
        *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
    }
    else
    {
        /* Check if entry is not NULL and get logical interface */
        if(NULL != entry)
        {
            log_if = pfe_if_db_entry_get_log_if(entry);
        }

        /* Check if the entry exists */
        if((NULL == entry) || (NULL == log_if))
        {
            /* Interface doesn't exist or couldn't be extracted from the entry */
            *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
            ret = ENOENT;
        }
        else
        {
            /* Destroy FP tables if they were used by this interface. */
            if(EOK == pfe_log_if_get_match_rules(log_if, &rules, &args))
            {
                /* Fix endians of FP tables */
                args.fp0_table = oal_ntohl(args.fp0_table);
                args.fp1_table = oal_ntohl(args.fp1_table);

                /* Destroy FP tables */
                (void)fci_interfaces_destroy_fptables((fpp_if_m_rules_t)rules, &args);
            }

            /* Remove interface from the database */
            (void)pfe_if_db_remove(fci_context->log_if_db, fci_context->if_session_id, entry);
            /* Destroy the interface */
            pfe_log_if_destroy(log_if);
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_UPDATE : Subroutine to get a log_if object and prepare data for update of the log_if object.
 */
static errno_t log_cmd__fpp_action_update__prepare_data(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t **log_if, pfe_ct_if_m_args_t *args, bool_t *break_switch)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EINVAL;
    pfe_if_db_entry_t *entry;
    pfe_ct_if_m_rules_t rules;

    *break_switch = FALSE;
    ret = pfe_if_db_get_first(fci_context->log_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_NAME, if_cmd->name, &entry);

    if(EOK != ret)
    {
        NXP_LOG_WARNING("Incorrect session ID detected\n");
        *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
        *break_switch = TRUE;
    }
    else
    {
        /* Check if entry is not NULL and get logical interface */
        if(NULL != entry)
        {
            *log_if = pfe_if_db_entry_get_log_if(entry);
        }

        /* Check if the entry exists */
        if((NULL == entry) || (NULL == *log_if))
        {
            /* Interface doesn't exist or couldn't be extracted from the entry */
            *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
            *break_switch = TRUE;
        }
        else
        {
            /* Get the currently set rules */
            ret = pfe_log_if_get_match_rules(*log_if, &rules, args);
            if(ret != EOK)
            {
                *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
                *break_switch = TRUE;
            }
            else
            {
                /* Avoid mixing IPV4 and IPV6 rules */
                if ((0U != ((((uint32)FPP_IF_MATCH_SIP)  | ((uint32)FPP_IF_MATCH_DIP))  & oal_ntohl(if_cmd->match))) &&
                    (0U != ((((uint32)FPP_IF_MATCH_SIP6) | ((uint32)FPP_IF_MATCH_DIP6)) & oal_ntohl(if_cmd->match))))
                {
                    /* FCI command requested unfulfillable action. Respond with FCI error code. */
                    *fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
                    *break_switch = TRUE;
                }
                else
                {
                    /* Fix endians of FP tables */
                    args->fp0_table = oal_ntohl(args->fp0_table);
                    args->fp1_table = oal_ntohl(args->fp1_table);

                    rules = (pfe_ct_if_m_rules_t)(~oal_ntohl(if_cmd->match));

                    /* Drop all unset rules (if any) */
                    ret = pfe_log_if_del_match_rule(*log_if, rules);

                    /* Destroy FP tables if they are not used by new rules */
                    (void)fci_interfaces_destroy_fptables((fpp_if_m_rules_t)rules, args);

                    if(EOK == ret)
                    {
                        NXP_LOG_INFO("All match rules were dropped on %s before match rule update.\n",  pfe_log_if_get_name(*log_if));
                    }
                    else
                    {
                        NXP_LOG_WARNING("Dropping of all match rules on logical interface %s failed !!\n",  pfe_log_if_get_name(*log_if));
                        *fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_UPDATE : Subroutine to update FP tables of log_if.
 */
static errno_t log_cmd__fpp_action_update__update_fp_tables(uint16 *fci_ret, uint32 *fp_table_destroy, char *fp_table_ifcmd, PFE_PTR(pfe_ct_fp_table_t) *fp0_table_args, bool_t *break_switch)
{
    const fci_t *fci_context = (fci_t *)&context;
    uint32 fp_table_addr;
    errno_t ret = EOK;

    *break_switch = FALSE;

    /* Get the newly configured table address */
    fp_table_addr = fci_fp_db_get_table_dmem_addr(fp_table_ifcmd);
    if(0U == fp_table_addr)
    {   /* Table has not been created yet */
        ret = fci_fp_db_push_table_to_hw(fci_context->class, fp_table_ifcmd);
        if(EOK != ret)
        {   /* Failed to write */
            *fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
            *break_switch = TRUE;
        }
        else
        {
            /* We have just created the table therefore the existing one must be different
            and it needs to be destroyed before we overwrite the reference */
            if(0U != *fp0_table_args)
            {
                /* Table is still in use therefore it cannot be destroyed,
                just remember it */
                *fp_table_destroy = *fp0_table_args;
            }
        }
    }
    else
    {   /* Table does exist */
        /* Check whether it is already configured */
        if(fp_table_addr != *fp0_table_args)
        {   /* Different table is configured thus the new one must be in use
            somewhere else (because it does have the address) and cannot be
            used here */
            NXP_LOG_WARNING("Table %s already in use.\n", *fp_table_ifcmd);
            *fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
            *break_switch = TRUE;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_UPDATE : Subroutine to destroy Flexible Parser table.
 */
static void log_cmd__fpp_action_update__destroy_fp_table(uint32 fp_table_destroy)
{
    char_t *table_name;

    if(0U != fp_table_destroy)
    {
        (void)fci_fp_db_get_table_from_addr(fp_table_destroy, &table_name);
        (void)fci_fp_db_pop_table_from_hw(table_name);
    }
}


/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_UPDATE : Subroutine to update egress interface list of log_if.
 */
static void log_cmd__fpp_action_update__update_egress(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t *log_if)
{
    const fci_t *fci_context = (fci_t *)&context;
    uint32 index = 0U, egress = 0U;
    pfe_phy_if_t *phy_if = NULL;
    pfe_if_db_entry_t *entry;
    errno_t ret = EOK;

    /* Update egress in case at least one is set (old egress is dropped) */
    if(0U != if_cmd->egress)
    {
        NXP_LOG_INFO("Updating egress interfaces on %s (0x%x)\n",  pfe_log_if_get_name(log_if), (uint_t)oal_ntohl(if_cmd->egress));
        for(index = 0U; (uint32)PFE_PHY_IF_ID_INVALID > index;  ++index)
        {

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            if((uint32)PFE_PHY_IF_ID_HIF == index)
            {
                /* Skip currently not used interfaces */
                continue;
            }
#else
            if(((uint32)PFE_PHY_IF_ID_HIF == index) || ((uint32)PFE_PHY_IF_ID_HIF_NOCPY == index))
            {
                /* Skip currently not used interfaces */
                continue;
            }
#endif
            /* For each bit in egress mask search if the phy if exists */
            ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)index, &entry);
            if((EOK == ret) && (NULL != entry))
            {   /* phy if does exist */
                phy_if = pfe_if_db_entry_get_phy_if(entry);
                /* Check whether the phy if shall be added
                We are getting inputs in network order thus conversion is needed */
                if(0U != (oal_ntohl(if_cmd->egress) & (1UL << index)))
                {   /* Add */
                    /* If the ID exits add corresponding phy_if as egress to log_if*/
                    ret = pfe_log_if_add_egress_if(log_if, phy_if);
                    evaluate_ret_error(fci_ret, ret, log_if, "Could not set egress interface for", FPP_ERR_IF_EGRESS_UPDATE_FAILED);
                }
                else
                {   /* Do not add (drop from the list if already on the list) */
                    /* Get current egress interfaces */
                    ret = pfe_log_if_get_egress_ifs(log_if, &egress);
                    if(EOK == ret)
                    {
                        if(0U != (egress & ((uint32)1U << index)))
                        {   /* Interface is on the current list but not on the requested list - drop it */
                            ret = pfe_log_if_del_egress_if(log_if, phy_if);
                        }
                    }
                    evaluate_ret_error(fci_ret, ret, log_if, "Could not get and clear egress interface for", FPP_ERR_IF_EGRESS_UPDATE_FAILED);

                }
            }
            else
            {
                NXP_LOG_WARNING("Egress %u on %s is not set because it doesn't exist\n", (uint_t)index,  pfe_log_if_get_name(log_if));
                /* Error in input do not continue */
                *fci_ret = FPP_ERR_IF_EGRESS_DOESNT_EXIST;
            }
        }
    }
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_UPDATE : Subroutine to update interface rules of log_if.
 */
static void log_cmd__fpp_action_update__update_rules(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, pfe_log_if_t *log_if)
{
    uint32 index = 0U;
    void *offset = NULL;
    uint32 fp_table_addr;
    errno_t ret = EOK;
    uint32 size = 0U;

    /* Update each rule one by one */
    for(index = 0U; (8U * sizeof(if_cmd->match)) > index; ++index)
    {
        if(0U != (oal_ntohl(if_cmd->match) & (1UL << index)))
        {
            /* Resolve position of data and size */
            ret = fci_interfaces_get_arg_info(&if_cmd->arguments, (pfe_ct_if_m_rules_t)(oal_ntohl(if_cmd->match) & (1UL << index)), &offset, &size, &fp_table_addr);
            if(EOK != ret)
            {
                NXP_LOG_WARNING("Failed to get update argument\n");
                *fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
            }

            /* Add match rule and arguments */
            ret = pfe_log_if_add_match_rule(log_if, (pfe_ct_if_m_rules_t)(oal_ntohl(if_cmd->match) & (1UL << index)), offset, size);

            if(EOK != ret)
            {
                NXP_LOG_WARNING("Updating single rule on logical interface %s failed !!\n",  pfe_log_if_get_name(log_if));
                *fci_ret = FPP_ERR_IF_MATCH_UPDATE_FAILED;
            }
        }
    }
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_UPDATE
 */
static errno_t log_cmd__fpp_action_update(uint16 *fci_ret, fpp_log_if_cmd_t *if_cmd, uint32 *reply_len)
{
    errno_t ret = EINVAL;
    pfe_ct_if_m_args_t args;
    uint32 fp_table_destroy[2];
    pfe_log_if_t *log_if = NULL;
    bool_t break_switch = FALSE;

    *fci_ret = FPP_ERR_OK;
    *reply_len = sizeof(fpp_log_if_cmd_t);

    ret = log_cmd__fpp_action_update__prepare_data(fci_ret, if_cmd, &log_if, &args, &break_switch);
    if((EOK == ret) && (FALSE == break_switch))
    {
        /* Clear the storage for queues to be destroyed */
        fp_table_destroy[0] = 0U;
        fp_table_destroy[1] = 0U;
        /* We are going to configure Flexible parser - prepare table(s) */
        if((uint32)FPP_IF_MATCH_FP0 == (oal_ntohl(if_cmd->match) & (uint32)FPP_IF_MATCH_FP0))
        {
            ret = log_cmd__fpp_action_update__update_fp_tables(fci_ret, &fp_table_destroy[0], if_cmd->arguments.fp_table0, &args.fp0_table, &break_switch);
        }
        if(FALSE == break_switch)
        {
            if((uint32)FPP_IF_MATCH_FP1 == (oal_ntohl(if_cmd->match) & (uint32)FPP_IF_MATCH_FP1))
            {
                ret = log_cmd__fpp_action_update__update_fp_tables(fci_ret, &fp_table_destroy[1], if_cmd->arguments.fp_table1, &args.fp1_table, &break_switch);
            }
            if(FALSE == break_switch)
            {
                log_cmd__fpp_action_update__update_rules(fci_ret, if_cmd, log_if);

                log_cmd__fpp_action_update__destroy_fp_table(fp_table_destroy[0]);
                log_cmd__fpp_action_update__destroy_fp_table(fp_table_destroy[1]);

                log_cmd__fpp_action_update__update_egress(fci_ret, if_cmd, log_if);

                ret = log_cmd__fpp_action_update__set_flags(fci_ret, if_cmd, log_if);
            }
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_QUERY_CONT : Subroutine to write interface statistics and interface flags into the query response buffer.
 */
static errno_t log_cmd__fpp_action_query_cont__stats_and_flags(fpp_log_if_cmd_t *reply_buf, pfe_log_if_t *log_if)
{
    errno_t ret = EINVAL;
    pfe_ct_class_algo_stats_t stats = { 0 };

    ret = pfe_log_if_get_stats(log_if,&stats);
    if(EOK != ret)
    {
        NXP_LOG_ERROR("Could not get interface statistics\n");
    }
    else
    {
        /* Copy the log if statistics to reply */
        (void)autolibc_memcpy(&reply_buf->stats, &stats, sizeof(reply_buf->stats));

        /* Get important flag values */
        (void)autolibc_memset(&reply_buf->flags, 0, sizeof(reply_buf->flags));
        if(pfe_log_if_is_enabled(log_if))
        {
            reply_buf->flags |= oal_htonl(FPP_IF_ENABLED);
        }

        if(pfe_log_if_is_promisc(log_if))
        {
            reply_buf->flags |= oal_htonl(FPP_IF_PROMISC);
        }

        if(pfe_log_if_is_discard(log_if))
        {
            reply_buf->flags |= oal_htonl(FPP_IF_DISCARD);
        }

        if(pfe_log_if_is_match_or(log_if))
        {
            reply_buf->flags |= oal_htonl(FPP_IF_MATCH_OR);
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_QUERY_CONT : Subroutine to write interface rules and their arguments into the query response buffer.
 */
static void log_cmd__fpp_action_query_cont__rules(fpp_log_if_cmd_t *reply_buf, pfe_log_if_t *log_if)
{
    pfe_ct_if_m_rules_t rules;
    pfe_ct_if_m_args_t args;
    char_t *table_name;

    (void)autolibc_memset(&rules, 0, sizeof(pfe_ct_if_m_rules_t));
    (void)autolibc_memset(&args, 0, sizeof(pfe_ct_if_m_args_t));
    /* Store rules for FCI */
    if(EOK != pfe_log_if_get_match_rules(log_if, &rules, &args))
    {
        NXP_LOG_ERROR("Was not possible to get match rules and arguments\n");
    }

    /* Fix endians of FP tables */
    args.fp0_table = oal_ntohl(args.fp0_table);
    args.fp1_table = oal_ntohl(args.fp1_table);
    reply_buf->match = (fpp_if_m_rules_t)(oal_htonl(rules));

    /* Store match rule arguments for FCI */
    reply_buf->arguments.vlan = args.vlan;
    reply_buf->arguments.ethtype = args.ethtype;
    reply_buf->arguments.sport = args.sport;
    reply_buf->arguments.dport = args.dport;
    reply_buf->arguments.proto = args.proto;
    reply_buf->arguments.hif_cookie = args.hif_cookie;

    /* Copy IPV4 or IPV6 according to match rule */
    if (0U != ((((uint32)FPP_IF_MATCH_SIP6) | ((uint32)FPP_IF_MATCH_DIP6)) & (uint32)rules))
    {
        (void)autolibc_memcpy( &reply_buf->arguments.ipv.v6, &args.ipv.v6, sizeof(reply_buf->arguments.ipv.v6));
    }
    else
    {
        (void)autolibc_memcpy( &reply_buf->arguments.ipv.v4, &args.ipv.v4, sizeof(reply_buf->arguments.ipv.v4));
    }

    (void)autolibc_memcpy(reply_buf->arguments.smac, args.smac, 6U);
    (void)autolibc_memcpy(reply_buf->arguments.dmac, args.dmac, 6U);

    /* Translate names of flexible parser tables from addresses to strings. */
    (void)autolibc_memset(reply_buf->arguments.fp_table0, 0, IFNAMSIZ);
    (void)autolibc_memset(reply_buf->arguments.fp_table1, 0, IFNAMSIZ);
    if(EOK == fci_fp_db_get_table_from_addr(args.fp0_table, &table_name))
    {
        (void)autolibc_strcpy(reply_buf->arguments.fp_table0, table_name);
    }
    if(EOK == fci_fp_db_get_table_from_addr(args.fp1_table, &table_name))
    {
        (void)autolibc_strcpy(reply_buf->arguments.fp_table1, table_name);
    }
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_QUERY_CONT : Subroutine to write egress list and interface rules into the query response buffer.
 */
static void log_cmd__fpp_action_query_cont__egress_and_rules(fpp_log_if_cmd_t *reply_buf, pfe_log_if_t *log_if)
{
    uint32 egress = 0U;

    /* Store egress interfaces */
    if(EOK != pfe_log_if_get_egress_ifs(log_if, &egress))
    {
        NXP_LOG_ERROR("Was not possible to get egress interfaces\n");
    }
    reply_buf->egress = oal_htonl(egress);

    log_cmd__fpp_action_query_cont__rules(reply_buf, log_if);

    /* Set ids */
    reply_buf->id = oal_htonl(pfe_log_if_get_id(log_if));
    reply_buf->parent_id = oal_htonl(pfe_phy_if_get_id(pfe_log_if_get_parent(log_if)));
}

/**
 * @brief           FPP_CMD_LOG_IF + FPP_ACTION_QUERY_CONT
 */
static errno_t log_cmd__fpp_action_query_cont(uint16 *fci_ret, pfe_if_db_entry_t *entry, fpp_log_if_cmd_t *reply_buf, uint32 *reply_len)
{
    pfe_phy_if_t *phy_if = NULL;
    pfe_log_if_t *log_if = NULL;
    errno_t ret = EOK;
    bool_t break_switch = FALSE;

    log_if = pfe_if_db_entry_get_log_if(entry);

    if(NULL != log_if)
    {
        phy_if = pfe_log_if_get_parent(log_if);
    }
    /* Store names */
    if(NULL != phy_if)
    {
        (void)autolibc_strncpy(reply_buf->name, pfe_log_if_get_name(log_if), (uint32)IFNAMSIZ-1U);
        (void)autolibc_strncpy(reply_buf->parent_name, pfe_phy_if_get_name(phy_if), (uint32)IFNAMSIZ-1U);
    }
    else
    {
        NXP_LOG_DEBUG("Was not possible to resolve DB entry to log_if or parent phy_if");
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        break_switch = TRUE;
    }
    if(FALSE == break_switch)
    {
        ret = log_cmd__fpp_action_query_cont__stats_and_flags(reply_buf, log_if);

        if(EOK == ret)
        {
            log_cmd__fpp_action_query_cont__egress_and_rules(reply_buf, log_if);
            *reply_len = sizeof(fpp_log_if_cmd_t);
            *fci_ret = FPP_ERR_OK;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_IF_MAC + FPP_ACTION_REGISTER
 */
static errno_t mac_cmd__fpp_action_register(uint16 *fci_ret, fpp_if_mac_cmd_t *if_mac_cmd, pfe_phy_if_t *phy_if, pfe_drv_id_t sender_phy_if_id)
{
    errno_t ret = EINVAL;

    ret = pfe_phy_if_add_mac_addr(phy_if, if_mac_cmd->mac, sender_phy_if_id);
    if (EOK != ret)
    {
        if (EEXIST == ret)
        {
            /* FCI command attempted to register already registered entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_MAC_ALREADY_REGISTERED;
            ret = EOK;
        }
        if (EINVAL == ret)
        {
            /* FCI command requested unfulfillable action. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief           FPP_CMD_IF_MAC + FPP_ACTION_DEREGISTER
 */
static errno_t mac_cmd__fpp_action_deregister(uint16 *fci_ret, fpp_if_mac_cmd_t *if_mac_cmd, pfe_phy_if_t *phy_if, pfe_drv_id_t sender_phy_if_id)
{
    errno_t ret = EINVAL;

    ret = pfe_phy_if_del_mac_addr(phy_if, if_mac_cmd->mac, sender_phy_if_id);
    if (EOK != ret)
    {
        if (ENOENT == ret)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_MAC_NOT_FOUND;
            ret = EOK;
        }
        if (EINVAL == ret)
        {
            /* FCI command requested unfulfillable action. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_LOG_IF commands
 * @param[in]       msg FCI message containing the FPP_CMD_LOG_IF command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_log_if_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with interface DB session lock.
 */
errno_t fci_interfaces_log_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_log_if_cmd_t *reply_buf, uint32 *reply_len)
{
    const fci_t *fci_context = (fci_t *)&context;
    fpp_log_if_cmd_t *if_cmd;
    errno_t ret = EOK;
    pfe_if_db_entry_t *entry = NULL;


    ret = fci_interfaces_log_cmd_param_validate(msg, fci_ret, reply_buf, reply_len, fci_context);
    if(EOK == ret)
    {
        /*  No data written to reply buffer (yet) */
        *reply_len = 0U;
        /*  Initialize the reply buffer */
        (void)autolibc_memset(reply_buf, 0, sizeof(fpp_log_if_cmd_t));

        if_cmd = (fpp_log_if_cmd_t *)msg->msg_cmd.payload;

        switch(if_cmd->action)
        {
            case FPP_ACTION_REGISTER:
            {
                ret = log_cmd__fpp_action_register(fci_ret, if_cmd);
                break;
            }

            case FPP_ACTION_DEREGISTER:
            {
                ret = log_cmd__fpp_action_deregister(fci_ret, if_cmd);
                break;
            }

            case FPP_ACTION_UPDATE:
            {
                ret = log_cmd__fpp_action_update(fci_ret, if_cmd, reply_len);
                break;
            }
            case FPP_ACTION_QUERY:
            {
                ret = pfe_if_db_get_first(fci_context->log_if_db, fci_context->if_session_id, IF_DB_CRIT_ALL, NULL, &entry);
                if (NULL == entry)
                {
                    *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
                    evaluate_ret_warning( fci_ret, ret, "Incorrect session ID detected\n", FPP_ERR_IF_WRONG_SESSION_ID);
                    ret = EOK;
                    break;
                }
            }/* FALLTHRU */
            /* no break */

            case FPP_ACTION_QUERY_CONT:
            {
                if (NULL == entry)
                {
                    ret = pfe_if_db_get_next(fci_context->log_if_db, fci_context->if_session_id, &entry);
                    if (NULL == entry)
                    {
                        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
                        evaluate_ret_warning( fci_ret, ret, "Incorrect session ID detected\n", FPP_ERR_IF_WRONG_SESSION_ID);
                        ret = EOK;
                        break;
                    }
                }
                ret = log_cmd__fpp_action_query_cont(fci_ret, entry, reply_buf, reply_len);
                break;
            }
            default:
            {
                /*Do Nothing*/
                break;
            }
        }
    }

    return ret;
}

/**
 * @brief           Validate param before processing FPP_CMD_PHY_IF commands
 * @param[in]       msg FCI message containing the FPP_CMD_PHY_IF command
  * @param[in]      fci_context FCI context
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_phy_if_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with interface DB session lock.
 */

static errno_t fci_interface_phy_param_validate(fci_msg_t *msg, uint16 *fci_ret, fpp_phy_if_cmd_t *reply_buf, uint32 *reply_len, const fci_t *fci_context)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len) || (NULL == fci_context)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_phy_if_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_if_cmd_t)\n");
            ret = EINVAL;
        }
    }

    (void)msg;
    (void)fci_ret;
    (void)reply_buf;
    (void)fci_context;

    return ret;
}

/**
 * @brief           FPP_CMD_PHY_IF + FPP_ACTION_UPDATE
 */
static errno_t phy_cmd__fpp_action_update(uint16 *fci_ret, fpp_phy_if_cmd_t *if_cmd)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;
    bool_t break_switch = FALSE;

    /* Get the requested interface */
    ret = phy_cmd__fpp_action_update__get_phy_if_and_set_mode(fci_ret, if_cmd, &phy_if);
    if(EOK == ret)
    {
        (void) phy_cmd__fpp_action_update__set_mirrors(fci_ret, if_cmd, phy_if);
        ret = phy_cmd__fpp_action_update__set_flags(fci_ret, if_cmd, phy_if, &break_switch);
        if(FALSE == break_switch)
        {
            phy_cmd__fpp_action_update__set_ftable(fci_ret, if_cmd, phy_if);
            ret = phy_cmd__fpp_action_update__set_ptp_mgmt_if(fci_ret, if_cmd, phy_if);
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_PHY_IF commands
 * @param[in]       msg FCI message containing the FPP_CMD_PHY_IF command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_phy_if_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with interface DB session lock.
 */
errno_t fci_interfaces_phy_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_phy_if_cmd_t *reply_buf, uint32 *reply_len)
{
    const fci_t *fci_context = (fci_t *)&context;
    fpp_phy_if_cmd_t *if_cmd;
    errno_t ret = EOK;
    pfe_if_db_entry_t *entry = NULL;
    pfe_phy_if_t *phy_if = NULL;

    ret = fci_interface_phy_param_validate(msg, fci_ret, reply_buf, reply_len, fci_context);
    if (EOK == ret)
    {
        /*  No data written to reply buffer (yet) */
        *reply_len = 0U;
        /*  Initialize the reply buffer */
        (void)autolibc_memset(reply_buf, 0, sizeof(fpp_phy_if_cmd_t));

        if_cmd = (fpp_phy_if_cmd_t *)msg->msg_cmd.payload;

        switch (if_cmd->action)
        {
            case FPP_ACTION_UPDATE:
            {
                ret = phy_cmd__fpp_action_update(fci_ret, if_cmd);
                break;
            }

            case FPP_ACTION_QUERY:
            {
                ret = pfe_if_db_get_first(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_ALL, NULL, &entry);

                if(EOK != ret)
                {
                    NXP_LOG_WARNING("Incorrect session ID detected\n");
                    *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
                    break;
                }

                if (NULL == entry)
                {
                    ret = EOK;
                    *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
                    break;
                }
            } /* FALLTHRU */
            /* no break */

            case FPP_ACTION_QUERY_CONT:
            {
                bool_t break_switch = FALSE;

                ret = phy_cmd__fpp_action_query_cont__part1(fci_ret, entry, reply_buf, &phy_if, &break_switch);

                if(TRUE == break_switch)
                {
                    break;
                }
                ret = phy_cmd__fpp_action_query_cont__part2(fci_ret, reply_buf, phy_if, &break_switch);
                if(TRUE == break_switch)
                {
                    break;
                }

                /* Set reply length end return OK */
                *reply_len = sizeof(fpp_phy_if_cmd_t);
                *fci_ret = FPP_ERR_OK;
                ret = EOK;
                break;
            }

            default:
            {
                NXP_LOG_WARNING("Interface Command: Unknown action received: 0x%x\n", if_cmd->action);
                *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                break;
            }
        }
    }
    return ret;
}

/**
 * @brief           Validate param before processing FPP_CMD_IF_MAC commands
 * @param[in]       msg FCI message containing the FPP_CMD_IF_MAC command
* @param[in]        fci_context FCI context
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_if_mac_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with interface DB session lock.
 */
static errno_t fci_interface_mac_param_validate(fci_msg_t *msg, uint16 *fci_ret, fpp_if_mac_cmd_t *reply_buf, uint32 *reply_len, const fci_t *fci_context)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len) || (NULL == fci_context)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *fci_ret = FPP_ERR_OK;

        if (*reply_len < sizeof(fpp_if_mac_cmd_t))
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_if_mac_cmd_t)\n");
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            ret = EINVAL;
        }
    }

    (void)msg;
    (void)fci_ret;
    (void)reply_buf;
    (void)fci_context;

    return ret;
}

/**
 * @brief           Process FPP_CMD_IF_MAC commands
 * @param[in]       msg FCI message containing the FPP_CMD_IF_MAC command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_if_mac_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with interface DB session lock.
 */
errno_t fci_interfaces_mac_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_if_mac_cmd_t *reply_buf, uint32 *reply_len)
{
    const fci_t *fci_context = (fci_t *)&context;
    fpp_if_mac_cmd_t *if_mac_cmd = NULL;
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;
    pfe_drv_id_t sender_phy_if_id = (pfe_drv_id_t) PFE_CFG_LOCAL_IF;

    ret = fci_interface_mac_param_validate(msg, fci_ret, reply_buf, reply_len, fci_context);
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    if (EOK == ret)
    {
        /* Get FCI sender */
        ret = fci_sender_get_phy_if_id(msg->msg_cmd.sender, (pfe_ct_phy_if_id_t *) &sender_phy_if_id);
        if (EOK != ret)
        {
            NXP_LOG_WARNING("Unable to get FCI sender");
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
    }
#endif
    if (EOK == ret)
    {
        /* No data written to reply buffer (yet) */
        *reply_len = 0U;
        /* Initialize the reply buffer */
        (void)autolibc_memset(reply_buf, 0, sizeof(fpp_if_mac_cmd_t));

        /* Initialize pointer to the command data */
        if_mac_cmd = (fpp_if_mac_cmd_t *)msg->msg_cmd.payload;
        
        ret = mac_cmd__get_phy_if(fci_ret, if_mac_cmd, &phy_if);

        if ((uint16)FPP_ERR_OK == *fci_ret)
        {
            /* Process the command */
            switch (if_mac_cmd->action)
            {
                case FPP_ACTION_REGISTER:
                {
                    ret = mac_cmd__fpp_action_register(fci_ret, if_mac_cmd, phy_if, sender_phy_if_id);

                    /* No further actions. */
                    break;
                }

                case FPP_ACTION_DEREGISTER:
                {
                    ret = mac_cmd__fpp_action_deregister(fci_ret, if_mac_cmd, phy_if, sender_phy_if_id);

                    /*  No further actions. */
                    break;
                }

                case FPP_ACTION_QUERY:
                {
                    ret = pfe_phy_if_get_mac_addr_first(phy_if, reply_buf->mac, MAC_DB_CRIT_ALL, PFE_TYPE_ANY, sender_phy_if_id);
                    ret = mac_cmd__set_fci_ret_based_on_get_mac_addr_ret(fci_ret, ret);
                    ret = mac_cmd__fpp_action_query__finish_and_set_length(fci_ret, reply_buf, reply_len, phy_if);
                    break;
                }

                case FPP_ACTION_QUERY_CONT:
                {
                    ret = pfe_phy_if_get_mac_addr_next(phy_if, reply_buf->mac);
                    ret = mac_cmd__set_fci_ret_based_on_get_mac_addr_ret(fci_ret, ret);
                    ret = mac_cmd__fpp_action_query__finish_and_set_length(fci_ret, reply_buf, reply_len, phy_if);
                    break;
                }

                default: 
                {
                    /* Unknown action. Respond with FCI error code. */
                    NXP_LOG_WARNING("FPP_CMD_IF_MAC: Unknown action received: 0x%x\n", if_mac_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    ret = EOK;
                    break;
                }
            }
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [115/185]: src\fci_l2br.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_l2br.c
 * @brief       L2 bridge management functions.
 * @details     All bridge-related functionality provided by the FCI should be
 *              implemented within this file. This includes mainly bridge-related
 *              commands.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"

#include "fci_internal.h"
#include "fci.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE
#ifdef PFE_CFG_L2BRIDGE_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief           Process FPP_CMD_L2_FLUSH_* commands
 * @param[in]       msg FCI cmd code
 * @param[out]      fci_ret FCI return code
 * @return          EOK if success, error code otherwise
 */
errno_t fci_l2br_flush_cmd(uint32 code, uint16 *fci_ret)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fci_ret))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *fci_ret = FPP_ERR_OK;

        switch (code)
        {
            case FPP_CMD_L2_FLUSH_ALL:
            {
                ret = pfe_l2br_flush_all(fci_context->l2_bridge);
                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    NXP_LOG_ERROR("Can't flush MAC table entries: %d\n", ret);
                }

                break;
            }

            case FPP_CMD_L2_FLUSH_LEARNED:
            {
                ret = pfe_l2br_flush_learned(fci_context->l2_bridge);
                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    NXP_LOG_ERROR("Can't flush learned MAC table entries: %d\n", ret);
                }

                break;
            }

            case FPP_CMD_L2_FLUSH_STATIC:
            {
                ret = pfe_l2br_flush_static(fci_context->l2_bridge);
                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    NXP_LOG_ERROR("Can't flush static MAC table entries: %d\n", ret);
                }

                break;
            }

            default:
            {
                NXP_LOG_WARNING("Unknown L2 bridge command: 0x%x\n", (uint_t)code);
                *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                break;
            }
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_L2BRIDGE_ENABLE */
#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [116/185]: src\fci_l2br_domains.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_l2br_domains.c
 * @brief       L2 bridge domains management functions.
 * @details     All bridge domains-related functionality provided by the FCI should be
 *              implemented within this file. This includes mainly bridge domain-related
 *              commands.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"

#include "fci_internal.h"
#include "fci.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE
#ifdef PFE_CFG_L2BRIDGE_ENABLE

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* usage scope: fci_l2br_domain_cmd */
static const pfe_ct_l2br_action_t fci_to_l2br_action[4] = {L2BR_ACT_FORWARD, L2BR_ACT_FLOOD, L2BR_ACT_PUNT, L2BR_ACT_DISCARD};

#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t fci_l2br_domain_remove(pfe_l2br_domain_t *domain);
static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *phy_if);
uint32 fci_l2br_static_entry_get_valid_fw_list(void);
static errno_t fci_l2br_domain_cmd_register(const fci_t *fci_context, uint16 *fci_ret, fpp_l2_bd_cmd_t *bd_cmd);
static errno_t fci_l2br_domain_cmd_deregister(const fci_t *fci_context, uint16 *fci_ret, fpp_l2_bd_cmd_t *bd_cmd);
static errno_t fci_l2br_domain_cmd_update_check_if_list(pfe_l2br_domain_t *domain, const fci_t *fci_context, uint32 session_id, uint16 *fci_ret,const fpp_l2_bd_cmd_t *bd_cmd);
static errno_t fci_l2br_domain_cmd_update_set_action(pfe_l2br_domain_t **domain, const fci_t *fci_context, uint16 *fci_ret, const fpp_l2_bd_cmd_t *bd_cmd);
static errno_t fci_l2br_domain_cmd_query_cont_build_repply_buf(pfe_l2br_domain_t *domain, fpp_l2_bd_cmd_t **bd_cmd, uint16 *fci_ret, fpp_l2_bd_cmd_t *reply_buf, const fci_t *fci_context);
static errno_t update_domain_if(pfe_l2br_domain_t *domain, pfe_phy_if_t *phy_if, const fpp_l2_bd_cmd_t *bd_cmd, bool_t tag, uint32 ii);
static errno_t remove_if_from_domain(pfe_l2br_domain_t *domain, uint16 *fci_ret, const fpp_l2_bd_cmd_t *bd_cmd, uint32 ii);
static void revert_domain_creation(uint16 *fci_ret, const fpp_l2_bd_cmd_t *bd_cmd, pfe_l2br_domain_t **domain);
static errno_t l2br_static_entry_cmd_fpp_action_register(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *br_ent_cmd);
static errno_t l2br_static_entry_cmd_fpp_action_update(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *br_ent_cmd);
static errno_t l2br_static_entry_cmd_fpp_action_deregister(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *br_ent_cmd);
static errno_t l2br_static_entry_cmd_fpp_action_query_cont(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *reply_buf, uint32 *reply_len, fpp_l2_static_ent_cmd_t *br_ent_cmd, pfe_l2br_static_entry_t *entry);
static errno_t process_l2br_command(uint16 *fci_ret, fpp_l2_bd_cmd_t *reply_buf, uint32 *reply_len, fpp_l2_bd_cmd_t *bd_cmd, uint32 session_id);
static errno_t fci_l2br_domain_cmd_update(const fci_t *fci_context, uint32 session_id, uint16 *fci_ret, fpp_l2_bd_cmd_t *bd_cmd);


static errno_t fci_l2br_domain_cmd_register(const fci_t *fci_context, uint16 *fci_ret, fpp_l2_bd_cmd_t *bd_cmd)
{
    errno_t ret = EOK;

    /*  Check input values. We need to translate integer to pfe_ct_l2br_action_t therefore
        some validation needs to be performed first. */
    if ((bd_cmd->ucast_hit > 3U) || (bd_cmd->ucast_miss > 3U)
            || (bd_cmd->mcast_hit > 3U) || (bd_cmd->mcast_miss > 3U))
    {
        NXP_LOG_WARNING("Unsupported action code received\n");
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        ret = EOK;
    }
    else if (oal_ntohs(bd_cmd->vlan) <= 1U)
    {
        /*  0 - fall-back, 1 - default */
        NXP_LOG_WARNING("VLAN %d is reserved\n", oal_ntohs(bd_cmd->vlan));
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        ret = EOK;
    }
    else
    {
        /*  Add new bridge domain */
        ret = pfe_l2br_domain_create(fci_context->l2_bridge, oal_ntohs(bd_cmd->vlan));
        if (EPERM == ret)
        {
            NXP_LOG_WARNING("Domain %d already created\n", oal_ntohs(bd_cmd->vlan));
            *fci_ret = FPP_ERR_L2_BD_ALREADY_REGISTERED;
            ret = EOK;
        }
        else if (EOK != ret)
        {
            NXP_LOG_WARNING("Domain creation failed: %d\n", ret);
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else
        {
            NXP_LOG_DEBUG("Bridge domain %d created\n", oal_ntohs(bd_cmd->vlan));
        }
    }

    return ret;
}

static errno_t fci_l2br_domain_cmd_deregister(const fci_t *fci_context, uint16 *fci_ret, fpp_l2_bd_cmd_t *bd_cmd)
{
    errno_t ret = EINVAL;
    pfe_l2br_domain_t *local_domain = NULL;

    if (oal_ntohs(bd_cmd->vlan) <= 1U)
    {
        /*  0 - fall-back, 1 - default */
        NXP_LOG_WARNING("VLAN %d is reserved\n", oal_ntohs(bd_cmd->vlan));
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        ret = EOK;
    }

    if (EOK != ret)
    {
        /*  Get and delete bridge domain */
        local_domain = pfe_l2br_get_first_domain(fci_context->l2_bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)oal_ntohs(bd_cmd->vlan));
        if (NULL == local_domain)
        {
            NXP_LOG_WARNING("Domain %d not found\n", oal_ntohs(bd_cmd->vlan));
            *fci_ret = FPP_ERR_L2_BD_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            /*  Remove domain, release interfaces */
            ret = fci_l2br_domain_remove(local_domain);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Could not destroy bridge domain: %d\n", ret);
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            else
            {
                NXP_LOG_DEBUG("Bridge domain %d removed\n", oal_ntohs(bd_cmd->vlan));
            }
        }
    }

    return ret;
}

static errno_t remove_if_from_domain(pfe_l2br_domain_t *domain, uint16 *fci_ret, const fpp_l2_bd_cmd_t *bd_cmd, uint32 ii)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if;

    /*  Remove the interface if domain does contain it */
    phy_if = pfe_l2br_domain_get_first_if(domain, L2BD_IF_BY_PHY_IF_ID, (void *)(addr_t)ii);
    if (NULL != phy_if)
    {
        ret = fci_l2br_domain_remove_if(domain, phy_if);
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            NXP_LOG_ERROR("Domain %d: Failed to remove interface %d\n", oal_ntohs(bd_cmd->vlan), ii);
        }
        else
        {
            NXP_LOG_INFO("Domain %d: Interface %d removed\n", (int_t)oal_ntohs(bd_cmd->vlan), (int_t)ii);
        }
    }

    return ret;
}

static errno_t update_domain_if(pfe_l2br_domain_t *domain, pfe_phy_if_t *phy_if, const fpp_l2_bd_cmd_t *bd_cmd, bool_t tag, uint32 ii)
{
    errno_t ret = EOK;

    /* Suppress compiler warnings when logging functions are not enabled (when NXP_LOG_ENABLED not defined). */
    (void) bd_cmd;
    (void) ii;

    ret = pfe_l2br_domain_del_if(domain, phy_if);
    if (EOK != ret)
    {
       NXP_LOG_ERROR("Could not update interface within bridge domain: %d\n", ret);
    }
    else
    {
       ret = pfe_l2br_domain_add_if(domain, phy_if, tag);
       if (EOK != ret)
       {
           NXP_LOG_ERROR("Could not update interface within bridge domain: %d\n", ret);
       }
       else
       {
           NXP_LOG_INFO("Domain %d: Interface %d updated\n", (int_t)oal_ntohs(bd_cmd->vlan), (int_t)ii);
       }
    }

   return ret;
}

static errno_t fci_l2br_domain_cmd_update_check_if_list(pfe_l2br_domain_t *domain, const fci_t *fci_context, uint32 session_id, uint16 *fci_ret,const fpp_l2_bd_cmd_t *bd_cmd)
{
    uint32 ii;
    bool_t tag;
    pfe_phy_if_t *phy_if;
    errno_t ret = EOK;
    pfe_if_db_entry_t *if_db_entry = NULL;

    for (ii=0U; ((ii < (8U * sizeof(bd_cmd->if_list))) && (ii <= (uint32)PFE_PHY_IF_ID_MAX)); ii++)
    {
        /*  Check if interface shall be added or removed */
        if (0U != (oal_ntohl(bd_cmd->if_list) & (1UL << ii)))
        {
            /*  Only add interfaces which are known to platform interface database */
            ret = pfe_if_db_get_first(fci_context->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)ii, &if_db_entry);

            if(EOK != ret)
            {
                NXP_LOG_DEBUG("DB was locked in different session, entry wasn't retrieved from DB\n");
                *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
                break;
            }

            if (NULL != if_db_entry)
            {
                /*  Got valid physical interface */
                tag = (0U == (oal_ntohl(bd_cmd->untag_if_list) & (1UL << ii)));

                /* Get physical interface */
                phy_if = pfe_if_db_entry_get_phy_if(if_db_entry);

                /*  Add it to domain */
                ret = pfe_l2br_domain_add_if(domain, phy_if, tag);
                if (EEXIST == ret)
                {
                    /*  Already added. Update = remove old -> add new. Update is only due
                        to tag/untag flag. */
                    ret =  update_domain_if(domain, phy_if, bd_cmd, tag, ii);
                    if (EOK != ret)
                    {
                        break; /* break the 'for' loop */
                    }
                }
                else if (EOK != ret)
                {
                    NXP_LOG_ERROR("Could not add interface to bridge domain: %d\n", ret);
                    break; /* break the 'for' loop */
                }
                else
                {
                    /*  Added */
                    NXP_LOG_INFO("Domain %d: Interface %d added\n", (int_t)oal_ntohs(bd_cmd->vlan), (int_t)ii);
                }
            }
            else
            {
                /*  Interface list contains interface not found in FCI database */
                NXP_LOG_WARNING("Interface %d not found\n", (int_t)ii);
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = EOK;
                break; /* break the 'for' loop */
            }
        }
        else
        {
            ret = remove_if_from_domain(domain, fci_ret, bd_cmd, ii);
            if (EOK != ret)
            {
                break;
            }
        }
    }

    return ret;
}

static void revert_domain_creation(uint16 *fci_ret, const fpp_l2_bd_cmd_t *bd_cmd, pfe_l2br_domain_t **domain)
{
    /* This function is called from a code that is shared by REGISTER and UPDATE actions. The payload (revert) must be executed only for REGISTER action. */
    if (FPP_ACTION_REGISTER == bd_cmd->action)
    {
        /*  New domain has not been properly created. Gracefully revert here. */
        if (EOK != fci_l2br_domain_remove((*domain)))
        {
            NXP_LOG_ERROR("Could not revert domain creation\n");
        }
        /*  Report failure */
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
    }
}

static errno_t fci_l2br_domain_cmd_update_set_action(pfe_l2br_domain_t **domain, const fci_t *fci_context, uint16 *fci_ret, const fpp_l2_bd_cmd_t *bd_cmd)
{
    errno_t ret = EOK;

    /*  Get the domain instance (by VLAN) */
    *domain = pfe_l2br_get_first_domain(fci_context->l2_bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)oal_ntohs(bd_cmd->vlan));
    if (NULL == *domain)
    {
        /*  This shall never happen */
        NXP_LOG_DEBUG("New domain not found\n");
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        ret = ENOENT;
        revert_domain_creation(fci_ret, bd_cmd, domain);
    }

    if (EOK == ret)
    {
        /*  Set hit/miss actions */
        ret = pfe_l2br_domain_set_ucast_action((*domain), fci_to_l2br_action[bd_cmd->ucast_hit], fci_to_l2br_action[bd_cmd->ucast_miss]);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("Could not set uni-cast actions: %d\n", ret);
            revert_domain_creation(fci_ret, bd_cmd, domain);
        }
        else
        {
            ret = pfe_l2br_domain_set_mcast_action((*domain), fci_to_l2br_action[bd_cmd->mcast_hit], fci_to_l2br_action[bd_cmd->mcast_miss]);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Could not set multi-cast actions: %d\n", ret);
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                revert_domain_creation(fci_ret, bd_cmd, domain);
            }
        }
    }

    return ret;
}

static errno_t fci_l2br_domain_cmd_query_cont_build_repply_buf(pfe_l2br_domain_t *domain, fpp_l2_bd_cmd_t **bd_cmd, uint16 *fci_ret, fpp_l2_bd_cmd_t *reply_buf, const fci_t *fci_context)
{
    errno_t ret = EOK;
    pfe_ct_vlan_stats_t stats = {0};

    /*  Write the reply buffer */
    *bd_cmd = reply_buf;

    /*  Build reply structure */
    if (EOK != pfe_l2br_domain_get_vlan(domain, &(*bd_cmd)->vlan))
    {
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
    }
    else
    {
        /*  Endian... */
        (*bd_cmd)->vlan = oal_htons((*bd_cmd)->vlan);

        if (EOK != pfe_l2br_domain_get_ucast_action(domain, (pfe_ct_l2br_action_t *)&(*bd_cmd)->ucast_hit, (pfe_ct_l2br_action_t *)&(*bd_cmd)->ucast_miss))
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else if (EOK != pfe_l2br_domain_get_mcast_action(domain, (pfe_ct_l2br_action_t *)&(*bd_cmd)->mcast_hit, (pfe_ct_l2br_action_t *)&(*bd_cmd)->mcast_miss))
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else if (EOK != pfe_l2br_get_domain_stats(fci_context->l2_bridge, &stats, pfe_l2br_get_vlan_stats_index(domain)))
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else
        {

            /* Copy the domain statistics to reply */
            (void)autolibc_memcpy(&(*bd_cmd)->stats, &stats, sizeof((*bd_cmd)->stats));

            if (TRUE == pfe_l2br_domain_is_default(domain))
            {
                (*bd_cmd)->flags |= FPP_L2_BD_DEFAULT;
            }

            if (TRUE == pfe_l2br_domain_is_fallback(domain))
            {
                (*bd_cmd)->flags |= FPP_L2_BD_FALLBACK;
            }

            (*bd_cmd)->if_list = oal_htonl(pfe_l2br_domain_get_if_list(domain));
            (*bd_cmd)->untag_if_list = oal_htonl(pfe_l2br_domain_get_untag_if_list(domain));

            *fci_ret = FPP_ERR_OK;
            ret = EOK;
        }
    }

    return ret;
}


static errno_t l2br_static_entry_cmd_fpp_action_register(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *br_ent_cmd)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    pfe_mac_addr_t mac = { 0 };
    uint32 valid_if_list = 0;

    valid_if_list = fci_l2br_static_entry_get_valid_fw_list();
    /* Check if valid logical interfaces are requested */
    if (oal_ntohl(br_ent_cmd->forward_list) != (oal_ntohl(br_ent_cmd->forward_list) & valid_if_list))
    {
        NXP_LOG_WARNING("Invalid interfaces in forward list\n");
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        ret = EOK;
    }
    else
    {
        (void)autolibc_memcpy(mac, br_ent_cmd->mac, sizeof(pfe_mac_addr_t));
        ret = pfe_l2br_static_entry_create(fci_context->l2_bridge, oal_ntohs(br_ent_cmd->vlan), mac, oal_ntohl(br_ent_cmd->forward_list));
        if (EOK == ret) {
            NXP_LOG_DEBUG("Static entry %02x:%02x:%02x:%02x:%02x:%02x added to vlan %d\n", mac[0], mac[1], mac[2], mac[3], mac[4], mac[5], oal_ntohs(br_ent_cmd->vlan));
            *fci_ret = FPP_ERR_OK;
        }
        else if (EPERM == ret)
        {
            NXP_LOG_WARNING("Duplicit static entry %02x:%02x:%02x:%02x:%02x:%02x wasn't added to vlan %d\n", mac[0], mac[1], mac[2], mac[3], mac[4], mac[5], oal_ntohs(br_ent_cmd->vlan));
            *fci_ret = FPP_ERR_L2_STATIC_ENT_ALREADY_REGISTERED;
        }
        else
        {
            NXP_LOG_WARNING("Static entry %02x:%02x:%02x:%02x:%02x:%02x wasn't added to vlan %d\n", mac[0], mac[1], mac[2], mac[3], mac[4], mac[5], oal_ntohs(br_ent_cmd->vlan));
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
    }

    return ret;
}

static errno_t l2br_static_entry_cmd_fpp_action_update(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *br_ent_cmd)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    pfe_l2br_static_entry_t *entry = NULL;
    uint32 valid_if_list = 0;

    valid_if_list = fci_l2br_static_entry_get_valid_fw_list();
    /* Check if valid logical interfaces are requested */
    if (oal_ntohl(br_ent_cmd->forward_list) != (oal_ntohl(br_ent_cmd->forward_list) & valid_if_list))
    {
        NXP_LOG_WARNING("Invalid interfaces in forward list\n");
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        ret = EOK;
    }
    else
    {
        /* search for entry update fw list */
        entry = pfe_l2br_static_entry_get_first(fci_context->l2_bridge, L2SENT_CRIT_BY_MAC_VLAN, (void*)(addr_t)oal_ntohs(br_ent_cmd->vlan), (void*)br_ent_cmd->mac);
        if (NULL == entry)
        {
            *fci_ret = FPP_ERR_L2_STATIC_EN_NOT_FOUND;
        }
        else
        {
            *fci_ret = FPP_ERR_OK;

            if (EOK != pfe_l2br_static_entry_replace_fw_list(fci_context->l2_bridge, entry, oal_ntohl(br_ent_cmd->forward_list)))
            {
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            if (EOK != pfe_l2br_static_entry_set_local_flag(fci_context->l2_bridge, entry, br_ent_cmd->local))
            {
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            if (EOK != pfe_l2br_static_entry_set_src_discard_flag(fci_context->l2_bridge, entry, br_ent_cmd->src_discard))
            {
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            if (EOK != pfe_l2br_static_entry_set_dst_discard_flag(fci_context->l2_bridge, entry, br_ent_cmd->dst_discard))
            {
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
        }
    }

    return ret;
}

static errno_t l2br_static_entry_cmd_fpp_action_deregister(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *br_ent_cmd)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    pfe_l2br_static_entry_t *entry = NULL;

    /* search for entry and delete if the entery exists */
    entry = pfe_l2br_static_entry_get_first(fci_context->l2_bridge, L2SENT_CRIT_BY_MAC_VLAN, (void*)(addr_t)oal_ntohs(br_ent_cmd->vlan), (void*)br_ent_cmd->mac);
    if (NULL == entry)
    {
        *fci_ret = FPP_ERR_L2_STATIC_EN_NOT_FOUND;
    }
    else
    {
        *fci_ret = FPP_ERR_OK;

        if (EOK != pfe_l2br_static_entry_destroy(fci_context->l2_bridge, entry))
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
    }

    return ret;
}

static errno_t l2br_static_entry_cmd_fpp_action_query_cont(uint16 *fci_ret, fpp_l2_static_ent_cmd_t *reply_buf, uint32 *reply_len, fpp_l2_static_ent_cmd_t *br_ent_cmd, pfe_l2br_static_entry_t *entry)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    bool_t break_switch = FALSE;

    if (NULL == entry)
    {
        entry = pfe_l2br_static_entry_get_next(fci_context->l2_bridge);
        if (NULL == entry)
        {
            ret = EOK;
            *fci_ret = FPP_ERR_L2_STATIC_EN_NOT_FOUND;
            break_switch = TRUE;
        }
    }

    if(FALSE == break_switch)
    {
        /*  Write the reply buffer */
        br_ent_cmd = reply_buf;
        *reply_len = sizeof(fpp_l2_static_ent_cmd_t);

        /*  Build reply structure */
        /* VLAN */
        br_ent_cmd->vlan = pfe_l2br_static_entry_get_vlan(entry);
        br_ent_cmd->vlan = oal_htons(br_ent_cmd->vlan);
        /* MAC */
        pfe_l2br_static_entry_get_mac(entry, br_ent_cmd->mac);
        /* FW list */
        br_ent_cmd->forward_list = oal_htonl(pfe_l2br_static_entry_get_fw_list(entry));
        /* misc flags */
        (void)pfe_l2br_static_entry_get_local_flag(fci_context->l2_bridge, entry, (bool_t *)&br_ent_cmd->local);
        (void)pfe_l2br_static_entry_get_src_discard_flag(fci_context->l2_bridge, entry, (bool_t *)&br_ent_cmd->src_discard);
        (void)pfe_l2br_static_entry_get_dst_discard_flag(fci_context->l2_bridge, entry, (bool_t *)&br_ent_cmd->dst_discard);
        *fci_ret = FPP_ERR_OK;
    }

    return ret;
}

static errno_t fci_l2br_domain_cmd_update(const fci_t *fci_context, uint32 session_id, uint16 *fci_ret, fpp_l2_bd_cmd_t *bd_cmd)
{
    errno_t ret = EOK;
    pfe_l2br_domain_t *domain = NULL;

    /*  Check input values. We need to translate integer to pfe_ct_l2br_action_t therefore
        some validation needs to be performed first. */
    if ((bd_cmd->ucast_hit > 3U) || (bd_cmd->ucast_miss > 3U)
            || (bd_cmd->mcast_hit > 3U) || (bd_cmd->mcast_miss > 3U))
    {
        NXP_LOG_WARNING("Unsupported action code received\n");
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        ret = EOK;
    }
    else
    {
        *fci_ret = FPP_ERR_OK;
        ret = fci_l2br_domain_cmd_update_set_action(&domain, fci_context, fci_ret, bd_cmd);
        if(FPP_ERR_OK == *fci_ret)
        {
            /*  Review if_list and untag_if_list and verify if contains valid interfaces. Valid interfaces
                are interfaces, which are known to the internal FCI database. Note that FCI API is using
                integer indexes to identify the physical interfaces but rest of SW works with pfe_phy_if_t
                instances. */
            ret = fci_l2br_domain_cmd_update_check_if_list(domain, fci_context, session_id, fci_ret, bd_cmd);
        }
    }

    return ret;
}

static errno_t process_l2br_command(uint16 *fci_ret, fpp_l2_bd_cmd_t *reply_buf, uint32 *reply_len, fpp_l2_bd_cmd_t *bd_cmd, uint32 session_id)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    pfe_l2br_domain_t *domain = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (bd_cmd->action)
        {
            case FPP_ACTION_REGISTER:
            {
                *fci_ret = FPP_ERR_OK;
                ret = fci_l2br_domain_cmd_register(fci_context, fci_ret, bd_cmd);
                if(FPP_ERR_OK != *fci_ret)
                {
                    break;
                }
            }/* FALLTHRU */
            /* no break */
            case FPP_ACTION_UPDATE:
            {
                ret = fci_l2br_domain_cmd_update(fci_context, session_id, fci_ret, bd_cmd);
                break;
            }

            case FPP_ACTION_DEREGISTER:
            {
                ret = fci_l2br_domain_cmd_deregister(fci_context, fci_ret, bd_cmd);
                break;
            }

            case FPP_ACTION_QUERY:
            {
                domain = pfe_l2br_get_first_domain(fci_context->l2_bridge, L2BD_CRIT_ALL, NULL);
                if (NULL == domain)
                {
                    ret = EOK;
                    *fci_ret = FPP_ERR_L2_BD_NOT_FOUND;
                    break;
                }
            }/* FALLTHRU */
            /* no break */

            case FPP_ACTION_QUERY_CONT:
            {
                if (NULL == domain)
                {
                    domain = pfe_l2br_get_next_domain(fci_context->l2_bridge);
                    if (NULL == domain)
                    {
                        ret = EOK;
                        *fci_ret = FPP_ERR_L2_BD_NOT_FOUND;
                        break;
                    }
                }

                /*  Write the reply buffer */
                *reply_len = sizeof(fpp_l2_bd_cmd_t);
                ret = fci_l2br_domain_cmd_query_cont_build_repply_buf(domain, &bd_cmd, fci_ret, reply_buf, fci_context);
                break;
            }

            default:
            {
                NXP_LOG_WARNING("FPP_CMD_L2_BD: Unknown action received: 0x%x\n", bd_cmd->action);
                *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                break;
            }
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_L2_BD commands
 * @param[in]       msg FCI message containing the FPP_CMD_L2_BD command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_l2_bd_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with domain DB protected against concurrent accesses.
 */
errno_t fci_l2br_domain_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_l2_bd_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_l2_bd_cmd_t *bd_cmd;
    errno_t ret = EOK;
    uint32 session_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_l2_bd_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_l2_bd_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            bd_cmd = (fpp_l2_bd_cmd_t *)(msg->msg_cmd.payload);

            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_l2_bd_cmd_t));

            ret = pfe_if_db_lock(&session_id);

            if(EOK != ret)
            {
                *fci_ret = FPP_ERR_IF_RESOURCE_ALREADY_LOCKED;
                ret = EOK;
            }
            else
            {
                ret = process_l2br_command(fci_ret, reply_buf, reply_len, bd_cmd, session_id);
                if (EOK != pfe_if_db_unlock(session_id))
                {
                    *fci_ret = FPP_ERR_IF_WRONG_SESSION_ID;
                    NXP_LOG_ERROR("DB unlock failed\n");
                }
            }

        }
    }
    return ret;
}

/**
 * @brief           Process FPP_CMD_L2_STATIC_ENT commands
 * @param[in]       msg FCI message containing the FPP_CMD_L2_STATIC_ENT command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_l2_static_ent_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 */
errno_t fci_l2br_static_entry_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_l2_static_ent_cmd_t *reply_buf, uint32 *reply_len)
{
    const fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;
    fpp_l2_static_ent_cmd_t *br_ent_cmd;
    pfe_l2br_static_entry_t *entry = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_l2_static_ent_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_l2_static_ent_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            br_ent_cmd = (fpp_l2_static_ent_cmd_t *)(msg->msg_cmd.payload);

            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_l2_static_ent_cmd_t));

            switch (br_ent_cmd->action)
            {
                case FPP_ACTION_REGISTER:
                {
                    ret = l2br_static_entry_cmd_fpp_action_register(fci_ret, br_ent_cmd);
                    break;
                }
                case FPP_ACTION_UPDATE:
                {
                    ret = l2br_static_entry_cmd_fpp_action_update(fci_ret, br_ent_cmd);
                    break;
                }
                case FPP_ACTION_DEREGISTER:
                {
                    ret = l2br_static_entry_cmd_fpp_action_deregister(fci_ret, br_ent_cmd);
                    break;
                }
                case FPP_ACTION_QUERY:
                {
                    entry = pfe_l2br_static_entry_get_first(fci_context->l2_bridge, L2SENT_CRIT_ALL, NULL, NULL);
                    if (NULL == entry)
                    {
                        ret = EOK;
                        *fci_ret = FPP_ERR_L2_STATIC_EN_NOT_FOUND;
                        break;
                    }
                }/* FALLTHRU */
                /* no break */
                case FPP_ACTION_QUERY_CONT:
                {
                    ret = l2br_static_entry_cmd_fpp_action_query_cont(fci_ret, reply_buf, reply_len, br_ent_cmd, entry);
                    break;
                }
                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_L2_STATIC_ENT: Unknown action received: 0x%x\n", br_ent_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }

        }
    }
    return ret;
}

/**
 * @brief       Get valid inteface list
 * @retval      valid interface list
 */
uint32 fci_l2br_static_entry_get_valid_fw_list(void)
{
    uint32 ii;
    uint32 session_id, valid_if_list = 0U;
    errno_t ret = EOK;
    const fci_t *fci_context = (fci_t *)&context;
    pfe_if_db_entry_t *if_db_entry = NULL;

    ret = pfe_if_db_lock(&session_id);
    if(EOK != ret)
    {
        NXP_LOG_DEBUG("DB lock failed\n");
        valid_if_list = 0;
    }
    else
    {
        for (ii=0U; ((ii < (8U * sizeof(uint32))) && (ii <= (uint32)PFE_PHY_IF_ID_MAX)); ii++)
        {
                /*  Only add interfaces which are known to platform interface database */
                if_db_entry = NULL;
                ret = pfe_if_db_get_first(fci_context->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)ii, &if_db_entry);
                if (EOK != ret)
                {
                    valid_if_list = 0;
                    break;
                }
                if (NULL != if_db_entry)
                {
                    valid_if_list |= ((uint32)1U << ii);
                }
        }

        if (EOK != pfe_if_db_unlock(session_id))
        {
            NXP_LOG_ERROR("DB unlock failed\n");
            valid_if_list = 0;
        }
    }

    return valid_if_list;
}

/**
 * @brief       Remove interface from domain and ensure it is properly re-configured if the interface
 *              is not member of another domain.
 * @param[in]   domain Domain
 * @param[in]   phy_if Interface instance
 * @retval      EOK Success
 */
static errno_t fci_l2br_domain_remove_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *phy_if)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != phy_if)
        {
            ret = pfe_l2br_domain_del_if(domain, phy_if);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Could not remove interface from domain\n");
            }
            else
            {
                ret = pfe_l2br_domain_flush_by_if(domain, phy_if);
            }
        }
    }

    return ret;
}

/**
 * @brief       Gracefully remove bridge domain
 * @param[in]   domain The domain instance
 * @retval      EOK Success
 */
static errno_t fci_l2br_domain_remove(pfe_l2br_domain_t *domain)
{
    const pfe_phy_if_t *phy_if;
    errno_t ret = EOK;
    uint16 vlan;

    if (NULL != domain)
    {
        /*  Remove all physical interfaces from the domain and adjust their properties. */
        phy_if = pfe_l2br_domain_get_first_if(domain, L2BD_IF_CRIT_ALL, NULL);
        while (NULL != phy_if)
        {
            /*  Remove from domain */
            if (EOK != fci_l2br_domain_remove_if(domain, phy_if))
            {
                NXP_LOG_ERROR("Interface removal failed\n");
            }
            else
            {
                if (EOK != pfe_l2br_domain_get_vlan(domain, &vlan))
                {
                    NXP_LOG_ERROR("Could not get domain VLAN ID\n");
                }

                NXP_LOG_INFO("Domain %d: Interface %d removed\n", vlan, pfe_phy_if_get_id(phy_if));
            }

            /*  Get next */
            phy_if = pfe_l2br_domain_get_next_if(domain);
        }

        /*  Remove the domain instance */
        ret = pfe_l2br_domain_destroy(domain);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Fatal: Could not destroy bridge domain: %d\n", ret);
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_L2BRIDGE_ENABLE */
#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */

/** @}*/


===== 文件 [117/185]: src\fci_mirror.c =====
 /* =========================================================================
  *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440


#include "pfe_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "fci_fp_db.h"
#include "fci_msg.h"
#include "fci.h"
#include "fci_internal.h"
#include "oal.h"
#include "fci_mirror.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


static errno_t fci_mirror_cmd_update_egress_port(fci_t **fci_context, pfe_mirror_t **mirror, uint16 **fci_ret, fpp_mirror_cmd_t *mirror_cmd);
static errno_t fci_mirror_cmd_update_set_filter(fci_t *fci_context, pfe_mirror_t **mirror, uint16 **fci_ret, fpp_mirror_cmd_t *mirror_cmd);
static errno_t fci_mirror_cmd_query_cont_get_mirror(fci_t *fci_context, pfe_mirror_t **mirror, uint16 **fci_ret, fpp_mirror_cmd_t **reply_buf);
static errno_t mirror_cmd_fpp_action_register(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd, bool_t *break_switch);
static errno_t mirror_cmd_fpp_query_cont(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *reply_buf, uint32 *reply_len);
static errno_t mirror_cmd_fpp_action_update(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd);
static errno_t mirror_cmd_get_mirror(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd);
static errno_t mirror_cmd_fpp_action_deregister(uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd);
static errno_t remove_fp_filter(errno_t ret, uint32 addr, uint16 **fci_ret);
static pfe_ct_phy_if_id_t get_egress_interface(fpp_mirror_cmd_t **reply_buf, pfe_mirror_t *tmp_mirror);
static errno_t fill_reply_buf(fpp_mirror_cmd_t **reply_buf, pfe_phy_if_t *phy_if, pfe_mirror_t *tmp_mirror, fci_t *fci_context);
#if defined(PFE_CFG_NULL_ARG_CHECK)
static errno_t null_arg_check(fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len);

/**
 * @brief           Auxiliary function to check for NULL arguments
 * @param[in]       msg FCI message containing the FPP_CMD_FP_TABLE command
 * @param[in]       fci_ret FCI command return value
 * @param[in]       reply_buf Pointer to a buffer where function will construct command reply (fpp_fp_table_cmd_t)
 * @param[in]       reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
static errno_t null_arg_check(fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len)
{
    errno_t ret=EOK;
    const fci_t *fci_context = (fci_t *)&context;

    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
    {
        /*MISRA required*/
    }

    return ret;
}
#endif /* PFE_CFG_NULL_ARG_CHECK */

static errno_t fci_mirror_cmd_update_egress_port(fci_t **fci_context, pfe_mirror_t **mirror, uint16 **fci_ret, fpp_mirror_cmd_t *mirror_cmd)
{
    errno_t             ret;
    pfe_ct_phy_if_id_t  egress_id;
    pfe_phy_if_t        *phy_if     = NULL;
    pfe_if_db_entry_t   *entry      = NULL;

    /* Lock interface db and get the requested interface */
    ret = pfe_if_db_lock(&(*fci_context)->if_session_id);
    if(EOK != ret)
    {
        /* FCI command requested unfulfillable action. Respond with FCI error code. */
        **fci_ret = FPP_ERR_IF_RESOURCE_ALREADY_LOCKED;
        ret = EOK;
    }
    else
    {

        (void)pfe_if_db_get_first((*fci_context)->phy_if_db, (*fci_context)->if_session_id, IF_DB_CRIT_BY_NAME, mirror_cmd->egress_phy_if, &entry);
        if (NULL != entry)
        {
            phy_if = pfe_if_db_entry_get_phy_if(entry);
        }

        if((NULL == entry) || (NULL == phy_if))
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            (void)pfe_if_db_unlock((*fci_context)->if_session_id);
            NXP_LOG_DEBUG("No interface '%s'\n", mirror_cmd->egress_phy_if);
            **fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            /* Set the interface as mirror's egress port */
            egress_id = pfe_phy_if_get_id(phy_if);
            ret = pfe_mirror_set_egress_port((*mirror), egress_id);
            if(EOK != ret)
            {
                /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                (void)pfe_if_db_unlock((*fci_context)->if_session_id);
                NXP_LOG_ERROR("Cannot set egress port for '%s'\n", mirror_cmd->name);
                **fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            else
            {
                (void)pfe_if_db_unlock((*fci_context)->if_session_id);
            }
        }
    }

    return ret;
}

static errno_t remove_fp_filter(errno_t ret, uint32 addr, uint16 **fci_ret)
{
    const char *str;

    if(0U != addr)
    {   /* Some filter (Flexible Parser table) is used. Get it and remove it from DMEM. */
        ret = fci_fp_db_get_table_from_addr(addr, (char **)&str);
        if(EOK != ret)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("Cannot obtain filter name.\n");
            **fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else
        {
            (void)fci_fp_db_pop_table_from_hw((char *)str);
        }
    }

    return ret;
}

static errno_t fci_mirror_cmd_update_set_filter(fci_t *fci_context, pfe_mirror_t **mirror, uint16 **fci_ret, fpp_mirror_cmd_t *mirror_cmd)
{
    errno_t ret = EOK;
    uint32 addr;

    if('\0' == mirror_cmd->filter_table_name[0U])
    {   /* FCI command requests that the filter shall be disabled */
        /* Check if the mirror currently uses some filter. */
        addr = pfe_mirror_get_filter((*mirror));
        ret = remove_fp_filter(ret, addr, fci_ret);

        if(EOK == ret)
        {
            /* Disable the filter */
            ret = pfe_mirror_set_filter((*mirror), 0U);
            if(EOK != ret)
            {
                /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                NXP_LOG_WARNING("Failed to disable filter on mirror '%s'.\n", mirror_cmd->name);
                **fci_ret = FPP_ERR_INTERNAL_FAILURE;
                ret = EOK;
            }
        }
    }
    else
    {   /* FCI command requests that the filter shall be enabled or replaced by another one. */

        /* Check that the newly requested filter exists */
        if (NULL == fci_fp_db_get_first(FP_TABLE_CRIT_NAME, mirror_cmd->filter_table_name))
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            NXP_LOG_WARNING("Requested filter table '%s' does not exist.\n", mirror_cmd->filter_table_name);
            **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
            ret = EOK;
        }
        else
        {
            /* Check if the mirror currently uses some filter. */
            addr = pfe_mirror_get_filter((*mirror));
            ret = remove_fp_filter(ret, addr, fci_ret);

            if(EOK == ret)
            {
                /* Set the filter */
                addr = fci_fp_db_get_table_dmem_addr((char_t *)mirror_cmd->filter_table_name);
                if(0U == addr)
                {   /* Requested filter table (from FCI command) is not used anywhere yet. Good. Use it as filter. */

                    /* Add filter table to HW */
                    (void)fci_fp_db_push_table_to_hw(fci_context->class, (char_t *)mirror_cmd->filter_table_name);
                    addr = fci_fp_db_get_table_dmem_addr((char_t *)mirror_cmd->filter_table_name);

                    /* Update filter address of mirror */
                    ret = pfe_mirror_set_filter((*mirror), addr);
                    if(EOK != ret)
                    {
                        /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                        NXP_LOG_ERROR("Failed to set filter %s to mirror %s\n", mirror_cmd->filter_table_name, mirror_cmd->name);
                        **fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    }
                }
                else
                {   /* Requested filter table (from FCI command) is already used somewhere and cannot be used here. */

                    /* FCI command requested unfulfillable action. Respond with FCI error code. */
                    NXP_LOG_WARNING("Filter '%s' already in use, but it should not be!\n", mirror_cmd->filter_table_name);
                    **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                    ret = EOK;
                }
            }
        }
    }

    return ret;
}

static errno_t fill_reply_buf(fpp_mirror_cmd_t **reply_buf, pfe_phy_if_t *phy_if, pfe_mirror_t *tmp_mirror, fci_t *fci_context)
{
    errno_t ret = EOK;
    pfe_ct_route_actions_t m_actions;
    const char *str;
    uint32 addr;
    pfe_ct_route_actions_args_t m_args;

    /* Get egress port name, step #2 - get name of the egress interface */
    str = pfe_phy_if_get_name(phy_if);
    (void)autolibc_strncpy((*reply_buf)->egress_phy_if, str, (uint32)IFNAMSIZ - 1U);
    (*reply_buf)->egress_phy_if[(uint32)IFNAMSIZ - 1U] = '\0';  /* Ensure termination */
    (void)pfe_if_db_unlock(fci_context->if_session_id);

    /* Get filter name */
    (void)autolibc_memset((*reply_buf)->filter_table_name, 0, IFNAMSIZ);
    addr = pfe_mirror_get_filter(tmp_mirror);
    if(0U != addr)
    {
        ret = fci_fp_db_get_table_from_addr(addr, (char **)&str);
        if(EOK == ret)
        {
            (void)autolibc_strncpy((*reply_buf)->filter_table_name, str, 15);
            (*reply_buf)->filter_table_name[15] = '\0';  /* Ensure termination */
        }
    }

    /* Initialize */
    (void)autolibc_memset(&m_args, 0, sizeof(pfe_ct_route_actions_args_t));
    m_actions = RT_ACT_NONE;

    /* Get modification actions */
    (*reply_buf)->m_actions = MODIFY_ACT_NONE;
    (void)pfe_mirror_get_actions(tmp_mirror, &m_actions, &m_args);
    m_actions = (pfe_ct_route_actions_t) oal_ntohl(m_actions);  /* PFE has modification actions in big endian. */
    if(0U != ((uint32)m_actions & (uint32)RT_ACT_ADD_VLAN_HDR))
    {
        (*reply_buf)->m_actions |= MODIFY_ACT_ADD_VLAN_HDR;
        (*reply_buf)->m_args.vlan = m_args.vlan;
    }
    (*reply_buf)->m_actions = (fpp_modify_actions_t)oal_htonl((*reply_buf)->m_actions);

    return ret;
}

static pfe_ct_phy_if_id_t get_egress_interface(fpp_mirror_cmd_t **reply_buf, pfe_mirror_t *tmp_mirror)
{
    const char *str;

    /* Get mirror name */
    str = pfe_mirror_get_name(tmp_mirror);
    (void)autolibc_strncpy((*reply_buf)->name, str, sizeof((*reply_buf)->name) - 1U);

    return pfe_mirror_get_egress_port(tmp_mirror);
}

static errno_t fci_mirror_cmd_query_cont_get_mirror(fci_t *fci_context, pfe_mirror_t **mirror, uint16 **fci_ret, fpp_mirror_cmd_t **reply_buf)
{
    errno_t ret = EOK;
    pfe_ct_phy_if_id_t egress_id;
    pfe_if_db_entry_t *entry = NULL;
    pfe_phy_if_t *phy_if = NULL;

    **fci_ret = FPP_ERR_OK;
    /* If not fallthrough, then get the next mirror */
    if(NULL == *mirror)
    {
        *mirror = pfe_mirror_get_next();
        if(NULL == *mirror)
        {
            /* End of the query process (no more entities to report). Respond with FCI error code. */
            **fci_ret = FPP_ERR_MIRROR_NOT_FOUND;
            ret = EOK;
        }
    }

    if(FPP_ERR_OK == **fci_ret)
    {
        /* Get egress port name, step #1 - find the egress interface in the interface db */
        egress_id = get_egress_interface(reply_buf, *mirror);
        ret = pfe_if_db_lock(&fci_context->if_session_id);
        if(EOK != ret)
        {
            /* FCI command requested unfulfillable action. Respond with FCI error code. */
            **fci_ret = FPP_ERR_IF_RESOURCE_ALREADY_LOCKED;
            ret = EOK;
        }
        else
        {
            (void)pfe_if_db_get_single(fci_context->phy_if_db, fci_context->if_session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)egress_id, &entry);
            if (NULL != entry)
            {
                phy_if = pfe_if_db_entry_get_phy_if(entry);
            }

            if((NULL == entry) || (NULL == phy_if))
            {
                /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                (void)pfe_if_db_unlock(fci_context->if_session_id);
                NXP_LOG_ERROR("Cannot get egress interface of the mirror '%s'.\n", pfe_mirror_get_name(*mirror));
                **fci_ret = FPP_ERR_INTERNAL_FAILURE;
                ret = ENOENT;
            }
            else
            {
                ret = fill_reply_buf(reply_buf, phy_if, *mirror, fci_context);
            }
        }
    }

    return ret;
}

static errno_t mirror_cmd_fpp_action_register(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd, bool_t *break_switch)
{
    errno_t ret = EOK;

    *break_switch = FALSE;

    /* Check that the requested mirror name is not already registered */
    *mirror = pfe_mirror_get_first(MIRROR_BY_NAME, mirror_cmd->name);
    if (NULL != *mirror)
    {
        /*  Notify mirror module we are done working with the mirror instance. */
        pfe_mirror_put(*mirror);
        *mirror = NULL;
        /* FCI command attempted to register already registered entity. Respond with FCI error code. */
        NXP_LOG_DEBUG("Mirror '%s' is already registered.\n", mirror_cmd->name);
        *fci_ret = FPP_ERR_MIRROR_ALREADY_REGISTERED;
        ret = EOK;
        *break_switch = TRUE;
    }
    else
    {
        /* Create mirror */
        *mirror = pfe_mirror_create(mirror_cmd->name);
        if (NULL == *mirror)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_WARNING("Cannot create mirror '%s'\n", mirror_cmd->name);
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            ret = EPERM;
            *break_switch = TRUE;
        }
    }

    return ret;
}

static errno_t mirror_cmd_fpp_action_update(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd)
{
    errno_t ret = EOK;
    fci_t *fci_context = (fci_t *)&context;
    pfe_ct_route_actions_args_t m_args;
    pfe_ct_route_actions_t m_actions;

    /* 1) Set egress port */
    ret = fci_mirror_cmd_update_egress_port(&fci_context, mirror, &fci_ret, mirror_cmd);
    if(FPP_ERR_OK == *fci_ret)
    {
        /* 2) Set filter to select frames */
        ret = fci_mirror_cmd_update_set_filter(fci_context, mirror, &fci_ret, mirror_cmd);
        if(FPP_ERR_OK == *fci_ret)
        {
            /* 3) Set modification actions */
            mirror_cmd->m_actions = (fpp_modify_actions_t)oal_ntohl(mirror_cmd->m_actions);
            if(MODIFY_ACT_NONE == mirror_cmd->m_actions)
            {   /* No modifications */
                ret = pfe_mirror_set_actions(*mirror, RT_ACT_NONE, NULL);
                if(EOK != ret)
                {
                    NXP_LOG_ERROR("Failed to set modification action: MODIFY_ACT_NONE.\n");
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
            }
            else
            {   /* Some actions to be set - add one by one */
                /* Initialize */
                (void)autolibc_memset(&m_args, 0, sizeof(pfe_ct_route_actions_args_t));
                m_actions = RT_ACT_NONE;

                /* Start adding */
                if(0U != ((uint32)mirror_cmd->m_actions & (uint32)MODIFY_ACT_ADD_VLAN_HDR))
                {   /* VLAN header add/replace */
                    m_args.vlan = mirror_cmd->m_args.vlan;
                    m_actions |= RT_ACT_ADD_VLAN_HDR;
                }

                /* Apply */
                m_actions = (pfe_ct_route_actions_t) oal_htonl(m_actions);  /* PFE has modification actions in big endian. */
                ret = pfe_mirror_set_actions(*mirror, m_actions, &m_args);
                if(EOK != ret)
                {
                    NXP_LOG_ERROR("Failed to set modification actions.\n");
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
            }
        }
    }

    return ret;
}

static errno_t mirror_cmd_fpp_action_deregister(uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd)
{
    errno_t ret = EOK;
    pfe_mirror_t *mirror = NULL;
    const char *str;
    uint32 addr;

    /* Get mirror */
    mirror = pfe_mirror_get_first(MIRROR_BY_NAME, mirror_cmd->name);
    if(NULL == mirror)
    {
        /* FCI command requested nonexistent entity. Respond with FCI error code. */
        NXP_LOG_DEBUG("No mirror with name '%s'\n", mirror_cmd->name);
        *fci_ret = FPP_ERR_MIRROR_NOT_FOUND;
        ret = EOK;
    }
    else
    {
        /* Note filter address (if any). */
        addr = pfe_mirror_get_filter(mirror);
        /* Destroy the mirror. */
        ret = pfe_mirror_destroy(mirror);
        if (EBUSY == ret)
        {
            /*  Notify mirror module we are done working with the mirror instance. */
            pfe_mirror_put(mirror);
            mirror = NULL;
            /* FCI command requested unfulfillable action. Respond with FCI error code. */
            NXP_LOG_WARNING("Cannot destroy a mirror (it is currently utilized).\n");
            *fci_ret = FPP_ERR_MIRROR_CURRENTLY_UTILIZED;
            ret = EOK;
            /* Intentionally skip destruction of filter. We are keeping the mirror completely intact. */
        }
        else
        {
            mirror = NULL;  /* Mirror was destroyed. */
            /* Check if the mirror had some filter. */
            if(0U != addr)
            {   /* Some filter (Flexible Parser table) is used. Get it and remove it from DMEM. */
                ret = fci_fp_db_get_table_from_addr(addr, (char **)&str);
                if(EOK != ret)
                {
                    /* No need to release the mirror instance here. The instance is already destroyed. */
                    /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                    NXP_LOG_ERROR("Cannot obtain filter name.\n");
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
                else
                {
                    (void)fci_fp_db_pop_table_from_hw((char *)str);
                }
            }
        }
    }

    return ret;
}

static errno_t mirror_cmd_get_mirror(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *mirror_cmd)
{
    errno_t ret = EOK;

    if(NULL == *mirror)
    {   /* Not the FALLTHRU case - obtain the mirror */
        /* Get mirror */
        *mirror = pfe_mirror_get_first(MIRROR_BY_NAME, mirror_cmd->name);
        if(NULL == *mirror)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            NXP_LOG_DEBUG("No mirror with name '%s'\n", mirror_cmd->name);
            *fci_ret = FPP_ERR_MIRROR_NOT_FOUND;
            ret = EINVAL;
        }
    }

    return ret;
}

static errno_t mirror_cmd_fpp_query_cont(pfe_mirror_t **mirror, uint16 *fci_ret, fpp_mirror_cmd_t *reply_buf, uint32 *reply_len)
{
    errno_t ret = EOK;
    fci_t *fci_context = (fci_t *)&context;

    ret = fci_mirror_cmd_query_cont_get_mirror(fci_context, mirror, &fci_ret, &reply_buf);
    if(FPP_ERR_OK == *fci_ret)
    {
        /* Set reply length end return OK */
        *reply_len = sizeof(fpp_mirror_cmd_t);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief           Processes FPP_CMD_MIRROR commands
 * @param[in]       msg FCI message containing the FPP_CMD_MIRROR command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_mirror_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 */
errno_t fci_mirror_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_mirror_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_mirror_cmd_t *mirror_cmd;
    errno_t ret = EOK;
    pfe_mirror_t *mirror = NULL;
    bool_t break_switch = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    ret = null_arg_check(msg, fci_ret, (void*) reply_buf, reply_len);
    if (likely(EOK == ret))
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *fci_ret = FPP_ERR_OK;

        /* Important to initialize to avoid buffer overflows */
        if (*reply_len < sizeof(fpp_mirror_cmd_t))
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_mirror_cmd_t)\n");
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            ret = EINVAL;
        }
        else
        {
            /* No data written to reply buffer (yet) */
            *reply_len = 0U;

            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_mirror_cmd_t));
            mirror_cmd = (fpp_mirror_cmd_t *)(msg->msg_cmd.payload);

            switch (mirror_cmd->action)
            {
                case FPP_ACTION_REGISTER:
                {
                    ret = mirror_cmd_fpp_action_register(&mirror, fci_ret, mirror_cmd, &break_switch);
                    if (TRUE == break_switch)
                    {
                        break;
                    }
                }/* FALLTHRU */
                /* no break */

                case FPP_ACTION_UPDATE:
                {
                    ret = mirror_cmd_get_mirror(&mirror, fci_ret, mirror_cmd);
                    if(EOK == ret)
                    {
                        ret = mirror_cmd_fpp_action_update(&mirror, fci_ret, mirror_cmd);
                    }
                    /*  Notify mirror module we are done working with the mirror instance. */
                    pfe_mirror_put(mirror);
                    mirror = NULL;
                    break;
                }

                case FPP_ACTION_DEREGISTER:
                {
                    ret = mirror_cmd_fpp_action_deregister(fci_ret, mirror_cmd);
                    break;
                }

                case FPP_ACTION_QUERY:
                {
                    /* Get the first mirror */
                    mirror = pfe_mirror_get_first(MIRROR_ANY, NULL);
                    if(NULL == mirror)
                    {
                        /* End of the query process (no more entities to report). Respond with FCI error code. */
                        *fci_ret = FPP_ERR_MIRROR_NOT_FOUND;
                        ret = EOK;
                        break;
                    }
                }/* FALLTHRU */
                /* no break */

                case FPP_ACTION_QUERY_CONT:
                {
                    ret = mirror_cmd_fpp_query_cont(&mirror, fci_ret, reply_buf, reply_len);
                    /*  Notify mirror module we are done working with the mirror instance. */
                    pfe_mirror_put(mirror);
                    mirror = NULL;
                    break;
                }

                default:
                {
                    /* Unknown command. Respond with FCI error code. */
                    NXP_LOG_WARNING("FPP_CMD_MIRROR command: Unknown action received: 0x%x\n", mirror_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    ret = EOK;
                    break;
                }
            }
        }
    }
    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [118/185]: src\fci_owner.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "pfe_platform.h"
#include "fci_ownership_mask.h"

#include "fci_internal.h"
#include "fci.h"

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#ifdef PFE_CFG_FCI_ENABLE

/**
 * @brief       This is the FCI ownership representation structure.
 */
typedef struct
{
    pfe_fci_owner_hif_id_t hif_fci_owner_chnls_mask;    /* Bit mask representing allowed FCI ownership */
    pfe_ct_phy_if_id_t lock_owner_if;       /* Current FCI owner lock holder: PFE_PHY_IF_ID_INVALID - no currewnt FCI owner or PFE_PHY_IF_ID_HIFn */
} fci_owner_t;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static fci_owner_t fci_owner_context;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
static errno_t fci_owner_lock_cmd(pfe_ct_phy_if_id_t sender, uint16 *fci_ret);
static errno_t fci_owner_unlock_cmd(pfe_ct_phy_if_id_t sender, uint16 *fci_ret);

/**
 * @brief       Initialize FCI ownership module
 * @param[in]   info Information with bit mask representing allowed FCI ownership
 * @return      EOK if success, error code otherwise
 */
errno_t fci_owner_init(fci_init_info_t *info)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == info))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Grant FCI ownership to all if none is provided */
        fci_owner_context.hif_fci_owner_chnls_mask = (FCI_OWNER_HIF_INVALID == info->hif_fci_owner_chnls_mask) ?
            (pfe_fci_owner_hif_id_t)(FCI_OWNER_HIF_0 | FCI_OWNER_HIF_1 | FCI_OWNER_HIF_2 | FCI_OWNER_HIF_3 | FCI_OWNER_HIF_NOCPY) :
            (info->hif_fci_owner_chnls_mask);

        NXP_LOG_INFO("FCI ownership mask: 0x%X\n", fci_owner_context.hif_fci_owner_chnls_mask);
        /* Default FCI ownership holder. Beware of availability of OAL_PFE_CFG_MASTER_IF if it is needed here! */
        fci_owner_context.lock_owner_if = PFE_PHY_IF_ID_INVALID;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Process FCI owner lock/unlock commands
 * @details     Call must be protected by FCI owner mutex, it has to be done outside
 * @param[in]   sender HIF interface from where request is originated
 * @param[in]   msg FCI cmd code
 * @param[out]  fci_ret FCI return code
 * @return      EOK if success, error code otherwise
 */
errno_t fci_owner_session_cmd(pfe_ct_phy_if_id_t sender, uint32 code, uint16 *fci_ret)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fci_ret))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *fci_ret = FPP_ERR_OK;

        switch (code)
        {
            case FPP_CMD_FCI_OWNERSHIP_LOCK:
            {
                ret = fci_owner_lock_cmd(sender, fci_ret);
                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    NXP_LOG_WARNING("Can't get FCI lock for sender: %d error: %d\n", sender, ret);
                }

                break;
            }

            case FPP_CMD_FCI_OWNERSHIP_UNLOCK:
            {
                ret = fci_owner_unlock_cmd(sender, fci_ret);
                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    NXP_LOG_WARNING("Can't release FCI lock for sender: %d error: %d\n", sender, ret);
                }

                break;
            }

            default:
            {
                NXP_LOG_WARNING("Unknown FCI lock/unlock command: 0x%x sender: %d\n", (uint_t)code, sender);
                *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                break;
            }
        }
    }
    return ret;
}

/**
 * @brief       Authorize FCI ownership request
 * @details     Call must be protected by FCI owner mutex, it has to be done outside
 *              Authorize denotes sender corresponds to a current FCI ownership holder
 * @param[in]   sender identified by HIF interface
 * @param[out]  auth_ret status of FCI ownership request
 * @return      EOK if success, error code otherwise
 */
errno_t fci_owner_authorize(pfe_ct_phy_if_id_t sender, bool_t *auth_ret)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == auth_ret))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely((FALSE == fci_context->fci_initialized) || (FALSE == fci_context->fci_owner_initialized)))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#else
    (void)fci_context;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *auth_ret = (sender == fci_owner_context.lock_owner_if);
    }

    return ret;
}

/**
 * @brief       Get physical interface of sender
 * @details     Sender value is validated, it must correspond to a valid HIF
 * @param[in]   sender interface identification or 0 for Local Sender
 * @param[out]  phy_if_id sender's physical interface
 * @return      EOK if success, error code otherwise
 */
errno_t fci_sender_get_phy_if_id(uint32 sender, pfe_ct_phy_if_id_t *phy_if_id)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == phy_if_id))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (sender)
        {
            case (uint32)PFE_PHY_IF_ID_HIF0:
            case (uint32)PFE_PHY_IF_ID_HIF1:
            case (uint32)PFE_PHY_IF_ID_HIF2:
            case (uint32)PFE_PHY_IF_ID_HIF3:
            case (uint32)PFE_PHY_IF_ID_HIF_NOCPY:
            {
                *phy_if_id = (pfe_ct_phy_if_id_t)sender;
                break;
            }

            default:
            {
                ret = EINVAL;
                break;
            }
        }
    }

    return ret;
}

/**
 * @brief       Lock FCI owner mutex
 * @return      EOK if success, error code otherwise
 */
errno_t fci_owner_mutex_lock(void)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((FALSE == fci_context->fci_initialized) || (FALSE == fci_context->fci_owner_initialized)))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#else
    (void)fci_context;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_FCI_OWNER_MUTEX);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Unlock FCI owner mutex
 * @return      EOK if success, error code otherwise
 */
errno_t fci_owner_mutex_unlock(void)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((FALSE == fci_context->fci_initialized) || (FALSE == fci_context->fci_owner_initialized)))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#else
    (void)fci_context;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_unlock(PFE_FCI_OWNER_MUTEX);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Acquire FCI ownership
 * @details     Call must be protected by FCI owner mutex, it has to be done outside
 * @param[in]   sender HIF interface from where request is originated
 * @param[out]  fci_ret status of FCI ownership request
 * @return      EOK if success, error code otherwise
 */
static errno_t fci_owner_lock_cmd(pfe_ct_phy_if_id_t sender, uint16 *fci_ret)
{
    fci_t *fci_context = (fci_t *)&context;
    pfe_fci_owner_hif_id_t chnl_bit_mask;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fci_ret))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely((FALSE == fci_context->fci_initialized) || (FALSE == fci_context->fci_owner_initialized)))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#else
    (void)fci_context;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (sender == fci_owner_context.lock_owner_if)
        {
            *fci_ret = FPP_ERR_OK;
        }
        else
        {
            chnl_bit_mask = pfe_fci_owner_hif_from_phy_id(sender);
            if (FCI_OWNER_HIF_INVALID == chnl_bit_mask)
            {
                ret = EINVAL;
            }
            else
            {
                if (0U == (chnl_bit_mask & fci_owner_context.hif_fci_owner_chnls_mask))
                {
                    *fci_ret = FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED;
                }
                else
                {
                    if (PFE_PHY_IF_ID_INVALID == fci_owner_context.lock_owner_if)
                    {
                        fci_owner_context.lock_owner_if = sender;
                        *fci_ret = FPP_ERR_OK;
                    }
                    else
                    {
                        *fci_ret = FPP_ERR_FCI_OWNERSHIP_ALREADY_LOCKED;
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Acquire floating FCI ownership
 * @details     Call must be protected by FCI owner mutex, it has to be done outside.
 *              To be able to get the floating lock, there must not be another current lock owner
 *              and sender must have permission to get FCI owhership.
 *              Floating FCI ownership must be released after current FCI cmd is executed.
 * @param[in]   sender HIF interface from where request is originated
 * @param[out]  fci_ret status of FCI ownership request
 * @param[out]  floating_lock result if floating FCI ownership was granted
 * @return      EOK if success, error code otherwise
 */
errno_t fci_owner_get_floating_lock(pfe_ct_phy_if_id_t sender, uint16 *fci_ret, bool_t *floating_lock)
{
    fci_t *fci_context = (fci_t *)&context;
    pfe_fci_owner_hif_id_t chnl_bit_mask;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == fci_ret) || (NULL == floating_lock)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely((FALSE == fci_context->fci_initialized) || (FALSE == fci_context->fci_owner_initialized)))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#else
    (void)fci_context;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_ID_INVALID != fci_owner_context.lock_owner_if)
        {
            *fci_ret = FPP_ERR_FCI_OWNERSHIP_NOT_OWNER;
        }
        else
        {
            chnl_bit_mask = pfe_fci_owner_hif_from_phy_id(sender);
            if (FCI_OWNER_HIF_INVALID == chnl_bit_mask)
            {
                ret = EINVAL;
            }
            else
            {
                if (0U == (chnl_bit_mask & fci_owner_context.hif_fci_owner_chnls_mask))
                {
                    *fci_ret = FPP_ERR_FCI_OWNERSHIP_NOT_AUTHORIZED;
                }
                else
                {
                    fci_owner_context.lock_owner_if = sender;
                    *fci_ret = FPP_ERR_OK;
                    *floating_lock = TRUE;
                }
            }
        }
    }

    return ret;
}


/**
 * @brief       Release FCI ownership
 * @details     Call must be protected by FCI owner mutex, it has to be done outside
 * @param[in]   sender HIF interface from where request is originated
 * @param[out]  fci_ret status of FCI ownership release action
 * @return      EOK if success, error code otherwise
 */
static errno_t fci_owner_unlock_cmd(pfe_ct_phy_if_id_t sender, uint16 *fci_ret)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fci_ret))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely((FALSE == fci_context->fci_initialized) || (FALSE == fci_context->fci_owner_initialized)))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#else
    (void)fci_context;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (sender == fci_owner_context.lock_owner_if)
        {
            fci_owner_context.lock_owner_if = PFE_PHY_IF_ID_INVALID;
            *fci_ret = FPP_ERR_OK;
        }
        else
        {
            *fci_ret = FPP_ERR_FCI_OWNERSHIP_NOT_OWNER;
        }
    }

    return ret;
}

/**
 * @brief       Clear floating FCI ownership lock
 * @details     Call must be protected by FCI owner mutex, it has to be done outside
 * @return      EOK if success, error code otherwise
 */
errno_t fci_owner_clear_floating_lock(void)
{
    fci_t *fci_context = (fci_t *)&context;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((FALSE == fci_context->fci_initialized) || (FALSE == fci_context->fci_owner_initialized)))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#else
    (void)fci_context;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fci_owner_context.lock_owner_if = PFE_PHY_IF_ID_INVALID;
    }

    return ret;
}
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */


===== 文件 [119/185]: src\fci_qos.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_qos.c
 * @brief       QoS management
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "pfe_platform.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"

#include "fci_internal.h"
#include "fci.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static pfe_phy_if_t *fci_get_phy_if_by_name(char_t *name);
static pfe_gpi_t *fci_qos_get_gpi(const pfe_phy_if_t *phy_if);
static errno_t fci_validate_cmd_params(const fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len, uint32 cmd_len);
static errno_t policer_flow_cmd_action_register(uint16 *fci_ret, fpp_qos_policer_flow_cmd_t *flow_cmd, pfe_iqos_flow_spec_t *gpi_flow, pfe_gpi_t *gpi);
static errno_t policer_flow_cmd_action_deregister(uint16 *fci_ret, fpp_qos_policer_flow_cmd_t *flow_cmd, pfe_gpi_t *gpi);
static errno_t policer_shp_cmd_action_update(uint16 *fci_ret, fpp_qos_policer_shp_cmd_t *shp_cmd, pfe_gpi_t *gpi, uint8 shp_id);
static errno_t policer_shp_cmd_action_query(fpp_qos_policer_shp_cmd_t *reply_buf, uint16 *fci_ret, fpp_qos_policer_shp_cmd_t *shp_cmd, pfe_gpi_t *gpi, uint8 shp_id);
static errno_t wred_thr_set_reg(pfe_gpi_t *gpi, fpp_iqos_queue_t queue, fpp_qos_policer_wred_cmd_t *wred_cmd);
static errno_t wred_prob_zone_set_reg(pfe_gpi_t *gpi, fpp_iqos_queue_t queue, fpp_qos_policer_wred_cmd_t *wred_cmd);
static errno_t policer_wred_cmd_action_update(uint16 *fci_ret, fpp_qos_policer_wred_cmd_t *wred_cmd, pfe_gpi_t *gpi, fpp_iqos_queue_t queue);
static errno_t policer_wred_cmd_action_query(fpp_qos_policer_wred_cmd_t *reply_buf, uint16 *fci_ret, fpp_qos_policer_wred_cmd_t *wred_cmd, pfe_gpi_t *gpi, fpp_iqos_queue_t queue);
static errno_t qos_queue_cmd_action_update(uint16 *fci_ret, fpp_qos_queue_cmd_t *q, const fci_t *fci);
static errno_t qos_queue_cmd_action_query(fpp_qos_queue_cmd_t *reply_buf, uint16 *fci_ret, fpp_qos_queue_cmd_t *q, const fci_t *fci);
static errno_t queue_mode_wred(uint16 *fci_ret, fpp_qos_queue_cmd_t *q, const fci_t *fci, pfe_phy_if_t *phy_if);
static errno_t shaper_cmd_action_update(uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp);
static errno_t shaper_cmd_action_query(fpp_qos_shaper_cmd_t *reply_buf, uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp);
static errno_t set_shaper_cmd_props(uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp, pfe_phy_if_t *phy_if);
static errno_t shaper_disconnect_and_disable(uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp, pfe_phy_if_t *phy_if);
static errno_t scheduler_cmd_action_update(uint16 *fci_ret, const fci_t *fci, fpp_qos_scheduler_cmd_t *sch);
static errno_t scheduler_cmd_action_query(fpp_qos_scheduler_cmd_t *reply_buf, uint16 *fci_ret, const fci_t *fci, fpp_qos_scheduler_cmd_t *sch);
static bool_t check_scheduler_input(fpp_qos_scheduler_cmd_t **sch, uint8 ii);
static void fci_qos_flow_entry_convert_to_gpi(const fpp_iqos_flow_spec_t *flow, pfe_iqos_flow_spec_t *gpi_flow);
static void fci_qos_flow_entry_convert_from_gpi(const pfe_iqos_flow_spec_t *gpi_flow, fpp_iqos_flow_spec_t *flow);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#ifdef NXP_LOG_ENABLED
#define ETH_43_PFE_START_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"

/*
 *  This is storage of scheduler algorithms ordered in way
 *  as defined by the FCI (see fpp_ext.h::fpp_qos_scheduler_cmd_t)
 */
static const char_t * const sch_algos_str[] = {"SCHED_ALGO_PQ", "SCHED_ALGO_DWRR", "SCHED_ALGO_RR", "SCHED_ALGO_WRR"};

#define ETH_43_PFE_STOP_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"
#endif /* NXP_LOG_ENABLED */

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* usage scope: fci_qos_queue_cmd*/
static const pfe_tmu_queue_mode_t fci_qmode_to_qmode[] =
    {TMU_Q_MODE_INVALID, TMU_Q_MODE_DEFAULT, TMU_Q_MODE_TAIL_DROP, TMU_Q_MODE_WRED};

/* usage scope: fci_qos_scheduler_cmd */
static const pfe_tmu_sched_algo_t sch_algos[] = {SCHED_ALGO_PQ, SCHED_ALGO_DWRR, SCHED_ALGO_RR, SCHED_ALGO_WRR};

#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t fci_qos_scheduler_cmd_update_set_mode(const fci_t *fci, fpp_qos_scheduler_cmd_t **sch, uint16 **fci_ret, pfe_phy_if_t *phy_if);
static errno_t fci_qos_scheduler_cmd_update_cfg_scheduler(const fci_t *fci, fpp_qos_scheduler_cmd_t **sch, uint16 **fci_ret, pfe_phy_if_t *phy_if);
static errno_t fci_qos_scheduler_cmd_query_get_sch(const fci_t *fci, fpp_qos_scheduler_cmd_t *sch, uint16 **fci_ret, fpp_qos_scheduler_cmd_t **reply_buf, pfe_phy_if_t *phy_if);

/**
 * @brief           Get Phy if by name
 * @param[in]       name The name of the phy if
 * @return          the Physical interface phy_if
 */
static pfe_phy_if_t *fci_get_phy_if_by_name(char_t *name)
{
    fci_t *fci = (fci_t *)&context;
    pfe_if_db_entry_t *entry = NULL;
    pfe_phy_if_t *phy_if = NULL;
    errno_t ret;
    uint32 sid;

    ret = pfe_if_db_lock(&sid);
    if (EOK != ret)
    {
        NXP_LOG_WARNING("Could not lock interface DB: %d\n", ret);
    }
    else
    {
        ret = pfe_if_db_get_first(fci->phy_if_db, sid, IF_DB_CRIT_BY_NAME, name, &entry);
        if (EOK != ret)
        {
            NXP_LOG_WARNING("Interface DB query failed: %d\n", ret);
        }

        if(NULL != entry)
        {
            phy_if = pfe_if_db_entry_get_phy_if(entry);
        }

        ret = pfe_if_db_unlock(sid);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Interface DB unlock failed: %d\n", ret);
        }
    }

    return phy_if;
}

static errno_t queue_mode_wred(uint16 *fci_ret, fpp_qos_queue_cmd_t *q, const fci_t *fci, pfe_phy_if_t *phy_if)
{
    errno_t ret = EOK;
    uint8 cnt, ii;

    if (q->mode == 3U)
    {
        NXP_LOG_DEBUG("Setting WRED zones probabilities\n");

        cnt = pfe_tmu_queue_get_cnt(fci->tmu, pfe_phy_if_get_id(phy_if));

        if (cnt > 32U)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("Invalid zones count...\n");
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            ret = EINVAL;
        }
        else
        {
            for (ii=0U; ii < cnt; ii++)
            {
                NXP_LOG_DEBUG("Setting queue %d zone %d probability %d%%\n", (int_t)q->id, (int_t)ii, (int_t)q->zprob[ii]);
                ret = pfe_tmu_queue_set_wred_prob(fci->tmu, pfe_phy_if_get_id(phy_if), q->id, ii, q->zprob[ii]);
                if (EOK != ret)
                {
                    /* FCI command has wrong data. Respond with FCI error code. */
                    NXP_LOG_WARNING("Could not set queue %d zone %d probability %d: %d\n", (int_t)q->id, (int_t)ii, (int_t)q->zprob[ii], (int_t)ret);
                    *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                    ret = EOK;
                    break; /* for */
                }
            }
        }
    }

    return ret;
}

static errno_t qos_queue_cmd_action_update(uint16 *fci_ret, fpp_qos_queue_cmd_t *q, const fci_t *fci)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;
    uint8 cnt;

    /*  Get physical interface ID */
    phy_if = fci_get_phy_if_by_name(q->if_name);
    if (NULL == phy_if)
    {
        /* FCI command requested nonexistent entity. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        ret = EOK;
    }
    else if (PFE_PHY_IF_ID_UTIL == pfe_phy_if_get_id(phy_if))
    {
        /* FCI command requested unfulfillable action. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
        ret = EOK;
    }
    else
    {
        /*  Check queue ID */
        cnt = pfe_tmu_queue_get_cnt(fci->tmu, pfe_phy_if_get_id(phy_if));
        if (q->id > cnt)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            NXP_LOG_WARNING("Queue ID %d out of range. Interface %s implements %d queues\n", (int_t)q->id, q->if_name, (int_t)cnt);
            *fci_ret = FPP_ERR_QOS_QUEUE_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            NXP_LOG_DEBUG("Setting queue %d mode: %d (min: %d, max: %d)\n", (int_t)q->id, (int_t)q->mode, (int_t)oal_ntohl(q->min), (int_t)oal_ntohl(q->max));

            if (q->mode > 3U)
            {
                /* FCI command has wrong data. Respond with FCI error code. */
                NXP_LOG_WARNING("Unsupported queue mode: %d\n", q->mode);
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = EOK;
            }
            else
            {
                if (q->mode == 0U)
                {
                    /*  Disable the queue to drop all packets */
                    ret = pfe_tmu_queue_set_mode(fci->tmu, pfe_phy_if_get_id(phy_if), q->id, TMU_Q_MODE_TAIL_DROP, 0U, 0U);
                }
                else
                {
                    ret = pfe_tmu_queue_set_mode(fci->tmu, pfe_phy_if_get_id(phy_if), q->id, fci_qmode_to_qmode[q->mode], oal_ntohl(q->min), oal_ntohl(q->max));
                }

                if (EOK != ret)
                {
                    if (ENOSPC == ret)
                    {
                        /* FCI command requested unfulfillable action. Respond with FCI error code. */
                        NXP_LOG_WARNING("Refused to set max length of %s queue %d to %u, because then the sum of %s queue lengths would exceed allowed total limit.\n", pfe_phy_if_get_name(phy_if), q->id, (uint_t)oal_ntohl(q->max), pfe_phy_if_get_name(phy_if));
                        *fci_ret = FPP_ERR_QOS_QUEUE_SUM_OF_LENGTHS_EXCEEDED;
                        ret = EOK;
                    }
                    else
                    {
                        /* FCI command has wrong data. Respond with FCI error code. */
                        NXP_LOG_WARNING("Could not set queue %d mode %d: %d\n", q->id, q->mode, ret);
                        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                        ret = EOK;
                    }
                }
                else
                {
                    ret = queue_mode_wred(fci_ret, q, fci, phy_if);
                }
            }
        }
    }

    return ret;
}

static errno_t get_wred_zone_probs(fpp_qos_queue_cmd_t *reply_buf, uint16 *fci_ret, fpp_qos_queue_cmd_t *q, const fci_t *fci, pfe_phy_if_t *phy_if)
{
    errno_t ret = EOK;
    uint8 cnt, ii;

    /*  Get zone probabilities */
    cnt = pfe_tmu_queue_get_wred_zones(fci->tmu, pfe_phy_if_get_id(phy_if), q->id);
    for (ii=0U; ii<32U; ii++)
    {
        if (ii < cnt)
        {
            ret = pfe_tmu_queue_get_wred_prob(fci->tmu, pfe_phy_if_get_id(phy_if), q->id, ii, &reply_buf->zprob[ii]);
            if (EOK != ret)
            {
                /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                NXP_LOG_ERROR("Could not get queue %d zone %d probability: %d\n", (int_t)q->id, (int_t)ii, (int_t)ret);
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                break; /* for */
            }
        }
        else
        {
            reply_buf->zprob[ii] = 255; /* Invalid */
        }
    }

    return ret;
}

static errno_t qos_queue_cmd_action_query(fpp_qos_queue_cmd_t *reply_buf, uint16 *fci_ret, fpp_qos_queue_cmd_t *q, const fci_t *fci)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;

    /*  Get physical interface ID */
    phy_if = fci_get_phy_if_by_name(q->if_name);
    if (NULL == phy_if)
    {
        /* FCI command requested nonexistent entity. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        ret = EOK;
    }
    else
    {
        /*  Check queue */
        ret = pfe_tmu_check_queue(fci->tmu, pfe_phy_if_get_id(phy_if), q->id);
        if (EOK != ret)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_QOS_QUEUE_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            /*  Copy original command properties into reply structure */
            reply_buf->action = q->action;
            reply_buf->id = q->id;
            (void)autolibc_strncpy(reply_buf->if_name, q->if_name, sizeof(reply_buf->if_name));
            reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';

            /*  Get queue mode */
            switch (pfe_tmu_queue_get_mode(fci->tmu, pfe_phy_if_get_id(phy_if), q->id, &reply_buf->min, &reply_buf->max))
            {
                case TMU_Q_MODE_TAIL_DROP:
                {
                    if (reply_buf->max == 0U)
                    {
                        reply_buf->mode = 0U; /* Disabled */
                        reply_buf->max = 0U;
                        reply_buf->min = 0U;
                    }
                    else
                    {
                        reply_buf->mode = 2U; /* Tail Drop */
                        reply_buf->max = oal_htonl(reply_buf->max);
                        reply_buf->min = 0U;
                    }

                    break;
                }

                case TMU_Q_MODE_DEFAULT:
                {
                    reply_buf->mode = 1U; /* Default */
                    reply_buf->max = oal_htonl(reply_buf->max);
                    reply_buf->max = oal_htonl(reply_buf->min);
                    break;
                }

                case TMU_Q_MODE_WRED:
                {
                    reply_buf->mode = 3U; /* WRED */
                    reply_buf->max = oal_htonl(reply_buf->max);
                    reply_buf->min = oal_htonl(reply_buf->min);
                    ret = get_wred_zone_probs(reply_buf, fci_ret, q, fci, phy_if);

                    break;
                }

                default:
                {
                    /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                    NXP_LOG_ERROR("Can't get queue %d mode\n", q->id);
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    break;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_QOS_QUEUE command
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_qos_queue_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 */
errno_t fci_qos_queue_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_queue_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_qos_queue_cmd_t *q;
    errno_t ret = EOK;
    const fci_t *fci = (fci_t *)&context;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_qos_queue_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_qos_queue_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_qos_queue_cmd_t));
            q = (fpp_qos_queue_cmd_t *)msg->msg_cmd.payload;

            switch(q->action)
            {
                case FPP_ACTION_UPDATE:
                {
                    *fci_ret = FPP_ERR_OK;
                    ret = qos_queue_cmd_action_update(fci_ret, q, fci);
                    break;
                }

                case FPP_ACTION_QUERY:
                {
                    *fci_ret = FPP_ERR_OK;
                    ret = qos_queue_cmd_action_query(reply_buf, fci_ret, q, fci);
                    *reply_len = sizeof(fpp_qos_queue_cmd_t);
                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_QOS_QUEUE: Unknown action received: 0x%x\n", q->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }
        }
    }

    return ret;
}

static errno_t fci_qos_scheduler_cmd_update_set_mode(const fci_t *fci, fpp_qos_scheduler_cmd_t **sch, uint16 **fci_ret, pfe_phy_if_t *phy_if)
{
    errno_t ret;

    /*  Set scheduler mode */
    if (0U == (*sch)->mode)
    {
        NXP_LOG_INFO("Disabling all scheduler %d inputs\n", (*sch)->id);
        /*  Mark all inputs as disabled. Change will be applied below. */
        (*sch)->input_en = 0U;
        ret = EOK;
    }
    else if (1U == (*sch)->mode)
    {
        NXP_LOG_INFO("Setting scheduler %d mode: Data rate\n", (*sch)->id);
        ret = pfe_tmu_sch_set_rate_mode(fci->tmu,
                pfe_phy_if_get_id(phy_if), (*sch)->id, RATE_MODE_DATA_RATE);
    }
    else if (2U == (*sch)->mode)
    {
        NXP_LOG_INFO("Setting scheduler %d mode: Packet rate\n", (*sch)->id);
        ret = pfe_tmu_sch_set_rate_mode(fci->tmu,
                pfe_phy_if_get_id(phy_if), (*sch)->id, RATE_MODE_PACKET_RATE);
    }
    else
    {
        NXP_LOG_WARNING("Unsupported scheduler mode: 0x%x\n", (*sch)->mode);
        ret = EINVAL;
    }

    if (EOK != ret)
    {
        /* FCI command has wrong data. Respond with FCI error code. */
        NXP_LOG_WARNING("Scheduler mode not set: %d\n", ret);
        **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        ret = EOK;
    }
    /*  Set scheduler algorithm */
    else if ((*sch)->algo > 3U)
    {
        /* FCI command has wrong data. Respond with FCI error code. */
        NXP_LOG_WARNING("Unsupported scheduler algorithm: 0x%x\n", (*sch)->algo);
        **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        ret = EOK;
    }
    else
    {

        NXP_LOG_INFO("Setting scheduler %d algorithm: %s\n",
                (*sch)->id, sch_algos_str[(*sch)->algo]);
        ret = pfe_tmu_sch_set_algo(fci->tmu, pfe_phy_if_get_id(phy_if),
                (*sch)->id, sch_algos[(*sch)->algo]);
        if (EOK != ret)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_WARNING("Scheduler algorithm not set: %d\n", ret);
            **fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
    }

    return ret;
}

/**
 * @brief           Auxiliary function to check scheduler input of the scheduler command
 */
static bool_t check_scheduler_input(fpp_qos_scheduler_cmd_t **sch, uint8 ii)
{
    bool_t ret_value = FALSE;

    ret_value = ((0U == (((uint32)1U << ii) & (*sch)->input_en)) || ((*sch)->input_src[ii] == 255U));

    return ret_value;
}


static errno_t fci_qos_scheduler_cmd_update_cfg_scheduler(const fci_t *fci, fpp_qos_scheduler_cmd_t **sch, uint16 **fci_ret, pfe_phy_if_t *phy_if)
{
    errno_t ret = EINVAL;
    uint8 cnt = 0U;
    uint8 ii = 0U;

    /*  Configure scheduler inputs */
    cnt = pfe_tmu_sch_get_input_cnt(fci->tmu, pfe_phy_if_get_id(phy_if), (*sch)->id);
    (*sch)->input_en = oal_ntohl((*sch)->input_en);
    for (ii = 0U; ii < cnt; ii++)
    {
        if (check_scheduler_input(sch, ii))
        {
            NXP_LOG_DEBUG("Disabling scheduler %d input %d\n", (int_t)((*sch)->id), (int_t)ii);
            ret = pfe_tmu_sch_bind_queue(fci->tmu, pfe_phy_if_get_id(phy_if), (*sch)->id, ii, PFE_TMU_INVALID_QUEUE);
            if (EOK != ret)
            {
                /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                NXP_LOG_ERROR("Could not invalidate scheduler input %d: %d\n", (int_t)ii, (int_t)ret);
                **fci_ret = FPP_ERR_INTERNAL_FAILURE;
                break; /* for */
            }
        }
        else
        {
            if ((*sch)->input_src[ii] < 8U)
            {
                NXP_LOG_DEBUG("Connecting source %d to scheduler %d input %d\n", (int_t)(*sch)->input_src[ii], (int_t)(*sch)->id, (int_t)ii);
                ret = pfe_tmu_sch_bind_queue(fci->tmu, pfe_phy_if_get_id(phy_if), (*sch)->id, ii, (*sch)->input_src[ii]);
                if (EOK != ret)
                {
                    /* FCI command has wrong data. Respond with FCI error code. */
                    NXP_LOG_WARNING("Could not connect source %d to scheduler input %d\n", (int_t)((*sch)->input_src[ii]), (int_t)ii);
                    **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                    ret = EOK;
                    break; /* for */
                }
            }
            else if ((*sch)->input_src[ii] == 8U)
            {
                NXP_LOG_DEBUG("Connecting scheduler %d output to scheduler %d input %d\n", (int_t)((*sch)->id-1U), (int_t)((*sch)->id), (int_t)ii);
                ret = pfe_tmu_sch_bind_sch_output(fci->tmu, pfe_phy_if_get_id(phy_if), (*sch)->id-1U, (*sch)->id, ii);
                if (EOK != ret)
                {
                    /* FCI command has wrong data. Respond with FCI error code. */
                    NXP_LOG_WARNING("Could not connect scheduler %d output to scheduler %d input %d: %d\n", ((*sch)->id-1U), ((*sch)->id), ii, ret);
                    **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                    ret = EOK;
                    break; /* for */
                }
            }
            else
            {
                /* FCI command has wrong data. Respond with FCI error code. */
                NXP_LOG_WARNING("Unsupported scheduler input %d source: %d\n", (int_t)ii, (int_t)((*sch)->input_src[ii]));
                **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = EOK;
                break; /* for */
            }
            NXP_LOG_DEBUG("Setting scheduler %d input %d weight: %d\n", (int_t)((*sch)->id), (int_t)ii, (int_t)oal_ntohl((*sch)->input_w[ii]));
            ret = pfe_tmu_sch_set_input_weight(fci->tmu, pfe_phy_if_get_id(phy_if), (*sch)->id, ii, oal_ntohl((*sch)->input_w[ii]));
            if (EOK != ret)
            {
                /* FCI command has wrong data. Respond with FCI error code. */
                NXP_LOG_WARNING("Could not set scheduler %d input %d weight %d: %d\n", ((*sch)->id), ii, oal_ntohl((*sch)->input_w[ii]), ret);
                **fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = EOK;
                break; /* for */
            }

        }
    }

    return ret;
}

static errno_t fci_qos_scheduler_cmd_query_get_sch(const fci_t *fci, fpp_qos_scheduler_cmd_t *sch, uint16 **fci_ret, fpp_qos_scheduler_cmd_t **reply_buf, pfe_phy_if_t *phy_if)
{
    errno_t ret = EOK;
    uint32 weight;
    uint8 ii, cnt, queue;

    /*  Get scheduler mode */
    switch (pfe_tmu_sch_get_rate_mode(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id))
    {
        case RATE_MODE_DATA_RATE:
        {
            (*reply_buf)->mode = 1U;
            break;
        }

        case RATE_MODE_PACKET_RATE:
        {
            (*reply_buf)->mode = 2U;
            break;
        }

        default:
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("Can't get scheduler %d mode or the mode is invalid\n", sch->id);
            **fci_ret = FPP_ERR_INTERNAL_FAILURE;
            ret = EINVAL;
            break;
        }
    }

    /*  Get scheduler algo */
    (*reply_buf)->algo = (uint8)pfe_tmu_sch_get_algo(fci->tmu,
            pfe_phy_if_get_id(phy_if), sch->id);
    if ((*reply_buf)->algo == (uint8)SCHED_ALGO_INVALID)
    {
        /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
        NXP_LOG_ERROR("Can't get scheduler %d algo or the algo is invalid\n", sch->id);
        **fci_ret = FPP_ERR_INTERNAL_FAILURE;
        ret = EINVAL;
    }
    else
    {
        /*  Get enabled inputs and associated sources. See the Egress QoS chapter in FCI doc. */
        cnt = pfe_tmu_sch_get_input_cnt(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id);
        (*reply_buf)->input_en = 0U;
        for (ii=0U; ii < cnt; ii++)
        {
            queue = pfe_tmu_sch_get_bound_queue(fci->tmu, pfe_phy_if_get_id(phy_if),
                    sch->id, ii);
            if (PFE_TMU_INVALID_QUEUE == queue)
            {
                if (PFE_TMU_INVALID_SCHEDULER == pfe_tmu_sch_get_bound_sch_output(fci->tmu,
                        pfe_phy_if_get_id(phy_if), sch->id, ii))
                {
                    /*  Scheduler input 'ii' is not connected */
                    (*reply_buf)->input_src[ii] = 255U;
                }
                else
                {
                    /*  Scheduler input 'ii' is connected to prepend scheduler output */
                    weight = pfe_tmu_sch_get_input_weight(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id, ii);
                    (*reply_buf)->input_w[ii] = oal_htonl(weight);
                    (*reply_buf)->input_src[ii] = 8U;
                    (*reply_buf)->input_en |= ((uint32)1U << ii);
                }
            }
            else
            {
                /*  Scheduler input 'ii' is connected to queue */
                weight = pfe_tmu_sch_get_input_weight(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id, ii);
                (*reply_buf)->input_w[ii] = oal_htonl(weight);
                (*reply_buf)->input_src[ii] = queue;
                (*reply_buf)->input_en |= ((uint32)1U << ii);
            }
        }

        /*  Maintain endianness as given by FCI doc */
        (*reply_buf)->input_en = oal_htonl((*reply_buf)->input_en);
        ret = EOK;
    }

    return ret;
}

static errno_t scheduler_cmd_action_update(uint16 *fci_ret, const fci_t *fci, fpp_qos_scheduler_cmd_t *sch)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;

    /*  Get physical interface ID */
    phy_if = fci_get_phy_if_by_name(sch->if_name);
    if (NULL == phy_if)
    {
        /* FCI command requested nonexistent entity. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        ret = EOK;
    }
    else
    {
        /*  Check scheduler */
        ret = pfe_tmu_check_scheduler(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id);
        if (EOK != ret)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_QOS_SCHEDULER_NOT_FOUND;
            ret = EOK;
        }
        else if (PFE_PHY_IF_ID_UTIL == pfe_phy_if_get_id(phy_if))
        {
            /* FCI command requested unfulfillable action. Respond with FCI error code. */
            *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
            ret = EOK;
        }
        else
        {
            if (FPP_ERR_OK == *fci_ret)
            {
                ret = fci_qos_scheduler_cmd_update_set_mode(fci, &sch, &fci_ret, phy_if);

                if(FPP_ERR_OK == *fci_ret)
                {
                    ret = fci_qos_scheduler_cmd_update_cfg_scheduler(fci, &sch, &fci_ret, phy_if);
                }
            }
        }
    }

    return ret;
}

static errno_t scheduler_cmd_action_query(fpp_qos_scheduler_cmd_t *reply_buf, uint16 *fci_ret, const fci_t *fci, fpp_qos_scheduler_cmd_t *sch)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;

    /*  Get physical interface ID */
    phy_if = fci_get_phy_if_by_name(sch->if_name);
    if (NULL == phy_if)
    {
        /* FCI command requested nonexistent entity. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        ret = EOK;
    }
    else
    {
        /*  Check scheduler */
        ret = pfe_tmu_check_scheduler(fci->tmu, pfe_phy_if_get_id(phy_if), sch->id);
        if (EOK != ret)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_QOS_SCHEDULER_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            /*  Copy original command properties into reply structure */
            reply_buf->action = sch->action;
            reply_buf->id = sch->id;
            (void)autolibc_strncpy(reply_buf->if_name, sch->if_name, sizeof(reply_buf->if_name));
            reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';

            ret = fci_qos_scheduler_cmd_query_get_sch(fci, sch, &fci_ret, &reply_buf, phy_if);
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_QOS_SCHEDULER command
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_qos_scheduler_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 */
errno_t fci_qos_scheduler_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_scheduler_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_qos_scheduler_cmd_t *sch;
    errno_t ret = EOK;
    const fci_t *fci = (fci_t *)&context;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_qos_scheduler_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_qos_scheduler_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_qos_scheduler_cmd_t));
            sch = (fpp_qos_scheduler_cmd_t *)msg->msg_cmd.payload;

            switch(sch->action)
            {
                case FPP_ACTION_UPDATE:
                {
                    *fci_ret = FPP_ERR_OK;
                    ret = scheduler_cmd_action_update(fci_ret, fci, sch);
                    break;
                }

                case FPP_ACTION_QUERY:
                {
                    *fci_ret = FPP_ERR_OK;
                    ret = scheduler_cmd_action_query(reply_buf, fci_ret, fci, sch);
                    *reply_len = sizeof(fpp_qos_scheduler_cmd_t);
                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_QOS_SCHEDULER: Unknown action received: 0x%x\n", sch->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }

        }
    }
    return ret;
}

static errno_t set_shaper_cmd_props(uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp, pfe_phy_if_t *phy_if)
{
    errno_t ret = EINVAL;
    bool_t break_switch = FALSE;

    NXP_LOG_DEBUG("Setting shaper %d rate mode %d\n", shp->id, shp->mode);
    if (1U == shp->mode)
    {
        ret = pfe_tmu_shp_set_rate_mode(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id, RATE_MODE_DATA_RATE);
    }
    else if (2U == shp->mode)
    {
        ret = pfe_tmu_shp_set_rate_mode(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id, RATE_MODE_PACKET_RATE);
    }
    else
    {
        /* FCI command has wrong data. Respond with FCI error code. */
        NXP_LOG_ERROR("Invalid shaper rate mode value: %d\n", shp->mode);
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        ret = EOK;
        break_switch = TRUE;
    }
    if(FALSE == break_switch)
    {
        if (EOK != ret)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("Unable to set shaper %d rate mode %d: %d\n", shp->id, shp->mode, ret);
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else
        {
            NXP_LOG_DEBUG("Setting shaper %d credit limits %d-%d\n", (int_t)shp->id, (int_t)oal_ntohl(shp->max_credit), (int_t)oal_ntohl(shp->min_credit));
            ret = pfe_tmu_shp_set_limits(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id, (sint32)oal_ntohl(shp->max_credit), (sint32)oal_ntohl(shp->min_credit));
            if (EOK != ret)
            {
                /* FCI command has wrong data. Respond with FCI error code. */
                NXP_LOG_WARNING("Unable to set shaper %d limits: %d\n", shp->id, ret);
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = EOK;
            }
            else
            {
                NXP_LOG_DEBUG("Setting shaper %d position to %d\n", shp->id, shp->position);
                ret = pfe_tmu_shp_set_position(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id, shp->position);
                if (EOK != ret)
                {
                    /* FCI command has wrong data. Respond with FCI error code. */
                    NXP_LOG_WARNING("Can't set shaper %d at position %d: %d\n",shp->id, shp->position, ret);
                    *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                    ret = EOK;
                }
                else
                {
                    NXP_LOG_DEBUG("Setting shaper %d idle slope: %d\n", (int_t)shp->id, (int_t)oal_ntohl(shp->isl));
                    ret = pfe_tmu_shp_set_idle_slope(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id, oal_ntohl(shp->isl));
                    if (EOK != ret)
                    {
                        /* FCI command has wrong data. Respond with FCI error code. */
                        NXP_LOG_WARNING("Can't set shaper %d idle slope %d: %d\n", shp->id, oal_ntohl(shp->isl), ret);
                        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                        ret = EOK;
                    }
                }
            }
        }
    }

    return ret;
}

static errno_t shaper_disconnect_and_disable(uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp, pfe_phy_if_t *phy_if)
{
    errno_t ret = EOK;
    bool_t break_switch = FALSE;

    if (255U == shp->position)
    {
        NXP_LOG_DEBUG("Disconnecting shaper %d\n", shp->id);
        ret = pfe_tmu_shp_set_position(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id, PFE_TMU_INVALID_POSITION);
        if (EOK != ret)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("Could not disconnect shaper %d: %d\n", shp->id, ret);
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            break_switch = TRUE;
        }
    }
    if(FALSE == break_switch)
    {
        NXP_LOG_DEBUG("Disabling shaper %d\n", shp->id);
        ret = pfe_tmu_shp_disable(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id);
        if (EOK != ret)
        {
            /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
            NXP_LOG_ERROR("Could not disable shaper %d: %d\n", shp->id, ret);
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
    }

    return ret;
}

static errno_t shaper_cmd_action_update(uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;

    /*  Get physical interface ID */
    phy_if = fci_get_phy_if_by_name(shp->if_name);
    if (NULL == phy_if)
    {
        /* FCI command requested nonexistent entity. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        ret = EOK;
    }
    else if (PFE_PHY_IF_ID_UTIL == pfe_phy_if_get_id(phy_if))
    {
        /* FCI command requested unfulfillable action. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
        ret = EOK;
    }
    else
    {
        /*  Check shaper */
        ret = pfe_tmu_check_shaper(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id);
        if (EOK != ret)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_QOS_SHAPER_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            if (0U == shp->mode)
            {
                shaper_disconnect_and_disable(fci_ret, fci, shp, phy_if);
            }
            else
            {
                NXP_LOG_DEBUG("Enabling shaper %d\n", shp->id);
                ret = pfe_tmu_shp_enable(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id);
                if (EOK != ret)
                {
                    /* Internal problem. Set fci_ret, but respond with detected internal error code (ret). */
                    NXP_LOG_ERROR("Could not enable shaper %d: %d\n", shp->id, ret);
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
                else
                {
                    ret = set_shaper_cmd_props(fci_ret, fci, shp, phy_if);
                }
            }
        }
    }

    return ret;
}

static errno_t shaper_cmd_action_query(fpp_qos_shaper_cmd_t *reply_buf, uint16 *fci_ret, const fci_t *fci, fpp_qos_shaper_cmd_t *shp)
{
    errno_t ret = EOK;
    pfe_phy_if_t *phy_if = NULL;
    uint32 isl;

    /*  Get physical interface ID */
    phy_if = fci_get_phy_if_by_name(shp->if_name);
    if (NULL == phy_if)
    {
        /* FCI command requested nonexistent entity. Respond with FCI error code. */
        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
        ret = EOK;
    }
    else
    {
        /*  Check shaper */
        ret = pfe_tmu_check_shaper(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id);
        if (EOK != ret)
        {
            /* FCI command requested nonexistent entity. Respond with FCI error code. */
            *fci_ret = FPP_ERR_QOS_SHAPER_NOT_FOUND;
            ret = EOK;
        }
        else
        {
            /*  Copy original command properties into reply structure */
            reply_buf->action = shp->action;
            reply_buf->id = shp->id;
            (void)autolibc_strncpy(reply_buf->if_name, shp->if_name, sizeof(reply_buf->if_name));
            reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';

            /*  Get shaper mode */
            switch (pfe_tmu_shp_get_rate_mode(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id))
            {
                case RATE_MODE_DATA_RATE:
                {
                    reply_buf->mode = 1U;
                    break;
                }

                case RATE_MODE_PACKET_RATE:
                {
                    reply_buf->mode = 2U;
                    break;
                }

                default:
                {
                    /*  Shaper is disabled or the query failed */
                    reply_buf->mode = 0U;
                    break;
                }
            }

            /*  Get credit limits */
            ret = pfe_tmu_shp_get_limits(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id, &reply_buf->max_credit, &reply_buf->min_credit);
            if (ret != EOK)
            {
                NXP_LOG_ERROR("Could not get shaper %d limits: %d\n", shp->id, ret);
            }
            else
            {
                /*  Ensure expected endianness */
                reply_buf->max_credit = (sint32)oal_htonl(reply_buf->max_credit);
                reply_buf->min_credit = (sint32)oal_htonl(reply_buf->min_credit);
            }

            /*  Get idle slope */
            isl = pfe_tmu_shp_get_idle_slope(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id);
            reply_buf->isl = oal_htonl(isl);

            /*  Get shaper position */
            reply_buf->position = pfe_tmu_shp_get_position(fci->tmu, pfe_phy_if_get_id(phy_if), shp->id);
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_QOS_SHAPER command
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_qos_shaper_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 */
errno_t fci_qos_shaper_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_shaper_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_qos_shaper_cmd_t *shp;
    errno_t ret = EOK;
    const fci_t *fci = (fci_t *)&context;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_qos_shaper_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_qos_shaper_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;

            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_qos_shaper_cmd_t));
            shp = (fpp_qos_shaper_cmd_t *)msg->msg_cmd.payload;

            switch(shp->action)
            {
                case FPP_ACTION_UPDATE:
                {
                    *fci_ret = FPP_ERR_OK;
                    ret = shaper_cmd_action_update(fci_ret, fci, shp);
                    break;
                }

                case FPP_ACTION_QUERY:
                {
                    *fci_ret = FPP_ERR_OK;
                    ret = shaper_cmd_action_query(reply_buf, fci_ret, fci, shp);
                    *reply_len = sizeof(fpp_qos_shaper_cmd_t);
                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_QOS_SHAPER: Unknown action received: 0x%x\n", shp->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }
        }
    }
    return ret;
}

/**
 * @brief           Auxiliary function to get gpi of the pfy_if
 */
static pfe_gpi_t *fci_qos_get_gpi(const pfe_phy_if_t *phy_if)
{
    const pfe_emac_t *emac = pfe_phy_if_get_emac(phy_if);
    pfe_gpi_t *gpi = NULL;

    if (NULL != emac)
    {
          gpi = pfe_emac_get_gpi(emac);
    }

    return gpi;
}

static errno_t fci_validate_cmd_params(const fci_msg_t *msg, uint16 *fci_ret, void *reply_buf, uint32 *reply_len, uint32 cmd_len)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == context.fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)msg;
        (void)fci_ret;
        (void)reply_buf;
        if (*reply_len < cmd_len)
        {
            NXP_LOG_WARNING("Buffer length does not match command lenght\n");
            ret = EINVAL;
        }
    }
    return ret;
}

/**
 * @brief           Process FPP_CMD_QOS_POLICER command
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_qos_policer_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
errno_t fci_qos_policer_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_qos_policer_cmd_t *pol_cmd;
    pfe_phy_if_t *phy_if = NULL;
    pfe_gpi_t *gpi = NULL;
    errno_t ret = EOK;

    ret = fci_validate_cmd_params(msg, fci_ret, reply_buf, reply_len, sizeof(*pol_cmd));
    if (EOK == ret)
    {
        /*  No data written to reply buffer (yet) */
        *reply_len = 0U;

        /*  Initialize the reply buffer */
        (void)autolibc_memset(reply_buf, 0, sizeof(*reply_buf));

        pol_cmd = (fpp_qos_policer_cmd_t *)msg->msg_cmd.payload;

        /* get from phy_if to gpi */
        phy_if = fci_get_phy_if_by_name(pol_cmd->if_name);
        if (NULL == phy_if)
        {
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
            ret = ENOENT;
        }
        else
        {
            gpi = fci_qos_get_gpi(phy_if);
            if (NULL == gpi)
            {
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = ENOENT;
            }
            else
            {
                *fci_ret = FPP_ERR_OK;

                switch(pol_cmd->action)
                {
                    case FPP_ACTION_UPDATE:
                    {
                        if (0U != pol_cmd->enable)
                        {
                            ret = pfe_gpi_qos_enable(gpi);
                        }
                        else
                        {
                            ret = pfe_gpi_qos_disable(gpi);
                        }

                        if (EOK != ret)
                        {
                            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                        }

                        break;
                    }

                    case FPP_ACTION_QUERY:
                    {
                        /*  Copy original command properties into reply structure */
                        reply_buf->action = pol_cmd->action;
                        (void)autolibc_strncpy(reply_buf->if_name, pol_cmd->if_name, sizeof(reply_buf->if_name));
                        reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';

                        /*  get policer data */
                        reply_buf->enable = pfe_gpi_qos_is_enabled(gpi);
                        *reply_len = sizeof(*pol_cmd);
                        break;
                    }

                    default:
                    {
                        NXP_LOG_WARNING("FPP_CMD_QOS_POLICER: Unknown action received: 0x%x\n", pol_cmd->action);
                        *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                        break;
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           Auxiliary function to concert flow entry to gpi
 */
static void fci_qos_flow_entry_convert_to_gpi(const fpp_iqos_flow_spec_t *flow, pfe_iqos_flow_spec_t *gpi_flow)
{
    gpi_flow->type_mask = (pfe_iqos_flow_type_t)oal_ntohs(flow->type_mask);
    gpi_flow->arg_type_mask = (pfe_iqos_flow_arg_type_t)oal_ntohs(flow->arg_type_mask);
    gpi_flow->action = (pfe_iqos_flow_action_t)flow->action;

    gpi_flow->args.vlan = (uint16)oal_ntohs(flow->args.vlan);
    gpi_flow->args.vlan_m = (uint16)oal_ntohs(flow->args.vlan_m);
    gpi_flow->args.sport_max = (uint16)oal_ntohs(flow->args.sport_max);
    gpi_flow->args.sport_min = (uint16)oal_ntohs(flow->args.sport_min);
    gpi_flow->args.dport_max = (uint16)oal_ntohs(flow->args.dport_max);
    gpi_flow->args.dport_min = (uint16)oal_ntohs(flow->args.dport_min);

    gpi_flow->args.sip = (uint32)oal_ntohl(flow->args.sip);
    gpi_flow->args.dip = (uint32)oal_ntohl(flow->args.dip);

    gpi_flow->args.tos = flow->args.tos;
    gpi_flow->args.tos_m = flow->args.tos_m;
    gpi_flow->args.l4proto = flow->args.l4proto;
    gpi_flow->args.l4proto_m = flow->args.l4proto_m;
    gpi_flow->args.sip_m = flow->args.sip_m;
    gpi_flow->args.dip_m = flow->args.dip_m;
}

/**
 * @brief           Auxiliary function to concert gpi to flow entry
 */
static void fci_qos_flow_entry_convert_from_gpi(const pfe_iqos_flow_spec_t *gpi_flow, fpp_iqos_flow_spec_t *flow)
{
    flow->type_mask = (fpp_iqos_flow_type_t)oal_htons(gpi_flow->type_mask);
    flow->arg_type_mask = (fpp_iqos_flow_arg_type_t)oal_htons(gpi_flow->arg_type_mask);
    flow->action = (fpp_iqos_flow_action_t)gpi_flow->action;

    flow->args.vlan = (uint16)oal_htons(gpi_flow->args.vlan);
    flow->args.vlan_m = (uint16)oal_htons(gpi_flow->args.vlan_m);
    flow->args.sport_max = (uint16)oal_htons(gpi_flow->args.sport_max);
    flow->args.sport_min = (uint16)oal_htons(gpi_flow->args.sport_min);
    flow->args.dport_max = (uint16)oal_htons(gpi_flow->args.dport_max);
    flow->args.dport_min = (uint16)oal_htons(gpi_flow->args.dport_min);

    flow->args.sip = (uint32)oal_htonl(gpi_flow->args.sip);
    flow->args.dip = (uint32)oal_htonl(gpi_flow->args.dip);

    flow->args.tos = gpi_flow->args.tos;
    flow->args.tos_m = gpi_flow->args.tos_m;
    flow->args.l4proto = gpi_flow->args.l4proto;
    flow->args.l4proto_m = gpi_flow->args.l4proto_m;
    flow->args.sip_m = gpi_flow->args.sip_m;
    flow->args.dip_m = gpi_flow->args.dip_m;
}

/**
 * @brief           Performs register action of the qos flow cmd
 */
static errno_t policer_flow_cmd_action_register(uint16 *fci_ret, fpp_qos_policer_flow_cmd_t *flow_cmd, pfe_iqos_flow_spec_t *gpi_flow, pfe_gpi_t *gpi)
{
    errno_t ret = EOK;

    /* populate gpi flow struct */
    fci_qos_flow_entry_convert_to_gpi(&flow_cmd->flow, gpi_flow);

    /* commit configuration to H/W */
    ret = pfe_gpi_qos_add_flow(gpi, flow_cmd->id, gpi_flow);
    if (EOVERFLOW == ret)
    {
        *fci_ret = FPP_ERR_QOS_POLICER_FLOW_TABLE_FULL;
    }
    else if (EINVAL == ret)
    {
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
    }
    else if (EOK != ret)
    {
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
    }
    else
    {
        ;/* Required by Misra */
    }

    return ret;
}

/**
 * @brief           Performs deregister action of the qos flow cmd
 */
static errno_t policer_flow_cmd_action_deregister(uint16 *fci_ret, fpp_qos_policer_flow_cmd_t *flow_cmd, pfe_gpi_t *gpi)
{
    errno_t ret = EOK;

    if (flow_cmd->id >= PFE_IQOS_FLOW_TABLE_SIZE)
    {
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
    }
    else
    {
        ret = pfe_gpi_qos_rem_flow(gpi, flow_cmd->id);
        if (ret != EOK)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_QOS_POLICER_FLOW command
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_qos_policer_flow_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
errno_t fci_qos_policer_flow_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_flow_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_qos_policer_flow_cmd_t *flow_cmd;
    pfe_iqos_flow_spec_t gpi_flow;
    pfe_phy_if_t *phy_if = NULL;
    pfe_gpi_t *gpi = NULL;
    errno_t ret = EOK;

    (void)autolibc_memset(&gpi_flow, 0, sizeof(pfe_iqos_flow_spec_t));
    ret = fci_validate_cmd_params(msg, fci_ret, reply_buf, reply_len, sizeof(*flow_cmd));
    if (EOK == ret)
    {
        /*  No data written to reply buffer (yet) */
        *reply_len = 0U;
        /*  Initialize the reply buffer */
        (void)autolibc_memset(reply_buf, 0, sizeof(*reply_buf));

        flow_cmd = (fpp_qos_policer_flow_cmd_t *)msg->msg_cmd.payload;

        /* get from phy_if to gpi */
        phy_if = fci_get_phy_if_by_name(flow_cmd->if_name);
        if (NULL == phy_if)
        {
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
            ret = ENOENT;
        }
        else
        {
            gpi = fci_qos_get_gpi(phy_if);
            if (NULL == gpi)
            {
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = ENOENT;
            }
            else
            {
                *fci_ret = FPP_ERR_OK;

                switch(flow_cmd->action)
                {
                    case FPP_ACTION_REGISTER:
                    {
                        ret = policer_flow_cmd_action_register(fci_ret, flow_cmd, &gpi_flow, gpi);
                        break;
                    }
                    case FPP_ACTION_DEREGISTER:
                    {
                        ret = policer_flow_cmd_action_deregister(fci_ret, flow_cmd, gpi);
                        break;
                    }
                    case FPP_ACTION_QUERY:
                    {
                        /*  Copy original command properties into reply structure */
                        reply_buf->action = flow_cmd->action;
                        (void)autolibc_strncpy(reply_buf->if_name, flow_cmd->if_name, sizeof(reply_buf->if_name));
                        reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';

                        ret = pfe_gpi_qos_get_first_flow(gpi, &reply_buf->id, &gpi_flow);
                        if (ret != EOK)
                        {
                            *fci_ret = FPP_ERR_QOS_POLICER_FLOW_NOT_FOUND;
                            ret = EOK;
                            break;
                        }

                        /* populate fci flow struct */
                        fci_qos_flow_entry_convert_from_gpi(&gpi_flow, &reply_buf->flow);

                        *reply_len = sizeof(*flow_cmd);
                        break;
                    }

                    case FPP_ACTION_QUERY_CONT:
                    {
                        /*  Copy original command properties into reply structure */
                        reply_buf->action = flow_cmd->action;
                        (void)autolibc_strncpy(reply_buf->if_name, flow_cmd->if_name, sizeof(reply_buf->if_name));
                        reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';

                        ret = pfe_gpi_qos_get_next_flow(gpi, &reply_buf->id, &gpi_flow);
                        if (ret != EOK)
                        {
                            *fci_ret = FPP_ERR_QOS_POLICER_FLOW_NOT_FOUND;
                            ret = EOK;
                            break;
                        }

                        /* populate fci flow struct */
                        fci_qos_flow_entry_convert_from_gpi(&gpi_flow, &reply_buf->flow);

                        *reply_len = sizeof(*flow_cmd);
                        break;
                    }
                    default:
                    {
                        NXP_LOG_WARNING("FPP_CMD_QOS_POLICER_FLOW: Unknown action received: 0x%x\n", flow_cmd->action);
                        *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                        break;
                    }
                }
            }
        }
    }

    return ret;
}


static errno_t wred_thr_set_reg(pfe_gpi_t *gpi, fpp_iqos_queue_t queue, fpp_qos_policer_wred_cmd_t *wred_cmd)
{
    errno_t ret = EOK;
    uint16 wred_thr;
    uint32 i;

    for (i = 0; i < (uint32)FPP_IQOS_WRED_THR_COUNT; i++)
    {
        wred_thr = oal_ntohs(wred_cmd->thr[i]);
        if (PFE_IQOS_WRED_THR_SKIP == wred_thr)
        {
            /* continue to next thr */
        }
        else
        {
            ret = pfe_gpi_wred_set_thr(gpi, (pfe_iqos_queue_t)queue, (pfe_iqos_wred_thr_t)i, wred_thr);
            if (EOK != ret)
            {
                break;
            }
        }
    }

    return ret;
}

static errno_t wred_prob_zone_set_reg(pfe_gpi_t *gpi, fpp_iqos_queue_t queue, fpp_qos_policer_wred_cmd_t *wred_cmd)
{
    errno_t ret = EOK;
    uint32 i;

    for (i = 0; i < (uint32)FPP_IQOS_WRED_ZONES_COUNT; i++)
    {
        if (PFE_IQOS_WRED_ZONE_PROB_SKIP == wred_cmd->zprob[i])
        {
            /* continue to next prob zone */
        }
        else
        {
            ret = pfe_gpi_wred_set_prob(gpi, (pfe_iqos_queue_t)queue, (pfe_iqos_wred_zone_t)i, wred_cmd->zprob[i]);
            if (EOK != ret)
            {
                break;
            }
        }
    }

    return ret;
}

static errno_t policer_wred_cmd_action_update(uint16 *fci_ret, fpp_qos_policer_wred_cmd_t *wred_cmd, pfe_gpi_t *gpi, fpp_iqos_queue_t queue)
{
    errno_t ret = EOK;
    bool_t switch_break = FALSE;

    if (0U != wred_cmd->enable)
    {
        ret = pfe_gpi_wred_enable(gpi, (pfe_iqos_queue_t)queue);
    }
    else
    {
        /* exit configuration update on disable */
        ret = pfe_gpi_wred_disable(gpi, (pfe_iqos_queue_t)queue);
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        switch_break = TRUE;
    }

    if(FALSE == switch_break)
    {
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else
        {
            ret = wred_thr_set_reg(gpi, queue, wred_cmd);

            if (EOK != ret)
            {
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            else
            {
                ret = wred_prob_zone_set_reg(gpi, queue, wred_cmd);

                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
            }
        }
    }

    return ret;
}

static errno_t policer_wred_cmd_action_query(fpp_qos_policer_wred_cmd_t *reply_buf, uint16 *fci_ret, fpp_qos_policer_wred_cmd_t *wred_cmd, pfe_gpi_t *gpi, fpp_iqos_queue_t queue)
{
    errno_t ret=EOK;
    uint32 i;
    uint16 wred_thr;

    /* copy original command properties into reply structure */
    reply_buf->action = wred_cmd->action;
    (void)autolibc_strncpy(reply_buf->if_name, wred_cmd->if_name, sizeof(reply_buf->if_name));
    reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';
    reply_buf->queue = queue;

    /* get WRED data */
    reply_buf->enable = pfe_gpi_wred_is_enabled(gpi, (pfe_iqos_queue_t)queue);

    for (i = 0; i < (uint32)FPP_IQOS_WRED_THR_COUNT; i++)
    {
        ret = pfe_gpi_wred_get_thr(gpi, (pfe_iqos_queue_t)queue, (pfe_iqos_wred_thr_t)i, &wred_thr);
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            break;
        }
        else
        {
            reply_buf->thr[i] = oal_htons(wred_thr);
        }
    }

    for (i = 0; i < (uint32)FPP_IQOS_WRED_ZONES_COUNT; i++)
    {
        ret = pfe_gpi_wred_get_prob(gpi, (pfe_iqos_queue_t)queue, (pfe_iqos_wred_zone_t)i, &reply_buf->zprob[i]);
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            break;
        }
    }

    return ret;
}

errno_t fci_qos_policer_wred_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_wred_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_qos_policer_wred_cmd_t *wred_cmd;
    fpp_iqos_queue_t queue;
    pfe_phy_if_t *phy_if;
    pfe_gpi_t *gpi;
    errno_t ret;

    ret = fci_validate_cmd_params(msg, fci_ret, reply_buf, reply_len, sizeof(*wred_cmd));
    if (EOK == ret)
    {
        /* no data written to reply buffer (yet) */
        *reply_len = 0U;

        /* initialize the reply buffer */
        (void)autolibc_memset(reply_buf, 0, sizeof(*reply_buf));

        /* map command structure to message payload (requires casting) */
        wred_cmd = (fpp_qos_policer_wred_cmd_t *)msg->msg_cmd.payload;

        /* get from phy_if to gpi */
        phy_if = fci_get_phy_if_by_name(wred_cmd->if_name);
        if (NULL == phy_if)
        {
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
            ret = ENOENT;
        }
        else
        {
            gpi = fci_qos_get_gpi(phy_if);
            if (NULL == gpi)
            {
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = ENOENT;
            }
            else
            {
                /* basic command validations */
                queue = wred_cmd->queue;
                if (queue >= FPP_IQOS_Q_COUNT)
                {
                    *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                    ret = EINVAL;
                }
                else
                {
                    *fci_ret = FPP_ERR_OK;

                    switch(wred_cmd->action)
                    {
                        case FPP_ACTION_UPDATE:
                        {
                            ret = policer_wred_cmd_action_update(fci_ret, wred_cmd, gpi, queue);
                            break;
                        }

                        case FPP_ACTION_QUERY:
                        {
                            ret = policer_wred_cmd_action_query(reply_buf, fci_ret, wred_cmd, gpi, queue);
                            *reply_len = sizeof(*wred_cmd);
                            break;
                        }

                        default:
                        {
                            NXP_LOG_WARNING("FPP_CMD_QOS_POLICER_WRED: Unknown action received: 0x%x\n", wred_cmd->action);
                            *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                            break;
                        }
                    }
                }
            }
        }
    }

    return ret;
}

static errno_t policer_shp_cmd_action_update(uint16 *fci_ret, fpp_qos_policer_shp_cmd_t *shp_cmd, pfe_gpi_t *gpi, uint8 shp_id)
{
    errno_t ret = EOK;
    fpp_iqos_shp_type_t shp_type;
    fpp_iqos_shp_rate_mode_t shp_mode;
    uint32  shp_isl;
    sint32 shp_max_credit = 0;
    sint32 shp_min_credit = 0;
    bool_t switch_break = FALSE;

    (void)autolibc_memset(&shp_type, 0, sizeof(fpp_iqos_shp_type_t));
    (void)autolibc_memset(&shp_mode, 0, sizeof(fpp_iqos_shp_rate_mode_t));

    if (0U != shp_cmd->enable)
    {
        ret = pfe_gpi_shp_enable(gpi, shp_id);
    }
    else
    {
        /* exit configuration update on disable */
        ret = pfe_gpi_shp_disable(gpi, shp_id);
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        switch_break = TRUE;
    }

    if(FALSE == switch_break)
    {
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else
        {
            shp_type = shp_cmd->type;
            shp_mode = shp_cmd->mode;
            shp_isl = oal_ntohl(shp_cmd->isl);
            shp_max_credit = (sint32)oal_ntohl(shp_cmd->max_credit);
            shp_min_credit = (sint32)oal_ntohl(shp_cmd->min_credit);

            /* commit command to h/w */
            ret = pfe_gpi_shp_set_type(gpi, shp_id, (pfe_iqos_shp_type_t)shp_type);
            if (EOK != ret)
            {
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            else
            {
                ret = pfe_gpi_shp_set_mode(gpi, shp_id, (pfe_iqos_shp_rate_mode_t)shp_mode);
                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
                else
                {
                    NXP_LOG_DEBUG("Setting shaper %d idle slope: %u\n", shp_id, (uint_t)shp_isl);
                    ret = pfe_gpi_shp_set_idle_slope(gpi, shp_id, shp_isl);
                    if (EOK != ret)
                    {
                        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                    }
                    else
                    {
                        NXP_LOG_DEBUG("Setting shaper %d credit limits: [%d, %d]\n", shp_id, (int_t)shp_min_credit, (int_t)shp_max_credit);
                        ret = pfe_gpi_shp_set_limits(gpi, shp_id, shp_max_credit, shp_min_credit);
                        if (EOK != ret)
                        {
                            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                        }
                    }
                }
            }
        }
    }

    return ret;
}

static errno_t policer_shp_cmd_action_query(fpp_qos_policer_shp_cmd_t *reply_buf, uint16 *fci_ret, fpp_qos_policer_shp_cmd_t *shp_cmd, pfe_gpi_t *gpi, uint8 shp_id)
{
    errno_t ret = EOK;
    fpp_iqos_shp_type_t shp_type;
    fpp_iqos_shp_rate_mode_t shp_mode;
    uint32  shp_isl;
    sint32 shp_max_credit = 0;
    sint32 shp_min_credit = 0;

    (void)autolibc_memset(&shp_type, 0, sizeof(fpp_iqos_shp_type_t));
    (void)autolibc_memset(&shp_mode, 0, sizeof(fpp_iqos_shp_rate_mode_t));

    /* copy original command properties into reply structure */
    reply_buf->action = shp_cmd->action;
    (void)autolibc_strncpy(reply_buf->if_name, shp_cmd->if_name, sizeof(reply_buf->if_name));
    reply_buf->if_name[sizeof(reply_buf->if_name) - 1U] = '\0';
    reply_buf->id = shp_id;

    /* get shaper data */
    reply_buf->enable = pfe_gpi_shp_is_enabled(gpi, shp_id);

    ret = pfe_gpi_shp_get_type(gpi, shp_id, (pfe_iqos_shp_type_t *)&shp_type);
    if (EOK != ret)
    {
        *fci_ret = FPP_ERR_INTERNAL_FAILURE;
    }
    else
    {
        ret = pfe_gpi_shp_get_mode(gpi, shp_id, (pfe_iqos_shp_rate_mode_t *)&shp_mode);
        if (EOK != ret)
        {
            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
        }
        else
        {
            ret = pfe_gpi_shp_get_idle_slope(gpi, shp_id, &shp_isl);
            if (EOK != ret)
            {
                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
            }
            else
            {
                ret = pfe_gpi_shp_get_limits(gpi, shp_id, &shp_max_credit, &shp_min_credit);
                if (EOK != ret)
                {
                    *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                }
                else
                {
                    reply_buf->type = shp_type;
                    reply_buf->mode = shp_mode;
                    reply_buf->isl = oal_htonl(shp_isl);
                    reply_buf->max_credit = (sint32)oal_htonl(shp_max_credit);
                    reply_buf->min_credit = (sint32)oal_htonl(shp_min_credit);
                }
            }
        }
    }
    return ret;
}
errno_t fci_qos_policer_shp_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_qos_policer_shp_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_qos_policer_shp_cmd_t *shp_cmd;
    uint8 shp_id;
    pfe_phy_if_t *phy_if;
    pfe_gpi_t *gpi;
    errno_t ret;

    ret = fci_validate_cmd_params(msg, fci_ret, reply_buf, reply_len, sizeof(*shp_cmd));
    if (EOK == ret)
    {
        /* no data written to reply buffer (yet) */
        *reply_len = 0U;
        /* initialize the reply buffer */
        (void)autolibc_memset(reply_buf, 0, sizeof(*reply_buf));

        /* map command structure to message payload (requires casting) */
        shp_cmd = (fpp_qos_policer_shp_cmd_t *)msg->msg_cmd.payload;

        /* get from phy_if to gpi */
        phy_if = fci_get_phy_if_by_name(shp_cmd->if_name);
        if (NULL == phy_if)
        {
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
            ret = ENOENT;
        }
        else
        {
            gpi = fci_qos_get_gpi(phy_if);
            if (NULL == gpi)
            {
                *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                ret = ENOENT;
            }
            else
            {
                /* basic command validations */
                shp_id = shp_cmd->id;
                if (shp_id >= PFE_IQOS_SHP_COUNT)
                {
                    *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
                    ret = EINVAL;
                }
                else
                {
                    *fci_ret = FPP_ERR_OK;

                    switch(shp_cmd->action)
                    {
                        case FPP_ACTION_UPDATE:
                        {
                            ret = policer_shp_cmd_action_update(fci_ret, shp_cmd, gpi, shp_id);
                            break;
                        }

                        case FPP_ACTION_QUERY:
                        {
                            ret = policer_shp_cmd_action_query(reply_buf, fci_ret, shp_cmd, gpi, shp_id);
                            *reply_len = sizeof(*shp_cmd);
                            break;
                        }

                        default:
                        {
                            NXP_LOG_WARNING("FPP_CMD_QOS_POLICER_SHP: Unknown action received: 0x%x\n", shp_cmd->action);
                            *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                            break;
                        }
                    }
                }
            }
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */
/** @}*/


===== 文件 [120/185]: src\fci_routes.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_routes.c
 * @brief       IP routes management functions.
 * @details     All IP routes related functionality provided by the FCI should be
 *              implemented within this file. This includes mainly route-related
 *              commands.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "pfe_platform_cfg.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"

#include "fci_internal.h"
#include "fci.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE
#ifdef PFE_CFG_RTABLE_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route);
static bool_t check_if_hif(pfe_ct_phy_if_id_t phy_if_id);
static errno_t routes_cmd_action_register(fci_msg_t *msg, uint16 *fci_ret, fpp_rt_cmd_t *rt_cmd, pfe_ip_addr_t *ip, pfe_mac_addr_t *dst_mac);
static errno_t routes_cmd_query_cont(uint16 *fci_ret, fpp_rt_cmd_t *reply_buf, uint32 *reply_len, fci_rt_db_entry_t *rt_entry);
static errno_t routes_cmd_action_deregister( uint16 *fci_ret, fpp_rt_cmd_t *rt_cmd, fci_rt_db_t *route_db);
static void prepare_mac_src(pfe_mac_addr_t *src_mac, pfe_phy_if_t *phy_if, fpp_rt_cmd_t *rt_cmd);

/**
 * @brief       Remove all connections related to the given route
 * @details     When a route becomes invalid or it is being removed, all related connections need
 *              to be handled. Go therefore through all registered connections and remove ones which
 *              are related to the referenced route (by ID).
 * @param[in]   route The reference route
 */

static void fci_routes_remove_related_connections(fci_rt_db_entry_t *route)
{
    const fci_t *fci_context = (fci_t *)&context;
    pfe_rtable_entry_t *entry;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == route)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry = pfe_rtable_get_first(fci_context->rtable, RTABLE_CRIT_BY_ROUTE_ID, &route->id);
        while (NULL != entry)
        {
            ret = fci_connections_drop_one(entry);
            if (EOK != ret)
            {
                NXP_LOG_WARNING("Couldn't properly drop a connection: %d\n", ret);
            }

            /* Release the entry */
            pfe_rtable_entry_free(fci_context->rtable, entry);

            entry = pfe_rtable_get_next(fci_context->rtable);
        }
    }
}

/**
 * @brief       Check if provided interface is a HIF
 */
static bool_t check_if_hif(pfe_ct_phy_if_id_t phy_if_id)
{
    bool_t result = FALSE;

    result = ((PFE_PHY_IF_ID_HIF0 == phy_if_id) || (PFE_PHY_IF_ID_HIF1 == phy_if_id) ||
            (PFE_PHY_IF_ID_HIF2 == phy_if_id) || (PFE_PHY_IF_ID_HIF3 == phy_if_id) ||
            (PFE_PHY_IF_ID_HIF_NOCPY == phy_if_id));

    return result;
}

/**
 * @brief       Prepare source MAC address
 */
static void prepare_mac_src(pfe_mac_addr_t *src_mac, pfe_phy_if_t *phy_if, fpp_rt_cmd_t *rt_cmd)
{
    const pfe_mac_addr_t zero_mac = {0u};
    pfe_ct_phy_if_id_t phy_if_id;

    (void)autolibc_memset(src_mac, 0, sizeof(pfe_mac_addr_t));
    if (0 == autolibc_memcmp(rt_cmd->src_mac, zero_mac, sizeof(pfe_mac_addr_t)))
    {
        phy_if_id = pfe_phy_if_get_id(phy_if);
        if (TRUE == check_if_hif(phy_if_id))
        {
            NXP_LOG_WARNING("FPP_CMD_IP_ROUTE: HIF does not have MAC address storage (yet)\n");
        }
        else
        {
            if (EOK != pfe_phy_if_get_mac_addr_first(phy_if, *src_mac, MAC_DB_CRIT_ALL, PFE_TYPE_ANY, PFE_CFG_LOCAL_IF))
            {
                NXP_LOG_WARNING("FPP_CMD_IP_ROUTE: Get the first MAC address from mac addr db failed\n");
            }
        }
    }
    else
    {
        (void)autolibc_memcpy(src_mac, rt_cmd->src_mac, sizeof(pfe_mac_addr_t));
    }
}

static errno_t routes_cmd_action_register(fci_msg_t *msg, uint16 *fci_ret, fpp_rt_cmd_t *rt_cmd, pfe_ip_addr_t *ip, pfe_mac_addr_t *dst_mac)
{
    errno_t ret = EOK;
    uint32 session_id = 0U;
    pfe_phy_if_t *phy_if = NULL;
    pfe_if_db_entry_t *if_entry = NULL;
    fci_t *fci_context = (fci_t *)&context;
    pfe_mac_addr_t src_mac;

    ret = pfe_if_db_lock(&session_id);
    if (EOK == ret)
    {
        /*  Validate the interface */
        ret = pfe_if_db_get_first(fci_context->phy_if_db, session_id, IF_DB_CRIT_BY_NAME, (void *)rt_cmd->output_device, &if_entry);
        if(EOK != ret)
        {
            NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: DB is locked in different session, entry was not retrieved from DB\n");
        }
    }
    else
    {
        NXP_LOG_WARNING("FPP_CMD_IP_ROUTE: DB lock failed\n");
    }

    if (NULL == if_entry)
    {
        /*  No such interface */
        NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: Interface %s not found\n", rt_cmd->output_device);
        *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
    }
    else
    {
        phy_if = pfe_if_db_entry_get_phy_if(if_entry);

        /*  Prepare MAC source address */
        prepare_mac_src(&src_mac, phy_if, rt_cmd);

        /*  Add entry to database (values in network endian) */
        ret = fci_rt_db_add(&fci_context->route_db, ip, &src_mac, dst_mac, phy_if, rt_cmd->id, msg->client, FALSE);

        if (EPERM == ret)
        {
            NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: Already registered\n");
            *fci_ret = FPP_ERR_RT_ENTRY_ALREADY_REGISTERED;
        }
        else if (EOK != ret)
        {
            NXP_LOG_WARNING("FPP_CMD_IP_ROUTE: Can't add route entry: %d\n", ret);
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        }
        else
        {
            NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: Route (ID: %d, IF: %s) added\n", (int_t)oal_ntohl(rt_cmd->id), rt_cmd->output_device);
            *fci_ret = FPP_ERR_OK;
        }
    }

    ret = pfe_if_db_unlock(session_id);
    if(EOK != ret)
    {
        NXP_LOG_ERROR("FPP_CMD_IP_ROUTE: DB unlock failed\n");
    }

    return ret;
}

static errno_t routes_cmd_query_cont(uint16 *fci_ret, fpp_rt_cmd_t *reply_buf, uint32 *reply_len, fci_rt_db_entry_t *rt_entry)
{
    errno_t ret = EOK;
    bool_t break_switch = FALSE;
    fci_t *fci_context = (fci_t *)&context;

    if (NULL == rt_entry)
    {
        rt_entry = fci_rt_db_get_next(&fci_context->route_db);
        if (NULL == rt_entry)
        {
            ret = EOK;
            *fci_ret = FPP_ERR_RT_ENTRY_NOT_FOUND;
            break_switch = TRUE;
        }
    }
    if(FALSE == break_switch)
    {
        /*  Write the reply buffer */
        *reply_len = sizeof(fpp_rt_cmd_t);

        /*  Build reply structure */
        reply_buf->mtu = rt_entry->mtu;
        (void)autolibc_memcpy(reply_buf->src_mac, rt_entry->src_mac, sizeof(pfe_mac_addr_t));
        (void)autolibc_memcpy(reply_buf->dst_mac, rt_entry->dst_mac, sizeof(pfe_mac_addr_t));

        if (rt_entry->dst_ip.is_ipv4)
        {
            /*  IPv4 */
            (void)autolibc_memcpy(&reply_buf->dst_addr[0], &rt_entry->dst_ip.v4, 4);
            reply_buf->flags = oal_htonl(1U); /* Magic number '1U' assigned to IPv4 for historic reasons. */
        }
        else
        {
            /*  IPv6 */
            (void)autolibc_memcpy(&reply_buf->dst_addr[0], &rt_entry->dst_ip.v6, 16);
            reply_buf->flags = oal_htonl(2U); /* Magic number '2U' assigned to IPv6 for historic reasons. */
        }

        reply_buf->id = rt_entry->id;
        (void)autolibc_strncpy(reply_buf->output_device, pfe_phy_if_get_name(rt_entry->iface), (uint32)IFNAMSIZ-1U);

        *fci_ret = FPP_ERR_OK;
        ret = EOK;
    }

    return ret;
}

static errno_t routes_cmd_action_deregister( uint16 *fci_ret, fpp_rt_cmd_t *rt_cmd, fci_rt_db_t *route_db)
{
    errno_t ret = EOK;
    fci_rt_db_entry_t *rt_entry = NULL;

    /*  Validate the route */
    rt_entry = fci_rt_db_get_first(route_db, RT_DB_CRIT_BY_ID, (void *)&rt_cmd->id);
    if (NULL == rt_entry)
    {
        NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: Requested route %d not found\n", (int_t)oal_ntohl(rt_cmd->id));
        *fci_ret = FPP_ERR_RT_ENTRY_NOT_FOUND;
    }
    else
    {
        /*  Remove related connections, then the route, and disable the interface if needed */
        ret = fci_routes_drop_one(rt_entry);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("FPP_CMD_IP_ROUTE: Can't remove route entry: %d\n", ret);
            *fci_ret = FPP_ERR_WRONG_COMMAND_PARAM;
        }
        else
        {
            NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: Route %d removed\n", (int_t)oal_ntohl(rt_cmd->id));
        }
    }

    return ret;
}

/**
 * @brief           Process FPP_CMD_IP_ROUTE commands
 * @param[in]       msg FCI message containing the FPP_RCMD_IP_ROUTE command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_rt_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 * @note            Function is only called within the FCI worker thread context.
 * @note            Must run with route DB protected against concurrent accesses.
 */
errno_t fci_routes_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_rt_cmd_t *reply_buf, uint32 *reply_len)
{
    fci_t *fci_context = (fci_t *)&context;
    fpp_rt_cmd_t *rt_cmd;
    bool_t is_ipv6 = FALSE;
    errno_t ret = EOK;
    pfe_mac_addr_t dst_mac;
    pfe_ip_addr_t ip;
    fci_rt_db_entry_t *rt_entry = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */

    {
        if (*reply_len < sizeof(fpp_rt_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_rt_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_rt_cmd_t));

            rt_cmd = (fpp_rt_cmd_t *)(msg->msg_cmd.payload);
            is_ipv6 = (oal_ntohl(rt_cmd->flags) == 2U) ? TRUE : FALSE;  /* Magic number '2U' assigned to IPv6 for historic reasons. */

            /*  Prepare MAC and IP destination address */
            (void)autolibc_memcpy(dst_mac, rt_cmd->dst_mac, sizeof(pfe_mac_addr_t));
            (void)autolibc_memset(&ip, 0, sizeof(pfe_ip_addr_t));

            if (is_ipv6)
            {
                /*  Convert to 'known' IPv6 address format */
                (void)autolibc_memcpy(&ip.v6, &rt_cmd->dst_addr[0], 16);
                ip.is_ipv4 = FALSE;
            }
            else
            {
                /*  Convert to 'known' IPv4 address format */
                (void)autolibc_memcpy(&ip.v4, &rt_cmd->dst_addr[0], 4);
                ip.is_ipv4 = TRUE;
            }

            switch (rt_cmd->action)
            {
                case FPP_ACTION_REGISTER:
                {
                    ret = routes_cmd_action_register(msg, fci_ret, rt_cmd, &ip, &dst_mac);
                    break;
                }

                case FPP_ACTION_DEREGISTER:
                {
                    ret = routes_cmd_action_deregister( fci_ret, rt_cmd, &fci_context->route_db);
                    break;
                }

                case FPP_ACTION_UPDATE:
                {
                    /*  Not supported yet */
                    NXP_LOG_DEBUG("FPP_CMD_IP_ROUTE: FPP_ACTION_UPDATE not supported (yet)\n");
                    *fci_ret = FPP_ERR_UNKNOWN_COMMAND;
                    break;
                }

                case FPP_ACTION_QUERY:
                {
                    rt_entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
                    if (NULL == rt_entry)
                    {
                        ret = EOK;
                        *fci_ret = FPP_ERR_RT_ENTRY_NOT_FOUND;
                        break;
                    }
                }/* FALLTHRU */
                /* no break */

                case FPP_ACTION_QUERY_CONT:
                {
                    ret = routes_cmd_query_cont(fci_ret, reply_buf, reply_len, rt_entry);
                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_IP_ROUTE: Unknown action received: 0x%x\n", reply_buf->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Remove single route, inform clients, resolve dependencies
 * @param[in]   route The route to be removed
 * @note        Function is only called within the FCI worker thread context.
 * @note        Must run with route DB protected against concurrent accesses.
 */
errno_t fci_routes_drop_one(fci_rt_db_entry_t *route)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_msg_t msg;
    fpp_rt_cmd_t *rt_cmd = NULL;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == route)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(&msg, 0, sizeof(fci_msg_t));
        msg.type = FCI_MSG_CMD;
        msg.msg_cmd.code = FPP_CMD_IP_ROUTE;

        rt_cmd = (fpp_rt_cmd_t *)msg.msg_cmd.payload;
        rt_cmd->action = FPP_ACTION_REMOVED;

        /*  Inform client about the entry is being removed */
        if (NULL != route->refptr)
        {
            rt_cmd->id = route->id;

            ret = fci_core_client_send((fci_core_client_t *)route->refptr, &msg, NULL);
            if (EOK != ret)
            {
                NXP_LOG_WARNING("Could not notify FCI client\n");
            }
        }

        NXP_LOG_DEBUG("Removing route with ID %d\n", (int_t)oal_ntohl(route->id));

        /*  Remove all associated connections */
        fci_routes_remove_related_connections(route);

        /*  Remove the route */
        ret = fci_rt_db_remove(&fci_context->route_db, route);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Can't remove route: %d\n", ret);
        }
    }
    return ret;
}

/**
 * @brief       Remove all routes, inform clients, resolve dependencies
 * @note        Function is only called within the FCI worker thread context.
 * @note        Must run with route DB protected against concurrent accesses.
 */
void fci_routes_drop_all(void)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_rt_db_entry_t *entry = NULL;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_DEBUG("Removing all routes\n");

        entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
        while (NULL != entry)
        {
            ret = fci_routes_drop_one(entry);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Couldn't properly drop a route: %d\n", ret);
            }

            entry = fci_rt_db_get_next(&fci_context->route_db);
        }
    }
}

/**
 * @brief       Remove all IPv4 routes, inform clients, resolve dependencies
 * @note        Function is only called within the FCI worker thread context.
 * @note        Must run with route DB protected against concurrent accesses.
 */
void fci_routes_drop_all_ipv4(void)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_rt_db_entry_t *entry = NULL;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_DEBUG("Removing all IPv4 routes\n");

        entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
        while (NULL != entry)
        {
            if (entry->dst_ip.is_ipv4)
            {
                ret = fci_routes_drop_one(entry);
                if (EOK != ret)
                {
                    NXP_LOG_DEBUG("Couldn't properly drop a route: %d\n", ret);
                }
            }

            entry = fci_rt_db_get_next(&fci_context->route_db);
        }
    }
}

/**
 * @brief       Remove all IPv6 routes, inform clients, resolve dependencies
 * @note        Function is only called within the FCI worker thread context.
 * @note        Must run with route DB protected against concurrent accesses.
 */
void fci_routes_drop_all_ipv6(void)
{
    fci_t *fci_context = (fci_t *)&context;
    fci_rt_db_entry_t *entry = NULL;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_DEBUG("Removing all IPv6 routes\n");

        entry = fci_rt_db_get_first(&fci_context->route_db, RT_DB_CRIT_ALL, NULL);
        while (NULL != entry)
        {
            if (!entry->dst_ip.is_ipv4)
            {
                ret = fci_routes_drop_one(entry);
                if (EOK != ret)
                {
                    NXP_LOG_DEBUG("Couldn't properly drop a route: %d\n", ret);
                }
            }

            entry = fci_rt_db_get_next(&fci_context->route_db);
        }
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_RTABLE_ENABLE */
#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */
/** @}*/


===== 文件 [121/185]: src\fci_rt_db.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_FCI
 * @{
 *
 * @file        fci_rt_db.c
 * @brief       Route database
 * @details     Route database is intended to store IP routes and provide
 *              functions to select or remove particular entries.
 *
 * @warning     All API calls related to a single DB instance must be protected
 *              from being preempted by another API calls related to the same
 *              DB instance.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "isa.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE
#ifdef PFE_CFG_RTABLE_ENABLE
#include "fci_rt_db.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static bool_t fci_rt_db_match_criterion(fci_rt_db_t *db, const fci_rt_db_entry_t *entry);
#if defined(PFE_CFG_NULL_ARG_CHECK)
static bool_t rt_db_null_arg_check(fci_rt_db_t *db, fci_rt_db_get_criterion_t crit, const void *arg);


/**
 * @brief       Auxiliary function fur fci_rt_db_get_first() to check for NULL argument
 */
static bool_t rt_db_null_arg_check(fci_rt_db_t *db, fci_rt_db_get_criterion_t crit, const void *arg)
{
    bool_t ret_value = FALSE;


    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_value = TRUE;
    }
    else if (unlikely((RT_DB_CRIT_ALL != crit) && (NULL_PTR == arg)))
    {
        /*  All criterions except RT_DB_CRIT_ALL require non-NULL argument */
        NXP_LOG_ERROR("NULL argument received\n");
        ret_value = TRUE;
    }
    else
    {
        ret_value = FALSE;
    }

    return ret_value;
}
#endif /* PFE_CFG_NULL_ARG_CHECK */

/**
 * @brief       Match entry with latest criterion provided via fci_rt_db_get_first()
 * @param[in]   db The route DB instance
 * @param[in]   entry The entry to be matched
 * @retval      True Entry matches the criterion
 * @retval      False Entry does not match the criterion
 */
static bool_t fci_rt_db_match_criterion(fci_rt_db_t *db, const fci_rt_db_entry_t *entry)
{
    bool_t match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == db) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (db->cur_crit)
        {
            case RT_DB_CRIT_ALL:
            {
                match = TRUE;
                break;
            }

            case RT_DB_CRIT_BY_IF:
            {
                match = (entry->iface == db->cur_crit_arg.iface);
                break;
            }

            case RT_DB_CRIT_BY_IF_NAME:
            {
                match = (0 == autolibc_strcmp(db->cur_crit_arg.outif_name, pfe_phy_if_get_name(entry->iface)));
                break;
            }

            case RT_DB_CRIT_BY_IP:
            {
                match = (0 == autolibc_memcmp(&db->cur_crit_arg.dst_ip, &entry->dst_ip, sizeof(pfe_ip_addr_t)));
                break;
            }

            case RT_DB_CRIT_BY_MAC:
            {
                match = (0 == autolibc_memcmp(&db->cur_crit_arg.dst_mac, &entry->dst_mac, sizeof(pfe_mac_addr_t)));
                break;
            }

            case RT_DB_CRIT_BY_ID:
            {
                match = (db->cur_crit_arg.id == entry->id);
                break;
            }

            default:
            {
                NXP_LOG_WARNING("Unknown criterion\n");
                match = FALSE;
                break;
            }
        }
    }
    return match;
}

/**
 * @brief       Initialize DB
 * @param[in]   db The route DB instance
 */
void fci_rt_db_init(fci_rt_db_t *db)
{
    pfe_isa_definition_t *rtdb_isa_def;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* initialize FCI route database entries storage ISA properties definition */
        rtdb_isa_def = &db->rtdb_entries_isa_def;
        rtdb_isa_def->item_count = FCI_CFG_RTDB_ENTRIES_CAPACITY;
        rtdb_isa_def->item_size = (uint32)sizeof(fci_rt_db_entry_t);
        rtdb_isa_def->flags.ordered = ISA_FLAG_STRICT_ORDER;
        rtdb_isa_def->item_indexes = db->rtdb_entries_index;
        rtdb_isa_def->items = db->rtdb_entries_pool;

        /* Initialize FCI route database entries ISA container */
        isa_init(&db->rtdb_entries, rtdb_isa_def);
    }
}

/**
 * @brief       Add a route to DB
 * @param[in]   db The route DB instance
 * @param[in]   src_mac Source MAC address
 * @param[in]   dst_mac Destination MAC address
 * @param[in]   iface Name of the output interface
 * @param[in]   id The route ID
 * @param[in]   refptr Reference pointer to be bound with entry
 * @param[in]   overwrite If true then if route exists, it is updated
 * @retval      EOK Success
 * @retval      ENOMEM Memory allocation failed
 * @retval      EPERM Attempt to insert already existing entry without 'overwrite' set to 'true'
 * @retval      EINVAL Input arguments check fail
 */
errno_t fci_rt_db_add(fci_rt_db_t *db,  pfe_ip_addr_t *dst_ip,
                    pfe_mac_addr_t *src_mac, pfe_mac_addr_t *dst_mac,
                    pfe_phy_if_t *iface, uint32 id, void *refptr, bool_t overwrite)
{
    fci_rt_db_entry_t *new_entry;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == dst_ip) || (NULL_PTR == src_mac) || (NULL_PTR == dst_mac) || (NULL_PTR == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Check duplicates by route ID */
        new_entry = fci_rt_db_get_first(db, RT_DB_CRIT_BY_ID, (void *)&id);
        if (NULL_PTR == new_entry)
        {
            new_entry = (fci_rt_db_entry_t *)isa_reserve(&db->rtdb_entries);
            if (NULL_PTR == new_entry)
            {
                NXP_LOG_ERROR("FCI RTDB ISA exhausted, no more entries left\n");
                ret = ENOMEM;
            }
            else
            {
                (void)autolibc_memset(new_entry, 0, sizeof(fci_rt_db_entry_t));
            }
        }
        else if (FALSE == overwrite)
        {
            ret = EPERM;
        }
        else
        {
            /*Do nothing - Avoid MISRA rule 15.7 */
        }

        if(EOK == ret)
        {
            /*  Store values */
            (void)autolibc_memcpy(&new_entry->dst_ip, dst_ip, sizeof(pfe_ip_addr_t));
            (void)autolibc_memcpy(&new_entry->src_mac, src_mac, sizeof(pfe_mac_addr_t));
            (void)autolibc_memcpy(&new_entry->dst_mac, dst_mac, sizeof(pfe_mac_addr_t));
            new_entry->iface = iface;
            new_entry->id = id;
            new_entry->mtu = 0; /* Not supported yet */
            new_entry->refptr = refptr;
        }
    }
    return ret;
}

/**
 * @brief       Remove entry from DB
 * @param[in]   db The route DB instance
 * @param[in]   entry Entry to be removed. If the call is successful the entry
 *                    becomes invalid and shall not be accessed.
 * @return      EOK if success, error code otherwise
 */
errno_t fci_rt_db_remove(fci_rt_db_t *db, fci_rt_db_entry_t *entry)
{
    sint32 entry_subscript;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry_subscript = isa_release(&db->rtdb_entries, entry);
        if ((entry_subscript >= 0) && (entry_subscript < (sint32)db->next_item))
        {
            /*  Decrease the iterator so we can call destroy() between get_first()
                and get_next() calls. */
            db->next_item--;
        }
    }

    return ret;
}

/**
 * @brief       Get first record from the DB matching given criterion
 * @details     Intended to be used with fci_rt_db_get_next
 * @param[in]   db The route DB instance
 * @param[in]   crit Get criterion
 * @param[in]   art Pointer to criterion argument
 * @return      The entry or NULL if not found
 * @warning     The returned entry must not be accessed after fci_rt_db_remove(entry)
 *              or fci_rt_db_drop_all() has been called.
 */
fci_rt_db_entry_t *fci_rt_db_get_first(fci_rt_db_t *db, fci_rt_db_get_criterion_t crit, const void *arg)
{
    fci_rt_db_entry_t *entry = NULL_PTR;
    bool_t is_unknown_crit = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (likely(rt_db_null_arg_check(db, crit, arg) == FALSE))
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remember criterion and argument for possible subsequent fci_rt_db_get_next() calls */
        db->cur_crit = crit;
        switch (db->cur_crit)
        {
            case RT_DB_CRIT_ALL:
            {
                break;
            }

            case RT_DB_CRIT_BY_IF:
            {
                db->cur_crit_arg.iface = (const pfe_phy_if_t *)arg;
                break;
            }

            case RT_DB_CRIT_BY_IF_NAME:
            {
                (void)autolibc_memset(db->cur_crit_arg.outif_name, 0, sizeof(db->cur_crit_arg.outif_name));
                (void)autolibc_strncpy(db->cur_crit_arg.outif_name, arg, sizeof(db->cur_crit_arg.outif_name)-1U);
                break;
            }

            case RT_DB_CRIT_BY_IP:
            {
                (void)autolibc_memcpy(&db->cur_crit_arg.dst_ip, arg, sizeof(db->cur_crit_arg.dst_ip));
                break;
            }

            case RT_DB_CRIT_BY_MAC:
            {
                (void)autolibc_memcpy(&db->cur_crit_arg.dst_mac, arg, sizeof(db->cur_crit_arg.dst_mac));
                break;
            }

            case RT_DB_CRIT_BY_ID:
            {
                (void)autolibc_memcpy(&db->cur_crit_arg.id, arg, sizeof(db->cur_crit_arg.id));
                break;
            }

            default:
            {
                NXP_LOG_WARNING("Unknown criterion\n");
                is_unknown_crit = TRUE;
                break;
            }
        }

        if(TRUE != is_unknown_crit)
        {
            db->next_item = 0U;
            entry = fci_rt_db_get_next(db);
        }
    }

    return entry;
}

/**
 * @brief       Get next record from the DB
 * @details     Intended to be used with fci_rt_db_get_first.
 * @param[in]   db The route DB instance
 * @return      The entry or NULL if not found
 * @warning     The returned entry must not be accessed after fci_rt_db_remove(entry)
 *              or fci_rt_db_drop_all() has been called.
 */
fci_rt_db_entry_t *fci_rt_db_get_next(fci_rt_db_t *db)
{
    fci_rt_db_entry_t *entry;
    bool_t match = FALSE;
    pfe_isa_t *isa;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        entry = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        isa = &db->rtdb_entries;

        /* traverse FCI route database */
        while (db->next_item < isa->occupied_items_count)
        {
            entry = (fci_rt_db_entry_t *)isa_item(isa, db->next_item);

            /* Remember current item to know where to start later */
            db->next_item++;

            if (NULL_PTR != entry)
            {
                match = fci_rt_db_match_criterion(db, entry);
                if (TRUE == match)
                {
                    break;
                }
            }
        }

        if (FALSE == match)
        {
            entry = NULL_PTR;
        }
    }

    return entry;
}

/**
 * @brief       Remove all entries
 * @param[in]   db The route DB instance
 * @return      EOK if success, error code otherwise
 */
errno_t fci_rt_db_drop_all(fci_rt_db_t *db)
{
    uint32 index;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for(index = db->rtdb_entries.occupied_items_count; index > 0U; index--)
        {
            (void)isa_release_subscript(&db->rtdb_entries, index - 1U);
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_RTABLE_ENABLE */
#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */
/** @}*/


===== 文件 [122/185]: src\fci_timer_owner.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "libfci.h"
#include "fpp.h"
#include "fpp_ext.h"
#include "pfe_platform.h"
#include "fci_internal.h"
#include "fci.h"

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_FCI_ENABLE

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


static pfe_phy_if_t *fci_get_phy_if_by_name(char_t *name);
#if defined(PFE_CFG_NULL_ARG_CHECK)
static errno_t timer_owner_null_arg_check(fci_msg_t *msg, uint16 *fci_ret, fpp_timer_cmd_t *reply_buf, uint32 *reply_len);


/**
 * @brief       Auxiliary function fur to check for NULL argument in fci_timer_owner lock and unlock cmd functions
 */
static errno_t timer_owner_null_arg_check(fci_msg_t *msg, uint16 *fci_ret, fpp_timer_cmd_t *reply_buf, uint32 *reply_len)
{
    errno_t ret = EOK;
    fci_t *fci_context = (fci_t *)&context;

    if (unlikely((NULL == msg) || (NULL == fci_ret) || (NULL == reply_buf) || (NULL == reply_len)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(FALSE == fci_context->fci_initialized))
    {
        NXP_LOG_ERROR("Context not initialized\n");
        ret = EPERM;
    }
    else
    {
        ret = EOK;
    }

    return ret;
}
#endif /* PFE_CFG_NULL_ARG_CHECK */

/**
 * @brief           Get physical interface by name
 * @param[in]       name The name of the physical interface
 * @return          the physical interface phy_if
 */
static pfe_phy_if_t *fci_get_phy_if_by_name(char_t *name)
{
    fci_t *fci_context = (fci_t *)&context;
    pfe_if_db_entry_t *entry = NULL;
    pfe_phy_if_t *phy_if = NULL;
    errno_t ret;
    uint32 sid = 0U;

    ret = pfe_if_db_lock(&sid);
    if (EOK != ret)
    {
        NXP_LOG_WARNING("Could not lock interface DB: %d\n", ret);
    }
    else
    {
        ret = pfe_if_db_get_first(fci_context->phy_if_db, sid, IF_DB_CRIT_BY_NAME, name, &entry);
        if (EOK != ret)
        {
            NXP_LOG_WARNING("Interface DB query failed: %d\n", ret);
        }

        if(NULL != entry)
        {
            phy_if = pfe_if_db_entry_get_phy_if(entry);
        }
    }
    
    ret = pfe_if_db_unlock(sid);
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Interface DB unlock failed: %d\n", ret);
    }

    return phy_if;
}

/**
 * @brief           Acquire FCI timer ownership
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_timer_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
errno_t fci_timer_owner_lock_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_timer_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_timer_cmd_t *timer_cmd;
    pfe_phy_if_t *phy_if = NULL;
    errno_t ret = EOK;
    bool_t has_owner = FALSE;
    pfe_drv_id_t cur_owner = PFE_PHY_IF_ID_INVALID;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    ret = timer_owner_null_arg_check(msg, fci_ret, reply_buf, reply_len);
    if(likely(EOK == ret))
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_timer_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_timer_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_timer_cmd_t));
            timer_cmd = (fpp_timer_cmd_t *)msg->msg_cmd.payload;

            switch(timer_cmd->action)
            {
                case FPP_ACTION_UPDATE:
                {
                    *fci_ret = FPP_ERR_OK;

                    /*  Get physical interface ID */
                    phy_if = fci_get_phy_if_by_name(timer_cmd->if_name);
                    if (NULL == phy_if)
                    {
                        /* FCI command requested nonexistent entity. Respond with FCI error code. */
                        NXP_LOG_DEBUG("No interface '%s'\n", timer_cmd->if_name);
                        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
                        ret = ENOENT;
                        break;
                    }
                    else if (PFE_PHY_IF_EMAC != pfe_phy_if_get_type(phy_if))
                    {
                        /* FCI command requested unfulfillable action. Respond with FCI error code. */
                        *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
                        ret = EOK;
                        break;
                    }
                    else
                    {
                        ; /* MISRA */
                    }
                    
                    /* Set the sender is timer owner of EMAC */
                    ret = pfe_emac_set_timer_ownership(pfe_phy_if_get_emac(phy_if), (pfe_drv_id_t)msg->msg_cmd.sender);
                    if (EOK == ret)
                    {
                        *fci_ret = FPP_ERR_OK;
                    }
                    else
                    {
                        /* Check if the sender was owner of EMAC */
                        ret = pfe_emac_check_timer_ownership(pfe_phy_if_get_emac(phy_if), &has_owner, &cur_owner);
                        if ((EOK == ret) && (TRUE == has_owner))
                        {
                            if (msg->msg_cmd.sender == cur_owner)
                            {
                                *fci_ret = FPP_ERR_OK;
                            }
                            else
                            {
                                *fci_ret = FPP_ERR_TIMER_ALREADY_LOCKED;
                                NXP_LOG_WARNING("The EMAC is locked by another driver instance: %d\n", cur_owner);
                            }
                        }
                        else
                        {
                            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                        }
                    }

                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_TIMER_LOCK: Unknown action received: 0x%x\n", timer_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           Release FCI timer ownership
 * @param[in]       msg FCI message containing the command
 * @param[out]      fci_ret FCI command return value
 * @param[out]      reply_buf Pointer to a buffer where function will construct command reply (fpp_timer_cmd_t)
 * @param[in,out]   reply_len Maximum reply buffer size on input, real reply size on output (in bytes)
 * @return          EOK if success, error code otherwise
 */
errno_t fci_timer_owner_unlock_cmd(fci_msg_t *msg, uint16 *fci_ret, fpp_timer_cmd_t *reply_buf, uint32 *reply_len)
{
    fpp_timer_cmd_t *timer_cmd;
    pfe_phy_if_t *phy_if = NULL;
    errno_t ret = EOK;
    bool_t has_owner = FALSE;
    pfe_drv_id_t cur_owner = PFE_PHY_IF_ID_INVALID;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    ret = timer_owner_null_arg_check(msg, fci_ret, reply_buf, reply_len);
    if(likely(EOK == ret))
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (*reply_len < sizeof(fpp_timer_cmd_t))
        {
            NXP_LOG_WARNING("Buffer length does not match expected value (fpp_timer_cmd_t)\n");
            ret = EINVAL;
        }
        else
        {
            /*  No data written to reply buffer (yet) */
            *reply_len = 0U;
            /*  Initialize the reply buffer */
            (void)autolibc_memset(reply_buf, 0, sizeof(fpp_timer_cmd_t));
            timer_cmd = (fpp_timer_cmd_t *)msg->msg_cmd.payload;

            switch(timer_cmd->action)
            {
                case FPP_ACTION_UPDATE:
                {
                    *fci_ret = FPP_ERR_OK;

                    /*  Get physical interface ID */
                    phy_if = fci_get_phy_if_by_name(timer_cmd->if_name);
                    if (NULL == phy_if)
                    {
                        /* FCI command requested nonexistent entity. Respond with FCI error code. */
                        *fci_ret = FPP_ERR_IF_ENTRY_NOT_FOUND;
                        ret = ENOENT;
                        break;
                    }
                    else if (PFE_PHY_IF_EMAC != pfe_phy_if_get_type(phy_if))
                    {
                        /* FCI command requested unfulfillable action. Respond with FCI error code. */
                        *fci_ret = FPP_ERR_IF_NOT_SUPPORTED;
                        ret = EOK;
                        break;
                    }
                    else
                    {
                        ; /* MISRA */
                    }

                    /* Set the sender is not timer owner of EMAC */
                    ret = pfe_emac_clear_timer_ownership(pfe_phy_if_get_emac(phy_if), (pfe_drv_id_t)msg->msg_cmd.sender);
                    if (EOK == ret)
                    {
                        *fci_ret = FPP_ERR_OK;
                    }
                    else
                    {
                        /* Get timer ownership status and check if the sender is not the current owner of EMAC */
                        ret = pfe_emac_check_timer_ownership(pfe_phy_if_get_emac(phy_if), &has_owner, &cur_owner);
                        if ((EOK == ret) && (TRUE == has_owner))
                        {
                            if (msg->msg_cmd.sender != cur_owner)
                            {
                                *fci_ret = FPP_ERR_TIMER_NOT_OWNER;
                            }
                            else
                            {
                                *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                            }
                        }
                        else
                        {
                            *fci_ret = FPP_ERR_INTERNAL_FAILURE;
                        }
                    }

                    break;
                }

                default:
                {
                    NXP_LOG_WARNING("FPP_CMD_TIMER_UNLOCK: Unknown action received: 0x%x\n", timer_cmd->action);
                    *fci_ret = FPP_ERR_UNKNOWN_ACTION;
                    break;
                }
            }
        }
    }

    return ret;
}
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [123/185]: src\fifo.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "oal_sync.h"
#include "hal.h"
#include "fifo.h"

#define is_power_of_2(n) ((n) && !((n) & ((n) - 1U)))

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================*/
__attribute__((hot)) errno_t fifo_get_fill_level(const fifo_t *const fifo, uint32 *fill_level)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == fifo) || (NULL == fill_level)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        PfeDevAssert(fifo->write >= fifo->read);
        *fill_level = (fifo->write - fifo->read);
        ret = EOK;
    }
    return ret;
}

/*==================================================================================================*/
__attribute__((hot)) errno_t fifo_get_free_space(const fifo_t *const fifo, uint32 *free_space)
{
    uint32 ret = 0U;
    errno_t err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == fifo) || (NULL == free_space)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        err = fifo_get_fill_level(fifo, &ret);
        PfeDevAssert(fifo->depth >= ret);
        *free_space = fifo->depth - ret;
    }
    return err;
}

/*==================================================================================================*/
__attribute__((cold)) fifo_t * fifo_create(const uint32 depth, fifo_t *fifo, void **data)
{
    fifo_t *tmp_fifo = fifo;

    if (!is_power_of_2(depth) || (depth > 0x7FFFFFFFU))
    {
        tmp_fifo = NULL;
    }
    else
    {
        tmp_fifo->read = 0U;
        tmp_fifo->write = 0U;
        tmp_fifo->depth = depth;
        tmp_fifo->depth_mask = depth - 1U;

        tmp_fifo->data = data;
        if (unlikely(NULL == tmp_fifo->data))
        {
            tmp_fifo = NULL;
        }
    }

    return tmp_fifo;
}

/*==================================================================================================*/
__attribute__((cold)) void fifo_destroy(fifo_t *fifo)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fifo))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fifo->read = 0U;
        fifo->write = 0U;
        fifo->depth = 0U;
        fifo->depth_mask = 0U;
        fifo->protected = FALSE;
        fifo->data = NULL;
    }
}

/*==================================================================================================*/
__attribute__((cold)) void fifo_clear(fifo_t *const fifo)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fifo))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    if (NULL != fifo)
    {
        fifo->read = 0U;
        fifo->write = fifo->depth;
    }
}

/*==================================================================================================*/
__attribute__((hot)) void * fifo_peek(const fifo_t * const fifo, uint32 num)
{
    volatile void *ret = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fifo))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (likely(num < fifo->depth))
        {
            ret = fifo->data[num];
        }
    }
    return (void *)ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [124/185]: src\isa.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2022-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @file        isa.c
 * @brief       Item Storage Array (ISA)
 * @details     Possible improvements:
 *              1) occupied items can be sorted upon desired criteria to improve find complexity to O(logN)
 *              2) multiple indexes can be created to support various criteria in find implementations
 */


/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440


#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "isa.h"
#include "autolibc.h" /* memcpy */

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

/**
 * @brief Acquire a pointer to an item entry
 * @param props ISA properties definition
 * @param index_subscript entry in occupied items_index
 * @return non NULL item pointer referenced by index_subscript
 * @note Internal helper function
 */
static inline void *isa_item_internal(const pfe_isa_definition_t *props, uint32 index_subscript)
{
    uint8 *items;
    const uint32 item_index = (uint32)(((uint64)props->item_size * props->item_indexes[index_subscript]) & UINT32_MAX);

    items = (uint8*)props->items;

    return &items[item_index];
}


/**
 * @brief Initialize index array to empty state
 * @param props ISA properties definition
 */
static void isa_init_index(const pfe_isa_definition_t *props)
{
    uint32 ii;
    pfe_isa_index_t *item_indexes = props->item_indexes;
    for(ii = 0U; ii < props->item_count; ii++)
    {
        item_indexes[ii] = (pfe_isa_index_t)ii;
    }
}

/**
 * @brief Initialize the ISA
 * @details The ISA after initialization is in empty state
 * @param isa item storage array descriptor
 * @param props ISA properties definition
 */
void isa_init(pfe_isa_t *isa, const pfe_isa_definition_t *props)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely((NULL_PTR == isa) || (NULL_PTR == props) || (NULL_PTR == props->item_indexes)
        || (NULL_PTR == props->items)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* currently no items are reserved */
        isa->occupied_items_count = 0U;
        /* set ISA definition */
        isa->props = props;

        /* now all items are vacant */
        isa_init_index(props);
    }
}

/**
 * @brief Restores empty state of the ISA
 * @param isa item storage array descriptor
 */
void isa_clear(pfe_isa_t *isa)
{
    const pfe_isa_definition_t *props;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == isa))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        props = isa->props;

        /* currently no items are reserved */
        isa->occupied_items_count = 0U;

        /* now all items are vacant */
        isa_init_index(props);
    }
}

/**
 * @brief Acquire pointer to an item of the ISA
 * @param isa item storage array descriptor
 * @param index_subscript entry in occupied items_index
 * @retval non NULL pointer to item at index_subscript
 * @retval NULL for index_subscript >= occupied_items_count
 */
void *isa_item(const pfe_isa_t *isa, uint32 index_subscript)
{
    void *item = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == isa))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(index_subscript < isa->occupied_items_count)
        {
            item = isa_item_internal(isa->props, index_subscript);
        }
    }

    return item;
}

/**
 * @brief Reserve single item from ISA
 * @details Reserved item becomes occupied and the occupied_items_count is increased by 1.
 * @param isa item storage array descriptor
 * @retval non NULL pointer of successfuly reserved item
 * @retval NULL cannot reserve any item
 */
void *isa_reserve(pfe_isa_t *isa)
{
    void *item = NULL;
    const pfe_isa_definition_t *props;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == isa))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        props = isa->props;
        if(isa->occupied_items_count < props->item_count)
        {
            item = isa_item_internal(props, isa->occupied_items_count);
            isa->occupied_items_count++;
        }
    }

    return item;
}

/**
 * @brief Release single reserved item in ISA
 * @details Released item becomes vacant ad the occupied_items_count is decreased by 1.
 * @param isa item storage array descriptor
 * @param index_subscript value in range <0, occupied_items_count)
 * @retval TRUE desired item was released
 * @retval FALSE desired item was not found in reserved items
 */
bool_t isa_release_subscript(pfe_isa_t *isa, uint32 index_subscript)
{
    pfe_isa_index_t liberated_index_value;
    pfe_isa_index_t *remove_index_ptr;
    pfe_isa_index_t *last_index_ptr;
    bool_t result = FALSE;
    const pfe_isa_definition_t *props;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == isa))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(index_subscript < isa->occupied_items_count)
        {
            /* peform internal item data cleanup */
            props = isa->props;

            /* vacate the item index */
            isa->occupied_items_count--;
            if(index_subscript < isa->occupied_items_count)
            {
                remove_index_ptr = &props->item_indexes[index_subscript];
                last_index_ptr = &props->item_indexes[isa->occupied_items_count];
                /* preserve liberated index value */
                liberated_index_value = *remove_index_ptr;
                if(props->flags.ordered == ISA_FLAG_STRICT_ORDER)
                {
                    /* shift index values in occupied part located after index_subscript
                     * in way that 1st succeeding is overwriting the liberated one */
                    (void)autolibc_memcpy(remove_index_ptr, &remove_index_ptr[1],
                            (isa->occupied_items_count - index_subscript) * sizeof(pfe_isa_index_t));
                }
                else
                {
                    /* ISA_FLAG_ANY_ORDER
                     * get last occupied index value and store it at place pointed by index_subscript */
                    *remove_index_ptr = *last_index_ptr;
                }
                /* store liberated index value after last occupied one */
                *last_index_ptr = liberated_index_value;
            }
            result = TRUE;
        }
    }

    return result;
}

/**
 * @brief Release single reserved item in ISA
 * @details Released item becomes vacant and the occupied_items_count is decreased by 1.
 * @param isa item storage array descriptor
 * @param item pointer to item to be liberated in the ISA
 * @retval >= 0 index subscript of the released item
 * @retval ISA_ITEM_NOT_FOUND if desired item was not found in the ISA
 */
sint32 isa_release(pfe_isa_t *isa, const void *item)
{
    sint32 index_subscript = ISA_ITEM_NOT_FOUND;
    uint32 ii;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely((NULL_PTR == isa) || (NULL_PTR == item)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for(ii = 0U; ii < isa->occupied_items_count; ii++)
        {
            if(item == isa_item_internal(isa->props, ii))
            {
                if(TRUE == isa_release_subscript(isa, ii))
                {
                    index_subscript = (sint32)ii;
                }
                break;
            }
        }
    }

    return index_subscript;
}

/**
 * @brief Checks if ISA contains any items
 * @param isa item storage array descriptor
 * @return TRUE if ISA is empty otherwise FALSE
 */
bool_t isa_isempty(const pfe_isa_t *isa)
{
    bool_t result;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == isa))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        result = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        result = (isa->occupied_items_count == 0U);
    }

    return result;
}

/**
 * @brief Get count of currently occupied items of ISA
 * @param isa item storage array descriptor
 * @return >= 0 number of occupied entries in the ISA
 */
uint32 isa_occupiedcount(const pfe_isa_t *isa)
{
    uint32 result;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if(unlikely(NULL_PTR == isa))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        result = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        result = isa->occupied_items_count;
    }

    return result;
}

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */


===== 文件 [125/185]: src\libfci_autosar.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright (C) 2007 Mindspeed Technologies, Inc.
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "pfe_platform_cfg.h"
#include "fpp.h"
#include "fci_msg.h"
#include "libfci.h"
#include "fci.h"
#include "fci_internal.h"
#include "oal.h"

#ifdef PFE_CFG_FCI_ENABLE

#ifndef EOK
#define EOK 0
#endif

/*
* Debug macros
*/
#define FCILIB_PRINT
#define FCILIB_ERR    1
#define FCILIB_INIT   0
#define FCILIB_OPEN   1
#define FCILIB_CLOSE  1
#define FCILIB_WRITE  0
#define FCILIB_READ   0
#define FCILIB_DUMP   0
#define FCILIB_CATCH  0
#define FCILIB_REG_CB 0

#if (defined(FCILIB_PRINT) && defined(NXP_LOG_ENABLED))
#define FCILIB_PRINTF(type, ...) do {if(type) NXP_LOG_INFO(__VA_ARGS__);} while(0);
#else
#define FCILIB_PRINTF(type, ...) do {} while(0);
#endif

struct fci_client_tag
{
    fci_mcast_groups_t group;
    fci_cb_retval_t (*event_cb)(unsigned short fcode, unsigned short len, unsigned short *payload);
};

typedef struct
{
    const uint16 *cmd_buf;
    uint16 cmd_len;
    uint16 *rep_buf;
    uint16 *rep_len;
}fci_params;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static FCI_CLIENT fci_client;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
static bool_t fci_client_created = FALSE;
#define ETH_43_PFE_STOP_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static FCI_CLIENT *fci_create_client(fci_mcast_groups_t group);
static sint32 fci_destroy_client(FCI_CLIENT *client);
static sint32 fci_command(FCI_CLIENT *client, uint16 fcode, fci_params *cmd_rep);

/****************************** PUBLICS FUNCTIONS ********************************/

/**
 * @brief     Create the FCI client
 * @param[in] client_type Type of FCI client
 * @param[in] group       Group of FCI client
 * @retval    NULL if client not created
 * @retval    non NULL pointer to created FCI client
 * @note      Only one client of identical type can be created !
 */
FCI_CLIENT *fci_open(fci_client_type_t client_type, fci_mcast_groups_t group)
{
    FCI_CLIENT *new_client = NULL_PTR;

    /* Create client according to the requested socket type */
    switch(client_type)
    {
        case FCI_CLIENT_DEFAULT:
        {
            FCILIB_PRINTF(FCILIB_OPEN, "fci_open:%d client type FCILIB_FF_CLIENT with group %d\n", __LINE__, group);
            new_client = fci_create_client(group);
            break;
        }

        default:
        {
            FCILIB_PRINTF(FCILIB_ERR, "LIB_FCI: fci_open():%d client type %d not supported\n", __LINE__, client_type);
            new_client = NULL;
        }

        break;
    }

    /* Unique ID used to identify this client */
    return new_client;
}

/*==================================================================================================*/
int fci_register_cb(FCI_CLIENT *client, fci_cb_retval_t (*event_cb)(unsigned short fcode, unsigned short len, unsigned short *payload))
{
    sint32 ret = -EINVAL;

    FCILIB_PRINTF(FCILIB_REG_CB, "fci_register_cb()\n")
    if (client != NULL)
    {
        client->event_cb = event_cb;
        if (NULL != event_cb)
        {
            context.is_some_client = TRUE;
            fci_hm_send_events();
        }
        else
        {
            context.is_some_client = FALSE;
        }
        ret = EOK;
    }

    return ret;
}

/*==================================================================================================*/
int fci_close(FCI_CLIENT *client)
{
    sint32 rc;
    sint32 ret = 0;

    FCILIB_PRINTF(FCILIB_CLOSE, "fci_close()\n");

    /* Unregister FCI client */
    if (client == NULL)
    {
        ret = -1;
    }
    else
    {
        rc = fci_register_cb(client, NULL);
        if(EOK != rc)
        {
            FCILIB_PRINTF(FCILIB_ERR, "fci_close: fci_register_cb failed with %d!\n", (int_t)rc);
        }
        rc = fci_destroy_client(client);
        if (rc < 0)
        {
            FCILIB_PRINTF(FCILIB_ERR, "fci_close: fci_destroy_client failed !\n");
            ret = rc;
        }
    }
    return ret;
}

/*==================================================================================================*/
int fci_cmd(FCI_CLIENT *client, unsigned short fcode, unsigned short *cmd_buf, unsigned short cmd_len, unsigned short *rep_buf, unsigned short *rep_len)
{
    FCILIB_PRINTF(FCILIB_WRITE, "fci_cmd: send fcode %#x length %d\n", fcode, cmd_len);

    fci_params cmd_rep = { .cmd_buf = cmd_buf, .cmd_len = cmd_len, .rep_buf = rep_buf, .rep_len = rep_len};
    return fci_command(client, fcode, &cmd_rep);
}

/*==================================================================================================*/
int fci_write(FCI_CLIENT *client, unsigned short fcode, unsigned short cmd_len, unsigned short *cmd_buf)
{
    FCILIB_PRINTF(FCILIB_WRITE, "fci_write: send fcode %#x length %d\n", fcode, cmd_len);

    fci_params cmd_rep = { .cmd_buf = cmd_buf, .cmd_len = cmd_len, .rep_buf = NULL, .rep_len = NULL};
    return fci_command(client, fcode, &cmd_rep);
}

/*==================================================================================================*/
int fci_query(FCI_CLIENT *client, unsigned short fcode, unsigned short cmd_len, unsigned short *cmd_buf, unsigned short *rep_len, unsigned short *rep_buf)
{
    FCILIB_PRINTF(FCILIB_WRITE, "fci_query: send fcode %#x length %d\n", fcode, cmd_len);

    fci_params cmd_rep = { .cmd_buf = cmd_buf, .cmd_len = cmd_len, .rep_buf = rep_buf, .rep_len = rep_len};
    return fci_command(client, fcode, &cmd_rep);
}

/*==================================================================================================*/
int fci_catch(FCI_CLIENT *client)
{
    fci_msg_t msg;
    sint32 ret = EOK;
    bool_t shall_quit = FALSE;
    fci_cb_retval_t cb_ret;

    while (FALSE == shall_quit)
    {
        /* Read message from kernel */
        ret = fci_core_client_get_msg(&msg);
        if (EOK != ret)
        {
            if (ENOENT == ret)
            {
                ret = EOK;
            }
            else
            {
                FCILIB_PRINTF(FCILIB_ERR, "fci_core_client_get_msg() failed: %d\n", (int_t)ret);
            }
            shall_quit = TRUE;
        }
        else
        {
            /* Message */
            FCILIB_PRINTF(FCILIB_CATCH," Received message payload: %s\n",(char*)msg.msg_cmd.payload);
            if ((FCI_MSG_CMD == msg.type) || (FCI_MSG_CORE_CLIENT_BROADCAST == msg.type))
            {
                /* Call registered callback */
                if (NULL != client->event_cb)
                {
                    cb_ret = client->event_cb((unsigned short)msg.msg_cmd.code,
                                              (unsigned short)msg.msg_cmd.length,
                                              (unsigned short *)msg.msg_cmd.payload);

                    if (FCI_CB_CONTINUE == cb_ret)
                    {
                        /* Continue */
                        ;
                    }
                    else
                    {
                        /* Terminate */
                        shall_quit = TRUE;
                    }
                }
            }
            else
            {
                FCILIB_PRINTF(FCILIB_ERR, "Unknown message received (type = 0x%x)\n", msg.type);
            }
        }
    }

    return ret;
}

/**
 * @brief       fci_fd: Not supported yet
 * @param[in]   client FCI client instance to be used
 * @return      Always -1 (failure) because the function is not supported.
 * @warning     Function shall not be used.
 */
int fci_fd(FCI_CLIENT *client)
{
    (void)*client;
    FCILIB_PRINTF(FCILIB_ERR, "LIBFCI: fci_fd() not implemented\n");
    return -1;
}

/****************************** PRIVATE FUNCTIONS ********************************/
static sint32 fci_command(FCI_CLIENT *client, uint16 fcode, fci_params *cmd_rep)
{
    fci_msg_t msg;
    fci_msg_t reply_msg;
    sint32 cmd_ret = EOK;
    sint32 ret;

    /* Make sure fci client is registered*/
    if (client == NULL)
    {
        FCILIB_PRINTF(FCILIB_ERR, "LIBFCI: Client is unregistered\n");
        ret = EINVAL;
    }
    else
    {
        (void)autolibc_memset(&msg, 0, sizeof(msg));
        (void)autolibc_memset(&reply_msg, 0, sizeof(reply_msg));

        msg.type = FCI_MSG_CMD;
        msg.msg_cmd.code = fcode;

        if (cmd_rep->cmd_len > 0U)
        {
            msg.msg_cmd.length = cmd_rep->cmd_len;
            (void)autolibc_memcpy(&msg.msg_cmd.payload, cmd_rep->cmd_buf, cmd_rep->cmd_len);
        }

        /* Local sender identification */
        msg.msg_cmd.sender = (uint32)PFE_CFG_LOCAL_IF;

        cmd_ret = fci_process_ipc_message(&msg, &reply_msg);

        if(cmd_ret != EOK)
        {
            /*  Command failure */
            FCILIB_PRINTF(FCILIB_ERR, "LIBFCI: Command failed with %d\n", (int_t)cmd_ret);
            ret = cmd_ret;
        }
        else
        {
            /*  Success, pass reply data (if any) and its length to user */
            if ((NULL != cmd_rep->rep_buf) && (NULL != cmd_rep->rep_len) && (4U <= reply_msg.msg_cmd.length))
            {
#if (TRUE == FCI_CFG_FORCE_LEGACY_API)
                (void)autolibc_memcpy(cmd_rep->rep_buf, reply_msg.msg_cmd.payload, reply_msg.msg_cmd.length);
                *cmd_rep->rep_len = reply_msg.msg_cmd.length;
#else
                (void)autolibc_memcpy(cmd_rep->rep_buf, (reply_msg.msg_cmd.payload + 4U), reply_msg.msg_cmd.length - 4U);
                *cmd_rep->rep_len = (uint16)(reply_msg.msg_cmd.length) - 4U;
#endif /* FCI_CFG_FORCE_LEGACY_API */
            }
            (void)autolibc_memcpy(&cmd_ret, reply_msg.msg_cmd.payload, sizeof(uint16));

            ret = cmd_ret;
        }
    }
    return ret;
}

/*==================================================================================================*/
static FCI_CLIENT *fci_create_client(fci_mcast_groups_t group)
{
    FCI_CLIENT *client;

    if (TRUE == fci_client_created)
    {
        FCILIB_PRINTF(FCILIB_ERR, "LIBFCI: fci_create_client() fci client already created\n");
        client = NULL_PTR;
    }
    else
    {
        fci_client_created = TRUE;
        fci_client.group = group;
        client = &fci_client;
    }

    return client;
}

/*==================================================================================================*/
static sint32 fci_destroy_client(FCI_CLIENT *client)
{
    (void)client;

    FCILIB_PRINTF(FCILIB_CLOSE, "fci_destroy_client()\n");
    if (TRUE == fci_client_created)
    {
        fci_client_created = FALSE;
        (void)autolibc_memset(&fci_client, 0, sizeof(fci_client));
    }

    return 0;
}
/*==================================================================================================*/

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_FCI_ENABLE */


===== 文件 [126/185]: src\nxp_snprintf.c =====
/**
 *  @file             nxp_snprintf.c
 *  @brief            Module serves to printing debug messages
 */
/*==================================================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright (c) 2014-2016 Freescale Semiconductor Inc.
 *  Copyright 2016-2018, 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
==================================================================================================*/
/*==================================================================================================
==================================================================================================*/

#ifdef __cplusplus
extern "C"{
#endif

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==================================================================================================
                                         INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "nxp_snprintf.h"

#if defined(NXP_LOG_ENABLED)

/*==================================================================================================
                                      FILE VERSION CHECKS
==================================================================================================*/

/*==================================================================================================
                                        LOCAL MACROS
==================================================================================================*/
#define FLAG_NONE                    0U
#define FLAG_MINUS                   1U  /* Left aligned position of - or + */
#define FLAG_PLUS                    2U  /* Add '+' or '-' */
#define FLAG_SPACE                   4U  /* Add ' ' or '-' */
#define FLAG_HASH                    8U  /* Add 0x to hexa, always add . to floating point */
#define FLAG_ZERO                   16U  /* Pad with leading zeros to get the minimal width */
#define FLAG_UNSUPPORTED           128U  /* Output only ?? and perform no other action - this type is not supported
                                            the rest of the arguments will be most probably corrupted */

#define WIDTH_NONE                   (-1) /* Output width not specified */
#define WIDTH_STAR                   (-2) /* The next argument specifies the width */

#define PRECISION_NONE               (-1)
#define PRECISION_STAR               (-2)

#define LENGTH_NONE                  0U
#define LENGTH_HH                    1U
#define LENGTH_H                     2U
#define LENGTH_LITTLE_L              3U
#define LENGTH_LITTLE_LL             4U
#define LENGTH_J                     5U
#define LENGTH_Z                     6U
#define LENGTH_T                     7U
#define LENGTH_LARGE_L               8U

#define SPECIFIER_NONE               0U

#define TYPE_NONE                    0U
#define TYPE_INT8                    1U
#define TYPE_UINT8                   2U
#define TYPE_INT16                   3U
#define TYPE_UINT16                  4U
#define TYPE_INT32                   5U
#define TYPE_UINT32                  6U
#define TYPE_INT64                   7U
#define TYPE_UINT64                  8U
#define TYPE_DOUBLE                  9U
#define TYPE_LONG_DOUBLE            10U
#define TYPE_STRING                 11U
#define TYPE_POINTER                12U
#define PUTC(Char) do{ if(pu8StrRplc < copcou8OutMax){ *pu8StrRplc = (uint8)(Char); pu8StrRplc++;} }while(FALSE)
#define CONV_BUF_SIZE 64U /* Big enough to be able to avoid output size checks */

/*==================================================================================================
                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/
/* Structure that keeps informations about parsed format specifier */
typedef struct {
    uint8 u8Flags;       /* Flags modifying the result number look */
    sint16 s16Width;     /* Number of digits or spaces - minimal width of the output */
    sint16 s16Precision; /* Number of digits (0s emitted instead of spaces to reach this limit)*/
    uint8 u8Length;      /* Length of the type to be converted (in bytes) */
    uint8 u8Type;        /* Type to be converted (char, short, int, long ...) */
    uint8 u8Specifier;   /* The letter specifying the format */
} FormatSpecifierType;

#if TRUE == NXP_SNPRINTF_CFG_FLOAT_SUPPORT
/*  This union is needed to be able to access bits of double values.
    Cast may not be used, it converts the value. */
typedef union
{
    float64_t dValue;
    uint64  u64Bits;
} tunDoubleToBits;
#endif /* NXP_SNPRINTF_CFG_FLOAT_SUPPORT */

/*==================================================================================================
                                       LOCAL CONSTANTS
==================================================================================================*/

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CONST_8
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

/* usage scope: nxp_vsnprintf */
static const uint8 au8HexaUpper[16] = { (uint8)'0', (uint8)'1', (uint8)'2', (uint8)'3',
                                     (uint8)'4', (uint8)'5', (uint8)'6', (uint8)'7',
                                     (uint8)'8', (uint8)'9', (uint8)'A', (uint8)'B',
                                     (uint8)'C', (uint8)'D', (uint8)'E', (uint8)'F'
                                   };

/* usage scope: nxp_vsnprintf */
static const uint8 au8HexaLower[16] = { (uint8)'0', (uint8)'1', (uint8)'2', (uint8)'3',
                                     (uint8)'4', (uint8)'5', (uint8)'6', (uint8)'7',
                                     (uint8)'8', (uint8)'9', (uint8)'a', (uint8)'b',
                                     (uint8)'c', (uint8)'d', (uint8)'e', (uint8)'f'
                                   };

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CONST_8
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

/*==================================================================================================
                                       LOCAL VARIABLES
==================================================================================================*/

/*==================================================================================================
                                       GLOBAL CONSTANTS
==================================================================================================*/

/*==================================================================================================
                                       GLOBAL VARIABLES
==================================================================================================*/

/*==================================================================================================
                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/

/*==================================================================================================
                                       LOCAL FUNCTIONS
==================================================================================================*/

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

static uint32 Minimum(uint32 u32Value1, uint32 u32Value2);
static uint8* StrReplaceSint32(sint32 s32Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec);
#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
static uint8* StrReplaceSint64(sint64 s64Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec);
#endif
static uint8* StrReplaceUint32(uint32 u32Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec);
#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
static uint8 * StrReplaceUint64(uint64 u64Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec);
#endif
static uint8* StrReplaceOctal32(uint32 u32Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec);
#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
static uint8* StrReplaceOctal64(uint64 u64Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec);
#endif
static uint8* StrReplaceHexa32(uint32 u32Value, uint8 *pu8DestStr, const uint8 pu8Hexa[], FormatSpecifierType formatSpec);
#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
static uint8* StrReplaceHexa64(uint64 u64Value, uint8 *pu8DestStr, const uint8 pu8Hexa[], FormatSpecifierType formatSpec);
#endif
static uint8* StrReplaceChar(uint8 u8Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec);
static uint8* StrReplaceString(const uint8 pcou8Value[], uint8 *pu8DestStr, uint32 u32DestFree, FormatSpecifierType formatSpec);
static uint8* ConvertBufWithWidthPrecision(const uint8 pcou8Buf[], uint16 u16BufLen, uint8 pu8DestStr[], FormatSpecifierType formatSpec);
static const uint8* ParseFormatSpecifier(const uint8 pcou8FormatStr[],FormatSpecifierType *formatSpec);
#if TRUE == NXP_SNPRINTF_CFG_FLOAT_SUPPORT
static void ConvertDoubleToScientific(float64_t dNum, char_t *pcNegative, sint16 *ps16Exp, uint8 *pu8Bdp, uint32 *pu32Adp);
#endif /* NXP_SNPRINTF_CFG_FLOAT_SUPPORT */
static inline uint8 *PutCA(const uint8 *pcou8Src, uint8 const * const copcou8InMax,
                                   uint8 *pu8Out,   uint8 const * const copcou8OutMax);
static inline uint8 *PutS(const char_t *coszSrc, uint8 *pu8Out, uint8 const * const copcou8OutMax);

/*==================================================================================================
                                       GLOBAL FUNCTIONS
==================================================================================================*/

/*================================================================================================*/
#if TRUE == NXP_SNPRINTF_CFG_FLOAT_SUPPORT
/*
* @brief Converts the floating point number to scientific format
* @param[in] dNum - Number to convert
* @param[out] pcNegative sign flag either '-' when the number is negative or ' '(space) when it is non-negative
* @param[out] ps16Exp - Exponent value (signed)
* @param[out] pu8Bdp - Part before decimal point (only one digit 0-9)
* @param[out] pu32Adp - Part after decimal point (9 digits including leading 0s which must be printed out)
* @details Function returns integer numbers to be printed out to form the scientific format (%e) for floating
*         point numbers output.
*         The converted numbers shall be displayed by the following formatting string
*         nxp_snprintf(string, size, "%c%1u.%09ue%02d", negative, bdp, adp, exp);
* @warning Function does not handle NaN (not a number) and infinity numbers, also 0 although it is a special
*          case is converted to the same format as other numbers.
* @note This function involves floating point divisions and multiplications which may be done several times
*       which may consume quite a lot of CPU cycles on some cores.
*/
static void ConvertDoubleToScientific(float64_t dNum, char_t *pcNegative, sint16 *ps16Exp, uint8 *pu8Bdp, uint32 *pu32Adp)
{
    *ps16Exp = 0; /* We have to do this at each case */

    if((dNum < (0.0)) || (dNum > (0.0)))
    {
        /* Get the sign and convert dNum to absolute value */
        if(dNum < 0.0)
        {   /* - */
            dNum = -dNum;
            *pcNegative = '-';
        }
        else /* dNum > 0.0 */
        { /* + */
            *pcNegative = ' ';
        }

        /* Get the exponent and normalize number
          - this is done gradually to improve the performance */
        while(dNum >= 1e64)
        {
            dNum /= 1e64;
            *ps16Exp = (sint16)(*ps16Exp + 64);
        }
        while(dNum >= 1e16)
        {
            dNum /= 1e16;
            *ps16Exp = (sint16)(*ps16Exp + 16);
        }
        while(dNum >= 1e4)
        {
            dNum /= 1e4;
            *ps16Exp = (sint16)(*ps16Exp + 4);
        }
        while(dNum >= 1e1)
        {
            dNum /= 1e1;
            *ps16Exp = (sint16)(*ps16Exp + 1);
        }

        while(dNum <= 1e-64)
        {
            dNum *= 1e64;
            *ps16Exp = (sint16)(*ps16Exp - 64);
        }
        while(dNum <= 1e-16)
        {
            dNum *= 1e16;
            *ps16Exp = (sint16)(*ps16Exp - 16);
        }
        while(dNum <= 1e-4)
        {
            dNum *= 1e4;
            *ps16Exp = (sint16)(*ps16Exp - 4);
        }
        while(dNum < 1.0)
        {
            dNum *= 10.0;
            *ps16Exp = (sint16)(*ps16Exp - 1);
        }

        /* Part before decimal point */
        *pu8Bdp = (uint8) dNum;

        /* Part after decimal point */
        dNum = dNum - (float64_t)(*pu8Bdp);
        dNum *= 1e9;
        *pu32Adp = (uint32) dNum;
    }
    else /* dNum == 0 - special case */
    {
        *pcNegative = ' ';
        *pu8Bdp = 0U;
        *pu32Adp = 0U;
    }
}
#endif /* NXP_SNPRINTF_CFG_FLOAT_SUPPORT */


/*
* @brief     Function returns minimum of two variables
* @details
* @param[in] u32Value1       first value to compare
* @param[in] u32Value1       second value to compare
* @return                    value of the variable with lower value
*/
static uint32 Minimum(uint32 u32Value1, uint32 u32Value2)
{
    uint32 u32Minimum;

    if (u32Value1 < u32Value2)
    {
        u32Minimum = u32Value1;
    }
    else
    {
        u32Minimum = u32Value2;
    }

    return u32Minimum;
}

/*
* @brief     Signed to String
* @details   Converts value of the signed variable to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceSint32(sint32 s32Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec)
{
    uint8 u8CurNum;
    sint32 s32Tmp;
    uint32 u32Tmp;
    uint8 au8Buffer[10U];
    uint16 u16NumCntr = 0U;
    uint8 *pu8ModifiedDestStr;

    if (0 > s32Value)
    {
        /* Change sign */
        s32Tmp = -s32Value;
        u32Tmp = (uint32)s32Tmp;
    }
    else
    {
        /* Do not change sign */
        u32Tmp = (uint32)s32Value;
    }

    do
    {
        u8CurNum = (uint8)(u32Tmp % 10U); /* Cannot be greater than 10 */
        au8Buffer[u16NumCntr] = (uint8)(u8CurNum + (uint8)'0');
        u16NumCntr++;
        u32Tmp /= 10U;
    } while (0U != u32Tmp);

    if (0 > s32Value)
    {
        /* Write - sign to buffer */
        au8Buffer[u16NumCntr] = (uint8)'-';
        u16NumCntr++;
    }
    else
    {   /* Positive number */
        if(FLAG_PLUS == (formatSpec.u8Flags & FLAG_PLUS))
        {   /* Plus sign shall be added */
            au8Buffer[u16NumCntr] = (uint8)'+';
            u16NumCntr++;
        }
        if(FLAG_SPACE == (formatSpec.u8Flags & FLAG_SPACE))
        {   /* Space shall be added */
            au8Buffer[u16NumCntr] = (uint8)' ';
            u16NumCntr++;
        }
    }

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}


#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
/*
* @brief     Signed to String
* @details   Converts value of the signed variable to the string
* @param[in] u64Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceSint64(sint64 s64Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec)
{
    uint8 u8CurNum;
    uint64 u64Tmp;
    sint64 s64Tmp;
    uint8 au8Buffer[21U];
    uint16 u16NumCntr = 0U;
    uint8 *pu8ModifiedDestStr;
    uint32 u32CurTmp;
    uint32 u32i;

    if (0 > s64Value)
    {
        /* Change sign */
        s64Tmp = -s64Value;
        u64Tmp = (uint64)s64Tmp;
    }
    else
    {
        /* Do not change sign */
        u64Tmp = (uint64)s64Value;
    }

    do
    {
        u32CurTmp = (uint32)(u64Tmp % 1000000000UL);
        u64Tmp /= 1000000000UL;
        for(u32i = 0U; u32i < 9U; u32i++)
        {   /* Produce 9 digits */
            u8CurNum = (uint8)(u32CurTmp % 10U);
            au8Buffer[u16NumCntr] = (uint8)(u8CurNum + (uint8)'0');
            u16NumCntr++;
            u32CurTmp /= 10U;
            if( (0U == u32CurTmp) && (0U == u64Tmp) )
            {   /* This is the last piece, skip leading zeros */
                break;
            }
        }
    } while (0U != u64Tmp);


    if (0 > s64Value)
    {
        /* Write - sign to buffer */
        au8Buffer[u16NumCntr] = (uint8)'-';
        u16NumCntr++;
    }
    else
    {   /* Positive number */
        if(FLAG_PLUS == (formatSpec.u8Flags & FLAG_PLUS))
        {   /* Plus sign shall be added */
            au8Buffer[u16NumCntr] = (uint8)'+';
            u16NumCntr++;
        }
        if(FLAG_SPACE == (formatSpec.u8Flags & FLAG_SPACE))
        {   /* Space shall be added */
            au8Buffer[u16NumCntr] = (uint8)' ';
            u16NumCntr++;
        }
    }

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}
#endif

/*
* @brief     Unsigned to String
* @details   Converts value of the unsigned variable to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceUint32(uint32 u32Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec)
{
    uint8 u8CurNum;
    uint32 u32Tmp = u32Value;
    uint8 au8Buffer[10U];
    uint16 u16NumCntr = 0U;
    uint8 *pu8ModifiedDestStr;

    /* Extract variable value */
    do
    {
        u8CurNum = (uint8)(u32Tmp % 10U);

        au8Buffer[u16NumCntr] = (uint8)(u8CurNum + (uint8)'0');
        u16NumCntr++;
        u32Tmp /= 10U;
    } while (0U != u32Tmp);

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}

#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
/*
* @brief     Unsigned to String
* @details   Converts value of the unsigned variable to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceUint64(uint64 u64Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec)
{
    uint8 u8CurNum;
    uint64 u64Tmp = u64Value;
    uint8 au8Buffer[21U];
    uint16 u16NumCntr = 0U;
    uint8 *pu8ModifiedDestStr;
    uint32 u32CurTmp;
    uint32 u32i;

    /* Extract variable value */
    do
    {
        u32CurTmp = (uint32)(u64Tmp % 1000000000UL);
        u64Tmp /= 1000000000UL;
        for(u32i = 0U; u32i < 9U; u32i++)
        {   /* Produce 9 digits */
            u8CurNum = (uint8)(u32CurTmp % 10U);
            au8Buffer[u16NumCntr] = (uint8)(u8CurNum + (uint8)'0');
            u16NumCntr++;
            u32CurTmp /= 10U;
            if( (0U == u32CurTmp) && (0U == u64Tmp) )
            {   /* This is the last piece, skip leading zeros */
                break;
            }
        }
    } while (0U != u64Tmp);

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}
#endif


/*
* @brief     Octal to String
* @details   Converts value of the variable to octal format and than to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceOctal32(uint32 u32Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec)
{
    uint8 au8Buffer[11U];
    uint16 u16NumCntr = 0U;
    uint8 u8CurNum;
    uint32 u32Tmp = u32Value;
    uint8 *pu8ModifiedDestStr;

    do
    {
        u8CurNum = (uint8)((uint8)u32Tmp & 0x7U);
        au8Buffer[u16NumCntr] = (uint8)(u8CurNum + (uint8)'0');
        u16NumCntr++;
        u32Tmp >>= 3U;
    } while (0U != u32Tmp);

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}

#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
/*
* @brief     Octal to String
* @details   Converts value of the variable to octal format and than to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceOctal64(uint64 u64Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec)
{
    uint8 au8Buffer[22U];
    uint16 u16NumCntr = 0U;
    uint8 u8CurNum;
    uint64 u64Tmp = u64Value;
    uint8 *pu8ModifiedDestStr;

    do
    {
        u8CurNum = (uint8)((uint8)u64Tmp & 0x7U);
        au8Buffer[u16NumCntr] = (uint8)(u8CurNum + (uint8)'0');
        u16NumCntr++;
        u64Tmp >>= 3U;
    } while (0U != u64Tmp);

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}
#endif

/*
* @brief     Hexa to String
* @details   Converts value of the variable to hexa format and than to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] *pu8Hexa        array with hexa characters
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceHexa32(uint32 u32Value, uint8 *pu8DestStr, const uint8 pu8Hexa[], FormatSpecifierType formatSpec)
{
    uint8 au8Buffer[8U];
    uint16 u16NumCntr = 0U;
    uint8 u8CurNum;
    uint32 u32Tmp = u32Value;
    uint8 *pu8ModifiedDestStr;

    do
    {
        u8CurNum = pu8Hexa[u32Tmp & 0xFU];
        au8Buffer[u16NumCntr] = u8CurNum;
        u16NumCntr++;
        u32Tmp >>= 4U;
    } while (0U != u32Tmp);

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}

#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
/*
* @brief     Hexa to String
* @details   Converts value of the variable to hexa format and than to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] *pu8Hexa        array with hexa characters
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceHexa64(uint64 u64Value, uint8 *pu8DestStr, const uint8 pu8Hexa[], FormatSpecifierType formatSpec)
{
    uint8 au8Buffer[16U];
    uint16 u16NumCntr = 0U;
    uint8 u8CurNum;
    uint64 u64Tmp = u64Value;
    uint8 *pu8ModifiedDestStr;

    do
    {
        u8CurNum = pu8Hexa[u64Tmp & 0xFU];
        au8Buffer[u16NumCntr] = u8CurNum;
        u16NumCntr++;
        u64Tmp >>= 4U;
    } while (0U != u64Tmp);

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, u16NumCntr, pu8DestStr, formatSpec);

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}
#endif
/*
* @brief     Char to String
* @details   Converts the char variable to the string
* @param[in] u32Value        value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceChar(uint8 u8Value, uint8 *pu8DestStr, FormatSpecifierType formatSpec)
{
    uint8 au8Buffer[1U];
    uint8 *pu8ModifiedDestStr;

    au8Buffer[0] = u8Value;

    /* Format "variable string" based on format specifier */
    pu8ModifiedDestStr = ConvertBufWithWidthPrecision(au8Buffer, 1U, pu8DestStr, formatSpec);

    /* Format "variable string" based on format specifier */
    return pu8ModifiedDestStr;
}


/*
* @brief     String to String
* @details   Converts the string variable to the string
* @param[in] pcou8Value      value to convert to string
* @param[in] *pu8DestStr     result destination
* @param[in] u32DestFree     available space in destination buffer
* @param[in] formatSpec      format specifier precision
* @return                    pointer to the current position in buffer with replaced characters
*/
static uint8 * StrReplaceString(const uint8 pcou8Value[], uint8 *pu8DestStr, uint32 u32DestFree, FormatSpecifierType formatSpec)
{
    uint8 *pu8ModifiedDestStr;
    const char_t *src = "(NULL)";

    if (NULL == pcou8Value)
    {
        pu8ModifiedDestStr = ConvertBufWithWidthPrecision((uint8*)src, (uint16)u32DestFree, pu8DestStr, formatSpec);
    }
    else
    {
        /* Format "variable string" based on format specifier */
        pu8ModifiedDestStr = ConvertBufWithWidthPrecision(pcou8Value, (uint16)u32DestFree, pu8DestStr, formatSpec);
    }

    /* Return current position in destination string */
    return pu8ModifiedDestStr;
}


/*
* @brief     Format the output according to the informations extracted from format specifier.
* @details   Function converts string passed through *pcou8Buf parameter to the format defined by formatSpec
*            structure and save the result to the *pu8DestStr.
* @param[in]  *pcou8Buf       string which should be formatted
* @param[in]  u16BufLen       string buffer length
* @param[out] *pu8DestStr     destination of the formatted string
* @param[in]  formatSpec      structure with desired format informations
* @return                     pointer to the current position in buffer with replaced characters
*/
static uint8 * ConvertBufWithWidthPrecision(const uint8 pcou8Buf[], uint16 u16BufLen, uint8 pu8DestStr[], FormatSpecifierType formatSpec)
{
    sint16 s16X;
    sint32 s32X;
    uint16 u16Index = 0U;

    /* Signed, unsigned, octal, hexa numbers */
    if (((uint8)'d' == formatSpec.u8Specifier) || ((uint8)'i' == formatSpec.u8Specifier) ||
        ((uint8)'u' == formatSpec.u8Specifier) || ((uint8)'o' == formatSpec.u8Specifier) ||
        ((uint8)'x' == formatSpec.u8Specifier) || ((uint8)'X' == formatSpec.u8Specifier) )
    {
        sint32 s32Spaces = 0;
        sint32 s32Zeros = 0;
        uint16 u16NumLenWithoutSign = u16BufLen;

        if( ((uint8)'-' == pcou8Buf[u16BufLen-1U]) ||
            (((uint8)'+' == pcou8Buf[u16BufLen-1U]) || ((uint8)' ' == pcou8Buf[u16BufLen-1U]))
          )
        {
            u16NumLenWithoutSign = (uint16)(u16BufLen-1U);
        }

        /* Test if the width was set (macros WIDTH_NONE and WIDTH_STAR)*/
        if (formatSpec.s16Width > 0)
        {
            /* Check whether zero shall be used for padding */
            if(FLAG_ZERO == (formatSpec.u8Flags & FLAG_ZERO))
            {
                s32Zeros = (sint32)formatSpec.s16Width - (sint32)u16BufLen;
            }
            else
            {
                s32Spaces = (sint32)formatSpec.s16Width - (sint32)u16BufLen;
            }
        }

        /* Test if the precision was set (macros PRECISION_NONE and PRECISION_STAR)*/
        if (formatSpec.s16Precision > 0)
        {
            if(((sint32)formatSpec.s16Precision - (sint32)u16NumLenWithoutSign) > s32Zeros)
            {
                s32Zeros = (sint32)formatSpec.s16Precision - (sint32)u16NumLenWithoutSign;
            }
        }

        /* Number of spaces is reduced by zeros */
        if (s32Zeros > 0)
        {
            s32Spaces -= s32Zeros;
        }

        /* Print spaces (nothing will be printed for negative number of spaces) */
        for (s32X = 0; s32X < s32Spaces; s32X++)
        {
            pu8DestStr[u16Index] = (uint8)' ';
            u16Index++;
        }

        /* Print minus sign if necessary */
        if ((uint8)'-' == pcou8Buf[u16BufLen-1U])
        {
            pu8DestStr[u16Index] = (uint8)'-';
            u16Index++;
        }

        /* Print zeros (nothing will be printed for negative number of zeros) */
        for (s32X = 0; s32X < s32Zeros; s32X++)
        {
            pu8DestStr[u16Index] = (uint8)'0';
            u16Index++;
        }

        /* Print the number */
        for (s16X = (sint16)(((sint16)u16NumLenWithoutSign-1)); s16X >= 0; s16X--)
        {
            pu8DestStr[u16Index] = pcou8Buf[s16X];
            u16Index++;
        }
    }
    /* String */
    else if ((uint8)'s' == formatSpec.u8Specifier)
    {
        uint16 u16Limit = 0U;     /* Number of string characters which should be printed */
        sint32 s32Spaces = 0;     /* Number of spaces which should be printed */

        /* Test if the precision was set (macros PRECISION_NONE and PRECISION_STAR)*/
        if (formatSpec.s16Precision >= 0)
        {
            u16Limit = (uint16)Minimum((uint32)(sint32)formatSpec.s16Precision, (uint32)u16BufLen);
        }
        else
        {
            u16Limit = u16BufLen;
        }

        /* Test if the width was set (macros WIDTH_NONE and WIDTH_STAR)*/
        if (formatSpec.s16Width >= 0)
        {
            s32Spaces = (sint32)formatSpec.s16Width - (sint32)u16Limit;
        }
        else
        {
            s32Spaces = 0;
        }

        /* Print spaces (nothing will be printed for negative number of spaces) */
        for (s32X = 0; s32X < s32Spaces; s32X++)
        {
            pu8DestStr[u16Index] = (uint8)' ';
            u16Index++;
        }

        /* Print string (or its part)*/
        for (s32X = 0; s32X < (sint32)u16Limit; s32X++)
        {
            if (0U == pcou8Buf[s32X])
            {   /* End of input string */
                break;
            }
            pu8DestStr[u16Index] = pcou8Buf[s32X];
            u16Index++;
        }
    }
    /* Char */
    else if ((uint8)'c' == formatSpec.u8Specifier)
    {
        if (formatSpec.s16Width > (sint16)u16BufLen)
        {
            for (s16X = (sint16)((formatSpec.s16Width - (sint16)u16BufLen)); s16X > 0; s16X--)
            {
                pu8DestStr[u16Index] = (uint8)' ';
                u16Index++;
            }
        }

        for(s16X = (sint16)(((sint16)u16BufLen - 1)); s16X >= 0; s16X--)
        {
            pu8DestStr[u16Index] = pcou8Buf[s16X];
            u16Index++;
        }
    }
    /* Pointer */
    else if ((uint8)'p' == formatSpec.u8Specifier)
    {
        sint32 s32Spaces = 0;
        sint32 s32Zeros = 0;

        /* Test if the width was set (macros WIDTH_NONE and WIDTH_STAR)*/
        if (formatSpec.s16Width > 0)
        {
            s32Spaces = (sint32)formatSpec.s16Width - ((sint32)u16BufLen + 2);
        }

        /* Test if the precision was set (macros PRECISION_NONE and PRECISION_STAR)*/
        if (formatSpec.s16Precision > 0)
        {
            s32Zeros = (sint32)formatSpec.s16Precision - ((sint32)u16BufLen + 2);
        }

        /* Number of spaces is reduced by zeros */
        if ((s32Spaces > 0) && (s32Zeros > 0))
        {
            s32Spaces -= s32Zeros;
        }

        /* Print spaces (nothing will be printed for negative number of spaces) */
        for (s32X = 0; s32X < s32Spaces; s32X++)
        {
            pu8DestStr[u16Index] = (uint8)' ';
            u16Index++;
        }

        /* Print 0x before pointer value */
        pu8DestStr[u16Index] = (uint8)'0';
        u16Index++;
        pu8DestStr[u16Index] = (uint8)'x';
        u16Index++;

        /* Print zeros (nothing will be printed for negative number of zeros) */
        for (s32X = 0; s32X < s32Zeros; s32X++)
        {
            pu8DestStr[u16Index] = (uint8)'0';
            u16Index++;
        }

        /* Print the number */
        for (s16X = (sint16)(((sint16)u16BufLen-1)); s16X >= 0; s16X--)
        {
            pu8DestStr[u16Index] = pcou8Buf[s16X];
            u16Index++;
        }
    }
    else
    {
        /* Nothing to be done */
    }

    /* Return current position in destination string */
    return &pu8DestStr[u16Index];
}


/*
* @brief      Parse format specifiers found in the input string.
* @details    Function is called whenever the fsl_printf function find % character in the input string.
*             The parsing of the format specifier is performed and extracted informations are stored to the formatSpec
*             structure.
* @param[in]  *pcou8FormatStr   String with the format specifier
* @param[out] *formatSpec       Pointer to the structure where data extracted from the format specifier are saved
* @return                       pointer to the current position in input string
*/
static const uint8 * ParseFormatSpecifier(const uint8 pcou8FormatStr[], FormatSpecifierType *formatSpec)
{
    uint8 u8TypeWidth = 0U;
    uint16 u16ResultWidth = 0U;
    uint16 u16ResultPrecision = 0U;
    uint16 u16Index = 0U;
    /* Format specifier structure initialization */
    formatSpec->u8Flags = FLAG_NONE;
    formatSpec->s16Width = WIDTH_NONE;
    formatSpec->s16Precision = PRECISION_NONE;
    formatSpec->u8Length = LENGTH_NONE;
    formatSpec->u8Specifier = SPECIFIER_NONE;
    formatSpec->u8Type = TYPE_NONE;

    /* Move to the symbol behind % */
    u16Index++;

    /* Parse flags */
    while(TRUE)
    {
        if (pcou8FormatStr[u16Index] == (uint8)'-')
        {
            formatSpec->u8Flags |= FLAG_MINUS;
            u16Index++;
        }
        else if (pcou8FormatStr[u16Index] == (uint8)'+')
        {
            formatSpec->u8Flags |= FLAG_PLUS;
            u16Index++;
        }
        else if (pcou8FormatStr[u16Index] == (uint8)' ')
        {
            formatSpec->u8Flags |= FLAG_SPACE;
            u16Index++;
        }
        else if (pcou8FormatStr[u16Index] == (uint8)'#')
        {
            formatSpec->u8Flags |= FLAG_HASH;
            u16Index++;
        }
        else if (pcou8FormatStr[u16Index] == (uint8)'0')
        {
            formatSpec->u8Flags |= FLAG_ZERO;
            u16Index++;
        }
        else
        {
            break;
        }
    }

    /* Parse width */
    if (pcou8FormatStr[u16Index] == (uint8)'*')
    {
        formatSpec->s16Width = WIDTH_STAR;
        u16Index++;
    }
    else if ((pcou8FormatStr[u16Index] >= (uint8)'0') && (pcou8FormatStr[u16Index] <= (uint8)'9'))
    {
        /* Convert string to uint16 */
        while ((pcou8FormatStr[u16Index] >= (uint8)'0') && (pcou8FormatStr[u16Index] <= (uint8)'9'))
        {
            u16ResultWidth = (uint16)(u16ResultWidth * 10U);
            u16ResultWidth = (uint16)(u16ResultWidth + ((uint16)(pcou8FormatStr[u16Index]) - (uint8)'0'));
            u16Index++;
        }

        /* Store result to the struct */
        formatSpec->s16Width = (sint16)u16ResultWidth;
    }
    else
    {
        /* Nothing to be done */
    }

    /* Parse precision */
    if (pcou8FormatStr[u16Index] == (uint8)'.')
    {
        u16Index++;

        if (pcou8FormatStr[u16Index] == (uint8)'*')
        {
            formatSpec->s16Precision = PRECISION_STAR;
        }
        else
        {
            /* Convert string to uint16 */
            while ((pcou8FormatStr[u16Index] >= (uint8)'0') && (pcou8FormatStr[u16Index] <= (uint8)'9'))
            {
                u16ResultPrecision = (uint16)(u16ResultPrecision * 10U);
                u16ResultPrecision = (uint16)(u16ResultPrecision + ((uint16)(pcou8FormatStr[u16Index]) - (uint8)'0'));
                u16Index++;
            }

            formatSpec->s16Precision = (sint16)u16ResultPrecision;
        }
    }

    /* Parse length */
    if ((uint8)'h' == pcou8FormatStr[u16Index])
    {
        formatSpec->u8Length = LENGTH_H;
        u16Index++;
        u8TypeWidth = (uint8)sizeof(short);


        if ((uint8)'h' == pcou8FormatStr[u16Index])
        {
            formatSpec->u8Length = LENGTH_HH;
            u16Index++;
            u8TypeWidth = (uint8)sizeof(char_t);
        }
    }
    else if ((uint8)'l' == pcou8FormatStr[u16Index] )
    {
        formatSpec->u8Length = LENGTH_LITTLE_L;
        u16Index++;
        u8TypeWidth = (uint8)sizeof(long int); /* Either 4 or 8 */

        if ((uint8)'l' == pcou8FormatStr[u16Index])
        {
            /* The long long (64bit) values are sometimes not supported */
            formatSpec->u8Length = LENGTH_LITTLE_LL;
            u16Index++;
            u8TypeWidth = (uint8)sizeof(long long int);
            #if FALSE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                formatSpec->u8Flags |= FLAG_UNSUPPORTED;
            #endif
        }
    }
    else if ((uint8)'j' == pcou8FormatStr[u16Index])
    {
        /* The intmax_t or uintmax_t values are not supported */
        formatSpec->u8Length = LENGTH_J;
        u16Index++;
        u8TypeWidth = 0U;
        formatSpec->u8Flags |= FLAG_UNSUPPORTED;

    }
    else if ((uint8)'z' == pcou8FormatStr[u16Index])
    {
        /* The size_t values are not supported */
        formatSpec->u8Length = LENGTH_Z;
        u16Index++;
        u8TypeWidth = 0U;
        formatSpec->u8Flags |= FLAG_UNSUPPORTED;
    }
    else if ((uint8)'t' == pcou8FormatStr[u16Index])
    {
        /* The ptrdiff_t values are not supported */
        formatSpec->u8Length = LENGTH_T;
        u16Index++;
        u8TypeWidth = 0U;
        formatSpec->u8Flags |= FLAG_UNSUPPORTED;
    }
    else if ((uint8)'L' == pcou8FormatStr[u16Index])
    {
        /* The long double (typ. 64 or 80 bits) 80 bits values are not supported */
        formatSpec->u8Length = LENGTH_LARGE_L;
        u16Index++;
        u8TypeWidth = (uint8)sizeof(long double);
        formatSpec->u8Flags |= FLAG_UNSUPPORTED;
    }
    else
    {
        /* Default length */
    }

    formatSpec->u8Specifier = pcou8FormatStr[u16Index];
    /* Parse specifier */
    switch(pcou8FormatStr[u16Index])
    {
        case (uint8)'d':
        case (uint8)'i':
            if(0U == u8TypeWidth) /* The default -> Integer */
            {
                u8TypeWidth = (uint8)sizeof(int);
            }

            if (1U == u8TypeWidth)
            {
                formatSpec->u8Type = TYPE_INT8;
            }
            else if (2U == u8TypeWidth)
            {
                formatSpec->u8Type = TYPE_INT16;
            }
            else if (4U == u8TypeWidth)
            {
                formatSpec->u8Type = TYPE_INT32;
            }
            else  /* 8U == u8TypeWidth */
            {
                formatSpec->u8Type = TYPE_INT64;
            }
            break;
        case (uint8)'u':
        case (uint8)'o':
        case (uint8)'x':
        case (uint8)'X':
            if(0U == u8TypeWidth) /* The default -> Integer */
            {
                u8TypeWidth = (uint8)sizeof(int);
            }

            if (1U == u8TypeWidth)
            {
                formatSpec->u8Type = TYPE_UINT8;
            }
            else if (2U == u8TypeWidth)
            {
                formatSpec->u8Type = TYPE_UINT16;
            }
            else if (4U == u8TypeWidth)
            {
                formatSpec->u8Type = TYPE_UINT32;
            }
            else  /* 8U == u8TypeWidth */
            {
                formatSpec->u8Type = TYPE_UINT64;
            }
            break;
        case (uint8)'a':
        case (uint8)'A':
        case (uint8)'f':
        case (uint8)'F':
        case (uint8)'e':
        case (uint8)'E':
        case (uint8)'g':
        case (uint8)'G':
            #if FALSE == NXP_SNPRINTF_CFG_FLOAT_SUPPORT
                /* Floating point numbers not supported */
                formatSpec->u8Flags |= FLAG_UNSUPPORTED;
            #else
                /* Hexadecimal floating point output is not supported for now */
                if(((uint8)'a' == pcou8FormatStr[u16Index]) || ((uint8)'A' == pcou8FormatStr[u16Index]))
                {
                    formatSpec->u8Flags |= FLAG_UNSUPPORTED;
                }
            #endif
            if (0U == u8TypeWidth)
            {   /* Check for default length (0U) */
                formatSpec->u8Type = TYPE_DOUBLE;
            }
            else
            {
                formatSpec->u8Type = TYPE_LONG_DOUBLE;
            }
            break;
        case (uint8)'c':
            formatSpec->u8Type = TYPE_INT8;
            break;
        case (uint8)'s':
            formatSpec->u8Type = TYPE_STRING;
            break;
        case (uint8)'p':
            formatSpec->u8Type = TYPE_POINTER;
            break;
        case (uint8)'n':
            formatSpec->u8Type = 0U;
            break;
        case (uint8)'%':
            formatSpec->u8Type = TYPE_NONE;
            break;
        default:
            formatSpec->u8Specifier = SPECIFIER_NONE;
            break;
    }

    /* Return pointer to the current position in input string */
    return &pcou8FormatStr[u16Index];
}

/*
* @brief      Copies uint8 from buffer to another.
* @details    Both buffers are specified by beginning and end addresses.
* @param[in]  *pcou8Src         Pionter to source buffer
* @param[in]  *copcou8InMax     Pointer to byte that follows source data (stops before copying this byte)
* @param[out] *pu8Out           Pointer to destination buffer
* @param[in]  *copcou8OutMax    Pointer to byte that follows last writable byte in destination buffer (cannot write here)
* @return                       Pointer to byte which follows last written byte in output buffer.
*/
static inline uint8 *PutCA(const uint8 *pcou8Src, uint8 const * const copcou8InMax,
                                   uint8 *pu8Out,   uint8 const * const copcou8OutMax)
{
    uint8 *pu8Out_temp = pu8Out;
    const uint8 *pcou8Src_temp = pcou8Src;

    while ((pu8Out_temp < copcou8OutMax) && (pcou8Src_temp < copcou8InMax))
    {
        *pu8Out_temp = *pcou8Src_temp;
        pcou8Src_temp++;
        pu8Out_temp++;
    }
    return pu8Out_temp;
}

/*  which is specified by beginning and end address */
/*
* @brief      Copies zero terminated string to uint8 buffer.
* @details    Destination buffer is specified by beginning and end addresses.
* @param[in]  *coszSrc          Pionter to source string, zero terminated
* @param[out] *pu8Out           Pointer to destination buffer
* @param[in]  *copcou8OutMax    Pointer to byte that follows last writable byte in destination buffer (cannot write here)
* @return                       Pointer to byte which follows last written byte in output buffer.
*/
static inline uint8 *PutS(const char_t *coszSrc, uint8 *pu8Out, uint8 const * const copcou8OutMax)
{
    uint8 *pu8Out_temp = pu8Out;
    const char_t *coszSrc_temp = coszSrc;

    while ((pu8Out_temp < copcou8OutMax) && (0U != (uint8)(*coszSrc_temp)))
    {
        *pu8Out_temp = (uint8)(*coszSrc_temp);
        pu8Out_temp++;
        coszSrc_temp++;
    }
    return pu8Out_temp;
}

/**
* @brief     Print data to the interface selected in configuration.
* @details   Function is used to print data through another module, which is joined in configuration.
*            It serves for printing debug messages.
* @param[in] *pcocStr String which should be printed. It can contain format specifiers which will be substituted by
*                      the values of the variables that are passed to the function through variable count of parameters.
*                      Format is same as in standard function printf. Conversion specifiers are either:
*                      - supported: diuoxXcsp%
*                      - with configurable support: fFeEgG (They are ignored if the support is disabled)
*                      - always ignored: aA
*                      - not recognized: all others (not recognized conversion specifiers will cause the conversion to abort)
*                      - Support of "long long" is configurable - it is ignored if it is disabled.
*                      - Long float is ignored.
*/

uint32 nxp_snprintf(char_t *str, uint32 size, const char_t *pcocStr, ...)
{
    uint32 retval;
    va_list VarArg;

    va_start(VarArg, pcocStr);
    retval = nxp_vsnprintf(str, size, pcocStr, VarArg);
    va_end(VarArg);
    return retval;
}

uint32 nxp_vsnprintf(char_t *str, uint32 size, const char_t *pcocStr, va_list VarArg)
{
    const uint8 *pcou8StrActChar = (const uint8*)pcocStr;  /* Pointer to actual input character */
    uint8 au8TmpConvBuf[CONV_BUF_SIZE]; /*  Temporary buffer for conversion output (except string conversions) */
    const uint8 *pu8TmpConvEnd; /* Points behind converted value (in au8TmpConvBuf) */
    uint8 *pu8StrRplc = (uint8 *)str; /* Pointer to buffer with replaced characters */
    uint8 const * const copcou8OutMax = pu8StrRplc + size - 1U; /* Max possible address of str's terminating '\0' */
#if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
    bool_t bLong = FALSE;             /* Indicates that long variant of the type is used */

    uint64 u64NextArg = 0U;         /* Variable to store function parameter */
#endif

    bool_t bAbort = FALSE;
    uint32 u32NextArg = 0U;         /* Variable to store function parameter */
#if TRUE == NXP_SNPRINTF_CFG_FLOAT_SUPPORT
    float64_t dNextArg;               /* Variable to store function parameter */
#endif
    void *pvNextArg = (void*)0U;      /* Variable to store function parameter */
    FormatSpecifierType formatSpec;   /* Keeps information about print format */

    /* Extract number of special characters from string */
    while(0U != *pcou8StrActChar)
    {
        /* Format specifier character found */
        if ((uint8)'%' == *pcou8StrActChar)
        {
        #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
            bLong = FALSE;
        #endif
            /* Parse format specifier at current position */
            pcou8StrActChar = ParseFormatSpecifier(pcou8StrActChar, &formatSpec);

            /* We must read the argument in each case */
            switch(formatSpec.u8Type)
            {   /*  Two assumptions were made here:                                                            */
                /*  1. Integer is 32bit wide                                                                   */
                /*  2. Integer promotion works as defined in C99 and in MISRA (same definition).               */
                /*  Both must be verified in tests for each platform, compiler, and compiler options set used. */
                case TYPE_INT8:           /* Promoted to int */
                case TYPE_UINT8:          /* Promoted to int */
                case TYPE_INT16:          /* Promoted to int */
                case TYPE_UINT16:         /* Promoted to int */
                case TYPE_INT32:          /* int */
                case TYPE_UINT32:         /* int */
                    u32NextArg = (uint32)va_arg(VarArg, unsigned int);
                    break;
                case TYPE_STRING:         /* Pointer in fact */
                case TYPE_POINTER:        /* Pointer (32 or 64 bit) */
                    pvNextArg = (void *)va_arg(VarArg, void *);
                    break;
                case TYPE_INT64:          /* long long */
                case TYPE_UINT64:         /* long long */
                #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    /* We must read it out even if this type is not supported */
                    u64NextArg = (uint64)va_arg(VarArg, unsigned long long);
                    bLong = TRUE;
                #else
                    (void)va_arg(VarArg, unsigned long long);
                #endif

                    break;
#if TRUE == NXP_SNPRINTF_CFG_FLOAT_SUPPORT
                case TYPE_DOUBLE:
                    dNextArg = (float64_t)va_arg(VarArg, double);
                    break;
                case TYPE_LONG_DOUBLE:
                    /* We must read it out even if this type is not supported */
                    (void)va_arg(VarArg, long double);
                    break;
#endif
                case TYPE_NONE:
                    /* Nothing to read from va_arg */
                    break;
                default:
                    /* Type was not recognized. If this happens then undefined behaviour may occur. */
                    /* Inform user about the problem: */
                    pu8StrRplc = PutS("(err)\n", pu8StrRplc, copcou8OutMax);
                    /* Parsing should stop to avoid undefined behaviour */
                    bAbort = TRUE;
                    break;

            }
            if(TRUE == bAbort)
            {   /* Abort processing of the input, exit this loop */
                break;
            }

            if(FLAG_UNSUPPORTED == (formatSpec.u8Flags & FLAG_UNSUPPORTED))
            {
                /* Output ?? when the type is unsupported */
                pu8StrRplc = PutS("??", pu8StrRplc, copcou8OutMax);
                /* Move to next character */
                pcou8StrActChar++;
                continue;
            }

            /* Check character behind % */
            switch((char_t)formatSpec.u8Specifier)
            {
                case 'i':
                case 'd':
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    if(FALSE == bLong)
                    {
                    #endif
                        pu8TmpConvEnd = StrReplaceSint32((sint32)u32NextArg, au8TmpConvBuf, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    }
                    else
                    {
                        pu8TmpConvEnd = StrReplaceSint64((sint64)u64NextArg, au8TmpConvBuf, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    }
                    #endif
                    break;
                case 'u':
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    if(FALSE == bLong)
                    {
                    #endif
                        pu8TmpConvEnd = StrReplaceUint32(u32NextArg, au8TmpConvBuf, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    }
                    else
                    {
                        pu8TmpConvEnd = StrReplaceUint64(u64NextArg, au8TmpConvBuf, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    }
                    #endif
                    break;
                case 'o':
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    if(FALSE == bLong)
                    {
                    #endif
                        pu8TmpConvEnd = StrReplaceOctal32(u32NextArg, au8TmpConvBuf, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    }
                    else
                    {
                        pu8TmpConvEnd = StrReplaceOctal64(u64NextArg, au8TmpConvBuf, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    }
                    #endif
                    break;
                case 'x':
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    if(FALSE == bLong)
                    {
                    #endif
                        pu8TmpConvEnd = StrReplaceHexa32(u32NextArg, au8TmpConvBuf, au8HexaLower, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    }
                    else
                    {
                        pu8TmpConvEnd = StrReplaceHexa64(u64NextArg, au8TmpConvBuf, au8HexaLower, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    }
                    #endif
                    break;
                case 'X':
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    if(FALSE == bLong)
                    {
                    #endif
                        pu8TmpConvEnd = StrReplaceHexa32(u32NextArg, au8TmpConvBuf, au8HexaUpper, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    }
                    else
                    {
                        pu8TmpConvEnd = StrReplaceHexa64(u64NextArg, au8TmpConvBuf, au8HexaUpper, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    }
                    #endif
                    break;
                case 'c':
                    pu8TmpConvEnd = StrReplaceChar((uint8)u32NextArg, au8TmpConvBuf, formatSpec);
                    pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    break;
                case 's':
                    /* Put the string directly to output buffer */
                    pu8StrRplc = StrReplaceString((uint8*)pvNextArg, pu8StrRplc, (uint32)copcou8OutMax-(uint32)pu8StrRplc, formatSpec);
                    break;
                case 'p':
                    if(4U == sizeof(void*))
                    {
                        pu8TmpConvEnd = StrReplaceHexa32((uint32)(uaddr_t)pvNextArg, au8TmpConvBuf, au8HexaUpper, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    }
                    #if TRUE == NXP_SNPRINTF_CFG_LLINT_SUPPORT
                    else
                    {
                        pu8TmpConvEnd = StrReplaceHexa64((uint64)(uaddr_t)pvNextArg, au8TmpConvBuf, au8HexaUpper, formatSpec);
                        pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                    }
                    #endif

                    break;
#if TRUE == NXP_SNPRINTF_CFG_FLOAT_SUPPORT
                case 'F': /* Letter case selection is not supported - so the next case is the same */
                case 'f': /* Floats promoted to double thus use the next case */
                case 'G': /* Letter case selection is not supported - so the next case is the same */
                case 'g': /* Appropriate format to be selected internally - done: the next one  */
                case 'E': /* Letter case selection is not supported - so the next case is the same */
                case 'e':
                    {   /* Block started to declare additional variables for this special case */
                        tunDoubleToBits unDouble; /* Union is needed to access bits (cast makes conversion instead) */
                        uint64 u64Exponent;
                        uint16 u16Exponent;

                        unDouble.dValue = dNextArg;
                        /* Check for special values encoded in exponent */
                        /* Valid for double defined in IEEE 754 */
                        u64Exponent = unDouble.u64Bits >> 52U;
                        u16Exponent = (uint16)u64Exponent;
                        u16Exponent &= 0x7FFU;
                        if(0x7FFU == u16Exponent)
                        {   /* Either inf or NaN */
                            if(0U == (unDouble.u64Bits & 0xFFFFFFFFFFFFFULL)) /* if mantis == zero */
                            {   /* Infinity */
                                if(0U != (unDouble.u64Bits & 0x8000000000000000ULL)) /* if sign bit is set */
                                {   /* Write minus */
                                    PUTC('-');
                                }
                                pu8StrRplc = PutS("INF", pu8StrRplc, copcou8OutMax);
                            }
                            else
                            {   /* NaN */
                                pu8StrRplc = PutS("NaN", pu8StrRplc, copcou8OutMax);
                            }
                        }
                        else
                        {   /* Normal number or signed zero or subnormal number */
                            char_t cSign;
                            uint8  u8Bdp;
                            uint32 u32Adp;
                            sint16 s16Exp;
                            FormatSpecifierType rFS;

                            ConvertDoubleToScientific(dNextArg, &cSign, &s16Exp, &u8Bdp, &u32Adp);

                            /* Currently no support for any user selectable formatting for floating point */
                            /* Add sign */
                            PUTC(cSign);
                            /* Add part before decimal point */
                            rFS.u8Flags = FLAG_NONE;
                            rFS.s16Width = 1;
                            rFS.s16Precision = PRECISION_NONE;
                            rFS.u8Length = LENGTH_NONE;
                            rFS.u8Specifier = (uint8)'u';
                            rFS.u8Type = TYPE_UINT8;
                            pu8TmpConvEnd = StrReplaceUint32((uint32)u8Bdp, au8TmpConvBuf, rFS);
                            pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                            /* Add dot */
                            PUTC('.');
                            /* Add part after decimal point */
                            rFS.s16Width = 9; /* 9 digits */
                            rFS.s16Precision = 9;
                            rFS.u8Flags = FLAG_ZERO; /* Include leading zeros */
                            rFS.u8Type = TYPE_UINT32;
                            pu8TmpConvEnd = StrReplaceUint32(u32Adp, au8TmpConvBuf, rFS);
                            pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                            /* Add 'e' character */
                            PUTC('e');
                            /* Add the exponent */
                            rFS.s16Width = 3; /* 3 digits */
                            rFS.s16Precision = 3;
                            rFS.u8Specifier = (uint8)'i';
                            rFS.u8Flags = FLAG_ZERO | FLAG_PLUS; /* Include leading zeros, always output + or - */
                            rFS.u8Type = TYPE_INT16;
                            pu8TmpConvEnd = StrReplaceSint32((sint32)s16Exp, au8TmpConvBuf, rFS);
                            pu8StrRplc = PutCA(au8TmpConvBuf, pu8TmpConvEnd, pu8StrRplc, copcou8OutMax);
                            /* We are finished */
                        }
                    }
                    break;
#endif
                case '%':
                    PUTC(*pcou8StrActChar);
                    break;
                default:
                        /* Nothing to be done. */
                    break;
            }
        }
        /* Normal character */
        else
        {
            PUTC(*pcou8StrActChar);
        }

        /* Move to next character */
        pcou8StrActChar++;
    }

    /* End the string and return length without terminating '\0' */
    *pu8StrRplc = (uint8)'\0';
    return pu8StrRplc - (uint8 *)str;
}

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#endif /* defined(NXP_LOG_ENABLED) */

#ifdef __cplusplus
}
#endif


===== 文件 [127/185]: src\oal_irq_autosar.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_OAL_IRQ
 * @{
 *
 * @file        oal_irq_autosar.c
 * @brief       The oal_irq module source file (AUTOSAR OS).
 * @details     This file contains AUTOSAR OS specific irq implementation.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "Std_Types.h"
#include "oal.h"
#include "hal.h"
#include "oal_irq.h"

/* LOCAL MACROS */
#define MAX_HANDLER_CNT 6U

/* TYPEDEFS */
/**
 * @brief   The IRQ instance representation
 */
struct oal_irq_tag
{
    sint32 id;
    bool_t created;
    oal_irq_flags_t flags;
    oal_irq_handler_t handler[MAX_HANDLER_CNT];
    void *data[MAX_HANDLER_CNT];
};

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* LOCAL VARIABLES */
static oal_irq_t irq_pool[Eth_43_PFE_IRQ_COUNT] = {0};

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================*/
/* GLOBAL FUNCTIONS */
void oal_irq_common_handler(oal_irq_idx_t idx)
{
    uint32 ctr;

    for(ctr=0U; ctr<MAX_HANDLER_CNT; ctr++)
    {
        if(NULL != irq_pool[idx].handler[ctr])
        {
            (void)irq_pool[idx].handler[ctr](irq_pool[idx].data[ctr]);
        }
    }
}

/*==================================================================================================*/
/* Not reentrant for same id */
oal_irq_t * oal_irq_create(sint32 id, oal_irq_flags_t flags, const char_t *name)
{
    oal_irq_t *ret_val = NULL;
    uint32 idx = (uint32)find_irq_idx_from_id(id);

    (void)name;
    if((idx < (uint32)Eth_43_PFE_IRQ_COUNT) && (FALSE == irq_pool[idx].created))
    {
        irq_pool[idx].created = TRUE;
        irq_pool[idx].id = id;
        irq_pool[idx].flags = flags;
        ret_val = &irq_pool[idx];
    }
    return ret_val;
}

/*==================================================================================================*/
errno_t oal_irq_add_handler(oal_irq_t *irq, oal_irq_handler_t handler, void *data, oal_irq_isr_handle_t *handle)
{
    errno_t ret_val = ENOMEM;
    uint32 ctr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == irq) || (NULL == handler)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Find unused handler entry */
        for(ctr=0U; ctr<MAX_HANDLER_CNT; ctr++)
        {
            if(NULL == irq->handler[ctr])
            {
                if(NULL != handle)
                {
                    *handle = ctr;
                }
                irq->handler[ctr] = handler;
                irq->data[ctr] = data;
                ret_val = EOK;
                break;
            }
        }
    }
    return ret_val;
}

/*==================================================================================================*/
errno_t oal_irq_del_handler(oal_irq_t *irq, oal_irq_isr_handle_t handle)
{
    errno_t ret_val = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == irq) || (handle >= MAX_HANDLER_CNT)))
    {
        NXP_LOG_ERROR("Invalid argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        irq->handler[handle] = NULL;
        irq->data[handle] = NULL;
    }
    return ret_val;
}

/*==================================================================================================*/
void oal_irq_destroy(oal_irq_t *irq)
{   /* Not possible in AUTOSAR OS */
    uint32 ctr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == irq))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        irq->created = FALSE;
        /* Remove all handlers */
        for(ctr=0U; ctr<MAX_HANDLER_CNT; ctr++)
        {
            irq->handler[ctr] = NULL;
            irq->data[ctr] = NULL;
        }
        irq->flags = (oal_irq_flags_t)0U;
    }
}

/*==================================================================================================*/
sint32 oal_irq_get_id(const oal_irq_t *irq)
{
    sint32 retval;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == irq))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        retval = -1;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        retval = irq->id;
    }
    return retval;
}

/*==================================================================================================*/
bool_t oal_irq_in_atomic(void)
{
    return FALSE;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/


===== 文件 [128/185]: src\oal_job_autosar.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_OAL_JOB
 * @{
 *
 * @file        oal_job_autosar.c
 * @brief       The oal_job module source file (AUTOSAR).
 * @details     This file contains AUTOSAR MCAL-specific (not)deferred job implementation.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "oal_job.h"
#include "hal.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

errno_t oal_job_run(oal_job_t *job)
{
    errno_t ret_val;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == job))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0 == autolibc_strcmp("HIF TX JOB", job->name))
        {
            oal_mutex_lock(PFE_HIF_TX_JOB_MUTEX);
        }

        if(NULL == job->func)
        {
            NXP_LOG_ERROR("Job pointer was NULL\n");
            ret_val = EINVAL;
        }
        else
        {
            /* Execute the job here, no extra threads in this implementation */
            job->func(job->arg);
            ret_val = EOK;
        }

        if (0 == autolibc_strcmp("HIF TX JOB", job->name))
        {
            oal_mutex_unlock(PFE_HIF_TX_JOB_MUTEX);
        }
    }
    return ret_val;
}

/* Not needed in current implementation (no asynchronous tasks) */
errno_t oal_job_drain(const oal_job_t *job)
{
    errno_t ret_val = EOK;

    (void)job;

    return ret_val;
}

oal_job_t *oal_job_create(oal_job_func func, void *arg, const char_t *name, oal_prio_t prio, oal_job_t *new_job)
{
    /* Not used in current implementation */
    oal_job_t *job = new_job;
    (void)prio;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == func) || (NULL == new_job)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        job = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        job->func = func;
        job->arg = arg;
        job->name = name;
    }
    return job;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/


===== 文件 [129/185]: src\oal_time_autosar.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_OAL_TIME
 * @{
 *
 * @file        oal_time_autosar.c
 * @brief       The oal_time module source file (AUTOSAR variant).
 * @details     This file contains AUTOSAR-MCAL-specific time management implementation.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal_types.h"
#include "oal_time.h"
#include "Tm.h" /* AUTOSAR Time Service */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================*/
void oal_time_usleep(uint32 usec)
{
    uint32 usec_ctr = usec;

    while(usec_ctr > 250U)
    {
        (void)Tm_BusyWait1us32bit(250U);
        usec_ctr -= 250U;
    }
    (void)Tm_BusyWait1us32bit(usec_ctr);
}

/*==================================================================================================*/
void oal_time_msleep(uint32 msec)
{
    uint32 u32Ctr;

    for(u32Ctr=0U; u32Ctr < msec; u32Ctr++)
    {
        oal_time_usleep(1000U);
    }
}

/*==================================================================================================*/
void oal_time_udelay(uint32 usec)
{
    oal_time_usleep(usec);
}

/*==================================================================================================*/
void oal_time_mdelay(uint32 msec)
{
    oal_time_msleep(msec);
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/


===== 文件 [130/185]: src\oal_util_autosar.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_OAL_UTIL
 * @{
 *
 * @file        oal_util_autosar.c
 * @brief       The oal_util module source file.
 * @details     This file contains utility management implementation.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include <stdarg.h>
#include "pfe_cfg.h"
#include "oal.h"
#include "autolibc.h"
#include "nxp_snprintf.h"
#include "oal_util.h"
#include "pfe_platform.h"
#include "Eth_43_PFE_Cfg.h"

#ifdef PFE_CFG_IEEE1588_SUPPORT
    #define L2_HDR_LEN          14U
    #define L2_HDR_VLAN_LEN     18U
    #define L3_HDR_IPv4_LEN     20U
    #define L3_HDR_IPv6_LEN     40U
    #define L4_HDR_UDP_LEN      8U

    #define IP_VERSION(base)  (((uint8 *)(base))[0U] >> 4U)
    #define IPV4_IHL(base)      (((uint8 *)(base))[0U] & 0xFU)
    #define IPV4_PROTOCOL(base) (((uint8 *)(base))[9U])
    #define IPV4_DST_ADDR(base) (oal_ntohl(((uint32 *)(base))[4U]))
    #define IPV4_SRC_ADDR(base) (oal_ntohl(((uint32 *)(base))[3U]))
    #define IPV6_PROTOCOL(base) (((uint8 *)(base))[6U])
    #define IPV6_DST_ADDR_PTR(base) ((uint8 *)(base) + 24U)
    #define IPV6_SRC_ADDR_PTR(base) ((uint8 *)(base) + 8U)
    #define UDP_SPORT(base) (oal_ntohs(((uint16 *)(base))[0U]))
    #define UDP_DPORT(base) (oal_ntohs(((uint16 *)(base))[1U]))

    #define ETHERTYPE_VLAN 0x8100U
    #define ETHERTYPE_PTP  0x88f7U
    #define ETHERTYPE_IPV4 0x0800U
    #define ETHERTYPE_IPV6 0x86ddU
    #define IPPROTOCOL_PTP 0x7bU
    #define IPPROTOCOL_UDP 0x11U

    #define ETH_43_PFE_START_SEC_CONST_8
    #include "Eth_43_PFE_MemMap.h"

    /* IPv6 */
    /* usage scope: oal_util_parse_ptp */
    static const uint8 primary_mcast[] = {0xffU, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0x1U, 0x81U};
    static const uint8 pdelay_mcast[] = {0xffU, 0x02U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0x6bU};

    #define ETH_43_PFE_STOP_SEC_CONST_8
    #include "Eth_43_PFE_MemMap.h"

    #define ETH_43_PFE_START_SEC_VAR_INIT_32
    #include "Eth_43_PFE_MemMap.h"

    /* usage scope: oal_util_get_unique_seqnum32*/
    static uint32 base = 0U;

    #define ETH_43_PFE_STOP_SEC_VAR_INIT_32
    #include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_IEEE1588_SUPPORT */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
#ifdef PFE_CFG_IEEE1588_SUPPORT
static errno_t check_ipv4_udp_header(addr_t hdr_addr);
static errno_t check_ipv6_udp_header(addr_t hdr_addr);
static errno_t oal_util_parse_ptp_l3(uint8 *buffer, uint32 len, uint8 l2_len, uint8 *l3_len, uint8 off);
#endif /* PFE_CFG_IEEE1588_SUPPORT */

/*==================================================================================================
*                                        LOCAL FUNCTIONS
==================================================================================================*/
#ifdef PFE_CFG_IEEE1588_SUPPORT
static errno_t check_ipv4_udp_header(addr_t hdr_addr)
{
    errno_t ret = ENOENT;

    if ((IPV4_PROTOCOL(hdr_addr) == IPPROTOCOL_UDP)
                    && (IP_VERSION(hdr_addr) == 4U)
                    && (IPV4_IHL(hdr_addr) == 5U)
                    && ( (IPV4_DST_ADDR(hdr_addr) == 0xE0000181UL)
                    || (IPV4_DST_ADDR(hdr_addr) == 0xE0000182UL)
                    || (IPV4_DST_ADDR(hdr_addr) == 0xE0000183UL)
                    || (IPV4_DST_ADDR(hdr_addr) == 0xE0000184UL)
                    || (IPV4_DST_ADDR(hdr_addr) == 0xE0000068UL)
                    ))
    {
        ret = EOK; /* IP OK, Continue parsing */
    }
    else
    {
        /* non-UDP */
    }

    return ret;
}
/*==================================================================================================*/

static errno_t check_ipv6_udp_header(addr_t hdr_addr)
{
    errno_t ret = ENOENT;

    if ((IPV6_PROTOCOL(hdr_addr) == IPPROTOCOL_UDP) && (IP_VERSION(hdr_addr) == 6U))
    {
        /* Intentionally omitted PTP version check. We do match both address variants (primary + pdelay) */
        if ((0 == autolibc_memcmp(&(IPV6_DST_ADDR_PTR(hdr_addr))[2U], &primary_mcast[2U], 14U))
        && ((IPV6_DST_ADDR_PTR(hdr_addr))[0U] == primary_mcast[0U])
        )
        {
            ret = EOK;/* IP OK, Continue parsing */
        }
        else if (0 == autolibc_memcmp(IPV6_DST_ADDR_PTR(hdr_addr), pdelay_mcast, 16U))
        {
            ret = EOK;/* IP OK, Continue parsing */
        }
        else
        {
            /* non-UDP */
        }
    }

    return ret;
}
#endif /* PFE_CFG_IEEE1588_SUPPORT */

/*==================================================================================================
*                                       GLOBAL FUNCTIONS
==================================================================================================*/
#ifdef PFE_CFG_IEEE1588_SUPPORT
/** Parse frame in 'buffer' and return l3_len if found */
static errno_t oal_util_parse_ptp_l3(uint8 *buffer, uint32 len, uint8 l2_len, uint8 *l3_len, uint8 off)
{
    addr_t hdr_addr;
    errno_t ret = ENOENT;

    hdr_addr = (addr_t)buffer + l2_len;
    if ((oal_ntohs(*((uint16 *)((addr_t)buffer + off))) == ETHERTYPE_IPV4)
            && (len >= ((uint32)l2_len + L3_HDR_IPv4_LEN)))
    {
        /* IPv4 */
        *l3_len = L3_HDR_IPv4_LEN;

        ret = check_ipv4_udp_header(hdr_addr);
    }
    else if ((oal_ntohs(*((uint16 *)((addr_t)buffer + off))) == ETHERTYPE_IPV6)
            && (len >= ((uint32)l2_len + L3_HDR_IPv6_LEN)))
    {
        *l3_len = L3_HDR_IPv6_LEN;

        ret = check_ipv6_udp_header(hdr_addr);
    }
    else
    {
        /* non-IP */
    }

    return ret;
}

/*==================================================================================================*/
/** Parse frame in 'buffer' and return pointer to PTP header if found */
errno_t oal_util_parse_ptp(uint8 *buffer, uint32 len, oal_util_ptp_header_t **ptph)
{
    uint8 l2_len;
    uint8 l3_len;
    uint8 l4_len;
    uint8 off = 0U;
    addr_t hdr_addr;
    errno_t ret = EOK;
    bool_t  fast_exit = FALSE;

    /* L2 check */
    if (len >= L2_HDR_LEN)
    {
        off = (oal_ntohs(*((uint16 *)((addr_t)buffer + 12U))) == ETHERTYPE_VLAN)
                ? 16U  /* skip L2+VLAN hdr */
                : 12U; /* skip L2 hdr */

        l2_len = off + 2U;

        if (oal_ntohs(*((uint16 *)((addr_t)buffer + off))) == ETHERTYPE_PTP)
        {
            /* PTP-over_Ethernet */
            *ptph = (oal_util_ptp_header_t *)((addr_t)buffer + l2_len);
            fast_exit = TRUE;
            ret = EOK;
        }
    }
    else
    {
        fast_exit = TRUE;
        ret = ENOENT;
    }

    if(TRUE != fast_exit)
    {
        /* L3 check */
        ret = oal_util_parse_ptp_l3(buffer, len, l2_len, &l3_len, off);
        if (EOK == ret)
        {
            /* L4 check */
            hdr_addr = (addr_t)buffer + l2_len + l3_len;
            l4_len = L4_HDR_UDP_LEN;
            if ((UDP_DPORT(hdr_addr) == 0x13fU) || (UDP_DPORT(hdr_addr) == 0x140U))
            {
                /* PTP-over-IP/UDP */
                *ptph = (oal_util_ptp_header_t *)((addr_t)buffer + l2_len + l3_len + l4_len);
                fast_exit = TRUE;
                ret = EOK;
            }

            if(TRUE != fast_exit)
            {
                /* PTP frame not found */
                ret = ENOENT;
            }
        }
    }
    return ret;
}
/*==================================================================================================*/
uint32 oal_util_get_unique_seqnum32(void)
{
    uint32 val;

    oal_mutex_lock(PFE_OAL_UTIL_SEQNUM_MUTEX);
    val = base;
    base = (uint32)(((uint64)base + 1U) & UINT32_MAX);  /* Expected to wrap */
    oal_mutex_unlock(PFE_OAL_UTIL_SEQNUM_MUTEX);

    return val;
}
#endif /* PFE_CFG_IEEE1588_SUPPORT */

#if defined(NXP_LOG_ENABLED)
/*==================================================================================================*/
uint32 oal_util_snprintf(char_t *buffer, uint32 buf_len, const char_t *format, ...)
{
    uint32 retval;
    va_list ap;

    va_start(ap, format);
    retval = (uint32)nxp_vsnprintf(buffer, buf_len, format, ap);
    va_end(ap);
    return retval;
}
#endif /* defined(NXP_LOG_ENABLED) */

/*==================================================================================================*/
/**
* @brief This function is used to raise DEM event for driver runtime errors
*/
void oal_util_raise_dem_for_drv_runtime_err(void)
{
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
    (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_DRIVER_RUNTIME_ERR_INTERNAL, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
}


#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/


===== 文件 [131/185]: src\oal_util_net_autosar.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 * 
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_OAL_UTIL_NET_AUTOSAR
 * @{
 *
 * @file        oal_util_net_autosar.c
 * @brief       The oal_util_net_autosar module source file.
 * @details     This file contains network utility implementation for AUTOSAR.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal_types.h"
#include "oal_util.h"
#include "oal_util_net.h"

#if (PFE_CFG_VERBOSITY_LEVEL >= 8)
#ifdef NXP_LOG_ENABLED

struct in6_addr {
    union {
        uint8       u6_addr8[16];
        uint16      u6_addr16[8];
        uint32      u6_addr32[4];
    } in6_u;
#define s6_addr         in6_u.u6_addr8
#define s6_addr16       in6_u.u6_addr16
#define s6_addr32       in6_u.u6_addr32
};

#define NIP4(addr) \
        ((const uint8 *)addr)[0], \
        ((const uint8 *)addr)[1], \
        ((const uint8 *)addr)[2], \
        ((const uint8 *)addr)[3]

#define NIP6(addr) \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[0]), \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[1]), \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[2]), \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[3]), \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[4]), \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[5]), \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[6]), \
        oal_ntohs(((const struct in6_addr *)addr)->s6_addr16[7])

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

char_t *oal_util_net_inet_ntop(sint32 af, const void *src, char_t *dst, uint32 size)
{
    sint32 ret;

    switch(af) {
        case AF_INET:
            ret = nxp_snprintf(dst, size, "%d.%d.%d.%d", NIP4(src));
            break;
        case AF_INET6:
            ret = nxp_snprintf(dst, size, "%d.%d.%d.%d.%d.%d.%d.%d", NIP6(src));
            break;
        default:
            ret = -EAFNOSUPPORT;
            break;
    }

    return (ret > 0) ? dst : NULL;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* NXP_LOG_ENABLED */
#endif /* PFE_CFG_VERBOSITY_LEVEL */


/** @}*/


===== 文件 [132/185]: src\pfe_bmu.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_platform_cfg.h"
#include "pfe_bmu.h"
#include "pfe_bmu_csr.h"

/* Configuration check */
#if ((PFE_CFG_BMU1_LMEM_BASEADDR + PFE_CFG_BMU1_LMEM_SIZE) > CBUS_LMEM_SIZE)
    #error BMU1 buffers exceed LMEM capacity
#endif

struct pfe_bmu_tag
{
    addr_t cbus_base_va;        /*    CBUS base virtual address */
    addr_t bmu_base_va;        /*    BMU base address (virtual) */
    addr_t pool_va_offset;    /*    Pre-calculated VA-PA conversion offset */
    addr_t pool_base_va;
    addr_t pool_base_pa;
    addr_t pool_size;
    addr_t bmu_base_offset;    /*    BMU base offset within CBUS space */
    uint32 buf_size;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_bmu_t bmu_instance[PFE_BMU_INSTANCES];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       BMU ISR
 * @param[in]   bmu The BMU instance
 * @return      EOK if interrupt has been handled
 */
__attribute__((cold)) errno_t pfe_bmu_isr(pfe_bmu_t *bmu)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_bmu_cfg_isr(bmu->bmu_base_va, bmu->cbus_base_va);
    }

    return ret;
}

/**
 * @brief       Mask BMU interrupts
 * @param[in]   bmu The BMU instance
 */
void pfe_bmu_irq_mask(pfe_bmu_t *bmu)
{
    pfe_bmu_cfg_irq_mask(bmu->bmu_base_va);
}

/**
 * @brief       Unmask BMU interrupts
 * @param[in]   hif The BMU instance
 */
void pfe_bmu_irq_unmask(pfe_bmu_t *bmu)
{
    pfe_bmu_cfg_irq_unmask(bmu->bmu_base_va);
}

/**
 * @brief       Create new BMU instance
 * @details     Creates and initializes BMU instance. New instance is disabled and needs
 *              to be enabled by pfe_bmu_enable().
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   bmu_base BMU base address offset within CBUS address space
 * @param[in]   cfg The BMU block configuration
 * @param[in]   bmu_index The BMU index to be initialized
 * @return      The BMU instance or NULL if failed
 */
__attribute__((cold)) pfe_bmu_t *pfe_bmu_create(addr_t cbus_base_va, addr_t bmu_base, const pfe_bmu_cfg_t *cfg, uint32 bmu_index)
{
    pfe_bmu_t *bmu;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == cfg) || (NULL_ADDR == cbus_base_va)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bmu = NULL;
    }
    else if (unlikely(NULL_ADDR == cfg->pool_pa))
    {
        NXP_LOG_ERROR("Buffer pool base is NULL\n");
        bmu = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (unlikely(PFE_BMU_INSTANCES <= bmu_index))
        {
            NXP_LOG_ERROR("BMU index out of range\n");
            bmu = NULL;
        }
        else
        {
            bmu = &bmu_instance[bmu_index];
            (void)autolibc_memset(bmu, 0, sizeof(pfe_bmu_t));
            bmu->cbus_base_va = cbus_base_va;
            bmu->bmu_base_offset = bmu_base;
            bmu->bmu_base_va = ADDR_BASE_OFFSET(bmu->cbus_base_va, bmu->bmu_base_offset);
            bmu->pool_base_pa = cfg->pool_pa;
            bmu->pool_base_va = cfg->pool_va;
            bmu->pool_va_offset = OFFSET_ADDR_BASE(bmu->pool_base_va, bmu->pool_base_pa);

            PfeDevAssert((UINT32_MAX / cfg->max_buf_cnt) >= cfg->buf_size);
            bmu->pool_size = cfg->buf_size * cfg->max_buf_cnt;
            bmu->buf_size = cfg->buf_size;

            pfe_bmu_reset(bmu);

            pfe_bmu_cfg_disable(bmu->bmu_base_va);
            pfe_bmu_cfg_init(bmu->bmu_base_va, cfg);
        }
    }

    return bmu;
}

/**
 * @brief       Reset the BMU block
 * @param[in]   bmu The BMU instance
 */
__attribute__((cold)) void pfe_bmu_reset(pfe_bmu_t *bmu)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_bmu_cfg_reset(bmu->bmu_base_va);

        if (ETIMEDOUT == ret)
        {
            NXP_LOG_WARNING("BMU reset timed-out\n");
        }
        else if (EOK != ret)
        {
            NXP_LOG_WARNING("BMU reset failed: 0x%x\n", ret);
        }
        else
        {
            /*Do Nothing*/
            ;
        }
    }
}

/**
 * @brief       Enable the BMU block
 * @param[in]   bmu The BMU instance
 */
__attribute__((cold)) void pfe_bmu_enable(pfe_bmu_t *bmu)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_bmu_cfg_enable(bmu->bmu_base_va);
    }
}

/**
 * @brief       Disable the BMU block
 * @param[in]   bmu The BMU instance
 */
__attribute__((cold)) void pfe_bmu_disable(pfe_bmu_t *bmu)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_bmu_cfg_disable(bmu->bmu_base_va);
    }
}

/**
 * @brief       Allocate buffer via BMU
 * @param[in]   bmu The BMU instance
 * @return      Allocated buffer pointer (physical)
 * @note        Thread safe
 */
__attribute__((hot)) void *pfe_bmu_alloc_buf(const pfe_bmu_t *bmu)
{
    void *ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  No resource protection here since it is done by register read */
        ret = (void *)pfe_bmu_cfg_alloc_buf(bmu->bmu_base_va);
    }

    return ret;
}

/**
 * @brief       Convert physical buffer address to virtual one
 * @param[in]   bmu The BMU instance
 * @param[in]   pa The address to be converted
 * @return      Associated virtual address or NULL if failed
 */
__attribute__((hot, pure)) void *pfe_bmu_get_va(const pfe_bmu_t *bmu, addr_t pa)
{
    void * ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (ADDR_BASE_OFFSET(bmu->pool_base_pa, bmu->pool_size) < pa)
        {
            /*  TODO: The condition is not sufficient and need to consider buffer size... */
            NXP_LOG_DEBUG("PA out of range\n");
        }
        ret = (void *)(pa + bmu->pool_va_offset);
    }

    return ret;
}

/**
 * @brief       Convert virtual buffer address to physical one
 * @param[in]   bmu The BMU instance
 * @param[in]   pa The address to be converted
 * @return      Associated virtual address or NULL if failed
 */
__attribute__((hot, pure)) void *pfe_bmu_get_pa(const pfe_bmu_t *bmu, addr_t va)
{
    void * ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (ADDR_BASE_OFFSET(bmu->pool_base_va, bmu->pool_size) < va)
        {
            /*  TODO: The condition is not sufficient and need to consider buffer size... */
            NXP_LOG_DEBUG("VA out of range\n");
        }
        ret = (void *)(va - bmu->pool_va_offset);
    }

    return ret;
}

/**
 * @brief       Free buffer via BMU
 * @param[in]   bmu The BMU instance
 * @param[in]   buffer Pointer (physical) to the buffer to be freed.
 * @note        Thread safe
 */
__attribute__((hot)) void pfe_bmu_free_buf(const pfe_bmu_t *bmu, addr_t buffer)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bmu) || (NULL_ADDR == buffer)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  No resource protection here since it is done by register write */
        pfe_bmu_cfg_free_buf(bmu->bmu_base_va, PFE_CFG_MEMORY_PHYS_TO_PFE(buffer));
    }
}

/**
 * @brief       Destroy BMU instance
 * @param[in]   bmu The BMU instance
 */
__attribute__((cold)) void pfe_bmu_destroy(pfe_bmu_t *bmu)
{
    if (NULL != bmu)
    {
        pfe_bmu_cfg_disable(bmu->bmu_base_va);
        pfe_bmu_cfg_fini(bmu->bmu_base_va);
    }
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return BMU runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   bmu         The BMU instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
__attribute__((cold)) uint32 pfe_bmu_get_text_statistics(const pfe_bmu_t *bmu, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += pfe_bmu_cfg_get_text_stat(bmu->bmu_base_va, buf, buf_len, verb_level);
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get BMU statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the bmu block.
 * @param[in]   bmu   The BMU instance
 * @param[in]   stat_id  required statistic (offset or register)
 * @return      if possible to get statistics, otherwise return PFE_INVALID_STAT
 *              when bmu is NULL
 */
uint32 pfe_bmu_get_stat_value(const pfe_bmu_t* bmu, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = PFE_INVALID_STAT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = pfe_bmu_cfg_get_stat_value(bmu->bmu_base_va, stat_id);
    }
    return stat_value;
}

/**
 * @brief       Get BMU statistic in numeric form for special registers
 * @details     This is a HW-specific function providing single statistic
 *              value from the bmu block.
 * @param[in]   bmu   The BMU instance
 * @param[out]  special_stats special statistic
 * @return      EOK if possible to get special statistics, otherwise return EINVAL
 *              when bmu or special_stats is NULL 
 */
errno_t pfe_bmu_get_special_stats(const pfe_bmu_t* bmu, pfe_bmu_stats_special_t* special_stats)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bmu) || unlikely(NULL == special_stats))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_bmu_cfg_get_special_stats(bmu->bmu_base_va, special_stats);
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [133/185]: src\pfe_bmu_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "Eth_43_PFE.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_bmu_csr.h"
#include "Eth_43_PFE_Cfg.h"


#define IS_POWER_OF_2(n) (((n) != 0U) && (((n) & ((n) - 1U)) == 0U))

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/

static void pfe_bmu_cfg_clear_buf_cnt_memory(addr_t base_va, uint32 cnt);
static void pfe_bmu_cfg_clear_internal_memory(addr_t base_va, uint32 cnt);

/*==================================================================================================
*                                        LOCAL FUNCTIONS
==================================================================================================*/
static void pfe_bmu_cfg_clear_buf_cnt_memory(addr_t base_va, uint32 cnt)
{
    uint32 ii;

    for (ii=0U; ii<cnt; ii++)
    {
        hal_write32(ii, base_va + BMU_BUF_CNT_MEM_ACCESS_ADDR);
        hal_write32(0U, base_va + BMU_BUF_CNT_MEM_ACCESS);
        hal_write32(0U, base_va + BMU_BUF_CNT_MEM_ACCESS2);
    }
}

/* ============================================================================================== */
static void pfe_bmu_cfg_clear_internal_memory(addr_t base_va, uint32 cnt)
{
    uint32 ii;

    for (ii=0U; ii<cnt; ii++)
    {
        hal_write32(ii, base_va + BMU_INT_MEM_ACCESS_ADDR);
        hal_write32(0U, base_va + BMU_INT_MEM_ACCESS);
        hal_write32(0U, base_va + BMU_INT_MEM_ACCESS2);
    }
}

/*==================================================================================================
*                                        GLOBAL FUNCTIONS
==================================================================================================*/
/**
 * @brief       BMU ISR
 * @details     MASK, ACK, and process triggered interrupts.
 *              Every BMU instance has its own handler. Access to registers is
 *              protected by mutex implemented within the BMU module (pfe_bmu.c).
 * @param[in]   base_va BMU register space base address (virtual)
 * @param[in]   cbus_base_va CBUS base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Make sure the call is protected by some per-BMU mutex
 */
errno_t pfe_bmu_cfg_isr(addr_t base_va, addr_t cbus_base_va)
{
    uint32 reg_src, reg_en, reg, reg_reen = 0U;
    errno_t ret = ENOENT;
    addr_t bmu_offset = OFFSET_ADDR_BASE(base_va, cbus_base_va);

#ifndef NXP_LOG_ENABLED
    (void)bmu_offset;
#endif /* NXP_LOG_ENABLED */

    /*  Get enabled interrupts */
    reg_en = hal_read32(base_va + BMU_INT_ENABLE);
    /*  Disable ALL */
    hal_write32(0U, base_va + BMU_INT_ENABLE);
    /*  Get triggered interrupts */
    reg_src = hal_read32(base_va + BMU_INT_SRC);
    /*  ACK triggered */
    hal_write32(reg_src, base_va + BMU_INT_SRC);
    /*  Enable the non-triggered ones. Keep the master and error interrupt bits set. */
    hal_write32((reg_en & ~reg_src)|BMU_FREE_ERR_INT, base_va + BMU_INT_ENABLE);

    /*  Process interrupts which are triggered AND enabled */
    if ((reg_src & reg_en & BMU_EMPTY_INT) != 0U)
    {
        /*  This means that zero buffers are allocated from the BMU pool,
            i.e. all buffers are free, i.e. number of allocated buffers is
            zero. */
        NXP_LOG_INFO("BMU_EMPTY_INT (BMU @ p0x%p). Pool ready.\n", (void *)bmu_offset);

        /*  Stay disabled but re-enable the "threshold" and "full" interrupt */
        reg_reen |= BMU_THRES_INT|BMU_FULL_INT;
        ret = EOK;
    }

    if ((reg_src & reg_en & BMU_FULL_INT) != 0U)
    {
        /*  All BMU buffers are allocated, i.e. no new buffer can be allocated. */
        pfe_hm_report_error(HM_SRC_BMU, HM_EVT_BMU_FULL, "(BMU @ p0x%p)", (void *)bmu_offset);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_BMU_FULL, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

        /*  Stay disabled but re-enable the "empty" interrupt */
        reg_reen |= BMU_EMPTY_INT;
        ret = EOK;
    }

    if ((reg_src & reg_en & BMU_THRES_INT) != 0U)
    {
        /*  More (or equal) than "threshold" number of buffers have been
            allocated. Read and print the threshold value. Stay disabled. */
        reg = hal_read32(base_va + BMU_THRES);
        NXP_LOG_INFO("BMU_THRES_INT (BMU @ p0x%p). Pool being depleted. Threshold: %u.\n", (void *)bmu_offset, ((uint_t)reg & 0xffffU));

        /*  Stay disabled but re-enable the "empty" interrupt */
        reg_reen |= BMU_EMPTY_INT;
        ret = EOK;
    }

    if ((reg_src & reg_en & BMU_FREE_ERR_INT) != 0U)
    {
        /*  Free error interrupt. Keep this one always enabled */
        pfe_hm_report_error(HM_SRC_BMU, HM_EVT_BMU_FREE_ERR, "(BMU @ p0x%p) address 0x%x", (void *)bmu_offset, (uint_t)hal_read32(base_va + BMU_FREE_ERROR_ADDR));
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_BMU_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
        ret = EOK;
    }

    if ((reg_src & reg_en & (BMU_MCAST_EMPTY_INT|BMU_MCAST_FULL_INT|BMU_MCAST_THRES_INT|BMU_MCAST_FREE_ERR_INT)) != 0U)
    {
        /*  This should never happen. TRM says that all BMU_MCAST_* flags are reserved and always 0 */
        pfe_hm_report_error(HM_SRC_BMU, HM_EVT_BMU_MCAST, "(BMU @ p0x%p)", (void *)bmu_offset);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_BMU_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
        ret = EOK;
    }

    /*  Re-enable requested interrupts */
    if (0U != reg_reen)
    {
        reg = hal_read32(base_va + BMU_INT_ENABLE);
        hal_write32(reg|reg_reen, base_va + BMU_INT_ENABLE);
    }

    return ret;
}

/**
 * @brief       Mask BMU interrupts
 * @param[in]   base_va Base address of the BMU register space (virtual)
 * @note        Make sure the call is protected by some per-BMU mutex
 */
void pfe_bmu_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    /*  Mask group */
    reg = hal_read32(base_va + BMU_INT_ENABLE) & ~(BMU_INT);
    hal_write32(reg, base_va + BMU_INT_ENABLE);
}

/**
 * @brief       Unmask BMU interrupts
 * @param[in]   base_va Base address of the BMU register space (virtual)
 * @note        Make sure the call is protected by some per-BMU mutex
 */
void pfe_bmu_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    /*  Unmask group */
    reg = hal_read32(base_va + BMU_INT_ENABLE) | BMU_INT;
    hal_write32(reg, base_va + BMU_INT_ENABLE);
}

/**
 * @brief       Initialize and configure the BMU block
 * @param[in]   base_va Base address of the BMU register space (virtual)
 * @param[in]   cfg Pointer to the configuration structure
 */
void pfe_bmu_cfg_init(addr_t base_va, const pfe_bmu_cfg_t *cfg)
{
    uint32 bmu_buf_size_exp;

    if (unlikely(FALSE == IS_POWER_OF_2(cfg->buf_size)))
    {
        NXP_LOG_ERROR("BMU buffer size is not power of 2\n");
    }
    else
    {
        hal_write32(0U, base_va + BMU_CTRL);
        hal_write32(0x0U, base_va + BMU_INT_ENABLE);
        hal_write32(0xffffffffU, base_va + BMU_INT_SRC);

        hal_write32((uint32)(cfg->pool_pa & 0xffffffffU), base_va + BMU_UCAST_BASEADDR);
        hal_write32(cfg->max_buf_cnt & 0xffffU, base_va + BMU_UCAST_CONFIG);

        for(bmu_buf_size_exp = 0; bmu_buf_size_exp < (sizeof(cfg->buf_size) * 8U); bmu_buf_size_exp++)
        {
            if(cfg->buf_size == (1UL << bmu_buf_size_exp))
            {
                hal_write32(bmu_buf_size_exp & 0xffffU, base_va + BMU_BUF_SIZE);
                break;
            }
        }

        /*  Thresholds. 75% of maximum number of available buffers. */
        hal_write32((cfg->max_buf_cnt * 75U) / 100U, base_va + BMU_THRES);

        /*  Low Watermark for pause frame generation start 5% of free buffers. */
        hal_write32((cfg->max_buf_cnt * 5U) / 100U, base_va + BMU_LOW_WATERMARK);
        /*  High Watermark for pause frame generation stop 10% of free buffers. */
        hal_write32((cfg->max_buf_cnt * 10U) / 100U, base_va + BMU_HIGH_WATERMARK);

        pfe_bmu_cfg_clear_internal_memory(base_va, cfg->int_mem_loc_cnt);
        pfe_bmu_cfg_clear_buf_cnt_memory(base_va, cfg->buf_mem_loc_cnt);

        /*  Enable BMU interrupts except the global enable bit */
        hal_write32(0xffffffffU & ~(BMU_INT), base_va + BMU_INT_ENABLE);
    }
}

/**
 * @brief       Finalize the BMU
 * @param[in]   base_va Base address of HIF register space (virtual)
 */
void pfe_bmu_cfg_fini(addr_t base_va)
{
    hal_write32(0U, base_va + BMU_CTRL);
    hal_write32(0x0U, base_va + BMU_INT_ENABLE);
    hal_write32(0xffffffffU, base_va + BMU_INT_SRC);
}

/**
 * @brief       BMU reset
 * @param[in]   base_va Base address of the BMU register space (virtual)
 * @return      EOK if success or error code otherwise
 */
errno_t pfe_bmu_cfg_reset(addr_t base_va)
{
    uint32 ii = 0U;
    errno_t ret = EOK;

    hal_write32(0x2U, base_va + BMU_CTRL);
    while ((hal_read32(base_va + BMU_CTRL) & 0x2U) != 0U)
    {
        if (++ii > 1000U)
        {
            ret = ETIMEDOUT;
            break;
        }
        else
        {
            oal_time_usleep(10U);
        }
    }

    return ret;
}

/**
 * @brief       Enable the BMU block
 * @param[in]   base_va Base address of the BMU register space (virtual)
 */
void pfe_bmu_cfg_enable(addr_t base_va)
{
    hal_write32(0x1U, base_va + BMU_CTRL);
}

/**
 * @brief       Disable the BMU block
 * @param[in]   base_va Base address of the BMU register space (virtual)
 */
void pfe_bmu_cfg_disable(addr_t base_va)
{
    hal_write32(0x0U, base_va + BMU_CTRL);
}

/**
 * @brief       Allocate buffer from BMU
 * @param[in]   base_va Base address of the BMU register space (virtual)
 * @return      Pointer to the allocated buffer
 */
void * pfe_bmu_cfg_alloc_buf(addr_t base_va)
{
    return (void *)(addr_t)hal_read32(base_va + BMU_ALLOC_CTRL);
}

/**
 * @brief       Free a previously allocated buffer
 * @param[in]   base_va Base address of the BMU register space (virtual)
 * @param[in]   buffer Pointer to the buffer to be released
 */
void pfe_bmu_cfg_free_buf(addr_t base_va, addr_t buffer)
{
    hal_write32((uint32)(buffer & 0xffffffffU), base_va + BMU_FREE_CTRL);
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Get BMU statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the BMU block.
 * @param[in]   base_va Base address of BMU register space (virtual)
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_bmu_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;
    uint32 reg, ii;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received (pfe_bmu_cfg_get_text_stat)\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(verb_level >= 10U)
        {
            len += (uint32)oal_util_snprintf(buf + len, size - len, "BMU_REM_BUF_CNT     : 0x%x\n", hal_read32(base_va + BMU_REM_BUF_CNT));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "BMU_FREE_ERROR_ADDR : 0x%x\n", hal_read32(base_va + BMU_FREE_ERROR_ADDR));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "BMU_CURR_BUF_CNT    : 0x%x\n", hal_read32(base_va + BMU_CURR_BUF_CNT));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "BMU_DEBUG_BUS       : 0x%x\n", hal_read32(base_va + BMU_DEBUG_BUS));
        }

        if(verb_level >= 9U)
        {
            /*  Get version */
            reg = hal_read32(base_va + BMU_VERSION);
            len += (uint32)oal_util_snprintf(buf + len, size - len, "Revision             : 0x%x\n", (reg >> 24) & 0xffU);
            len += (uint32)oal_util_snprintf(buf + len, size - len, "Version              : 0x%x\n", (reg >> 16) & 0xffU);
            len += (uint32)oal_util_snprintf(buf + len, size - len, "ID                   : 0x%x\n", reg & 0xffffU);
        }
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Buffer Base (uc)     : p0x%x\n", (uint32)hal_read32(base_va + BMU_UCAST_BASEADDR));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Buffer Size          : 0x%x\n", 1U << hal_read32(base_va + BMU_BUF_SIZE));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Buffers Remaining    : 0x%x\n", hal_read32(base_va + BMU_REM_BUF_CNT));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Buffers Allocated    : 0x%x\n", hal_read32(base_va + BMU_CURR_BUF_CNT));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Low Watermark        : 0x%x\n", hal_read32(base_va + BMU_LOW_WATERMARK));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "High Watermark       : 0x%x\n", hal_read32(base_va + BMU_HIGH_WATERMARK));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "IRQ Threshold (uc)   : 0x%x\n", hal_read32(base_va + BMU_THRES) & 0xffffU);
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Free Error Address   : 0x%x\n", hal_read32(base_va + BMU_FREE_ERROR_ADDR));
        reg = hal_read32(base_va + BMU_BUF_CNT);
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Free Error Count     : 0x%x\n", reg >> 16);
        len += (uint32)oal_util_snprintf(buf + len, size - len, "Active Buffers       : 0x%x\n", reg & 0xffffU);

        len += (uint32)oal_util_snprintf(buf + len, size - len, "IRQ Source           : 0x%x\n", hal_read32(base_va + BMU_INT_SRC));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "IRQ Enable           : 0x%x\n", hal_read32(base_va + BMU_INT_ENABLE));

        for (ii=0; ii<32U; ii++)
        {
            reg = hal_read32(base_va + BMU_MAS0_BUF_CNT + (4U*ii));
            if (0U != reg)
            {
                len += (uint32)oal_util_snprintf(buf + len, size - len, "MASTER%02d Count       : 0x%x\n", ii, reg);
            }
        }
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get BMU statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the BMU block.
 * @param[in]   base_va  Base address of BMU register space (virtual)
 * @param[in]   stat_id  ID of required statistic (offset of register)
 * @return      Value of requested statistic or PFE_INVALID_STAT as an error
 */
uint32 pfe_bmu_cfg_get_stat_value(addr_t base_va, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = PFE_INVALID_STAT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = hal_read32(base_va + stat_id);
    }
    return stat_value;
}

/**
 * @brief       Get BMU statistic in numeric form for special registers
 * @details     This is a HW-specific function providing single statistic
 *              value from the BMU block.
 * @param[in]   base_va     Base address of BMU register space (virtual)
 * @param[out]  special_stats  Point to required special statistic
 */
void pfe_bmu_cfg_get_special_stats(addr_t base_va, pfe_bmu_stats_special_t* special_stats)
{
    special_stats->revision = (pfe_bmu_cfg_get_stat_value(base_va, BMU_VERSION)>>24) & 0xFFU;
    special_stats->version = (pfe_bmu_cfg_get_stat_value(base_va, BMU_VERSION)>>16) & 0xFFU;
    special_stats->id = pfe_bmu_cfg_get_stat_value(base_va, BMU_VERSION) & 0xFFU;
    special_stats->free_error_cnt = pfe_bmu_cfg_get_stat_value(base_va, BMU_BUF_CNT) >> 16;
    special_stats->buff_size =  1UL << pfe_bmu_cfg_get_stat_value(base_va, BMU_BUF_SIZE);
    special_stats->active_buff = pfe_bmu_cfg_get_stat_value(base_va, BMU_BUF_CNT) & 0XFFFFU;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [134/185]: src\pfe_bus_err.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_bus_err.h"
#include "pfe_bus_err_csr.h"

struct pfe_bus_err_tag
{
    addr_t cbus_base_va;
    addr_t bus_err_base_offset;
    addr_t bus_err_base_va;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_bus_err_t bus_err_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create new BUS_ERR instance
 * @details     Create and initializes BUS_ERR instance. New instance is always enabled.
 *              Use mask and unmask function to control interrupts.
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   bus_err_base BUS_ERR base address offset within CBUS address space
 * @return      EOK if interrupt has been handled, error code otherwise
 * @return      The BUS_ERR instance or NULL if failed
 */
pfe_bus_err_t *pfe_bus_err_create(addr_t cbus_base_va, addr_t bus_err_base)
{
    pfe_bus_err_t *bus_err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bus_err = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        bus_err = &bus_err_instance;
        (void)autolibc_memset(bus_err, 0, sizeof(pfe_bus_err_t));
        bus_err->cbus_base_va = cbus_base_va;
        bus_err->bus_err_base_offset = bus_err_base;
        bus_err->bus_err_base_va = ADDR_BASE_OFFSET(bus_err->cbus_base_va, bus_err->bus_err_base_offset);

        /* Unmask all interrupts */
        pfe_bus_err_cfg_irq_unmask_all(bus_err->bus_err_base_va);
    }

    return bus_err;
}

/**
 * @brief       Destroy BUS_ERR instance
 * @param[in]   bus_err The BUS_ERR instance
 */
void pfe_bus_err_destroy(pfe_bus_err_t *bus_err)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bus_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Mask bus_err interrupts */
        pfe_bus_err_cfg_irq_mask(bus_err->bus_err_base_va);
    }
}

/**
 * @brief       BUS_ERR ISR
 * @param[in]   bus_err The BUS_ERR instance
 * @return      EOK if interrupt has been handled
 */
errno_t pfe_bus_err_isr(const pfe_bus_err_t *bus_err)
{
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bus_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = ENOMEM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_bus_err_cfg_isr(bus_err->bus_err_base_va);
    }

    return ret;
}

/**
 * @brief       Mask BUS_ERR interrupts
 * @param[in]   bus_err The BUS_ERR instance
 */
void pfe_bus_err_irq_mask(const pfe_bus_err_t *bus_err)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bus_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_bus_err_cfg_irq_mask(bus_err->bus_err_base_va);
    }
}

/**
 * @brief       Unmask BUS_ERR interrupts
 * @param[in]   bus_err The BUS_ERR instance
 */
void pfe_bus_err_irq_unmask(const pfe_bus_err_t *bus_err)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bus_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_bus_err_cfg_irq_unmask(bus_err->bus_err_base_va);
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [135/185]: src\pfe_bus_err_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_bus_err_csr.h"
#include "pfe_global_wsp.h"
#include "Eth_43_PFE_Cfg.h"

#define BUS_ERR_INT_SRC_NUMBER   20U
#define TRIG_EN_INTERRUPTS_CHECK   (M1_BUS_RD_ERR_INT | M2_BUS_WR_ERR_INT | M3_BUS_WR_ERR_INT | M4_BUS_RD_ERR_INT | \
                                    HGPI_BUS_RD_ERR_INT | HGPI_BUS_WR_ERR_INT | EGPI0_BUS_RD_ERR_INT | EGPI0_BUS_WR_ERR_INT | \
                                    EGPI1_BUS_RD_ERR_INT | EGPI1_BUS_WR_ERR_INT | EGPI2_BUS_RD_ERR_INT | EGPI2_BUS_WR_ERR_INT | \
                                    CLASS_BUS_RD_ERR_INT | CLASS_BUS_WR_ERR_INT | HIF_NOCPY_BUS_RD_ERR_INT | HIF_NOCPY_BUS_WR_ERR_INT | \
                                    TMU_BUS_RD_ERR_INT | FET_BUS_RD_ERR_INT | UPE_BUS_RD_ERR_INT | UPE_BUS_WR_ERR_INT \
                                   )

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       BUS_ERR ISR
 * @details     MASK, ACK, and process triggered interrupts.
 * @param[in]   base_va BUS_ERR register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 */
errno_t pfe_bus_err_cfg_isr(addr_t base_va)
{
    uint32 reg_en, reg_src;
    errno_t ret = ENOENT;
    uint32 trig_en_interrupts;
    uint8 index = 0U;

    static const pfe_hm_evt_t event_id[BUS_ERR_INT_SRC_NUMBER] =
    {
        HM_EVT_BUS_MASTER1,
        HM_EVT_BUS_MASTER2,
        HM_EVT_BUS_MASTER3,
        HM_EVT_BUS_MASTER4,
        HM_EVT_BUS_HGPI_READ,
        HM_EVT_BUS_HGPI_WRITE,
        HM_EVT_BUS_EMAC0_READ,
        HM_EVT_BUS_EMAC0_WRITE,
        HM_EVT_BUS_EMAC1_READ,
        HM_EVT_BUS_EMAC1_WRITE,
        HM_EVT_BUS_EMAC2_READ,
        HM_EVT_BUS_EMAC2_WRITE,
        HM_EVT_BUS_CLASS_READ,
        HM_EVT_BUS_CLASS_WRITE,
        HM_EVT_BUS_HIF_NOCPY_READ,
        HM_EVT_BUS_HIF_NOCPY_WRITE,
        HM_EVT_BUS_TMU,
        HM_EVT_BUS_FET,
        HM_EVT_BUS_UTIL_PE_READ,
        HM_EVT_BUS_UTIL_PE_WRITE,
    };

    /*  Get enabled interrupts */
    reg_en = hal_read32(base_va + WSP_BUS_ERR_INT_EN);
    /* Mask bus error interrupts */
    hal_write32((reg_en & ~(BUS_ERR_INT_EN)), base_va + WSP_BUS_ERR_INT_EN);
    /*  Get triggered interrupts */
    reg_src = hal_read32(base_va + WSP_BUS_ERR_INT_SRC);
    /*  ACK triggered interrupts*/
    hal_write32(reg_src, base_va + WSP_BUS_ERR_INT_SRC);

    /* Process interrupts which are triggered AND enabled */
    trig_en_interrupts = reg_src & reg_en & TRIG_EN_INTERRUPTS_CHECK;
    if (0U != trig_en_interrupts)
    {
        trig_en_interrupts >>= 1U;
        while (0U != trig_en_interrupts)
        {
            PfeDevAssert(index < BUS_ERR_INT_SRC_NUMBER);

            if (0U != (trig_en_interrupts & 1UL))
            {
                pfe_hm_report_error(HM_SRC_BUS, event_id[index], "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
                (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_BUS_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
            }
            trig_en_interrupts >>= 1U;
            index++;
        }
        ret = EOK;
    }

    /*  Enable the non-triggered ones only to prevent flooding */
    hal_write32((reg_en & ~reg_src), base_va + WSP_BUS_ERR_INT_EN);

    return ret;
}

/**
 * @brief       Mask BUS_ERR interrupts
 * @param[in]   base_va Base address of the BUS_ERR register space
 */
void pfe_bus_err_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_BUS_ERR_INT_EN) & ~(BUS_ERR_INT_EN);
    hal_write32(reg, base_va + WSP_BUS_ERR_INT_EN);
}

/**
 * @brief       Unmask BUS_ERR interrupts
 * @param[in]   base_va Base address of the BUS_ERR register space
 */
void pfe_bus_err_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_BUS_ERR_INT_EN) | BUS_ERR_INT_EN;
    hal_write32(reg, base_va + WSP_BUS_ERR_INT_EN);
}

/**
 * @brief       Unmask all BUS_ERR interrupts
 * @param[in]   base_va Base address of the BUS_ERR register space
 * @note        This function is called from thread.
 */
void pfe_bus_err_cfg_irq_unmask_all(addr_t base_va)
{
    hal_write32(BUS_ERR_INT_ENABLE_ALL, base_va + WSP_BUS_ERR_INT_EN); /*direct write*/
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [136/185]: src\pfe_class.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_pe.h"
#include "pfe_class.h"
#include "pfe_class_csr.h"
#include "blalloc.h"
#include "fci.h"
#include "fpp.h"
#include "fpp_ext.h"

/* Configures size of the dmem heap allocator chunk (the smallest allocated memory size)
* The size is actually 2^configured value: 1 means 2, 2 means 4, 3 means 8, 4 means 16 etc.
* Do not configure less than 8 bytes (value 3) to avoid alignment problems when allocating structures
* containing uint64.
*/
#define PFE_CLASS_HEAP_CHUNK_SIZE 4

#define SUM_WRAP_U32(A, B) ((uint32)(((uint64)(A) + (B)) & UINT32_MAX))

struct pfe_classifier_tag
{
    bool_t             is_fw_loaded;   /*   Flag indicating that firmware has been loaded */
    bool_t             enabled;        /*   Flag indicating that classifier has been enabled */
    addr_t             cbus_base_va;   /*   CBUS base virtual address */
    uint32           pe_num;         /*   Number of PEs */
    pfe_pe_t           pe[PFE_CLASS_PE_COUNT]; /*    List of particular PEs */
    blalloc_t *        heap_context;   /* Heap manager context */
    uint32           dmem_heap_base; /* DMEM base address of the heap */
    bool_t             miflock_pe;     /* Shared 'miflock' diagnostic flag for CLASS PE cores */
    uint32           current_feature;   /* Index of the feature to return by pfe_class_get_feature_next() */
    pfe_fw_feature_t   fw_features[PFE_CFG_CLASS_FW_FEATURES_COUNT]; /* List of all features*/
    uint32           fw_features_count; /* Number of items in fw_features */
    uint32           phy_if_bitmap_br_modes;  /* Bitmap list of PHY interfaces with enabled bridge mode, used to control HW bridge lookup */
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_class_t classifier_instance;
static pfe_ct_classify_stats_t pfe_class_stats[PFE_CLASS_PE_COUNT];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t  pfe_class_dmem_heap_init(pfe_class_t *class);
static errno_t  pfe_class_load_fw_features(pfe_class_t *class);
static errno_t  pfe_class_load_fw_process(pfe_class_t *class);


static void     pfe_class_alg_stats_endian(pfe_ct_class_algo_stats_t *stat);
static void     pfe_class_ihc_stats_endian(pfe_ct_class_ihc_stats_t *stat);
static void     pfe_class_sum_pe_algo_stats(pfe_ct_class_algo_stats_t *sum, const pfe_ct_class_algo_stats_t *val);
static void     pfe_class_sum_pe_ihc_stats(pfe_ct_class_ihc_stats_t *sum, const pfe_ct_class_ihc_stats_t *val);
static void     pfe_class_cal_total_stats(pfe_class_t *class, pfe_ct_classify_stats_t *total_stat, pfe_ct_classify_stats_t *stats);
static void     pfe_class_check_pes(pfe_class_t *class);

/* Check all PEs whether they report a firmware error */
static void pfe_class_check_pes(pfe_class_t *class)
{
    for (uint32 i = 0U; i < class->pe_num; i++)
    {
        /*  Read and print the error record from each PE */
        (void)pfe_pe_get_fw_messages_nolock(&class->pe[i]);
        /* Check the PE core for stalled state */
        (void)pfe_pe_check_stalled_nolock(&class->pe[i]);

#ifdef PFE_CFG_FCI_ENABLE
        pfe_ct_buffer_t buf;

        /*  Check if there is new message */
        if (EOK == pfe_pe_get_data_nolock(&class->pe[i], &buf))
        {
            fci_msg_t       msg = { .msg_cmd = { 0U }};
            /*  Provide data to user via FCI */
            msg.msg_cmd.code   = FPP_CMD_DATA_BUF_AVAIL;
            msg.msg_cmd.length = buf.len;
            msg.client = NULL;

            if (msg.msg_cmd.length > (uint32)sizeof(msg.msg_cmd.payload))
            {
                NXP_LOG_ERROR("FCI buffer is too small\n");
            }
            else
            {
                (void)autolibc_memcpy(&msg.msg_cmd.payload, buf.payload, buf.len);
                const errno_t ret = fci_core_client_send_broadcast(&msg, NULL);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("fci_core_client_send_broadcast() failed: %d\n", ret);
                }
            }
        }
#endif /* PFE_CFG_FCI_ENABLE */
    }
}

/**
 * @brief CLASS ISR
 * @details Checks all PEs whether they report a firmware error
 * @param[in] class The CLASS instance
 */
errno_t pfe_class_isr(pfe_class_t *class)
{
    errno_t  ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == class)
    {
        NXP_LOG_ERROR("NULL argument\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Allow safe use of _nolock() functions. We don't call the _mem_lock()
            here as we don't need to have coherent accesses. */
        oal_mutex_lock(PFE_CLASS_PE_MUTEX_03);
        pfe_pe_lock_family(class->pe);

        pfe_class_check_pes(class);

        pfe_pe_unlock_family(class->pe);
        oal_mutex_unlock(PFE_CLASS_PE_MUTEX_03);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Mask CLASS interrupts
 * @param[in]   class The CLASS instance
 */
void pfe_class_irq_mask(const pfe_class_t *class)
{
    /*  Intentionally empty */
    (void)class;
}

/**
 * @brief       Unmask CLASS interrupts
 * @param[in]   class The CLASS instance
 */
void pfe_class_irq_unmask(const pfe_class_t *class)
{
    /*  Intentionally empty */
    (void)class;
}

/**
 * @brief       Create all PEs instance for new classifier
 * @param[in]   class The class instance
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   pe_num Number of PEs to be included
 */
static errno_t pfe_class_create_pe(pfe_class_t *class, addr_t cbus_base_va, uint32 pe_num)
{
    pfe_pe_t *pe;
    uint32  ii;
    errno_t ret = EOK;

    /*  Create PEs */
    for (ii = 0U; ii < pe_num; ii++)
    {
        pe = pfe_pe_create(cbus_base_va, PE_TYPE_CLASS, (uint8)ii, &class->pe[ii], &class->miflock_pe);

        if (NULL == pe)
        {
            ret = ENOENT;
            break;
        }
        else
        {
            pfe_pe_set_iaccess(pe, CLASS_MEM_ACCESS_WDATA, CLASS_MEM_ACCESS_RDATA, CLASS_MEM_ACCESS_ADDR);
            pfe_pe_set_dmem(pe, PFE_CFG_CLASS_ELF_DMEM_BASE, PFE_CFG_CLASS_DMEM_SIZE);
            pfe_pe_set_imem(pe, PFE_CFG_CLASS_ELF_IMEM_BASE, PFE_CFG_CLASS_IMEM_SIZE);
            pfe_pe_set_lmem(pe, ADDR_BASE_OFFSET(PFE_CFG_CBUS_PHYS_BASE_ADDR, PFE_CFG_PE_LMEM_BASE), PFE_CFG_PE_LMEM_SIZE);
            class->pe_num = SUM_WRAP_U32(class->pe_num, 1U);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Create new classifier instance
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   pe_num Number of PEs to be included
 * @param[in]   cfg The classifier block configuration
 * @return      The classifier instance or NULL if failed
 */
pfe_class_t *pfe_class_create(addr_t cbus_base_va, uint32 pe_num, const pfe_class_cfg_t *cfg)
{
    pfe_class_t *class;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_ADDR == cbus_base_va) || (NULL == cfg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        class = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        class = &classifier_instance;
        (void)autolibc_memset(class, 0, sizeof(pfe_class_t));
        class->cbus_base_va = cbus_base_va;

        if (pe_num > 0U)
        {
           ret = pfe_class_create_pe(class, cbus_base_va, pe_num);

           if(EOK != ret)
           {
               pfe_class_destroy(class);
               class = NULL;
           }

           if (NULL != class)
           {
               /*   Issue block reset */
               pfe_class_reset(class);

               /* After soft reset, need to wait for 10us to perform another CSR write/read */
               oal_time_usleep(10);

               /*   Disable the classifier */
               pfe_class_disable(class);

               /*   Set new configuration */
               pfe_class_cfg_set_config(class->cbus_base_va, cfg);
           }
        }
        else
        {
            class = NULL_PTR;
        }
    }

    return class;
}

/**
 * @brief       Initializes the DMEM heap manager
 * @param[in]   class The classifier instance
 */
static errno_t pfe_class_dmem_heap_init(pfe_class_t *class)
{
    pfe_ct_pe_mmap_t mmap;
    errno_t          ret;

    ret = pfe_pe_get_mmap(&class->pe[0U], &mmap);

    if (EOK == ret)
    {

        class->heap_context = blalloc_create(oal_ntohl(mmap.class_pe.dmem_heap_size), PFE_CLASS_HEAP_CHUNK_SIZE);
        if (NULL_PTR == class->heap_context)
        {
            ret = ENOMEM;
        }
        else
        {
            class->dmem_heap_base = oal_ntohl(mmap.class_pe.dmem_heap_base);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Allocates memory from the DMEM heap
 * @param[in]   class The classifier instance
 * @param[in]   size Requested memory size
 * @return      Address of the allocated memory or value 0 on failure.
 */
addr_t pfe_class_dmem_heap_alloc(const pfe_class_t *class, uint32 size)
{
    addr_t  addr;
    errno_t ret;

    ret = blalloc_alloc_offs(class->heap_context, size, 0, &addr);

    if (EOK == ret)
    {
        addr = ADDR_BASE_OFFSET(addr, class->dmem_heap_base);
    }
    else
    { /* Allocation failed - return "NULL" */
        NXP_LOG_DEBUG("Failed to allocate memory (size %u)\n", (uint_t)size);
        addr = 0U;
    }

    return addr;
}

/**
 * @brief       Returns previously allocated memory to the DMEM heap
 * @param[in]   class The classifier instance
 * @param[in]   addr Address of the previously allocated memory by pfe_class_dmem_heap_alloc()
 */
void pfe_class_dmem_heap_free(const pfe_class_t *class, addr_t addr)
{
    if (0U == addr)
    { /* Ignore "NULL" */
    }
    else if (addr < class->dmem_heap_base)
    {
        NXP_LOG_ERROR("Impossible address 0x%" PRINTADDR_T " (base is 0x%x)\n", addr, (uint_t) class->dmem_heap_base);
    }
    else
    {
        blalloc_free_offs(class->heap_context, addr - class->dmem_heap_base);
    }
}

/**
 * @brief       Reset the classifier block
 * @param[in]   class The classifier instance
 */
void pfe_class_reset(pfe_class_t *class)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_class_disable(class);
        pfe_class_cfg_reset(class->cbus_base_va);
        class->enabled = FALSE;
    }
}

/**
 * @brief       Enable the classifier block
 * @details     Enable all classifier PEs
 * @param[in]   class The classifier instance
 */
void pfe_class_enable(pfe_class_t *class)
{
    uint16             timeout = 50U;
    pfe_ct_pe_sw_state_t state;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (unlikely(FALSE == class->is_fw_loaded))
        {
            NXP_LOG_WARNING("Attempt to enable classifier without previous firmware upload\n");
        }

        pfe_class_cfg_enable(class->cbus_base_va);

        do
        {
            oal_time_usleep(5U);
            timeout--;
            state = pfe_pe_get_fw_state(&class->pe[0U]);
        } while ((state < PFE_FW_STATE_INIT) && (timeout > 0U));

        if (timeout == 0U)
        {
            NXP_LOG_ERROR("Time-out waiting for classifier to init\n");
        }
        else
        {
            class->enabled = TRUE;
        }
    }
}

/**
 * @brief       Disable the classifier block
 * @details     Disable all classifier PEs
 * @param[in]   class The classifier instance
 */
void pfe_class_disable(pfe_class_t *class)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_class_cfg_disable(class->cbus_base_va);
    }
}

/**
 * @brief       Load firmware elf into PEs memories
 * @param[in]   class The classifier instance
 * @param[in]   elf The elf file object to be uploaded
 * @return      EOK when success or error code otherwise
 */
errno_t pfe_class_load_firmware(pfe_class_t *class, const void *elf)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == elf)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_pe_load_firmware(class->pe, class->pe_num, elf);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Classifier firmware loading the PE failed: %d\n", ret);
        }

        if (EOK == ret)
        {
            class->is_fw_loaded = TRUE;

            /* Check the memory map whether it is correct */
            /* All PEs have the same map therefore it is sufficient to check one */
            ret = pfe_pe_check_mmap(&class->pe[0U]);

            if (EOK == ret)
            {
                /* Firmware has been loaded and the DMEM heap is known - initialize the allocator */
                ret = pfe_class_dmem_heap_init(class);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Dmem heap allocator initialization failed\n");
                }
            }

            ret = pfe_class_load_fw_features(class);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Failed to initialize FW features\n");
            }
        }
    }

    return ret;
}

static errno_t pfe_class_load_fw_process(pfe_class_t *class)
{
    errno_t                ret = EINVAL;
    uint32               i, j;
    pfe_ct_feature_desc_t *entry;
    bool_t                 val_break = FALSE;
    pfe_fw_feature_t       *fw_features;

    /* Initialize current_feature */
    class->current_feature = 0U;
    for (i = 0U; i < class->fw_features_count; i++)
    {
        fw_features = pfe_fw_feature_create(&class->fw_features[i]);
        if (NULL == fw_features)
        {
            NXP_LOG_ERROR("Failed to create feature %u\n", (uint_t)i);
            /* Destroy previously created and return failure */
            for (j = 0U; j < i; j++)
            {
                pfe_fw_feature_destroy(&class->fw_features[j]);
            }
            ret       = ENOMEM;
            val_break = TRUE;
        }
        else
        {
            /* Get feature low level data */
            ret = pfe_pe_get_fw_feature_entry(&class->pe[0U], i, &entry);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Failed get ll data for feature %u\n", (uint_t)i);
                /* Destroy previously created and return failure */
                for (j = 0U; j < i; j++)
                {
                    pfe_fw_feature_destroy(&class->fw_features[j]);
                }
                ret       = EINVAL;
                val_break = TRUE;
            }
            else
            {
                /* Set the low level data in the feature */
                (void)pfe_fw_feature_set_ll_data(fw_features, entry, (uint8)(pfe_class_get_num_of_pes(class) & UINT8_MAX));
                /* Set the feature string base */
                ret = pfe_fw_feature_set_string_base(fw_features, pfe_pe_get_fw_feature_str_base(&class->pe[0U]));
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Failed to set string base for feature %u\n", (uint_t)i);
                    /* Destroy previously created and return failure */
                    for (j = 0U; j < i; j++)
                    {
                        pfe_fw_feature_destroy(&class->fw_features[j]);
                    }
                    ret       = EINVAL;
                    val_break = TRUE;
                }
                else
                {
                    /* Set functions to read/write DMEM and their data */
                    (void)pfe_fw_feature_set_dmem_funcs(fw_features, pfe_class_read_dmem, pfe_class_write_dmem, (void *)class);
                }
            }
        }
        if (TRUE == val_break)
        {
            break;
        }
    }

    if (EOK != ret)
    {
        class->fw_features_count = 0U;
    }

    return ret;
}

static errno_t pfe_class_load_fw_features(pfe_class_t *class)
{
    pfe_ct_pe_mmap_t       mmap;
    errno_t                ret;

    ret = pfe_pe_get_mmap(&class->pe[0U], &mmap);
    if (EOK == ret)
    {
        class->fw_features_count = oal_ntohl(mmap.common.version.features_count);
        if (class->fw_features_count > 0U)
        {
            if (class->fw_features_count > PFE_CFG_CLASS_FW_FEATURES_COUNT)
            {
                NXP_LOG_ERROR("Insufficient class features storage for %u entries\n", (uint_t)class->fw_features_count);
                class->fw_features_count = 0U;
                ret = ENOMEM;
            }
            else
            {
                ret = pfe_class_load_fw_process(class);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Errors during load FW features\n");
                }
            }
        } /* Else is OK too */
    }
    return ret;
}

/**
 * @brief       Get pointer to PE's memory where memory map data is stored
 * @param[in]   class The classifier instance
 * @param[in]   pe_idx PE index
 * @param[out]  mmap Pointer where memory map data shall be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_class_get_mmap(pfe_class_t *class, sint32 pe_idx, pfe_ct_class_mmap_t *mmap)
{
    errno_t          ret;
    pfe_ct_pe_mmap_t mmap_tmp = {0};

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == mmap)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        PfeDevAssert(pe_idx >= 0);
        if ((uint32)pe_idx >= class->pe_num)
        {
            ret = EINVAL;
        }
        else
        {
            ret = pfe_pe_get_mmap(&class->pe[pe_idx], &mmap_tmp);
            (void)autolibc_memcpy(mmap, &mmap_tmp.class_pe, sizeof(pfe_ct_class_mmap_t));
        }
    }

    return ret;
}

/**
 * @brief       Write data from host memory to DMEM
 * @param[in]   class_p The classifier instance
 * @param[in]   pe_idx PE index or -1 if all PEs shall be written
 * @param[in]   dst_addr Destination address within DMEM (physical)
 * @param[in]   src_ptr Pointer to data in host memory (virtual address)
 * @param[in]   len Number of bytes to be written
 * @return      EOK or error code in case of failure
 */
errno_t pfe_class_write_dmem(void *class_p, sint32 pe_idx, addr_t dst_addr, const void *src_ptr, uint32 len)
{
    uint32 ii;
    pfe_class_t *class = (pfe_class_t *)class_p;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (pe_idx >= 0)
        {
            if ((uint32)pe_idx >= class->pe_num)
            {
                ret = EINVAL;
            }
            else
            {
                /*  Single PE */
                pfe_pe_memcpy_from_host_to_dmem_32(&class->pe[pe_idx], dst_addr, src_ptr, len);
                ret = EOK;
            }
        }
        else
        {
            /*  All PEs */
            for (ii = 0U; ii < class->pe_num; ii++)
            {
                pfe_pe_memcpy_from_host_to_dmem_32(&class->pe[ii], dst_addr, src_ptr, len);
            }
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Read data from DMEM to host memory
 * @param[in]   class_p The classifier instance
 * @param[in]   pe_idx PE index
 * @param[in]   dst_ptr Destination address within host memory (virtual)
 * @param[in]   src_addr Source address within DMEM (physical)
 * @param[in]   len Number of bytes to be read
 * @return      EOK or error code in case of failure
 */
errno_t pfe_class_read_dmem(void *class_p, sint32 pe_idx, void *dst_ptr, addr_t src_addr, uint32 len)
{
    pfe_class_t *class = (pfe_class_t *)class_p;
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == dst_ptr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        PfeDevAssert(pe_idx >= 0);
        if ((uint32)pe_idx >= class->pe_num)
        {
            NXP_LOG_ERROR("Wrong PE index\n");
            ret = EINVAL;
        }
        else
        {
            pfe_pe_memcpy_from_dmem_to_host_32(&class->pe[pe_idx], dst_ptr, src_addr, len);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Read data from DMEM from all PEs atomically to host memory
 * @param[in]   class The classifier instance (All PEs from given class are read)
 * @param[in]   dst_ptr Destination address within host memory (virtual) available memory has to be pe_count * len
 * @param[in]   src_addr Source address within DMEM (physical)
 * @param[in]   buffer_len Destination buffer size
 * @param[in]   read_len Number of bytes to be read (From one PE)
 * @return      EOK or error code in case of failure
 */
errno_t pfe_class_gather_read_dmem(pfe_class_t *class, void *dst_ptr, addr_t src_addr, uint32 buffer_len, uint32 read_len)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == dst_ptr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        PfeDevAssert(class->pe_num <= (uint32)INT32_MAX);
        ret = pfe_pe_gather_memcpy_from_dmem_to_host_32(class->pe,
                                                        (sint32)class->pe_num,
                                                        dst_ptr,
                                                        (addr_t)src_addr,
                                                        buffer_len,
                                                        read_len);
    }

    return ret;
}

/**
 * @brief       Destroy classifier instance
 * @param[in]   class The classifier instance
 */
void pfe_class_destroy(pfe_class_t *class)
{
    uint32 ii;

    if (NULL != class)
    {
        pfe_class_disable(class);

        pfe_pe_destroy(class->pe, class->pe_num);

        for (ii = 0U; ii < class->fw_features_count; ii++)
        {
            pfe_fw_feature_destroy(&class->fw_features[ii]);
        }
        class->fw_features_count = 0U;
        class->pe_num = 0U;

        if (NULL_PTR != class->heap_context)
        {
            blalloc_destroy(class->heap_context);
            class->heap_context = NULL_PTR;
        }
    }
}

/**
 * @brief       Set routing table parameters
 * @param[in]   class The classifier instance
 * @param[in]   rtable_pa Physical address of the routing table
 * @param[in]   rtable_len Number of entries in the table
 * @param[in]   entry_size Routing table entry size in number of bytes
 * @return      EOK if success, error code otherwise
 * @note        Must be called before the classifier is enabled.
 */
errno_t pfe_class_set_rtable(pfe_class_t *class, addr_t rtable_pa, uint32 rtable_len, uint32 entry_size)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL_ADDR == rtable_pa)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (class->enabled)
        {
            ret = EBUSY;
        }
        else
        {
            ret = pfe_class_cfg_set_rtable(class->cbus_base_va, rtable_pa, rtable_len, entry_size);
        }
    }

    return ret;
}

/**
 * @brief       Set default VLAN ID
 * @details     Every packet without VLAN tag set received via physical interface will
 *              be treated as packet with VLAN equal to this default VLAN ID.
 * @param[in]   class The classifier instance
 * @param[in]   vlan The default VLAN ID (12bit)
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_class_set_default_vlan(const pfe_class_t *class, uint16 vlan)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_class_cfg_set_def_vlan(class->cbus_base_va, vlan);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Returns number of PEs available
 * @param[in]   class The classifier instance
 * @return      Number of available PEs
 */

uint32 pfe_class_get_num_of_pes(const pfe_class_t *class)
{
    uint32 pe_num;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        pe_num = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pe_num = class->pe_num;
    }
    return pe_num;
}

/**
 * @brief Finds and returns Classifier FW feature by its name
 * @param[in] class The classifier instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @param[in] name Name of the feature to be found
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
errno_t pfe_class_get_feature(pfe_class_t *class, pfe_fw_feature_t **feature, const char *name)
{
    uint32    i;
    const char *fname;
    errno_t     ret = ENOENT;
    errno_t     ret_val = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == feature) || (NULL == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (i = 0U; i < class->fw_features_count; i++)
        {
            ret_val = pfe_fw_feature_get_name(&class->fw_features[i], &fname);
            if (EOK == ret_val)
            {
                if (0 == autolibc_strcmp(fname, name))
                {
                    *feature = &class->fw_features[i];
                    ret = EOK;
                    break;
                }
            }
        }
    }
    return ret;
}

/**
 * @brief Finds and returns the 1st Classifier FW feature by order of their discovery - used for listing all features
 * @param[in] class The classifier instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
errno_t pfe_class_get_feature_first(pfe_class_t *class, pfe_fw_feature_t **feature)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == feature)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (class->fw_features_count > 0U)
        {
            class->current_feature = 0U;
            *feature = &class->fw_features[class->current_feature];
            ret = EOK;
        }
        else
        {
            ret = ENOENT;
        }
    }

    return ret;
}

/**
 * @brief Finds and returns the next Classifier FW feature by order of their discovery - used for listing all features
 * @param[in] class The classifier instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
errno_t pfe_class_get_feature_next(pfe_class_t *class, pfe_fw_feature_t **feature)
{
    errno_t ret = ENOENT;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == feature)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (class->fw_features_count > 0U)
        {
            /* Avoid going out of the array boundaries */
            if ((class->current_feature + 1U) < class->fw_features_count)
            {
                class->current_feature += 1U;
                *feature = &class->fw_features[class->current_feature];
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
* @brief Converts endiannes of the whole structure containing statistics
* @param[in,out] stat Statistics which endiannes shall be converted
*/
static void pfe_class_alg_stats_endian(pfe_ct_class_algo_stats_t *stat)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == stat))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif
    {
        stat->processed = oal_ntohl(stat->processed);
        stat->accepted  = oal_ntohl(stat->accepted);
        stat->rejected  = oal_ntohl(stat->rejected);
        stat->discarded = oal_ntohl(stat->discarded);
    }
}

/**
* @brief Converts endiannes of the whole structure containing statistics
* @param[in,out] stat Statistics which endiannes shall be converted
*/
static void pfe_class_ihc_stats_endian(pfe_ct_class_ihc_stats_t *stat)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == stat))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif
    {
        stat->rx        = oal_ntohl(stat->rx);
        stat->tx        = oal_ntohl(stat->tx);
        stat->discarded = oal_ntohl(stat->discarded);
    }
}

/* Swap endianness of pfe_ct_class_flexi_parser_stats_t stats */
void pfe_class_flexi_parser_stats_endian(pfe_ct_class_flexi_parser_stats_t *stats)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == stats))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif
    {
        stats->accepted = oal_ntohl(stats->accepted);
        stats->rejected = oal_ntohl(stats->rejected);
    }
}

/* Accumulate FP statistics */
void pfe_class_sum_flexi_parser_stats(pfe_ct_class_flexi_parser_stats_t *sum, const pfe_ct_class_flexi_parser_stats_t *val)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == sum) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif
    {
        sum->accepted = SUM_WRAP_U32(sum->accepted, val->accepted);
        sum->rejected = SUM_WRAP_U32(sum->rejected, val->rejected);
    }
}

/**
* @brief Function adds statistics value to sum
* @param[in] sum Sum to add the value (results are in HOST endian)
* @param[in] val Value to be added to the sum (it is in HOST endian)
*/
static void pfe_class_sum_pe_algo_stats(pfe_ct_class_algo_stats_t *sum, const pfe_ct_class_algo_stats_t *val)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == sum) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif
    {
        sum->processed = SUM_WRAP_U32(sum->processed, val->processed);
        sum->accepted = SUM_WRAP_U32(sum->accepted, val->accepted);
        sum->rejected = SUM_WRAP_U32(sum->rejected, val->rejected);
        sum->discarded = SUM_WRAP_U32(sum->discarded, val->discarded);
    }
}

/**
* @brief Function adds statistics value to sum
* @param[in] sum Sum to add the value (results are in HOST endian)
* @param[in] val Value to be added to the sum (it is in HOST endian)
*/
static void pfe_class_sum_pe_ihc_stats(pfe_ct_class_ihc_stats_t *sum, const pfe_ct_class_ihc_stats_t *val)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == sum) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif
    {
        sum->rx = SUM_WRAP_U32(sum->rx, val->rx);
        sum->tx = SUM_WRAP_U32(sum->tx, val->tx);
        sum->discarded = SUM_WRAP_U32(sum->discarded, val->discarded);
    }
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief                  Converts statistics of a logical interface or classification algorithm into a text form
 * @param[in]   stat       Statistics to convert - expected in HOST endian
 * @param[out]  buf        Buffer where to write the text
 * @param[in]   buf_len    Buffer length
 * @param[in]   verb_level Verbosity level
 * @return                 Number of bytes written into the output buffer
 */
uint32 pfe_class_fp_stat_to_str(const pfe_ct_class_flexi_parser_stats_t *stat, char *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

    (void)verb_level;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == stat) || (NULL == buf)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "Frames accepted:  %u\n", stat->accepted);
        len += oal_util_snprintf(buf + len, buf_len - len, "Frames rejected:  %u\n", stat->rejected);
    }
    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Send data buffer
 * @param[in]   class The CLASS instance
 * @param[in]   buf Buffer to be sent
 * @return      EOK success, error code otherwise
 */
errno_t pfe_class_put_data(pfe_class_t *class, pfe_ct_buffer_t *buf)
{
    uint32 ii, tries;
    errno_t  ret = EINVAL;

    /*  Allow safe use of _nolock() functions. We don't call the _mem_lock()
        here as we don't need to have coherent accesses. */
    oal_mutex_lock(PFE_CLASS_PE_MUTEX_04);
    pfe_pe_lock_family(class->pe);
    for (ii = 0U; ii < class->pe_num; ii++)
    {
        tries = 0U;
        do
        {
            ret = pfe_pe_put_data_nolock(&class->pe[ii], buf);
            if (EAGAIN == ret)
            {
                tries++;
                oal_time_usleep(200U);
            }
        } while ((ret == EAGAIN) && (tries < 10U));

        if (EOK != ret)
        {
            NXP_LOG_ERROR("Unable to update pe %u\n", (uint_t)ii);
            ret = EBUSY;
            break;
        }
    }
    pfe_pe_unlock_family(class->pe);
    oal_mutex_unlock(PFE_CLASS_PE_MUTEX_04);

    return ret;
}

/**
 * @brief           Calculate total statistics
 * @param[in]       class The CLASS instance
 * @param[out]      total_stat Total statistics
 * @param[in,out]   stats Statistic structure
 */
static void pfe_class_cal_total_stats(pfe_class_t *class, pfe_ct_classify_stats_t *total_stat, pfe_ct_classify_stats_t *stats)
{
    uint32                 i = 0U, j = 0U;

    /* Calculate total statistics */
    while (i < pfe_class_get_num_of_pes(class))
    {
        pfe_class_alg_stats_endian(&stats[i].flexible_router);
        pfe_class_alg_stats_endian(&stats[i].ip_router);
        pfe_class_alg_stats_endian(&stats[i].vlan_bridge);
        pfe_class_alg_stats_endian(&stats[i].log_if);

        for (j = 0U; j < ((uint32)PFE_PHY_IF_ID_MAX + 1U); j++)
        {
            pfe_class_ihc_stats_endian(&stats[i].hif_to_hif[j]);
        }
        pfe_class_sum_pe_algo_stats(&total_stat->flexible_router, &stats[i].flexible_router);
        pfe_class_sum_pe_algo_stats(&total_stat->ip_router, &stats[i].ip_router);
        pfe_class_sum_pe_algo_stats(&total_stat->vlan_bridge, &stats[i].vlan_bridge);
        pfe_class_sum_pe_algo_stats(&total_stat->log_if, &stats[i].log_if);

        for (j = 0U; j < ((uint32)PFE_PHY_IF_ID_MAX + 1U); j++)
        {
            pfe_class_sum_pe_ihc_stats(&total_stat->hif_to_hif[j], &stats[i].hif_to_hif[j]);
        }

        ++i;
    }
}

/**
 * @brief       Get class algo statistics
 * @param[in]   class
 * @param[out]  stat Statistic structure
 * @retval      EOK Success
 * @retval      NOMEM Not possible to allocate memory for read
 */
errno_t pfe_class_get_stats(pfe_class_t *class, pfe_ct_classify_stats_t *stat)
{
    pfe_ct_pe_mmap_t         mmap;
    errno_t                  ret      = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == stat)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(stat, 0, sizeof(pfe_ct_classify_stats_t));

        /* Get the memory map - all PEs share the same memory map
        therefore we can read arbitrary one (in this case 0U) */
        ret = pfe_pe_get_mmap(&class->pe[0U], &mmap);

        if (EOK != ret)
        {
            NXP_LOG_ERROR("Cannot get PE memory map\n");
        }
        else
        {
            /* Gather memory from all PEs*/
            ret = pfe_class_gather_read_dmem(class, pfe_class_stats,
                oal_ntohl(mmap.class_pe.classification_stats),
                sizeof(pfe_class_stats), sizeof(pfe_ct_classify_stats_t));

            pfe_class_cal_total_stats(class, stat, pfe_class_stats);
        }
    }

    return ret;
}

#define HIF_CHANNELS_MASK (((uint32)1U << (uint32)PFE_PHY_IF_ID_HIF0)\
                          |((uint32)1U << (uint32)PFE_PHY_IF_ID_HIF1)\
                          |((uint32)1U << (uint32)PFE_PHY_IF_ID_HIF2)\
                          |((uint32)1U << (uint32)PFE_PHY_IF_ID_HIF3)\
                          |((uint32)1U << (uint32)PFE_PHY_IF_ID_HIF_NOCPY))

/**
 * @brief       Returns firmware versions
 * @param[in]   class The classifier instance
 * @return      ver Parsed firmware metadata
 */
errno_t pfe_class_get_fw_version(const pfe_class_t *class, pfe_ct_version_t *ver)
{
    pfe_ct_pe_mmap_t pfe_pe_mmap;
    errno_t          ret;

    /*  Get mmap base from PE[0] since all PEs have the same memory map */
    ret = pfe_pe_get_mmap(&class->pe[0], &pfe_pe_mmap);
    if ((class->pe_num == 0) || (EOK != ret))
    {
        ret = EINVAL;
    }
    else
    {
        (void)autolibc_memcpy(ver, &pfe_pe_mmap.class_pe.common.version, sizeof(pfe_ct_version_t));
        ret = EOK;
    }

    return ret;
}

/**
* @brief        Enable HW lookup of routing table
* @param[in]    class The classifier instance
*/
void pfe_class_rtable_lookup_enable(const pfe_class_t *class)
{  
    oal_mutex_lock(PFE_CLASS_MUTEX_01);
    pfe_class_cfg_rtable_lookup_enable(class->cbus_base_va);
    oal_mutex_unlock(PFE_CLASS_MUTEX_01);
}

/**
* @brief        Disable HW lookup of routing table
* @param[in]    class The classifier instance
*/
void pfe_class_rtable_lookup_disable(const pfe_class_t *class)
{
    oal_mutex_lock(PFE_CLASS_MUTEX_02);
    pfe_class_cfg_rtable_lookup_disable(class->cbus_base_va);
    oal_mutex_unlock(PFE_CLASS_MUTEX_02);
}

/**
* @brief        Control HW bridge lookup
* @param[in]    class The classifier instance
* @param[in]    if_bitmap The bitmap represnting PHY IF
* @param[in]    br_mode The bridge mode state of PHY IF
* @note         HW bridge lookup is enabled with the 1st PHY IF set to bridge mode,
*               disabled when the last PHY IF bridge mode is unset.
*/
void pfe_class_update_hw_bridge_lookup(pfe_class_t *class, uint32 if_bitmap, bool_t br_mode)
{
    uint32 if_bitmap_br_modes_before;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CLASS_MUTEX_00);
        
        if_bitmap_br_modes_before = class->phy_if_bitmap_br_modes;
        if (TRUE == br_mode)
        {
            class->phy_if_bitmap_br_modes |= if_bitmap;
            if (0U == if_bitmap_br_modes_before)
            {
                /* Enable HW bridge lookup */
                pfe_class_cfg_bridge_lookup_enable(class->cbus_base_va);
            }
        }
        else
        {
            class->phy_if_bitmap_br_modes &= ~if_bitmap;
            if ((0U != if_bitmap_br_modes_before) && (0U == class->phy_if_bitmap_br_modes))
            {
                /* Disable HW bridge lookup */
                pfe_class_cfg_bridge_lookup_disable(class->cbus_base_va);
            }
        }
        
        oal_mutex_unlock(PFE_CLASS_MUTEX_00);
    }
}


#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [137/185]: src\pfe_class_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_class_csr.h"
#include "pfe_tmu.h"
#include "pfe_tmu_csr.h"
#include "pfe_feature_mgr.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#include "pfe_bmu_csr.h"


#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_class_cfg_validate_rtable_len(uint32 rtable_len, uint8 *rtable_idx);

/**
 * @brief       Initialize and configure the CLASS block
 * @param[in]   base_va Base address of CLASS register space (virtual)
 * @param[in]   cfg Pointer to the configuration structure
 */
void pfe_class_cfg_set_config(addr_t base_va, const pfe_class_cfg_t *cfg)
{
    uint32 regval;
    (void)cfg;

    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU1_BASE_ADDR + BMU_FREE_CTRL, base_va + CLASS_BMU1_BUF_FREE);
    hal_write32(CLASS_PE0_RO_DM_ADDR0_VAL, base_va + CLASS_PE0_RO_DM_ADDR0);
    hal_write32(CLASS_PE0_RO_DM_ADDR1_VAL, base_va + CLASS_PE0_RO_DM_ADDR1);
    hal_write32(CLASS_PE0_QB_DM_ADDR0_VAL, base_va + CLASS_PE0_QB_DM_ADDR0);
    hal_write32(CLASS_PE0_QB_DM_ADDR1_VAL, base_va + CLASS_PE0_QB_DM_ADDR1);
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + TMU_PHY_INQ_PKTPTR, base_va + CLASS_TM_INQ_ADDR);
    hal_write32(0x18U, base_va + CLASS_MAX_BUF_CNT);
    hal_write32(0x14U, base_va + CLASS_AFULL_THRES);
    hal_write32(0x3c0U, base_va + CLASS_INQ_AFULL_THRES);
    hal_write32(0x1U, base_va + CLASS_USE_TMU_INQ);
    hal_write32(0x1U, base_va + CLASS_PE_SYS_CLK_RATIO);
    hal_write32(0U, base_va + CLASS_L4_CHKSUM);
    hal_write32(((uint32)cfg->ro_header_size << 16U) | (uint32)cfg->lmem_header_size, base_va + CLASS_HDR_SIZE);
    hal_write32(PFE_CFG_LMEM_BUF_SIZE, base_va + CLASS_LMEM_BUF_SIZE);
    hal_write32(CLASS_TPID0_TPID1_VAL, base_va + CLASS_TPID0_TPID1);
    hal_write32(CLASS_TPID2_VAL, base_va + CLASS_TPID2);
    regval = hal_read32(base_va + CLASS_AXI_CTRL_ADDR);
    if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
    {
        regval &= ~AXI_DBUS_BURST_SIZE(0x3ffU);
        regval |= AXI_DBUS_BURST_SIZE(0x200U);
        regval |= 0x3U;
        hal_write32(regval, base_va + CLASS_AXI_CTRL_ADDR);
    }
    else if (cfg->g2_ordered_class_writes)
    {
        regval |= 0x3U;
        hal_write32(regval, base_va + CLASS_AXI_CTRL_ADDR);
    }
    else
    {
        /* Required by Misra */
    }

    hal_write32(0U
            | RT_TWO_LEVEL_REF(FALSE)
            | PHYNO_IN_HASH(FALSE)
            | PARSE_ROUTE_EN(FALSE)
            | VLAN_AWARE_BRIDGE(TRUE)
            | PARSE_BRIDGE_EN(FALSE)
            | IPALIGNED_PKT(FALSE)
            | ARC_HIT_CHECK_EN(FALSE)
            | VLAN_AWARE_BRIDGE_PHY1(FALSE)
            | VLAN_AWARE_BRIDGE_PHY2(FALSE)
            | VLAN_AWARE_BRIDGE_PHY3(FALSE)
            | CLASS_TOE(FALSE)
            | ASYM_HASH(ASYM_HASH_SIP_SPORT_CRC)
            | SYM_RTENTRY(FALSE)
            | QB2BUS_ENDIANESS(TRUE)
            | LEN_CHECK(FALSE)
            , base_va + CLASS_ROUTE_MULTI);
}

/**
 * @brief       Reset the classifier block
 * @param[in]   base_va Base address of CLASS register space (virtual)
 */
void pfe_class_cfg_reset(addr_t base_va)
{
    hal_write32(PFE_CORE_SW_RESET, base_va + CLASS_TX_CTRL);
}

/**
 * @brief       Enable the classifier block
 * @details     Enable all classifier PEs
 * @param[in]   base_va Base address of CLASS register space (virtual)
 */
void pfe_class_cfg_enable(addr_t base_va)
{
    hal_write32(PFE_CORE_ENABLE, base_va + CLASS_TX_CTRL);
}

/**
 * @brief       Disable the classifier block
 * @details     Disable all classifier PEs
 * @param[in]   base_va Base address of CLASS register space (virtual)
 */
void pfe_class_cfg_disable(addr_t base_va)
{
    hal_write32(PFE_CORE_DISABLE, base_va + CLASS_TX_CTRL);
}

/**
 * @brief       Validate rtable length
 * @param[in]   rtable_len Number of entries in the table
 * @param[in]   rtable_idx Pointer to the rtable index
 */
static errno_t pfe_class_cfg_validate_rtable_len(uint32 rtable_len, uint8 *rtable_idx)
{
    errno_t ret = EOK;
    uint8 idx;

    /* Validate that rtable_len is a power of 2 and it's within boundaries. */
    for (idx = 0U; idx < (sizeof(rtable_len) * 8U); idx++)
    {
        if (0U != (rtable_len & (1UL << idx)))
        {
            if (0U != (rtable_len & ~(1UL << idx)))
            {
                NXP_LOG_ERROR("Routing table length is not a power of 2\n");
                ret = EINVAL;
            }
            else if ((idx < 6U) || (idx > 20U))
            {
                NXP_LOG_ERROR("Table length out of boundaries\n");
                ret = EINVAL;
            }
            else
            {
                ret = EOK;
            }

            break;
        }
    }

    *rtable_idx = idx;

    return ret;
}

/**
 * @brief       Set up routing table
 * @param[in]   base_va Base address of CLASS register space (virtual)
 * @param[in]   rtable_pa Physical address of the routing table space
 * @param[in]   rtable_len Number of entries in the table
 * @param[in]   entry_size Routing table entry size in number of bytes
 * @return      Execution status, EOK if success, error code otherwise
 */
errno_t pfe_class_cfg_set_rtable(addr_t base_va, addr_t rtable_pa, uint32 rtable_len, uint32 entry_size)
{
    uint32 reg;
    errno_t ret = EOK;
    uint8 rtable_idx;

    if (NULL_ADDR == rtable_pa)
    {
        pfe_class_cfg_rtable_lookup_disable(base_va);
        ret = EOK;
    }
    else
    {

        /* rtable not NULL, add it */
        if (entry_size > ROUTE_ENTRY_SIZE(0xffffffffu))
        {
            NXP_LOG_ERROR("Entry size exceeds maximum value\n");
            ret = EINVAL;
        }
        else
        {
            /* Validate rtable entry size if route parsing is already enabled. */
            reg = hal_read32(base_va + CLASS_ROUTE_MULTI);
            if (0U != (reg & PARSE_ROUTE_EN(TRUE)))
            {
                if (entry_size != 128U)
                {
                    NXP_LOG_ERROR("FATAL: Route table entry length exceeds 128bytes\n");
                    ret = EINVAL;
                }
            }

            if (EOK == ret)
            {
                ret = pfe_class_cfg_validate_rtable_len(rtable_len, &rtable_idx);

                if (EOK == ret)
                {
                    hal_write32((uint32)(rtable_pa & 0xffffffffU), base_va + CLASS_ROUTE_TABLE_BASE);
                    hal_write32(0UL
                                | ROUTE_HASH_SIZE(rtable_idx)
                                | ROUTE_ENTRY_SIZE(entry_size)
                                , base_va + CLASS_ROUTE_HASH_ENTRY_SIZE);

                    /* Don't enable PARSE_ROUTE_EN here as it will be enabled only when needed later. */
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Set default VLAN ID
 * @details     Every packet without VLAN tag set received via physical interface will
 *              be treated as packet with VLAN equal to this default VLAN ID.
 * @param[in]   base_va Base address of CLASS register space (virtual)
 * @param[in]   vlan The default VLAN ID (12bit)
 */
void pfe_class_cfg_set_def_vlan(addr_t base_va, uint16 vlan)
{
    hal_write32(0UL
            | USE_DEFAULT_VLANID(TRUE)
            | DEF_VLANID((uint32)vlan & (uint32)0xfffU)
            , base_va + CLASS_VLAN_ID);
}

#if defined(PFE_CFG_TEXT_STATS)

/**
 * @brief       Get CLASS statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the CLASS block.
 * @param[in]   base_va Base address of CLASS register space (virtual)
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_class_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;
    uint32 reg;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Debug registers */
        if(verb_level >= 10U)
        {
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE0_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE0_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE1_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE1_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE2_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE2_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE3_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE3_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE4_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE4_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE5_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE5_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE6_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE6_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PE7_DEBUG\t0x%x\n", hal_read32(base_va + CLASS_PE7_DEBUG));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_STATE\t0x%x\n", hal_read32(base_va + CLASS_STATE));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_QB_BUF_AVAIL\t0x%x\n", hal_read32(base_va + CLASS_QB_BUF_AVAIL));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_RO_BUF_AVAIL\t0x%x\n", hal_read32(base_va + CLASS_RO_BUF_AVAIL));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_DEBUG_BUS01\t0x%x\n", hal_read32(base_va + CLASS_DEBUG_BUS01));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_DEBUG_BUS23\t0x%x\n", hal_read32(base_va + CLASS_DEBUG_BUS23));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_DEBUG_BUS45\t0x%x\n", hal_read32(base_va + CLASS_DEBUG_BUS45));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_DEBUG_BUS67\t0x%x\n", hal_read32(base_va + CLASS_DEBUG_BUS67));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_DEBUG_BUS89\t0x%x\n", hal_read32(base_va + CLASS_DEBUG_BUS89));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_DEBUG_BUS1011\t0x%x\n", hal_read32(base_va + CLASS_DEBUG_BUS1011));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_DEBUG_BUS12\t0x%x\n", hal_read32(base_va + CLASS_DEBUG_BUS12));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_RX_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_RX_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_L3_FAIL_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_L3_FAIL_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_V4_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_V4_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_V6_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_V6_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_CHKSUM_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_CHKSUM_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_TTL_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_TTL_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_RX_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_RX_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_L3_FAIL_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_L3_FAIL_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_V4_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_V4_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_V6_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_V6_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_CHKSUM_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_CHKSUM_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_TTL_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_TTL_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_RX_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_RX_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_L3_FAIL_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_L3_FAIL_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_V4_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_V4_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_V6_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_V6_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_CHKSUM_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_CHKSUM_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_TTL_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_TTL_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_RX_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_RX_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_L3_FAIL_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_L3_FAIL_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_V4_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_V4_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_V6_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_V6_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_CHKSUM_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_CHKSUM_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_TTL_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_TTL_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_RX_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_RX_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_L3_FAIL_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_L3_FAIL_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_V4_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_V4_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_V6_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_V6_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_CHKSUM_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_CHKSUM_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_TTL_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_TTL_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_ICMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_ICMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_IGMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_IGMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_TCP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_TCP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY1_UDP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY1_UDP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_ICMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_ICMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_IGMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_IGMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_TCP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_TCP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY2_UDP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY2_UDP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_ICMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_ICMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_IGMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_IGMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_TCP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_TCP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY3_UDP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY3_UDP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_ICMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_ICMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_IGMP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_IGMP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_TCP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_TCP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_UDP_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_UDP_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_RX_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_RX_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_L3_FAIL_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_L3_FAIL_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_V4_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_V4_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_V6_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_V6_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_CHKSUM_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_CHKSUM_ERR_PKTS));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_PHY4_TTL_ERR_PKTS\t0x%x\n", hal_read32(base_va + CLASS_PHY4_TTL_ERR_PKTS));
        }

        if(verb_level >= 9U)
        {
            /*  Get version */
            reg = hal_read32(base_va + CLASS_VERSION);
            len += oal_util_snprintf(buf + len, size - len, "Revision\t0x%x\n", (reg >> 24U) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "Version \t0x%x\n", (reg >> 16U) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "ID      \t0x%x\n", reg & 0xffffU);
        }
            /*  CLASS_ROUTE_MULTI */
            reg = hal_read32(base_va + CLASS_ROUTE_MULTI);
            len += oal_util_snprintf(buf + len, size - len, "CLASS_ROUTE_MULTI \t0x%x\n", reg);

            /*  CLASS_STATE */
            reg = hal_read32(base_va + CLASS_STATE);
            len += oal_util_snprintf(buf + len, size - len, "CLASS_STATE       \t0x%x\n", reg);

            reg = hal_read32(base_va + CLASS_QB_BUF_AVAIL);
            len += oal_util_snprintf(buf + len, size - len, "CLASS_QB_BUF_AVAIL\t0x%x\n", reg);

            reg = hal_read32(base_va + CLASS_RO_BUF_AVAIL);
            len += oal_util_snprintf(buf + len, size - len, "CLASS_RO_BUF_AVAIL\t0x%x\n", reg);

            reg = hal_read32(base_va + CLASS_PE0_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE0 PC\t0x%x\n", reg & 0xffffU);
            reg = hal_read32(base_va + CLASS_PE1_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE1 PC\t0x%x\n", reg & 0xffffU);
            reg = hal_read32(base_va + CLASS_PE2_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE2 PC\t0x%x\n", reg & 0xffffU);
            reg = hal_read32(base_va + CLASS_PE3_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE3 PC\t0x%x\n", reg & 0xffffU);
            reg = hal_read32(base_va + CLASS_PE4_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE4 PC\t0x%x\n", reg & 0xffffU);
            reg = hal_read32(base_va + CLASS_PE5_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE5 PC\t0x%x\n", reg & 0xffffU);
            reg = hal_read32(base_va + CLASS_PE6_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE6 PC\t0x%x\n", reg & 0xffffU);
            reg = hal_read32(base_va + CLASS_PE7_DEBUG);
            len += oal_util_snprintf(buf + len, size - len, "PE7 PC\t0x%x\n", reg & 0xffffU);

            if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
            {
                len += oal_util_snprintf(buf + len, size - len, "Packets freed by HW: %u\n", hal_read32(base_va + CLASS_PE_CUM_DROP_COUNT_ADDR));
            }
            /*  Get info per PHY */
            len += oal_util_snprintf(buf + len, size - len, "[PHY1]\n");

            len += oal_util_snprintf(buf + len, size - len, "RX\t%10u TX\t%10u\nIPV4\t%10u IPV6\t%10u\n",
                    hal_read32(base_va + CLASS_PHY1_RX_PKTS),
                    hal_read32(base_va + CLASS_PHY1_TX_PKTS),
                    hal_read32(base_va + CLASS_PHY1_V4_PKTS),
                    hal_read32(base_va + CLASS_PHY1_V6_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "ICMP\t%10u IGMP\t%10u TCP\t%10u UDP\t%10u\n",
                    hal_read32(base_va + CLASS_PHY1_ICMP_PKTS),
                    hal_read32(base_va + CLASS_PHY1_IGMP_PKTS),
                    hal_read32(base_va + CLASS_PHY1_TCP_PKTS),
                    hal_read32(base_va + CLASS_PHY1_UDP_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "L3 Fail\t%10u CSUM Fail\t%10u TTL Fail\t%10u\n",
                    hal_read32(base_va + CLASS_PHY1_L3_FAIL_PKTS),
                    hal_read32(base_va + CLASS_PHY1_CHKSUM_ERR_PKTS),
                    hal_read32(base_va + CLASS_PHY1_TTL_ERR_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "[PHY2]\n");

            len += oal_util_snprintf(buf + len, size - len, "RX\t%10u TX\t%10u\t IPV4\t%10u IPV6\t%10u\n",
                    hal_read32(base_va + CLASS_PHY2_RX_PKTS),
                    hal_read32(base_va + CLASS_PHY2_TX_PKTS),
                    hal_read32(base_va + CLASS_PHY2_V4_PKTS),
                    hal_read32(base_va + CLASS_PHY2_V6_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "ICMP\t%10u IGMP\t%10u TCP\t%10u UDP\t%10u\n",
                    hal_read32(base_va + CLASS_PHY2_ICMP_PKTS),
                    hal_read32(base_va + CLASS_PHY2_IGMP_PKTS),
                    hal_read32(base_va + CLASS_PHY2_TCP_PKTS),
                    hal_read32(base_va + CLASS_PHY2_UDP_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "L3 Fail\t%10u CSUM Fail\t%10u TTL Fail\t%10u\n",
                    hal_read32(base_va + CLASS_PHY2_L3_FAIL_PKTS),
                    hal_read32(base_va + CLASS_PHY2_CHKSUM_ERR_PKTS),
                    hal_read32(base_va + CLASS_PHY2_TTL_ERR_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "[PHY3]\n");

            len += oal_util_snprintf(buf + len, size - len, "RX\t%10u TX\t%10u\nIPV4\t%10u IPV6\t%10u\n",
                    hal_read32(base_va + CLASS_PHY3_RX_PKTS),
                    hal_read32(base_va + CLASS_PHY3_TX_PKTS),
                    hal_read32(base_va + CLASS_PHY3_V4_PKTS),
                    hal_read32(base_va + CLASS_PHY3_V6_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "ICMP\t%10u IGMP\t%10u TCP\t%10u UDP\t%10u\n",
                    hal_read32(base_va + CLASS_PHY3_ICMP_PKTS),
                    hal_read32(base_va + CLASS_PHY3_IGMP_PKTS),
                    hal_read32(base_va + CLASS_PHY3_TCP_PKTS),
                    hal_read32(base_va + CLASS_PHY3_UDP_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "L3 Fail\t%10u CSUM Fail\t%10u TTL Fail\t%10u\n",
                    hal_read32(base_va + CLASS_PHY3_L3_FAIL_PKTS),
                    hal_read32(base_va + CLASS_PHY3_CHKSUM_ERR_PKTS),
                    hal_read32(base_va + CLASS_PHY3_TTL_ERR_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "[PHY4]\n");

            len += oal_util_snprintf(buf + len, size - len, "RX\t%10u TX\t%10u\nIPV4\t%10u IPV6\t%10u\n",
                    hal_read32(base_va + CLASS_PHY4_RX_PKTS),
                    hal_read32(base_va + CLASS_PHY4_TX_PKTS),
                    hal_read32(base_va + CLASS_PHY4_V4_PKTS),
                    hal_read32(base_va + CLASS_PHY4_V6_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "ICMP\t%10u IGMP\t%10u TCP\t%10u UDP\t%10u\n",
                    hal_read32(base_va + CLASS_PHY4_ICMP_PKTS),
                    hal_read32(base_va + CLASS_PHY4_IGMP_PKTS),
                    hal_read32(base_va + CLASS_PHY4_TCP_PKTS),
                    hal_read32(base_va + CLASS_PHY4_UDP_PKTS));

            len += oal_util_snprintf(buf + len, size - len, "L3 Fail\t%10u CSUM Fail\t%10u TTL Fail\t%10u\n",
                    hal_read32(base_va + CLASS_PHY4_L3_FAIL_PKTS),
                    hal_read32(base_va + CLASS_PHY4_CHKSUM_ERR_PKTS),
                    hal_read32(base_va + CLASS_PHY4_TTL_ERR_PKTS));
    }

    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Enable HW lookup of routing table
 * @param[in]   base_va Base address of CLASS register space (virtual)
 */
void pfe_class_cfg_rtable_lookup_enable(const addr_t base_va)
{
    uint32 reg = hal_read32(base_va + CLASS_ROUTE_MULTI);
    hal_write32(reg | PARSE_ROUTE_EN(TRUE), base_va + CLASS_ROUTE_MULTI);

    NXP_LOG_INFO("Enabling RTable lookup PARSE_ROUTE_EN\n");
}

/**
 * @brief       Enable HW lookup of routing table
 * @param[in]   base_va Base address of CLASS register space (virtual)
 */
void pfe_class_cfg_rtable_lookup_disable(const addr_t base_va)
{
    uint32 reg = hal_read32(base_va + CLASS_ROUTE_MULTI);
    hal_write32(reg & (~PARSE_ROUTE_EN(TRUE)), base_va + CLASS_ROUTE_MULTI);

    NXP_LOG_INFO("Disabling RTable lookup PARSE_ROUTE_EN\n");
}

/**
 * @brief       Enable HW bridge lookup
 * @param[in]   base_va Base address of CLASS register space (virtual)
 */
void pfe_class_cfg_bridge_lookup_enable(const addr_t base_va)
{
    uint32 reg = hal_read32(base_va + CLASS_ROUTE_MULTI);
    hal_write32(reg | PARSE_BRIDGE_EN(TRUE), base_va + CLASS_ROUTE_MULTI);

    NXP_LOG_INFO("Enabling HW bridge lookup PARSE_BRIDGE_EN\n");
}

/**
 * @brief       Disable HW bridge lookup
 * @param[in]   base_va Base address of CLASS register space (virtual)
 */
void pfe_class_cfg_bridge_lookup_disable(const addr_t base_va)
{
    uint32 reg = hal_read32(base_va + CLASS_ROUTE_MULTI);
    hal_write32(reg & (~PARSE_BRIDGE_EN(TRUE)), base_va + CLASS_ROUTE_MULTI); /*direct write*/

    NXP_LOG_INFO("Disabling HW bridge lookup PARSE_BRIDGE_EN\n");
}
/*==================================================================================================*/

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [138/185]: src\pfe_ecc_err.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_ecc_err.h"
#include "pfe_ecc_err_csr.h"

struct pfe_ecc_err_tag
{
    addr_t cbus_base_va;
    addr_t ecc_err_base_offset;
    addr_t ecc_err_base_va;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_ecc_err_t ecc_err_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create new ECC_ERR instance
 * @details     Create and initializes ECC_ERR instance. New instance is always enabled.
 *              Use mask and unmask function to control interrupts.
 * @param[in]   base_va ECC_ERR register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Interrupt which were triggered are masked here, it is periodically unmasked again in SAFETY thread
 */
pfe_ecc_err_t *pfe_ecc_err_create(addr_t cbus_base_va, addr_t ecc_err_base)
{
    pfe_ecc_err_t *ecc_err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ecc_err = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ecc_err = &ecc_err_instance;
        (void)autolibc_memset(ecc_err, 0, sizeof(pfe_ecc_err_t));
        ecc_err->cbus_base_va = cbus_base_va;
        ecc_err->ecc_err_base_offset = ecc_err_base;
        ecc_err->ecc_err_base_va = ADDR_BASE_OFFSET(ecc_err->cbus_base_va, ecc_err->ecc_err_base_offset);

        /* Unmask all interrupts */
        pfe_ecc_err_cfg_irq_unmask_all(ecc_err->ecc_err_base_va);
    }

    return ecc_err;
}

/**
 * @brief       Destroy ECC_ERR instance
 * @param[in]   ecc_err The ECC_ERR instance
 */
void pfe_ecc_err_destroy(pfe_ecc_err_t *ecc_err)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ecc_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Mask ecc_err interrupts */
        pfe_ecc_err_cfg_irq_mask(ecc_err->ecc_err_base_va);
    }
}

/**
 * @brief       ECC_ERR ISR
 * @param[in]   ecc_err The ECC_ERR instance
 * @return      EOK if interrupt has been handled
 */
errno_t pfe_ecc_err_isr(const pfe_ecc_err_t *ecc_err)
{
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ecc_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = ENOMEM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_ecc_err_cfg_isr(ecc_err->ecc_err_base_va);
    }

    return ret;
}

/**
 * @brief       Mask ECC_ERR interrupts
 * @param[in]   ecc_err The ECC_ERR instance
 */
void pfe_ecc_err_irq_mask(const pfe_ecc_err_t *ecc_err)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ecc_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_ecc_err_cfg_irq_mask(ecc_err->ecc_err_base_va);
    }
}

/**
 * @brief       Unmask ECC_ERR interrupts
 * @param[in]   ecc_err The ECC_ERR instance
 */
void pfe_ecc_err_irq_unmask(const pfe_ecc_err_t *ecc_err)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ecc_err))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_ecc_err_cfg_irq_unmask(ecc_err->ecc_err_base_va);
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [139/185]: src\pfe_ecc_err_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_ecc_err_csr.h"
#include "pfe_global_wsp.h"
#include "Eth_43_PFE_Cfg.h"

#define TRIG_EN_INTERRUPTS_CHECK    (ECC_ERR_INT | ECC_MULTI_ERR_INT)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       ECC_ERR ISR
 * @details     MASK, ACK, and process triggered interrupts.
 * @param[in]   base_va ECC_ERR register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 */
errno_t pfe_ecc_err_cfg_isr(addr_t base_va)
{
    uint32 reg_en, reg_src;
    errno_t ret = ENOENT;
    uint32 trig_en_interrupts;

    /*  Get enabled interrupts */
    reg_en = hal_read32(base_va + WSP_ECC_ERR_INT_EN);
    /* Mask ECC Errors interrupts */
    hal_write32((reg_en & ~(ECC_ERR_INT_EN)), base_va + WSP_ECC_ERR_INT_EN);
    /* Get triggered interrupts */
    reg_src = hal_read32(base_va + WSP_ECC_ERR_INT_SRC);
    /* ACK triggered interrupts */
    hal_write32(reg_src, base_va + WSP_ECC_ERR_INT_SRC);

    /* Process interrupts which are triggered AND enabled */
    trig_en_interrupts = reg_src & reg_en & TRIG_EN_INTERRUPTS_CHECK;
    if (0U != trig_en_interrupts)
    {
        pfe_hm_report_error(HM_SRC_ECC, HM_EVT_ECC, "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_PFE_ECC_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
        ret = EOK;
    }

    /*  Enable the non-triggered ones only to prevent flooding */
    hal_write32((reg_en & ~reg_src), base_va + WSP_ECC_ERR_INT_EN);

    return ret;
}

/**
 * @brief       Mask ECC_ERR interrupts
 * @param[in]   base_va Base address of the ECC_ERR register space
 */
void pfe_ecc_err_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_ECC_ERR_INT_EN) & ~(ECC_ERR_INT_EN);
    hal_write32(reg, base_va + WSP_ECC_ERR_INT_EN);
}

/**
 * @brief       Unmask ECC_ERR interrupts
 * @param[in]   base_va Base address of the ECC_ERR register space
 */
void pfe_ecc_err_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_ECC_ERR_INT_EN) | ECC_ERR_INT_EN;
    hal_write32(reg, base_va + WSP_ECC_ERR_INT_EN);
}

/**
 * @brief       Unmask all ECC_ERR interrupts
 * @param[in]   base_va Base address of the ECC_ERR register space
 * @note        This function is called from thread.
 */
void pfe_ecc_err_cfg_irq_unmask_all(addr_t base_va)
{
    hal_write32(ECC_ERR_INT_ENABLE_ALL, base_va + WSP_ECC_ERR_INT_EN);      /*direct write*/
}
/*==================================================================================================*/

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [140/185]: src\pfe_emac.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_emac_csr.h"
#include "pfe_emac.h"
#include "pfe_platform.h"
#include "pfe_mac_db.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_emac_t emac_instance[PFE_EMAC_INSTANCES];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"

/* usage scope: pfe_emac_mdio_lock */
static uint32 key_seed = 123U;

#define ETH_43_PFE_STOP_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#define PFE_CFG_EMAC0_PPS0_PERIOD_SEC ((PFE_CFG_EMAC0_PPS0_PERIOD_TICKS + 1U) / PFE_CFG_IEEE1588_EMAC0_O_CLK_HZ)

static errno_t pfe_emac_del_addr_nolock(pfe_emac_t *emac, const pfe_mac_addr_t addr, pfe_drv_id_t owner);
static uint8 pfe_emac_mac_slot_idx(pfe_emac_t *emac, const pfe_mac_addr_t addr);
static bool_t pfe_emac_mac_hash_col(pfe_emac_t *emac, const pfe_mac_addr_t addr);
static bool_t pfe_emac_mac_in_db(pfe_emac_t *emac, const pfe_mac_addr_t addr);
static addr_t pfe_get_hif_base_addr(pfe_platform_t *platform);

/* 
 * Get HIF base address of HIF register space (virtual)
 */
static addr_t pfe_get_hif_base_addr(pfe_platform_t *platform)
{
    PfeDevAssert((UINT32_MAX - platform->cbus_baseaddr) >= CBUS_HIF_BASE_ADDR); 
    return platform->cbus_baseaddr + CBUS_HIF_BASE_ADDR;
}

/**
 * @brief       Search whether there exist other MAC in EMAC hash table with the same hash index
 * @details     Hash index is calculated according to upper six bits from 32 bit hash value, 
                so only upper six bits from hash value are compared.
 * @param[in]   emac The EMAC instance
 * @param[in]   addr The MAC address to search for
 * @return      TRUE There exist at least one other MAC in database with collision in upper six bits
 * @return      FALSE No match
 */
static bool_t pfe_emac_mac_hash_col(pfe_emac_t *emac, const pfe_mac_addr_t addr)
{
    errno_t ret;
    bool_t found = FALSE;
    pfe_mac_addr_t addr_temp;
    const uint32 hash_match_mask = pfe_emac_cfg_get_hash(emac->emac_base_va, addr) & EMAC_CFG_MAC_HASH_MASK;
    
    ret = pfe_mac_db_get_first_addr(&emac->mac_db, MAC_DB_CRIT_ALL, PFE_TYPE_ANY, PFE_PHY_IF_ID_MAX, addr_temp);
    while (EOK == ret)
    {
        if (EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT == pfe_emac_mac_slot_idx(emac, addr_temp))
        {
            /* Not exists in slot, must be in hash table */
            uint32 hash_temp = pfe_emac_cfg_get_hash(emac->emac_base_va, addr_temp);
            if ((EMAC_CFG_MAC_HASH_MASK & hash_temp) == hash_match_mask)
            {
                /* found hash colision in upper six bits */
                found = TRUE;
                break;
            }
            
        }
        
        ret = pfe_mac_db_get_next_addr(&emac->mac_db, addr_temp);
    }
    
    return found;
}

/**
 * @brief       Search whether MAC is stored in EMAC exact match slot or not
 * @param[in]   emac The EMAC instance
 * @param[in]   addr The MAC address to search for
 * @return      If found, returns slot index, otherwise returns EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT
 */
static uint8 pfe_emac_mac_slot_idx(pfe_emac_t *emac, const pfe_mac_addr_t addr)
{
    uint8 found_idx = EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT;
    pfe_mac_addr_t addr_in_slot;
    
    /* Try to find address in individual address slot */
    for (uint8 slot = 0U; slot < EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT; slot++)
    {
        if (0U != (emac->mac_addr_slots & (1U << slot)))
        {
            /* Slot is in use, check address */
            pfe_emac_cfg_read_addr_slot(emac->emac_base_va, addr_in_slot, slot);
            if (0 == autolibc_memcmp(addr, addr_in_slot, sizeof(pfe_mac_addr_t)))
            {
                /* Address found */
                found_idx = slot;
                break;
            }
        }
    }
    return found_idx;
}

/**
 * @brief       Search whether given MAC exists in db
 * @param[in]   emac The EMAC instance
 * @param[in]   addr The MAC address to search for
 * @return      TRUE There exist at least one other MAC in database
 * @return      FALSE No match
 */
static bool_t pfe_emac_mac_in_db(pfe_emac_t *emac, const pfe_mac_addr_t addr)
{
    errno_t ret;
    bool_t found = FALSE;
    pfe_mac_addr_t addr_temp;
    
    ret = pfe_mac_db_get_first_addr(&emac->mac_db, MAC_DB_CRIT_ALL, PFE_TYPE_ANY, PFE_PHY_IF_ID_MAX, addr_temp);
    while (EOK == ret)
    {
        if (0 == autolibc_memcmp(addr, addr_temp, sizeof(pfe_mac_addr_t)))
        {
            found = TRUE;
            break;
        }            
        
        ret = pfe_mac_db_get_next_addr(&emac->mac_db, addr_temp);
    }
    return found;
}

/**
 * @brief       Helper function for pfe_emac_create
 * @param[in]   emac The EMAC instance
*/
static void pfe_emac_create_configure(pfe_emac_t *emac)
{
    /*  Disable loop-back */
    pfe_emac_disable_loopback(emac);

    /*  Disable promiscuous mode */
    pfe_emac_disable_promisc_mode(emac);

    /*  Disable broadcast */
    pfe_emac_disable_broadcast(emac);
}

/**
 * @brief       Create new EMAC instance
 * @details     Creates and initializes MAC instance
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   emac_base EMAC base address offset within CBUS address space
 * @param[in]   mode The MII mode to be used @see pfe_emac_mii_mode_t
 * @param[in]   speed Speed @see pfe_emac_speed_t
 * @param[in]   duplex The duplex type @see pfe_emac_duplex_t
 * @return      The EMAC instance or NULL if failed
 */
pfe_emac_t *pfe_emac_create(addr_t cbus_base_va, addr_t emac_base, pfe_emac_mii_mode_t mode, pfe_emac_speed_t speed, pfe_emac_duplex_t duplex)
{
    pfe_emac_t *emac;
    uint8 emac_index = 255U;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        emac = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        PfeDevAssert((UINT32_MAX - emac_base) >= cbus_base_va);
        emac_index = pfe_emac_cfg_get_index(emac_base + cbus_base_va, cbus_base_va);
        if (unlikely(PFE_EMAC_INSTANCES <= emac_index))
        {
            NXP_LOG_ERROR("EMAC index out of range\n");
            emac = NULL;
        }
        else
        {
            emac = &emac_instance[emac_index];
            (void)autolibc_memset(emac, 0, sizeof(pfe_emac_t));
            emac->cbus_base_va = cbus_base_va;
            emac->emac_base_offset = emac_base;
            emac->emac_base_va = (emac->cbus_base_va + emac->emac_base_offset);
            emac->mode = EMAC_MODE_INVALID;
            emac->speed = EMAC_SPEED_INVALID;
            emac->duplex = EMAC_DUPLEX_INVALID;
            emac->emac_id = (pfe_ct_phy_if_id_t)emac_index;

            /*  All slots are free */
            emac->mac_addr_slots = 0U;

            /*  Initialize the MAC address DB. We do not check the return value because the only reason to fail
             *  is when NULL pointer is provided. */
            (void) pfe_mac_db_create(&emac->mac_db);

            /* ERR050221: to ensure parity_en is set before any registers READ to MAC */
            pfe_emac_cfg_pre_init(emac->emac_base_va);
            
            /*  Disable the HW */
            pfe_emac_disable(emac);

            /*  Initialize the HW */
            if (EOK != pfe_emac_cfg_init(emac->emac_base_va, mode, speed, duplex))
            {
                /*  Invalid configuration */
                NXP_LOG_ERROR("Invalid configuration requested\n");
                emac = NULL;
            }
            else
            {
                emac->mode = mode;
                emac->speed = speed;
                emac->duplex = duplex;

                pfe_emac_create_configure(emac);
            }
        }
    }

    return emac;
}

/**
 * @brief       Get EMAC instance index
 * @param[in]   emac The EMAC instance
 * @return      Index (0, 1, 2, ..) or 255 if failed
 */
uint8 pfe_emac_get_index(const pfe_emac_t *emac)
{
    uint8 emac_idx;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        emac_idx = 255U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        emac_idx = pfe_emac_cfg_get_index(emac->emac_base_va, emac->cbus_base_va);
    }
    return emac_idx;
}

errno_t pfe_emac_bind_gpi(pfe_emac_t *emac, pfe_gpi_t *gpi)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == gpi)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        emac->gpi = gpi;
        ret = EOK;
    }

    return ret;
}

/* Return EMAC's GPI */
pfe_gpi_t *pfe_emac_get_gpi(const pfe_emac_t *emac)
{
    return emac->gpi;
}

/**
 * @brief       Enable the EMAC
 * @details     Data transmission/reception is possible after this call
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_enable(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_enable(emac->emac_base_va, TRUE);
    }
}

/**
 * @brief       Disable the EMAC
 * @details     No data transmission/reception is possible after this call
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_disable(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_enable(emac->emac_base_va, FALSE);
    }
}

/**
 * @brief       Enable timestamping
 * @param[in]   emac The EMAC instance
 * @param[in]   i_clk_hz Input reference clock frequency (Hz) when internal timer is
 *                     used. The timer ticks with 1/clk_hz period. If zero then external
 *                     clock reference is used.
 * @param[in]   o_clk_hz Desired output clock frequency. This one will be used to
 *                       increment IEEE1588 system time. Directly impacts the timer
 *                       accuracy and must be less than i_clk_hz. If zero then external
 *                       clock reference is used.
 */
errno_t pfe_emac_enable_ts(pfe_emac_t *emac, uint32 i_clk_hz, uint32 o_clk_hz)
{
    errno_t ret = EOK;
    bool_t is_owner = FALSE;
    bool_t eclk = (i_clk_hz == 0U) || (o_clk_hz == 0U);

    if (!eclk && (i_clk_hz <= o_clk_hz))
    {
        NXP_LOG_ERROR("Invalid clock configuration\n");
        ret = EINVAL;
    }
    else
    {
        ret = pfe_emac_local_is_timer_owner(emac, &is_owner);

        if ((EOK == ret) && (TRUE == is_owner))
        {
            emac->i_clk_hz = i_clk_hz;
            emac->o_clk_hz = o_clk_hz;
            oal_mutex_lock(PFE_EMAC_TS_MUTEX_00);
            ret = pfe_emac_cfg_enable_ts(emac->emac_base_va, eclk, i_clk_hz, o_clk_hz);
            oal_mutex_unlock(PFE_EMAC_TS_MUTEX_00);
        }
        else
        {
            ret = EPERM;
        }
    }
    return ret;
}

/**
 * @brief       Adjust timestamping clock frequency to compensate drift
 * @param[in]   emac The EMAC instance
 * @param[in]   ppb Frequency change in [ppb]
 * @param[in]   pos The ppb sign. If TRUE then the value is positive, else it is negative
 */
errno_t pfe_emac_set_ts_freq_adjustment(pfe_emac_t *emac, uint32 ppb, bool_t sgn)
{
    errno_t ret = EOK;
    bool_t is_owner = FALSE;

    ret = pfe_emac_local_is_timer_owner(emac, &is_owner);

    if ((EOK == ret) && (TRUE == is_owner))
    {
        oal_mutex_lock(PFE_EMAC_TS_MUTEX_01);
        emac->adj_ppb = ppb;
        emac->adj_sign = sgn;
        ret = pfe_emac_cfg_adjust_ts_freq(emac->emac_base_va, emac->i_clk_hz, emac->o_clk_hz, ppb, sgn);
        oal_mutex_unlock(PFE_EMAC_TS_MUTEX_01);
    }
    else
    {
        ret = EPERM;
    }

    return ret;
}

/**
 * @brief           Get current adjustment value
 * @param[in]       emac The EMAC instance
 * @param[in,out]   ppb Pointer where the current adjustment value in ppb shall be written
 * @param[in,out]   sgn Pointer where the sign flag shall be written (TRUE means that
 *                  the 'ppb' is positive, FALSE means it is nagative)
 * @return          EOK if success, error code otherwise
 */
errno_t pfe_emac_get_ts_freq_adjustment(pfe_emac_t *emac, uint32 *ppb, bool_t *sgn)
{
    errno_t ret = EOK;
    
    if ((NULL == ppb) || (NULL == sgn))
    {
        ret = EINVAL;
    }
    else
    {
        *ppb = emac->adj_ppb;
        *sgn = emac->adj_sign;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief           Get current time
 * @param[in]       emac THe EMAC instance
 * @param[in,out]   sec Pointer where seconds value shall be written
 * @param[in,out]   nsec Pointer where nano-seconds value shall be written
 * @param[in,out]   sec_hi Pointer where higher-word-seconds value shall be written
 * @return          EOK if success, error code otherwise
 */
errno_t pfe_emac_get_ts_time(pfe_emac_t *emac, uint32 *sec, uint32 *nsec, uint16 *sec_hi)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((NULL == sec) || (NULL == nsec) || (NULL == sec_hi))
        {
            ret = EINVAL;
        }
        else
        {
            pfe_emac_cfg_get_ts_time(emac->emac_base_va, sec, nsec, sec_hi);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Adjust current time
 * @details     Current timer value will be adjusted by adding or subtracting the
 *              desired value.
 * @param[in]   emac The EMAC instance
 * @param[in]   sec Seconds
 * @param[in]   nsec NanoSeconds
 * @param[in]   sgn Sign of the adjustment. If TRUE then the adjustment will be positive
 *                  ('sec' and 'nsec' will be added to the current time. If FALSE then the
 *                  adjustment will be negative ('sec' and 'nsec' will be subtracted from
 *                  the current time).
 */
errno_t pfe_emac_adjust_ts_time(pfe_emac_t *emac, uint32 sec, uint32 nsec, bool_t sgn)
{
    errno_t ret = EOK;
    bool_t is_owner = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {

        ret = pfe_emac_local_is_timer_owner(emac, &is_owner);

        if ((EOK == ret) && (TRUE == is_owner))
        {
            oal_mutex_lock(PFE_EMAC_TS_MUTEX_02);
            ret = pfe_emac_cfg_adjust_ts_time(emac->emac_base_va, sec, nsec, sgn);
            oal_mutex_unlock(PFE_EMAC_TS_MUTEX_02);
        }
        else
        {
            ret = EPERM;
        }
    }

    return ret;
}

/**
 * @brief       Set current time
 * @details     Funcion will set new system time. Current timer value
 *              will be overwritten with the desired value.
 * @param[in]   emac The EMAC instance
 * @param[in]   sec New seconds value
 * @param[in]   nsec New nano-seconds value
 * @param[in]   sec_hi New higher-word-seconds value
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_emac_set_ts_time(pfe_emac_t *emac, uint32 sec, uint32 nsec, uint16 sec_hi)
{
    errno_t ret = EOK;
    bool_t is_owner = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_local_is_timer_owner(emac, &is_owner);

        if ((EOK == ret) && (TRUE == is_owner))
        {
            oal_mutex_lock(PFE_EMAC_TS_MUTEX_03);
            ret = pfe_emac_cfg_set_ts_time(emac->emac_base_va, sec, nsec, sec_hi);
            oal_mutex_unlock(PFE_EMAC_TS_MUTEX_03);
        }
        else
        {
            ret = EPERM;
        }
    }

    return ret;
}

/**
 * @brief       Enable the local loop-back mode
 * @details     This function controls the EMAC internal loop-back mode
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_enable_loopback(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_loopback(emac->emac_base_va, TRUE);
    }
}

/**
 * @brief       Disable loop-back mode
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_disable_loopback(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_loopback(emac->emac_base_va, FALSE);
    }
}

/**
 * @brief       Enable promiscuous mode
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_enable_promisc_mode(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_promisc_mode(emac->emac_base_va, TRUE);
    }
}

/**
 * @brief       Disable promiscuous mode
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_disable_promisc_mode(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_promisc_mode(emac->emac_base_va, FALSE);
    }
}

/**
 * @brief       Enable ALLMULTI mode
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_enable_allmulti_mode(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_allmulti_mode(emac->emac_base_va, TRUE);
    }
}

/**
 * @brief       Disable ALLMULTI mode
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_disable_allmulti_mode(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_allmulti_mode(emac->emac_base_va, FALSE);
    }
}

/**
 * @brief       Enable broadcast reception
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_enable_broadcast(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_broadcast(emac->emac_base_va, TRUE);
    }
}

/**
 * @brief       Disable broadcast reception
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_disable_broadcast(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_broadcast(emac->emac_base_va, FALSE);
    }
}

void pfe_emac_get_flow_control(const pfe_emac_t *emac, bool_t *tx_enable, bool_t *rx_enable)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac) || unlikely(NULL == tx_enable) ||
        unlikely(NULL == rx_enable))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_get_tx_flow_control(emac->emac_base_va,tx_enable);
        pfe_emac_cfg_get_rx_flow_control(emac->emac_base_va,rx_enable);
    }
}

/**
 * @brief       Enable tx flow control
 * @details     Enables PAUSE frames processing
 * @param       emac The EMAC instance
 */
void pfe_emac_enable_tx_flow_control(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_tx_flow_control(emac->emac_base_va, TRUE);
    }
}

/**
 * @brief       Disable tx flow control
 * @details     Disables PAUSE frames processing
 * @param       emac The EMAC instance
 */
void pfe_emac_disable_tx_flow_control(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_tx_flow_control (emac->emac_base_va, FALSE);
    }
}

/**
 * @brief               Enable rx flow control
 * @details             Enables PAUSE frames processing
 * @param               emac The EMAC instance
 */
void pfe_emac_enable_rx_flow_control(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_rx_flow_control(emac->emac_base_va, TRUE);
    }
}

/**
 * @brief               Disable rx flow control
 * @details             Disables PAUSE frames processing
 * @param               emac The EMAC instance
 */
void pfe_emac_disable_rx_flow_control(const pfe_emac_t *emac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_emac_cfg_set_rx_flow_control(emac->emac_base_va, FALSE);
    }
}


/**
 * @brief       Set maximum frame length
 * @param       emac The EMAC instance
 * @param       len New frame length
 * @return      EOK if success errno otherwise
 */
errno_t pfe_emac_set_max_frame_length(const pfe_emac_t *emac, uint32 len)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_cfg_set_max_frame_length(emac->emac_base_va, len);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Attempt to set unsupported frame length value\n");
        }
    }
    return ret;
}

/**
 * @brief       Get current MII mode
 * @param[in]   emac The EMAC instance
 * @return      Currently configured MII mode @see pfe_emac_mii_mode_t
 */
pfe_emac_mii_mode_t pfe_emac_get_mii_mode(const pfe_emac_t *emac)
{
    pfe_emac_mii_mode_t mii_mode;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        mii_mode = EMAC_MODE_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        mii_mode = emac->mode;
    }
    return mii_mode;
}

/**
 * @brief       Get the EMAC link configuration
 * @param[in]   emac The EMAC instance
 * @param[out]  speed The EMAC speed configuration @see pfe_emac_speed_t
 * @param[out]  duplex The EMAC duplex configuration @see pfe_emac_duplex_t
 * @return      EOK if success
 */
errno_t pfe_emac_get_link_config(const pfe_emac_t *emac, pfe_emac_speed_t *speed, pfe_emac_duplex_t *duplex)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_cfg_get_link_config(emac->emac_base_va, speed, duplex);
    }

    return ret;
}

/**
 * @brief       Get the EMAC link status
 * @param[in]   emac The EMAC instance
 * @param[out]  speed The EMAC link speed @see pfe_emac_link_speed_t
 * @param[out]  duplex The EMAC duplex status @see pfe_emac_duplex_t
 * @param[out]  link The EMAC link status
 * @return      EOK if success
 */
errno_t pfe_emac_get_link_status(const pfe_emac_t *emac, pfe_emac_link_speed_t *link_speed, pfe_emac_duplex_t *duplex, bool_t *link)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_cfg_get_link_status(emac->emac_base_va, link_speed, duplex, link);
    }
    return ret;
}

/**
 * @brief       Set the EMAC link speed
 * @param[in]   emac The EMAC instance
 * @param[in]   link_speed The EMAC link speed @see pfe_emac_link_speed_t
 * @return      EOK if success
 * @details     This function can be used for runtime changes of speed (eg. after auto-negotiation).
 */
errno_t pfe_emac_set_link_speed(const pfe_emac_t *emac, pfe_emac_speed_t link_speed)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_cfg_set_speed(emac->emac_base_va, link_speed);
    }

    return ret;
}

/**
 * @brief       Set the EMAC link duplex
 * @param[in]   emac The EMAC instance
 * @param[in]   duplex The EMAC duplex @see pfe_emac_duplex_t
 * @return      EOK if success
 * @details     This function can be used for runtime changes of duplex (eg. after auto-negotiation).
 */
errno_t pfe_emac_set_link_duplex(const pfe_emac_t *emac, pfe_emac_duplex_t duplex)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_cfg_set_duplex(emac->emac_base_va, duplex);
    }

    return ret;
}

/**
 * @brief       Delete MAC addresses added by owner with defined type
 * @param[in]   emac The EMAC instance
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner The identification of driver instance
 * @return      EOK if success
 * @return      EINVAL NULL argument received
 * @note        Must not be preempted by: pfe_emac_del_addr(), pfe_emac_add_addr(), pfe_emac_destroy()
 */
errno_t pfe_emac_flush_mac_addrs(pfe_emac_t *emac, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner)
{
    pfe_mac_db_list_entry_t entry;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_EMAC_MUTEX_00);
        
        ret = pfe_mac_db_find_by_crit(&emac->mac_db, crit, type, owner, &entry);
        while (EOK == ret)
        {
            ret = pfe_emac_del_addr_nolock(emac, entry.addr, entry.owner);
            if (EOK == ret)
            {
                NXP_LOG_DEBUG(  "Address %02x:%02x:%02x:%02x:%02x:%02x removed from owner ID %d\n",
                                entry.addr[0],
                                entry.addr[1],
                                entry.addr[2],
                                entry.addr[3],
                                entry.addr[4],
                                entry.addr[5],
                                entry.owner);
                ret = pfe_mac_db_find_by_crit(&emac->mac_db, crit, type, owner, &entry);
            }
            else
            {
                NXP_LOG_WARNING("Can't remove MAC address within the flush function\n");
            }
        }
        
        if (ENOENT == ret)
        {
            /* It is expected to be stopped with ENOENT */
            ret = EOK;
        }
        
        oal_mutex_unlock(PFE_EMAC_MUTEX_00);
    }

    return ret;
}

/**
 * @brief       Remove MAC address from EMAC
 * @details     Address resolution will be done using exact match with the added address
 * @param[in]   emac The EMAC instance
 * @param[in]   addr The MAC address to delete
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      ENOENT Address not found
 * @note        Must not be preempted by: pfe_emac_add_addr(), pfe_emac_destroy()
 */
errno_t pfe_emac_del_addr(pfe_emac_t *emac, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_EMAC_MUTEX_01);

        ret = pfe_emac_del_addr_nolock(emac, addr, owner);

        oal_mutex_unlock(PFE_EMAC_MUTEX_01);
    }

    return ret;
}

/**
 * @brief       Remove MAC address from EMAC without entering the critical section
 * @details     Address resolution will be done using exact match with the added address
 * @param[in]   emac The EMAC instance
 * @param[in]   addr The MAC address to delete
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      ENOENT Address not found
 * @note        Must not be preempted by: pfe_emac_add_addr(), pfe_emac_destroy()
 */
static errno_t pfe_emac_del_addr_nolock(pfe_emac_t *emac, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Remove entry from database */
        ret = pfe_mac_db_del_addr(&emac->mac_db, addr, owner);
        
        if (EOK == ret)
        {
            if (FALSE == pfe_emac_mac_in_db(emac, addr))
            {
                /* The address is not in db any more, it must removed from EMAC filter */
                
                /* Try to find address in individual address slot */
                uint8 slot = pfe_emac_mac_slot_idx(emac, addr);
                
                if (slot < EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT)
                {
                    /* Address was found in slot, delete this entry by writing zero filled address */
                    pfe_mac_addr_t zero_address;
                    (void)autolibc_memset(zero_address, 0, sizeof(pfe_mac_addr_t));
                    pfe_emac_cfg_write_addr_slot(emac->emac_base_va, zero_address, slot);
                    
                    /*  Mark the slot as unused */
                    emac->mac_addr_slots &= ~(1U << slot);
                }
                else
                {
                    /* Address exist in hash table, check whether to removed hash idx or not */
                    if (FALSE == pfe_emac_mac_hash_col(emac, addr))
                    {
                        /* There is no other address in db with same hash idx, clear hash idx */
                        uint32 hash = pfe_emac_cfg_get_hash(emac->emac_base_va, addr);
                        pfe_emac_cfg_set_hash_group(emac->emac_base_va, hash, FALSE);
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Assign an individual MAC address to EMAC
 * @param[in]   emac The EMAC instance
 * @param[in]   addr The MAC address to add
 * @retval      EOK Success
 * @retval      EINVAL NULL pointer or broadcast MAC provided
 * @retval      ENOMEM Not enough memory
 * @retval      EEXIST Address already added
 * @note        Must not be preempted by: pfe_emac_del_addr(), pfe_emac_destroy()
 */
errno_t pfe_emac_add_addr(pfe_emac_t *emac, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (pfe_emac_is_broad(addr))
        {
            NXP_LOG_ERROR("broadcast MAC received\n");
            ret = EINVAL;
        }
        else
        {
            oal_mutex_lock(PFE_EMAC_MUTEX_02);

            /* Store address into EMAC's database */
            ret = pfe_mac_db_add_addr(&emac->mac_db, addr, owner);
            
            if (EOK == ret)
            {
                /* Check if the address (not owner related) already exists in slot */
                uint32 slot = pfe_emac_mac_slot_idx(emac, addr);
                if (EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT == slot)
                {
                    /* Address is not in slot, get free slot or add to hash table */
                    
                    /*  Try to get free individual address slot */
                    for (slot=0U; slot<EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT; slot++)
                    {
                        if (0U == (emac->mac_addr_slots & (1U << slot)))
                        {
                            /*  Found */
                            break;
                        }
                    }

                    /* Slots are full, add hash of the address into the hash table */
                    if (EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT == slot)
                    {
                        /*  Get the hash */
                        uint32 hash = pfe_emac_cfg_get_hash(emac->emac_base_va, addr);

                        /*  Configure the HW */
                        pfe_emac_cfg_set_hash_group(emac->emac_base_va, hash, TRUE);
                    }
                    /* There is free address slot, use it */
                    else
                    {
                        /*  Mark the slot as used */
                        emac->mac_addr_slots |= (1U << slot);

                        /*  Write the address to HW as individual address */
                        pfe_emac_cfg_write_addr_slot(emac->emac_base_va, addr, (uint8)slot);
                    }
                }
            }
            oal_mutex_unlock(PFE_EMAC_MUTEX_02);
        }
    }

    return ret;
}


/**
 * @brief       Destroy MAC instance
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_destroy(pfe_emac_t *emac)
{
    if (NULL != emac)
    {
        pfe_mac_addr_t zero_address;
        (void)autolibc_memset(zero_address, 0, sizeof(pfe_mac_addr_t));


        /* Clear MAC db */
        (void)autolibc_memset(&emac->mac_db, 0, sizeof(pfe_mac_db_t));

        /* Clear MAC exact match slots */
        for (uint8 slot = 0U; slot < EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT; slot++)
        {
            /* Delete this entry by writing zero filled address */
            pfe_emac_cfg_write_addr_slot(emac->emac_base_va, zero_address, slot);

            /*  Mark the slot as unused */
            emac->mac_addr_slots &= ~(1U << slot);
        }

        /* Clear hash table */
        pfe_emac_cfg_clear_hash_table(emac->emac_base_va);

        /*  Disable traffic */
        pfe_emac_disable(emac);

        /*  Disable TS */
        pfe_emac_cfg_disable_ts(emac->emac_base_va);
    }
}

/**
 * @brief       Lock access to MDIO resource
 * @details     Once locked, only lock owner can perform MDIO accesses
 * @param[in]   emac The EMAC instance
 * @param[out]  key Pointer to memory where the key to be used for access to locked MDIO and for
 *                  unlock shall be stored
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_emac_mdio_lock(pfe_emac_t *emac, uint32 *key)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == key)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_EMAC_MUTEX_03);

        if (TRUE == emac->mdio_locked)
        {
            ret = EPERM;
        }
        else
        {
            /*  Perform lock + generate and store access key */
            emac->mdio_locked = TRUE;
            emac->mdio_key = key_seed;
            key_seed = (uint32)(((uint64)key_seed + 1U) & UINT32_MAX);  /* Expected to wrap */
            *key = emac->mdio_key;
            ret = EOK;
        }

        oal_mutex_unlock(PFE_EMAC_MUTEX_03);
    }

    return ret;
}

/**
 * @brief       Unlock access to MDIO resource
 * @details     Once locked, only lock owner can perform MDIO accesses
 * @param[in]   emac The EMAC instance
 * @param[in]   key The key
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_emac_mdio_unlock(pfe_emac_t *emac, uint32 key)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == emac->mdio_locked)
        {
            if (key == emac->mdio_key)
            {
                emac->mdio_locked = FALSE;
                ret = EOK;
            }
            else
            {
                ret = EPERM;
            }
        }
        else
        {
            ret = ENOLCK;
        }
    }

    return ret;
}

/**
 * @brief       Read value from the MDIO bus using Clause 22
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   ra Register address
 * @param[out]  val If success the the read value is written here
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_read22(pfe_emac_t *emac, uint8 pa, uint8 ra, uint16 *val, uint32 key)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == emac->mdio_locked)
        {
            /*  Locked. Check key. */
            if (key == emac->mdio_key)
            {
                ret = pfe_emac_cfg_mdio_read22(emac->emac_base_va, pa, ra, val);
            }
            else
            {
                ret = EPERM;
            }
        }
        else
        {
            /*  Unlocked. No check required. */
            ret = pfe_emac_cfg_mdio_read22(emac->emac_base_va, pa, ra, val);
        }
    }

    return ret;
}

/**
 * @brief       Write value to the MDIO bus using Clause 22
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   ra Register address
 * @param[in]   val Value to be written
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_write22(pfe_emac_t *emac, uint8 pa, uint8 ra, uint16 val, uint32 key)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == emac->mdio_locked)
        {
            /*  Locked. Check key. */
            if (key == emac->mdio_key)
            {
                ret = pfe_emac_cfg_mdio_write22(emac->emac_base_va, pa, ra, val);
            }
            else
            {
                ret = EPERM;
            }
        }
        else
        {
            /*  Unlocked. No check required. */
            ret = pfe_emac_cfg_mdio_write22(emac->emac_base_va, pa, ra, val);
        }
    }
    return ret;
}

/**
 * @brief       Read value from the MDIO bus using Clause 45
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   dev Device address
 * @param[in]   ra Register address
 * @param[out]  val If success the the read value is written here
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_read45(pfe_emac_t *emac, uint8 pa, uint8 dev, uint16 ra, uint16 *val, uint32 key)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == emac->mdio_locked)
        {
            /*  Locked. Check key. */
            if (key == emac->mdio_key)
            {
                ret = pfe_emac_cfg_mdio_read45(emac->emac_base_va, pa, dev, ra, val);
            }
            else
            {
                ret = EPERM;
            }
        }
        else
        {
            /*  Unlocked. No check required. */
            ret = pfe_emac_cfg_mdio_read45(emac->emac_base_va, pa, dev, ra, val);
        }
    }

    return ret;
}

/**
 * @brief       Write value to the MDIO bus using Clause 45
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   dev Device address
 * @param[in]   ra Register address
 * @param[in]   val Value to be written
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_write45(pfe_emac_t *emac, uint8 pa, uint8 dev, uint16 ra, uint16 val, uint32 key)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == emac->mdio_locked)
        {
            /*  Locked. Check key. */
            if (key == emac->mdio_key)
            {
                ret = pfe_emac_cfg_mdio_write45(emac->emac_base_va, pa, dev, ra, val);
            }
            else
            {
                ret = EPERM;
            }
        }
        else
        {
            /*  Unlocked. No check required. */
            ret = pfe_emac_cfg_mdio_write45(emac->emac_base_va, pa, dev, ra, val);
        }
    }

    return ret;
}

/**
 * @brief       Get number of received packets
 * @param[in]   emac The EMAC instance
 * @return      Number of received packets
 */
uint32 pfe_emac_get_rx_cnt(const pfe_emac_t *emac)
{
    uint32 rx_cnt;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        rx_cnt = 0xFFFFFFFFU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        rx_cnt = pfe_emac_cfg_get_rx_cnt(emac->emac_base_va);
    }
    return rx_cnt;
}

/**
 * @brief       Get number of transmitted packets
 * @param[in]   emac The EMAC instance
 * @return      Number of transmitted packets
 */
uint32 pfe_emac_get_tx_cnt(const pfe_emac_t *emac)
{
    uint32 tx_cnt;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        tx_cnt = 0xFFFFFFFFU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tx_cnt = pfe_emac_cfg_get_tx_cnt(emac->emac_base_va);
    }
    return tx_cnt;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return EMAC runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   gpi         The EMAC instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_emac_get_text_statistics(const pfe_emac_t *emac, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += pfe_emac_cfg_get_text_stat(emac->emac_base_va, buf + len, buf_len - len, verb_level);
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get EMAC statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the EMAC block.
 * @param[in]   emac        The EMAC instance
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic
 */
uint32 pfe_emac_get_stat_value(const pfe_emac_t *emac, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = 0xFFFFFFFFU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = pfe_emac_cfg_get_stat_value(emac->emac_base_va, stat_id);
    }
    return stat_value;
}

/**
 * @brief       EMAC ISR
 * @param[in]   emac The EMAC instance
 */
errno_t pfe_emac_isr(pfe_emac_t *emac)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_cfg_isr(emac->emac_base_va, emac->cbus_base_va);
    }

    return ret;
}

/**
 * @brief       Mask EMAC interrupts
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_irq_mask(pfe_emac_t *emac)
{
    (void)emac;
}

/**
 * @brief       Unmask EMAC interrupts
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_irq_unmask(pfe_emac_t *emac)
{
    (void)emac;
}

/**
 * @brief       Set the driver instance is the timer owner of EMAC
 * @param[in]   emac The EMAC instance
 * @param[in]   drv_id The identification of driver instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_emac_set_timer_ownership(pfe_emac_t *emac, pfe_drv_id_t drv_id)
{
    errno_t ret = EOK;
    bool_t has_owner = FALSE;
    pfe_drv_id_t drv_id_owner = PFE_PHY_IF_ID_INVALID;
    pfe_platform_t *platform = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        platform = pfe_platform_get_instance();
        if (NULL_PTR == platform)
        {
            ret = EINVAL;
            NXP_LOG_ERROR("Could not get PFE platform instance\n");
        }
        else
        {
            oal_mutex_lock(PFE_EMAC_TS_MUTEX_04);
            ret = pfe_emac_check_timer_ownership(emac, &has_owner, &drv_id_owner);
            if ((EOK == ret) && (FALSE == has_owner)) /* check no owner yet*/
            {
                ret = pfe_hif_chnl_set_emac_timer_ownership(pfe_get_hif_base_addr(platform), drv_id, emac->emac_id, TRUE);
            }
            else
            {
                ret = EPERM;
            }
            oal_mutex_unlock(PFE_EMAC_TS_MUTEX_04);
        }
    }

    return ret;
}

/**
 * @brief       Check if any driver instance associated with HIF instances is the timer owner of EMAC
 * @param[in]   emac The EMAC instance
 * @param[out]  has_owner The ownership value shall be written here.
 *              TRUE if having another driver instance is the timer owner of EMAC. FALSE otherwise
 * @param[out]  drv_id The driver instance is currently the owner of EMAC
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_emac_check_timer_ownership(pfe_emac_t *emac, bool_t *has_owner, pfe_drv_id_t *drv_id)
{
    errno_t ret = EOK;
    pfe_platform_t *platform = NULL;
    pfe_ct_phy_if_id_t chnl_id = PFE_PHY_IF_ID_INVALID;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == has_owner)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *has_owner = FALSE;

        platform = pfe_platform_get_instance();
        if (NULL_PTR == platform)
        {
            ret = EINVAL;
            NXP_LOG_ERROR("Could not get PFE platform instance\n");
        }
        else
        {
            for (chnl_id = PFE_PHY_IF_ID_HIF_NOCPY; chnl_id <= PFE_PHY_IF_ID_HIF3; chnl_id++)
            {
                if (PFE_PHY_IF_ID_UTIL == chnl_id)
                {
                    continue;
                }

                *has_owner = pfe_hif_chnl_get_emac_timer_ownership(pfe_get_hif_base_addr(platform), chnl_id, emac->emac_id);
                ret = EOK;

                if (TRUE == (*has_owner))
                {
                    *drv_id = chnl_id;
                    break;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Clear timer ownership status for the driver instance
 * @param[in]   emac The EMAC instance
 * @param[in]   drv_id The identification of driver instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_emac_clear_timer_ownership(pfe_emac_t *emac, pfe_drv_id_t drv_id)
{
    errno_t ret = EOK;
    pfe_platform_t *platform = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        platform = pfe_platform_get_instance();
        if (NULL_PTR == platform)
        {
            ret = EINVAL;
            NXP_LOG_ERROR("Could not get PFE platform instance\n");
        }
        else
        {
            oal_mutex_lock(PFE_EMAC_TS_MUTEX_05);
            if (TRUE == pfe_hif_chnl_get_emac_timer_ownership(pfe_get_hif_base_addr(platform), drv_id, emac->emac_id)) /* check if specified PFE instance is the owner */
            {
                ret = pfe_hif_chnl_set_emac_timer_ownership(pfe_get_hif_base_addr(platform), drv_id, emac->emac_id, FALSE);
            }
            else
            {
                ret = EPERM;
            }
            oal_mutex_unlock(PFE_EMAC_TS_MUTEX_05);
        }
    }

    return ret;
}

/**
 * @brief       Check if the driver instance associated with the local HIF is the timer owner of EMAC
 * @param[in]   emac The EMAC instance
 * @param[out]  is_owner The timer ownership status shall be written here
 * @return      EOK if sucess, error code otherwise
 */
errno_t pfe_emac_local_is_timer_owner(pfe_emac_t *emac, bool_t *is_owner)
{
    errno_t ret = EOK;
    pfe_platform_t *platform = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == is_owner)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        platform = pfe_platform_get_instance();
        if (NULL_PTR == platform)
        {
            ret = EINVAL;
            NXP_LOG_ERROR("Could not get PFE platform instance\n");
        }
        else
        {
            *is_owner = pfe_hif_chnl_get_emac_timer_ownership(pfe_get_hif_base_addr(platform), PFE_CFG_LOCAL_IF, emac->emac_id);
            ret = EOK;
        }
    }

    return ret;
}

#ifdef PFE_CFG_EMAC0_PPS0_ENABLE
/**
 * @brief       Re-synchronize PPS output
 * @details     Re-alligns PPS output rising edge to system time seconds update event
 *              Disables PPS output immediately and re-enable at the next time that
 *              is an integer multiple of the PPS period
 * @param[in]   emac The EMAC instance
 */
void pfe_emac_pps0_resync(pfe_emac_t *emac)
{
    uint32 pps_restart_sec;
    uint32 sec;
    uint32 nsec;
    uint16 sec_hi;

    pfe_emac_cfg_get_ts_time(emac->emac_base_va, &sec, &nsec, &sec_hi);

    do {
#if PFE_CFG_EMAC0_PPS0_PERIOD_SEC <= 1U
        pps_restart_sec = sec + 1u;
#else
        /* restart at the nearest integer multiple of the PPS period */
        pps_restart_sec = sec + (PFE_CFG_EMAC0_PPS0_PERIOD_SEC - (sec % PFE_CFG_EMAC0_PPS0_PERIOD_SEC));
#endif
        pfe_emac_cfg_pps0_set_target_time(emac->emac_base_va, pps_restart_sec, 0U);

        pfe_emac_cfg_pps_cmd(emac->emac_base_va, EMAC_CFG_PPS_PPSCMD_STOP_IMMEDIATELY);
        pfe_emac_cfg_pps_cmd(emac->emac_base_va, EMAC_CFG_PPS_PPSCMD_START_PULSE_TRAIN);

        pfe_emac_cfg_get_ts_time(emac->emac_base_va, &sec, &nsec, &sec_hi);
    } while(sec == pps_restart_sec);
}
#endif

/**
 * @brief       Configure PPS output
 * @details     PPS output is available on EMAC0 only. Flexible PPS Output Mode is used for signal generation.
 * @param[in]   emac The EMAC instance
 * @param[in]   enable Enable/Disable PPS output signal generation
 * @param[in]   period Period width (in units of PPS counter ticks)
 * @param[in]   pulse_width Pulse width (in units of PPS counter ticks)
 * @return      EOK if sucess, error code otherwise
 */
errno_t pfe_emac_pps0_configure(pfe_emac_t *emac, bool_t enable, uint32 period, uint32 pulse_width)
{
    errno_t ret = EINVAL;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U == pfe_emac_get_index(emac))
        {
            if (enable)
            {
                pfe_emac_cfg_pps0_set_period(emac->emac_base_va, period);
                pfe_emac_cfg_pps0_set_pulse_width(emac->emac_base_va, pulse_width);
                pfe_emac_cfg_pps0_configure(emac->emac_base_va,
                                            FALSE,
                                            EMAC_CFG_PPS_TRGTMODSEL_ONLY_ST,
                                            TRUE);
            }
            else
            {
                pfe_emac_cfg_pps0_configure(emac->emac_base_va, FALSE, 0U, FALSE);
            }
            ret = EOK; 
        }
        else
        {
            NXP_LOG_ERROR("PPS output not available on given EMAC instance");
        }
    }
    
    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [141/185]: src\pfe_emac_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_emac_csr.h"
#include "pfe_feature_mgr.h"
#include "pfe_emac.h"
#include "Eth_43_PFE_Cfg.h"

#if defined(PFE_CFG_TEXT_STATS)

#define ETH_43_PFE_START_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"

/* Mode conversion table */
/* usage scope: phy_mode_to_str */
static const char_t * const phy_mode[] =
{
        "GMII_MII",
        "RGMII",
        "SGMII",
        "TBI",
        "RMII",
        "RTBI",
        "SMII",
        "RevMII",
        "INVALID",
};

#define ETH_43_PFE_STOP_SEC_CONST_32
#include "Eth_43_PFE_MemMap.h"

#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#define EMAC_ERR_SRC_NUMBER                4U
#define EMAC_ERR_SRC_INDEX_UNCORRECTABLE   0U
#define EMAC_ERR_SRC_INDEX_ADDRESS         1U
#define EMAC_ERR_SRC_INDEX_PARITY          2U
#define EMAC_ERR_SRC_INDEX_WDT             3U
#define EMAC_ERR_SRC_INDEX_INVALID         255U

#define CONST_1E9  (1000000000U)

static inline bool_t is_eclk_enabled(addr_t base_va);
static errno_t reg_wait_for_clear(const volatile uint32 * reg_address, uint32 value, uint8 timeout_100us);

#if defined(PFE_CFG_TEXT_STATS)

static inline const char_t* phy_mode_to_str(uint32 mode);
static const char *emac_speed_to_str(pfe_emac_speed_t speed);

#endif /* defined(PFE_CFG_TEXT_STATS) */

#ifdef PFE_CFG_PFE_MASTER
static inline uint32 reverse_bits_32(uint32 u32Data);
static inline uint32 crc32_reversed(const uint8 *const data, const uint32 len);
static inline uint8 pfe_emac_get_emac_err_src_index(pfe_hm_evt_t event);
static inline void pfe_emac_cfg_clear_registers(addr_t base_va);

/* Reverse uint32 bit order */
static inline uint32 reverse_bits_32(uint32 u32Data)
{
    uint8 u8Index;
    uint32 u32DataTemp = u32Data;
    uint32 u32RevData = 0U;

    for(u8Index = 0U; u8Index < 32U; u8Index++)
    {
        u32RevData = (u32RevData << 1U) | (u32DataTemp & 0x1U);
        u32DataTemp >>= 1U;
    }

    return u32RevData;
}

/* Calculate CRC32 value. Same as used by EMAC peripheral to calculate MAC address
 * hash value for MAC address filtering. */
static inline uint32 crc32_reversed(const uint8 *const data, const uint32 len)
{
    const uint32 poly = 0xEDB88320U;
    uint32 res = 0xffffffffU;
    uint32 ii, jj;

    for (ii=0U; ii<len; ii++)
    {
        res ^= (uint32)data[ii];

        for (jj=0U; jj<8U; jj++)
        {
            if ((res & 0x1U) != 0U)
            {
                res = res >> 1U;
                res = (uint32)(res ^ poly);
            }
            else
            {
                res = res >> 1U;
            }
        }
    }

    return reverse_bits_32(~res);
}

/* Get EMAC Error source idx from HW event */
static inline uint8 pfe_emac_get_emac_err_src_index(pfe_hm_evt_t event)
{
    uint8 index = EMAC_ERR_SRC_INDEX_INVALID;

    switch (event)
    {
        case HM_EVT_EMAC_ECC_TX_FIFO_UNCORRECTABLE:
        case HM_EVT_EMAC_ECC_RX_FIFO_UNCORRECTABLE:
        {
            index = EMAC_ERR_SRC_INDEX_UNCORRECTABLE;
            break;
        }
        case HM_EVT_EMAC_ECC_TX_FIFO_ADDRESS:
        case HM_EVT_EMAC_ECC_RX_FIFO_ADDRESS:
        {
            index = EMAC_ERR_SRC_INDEX_ADDRESS;
            break;
        }
        case HM_EVT_EMAC_APP_TX_PARITY:
        case HM_EVT_EMAC_APP_RX_PARITY:
        case HM_EVT_EMAC_MTL_PARITY:
        case HM_EVT_EMAC_FSM_PARITY:
        {
            index = EMAC_ERR_SRC_INDEX_PARITY;
            break;
        }
        case HM_EVT_EMAC_FSM_TX_TIMEOUT:
        case HM_EVT_EMAC_FSM_RX_TIMEOUT:
        case HM_EVT_EMAC_FSM_APP_TIMEOUT:
        case HM_EVT_EMAC_FSM_PTP_TIMEOUT:
        case HM_EVT_EMAC_MASTER_TIMEOUT:
        {
            index = EMAC_ERR_SRC_INDEX_WDT;
            break;
        }
        default:
        {
            NXP_LOG_ERROR("Invalid event to get index");
            break;
        }
    }

    return index;
}

/**
 * @brief       Clear emac configuration registers
 * @details     EMAC registers have defined state on SOC reset but in some
 *              specific situations this mechanism may be bypassed.
 *              This ensures defined state on every initialization.
 * @param[in]   base_va The EMAC base address
 */
static inline void pfe_emac_cfg_clear_registers(addr_t base_va)
{
    /* Clear MAC exact match slots. First entry is always enabled. */
    hal_write32(MAC_ADDRESS0_HIGH_RESET_VAL, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_HIGH(0U)));
    hal_write32(MAC_ADDRESSX_LOW_RESET_VAL, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_LOW(0U)));
    for (uint8 slot = 1U; slot < EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT; slot++)
    {
        hal_write32(MAC_ADDRESSX_HIGH_RESET_VAL, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_HIGH((uint64)slot)));
        hal_write32(MAC_ADDRESSX_LOW_RESET_VAL, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_LOW((uint64)slot)));
    }

    /* Clear hash table */
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_HASH_TABLE_REG0));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_HASH_TABLE_REG1));

    /*  Wait at least 4 clock cycles ((G)MII) */
    oal_time_udelay(10);
}

/**
 * @brief       HW-specific pre-initialization function related to ERR050221
 *              This function should be called before any READ of MAC registers
 * @param[in]   base_va Base address of MAC register space (virtual)
 */
void pfe_emac_cfg_pre_init(addr_t base_va)
{
    hal_write32(0x1U, ADDR_BASE_OFFSET(base_va, MTL_DPP_CONTROL));
}

/**
 * @brief       HW-specific initialization function
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   mode MII mode to be configured @see pfe_emac_mii_mode_t
 * @param[in]   speed Speed to be configured @see pfe_emac_speed_t
 * @param[in]   duplex Duplex type to be configured @see pfe_emac_duplex_t
 * @return      EOK if success, error code if invalid configuration is detected
 */
errno_t pfe_emac_cfg_init(addr_t base_va, pfe_emac_mii_mode_t mode,
                            pfe_emac_speed_t speed, pfe_emac_duplex_t duplex)
{
    uint32 reg;
    errno_t ret;
    
    pfe_emac_cfg_clear_registers(base_va);

    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));
    hal_write32(0x8000ffeeU, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS0_HIGH));
    hal_write32(0xddccbbaaU, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS0_LOW));
    hal_write32(0U
            | RECEIVE_ALL(0U)
            | DROP_NON_TCP_UDP(0U)
            | L3_L4_FILTER_ENABLE(0U)
            | VLAN_TAG_FILTER_ENABLE(0U)
            | HASH_OR_PERFECT_FILTER(1U)
            | SA_FILTER(0U)
            | SA_INVERSE_FILTER(0U)
            | PASS_CONTROL_PACKETS(FORWARD_ALL_EXCEPT_PAUSE)
            | DISABLE_BROADCAST_PACKETS(0U)
            | PASS_ALL_MULTICAST(0U)
            | DA_INVERSE_FILTER(0U)
            | HASH_MULTICAST(1U)
            | HASH_UNICAST(1U)
            | PROMISCUOUS_MODE(0U)
            , ADDR_BASE_OFFSET(base_va, MAC_PACKET_FILTER));

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_Q0_TX_FLOW_CTRL));
    reg &= ~TX_FLOW_CONTROL_ENABLE(1U);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_Q0_TX_FLOW_CTRL));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_INTERRUPT_ENABLE));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va, MMC_RX_INTERRUPT_MASK));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va, MMC_TX_INTERRUPT_MASK));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va, MMC_IPC_RX_INTERRUPT_MASK));

    /* Enable ECC, timeout and parity chcecking */
    hal_write32(0U
            | ECC_TX(1U)
            | ECC_RX(1U)
            | ECC_EST(1U)
            | ECC_RXP(1U)
            | ECC_TSO(1U)
            , ADDR_BASE_OFFSET(base_va, MTL_ECC_CONTROL));
    reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_FSM_ACT_TIMER));
    hal_write32(reg
            | LARGE_MODE_TIMEOUT(0x2U)
            | NORMAL_MODE_TIMEOUT(0x2U)
            /* Select according to real CSR clock frequency. S32G: CSR_CLK = 300MHz => 300 ticks */
            | 0x12CUL
            , ADDR_BASE_OFFSET(base_va, MAC_FSM_ACT_TIMER));
    hal_write32(0U
            | DATA_PARITY_PROTECTION(1U)
            | SLAVE_PARITY_CHECK(1U)
            , ADDR_BASE_OFFSET(base_va, MTL_DPP_CONTROL));
    hal_write32(0U
            | FSM_PARITY_ENABLE(1U)
            | FSM_TIMEOUT_ENABLE(1U)
            , ADDR_BASE_OFFSET(base_va, MAC_FSM_CONTROL));

    reg = 0U | ARP_OFFLOAD_ENABLE(0U)
                 | SA_INSERT_REPLACE_CONTROL(CTRL_BY_SIGNALS)
                 | CHECKSUM_OFFLOAD(1U)
                 | INTER_PACKET_GAP(0U)
                 | GIANT_PACKET_LIMIT_CONTROL(1U)
                 | SUPPORT_2K_PACKETS(0U)
                 | CRC_STRIPPING_FOR_TYPE(1U)
                 | AUTO_PAD_OR_CRC_STRIPPING(1U)
                 | WATCHDOG_DISABLE(1U)
                 | PACKET_BURST_ENABLE(0U)
                 | JABBER_DISABLE(1U)
                 | PORT_SELECT(0U)               /* To be set up by pfe_emac_cfg_set_speed() */
                 | SPEED(0U)                             /* To be set up by pfe_emac_cfg_set_speed() */
                 | DUPLEX_MODE(1U)               /* To be set up by pfe_emac_cfg_set_duplex() */
                 | LOOPBACK_MODE(0U)
                 | CARRIER_SENSE_BEFORE_TX(0U)
                 | DISABLE_RECEIVE_OWN(0)
                 | DISABLE_CARRIER_SENSE_TX(0U)
                 | DISABLE_RETRY(0U)
                 | BACK_OFF_LIMIT(MIN_N_10)
                 | DEFERRAL_CHECK(0U)
                 | PREAMBLE_LENGTH_TX(PREAMBLE_7B)
                 | TRANSMITTER_ENABLE(0U)
                 | RECEIVER_ENABLE(0U);

    if (TRUE == pfe_feature_mgr_is_available("jumbo_frames"))
    {
        reg |= JUMBO_PACKET_ENABLE(1U);
    }
    else
    {
        reg |= JUMBO_PACKET_ENABLE(0U);
    }

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));

    hal_write32((uint32)0U
            | FORWARD_ERROR_PACKETS(1U)
            , ADDR_BASE_OFFSET(base_va, MTL_RXQ0_OPERATION_MODE));

    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MTL_TXQ0_OPERATION_MODE));
    if (TRUE == pfe_feature_mgr_is_available("jumbo_frames"))
    {
        hal_write32(GIANT_PACKET_SIZE_LIMIT(9022U), ADDR_BASE_OFFSET(base_va, MAC_EXT_CONFIGURATION));
    }
    else
    {
        hal_write32(GIANT_PACKET_SIZE_LIMIT(1522U), ADDR_BASE_OFFSET(base_va, MAC_EXT_CONFIGURATION));
    }

    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_SUB_SECOND_INCREMENT));

    /*  Set speed */
    if (EOK != pfe_emac_cfg_set_speed(base_va, speed))
    {
        ret = EINVAL;
    }
    else
    {
        /*  Set MII mode */
        if (EOK != pfe_emac_cfg_set_mii_mode(base_va, mode))
        {
            ret = EINVAL;
        }
        else
        {
            /*  Set duplex */
            if (EOK != pfe_emac_cfg_set_duplex(base_va, duplex))
            {
                ret = EINVAL;
            }
            else
            {
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
 * @brief       Enable timestamping
 * @param[in]   base_va Base address
 * @param[in]   eclk TRUE means to use external clock reference (chain)
 * @param[in]   i_clk_hz Reference clock frequency
 * @param[in]   o_clk_hz Requested nominal output frequency
 * @param[in]   en TRUE means ENABLE, FALSE means DISABLE
 */
errno_t pfe_emac_cfg_enable_ts(addr_t base_va, bool_t eclk, uint32 i_clk_hz, uint32 o_clk_hz)
{
    uint32 ss = 0U;
    uint32 regval;
    errno_t ret;

    hal_write32(0U
            | EXTERNAL_TIME(eclk)
            | SELECT_PTP_PACKETS(0x1U)
            | PTP_OVER_IPV4(1U)
            | PTP_OVER_IPV6(1U)
            | PTP_OVER_ETH(1U)
            | PTPV2(1U)
            | DIGITAL_ROLLOVER(1U)
            | FINE_UPDATE(1U)
            | ENABLE_TIMESTAMP(1U)
            | ENABLE_TIMESTAMP_FOR_All(1U), ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));

    if (eclk == TRUE)
    {
        NXP_LOG_INFO("IEEE1588: Using external timestamp input\n");
        ret = EOK;
    }
    else
    {
        if ((o_clk_hz == 0U) || (i_clk_hz == 0U))
        {
            NXP_LOG_ERROR("Invalid frequency value");
            ret = EINVAL;
        }
        else
        {
            /*  Get output period [ns] */
            ss = CONST_1E9 / o_clk_hz;  /* o_clk_hz is guaranteed by Tresos to be larger than 3906250U */
            PfeDevAssert(ss <= UINT8_MAX);

            /*  Get sub-nanosecond part */
            const uint8 sns = (uint8)(((256U * (uint64)CONST_1E9) / o_clk_hz) & UINT8_MAX);
            NXP_LOG_INFO(   "IEEE1588: Input Clock: %uHz, Output: %uHz, Accuracy: %u.%03uns\n",
                            (uint_t)i_clk_hz,
                            (uint_t)o_clk_hz,
                            (uint_t)ss,
                            (uint_t)((sns * 1000U) / 256U));

            /*  Set 'increment' values */
            hal_write32(((ss & 0xFFu) << 16U) | (sns << 8U), ADDR_BASE_OFFSET(base_va, MAC_SUB_SECOND_INCREMENT));

            /*  Set initial 'addend' value */
            const uint64 u64_addend = ((uint64)o_clk_hz << 32U) / (uint64)i_clk_hz;
            PfeDevAssert(u64_addend <= UINT32_MAX);
            const uint32 u32_addend = (uint32) u64_addend;
            hal_write32(u32_addend, ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_ADDEND));

            regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
            hal_write32(regval | UPDATE_ADDEND(1), ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
            ret = reg_wait_for_clear((volatile uint32 *)(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL)), UPDATE_ADDEND(1), 10);

            if (EOK == ret)
            {
                /*  Set 'update' values */
                hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_STSU));
                hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_STNSU));

                regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
                regval |= INITIALIZE_TIMESTAMP(1);
                hal_write32(regval, ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
                ret = reg_wait_for_clear((volatile uint32 *)(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL)), INITIALIZE_TIMESTAMP(1), 10);
            }
        }
    }

    return ret;
}

/**
 * @brief   Disable timestamping
 */
void pfe_emac_cfg_disable_ts(addr_t base_va)
{
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
}
#endif /* PFE_CFG_PFE_MASTER */

/**
 * @brief       Check if external IEEE1588 clock is used on EMAC 
 * @param[in]   base_va Base address
 * @return      TRUE if external clock enabled
 */
static inline bool_t is_eclk_enabled(addr_t base_va) {
    bool_t eclk_enabled = FALSE;
    uint32 regval;
    
    regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
    if (regval & EXTERNAL_TIME(1U))
    {
        eclk_enabled = TRUE;
    }
    
    return eclk_enabled;
}

/**
 * @brief       Wait for value to be cleared in reg
 * @param[in]   reg_address register address
 * @param[in]   value waiting for active bits to be cleared in the register
 * @param[in]   timeout_100us timeout value in multiple of hundred of microseconds
 * @return      ETIME in case of timeout, EOK otherwise
 */
static errno_t reg_wait_for_clear(const volatile uint32 * reg_address, uint32 value, uint8 timeout_100us)
{
    errno_t result = ETIME;

    for (uint8 timeout_cnt = 0U; timeout_cnt < timeout_100us; timeout_cnt++)
    {
        uint32 regval = *reg_address;
        if ((regval & value) == 0U)
        {
            result = EOK;
            break;
        }

        oal_time_usleep(100U);
    }
    return result;
}

#if defined(PFE_CFG_TEXT_STATS)

/**
 * @brief       Convert EMAC mode to string
 * @details     Helper function for statistics to convert phy mode to string.
 * @param[in]   mode    phy mode
 * @return      pointer to string
 */
static inline const char_t* phy_mode_to_str(uint32 mode)
{
    /* Initialize to invalid */
    uint32 index  = ((uint32)(sizeof(phy_mode))/(uint32)(sizeof(phy_mode[0]))) - 1UL;

    if(((uint32)(sizeof(phy_mode))/(uint32)(sizeof(phy_mode[0]))) > mode)
    {
        index = mode;
    }

    return phy_mode[index];
}

/**
 * @brief       Convert EMAC speed to string
 * @details     Helper function for statistics to convert emac speed to string.
 * @param[in]   speed   emac speed
 * @return      pointer to string
 */
static const char *emac_speed_to_str(pfe_emac_speed_t speed)
{
    const char *ret;

    switch (speed)
    {
        case EMAC_SPEED_10_MBPS:
            ret = "10 Mbps";
            break;
        case EMAC_SPEED_100_MBPS:
            ret = "100 Mbps";
            break;
        case EMAC_SPEED_1000_MBPS:
            ret = "1 Gbps";
            break;
        case EMAC_SPEED_2500_MBPS:
            ret = "2.5 Gbps";
            break;
        default:
            ret = "unknown";
            break;
    }
    return ret;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get EMAC instance index
 * @param[in]   emac_base The EMAC base address
 * @param[in]   cbus_base The PFE CBUS base address
 * @return      Index (0, 1, 2, ..) or 255 if failed
 */
uint8 pfe_emac_cfg_get_index(addr_t emac_base, addr_t cbus_base)
{
    uint8 idx;

    PfeDevAssert(emac_base >= cbus_base);
    switch ((addr_t)emac_base - (addr_t)cbus_base)
    {
        case CBUS_EMAC1_BASE_ADDR:
        {
            idx = 0U;
            break;
        }

        case CBUS_EMAC2_BASE_ADDR:
        {
            idx = 1U;
            break;
        }

        case CBUS_EMAC3_BASE_ADDR:
        {
            idx = 2U;
            break;
        }

        default:
        {
            idx = 255U;
            break;
        }
    }

    return idx;
}

/**
 * @brief       Adjust timestamping clock frequency
 * @param[in]   base_va Base address
 * @param[in]   ppb Frequency change in [ppb]
 * @param[in]   sgn If TRUE then 'ppb' is positive, else it is negative
 */
errno_t pfe_emac_cfg_adjust_ts_freq(addr_t base_va, uint32 i_clk_hz, uint32 o_clk_hz, uint32 ppb, bool_t sgn)
{
    uint32 nil, delta, regval;
    errno_t ret;
    
    if (is_eclk_enabled(base_va) == TRUE)
    {
        ret = EACCES;
    }
    else
    {
        if(i_clk_hz == 0U)
        {
            NXP_LOG_ERROR("Invalid frequency value");
            ret = EINVAL;
        }
        else
        {
            /*  Nil drift addend: 1^32 / (o_clk_hz / i_clk_hz) */
            const uint64 u64_nil = ((uint64)o_clk_hz << 32U) / (uint64)i_clk_hz;
            PfeDevAssert(u64_nil <= UINT32_MAX);
            nil = (uint32) u64_nil;

            /*  delta = x * ppb * 0.000000001 */
            const uint64 u64_delta = (((uint64)nil * (uint64)ppb) / 1000000000ULL);
            PfeDevAssert(u64_delta <= UINT32_MAX);
            delta = (uint32) u64_delta;

            /*  Adjust the 'addend' */
            if (sgn)
            {
                if (((uint64)nil + (uint64)delta) > 0xffffffffULL)
                {
                    NXP_LOG_WARNING("IEEE1588: Frequency adjustment out of positive range\n");
                    regval = 0xffffffffU;
                }
                else
                {
                    regval = nil + delta;
                }
            }
            else
            {
                if (delta > nil)
                {
                    NXP_LOG_WARNING("IEEE1588: Frequency adjustment out of negative range\n");
                    regval = 0U;
                }
                else
                {
                    regval = nil - delta;
                }
            }

            /*  Update the 'addend' value */
            hal_write32(regval, ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_ADDEND));

            /*  Request update 'addend' value */
            regval = hal_read32((addr_t)ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
            hal_write32(regval | UPDATE_ADDEND(1), (addr_t)ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));

            /*  Wait for completion */
            ret = reg_wait_for_clear((volatile uint32 *)(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL)), UPDATE_ADDEND(1), 10U);
        }
    }

    return ret;
}

/**
 * @brief           Get system time
 * @param[in]       base_va Base address
 * @param[in,out]   sec Seconds
 * @param[in,out]   nsec NanoSeconds
 * @param[in,out]   sec_hi Higher Word Seconds
 */
void pfe_emac_cfg_get_ts_time(addr_t base_va, uint32 *sec, uint32 *nsec, uint16 *sec_hi)
{
    uint32 sec_tmp;

    do
    {
        *sec = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_SYSTEM_TIME_SECONDS));
        *nsec = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_SYSTEM_TIME_NANOSECONDS));
        *sec_hi = (uint16)(hal_read32(ADDR_BASE_OFFSET(base_va, MAC_STS_HIGHER_WORD)) & 0xFFFFu);
        sec_tmp = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_SYSTEM_TIME_SECONDS));
    } while (*sec != sec_tmp);
}

/**
 * @brief       Set system time
 * @details     Current time will be overwritten with the desired value
 * @param[in]   base_va Base address
 * @param[in]   sec Seconds
 * @param[in]   nsec NanoSeconds
 * @param[in]   sec_hi Higher Word Seconds
 */
errno_t pfe_emac_cfg_set_ts_time(addr_t base_va, uint32 sec, uint32 nsec, uint16 sec_hi)
{
    uint32 regval;
    errno_t ret;

    if (nsec > 0x7fffffffU)
    {
        ret = EINVAL;
    }
    else if (is_eclk_enabled(base_va) == TRUE)
    {
        ret = EACCES;
    }
    else
    {
        hal_write32(sec, ADDR_BASE_OFFSET(base_va, MAC_STSU));
        hal_write32(nsec, ADDR_BASE_OFFSET(base_va, MAC_STNSU));
        hal_write32(sec_hi, ADDR_BASE_OFFSET(base_va, MAC_STS_HIGHER_WORD));

        /*  Initialize time */
        regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
        regval |= INITIALIZE_TIMESTAMP(1);
        hal_write32(regval, ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));

        /*  Wait for completion */
        ret = reg_wait_for_clear((volatile uint32 *)(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL)), INITIALIZE_TIMESTAMP(1), 10);
    }

    return ret;
}

/**
 * @brief       Adjust system time
 * @param[in]   base_va Base address
 * @param[in]   sec Seconds
 * @param[in]   nsec NanoSeconds
 * @param[in]   sgn Sing of the adjustment (TRUE - positive, FALSE - negative)
 */
errno_t pfe_emac_cfg_adjust_ts_time(addr_t base_va, uint32 sec, uint32 nsec, bool_t sgn)
{
    
    uint32 regval;
    uint32 nsec_temp = nsec;
    uint32 sec_temp = sec;
    errno_t ret;

    if (nsec_temp > 0x7fffffffU)
    {
        ret = EINVAL;
    }
    else if (is_eclk_enabled(base_va) == TRUE)
    {
        ret = EACCES;
    }
    else
    {
        ret = EOK;

        regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));

        if (!sgn)
        {
            if (0U != (regval & DIGITAL_ROLLOVER(1)))
            {
                nsec_temp = 1000000000U - nsec;
            }
            else
            {
                nsec_temp = (1UL << 31U) - nsec;
            }

            /* For negative adjustment, the value filled to the register must be complement */
            sec_temp = (uint32)(((uint64)UINT32_MAX - sec + 1U) & UINT32_MAX);
        }

        if (0U != (regval & DIGITAL_ROLLOVER(1)))
        {
            if (nsec_temp > 0x3b9ac9ffU)
            {
                ret = EINVAL;
            }
        }

        if (EOK == ret)
        {
            hal_write32(sec_temp, ADDR_BASE_OFFSET(base_va, MAC_STSU));
            hal_write32(ADDSUB(!sgn) | nsec_temp, ADDR_BASE_OFFSET(base_va, MAC_STNSU));

            /*  Trigger the update */
            regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));
            regval |= UPDATE_TIMESTAMP(1);
            hal_write32(regval, ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL));

            /*  Wait for completion */
            ret = reg_wait_for_clear((volatile uint32 *)(ADDR_BASE_OFFSET(base_va, MAC_TIMESTAMP_CONTROL)), UPDATE_TIMESTAMP(1), 10);
        }
    }

    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)

/**
 * @brief       Get EMAC statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the EMAC block.
 * @param[in]   base_va     Base address of EMAC register space (virtual)
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_emac_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;
    uint32 reg;
    pfe_emac_speed_t speed;
    pfe_emac_duplex_t duplex;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get version */
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_VERSION));
        len += oal_util_snprintf(buf + len, size - len, "SNPVER                    : 0x%x\n", reg & 0xffU);
        len += oal_util_snprintf(buf + len, size - len, "USERVER                   : 0x%x\n", (reg >> 8) & 0xffU);

        reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_PACKETS_COUNT_GOOD_BAD));
        len += oal_util_snprintf(buf + len, size - len, "RX_PACKETS_COUNT_GOOD_BAD : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_PACKET_COUNT_GOOD_BAD));
        len += oal_util_snprintf(buf + len, size - len, "TX_PACKET_COUNT_GOOD_BAD  : 0x%x\n", reg);

        (void)pfe_emac_cfg_get_link_config(base_va, &speed, &duplex);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));
        len += oal_util_snprintf(buf + len, size - len, "MAC_CONFIGURATION         : 0x%x [speed: %s]\n", reg, emac_speed_to_str(speed));

        reg = (hal_read32(ADDR_BASE_OFFSET(base_va, MAC_HW_FEATURE0)) >> 28U) & 0x07U;
        len += oal_util_snprintf(buf + len, size - len, "ACTPHYSEL(MAC_HW_FEATURE0): %s\n", phy_mode_to_str(reg));

        /* Error debugging */
        if(verb_level >= 8U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_UNDERFLOW_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_UNDERFLOW_ERROR_PACKETS        : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_SINGLE_COLLISION_GOOD_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_SINGLE_COLLISION_GOOD_PACKETS  : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_MULTIPLE_COLLISION_GOOD_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_MULTIPLE_COLLISION_GOOD_PACKETS: 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_DEFERRED_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_DEFERRED_PACKETS               : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_LATE_COLLISION_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_LATE_COLLISION_PACKETS         : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_EXCESSIVE_COLLISION_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_EXCESSIVE_COLLISION_PACKETS    : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_CARRIER_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_CARRIER_ERROR_PACKETS          : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_EXCESSIVE_DEFERRAL_ERROR));
            len += oal_util_snprintf(buf + len, size - len, "TX_EXCESSIVE_DEFERRAL_ERROR       : 0x%x\n", reg);

            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_OSIZE_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "TX_OSIZE_PACKETS_GOOD             : 0x%x\n", reg);

            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_CRC_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_CRC_ERROR_PACKETS              : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_ALIGNMENT_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_ALIGNMENT_ERROR_PACKETS        : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_RUNT_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_RUNT_ERROR_PACKETS             : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_JABBER_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_JABBER_ERROR_PACKETS           : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_LENGTH_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_LENGTH_ERROR_PACKETS           : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_OUT_OF_RANGE_TYPE_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_OUT_OF_RANGE_TYPE_PACKETS      : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_FIFO_OVERFLOW_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_FIFO_OVERFLOW_PACKETS          : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_RECEIVE_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_RECEIVE_ERROR_PACKETS          : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_RECEIVE_ERROR_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_RECEIVE_ERROR_PACKETS          : 0x%x\n", reg);

            reg = hal_read32(ADDR_BASE_OFFSET(base_va, MTL_ECC_ERR_CNTR_STATUS));
            len += oal_util_snprintf(buf + len, size - len, "MTL_ECC_CORRECTABLE_ERRORS        : 0x%x\n", (reg & 0xffU));
            len += oal_util_snprintf(buf + len, size - len, "MTL_ECC_UNCORRECTABLE_ERRORS      : 0x%x\n", ((reg >> 16U) & 0xfU));
        }

        /* Cast/vlan/flow control */
        if(verb_level >= 3U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_UNICAST_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_UNICAST_PACKETS_GOOD_BAD       : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_BROADCAST_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "TX_BROADCAST_PACKETS_GOOD         : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_BROADCAST_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_BROADCAST_PACKETS_GOOD_BAD     : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_MULTICAST_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "TX_MULTICAST_PACKETS_GOOD         : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_MULTICAST_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_MULTICAST_PACKETS_GOOD_BAD     : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_VLAN_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "TX_VLAN_PACKETS_GOOD              : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_PAUSE_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "TX_PAUSE_PACKETS                  : 0x%x\n", reg);
        }

        if(verb_level >= 4U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_UNICAST_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "RX_UNICAST_PACKETS_GOOD           : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_BROADCAST_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "RX_BROADCAST_PACKETS_GOOD         : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_MULTICAST_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "RX_MULTICAST_PACKETS_GOOD         : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_VLAN_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_VLAN_PACKETS_GOOD_BAD          : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_PAUSE_PACKETS));
            len += oal_util_snprintf(buf + len, size - len, "RX_PAUSE_PACKETS                  : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_CONTROL_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "RX_CONTROL_PACKETS_GOOD           : 0x%x\n", reg);
        }

        if(verb_level >= 1U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_OCTET_COUNT_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "TX_OCTET_COUNT_GOOD                : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_OCTET_COUNT_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_OCTET_COUNT_GOOD_BAD            : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_64OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_64OCTETS_PACKETS_GOOD_BAD       : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_65TO127OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_65TO127OCTETS_PACKETS_GOOD_BAD  : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_128TO255OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_128TO255OCTETS_PACKETS_GOOD_BAD : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_256TO511OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_256TO511OCTETS_PACKETS_GOOD_BAD : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_512TO1023OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_512TO1023OCTETS_PACKETS_GOOD_BAD: 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_1024TOMAXOCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "TX_1024TOMAXOCTETS_PACKETS_GOOD_BAD: 0x%x\n", reg);
        }

        if(verb_level >= 5U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, TX_OSIZE_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "TX_OSIZE_PACKETS_GOOD              : 0x%x\n", reg);
        }

        if(verb_level >= 2U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_OCTET_COUNT_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "RX_OCTET_COUNT_GOOD                : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_OCTET_COUNT_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_OCTET_COUNT_GOOD_BAD            : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_64OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_64OCTETS_PACKETS_GOOD_BAD       : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_65TO127OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_65TO127OCTETS_PACKETS_GOOD_BAD  : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_128TO255OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_128TO255OCTETS_PACKETS_GOOD_BAD : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_256TO511OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_256TO511OCTETS_PACKETS_GOOD_BAD : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_512TO1023OCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_512TO1023OCTETS_PACKETS_GOOD_BAD: 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_1024TOMAXOCTETS_PACKETS_GOOD_BAD));
            len += oal_util_snprintf(buf + len, size - len, "RX_1024TOMAXOCTETS_PACKETS_GOOD_BAD: 0x%x\n", reg);
        }

        if(verb_level >= 5U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_OVERSIZE_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "RX_OSIZE_PACKETS_GOOD              : 0x%x\n", reg);
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, RX_UNDERSIZE_PACKETS_GOOD));
            len += oal_util_snprintf(buf + len, size - len, "RX_UNDERSIZE_PACKETS_GOOD          : 0x%x\n", reg);
        }
    }

    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

errno_t pfe_emac_cfg_get_link_config(addr_t base_va, pfe_emac_speed_t *speed, pfe_emac_duplex_t *duplex)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));

    /* speed */
    switch (GET_LINE_SPEED(reg))
    {
        case 0x01U:
            *speed = EMAC_SPEED_2500_MBPS;
            break;
        case 0x02U:
            *speed = EMAC_SPEED_10_MBPS;
            break;
        case 0x03U:
            *speed = EMAC_SPEED_100_MBPS;
            break;
        case 0x0U:
        default:
            *speed = EMAC_SPEED_1000_MBPS;
            break;
    }

    /* duplex */
    *duplex = (1U == GET_DUPLEX_MODE(reg)) ? EMAC_DUPLEX_FULL : EMAC_DUPLEX_HALF;

    return EOK;
}

/**
 * @brief       Get EMAC statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the EMAC block.
 * @param[in]   base_va     Base address of EMAC register space (virtual)
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic
 */
uint32 pfe_emac_cfg_get_stat_value(addr_t base_va, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = 0xFFFFFFFFU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = hal_read32(ADDR_BASE_OFFSET(base_va, stat_id));
    }
    return stat_value;
}

#ifdef PFE_CFG_PFE_MASTER

/**
 * @brief       Set MAC duplex
 * @param[in]   base_va Base address to be written
 * @param[in]   duplex Duplex type to be configured @see pfe_emac_duplex_t
 * @return      EOK if success, error code when invalid configuration is requested
 */
errno_t pfe_emac_cfg_set_duplex(addr_t base_va, pfe_emac_duplex_t duplex)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION)) & ~(DUPLEX_MODE(1U));
    errno_t ret = EOK;

    switch (duplex)
    {
        case EMAC_DUPLEX_HALF:
        {
            reg |= DUPLEX_MODE(0U);
            break;
        }

        case EMAC_DUPLEX_FULL:
        {
            reg |= DUPLEX_MODE(1U);
            break;
        }

        default:
            ret = EINVAL;
            break;
    }
    if(EOK == ret)
    {
        hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));
    }

    return ret;
}

/**
 * @brief       Set MAC MII mode
 * @param[in]   base_va Base address to be written
 * @param[in]   mode MII mode to be configured @see pfe_emac_mii_mode_t
 * @return      EOK if success, error code when invalid configuration is requested
 */
errno_t pfe_emac_cfg_set_mii_mode(addr_t base_va, pfe_emac_mii_mode_t mode)
{
    /*
         The PHY mode selection is done using a HW interface. See the "phy_intf_sel" signal.
    */
    (void)base_va;
    (void)mode;

    return EOK;
}

/**
 * @brief       Set MAC speed
 * @param[in]   base_va Base address to be written
 * @param[in]   speed Speed to be configured @see pfe_emac_speed_t
 * @return      EOK if success, error code when invalid configuration is requested
 */
errno_t pfe_emac_cfg_set_speed(addr_t base_va, pfe_emac_speed_t speed)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION)) & ~(PORT_SELECT(1U) | SPEED(1U));
    errno_t ret = EOK;

    switch (speed)
    {
        case EMAC_SPEED_10_MBPS:
        {
            reg |= PORT_SELECT(1U);
            reg |= SPEED(0U);
            break;
        }

        case EMAC_SPEED_100_MBPS:
        {
            reg |= PORT_SELECT(1U);
            reg |= SPEED(1U);
            break;
        }

        case EMAC_SPEED_1000_MBPS:
        {
            reg |= PORT_SELECT(0);
            reg |= SPEED(0);
            break;
        }

        case EMAC_SPEED_2500_MBPS:
        {
            reg |= PORT_SELECT(0);
            reg |= SPEED(1);
            break;
        }

        default:
        {
            ret = EINVAL;
            break;
        }
    }

    if (EOK == ret)
    {
        /*  Configure speed in EMAC registers */
        hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));
    }

    return ret;
}

/**
 * @brief       Get MAC configured link parameters
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[out]  clock_speed Currently configured link speed
 * @param[out]  duplex Currently configured Duplex type @see pfe_emac_duplex_t
 * @param[out]  link Current link state
 * @return      EOK if success
 */
errno_t pfe_emac_cfg_get_link_status(addr_t base_va, pfe_emac_link_speed_t *link_speed, pfe_emac_duplex_t *duplex, bool_t *link)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_PHYIF_CONTROL_STATUS));

    /* speed */
    switch (LNKSPEED(reg))
    {
        case 0x01U:
            *link_speed = EMAC_LINK_SPEED_25_MHZ;
            break;
        case 0x02U:
            *link_speed = EMAC_LINK_SPEED_125_MHZ;
            break;
        case 0x03U:
            *link_speed = EMAC_LINK_SPEED_INVALID;
            break;
        case 0x0U:
        default:
            *link_speed = EMAC_LINK_SPEED_2_5_MHZ;
            break;
    }

    /* duplex */
    *duplex = (1U == LNKMOD(reg)) ? EMAC_DUPLEX_FULL : EMAC_DUPLEX_HALF;

    /* link */
    *link = LNKSTS(reg) == 1U;

    return EOK;
}

/**
 * @brief       Set maximum frame length
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   len The new maximum frame length
 * @return      EOK if success, error code if invalid value is requested
 */
errno_t pfe_emac_cfg_set_max_frame_length(addr_t base_va, uint32 len)
{
    uint32 reg, maxlen = 0U;
    bool_t je, s2kp, gpslce, edvlp;
    errno_t ret;

    /*
        In this case the function just performs check whether the requested length
        is supported by the current MAC configuration. When change is needed then
        particular parameters (JE, S2KP, GPSLCE, DVLP, and GPSL must be changed).
    */

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));
    je = !!(reg & JUMBO_PACKET_ENABLE(1U));
    s2kp = !!(reg & SUPPORT_2K_PACKETS(1U));
    gpslce = !!(reg & GIANT_PACKET_LIMIT_CONTROL(1U));

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_VLAN_TAG_CTRL));
    edvlp = !!(reg & ENABLE_DOUBLE_VLAN(1U));

    if (je && edvlp)
    {
        maxlen = 9026U;
    }

    if (!je && s2kp)
    {
        maxlen = 2000U;
    }

    if (!je && !s2kp && gpslce && edvlp)
    {
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_EXT_CONFIGURATION));
        maxlen = reg & GIANT_PACKET_SIZE_LIMIT((uint32)-1);
        maxlen += 8U;
    }

    if (!je && !s2kp && !gpslce && edvlp)
    {
        maxlen = 1526U;
    }

    if (je && !edvlp)
    {
        maxlen = 9022U;
    }

    if (!je && !s2kp && gpslce && !edvlp)
    {
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_EXT_CONFIGURATION));
        maxlen = reg & GIANT_PACKET_SIZE_LIMIT((uint32)-1);
        maxlen += 4U;
    }

    if (!je && !s2kp && !gpslce && !edvlp)
    {
        maxlen = 1522U;
    }

    if (len > maxlen)
    {
        ret = EINVAL;
    }
    else
    {
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Write MAC address to a specific individual address slot
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   addr The MAC address to be written
 * @param[in]   slot Index of slot where the address shall be written
 * @note        Maximum number of slots is given by EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT
 */
void pfe_emac_cfg_write_addr_slot(addr_t base_va, const pfe_mac_addr_t addr, uint8 slot)
{
    uint32 bottom = ((uint32)addr[3] << 24U) | ((uint32)addr[2] << 16U) | ((uint32)addr[1] << 8U) | ((uint32)addr[0] << 0U);
    uint32 top = ((uint32)addr[5] << 8U) | ((uint32)addr[4] << 0U);

    /*  All-zeros MAC address is special case (invalid entry) */
    if ((0U != top) || (0U != bottom))
    {
        top |= 0x80000000U;
    }

    hal_write32(top, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_HIGH((uint64)slot)));
    hal_write32(bottom, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_LOW((uint64)slot)));
    oal_time_udelay(10);
    hal_write32(bottom, ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_LOW((uint64)slot)));
}

/**
 * @brief       Read MAC address from a specific individual address slot
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[out]  addr The MAC address to be read, filled with zeroes when slot is disabled
 * @param[in]   slot Index of slot where the address shall be read
 * @note        Maximum number of slots is given by EMAC_CFG_INDIVIDUAL_ADDR_SLOTS_COUNT
 */
void pfe_emac_cfg_read_addr_slot(addr_t base_va, pfe_mac_addr_t addr, uint8 slot)
{
    uint32 top = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_HIGH((uint64)slot)));
    uint32 bottom = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_ADDRESS_LOW((uint64)slot)));
    
    /* Check whether the address slot is in use */
    if ((top & 0x80000000U) != 0U)
    {
        /* Address slot is in use */
        addr[0] = (uint8) (bottom & 0xFFu);
        addr[1] = (uint8) ((bottom >> 8U) & 0xFFu);
        addr[2] = (uint8) ((bottom >> 16U) & 0xFFu);
        addr[3] = (uint8) ((bottom >> 24U) & 0xFFu);
        addr[4] = (uint8) (top & 0xFFu);
        addr[5] = (uint8) ((top >> 8U) & 0xFFu);
    }
    else
    {
        /* Address slot is not in use */
        (void)autolibc_memset(addr, 0, sizeof(pfe_mac_addr_t));
    }
}

/**
 * @brief       Convert MAC address to its hash representation
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   addr The MAC address to compute the hash for
 * @retval      The hash value as represented/used by the HW
 */
uint32 pfe_emac_cfg_get_hash(addr_t base_va, const pfe_mac_addr_t addr)
{
    (void)base_va;

    return crc32_reversed((uint8 *)addr, 6U);
}

/**
 * @brief       Enable/Disable individual address group defined by 'hash'
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   hash The hash value
 * @param[in]   en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_hash_group(addr_t base_va, uint32 hash, bool_t en)
{
    uint32 reg, old_reg;
    uint32 val;
    uint8 hash_table_idx, pos;

    /*
     * NOTE:
     * The algorithm calculates value to write into Hash table
     * (Refer to the register description of MAC_HASH_TABLE_REG in RM for more details)
     *    - Step 1:  Compute the CRC value of the destination MAC address (see crc32_reversed())
     *    - Step 2:  Reverse 32 bits of CRC result (see crc32_reversed())
     *    - Step 3:  Select the appropriate register bit to set.
     *
     * In this function, it executes Step 3 in above algorithm.
     * Currently, 64-bit Hash is used, so the upper 6 bits after passing through the CRC calculator are used to index the bit to set in the Hash table
     * The MSB in these group represents the index of the register to be used
     * The remaining 5 bits reveals information on the position to set in the corresponding register
     */

    val = (hash & EMAC_CFG_MAC_HASH_MASK) >> 26U;     /* Upper 6 bits of CRC result */
    hash_table_idx = ((uint8)val & 0x20U) >> 5U;    /* MSB represents Hash table register index (0/1) */
    pos = ((uint8)val & 0x1fU);                     /* Remaining 5 bits illustrates the bit to set in corresponding register  */

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_HASH_TABLE_REG((uint64)hash_table_idx)));
    old_reg = reg;

    if (en)
    {
        reg |= ((uint32)1U << pos);
    }
    else
    {
        reg &= ~((uint32)1U << pos);
    }

    if (reg != old_reg)
    {
        hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_HASH_TABLE_REG((uint64)hash_table_idx)));
        /*  Wait at least 4 clock cycles ((G)MII) */
        oal_time_udelay(10);
        hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_HASH_TABLE_REG((uint64)hash_table_idx)));
    }
}

/**
 * @brief       Clear hash table
 * @param[in]   base_va Base address of MAC register space (virtual)
 */
void pfe_emac_cfg_clear_hash_table(addr_t base_va)
{
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_HASH_TABLE_REG0));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, MAC_HASH_TABLE_REG1));
    /*  Wait at least 4 clock cycles ((G)MII) */
    oal_time_udelay(10);
}

/**
 * @brief       Enable/Disable loopback mode
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param       en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_loopback(addr_t base_va, bool_t en)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION)) & ~(LOOPBACK_MODE(1));

    reg |= LOOPBACK_MODE(en);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));
}

/**
 * @brief       Enable/Disable promiscuous mode
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param       en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_promisc_mode(addr_t base_va, bool_t en)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_PACKET_FILTER)) & ~(PROMISCUOUS_MODE(1));

    reg |= PROMISCUOUS_MODE(en);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_PACKET_FILTER));
}

/**
 * @brief       Enable/Disable ALLMULTI mode
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param       en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_allmulti_mode(addr_t base_va, bool_t en)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_PACKET_FILTER)) & ~(PASS_ALL_MULTICAST(1));

    reg |= PASS_ALL_MULTICAST(en);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_PACKET_FILTER));
}

/**
 * @brief       Enable/Disable broadcast reception
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param       en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_broadcast(addr_t base_va, bool_t en)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_PACKET_FILTER)) & ~(DISABLE_BROADCAST_PACKETS(1));

    reg |= DISABLE_BROADCAST_PACKETS(!en);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_PACKET_FILTER));
}

/**
 * @brief       Enable/Disable the Ethernet controller
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param       en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_enable(addr_t base_va, bool_t en)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));

    reg &= ~(TRANSMITTER_ENABLE(1) | RECEIVER_ENABLE(1));
    reg |= TRANSMITTER_ENABLE(en) | RECEIVER_ENABLE(en);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_CONFIGURATION));
}

/* Get state (Enabled/Disabled) of TX flow control */
void pfe_emac_cfg_get_tx_flow_control(addr_t base_va, bool_t* en)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_Q0_TX_FLOW_CTRL));

    *en = (0U == (reg & TX_FLOW_CONTROL_ENABLE(1))) ? FALSE : TRUE;
}

/* Get state (Enabled/Disabled) of RX flow control */
void pfe_emac_cfg_get_rx_flow_control(addr_t base_va, bool_t* en)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_RX_FLOW_CTRL));

    *en = (0U == (reg & RX_FLOW_CONTROL_ENABLE(1))) ? FALSE : TRUE;
}

/**
 * @brief       Enable/Disable the tx flow control
 * @details     Once enabled the MAC shall send PAUSE frames
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param       en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_tx_flow_control(addr_t base_va, bool_t en)
{
    uint32 reg, ii=0U;

    do
    {
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_Q0_TX_FLOW_CTRL));
        oal_time_usleep(100U);
        ii++;
    } while ((reg & BUSY_OR_BACKPRESSURE_ACTIVE(1)) && (ii < 10U));

    if (ii >= 10U)
    {
        NXP_LOG_ERROR("Flow control is busy, exiting...\n");
    }
    else
    {
        reg &= ~(TX_FLOW_CONTROL_ENABLE(1));
        reg |= TX_FLOW_CONTROL_ENABLE(en);

        reg |= TX_PAUSE_TIME(DEFAULT_PAUSE_QUANTA);
        reg |= TX_PAUSE_LOW_TRASHOLD(0x0);

        hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_Q0_TX_FLOW_CTRL));
    }
}

/**
 * @brief               Enable/Disable the rx flow control
 * @details             Once enabled the MAC shall process PAUSE frames
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param               en TRUE means ENABLE, FALSE means DISABLE
 */
void pfe_emac_cfg_set_rx_flow_control(addr_t base_va, bool_t en)
{
    uint32 reg =  hal_read32(ADDR_BASE_OFFSET(base_va, MAC_RX_FLOW_CTRL));

    reg &= ~(RX_FLOW_CONTROL_ENABLE(1));
    reg |= RX_FLOW_CONTROL_ENABLE(en);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_RX_FLOW_CTRL));
}

/**
 * @brief       Read value from the MDIO bus using Clause 22
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   pa Address of the PHY to read (5-bit)
 * @param[in]   ra Address of the register in the PHY to be read (5-bit)
 * @param[out]  val If success the the read value is written here (16 bit)
 * @retval      EOK Success
 */
errno_t pfe_emac_cfg_mdio_read22(addr_t base_va, uint8 pa, uint8 ra, uint16 *val)
{
    uint32 reg;
    uint32 timeout = 500U;
    errno_t ret = EOK;

    reg = GMII_BUSY(1U)
            | CLAUSE45_ENABLE(0U)
            | GMII_OPERATION_CMD(GMII_READ)
            | SKIP_ADDRESS_PACKET(0U)
            /*  Select according to real CSR clock frequency. S32G: CSR_CLK = PFE_SYS_CLK = 300MHz */
            | CSR_CLOCK_RANGE(CSR_CLK_300_500_MHZ_MDC_CSR_DIV_204)
            | NUM_OF_TRAILING_CLOCKS(0U)
            | REG_DEV_ADDR(ra)
            | PHYS_LAYER_ADDR(pa)
            | BACK_TO_BACK(0U)
            | PREAMBLE_SUPPRESSION(0U);


    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS));
    do
    {
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS));
        if (timeout == 0U)
        {
            ret = ETIME;
            break;
        }
        timeout--;
        oal_time_usleep(10);
    }
    while(GMII_BUSY(1) == (reg & GMII_BUSY(1)));

    if (EOK == ret)
    {
        /*  Get the data */
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_MDIO_DATA));
        *val = (uint16)GMII_DATA(reg);
    }

    return ret;
}

/**
* @brief        Read value from the MDIO bus using Clause 45
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   pa  Address of the PHY to read (5-bit)
 * @param[in]   dev Selects the device in the PHY to read (5-bit)
 * @param[in]   ra  Register address in the device to read  (16-bit)
 * @param[out]  val If success the the read value is written here (16-bit)
 * @retval      EOK Success
 */
errno_t pfe_emac_cfg_mdio_read45(addr_t base_va, uint8 pa, uint8 dev, uint16 ra, uint16 *val)
{
    uint32 reg;
    uint32 timeout = 500U;
    errno_t ret = EOK;

    /* Set the register addresss to read */
    reg = (uint32)GMII_REGISTER_ADDRESS(ra);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_MDIO_DATA));

    reg = GMII_BUSY(1U)
            | CLAUSE45_ENABLE(1U)
            | GMII_OPERATION_CMD(GMII_READ)
            | SKIP_ADDRESS_PACKET(0U)
            /*  Select according to real CSR clock frequency. S32G: CSR_CLK = PFE_SYS_CLK = 300MHz */
            | CSR_CLOCK_RANGE(CSR_CLK_300_500_MHZ_MDC_CSR_DIV_204)
            | NUM_OF_TRAILING_CLOCKS(0U)
            | REG_DEV_ADDR(dev)
            | PHYS_LAYER_ADDR(pa)
            | BACK_TO_BACK(0U)
            | PREAMBLE_SUPPRESSION(0U);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS));
    while(GMII_BUSY(1) == (hal_read32(ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS)) & GMII_BUSY(1)))
    {
        if (timeout-- == 0U)
        {
            ret = ETIME;
            break;
        }

        oal_time_usleep(10);
    }

    if (EOK == ret)
    {
        /*  Get the data */
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_MDIO_DATA));
        *val = (uint16)GMII_DATA(reg);
    }

    return ret;
}

/**
 * @brief       Write value to the MDIO bus using Clause 22
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   pa Address of the PHY to be written (5-bit)
 * @param[in]   ra Address of the register in the PHY to be written (5-bit)
 * @param[in]   val Value to be written into the register (16 bit)
 * @retval      EOK Success
 */
errno_t pfe_emac_cfg_mdio_write22(addr_t base_va, uint8 pa, uint8 ra, uint16 val)
{
    uint32 reg;
    uint32 timeout = 500U;
    errno_t ret = EOK;

    reg = (uint32)GMII_DATA(val);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_MDIO_DATA));

    reg = GMII_BUSY(1U)
                | CLAUSE45_ENABLE(0U)
                | GMII_OPERATION_CMD(GMII_WRITE)
                | SKIP_ADDRESS_PACKET(0U)
                /*  Select according to real CSR clock frequency. S32G: CSR_CLK = PFE_SYS_CLK = 300MHz */
                | CSR_CLOCK_RANGE(CSR_CLK_300_500_MHZ_MDC_CSR_DIV_204)
                | NUM_OF_TRAILING_CLOCKS(0U)
                | REG_DEV_ADDR(ra)
                | PHYS_LAYER_ADDR(pa)
                | BACK_TO_BACK(0U)
                | PREAMBLE_SUPPRESSION(0U);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS));
    while(GMII_BUSY(1) == (hal_read32(ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS)) & GMII_BUSY(1)))
    {
        if (timeout-- == 0U)
        {
            ret = ETIME;
            break;
        }
        oal_time_usleep(10);
    }

    return ret;
}

/**
* @brief        Write value to the MDIO bus using Clause 45
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   pa  Address of the PHY to be written (5-bit)
 * @param[in]   dev Device in the PHY to be written (5-bit)
 * @param[in]   ra  Address of the register in the device to be written (16-bit)
 * @param[in]   val Value to be written (16-bit)
 * @retval      EOK Success
 */
errno_t pfe_emac_cfg_mdio_write45(addr_t base_va, uint8 pa, uint8 dev, uint16 ra, uint16 val)
{
    uint32 reg;
    uint32 timeout = 500U;
    errno_t ret = EOK;

    reg = (uint32)(GMII_DATA(val) | GMII_REGISTER_ADDRESS(ra));
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_MDIO_DATA));

    reg = GMII_BUSY(1U)
                | CLAUSE45_ENABLE(1U)
                | GMII_OPERATION_CMD(GMII_WRITE)
                | SKIP_ADDRESS_PACKET(0U)
                /*  Select according to real CSR clock frequency. S32G: CSR_CLK = PFE_SYS_CLK = 300MHz */
                | CSR_CLOCK_RANGE(CSR_CLK_300_500_MHZ_MDC_CSR_DIV_204)
                | NUM_OF_TRAILING_CLOCKS(0U)
                | REG_DEV_ADDR(dev)
                | PHYS_LAYER_ADDR(pa)
                | BACK_TO_BACK(0U)
                | PREAMBLE_SUPPRESSION(0U);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS));
    while(GMII_BUSY(1) == (hal_read32(ADDR_BASE_OFFSET(base_va, MAC_MDIO_ADDRESS)) & GMII_BUSY(1)))
    {
        if (timeout-- == 0U)
        {
            ret = ETIME;
            break;
        }

        oal_time_usleep(10);
    }

    return ret;
}

/**
 * @brief       Configure PPS0 output
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   mcgr_en Enable MCGR mode
 * @param[in]   trgtmodsel Target Time Register Mode for PPS0 Output
 * @param[in]   flexible_en Enable Flexiple PPS output mode
 */
void pfe_emac_cfg_pps0_configure(addr_t base_va, bool_t mcgr_en, uint8 trgtmodsel, bool_t flexible_en)
{
    uint32 regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_PPS_CONTROL));
    
    if (mcgr_en)
    {
        regval |= EMAC_CFG_PPS0_MCGR_ENABLE;
    }
    else
    {
        regval &= ~EMAC_CFG_PPS0_MCGR_ENABLE;
    }
    
    regval &= ~EMAC_CFG_PPS0_TRGTMODSEL0_MASK;
    regval |= EMAC_CFG_PPS0_TRGTMODSEL0(trgtmodsel);
    
    if (flexible_en)
    {
        regval |= EMAC_CFG_PPS0_FLEXIBLE_MODE;
    }
    else
    {
        regval &= ~EMAC_CFG_PPS0_FLEXIBLE_MODE;
    }
    
    hal_write32(regval, ADDR_BASE_OFFSET(base_va, MAC_PPS_CONTROL));
}

/**
 * @brief       Initiate PPS0 event (Flexiple PPS Output Control)
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   cmd PPS command
 */
void pfe_emac_cfg_pps_cmd(addr_t base_va, uint8 cmd)
{
    uint32 regval = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_PPS_CONTROL));
    
    regval &= ~EMAC_CFG_PPS_PPSCMD_MASK;
    regval |= cmd;
    
    hal_write32(regval, ADDR_BASE_OFFSET(base_va, MAC_PPS_CONTROL));
}

/**
 * @brief       Configure PPS0 target time
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   seconds value to be filled to seconds register
 * @param[in]   nanoseconds value to be filled to nanoseconds register
 */
void pfe_emac_cfg_pps0_set_target_time(addr_t base_va, uint32 seconds, uint32 nanoseconds)
{
    hal_write32(nanoseconds, ADDR_BASE_OFFSET(base_va, MAC_PPS0_TARGET_TIME_NANOSECONDS));
    hal_write32(seconds, ADDR_BASE_OFFSET(base_va, MAC_PPS0_TARGET_TIME_SECONDS));
}

/**
 * @brief       Configure PPS0 period
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   period Period width (in units of PPS counter ticks)
 */
void pfe_emac_cfg_pps0_set_period(addr_t base_va, uint32 period)
{
    hal_write32(period, ADDR_BASE_OFFSET(base_va, MAC_PPS0_INTERVAL));
}

/**
 * @brief       Configure PPS0 pulse width
 * @param[in]   base_va Base address of MAC register space (virtual)
 * @param[in]   pulse_width Pulse width (in units of PPS counter ticks)
 */
void pfe_emac_cfg_pps0_set_pulse_width(addr_t base_va, uint32 pulse_width)
{
    hal_write32(pulse_width, ADDR_BASE_OFFSET(base_va, MAC_PPS0_WIDTH));
}

/**
 * @brief       Get number of transmitted packets
 * @param[in]   base_va Base address of EMAC register space (virtual)
 * @return      Number of transmitted packets
 */
uint32 pfe_emac_cfg_get_tx_cnt(addr_t base_va)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va, TX_PACKET_COUNT_GOOD_BAD));
}

/**
 * @brief       Get number of received packets
 * @param[in]   base_va Base address of EMAC register space (virtual)
 * @return      Number of received packets
 */
uint32 pfe_emac_cfg_get_rx_cnt(addr_t base_va)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va, RX_PACKETS_COUNT_GOOD_BAD));
}

/**
 * @brief       Reports events corresponding to triggered interrupts to HM
 * @param[in]   id ID of the Peripheral that triggered the interrupt
 * @param[in]   events  List of events, ordered by interrupt flag position (0-31)
 * @param[in]   events_len  Amount of events defined
 * @param[in]   flags   Interrupts flags
 */
static void pfe_emac_cfg_report_hm_event(uint8 id, const pfe_hm_evt_t events[], uint8 events_len, uint32 flags)
{
    static const pfe_hm_src_t hm_src[] =
    {
        HM_SRC_EMAC0,
        HM_SRC_EMAC1,
        HM_SRC_EMAC2,
    };
    uint8 index = 0U;
    uint32 isr_flags = flags;
    pfe_hm_src_t src = HM_SRC_EMAC0;
    uint8 emac_err_src_index = 0U;
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
    const Dem_EventIdType emac_dem_err_id[PFE_EMAC_INSTANCES][EMAC_ERR_SRC_NUMBER] =
    {
        {ETH_43_PFE_CFG_DEM_E_EMAC0_ECC_UNCORRECTABLE_ERR, ETH_43_PFE_CFG_DEM_E_EMAC0_ECC_ADDRESS_ERR, ETH_43_PFE_CFG_DEM_E_EMAC0_PARITY_ERR, ETH_43_PFE_CFG_DEM_E_EMAC0_WDT_ERR},
        {ETH_43_PFE_CFG_DEM_E_EMAC1_ECC_UNCORRECTABLE_ERR, ETH_43_PFE_CFG_DEM_E_EMAC1_ECC_ADDRESS_ERR, ETH_43_PFE_CFG_DEM_E_EMAC1_PARITY_ERR, ETH_43_PFE_CFG_DEM_E_EMAC1_WDT_ERR},
        {ETH_43_PFE_CFG_DEM_E_EMAC2_ECC_UNCORRECTABLE_ERR, ETH_43_PFE_CFG_DEM_E_EMAC2_ECC_ADDRESS_ERR, ETH_43_PFE_CFG_DEM_E_EMAC2_PARITY_ERR, ETH_43_PFE_CFG_DEM_E_EMAC2_WDT_ERR}
    };
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */

    if (id < (sizeof(hm_src)/sizeof(hm_src[0U])))
    {
        src = hm_src[id];
        while ((0U != isr_flags) && (index < events_len))
        {
            if ((0U != (isr_flags & 0x1UL)) && (events[index] != HM_EVT_NONE))
            {
                switch (events[index])
                {
                    case HM_EVT_EMAC_ECC_TX_FIFO_CORRECTABLE:
                    case HM_EVT_EMAC_ECC_RX_FIFO_CORRECTABLE:
                    {
                        pfe_hm_report_warning(src, events[index], "");
                        break;
                    }
                    case HM_EVT_EMAC_ECC_TX_FIFO_UNCORRECTABLE:
                    case HM_EVT_EMAC_ECC_RX_FIFO_UNCORRECTABLE:
                    case HM_EVT_EMAC_ECC_TX_FIFO_ADDRESS:
                    case HM_EVT_EMAC_ECC_RX_FIFO_ADDRESS:
                    case HM_EVT_EMAC_APP_TX_PARITY:
                    case HM_EVT_EMAC_APP_RX_PARITY:
                    case HM_EVT_EMAC_MTL_PARITY:
                    case HM_EVT_EMAC_FSM_PARITY:
                    case HM_EVT_EMAC_FSM_TX_TIMEOUT:
                    case HM_EVT_EMAC_FSM_RX_TIMEOUT:
                    case HM_EVT_EMAC_FSM_APP_TIMEOUT:
                    case HM_EVT_EMAC_FSM_PTP_TIMEOUT:
                    case HM_EVT_EMAC_MASTER_TIMEOUT:
                    {
                        emac_err_src_index = pfe_emac_get_emac_err_src_index(events[index]);
                        if (EMAC_ERR_SRC_INDEX_INVALID != emac_err_src_index)
                        {
                            pfe_hm_report_error(src, events[index], "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
                           (void)Dem_SetEventStatus(emac_dem_err_id[id][emac_err_src_index], DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
                        }
                        break;
                    }
                    default:
                    {
                        /* Do nothing */
                        break;
                    }
                }
            }
            index++;
            isr_flags >>= 1U;
        }
    }
    else
    {
        NXP_LOG_ERROR("Argument out of range");
    }
}

/**
 * @brief       EMAC ISR
 * @details     Process triggered interrupts.
 * @param[in]   base_va EMAC register space base address
 * @param[in]   cbus_base The PFE CBUS base address
 * @return      EOK if interrupt has been handled, error code otherwise
 */
errno_t pfe_emac_cfg_isr(addr_t base_va, addr_t cbus_base)
{
    uint8 instance_id = pfe_emac_cfg_get_index(base_va, cbus_base);

    static const pfe_hm_evt_t mtl_ecc_events[] =
    {
        HM_EVT_EMAC_ECC_TX_FIFO_CORRECTABLE,
        HM_EVT_EMAC_ECC_TX_FIFO_ADDRESS,
        HM_EVT_EMAC_ECC_TX_FIFO_UNCORRECTABLE,
        HM_EVT_NONE,
        HM_EVT_EMAC_ECC_RX_FIFO_CORRECTABLE,
        HM_EVT_EMAC_ECC_RX_FIFO_ADDRESS,
        HM_EVT_EMAC_ECC_RX_FIFO_UNCORRECTABLE,
    };

    static const pfe_hm_evt_t dpp_fsm_events[] =
    {
        HM_EVT_EMAC_APP_TX_PARITY,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_EMAC_MTL_PARITY,
        HM_EVT_NONE,
        HM_EVT_EMAC_APP_RX_PARITY,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_EMAC_FSM_TX_TIMEOUT,
        HM_EVT_EMAC_FSM_RX_TIMEOUT,
        HM_EVT_NONE,
        HM_EVT_EMAC_FSM_APP_TIMEOUT,
        HM_EVT_EMAC_FSM_PTP_TIMEOUT,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_EMAC_MASTER_TIMEOUT,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_NONE,
        HM_EVT_EMAC_FSM_PARITY,
    };

    uint32 mtl_ecc_status = hal_read32(ADDR_BASE_OFFSET(base_va, MTL_ECC_INTERRUPT_STATUS));
    uint32 dpp_fsm_status = hal_read32(ADDR_BASE_OFFSET(base_va, MAC_DPP_FSM_INTERRUPT_STATUS));

    pfe_emac_cfg_report_hm_event(
            instance_id,
            mtl_ecc_events,
            sizeof(mtl_ecc_events)/sizeof(mtl_ecc_events[0]),
            mtl_ecc_status);

    pfe_emac_cfg_report_hm_event(
            instance_id,
            dpp_fsm_events,
            sizeof(dpp_fsm_events)/sizeof(dpp_fsm_events[0]),
            dpp_fsm_status);

    /* Clear interrupts */
    hal_write32(mtl_ecc_status, ADDR_BASE_OFFSET(base_va, MTL_ECC_INTERRUPT_STATUS));
    hal_write32(dpp_fsm_status, ADDR_BASE_OFFSET(base_va, MAC_DPP_FSM_INTERRUPT_STATUS));

    return EOK;
}
#endif

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [142/185]: src\pfe_emac_slave.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2022-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */


/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "hal.h"
#include "pfe_emac.h"
#ifdef PFE_CFG_PFE_SLAVE
#include "pfe_platform_cfg.h"
#include "pfe_emac_csr.h"
#include "pfe_cbus.h"
#include "pfe_idex.h" /* The RPC provider */
#include "pfe_platform_rpc.h" /* The RPC codes and data structures */
#include "pfe_platform.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_emac_t emac_instance[PFE_EMAC_INSTANCES];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

/**
 * @brief       Create new EMAC instance
 * @details     Creates and initializes MAC instance
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   emac_base EMAC base address offset within CBUS address space
 * @param[in]   mode The MII mode to be used @see pfe_emac_mii_mode_t
 * @param[in]   speed Speed @see pfe_emac_speed_t
 * @param[in]   duplex The duplex type @see pfe_emac_duplex_t
 * @return      The EMAC instance or NULL if failed
 */
pfe_emac_t *pfe_emac_create(addr_t cbus_base_va, addr_t emac_base, pfe_emac_mii_mode_t mode, pfe_emac_speed_t speed, pfe_emac_duplex_t duplex)
{
    pfe_emac_t *emac;
    uint8 emac_index = 255U;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        emac = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        emac_index = pfe_emac_cfg_get_index(ADDR_BASE_OFFSET(emac_base, cbus_base_va), cbus_base_va);

        if (unlikely(PFE_EMAC_INSTANCES <= emac_index))
        {
            NXP_LOG_ERROR("EMAC index out of range\n");
            emac = NULL;
        }
        else
        {
            emac = &emac_instance[emac_index];
            (void)autolibc_memset(emac, 0, sizeof(pfe_emac_t));
            emac->cbus_base_va = cbus_base_va;
            emac->emac_base_offset = emac_base;
            emac->emac_base_va = ADDR_BASE_OFFSET(emac->cbus_base_va, emac->emac_base_offset);
            emac->mode = mode;
            emac->speed = speed;
            emac->duplex = duplex;
            emac->emac_id = (pfe_ct_phy_if_id_t)emac_index;
        }
    }

    return emac;
}

/**
 * @brief       Get EMAC instance index
 * @param[in]   emac The EMAC instance
 * @return      Index (0, 1, 2, ..) or 255 if failed
 */
uint8 pfe_emac_get_index(const pfe_emac_t *emac)
{
    uint8 emac_idx;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        emac_idx = 255U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (emac->emac_base_offset)
        {
            case CBUS_EMAC1_BASE_ADDR:
            {
                emac_idx = 0U;
                break;
            }

            case CBUS_EMAC2_BASE_ADDR:
            {
                emac_idx = 1U;
                break;
            }

            case CBUS_EMAC3_BASE_ADDR:
            {
                emac_idx = 2U;
                break;
            }

            default:
            {
                emac_idx = 255U;
                break;
            }
        }
    }

    return emac_idx;
}

/**
 * @brief       Read value from the MDIO bus using Clause 22
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   ra Register address
 * @param[out]  val If success the the read value is written here
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_read22(pfe_emac_t *emac, uint8 pa, uint8 ra, uint16 *val, uint32 key)
{
    errno_t ret;
    uint8 emac_index;
    pfe_platform_rpc_mdio_proxy_arg_t rpc_arg;
    pfe_platform_rpc_mdio_proxy_ret_t rpc_ret = {0U};

    (void)autolibc_memset(&rpc_arg, 0, sizeof(pfe_platform_rpc_mdio_proxy_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        emac_index = pfe_emac_get_index(emac);
        if (2U < emac_index)
        {
            NXP_LOG_ERROR("Invalid EMAC id: %d\n", emac_index);
            ret = EINVAL;
        }
        else
        {
            rpc_arg.emac_id = emac_index;
            rpc_arg.op = PFE_PLATFORM_RPC_MDIO_OP_READ_CL22;
            rpc_arg.pa = pa;
            rpc_arg.ra = ra;

            if (TRUE == emac->mdio_locked)
            {
                /*  Locked. Check key. */
                if (key == emac->mdio_key)
                {
                    ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), &rpc_ret, (uint16)sizeof(rpc_ret));
                }
                else
                {
                    ret = EPERM;
                }
            }
            else
            {
                /*  Unlocked. No check required. */
                ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), &rpc_ret, (uint16)sizeof(rpc_ret));
            }

            if (EOK == ret)
            {
                *val = rpc_ret.val;
            }
            else
            {
                *val = 0xFFFFU;
            }
        }
    }

    return ret;
}

/**
 * @brief       Write value to the MDIO bus using Clause 22
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   ra Register address
 * @param[in]   val Value to be written
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_write22(pfe_emac_t *emac, uint8 pa, uint8 ra, uint16 val, uint32 key)
{
    errno_t ret;
    uint8 emac_index;
    pfe_platform_rpc_mdio_proxy_arg_t rpc_arg;

    (void)autolibc_memset(&rpc_arg, 0, sizeof(pfe_platform_rpc_mdio_proxy_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        emac_index = pfe_emac_get_index(emac);
        if (2U < emac_index)
        {
            NXP_LOG_ERROR("Invalid EMAC id: %d\n", emac_index);
            ret = EINVAL;
        }
        else
        {
            rpc_arg.emac_id = emac_index;
            rpc_arg.op = PFE_PLATFORM_RPC_MDIO_OP_WRITE_CL22;
            rpc_arg.pa = pa;
            rpc_arg.ra = ra;
            rpc_arg.val = val;

            if (TRUE == emac->mdio_locked)
            {
                /*  Locked. Check key. */
                if (key == emac->mdio_key)
                {
                    ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), NULL, 0U);
                }
                else
                {
                    ret = EPERM;
                }
            }
            else
            {
                /*  Unlocked. No check required. */
                ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), NULL, 0U);
            }
        }
    }
    return ret;
}

/**
 * @brief       Read value from the MDIO bus using Clause 45
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   dev Device address
 * @param[in]   ra Register address
 * @param[out]  val If success the the read value is written here
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_read45(pfe_emac_t *emac, uint8 pa, uint8 dev, uint16 ra, uint16 *val, uint32 key)
{
    errno_t ret;
    uint8 emac_index;
    pfe_platform_rpc_mdio_proxy_arg_t rpc_arg;
    pfe_platform_rpc_mdio_proxy_ret_t rpc_ret = {0U};

    (void)autolibc_memset(&rpc_arg, 0, sizeof(pfe_platform_rpc_mdio_proxy_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        emac_index = pfe_emac_get_index(emac);
        if (2U < emac_index)
        {
            NXP_LOG_ERROR("Invalid EMAC id: %d\n", emac_index);
            ret = EINVAL;
        }
        else
        {
            rpc_arg.emac_id = emac_index;
            rpc_arg.op = PFE_PLATFORM_RPC_MDIO_OP_READ_CL45;
            rpc_arg.pa = pa;
            rpc_arg.dev = dev;
            rpc_arg.ra = ra;

            if (TRUE == emac->mdio_locked)
            {
                /*  Locked. Check key. */
                if (key == emac->mdio_key)
                {
                    ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), &rpc_ret, (uint16)sizeof(rpc_ret));
                }
                else
                {
                    ret = EPERM;
                }
            }
            else
            {
                /*  Unlocked. No check required. */
                ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), &rpc_ret, (uint16)sizeof(rpc_ret));
            }

            if (EOK == ret)
            {
                *val = rpc_ret.val;
            }
            else
            {
                *val = 0xFFFFU;
            }
        }
    }

    return ret;
}

/**
 * @brief       Write value to the MDIO bus using Clause 45
 * @param[in]   emac The EMAC instance
 * @param[in]   pa PHY address
 * @param[in]   dev Device address
 * @param[in]   ra Register address
 * @param[in]   val Value to be written
 * @param[in]   key Access key in case the resource is locked
 * @retval      EOK Success
 */
errno_t pfe_emac_mdio_write45(pfe_emac_t *emac, uint8 pa, uint8 dev, uint16 ra, uint16 val, uint32 key)
{
    errno_t ret;
    uint8 emac_index;
    pfe_platform_rpc_mdio_proxy_arg_t rpc_arg;

    (void)autolibc_memset(&rpc_arg, 0, sizeof(pfe_platform_rpc_mdio_proxy_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        emac_index = pfe_emac_get_index(emac);
        if (2U < emac_index)
        {
            NXP_LOG_ERROR("Invalid EMAC id: %d\n", emac_index);
            ret = EINVAL;
        }
        else
        {
            rpc_arg.emac_id = emac_index;
            rpc_arg.op = PFE_PLATFORM_RPC_MDIO_OP_WRITE_CL45;
            rpc_arg.pa = pa;
            rpc_arg.dev = dev;
            rpc_arg.ra = ra;
            rpc_arg.val = val;

            if (TRUE == emac->mdio_locked)
            {
                /*  Locked. Check key. */
                if (key == emac->mdio_key)
                {
                    ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), NULL, 0U);
                }
                else
                {
                    ret = EPERM;
                }
            }
            else
            {
                /*  Unlocked. No check required. */
                ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_MDIO_PROXY, &rpc_arg, (uint16)sizeof(rpc_arg), NULL, 0U);
            }
        }
    }

    return ret;
}

/**
 * @brief       Adjust timestamping clock frequency to compensate drift
 * @param[in]   emac The EMAC instance
 * @param[in]   ppb Frequency change in [ppb]
 * @param[in]   sgn The ppb sign. If TRUE then the value is positive, else it is negative
 */
errno_t pfe_emac_set_ts_freq_adjustment(pfe_emac_t *emac, uint32 ppb, bool_t sgn)
{
    errno_t ret = EOK;
    bool_t is_owner = FALSE;

    ret = pfe_emac_local_is_timer_owner(emac, &is_owner);

    if ((EOK == ret) && (TRUE == is_owner))
    {
        oal_mutex_lock(PFE_EMAC_TS_MUTEX_01);

        emac->adj_ppb = ppb;
        emac->adj_sign = sgn;

        ret = pfe_emac_cfg_adjust_ts_freq(emac->emac_base_va, emac->i_clk_hz, emac->o_clk_hz, ppb, sgn);

        oal_mutex_unlock(PFE_EMAC_TS_MUTEX_01);
    }
    else
    {
        ret = EPERM;
    }

    return ret;
}

/**
 * @brief           Get current adjustment value
 * @param[in]       emac The EMAC instance
 * @param[in,out]   ppb Pointer where the current adjustment value in ppb shall be written
 * @param[in,out]   sgn Pointer where the sign flag shall be written (TRUE means that
 *                  the 'ppb' is positive, FALSE means it is nagative)
 * @return          EOK if success, error code otherwise
 */
errno_t pfe_emac_get_ts_freq_adjustment(pfe_emac_t *emac, uint32 *ppb, bool_t *sgn)
{
    errno_t ret = EOK;

    if ((NULL == ppb) || (NULL == sgn))
    {
        ret = EINVAL;
    }
    else
    {
        *ppb = emac->adj_ppb;
        *sgn = emac->adj_sign;
        ret = EOK;
    }

    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return EMAC runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   gpi         The EMAC instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_emac_get_text_statistics(const pfe_emac_t *emac, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += pfe_emac_cfg_get_text_stat(emac->emac_base_va, buf + len, buf_len - len, verb_level);
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief           Get current time
 * @param[in]       emac THe EMAC instance
 * @param[in,out]   sec Pointer where seconds value shall be written
 * @param[in,out]   nsec Pointer where nano-seconds value shall be written
 * @param[in,out]   sec_hi Pointer where higher-word-seconds value shall be written
 * @return          EOK if success, error code otherwise
 */
errno_t pfe_emac_get_ts_time(pfe_emac_t *emac, uint32 *sec, uint32 *nsec, uint16 *sec_hi)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((NULL == sec) || (NULL == nsec) || (NULL == sec_hi))
        {
            ret = EINVAL;
        }
        else
        {
            pfe_emac_cfg_get_ts_time(emac->emac_base_va, sec, nsec, sec_hi);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Adjust current time
 * @details     Current timer value will be adjusted by adding or subtracting the
 *              desired value.
 * @param[in]   emac The EMAC instance
 * @param[in]   sec Seconds
 * @param[in]   nsec NanoSeconds
 * @param[in]   sgn Sign of the adjustment. If TRUE then the adjustment will be positive
 *                  ('sec' and 'nsec' will be added to the current time. If FALSE then the
 *                  adjustment will be negative ('sec' and 'nsec' will be subtracted from
 *                  the current time).
 */
errno_t pfe_emac_adjust_ts_time(pfe_emac_t *emac, uint32 sec, uint32 nsec, bool_t sgn)
{
    errno_t ret = EOK;
    bool_t is_owner = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_local_is_timer_owner(emac, &is_owner);

        if ((EOK == ret) && (TRUE == is_owner))
        {
            oal_mutex_lock(PFE_EMAC_TS_MUTEX_02);

            ret = pfe_emac_cfg_adjust_ts_time(emac->emac_base_va, sec, nsec, sgn);

            oal_mutex_unlock(PFE_EMAC_TS_MUTEX_02);
        }
        else
        {
            ret = EPERM;
        }
    }

    return ret;
}

/**
 * @brief       Set current time
 * @details     Funcion will set new system time. Current timer value
 *              will be overwritten with the desired value.
 * @param[in]   emac The EMAC instance
 * @param[in]   sec New seconds value
 * @param[in]   nsec New nano-seconds value
 * @param[in]   sec_hi New higher-word-seconds value
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_emac_set_ts_time(pfe_emac_t *emac, uint32 sec, uint32 nsec, uint16 sec_hi)
{
    errno_t ret = EOK;
    bool_t is_owner = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_emac_local_is_timer_owner(emac, &is_owner);

        if ((EOK == ret) && (TRUE == is_owner))
        {
            oal_mutex_lock(PFE_EMAC_TS_MUTEX_03); 

            ret = pfe_emac_cfg_set_ts_time(emac->emac_base_va, sec, nsec, sec_hi);

            oal_mutex_unlock(PFE_EMAC_TS_MUTEX_03);
        }
        else
        {
            ret = EPERM;
        }
    }

    return ret;
}

/**
 * @brief       Check if the driver instance associated with the local HIF is the timer owner of EMAC
 * @param[in]   emac The EMAC instance
 * @param[out]  is_owner The timer ownership status shall be written here
 * @return      EOK if sucess, error code otherwise
 */
errno_t pfe_emac_local_is_timer_owner(pfe_emac_t *emac, bool_t *is_owner)
{
    errno_t ret = EOK;
    pfe_hif_chnl_t *local_hif_chnl = NULL;
    pfe_platform_t *platform = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == is_owner)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        platform = pfe_platform_get_instance();
        if (NULL_PTR == platform)
        {
            ret = EINVAL;
            NXP_LOG_ERROR("Could not get PFE platform instance\n");
        }
        else
        {
            local_hif_chnl = pfe_hif_get_channel(platform->hif, pfe_hif_chnl_from_phy_id(PFE_CFG_LOCAL_IF));
            if (NULL_PTR == local_hif_chnl)
            {
                ret = EINVAL;
                NXP_LOG_ERROR("Can't get HIF channel instance\n");
            }
            else
            {
                *is_owner = pfe_hif_chnl_get_emac_timer_ownership(local_hif_chnl->cbus_base_va, PFE_CFG_LOCAL_IF, emac->emac_id);
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
 * @brief       Get EMAC statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the EMAC block.
 * @param[in]   emac        The EMAC instance
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic
 */
uint32 pfe_emac_get_stat_value(const pfe_emac_t *emac, uint32 stat_id)
{
    uint32 stat_value = 0U;
#if (FALSE == PFE_CFG_SLAVE_READ_EMAC_STAT_CNT_DIRECT)
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_get_stat_value_arg_t arg = {.phy_if_id = PFE_PHY_IF_ID_EMAC0, .stat_id = 0U};
    pfe_platform_rpc_pfe_phy_if_get_stat_value_ret_t rpc_ret = {0U};
    uint8 emac_id;
#endif /* PFE_CFG_SLAVE_READ_EMAC_STAT_CNT_DIRECT */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == emac))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = 0xFFFFFFFFU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if (TRUE == PFE_CFG_SLAVE_READ_EMAC_STAT_CNT_DIRECT)
        stat_value = pfe_emac_cfg_get_stat_value(emac->emac_base_va, stat_id);
#else
        emac_id = pfe_emac_get_index(emac);
        if (2U < emac_id)
        {
            NXP_LOG_ERROR("Invalid EMAC id: %d\n", emac_id);
            stat_value = 0xFFFFFFFFU;
        }
        else
        {
            /*  Ask the master driver to get statistic values */
            arg.phy_if_id = (pfe_ct_phy_if_id_t)emac_id;
            arg.stat_id = stat_id;
            ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_GET_STAT_VALUE, &arg, (uint16)sizeof(arg), &rpc_ret, (uint16)sizeof(rpc_ret));
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_GET_STAT_VALUE failed: %d\n", ret);
            }
            else
            {
                stat_value = rpc_ret.stat_val;
            }
        }
#endif /* PFE_CFG_SLAVE_READ_EMAC_STAT_CNT_DIRECT */
    }
    return stat_value;
}

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
#endif /* PFE_CFG_PFE_SLAVE */


===== 文件 [143/185]: src\pfe_fail_stop.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_fail_stop.h"
#include "pfe_fail_stop_csr.h"

struct pfe_fail_stop_tag
{
    addr_t cbus_base_va;
    addr_t fail_stop_base_offset;
    addr_t fail_stop_base_va;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_fail_stop_t fail_stop_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create new FAIL_STOP instance
 * @details     Create and initializes FAIL_STOP instance. New instance is always enabled.
 *              Use mask and unmask function to control interrupts.
 * @param[in]   base_va FAIL_STOP register space base address (virtual)
 * @param[in]   fail_stop to be initialized
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Interrupt which were triggered are masked here, it is periodically unmasked again in SAFETY thread
 */
pfe_fail_stop_t *pfe_fail_stop_create(addr_t cbus_base_va, addr_t fail_stop_base)
{
    pfe_fail_stop_t *fail_stop;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        fail_stop = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fail_stop = &fail_stop_instance;
        (void)autolibc_memset(fail_stop, 0, sizeof(pfe_fail_stop_t));
        fail_stop->cbus_base_va = cbus_base_va;
        fail_stop->fail_stop_base_offset = fail_stop_base;
        fail_stop->fail_stop_base_va = ADDR_BASE_OFFSET(fail_stop->cbus_base_va, fail_stop->fail_stop_base_offset);

        /* Unmask all interrupts */
        pfe_fail_stop_cfg_irq_unmask_all(fail_stop->fail_stop_base_va);
    }

    return fail_stop;
}

/**
 * @brief       Destroy FAIL_STOP instance
 * @param[in]   fail_stop The FAIL_STOP instance
 */
void pfe_fail_stop_destroy(pfe_fail_stop_t *fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Mask fail_stop interrupts */
        pfe_fail_stop_cfg_irq_mask(fail_stop->fail_stop_base_va);
    }
}

/**
 * @brief       FAIL_STOP ISR
 * @param[in]   fail_stop The FAIL_STOP instance
 * @return      EOK if interrupt has been handled
 */
errno_t pfe_fail_stop_isr(const pfe_fail_stop_t *fail_stop)
{
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = ENOMEM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_fail_stop_cfg_isr(fail_stop->fail_stop_base_va);
    }

    return ret;
}

/**
 * @brief       Mask FAIL_STOP interrupts
 * @param[in]   fail_stop The FAIL_STOP instance
 */
void pfe_fail_stop_irq_mask(const pfe_fail_stop_t *fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_fail_stop_cfg_irq_mask(fail_stop->fail_stop_base_va);
    }
}

/**
 * @brief       Unmask FAIL_STOP interrupts
 * @param[in]   fail_stop The FAIL_STOP instance
 */
void pfe_fail_stop_irq_unmask(const pfe_fail_stop_t *fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_fail_stop_cfg_irq_unmask(fail_stop->fail_stop_base_va);
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [144/185]: src\pfe_fail_stop_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_global_wsp.h"
#include "pfe_fail_stop_csr.h"
#include "Eth_43_PFE_Cfg.h"

#define FAIL_STOP_INT_SRC_NUMBER   6U

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       FAIL_STOP ISR
 * @details     MASK, ACK, and process triggered interrupts.
 * @param[in]   base_va FAIL_STOP register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 */
errno_t pfe_fail_stop_cfg_isr(addr_t base_va)
{
    uint32 reg_en, reg_src, reg_source;
    errno_t ret = ENOENT;
    uint32 trig_en_interrupts = 0U;
    uint8 index = 0U;
    static const pfe_hm_evt_t event_id[FAIL_STOP_INT_SRC_NUMBER] =
    {
        HM_EVT_FAIL_STOP_PARITY,
        HM_EVT_FAIL_STOP_WATCHDOG,
        HM_EVT_FAIL_STOP_BUS,
        HM_EVT_FAIL_STOP_ECC_MULTIBIT,
        HM_EVT_FAIL_STOP_FW,
        HM_EVT_FAIL_STOP_HOST,
    };

    /* Get enabled interrupts */
    reg_en = hal_read32(base_va + WSP_FAIL_STOP_MODE_INT_EN);
    /* Mask Fail Stop interrupts */
    hal_write32((reg_en & ~(FAIL_STOP_INT_EN)), base_va + WSP_FAIL_STOP_MODE_INT_EN);
    /* Get triggered interrupts */
    reg_src = hal_read32(base_va + WSP_FAIL_STOP_MODE_INT_SRC);
    if (0U != (reg_src & reg_en & FAIL_STOP_INT_ENABLE_ALL))
    {
        reg_source = hal_read32(base_va + WSP_FAILSTOP_INTERRUPT_SOURCE) & \
                     hal_read32(base_va + WSP_FAIL_STOP_MODE_EN);
    }
    else
    {
        reg_source = 0U;
    }

    /* Process interrupts which are triggered AND enabled */
    if (0U != reg_source)
    {
        trig_en_interrupts = reg_source;
        while (0U != trig_en_interrupts)
        {
            PfeDevAssert(index < FAIL_STOP_INT_SRC_NUMBER);

            if (0U != (trig_en_interrupts & 1UL))
            {
                pfe_hm_report_error(HM_SRC_FAIL_STOP, event_id[index], "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
               (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_FAIL_STOP_HW_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
            }
            trig_en_interrupts >>= 1U;

            index++;
        }
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Mask FAIL_STOP interrupts
 * @param[in]   base_va Base address of the FAIL_STOP register space
 */
void pfe_fail_stop_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_FAIL_STOP_MODE_INT_EN) & ~(FAIL_STOP_INT_EN);
    hal_write32(reg, base_va + WSP_FAIL_STOP_MODE_INT_EN);
}

/**
 * @brief       Unmask FAIL_STOP interrupts
 * @param[in]   base_va Base address of the FAIL_STOP register space
 */
void pfe_fail_stop_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_FAIL_STOP_MODE_INT_EN) | FAIL_STOP_INT_EN;
    hal_write32(reg, base_va + WSP_FAIL_STOP_MODE_INT_EN);
}

/**
 * @brief       Unmask all FAIL_STOP interrupts
 * @param[in]   base_va Base address of the FAIL_STOP register space
 * @note        This function is called from thread.
 */
void pfe_fail_stop_cfg_irq_unmask_all(addr_t base_va)
{
    hal_write32(FAIL_STOP_INT_ENABLE_ALL, base_va + WSP_FAIL_STOP_MODE_INT_EN);     /*direct write*/
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [145/185]: src\pfe_feature_mgr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_platform_cfg.h"
#include "pfe_class.h"
#include "pfe_util.h"
#include "pfe_tmu.h"
#include "pfe_hw_feature.h"
#include "pfe_feature_mgr.h"
#include "pfe_fw_feature.h"

/*
--------------         -----------------         -----------
|PFE Platform|--uses-->|pfe_feature_mgr|--uses-->|pfe_class|--uses---------\
--------------         -----------------         -----------               |
                          ^    |      |          ----------                |
-----                     |    |      \---uses-->|pfe_util|---uses------\  |
|FCI|----uses-------------/    |                 ----------             |  |
-----                          |                                        V  V
                               |                                     ----------------
                               |------------------------------uses-->|pfe_fw_feature|
                               |                                     ----------------
                               |
                               |                                     ----------------
                               \------------------------------uses-->|pfe_hw_feature|
                                                                     ----------------
*/

typedef struct
{
    uint32 *         cbus_base;
    uint32           current_hw_feature; /* Index of the hw feature to return by pfe_hw_get_feature_next() */
    pfe_hw_feature_t   hw_features[2];        /* List of all hw features*/
    uint32           hw_features_count;  /* Number of items in hw_features */

    bool_t rewind_flg; /* Internal flag supporting transition walk from hw_feature set to fw_feature set */
    pfe_class_t *class;
    pfe_util_t *util;
    pfe_tmu_t * tmu; /* Included because of err051211_workaround */
} pfe_feature_mgr_t;

typedef struct
{
    bool_t   class_avail;
    bool_t   util_avail;
} pfe_feature_mgr_state_info_t;

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/**
 * @brief Feature manager instance
 * @details The feature manager is a single instance only, the instance handle is stored here
 */
static pfe_feature_mgr_t feature_mgr = { 0 };
#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
/**
 *  Internal flag supporting transition walk from cfg table to stats table
 */
static bool_t table_rewind_flag = FALSE;
#define ETH_43_PFE_STOP_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_hw_get_feature(pfe_feature_mgr_t *fmgr, pfe_hw_feature_t **feature, const char *name);
static errno_t pfe_hw_get_feature_first(pfe_feature_mgr_t *fmgr, pfe_hw_feature_t **feature);
static errno_t pfe_hw_get_feature_next(pfe_feature_mgr_t *fmgr, pfe_hw_feature_t **feature);
static errno_t pfe_feature_mgr_configure_driver(const char *feature_name, const uint8 val);
static errno_t pfe_feature_mgr_disable_hw_feature(const char *feature_name);
static errno_t pfe_feature_mgr_disable_class_feature(const char *feature_name);
static errno_t pfe_feature_mgr_enable_class_feature(const char *feature_name);
static errno_t pfe_feature_mgr_enable_hw_feature(const char *feature_name);
static errno_t pfe_feature_mgr_get_val_class_util(const char *feature_name, uint8 **val);
static errno_t pfe_feature_mgr_set_val_class_util(pfe_fw_feature_t *fw_feature_class, pfe_fw_feature_t *fw_feature_util, const uint8 val);
static errno_t pfe_feature_mgr_handle_feature(const pfe_feature_mgr_t *fmgr, const char *feature_name, const uint8 val);
static void pfe_feature_mgr_is_feature_present(pfe_fw_feature_t *fw_feature_class, pfe_feature_mgr_state_info_t *mgr_state);
static errno_t pfe_feature_mgr_is_class_available(const char *feature_name, pfe_fw_feature_t **fw_feature_class, pfe_feature_mgr_state_info_t *mgr_state);
#if defined(PFE_CFG_NULL_ARG_CHECK)
static errno_t table_set_val_null_check(const char *feature_name, const char *table_el_name, uint8* val);
#endif

/**
 * @brief Initializes (the only) feature manager instance
 * @param[in] cbus_base Reference to the Platform config
 * @return EOK or error code in case of failure.
 */
errno_t pfe_feature_mgr_init(uint32 *cbus_base)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == cbus_base)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        (void)autolibc_memset(&feature_mgr, 0, sizeof(pfe_feature_mgr_t));
        feature_mgr.cbus_base = cbus_base;
        table_rewind_flag = FALSE;
        ret = pfe_hw_feature_init_all(cbus_base, feature_mgr.hw_features, &feature_mgr.hw_features_count);
    }

    return ret;
}

/**
 * @brief Link FW modules class and util
 * @param[in] class Reference to the class module (cannot be NULL - class must be always present)
 * @param[in] util Reference to the util module (value NULL means util is not present)
 * @param[in] tmu Reference to the tmu module  (cannot be NULL - tmu must be always present)
 * @return EOK or error code in case of failure.
 */
errno_t pfe_feature_mgr_add_modules(pfe_class_t *class, pfe_util_t *util, pfe_tmu_t *tmu)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL == class) || (NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
/* Note it is OK for "util" to be NULL */
#endif
    {
        feature_mgr.class = class;
        feature_mgr.util = util;
        feature_mgr.tmu = tmu;
        ret = EOK;
    }

    return ret;
}

/**
 * @brief Deinitializes the feature manager instance
 * @return EOK or error code in case of failure.
 */
errno_t pfe_feature_mgr_fini(void)
{
    (void)autolibc_memset(&feature_mgr, 0, sizeof(pfe_feature_mgr_t));

    return EOK;
}

/**
 * @brief       Checks whether the firmware feature with given name is available to be used
 * @param[in]   feature_name Name of the feature to check
 * @param[in]   fw_feature_class Feature descriptor in class.
 * @param[in]   mgr_state Class/Util feature state
 * @return      EOK or failure code.
 * @details     It is checked whether the feature is applicable for class and then
 *              it is checked whether it is enabled at all places it is applicable for.
 */

static errno_t pfe_feature_mgr_is_class_available(const char *feature_name, pfe_fw_feature_t **fw_feature_class, pfe_feature_mgr_state_info_t *mgr_state)
{
    errno_t ret;

    ret = pfe_class_get_feature(feature_mgr.class, fw_feature_class, feature_name);

    /* Analyze Class */
    if (EOK == ret)
    {
        /* Descriptor in class is available */

        if (TRUE == pfe_fw_feature_is_in_class(*fw_feature_class))
        {
            /* This feature is applicable for class */

            if (pfe_fw_feature_enabled(*fw_feature_class))
            {
                /* Feature is enabled thus it is available */
                mgr_state->class_avail = TRUE;
            }
            else
            {
                /* Feature is disabled thus it is not available */
                mgr_state->class_avail = FALSE;
            }
        }
        else
        {
            /* Not applicable for class */
            /* Do not block availability of the feature which is not applicable */
            mgr_state->class_avail = TRUE;
        }
    }

    return ret;
}

/**
 * @brief       Checks whether the feature requires util to be present
 * @param[in]   fw_feature_class class information
 * @param[in]   mgr_state Class/Util feature state
 */
static void pfe_feature_mgr_is_feature_present(pfe_fw_feature_t *fw_feature_class, pfe_feature_mgr_state_info_t *mgr_state)
{
    /* Use class information to check whether the feature requires util to be present */
    if (pfe_fw_feature_is_in_util(fw_feature_class))
    {
        /* No firmware = no feature */
        mgr_state->util_avail = FALSE;
    }
    else
    {
        /* Feature does not need util to be present */
        mgr_state->util_avail = TRUE;
    }
}

/**
 * @brief       Checks whether the firmware feature with given name is available to be used
 * @param[in]   name Name of the feature to check
 * @retval      TRUE Feature is available
 * @retval      FALSE Feature is not available
 * @details     It is checked whether the feature is applicable for hw, class and then
 *              it is checked whether it is enabled at all places it is applicable for.
 */
bool_t pfe_feature_mgr_is_available(const char *feature_name)
{
    pfe_hw_feature_t *hw_feature = NULL;
    pfe_fw_feature_t *fw_feature_class = NULL;
    pfe_feature_mgr_state_info_t mgr_state;
    errno_t           ret_class;
    bool_t            is_avail = FALSE;
    errno_t           ret_hw;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_avail = FALSE;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            is_avail = FALSE;
        }
        else
        {
            (void)autolibc_memset(&mgr_state, 0, sizeof(pfe_feature_mgr_state_info_t));
            ret_hw = pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name);
            if (EOK == ret_hw)
            {
                /* Descriptor in platform is available */
                if (pfe_hw_feature_enabled(hw_feature))
                {
                    /* Feature is enabled thus it is available */
                    is_avail = TRUE;
                }
                else
                {
                    /* Feature is disabled thus it is not available */
                    is_avail = FALSE;
                }
            }
            else
            {
                if (NULL == feature_mgr.class)
                {
                    /* Class block is not initialized */
                    is_avail = FALSE;
                }
                else
                {
                    ret_class = pfe_feature_mgr_is_class_available(feature_name, &fw_feature_class, &mgr_state);
                    if (EOK == ret_class)
                    {
                        /* Check whether the feature requires UTIL to be present */
                        pfe_feature_mgr_is_feature_present(fw_feature_class, &mgr_state);
                        /* is_avail is set when the feature is CLASS available and does not require UTIL to be present */
                        is_avail = ((FALSE != mgr_state.class_avail) && (FALSE != mgr_state.util_avail)) ? TRUE : FALSE;
                    }                    
                }
            }
        }
    }

    return is_avail;
}

/**
 * @brief  Set value for class and util feature
 * @param[in] fw_feature_class Name of the class feature to be set
 * @param[in] fw_feature_util Name of the util feature to be set
 * @param[in] val Value to be set
 * @return EOK or failure code.
 */
static errno_t pfe_feature_mgr_set_val_class_util(pfe_fw_feature_t *fw_feature_class, pfe_fw_feature_t *fw_feature_util, const uint8 val)
{
    errno_t ret = EOK;
    uint8 old_val = 0U;

    /* Handle the Class */
    if (TRUE == pfe_fw_feature_is_in_class(fw_feature_class))
    {
        /* Backup the original value for the failure case */
        (void)pfe_fw_feature_get_val(fw_feature_class, &old_val);
        /* Set the new value */
        ret = pfe_fw_feature_set_val(fw_feature_class, val);
    }

    /* Handle the Util */
    if (NULL != fw_feature_util)
    { /* Util is present */
        /* Continue only if the previous code succeeded - we need to
        keep the class and util coherent */
        if (EOK == ret)
        {
            if (TRUE == pfe_fw_feature_is_in_util(fw_feature_util))
            {
                ret = pfe_fw_feature_set_val(fw_feature_util, val);
                if (EOK != ret)
                { /* Failure */
                    /* Revert the changes already made */
                    (void)pfe_fw_feature_set_val(fw_feature_util, old_val);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief  Handle class and util feature
 * @param[in] fmgr The feature_mgr instance
 * @param[in] feature_name Name of the feature to be set
 * @param[in] val Value to be set
 * @return EOK or failure code.
 */
static errno_t pfe_feature_mgr_handle_feature(const pfe_feature_mgr_t *fmgr, const char *feature_name, const uint8 val)
{
    errno_t          ret = EOK;
    pfe_fw_feature_t *fw_feature_class = NULL;
    pfe_fw_feature_t *fw_feature_util = NULL;
    errno_t           ret_class, ret_util;

    ret_class = pfe_class_get_feature(fmgr->class, &fw_feature_class, feature_name);
    if (EOK != ret_class)
    { /* Feature does not exist or data is inconsistent */
        ret = EINVAL;
    }
    else
    {
        if (NULL != fmgr->util)
        {
            ret_util = pfe_util_get_feature(fmgr->util, &fw_feature_util, feature_name);
            if (EOK != ret_util)
            { /* Feature does not exist or data is inconsistent */
                ret = EINVAL;
            }
        }

        if (EOK == ret)
        {
            ret = pfe_feature_mgr_set_val_class_util(fw_feature_class, fw_feature_util, val);
            /* Check/configure driver (if needed) */
            if (EOK == ret)
            {
                ret = pfe_feature_mgr_configure_driver(feature_name, val);
            }
        }
    }

    return ret;
}

/**
 * @brief Sets the value of the feature enable variable
 * @param[in] feature_name Name of the feature to be set
 * @param[in] val Value to be set
 * @return EOK or failure code.
 */
errno_t pfe_feature_mgr_set_val(const char *feature_name, const uint8 val)
{
    pfe_hw_feature_t *hw_feature;
    pfe_ct_feature_flags_t flags = F_NONE;
    errno_t           ret_feature;
    errno_t           ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {
            ret_feature = pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name);
            if (EOK == ret_feature)
            { /* Feature exists */
                ret = pfe_hw_feature_get_flags(hw_feature, &flags);
                if (0U != ((uint8)flags & (uint8)F_RUNTIME))
                {
                    ret = pfe_hw_feature_set_val(hw_feature, val);
                }
                else
                {
                    ret = EFAULT;
                }
            }
            else
            {
                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {
                    ret = pfe_feature_mgr_handle_feature(&feature_mgr, feature_name, val);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Enables the given hw feature
 * @param[in]   feature_name Feature to enable
 * @retval      EOK the feature is enabled
 * @return      Failure code means the feature could not be enabled
 */
static errno_t pfe_feature_mgr_enable_hw_feature(const char *feature_name)
{
    errno_t             ret = EINVAL;
    errno_t             ret_val;
    pfe_hw_feature_t *  hw_feature;
    pfe_ct_feature_flags_t tmp;

    /* HW feature first */
    ret_val = pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name);
    if (EOK == ret_val)
    {
        ret_val = pfe_hw_feature_get_flags(hw_feature, &tmp);
        if (EOK == ret_val)
        {
            if (0U == ((uint8)tmp & (uint8)F_PRESENT))
            { /* Feature cannot be enabled */
                NXP_LOG_WARNING("Cannot enable feature %s - not present in Platform\n", feature_name);
                ret = EINVAL;
            }
            else if (0U == ((uint8)tmp & (uint8)F_RUNTIME))
            { /* Feature cannot be disabled */
                NXP_LOG_INFO("Feature %s is always enabled in Platform\n", feature_name);
                ret = EOK;
            }
            else
            { /* Feature needs to be enabled */
                ret = pfe_feature_mgr_set_val(feature_name, 1);
            }
        }
        /* Don't continue with FW features */
    }

    return ret;
}

/**
 * @brief       Enables the given class feature
 * @param[in]   feature_name Feature to enable
 * @retval      EOK the feature is enabled
 * @return      Failure code means the feature could not be enabled
 */
static errno_t pfe_feature_mgr_enable_class_feature(const char *feature_name)
{
    errno_t              ret = EINVAL;
    errno_t              ret_val;
    pfe_fw_feature_t *   fw_feature_class;
    pfe_ct_feature_flags_t tmp;

    /* Class and util share the same information thus it is enough to use just the class to get it */
    ret_val = pfe_class_get_feature(feature_mgr.class, &fw_feature_class, feature_name);
    if (EOK == ret_val)
    {
        ret_val = pfe_fw_feature_get_flags(fw_feature_class, &tmp);
        if (EOK == ret_val)
        {
            if (0U == ((uint8)tmp & (uint8)F_PRESENT))
            { /* Feature cannot be enabled */
                NXP_LOG_INFO("Cannot enable feature %s - not present in FW\n", feature_name);
                ret = EINVAL;
            }
            else if (0U == ((uint8)tmp & (uint8)F_RUNTIME))
            { /* Feature cannot be disabled */
                NXP_LOG_ERROR("Feature %s is always enabled in FW\n", feature_name);
                ret = EOK;
            }
            else
            { /* Feature needs to be enabled */
                ret = pfe_feature_mgr_set_val(feature_name, 1);
            }
        }
    }

    return ret;
}

/**
 * @brief       Enables the given feature
 * @param[in]   feature_name Feature to enabled
 * @retval      EOK the feature is enabled
 * @return      Failure code means the feature could not be enabled
 */
errno_t pfe_feature_mgr_enable(const char *feature_name)
{
    errno_t                ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {

            ret = pfe_feature_mgr_enable_hw_feature(feature_name);
            if(EOK != ret)
            {
                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {
                    ret = pfe_feature_mgr_enable_class_feature(feature_name);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Disables the given hw feature
 * @param[in]   feature_name Feature to disable
 * @retval      EOK the feature is disabled
 * @return      Failure code means the feature could not be disabled
 */
static errno_t pfe_feature_mgr_disable_hw_feature(const char *feature_name)
{
    errno_t             ret = EINVAL;
    errno_t             ret_val;
    pfe_hw_feature_t *  hw_feature;
    pfe_ct_feature_flags_t tmp;

    /* HW feature first */
    ret_val = pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name);
    if (EOK == ret_val)
    {
        ret_val = pfe_hw_feature_get_flags(hw_feature, &tmp);
        if (EOK == ret_val)
        {
            if (0U == ((uint8)tmp & (uint8)F_PRESENT))
            { /* Feature cannot be enabled */
                NXP_LOG_INFO("Feature %s is always disabled in Platform\n", feature_name);
                ret = EOK;
            }
            else if (0U == ((uint8)tmp & (uint8)F_RUNTIME))
            { /* Feature cannot be disabled */
                NXP_LOG_ERROR("Cannot disabled feature %s - always enabled in Platform\n", feature_name);
                ret = EINVAL;
            }
            else
            { /* Feature needs to be disabled */
                ret = pfe_feature_mgr_set_val(feature_name, 0);
            }
        }

        /* Don't continue with FW features */
    }

    return ret;
}

/**
 * @brief       Disables the given class feature
 * @param[in]   feature_name Feature to disable
 * @retval      EOK the feature is disabled
 * @return      Failure code means the feature could not be disabled
 */
static errno_t pfe_feature_mgr_disable_class_feature(const char *feature_name)
{
    errno_t              ret = EINVAL;
    errno_t              ret_val;
    pfe_fw_feature_t    *fw_feature_class;
    pfe_ct_feature_flags_t tmp;

    /* Class and util share the same information thus it is enough to use just the class to get it */
    ret_val = pfe_class_get_feature(feature_mgr.class, &fw_feature_class, feature_name);
    if (EOK == ret_val)
    {
        ret_val = pfe_fw_feature_get_flags(fw_feature_class, &tmp);
        if (EOK == ret_val)
        {
            if (0U == ((uint8)tmp & (uint8)F_PRESENT))
            { /* Feature cannot be enabled */
                NXP_LOG_INFO("Feature %s is always disabled in FW\n", feature_name);
                ret = EOK;
            }
            else if (0U == ((uint8)tmp & (uint8)F_RUNTIME))
            { /* Feature cannot be disabled */
                NXP_LOG_ERROR("Cannot disabled feature %s - always enabled in FW\n", feature_name);
                ret = EINVAL;
            }
            else
            { /* Feature needs to be disabled */
                ret = pfe_feature_mgr_set_val(feature_name, 0);
            }
        }
    }

    return ret;
}

/**
 * @brief       Disables the given feature
 * @param[in]   feature_name Feature to disable
 * @retval      EOK the feature is disabled
 * @return      Failure code means the feature could not be disabled
 */
errno_t pfe_feature_mgr_disable(const char *feature_name)
{
    errno_t                ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {

            ret = pfe_feature_mgr_disable_hw_feature(feature_name);
            if(EOK != ret)
            {
                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {

                    ret = pfe_feature_mgr_disable_class_feature(feature_name);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Reads the class/util feature value
 * @param[in]   feature_name Name of the feature to be read
 * @param[out]  val The read value of the feature enable variable
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_get_val_class_util(const char *feature_name, uint8 **val)
{
    errno_t             ret = EOK;
    pfe_fw_feature_t    *fw_feature_util = NULL;
    pfe_fw_feature_t    *fw_feature_class;
    errno_t             ret_val;

    ret_val = pfe_class_get_feature(feature_mgr.class, &fw_feature_class, feature_name);
    if (EOK != ret_val)
    { /* Feature does not exist or data is inconsistent */
        ret = EINVAL;
    }
    else
    {

        if (NULL != feature_mgr.util)
        {
            ret_val = pfe_util_get_feature(feature_mgr.util, &fw_feature_util, feature_name);
            if (EOK != ret_val)
            { /* Data is inconsistent - feature found in class but not in util */
                    NXP_LOG_WARNING("Inconsistent feature data for %s\n", feature_name);
                    ret = EINVAL;
                }
        }

        if (EOK == ret)
        {
            /* Check the value in class if relates to class */
            if (TRUE == pfe_fw_feature_is_in_class(fw_feature_class))
            {
                ret = pfe_fw_feature_get_val(fw_feature_class, *val);
                /* We can stop here because data shall be consistent between class and util
                thus it does not matter which value is read */
            }
            else
            {
                /* This is for features related to util only (code above will not read the value)*/
                if (NULL != feature_mgr.util)
                { /* Util is available */
                    /* Check the value in util if relates to util */
                    if (TRUE == pfe_fw_feature_is_in_util(fw_feature_util))
                    {
                        ret = pfe_fw_feature_get_val(fw_feature_util, *val);
                    }
                    else
                    {
                        /* We can get here only if feature is not present in class nor util */
                        NXP_LOG_WARNING("Wrong feature %s (not relevant to any FW)\n", feature_name);
                    }
                }
                else
                {
                    /* We can get here only if feature is not present in class nor util */
                    NXP_LOG_WARNING("Wrong feature %s (not relevant to any FW)\n", feature_name);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Reads the feature value
 * @param[in]   feature_name Name of the feature to be read
 * @param[out]  val The read value of the feature enable variable
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_get_val(const char *feature_name, uint8 *val)
{
    pfe_hw_feature_t *hw_feature;
    errno_t           ret_feature;
    errno_t           ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL == feature_name) || (NULL == val))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {

            ret_feature = pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name);
            if (EOK == ret_feature)
            { /* Feature exist */
                ret = pfe_hw_feature_get_val(hw_feature, val);
            }
            else
            {

                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {
                    ret = pfe_feature_mgr_get_val_class_util(feature_name, &val);

                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the 1st feature (resets the features query)
 * @param[out]  feature_name Name of the 1st feature
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_get_first(const char **feature_name)
{
    pfe_hw_feature_t *hw_feature;
    pfe_fw_feature_t *fw_feature;
    errno_t           ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {

            /* HW feature first */
            ret = pfe_hw_get_feature_first(&feature_mgr, &hw_feature);
            if (EOK == ret)
            {
                ret = pfe_hw_feature_get_name(hw_feature, feature_name);
                /* Signal rewind_flg for class/util fw feature walk */
                feature_mgr.rewind_flg = TRUE;
            }
            else
            {
                /* We use the fact that class and util share same list of features and read
           from only one of them */

                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {
                    ret = pfe_class_get_feature_first(feature_mgr.class, &fw_feature);
                    if (EOK == ret)
                    {
                        ret = pfe_fw_feature_get_name(fw_feature, feature_name);
                    }
                    feature_mgr.rewind_flg = FALSE;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the next feature (continues the features query)
 * @param[out]  feature_name Name of the next feature
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_get_next(const char **feature_name)
{
    pfe_hw_feature_t *hw_feature;
    pfe_fw_feature_t *fw_feature;
    errno_t           ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {

            /* HW feature first */
            ret = pfe_hw_get_feature_next(&feature_mgr, &hw_feature);
            if (EOK == ret)
            {
                ret = pfe_hw_feature_get_name(hw_feature, feature_name);
            }
            else if (ENOENT == ret)
            {
                /* We use the fact that class and util share same list of features and read
           from only one of them */

                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {

                    if (TRUE == feature_mgr.rewind_flg)
                    {
                        ret = pfe_class_get_feature_first(feature_mgr.class, &fw_feature);
                        /* Unset 'rewind_flg' to use real pfe_class_get_feature_next next time */
                        feature_mgr.rewind_flg = FALSE;
                    }
                    else
                    {
                        ret = pfe_class_get_feature_next(feature_mgr.class, &fw_feature);
                    }

                    if (EOK == ret)
                    {
                        ret = pfe_fw_feature_get_name(fw_feature, feature_name);
                    }
                }
            }
            else
            {
                ; /* No action required */
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the feature default value
 * @param[in]   feature_name Name of the feature
 * @param[out]  val Default (initial) value of feature enable variable
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_get_def_val(const char *feature_name, uint8 *val)
{
    pfe_hw_feature_t *hw_feature;
    pfe_fw_feature_t *fw_feature_class;
    errno_t           ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {
            /* HW feature first */
            if (EOK == pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name))
            {
                ret = pfe_hw_feature_get_def_val(hw_feature, val);
            }
            else
            {

                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {
                    /* The data shall be consistent between util and class thus it is enough to read them from class */

                    ret = pfe_class_get_feature(feature_mgr.class, &fw_feature_class, feature_name);
                    if (EOK == ret)
                    {
                        ret = pfe_fw_feature_get_def_val(fw_feature_class, val);
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the feature default description text
 * @param[in]   feature_name Name of the feature
 * @param[out]  desc Feature description text (string)
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_get_desc(const char *feature_name, const char **desc)
{
    pfe_hw_feature_t *hw_feature;
    pfe_fw_feature_t *fw_feature_class;
    errno_t           ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL == desc) || (NULL == feature_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {
            /* Platfoorm feature first */
            if (EOK == pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name))
            {
                ret = pfe_hw_feature_get_desc(hw_feature, desc);
            }
            else
            {
                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {
                    /* The data shall be consistent between util and class thus it is enough to read
                    them from class */
                    ret = pfe_class_get_feature(feature_mgr.class, &fw_feature_class, feature_name);
                    if (EOK == ret)
                    {
                        ret = pfe_fw_feature_get_desc(fw_feature_class, desc);
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the feature variant
 * @param[in]   feature_name Name of the feature
 * @param[out]  val Value of the flags defining feature variant
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_get_variant(const char *feature_name, uint8 *val)
{
    pfe_hw_feature_t *     hw_feature;
    pfe_fw_feature_t *     fw_feature_class;
    errno_t                ret;
    pfe_ct_feature_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL == feature_name) || (NULL == val))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0U == feature_mgr.hw_features_count)
        {
            NXP_LOG_ERROR("Feature Mgr not initialized\n");
            ret = EINVAL;
        }
        else
        {
            /* HW feature first */
            if (EOK == pfe_hw_get_feature(&feature_mgr, &hw_feature, feature_name))
            {
                ret = pfe_hw_feature_get_flags(hw_feature, &tmp);
                if (EOK == ret)
                {
                    *val = (uint8)tmp & ((uint8)F_PRESENT | (uint8)F_RUNTIME);
                }
            }
            else
            {
                if (NULL == feature_mgr.class)
                { /* Class block is not initialized */
                    ret = EINVAL;
                }
                else
                {
                    /* The data shall be consistent between util and class thus it is enough to read
                    them from class */
                    ret = pfe_class_get_feature(feature_mgr.class, &fw_feature_class, feature_name);
                    if (EOK == ret)
                    {
                        ret = pfe_fw_feature_get_flags(fw_feature_class, &tmp);
                        if (EOK == ret)
                        {
                            *val = (uint8)tmp & ((uint8)F_PRESENT | (uint8)F_RUNTIME);
                        }
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief Finds and returns HW feature by its name
 * @param[in] fmgr The feature_mgr instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @param[in] name Name of the feature to be found
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
static errno_t pfe_hw_get_feature(pfe_feature_mgr_t *fmgr, pfe_hw_feature_t **feature, const char *name)
{
    uint32    i;
    const char *fname;
    errno_t     ret = ENOENT;
    errno_t     ret_val = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == fmgr) || (NULL == feature) || (NULL == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (i = 0U; i < fmgr->hw_features_count; i++)
        {
            ret_val = pfe_hw_feature_get_name(&fmgr->hw_features[i], &fname);
            if (ret_val == EOK)
            {
                if (0 == autolibc_strcmp(fname, name))
                {
                    *feature = &fmgr->hw_features[i];
                    ret = EOK;
                    break;
                }
            }
        }
    }
    return ret;
}

/**
 * @brief Finds and returns the 1st HW feature by order of their discovery - used for listing all features
 * @param[in] fmgr The feature mgr instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
static errno_t pfe_hw_get_feature_first(pfe_feature_mgr_t *fmgr, pfe_hw_feature_t **feature)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == fmgr) || (NULL == feature)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (fmgr->hw_features_count > 0U)
        {
            fmgr->current_hw_feature = 0U;
            *feature = &fmgr->hw_features[fmgr->current_hw_feature];
            ret = EOK;
        }
        else
        {
            ret = ENOENT;
        }
    }

    return ret;
}

/**
 * @brief Finds and returns the next HW feature by order of their discovery - used for listing all features
 * @param[in] fmgr The feature_mgr instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
static errno_t pfe_hw_get_feature_next(pfe_feature_mgr_t *fmgr, pfe_hw_feature_t **feature)
{
    errno_t ret = ENOENT;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == fmgr) || (NULL == feature)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (fmgr->hw_features_count > 0U)
        {
            /* Avoid going out of the array boundaries */
            if ((fmgr->current_hw_feature + 1U) < fmgr->hw_features_count)
            {
                fmgr->current_hw_feature += 1U;
                *feature = &fmgr->hw_features[fmgr->current_hw_feature];
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
 * @brief Executes driver-side checks and configurations (if some are needed) in response to FW feature being enabled/disabled.
 * @param[in] feature_name Name of the feature to be set
 * @param[in] val Enable/disable value of the FW feture which was freshly set.
 * @return EOK or failure code.
 */
static errno_t pfe_feature_mgr_configure_driver(const char *feature_name, const uint8 val)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == feature_name)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if (0 == autolibc_strcmp(feature_name, "err051211_workaround"))
        {
            if (0U != val) /* feature got enabled */
            {
                ret = pfe_tmu_queue_err051211_sync(feature_mgr.tmu);
            }
        }
    }
    return ret;
}

static errno_t pfe_feature_mgr_table_parent_inst(const char *feature_name, pfe_fw_feature_t **feature)
{
    errno_t ret = EOK;
    bool_t class_parrent = TRUE;
    const char *pFeatureNameTemp = feature_name;

    if((feature_name[0] == 'u') && (feature_name[1] == '_'))
    {
        pFeatureNameTemp = &pFeatureNameTemp[2];
        class_parrent = FALSE;
    }

    if(TRUE == class_parrent)
    {
        if (NULL == feature_mgr.class)
        { /* Class block is not initialized */
            ret = EINVAL;
        }
        else
        {
            ret = pfe_class_get_feature(feature_mgr.class, feature, pFeatureNameTemp);
        }
    }
    else
    {
        if (NULL == feature_mgr.util)
        { /* Class block is not initialized */
            ret = EINVAL;
        }
        else
        {
            ret = pfe_util_get_feature(feature_mgr.util, feature, pFeatureNameTemp);
        }
    }

    return ret;
}

#if defined(PFE_CFG_NULL_ARG_CHECK)
/* Check parameters for NULL */
static errno_t table_set_val_null_check(const char *feature_name, const char *table_el_name, uint8* val)
{
    errno_t ret = EOK;
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == val))
    {
        ret = EINVAL;
    }
    
    return ret;
}
#endif


/**
 * @brief       Sets a value in the provided feature table element
 * @param[in]   feature_name Name of the feature to set the value
 * @param[in]   table_type In witch table the element is looked for
 * @param[in]   table_el_name Name of the table element to set the value
 * @param[in]   index Index of the value in the table
                index=0 means set the value on all table described by elemnt
                index > 0 means to set the value at a specific index witch
                start from 1.
 * @param[in]   val Value to be set
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_table_set_val(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 index, uint8* val)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_entry;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (EOK != table_set_val_null_check(feature_name, table_el_name, val))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            switch (table_type)
            {
                case FW_FEATURE_TABLE_DEFAULT:
                    ret = pfe_fw_feature_table_cfg_by_name(fw_feature, table_el_name, &fw_feature_table_entry);
                    if (ENOENT == ret)
                    {
                        ret = pfe_fw_feature_table_stats_by_name(fw_feature, table_el_name, &fw_feature_table_entry);
                    }
                    break;
                case FW_FEATURE_TABLE_CONFIG:
                    ret = pfe_fw_feature_table_cfg_by_name(fw_feature, table_el_name, &fw_feature_table_entry);
                    break;
                case FW_FEATURE_TABLE_STATS:
                    ret = pfe_fw_feature_table_stats_by_name(fw_feature, table_el_name, &fw_feature_table_entry);
                    break;
                default:
                    ret = EINVAL;
                    break;
            }

            if (EOK == ret)
            {
                if (index == 0)
                {
                    const uint32 mem_size = pfe_fw_feature_table_entry_allocsize(fw_feature_table_entry);
                    /* mem_size is limited to U16 by pfe_fw_feature_table_entry_allocsize */
                    ret = pfe_fw_feature_table_entry_set(fw_feature_table_entry, (void *) val, (uint16)(mem_size & UINT16_MAX));
                }
                else
                {
                    ret = pfe_fw_feature_table_entry_set_by_idx(fw_feature_table_entry, (void *) val, index-1);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief    Returns the 1st feature table stats element
 *            (resets the features table stts element query)
 * @param[in]    feature_name Name of the feature to be set.
 * @param[out]    Name of the 1st element.
 * @return        EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_stats_first(const char *feature_name, const char **table_el_name)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t    fw_feature_table_stats;
    errno_t                ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    { 
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_stats_first(fw_feature, &fw_feature_table_stats);
            if (EOK == ret)
            {
                ret = pfe_fw_feature_table_entry_name(fw_feature_table_stats, table_el_name);
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the next feature element in stats table
 *              (continues the features table stats query)
 * @param[in]   feature_name Name of the feature to be set
 * @param[out]  Name of the next element.
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_stats_next(const char *feature_name, const char **table_el_name)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_stats;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_stats_next(fw_feature, &fw_feature_table_stats);
            if (EOK == ret)
            {
                ret = pfe_fw_feature_table_entry_name(fw_feature_table_stats, table_el_name);
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the 1st feature table config element 
 *              (resets the features table config element query)
 * @param[in]   feature_name Name of the feature to be set.
 * @param[out]  Name of the 1st element.
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_cfg_first(const char *feature_name, const char **table_el_name)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_cfg;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_cfg_first(fw_feature, &fw_feature_table_cfg);
            if (EOK == ret)
            {
                ret = pfe_fw_feature_table_entry_name(fw_feature_table_cfg, table_el_name);
            }
        }
    }

    return ret;
}

/**
 * @brief       Returns the next feature element in config table 
 *              (continues the features table config query)
 * @param[in]   feature_name Name of the feature to be set
 * @param[out]  Name of the next element.
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_cfg_next(const char *feature_name, const char **table_el_name)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_cfg;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_cfg_next(fw_feature, &fw_feature_table_cfg);
            if (EOK == ret)
            {
                ret = pfe_fw_feature_table_entry_name(fw_feature_table_cfg, table_el_name);
            }
        }
     }

    return ret;
}

/**
 * @brief       Returns the 1st feature table element (resets the features table element query)
 * @param[in]   feature_name Name of the feature to be set
 * @param[in]   table_type In witch table the element is looked for
 * @param[out]  Name of the 1st element
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_table_first(const char *feature_name, pfe_table_type_t table_type, const char **table_el_name)
{
    errno_t ret = EOK;

    switch(table_type)
    {
        case FW_FEATURE_TABLE_DEFAULT:
            ret = pfe_feature_mgr_table_cfg_first(feature_name, table_el_name);
            table_rewind_flag = TRUE;
            if (EOK != ret)
            {
                ret = pfe_feature_mgr_table_stats_first(feature_name, table_el_name);
                table_rewind_flag = FALSE;
            }
            break;
        case FW_FEATURE_TABLE_CONFIG:
            ret = pfe_feature_mgr_table_cfg_first(feature_name, table_el_name);
            break;
        case FW_FEATURE_TABLE_STATS:
            ret = pfe_feature_mgr_table_stats_first(feature_name, table_el_name);
            break;
        default:
            ret = EINVAL;
            break;
    }

    return ret;
}

/**
 * @brief       Returns the next feature element (continues the features element query)
 * @param[in]   feature_name Name of the feature to be set
 * @param[in]   table_type In witch table the element is looked for
 * @param[out]  feature table name of the next element
 * @return      EOK or failure code.
 */

errno_t pfe_feature_mgr_table_next(const char *feature_name, pfe_table_type_t table_type, const char **table_el_name)
{
    errno_t ret = EOK;

    switch(table_type)
    {
        case FW_FEATURE_TABLE_DEFAULT:
            ret = pfe_feature_mgr_table_cfg_next(feature_name, table_el_name);
            if (ENOENT == ret)
            {
                if (TRUE == table_rewind_flag)
                {
                    ret = pfe_feature_mgr_table_stats_first(feature_name, table_el_name);
                    table_rewind_flag = FALSE;
                }
                else
                {
                    ret = pfe_feature_mgr_table_stats_next(feature_name, table_el_name);
                }
            }
            break;
        case FW_FEATURE_TABLE_CONFIG:
            ret = pfe_feature_mgr_table_cfg_next(feature_name, table_el_name);
            break;
        case FW_FEATURE_TABLE_STATS:
            ret = pfe_feature_mgr_table_stats_next(feature_name, table_el_name);
            break;
        default:
            ret = EINVAL;
            break;
    }

    return ret;
}

/**
 * @brief       Reads the config table element size
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[out]  count The read value of the table element size
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_cfg_get_size(const char *feature_name, const char *table_el_name, uint8 *size)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t    fw_feature_table_cfg;
    errno_t                ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == size))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_cfg_by_name(fw_feature, table_el_name, &fw_feature_table_cfg);
            if (EOK == ret)
            {
                /* pfe_fw_feature_table_entry_size output is limited to U8 */
                *size = (uint8)(pfe_fw_feature_table_entry_size(fw_feature_table_cfg) & UINT8_MAX);
            }
        }
    }
    return ret;
}

/**
 * @brief       Reads the config table element multiplicity
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[out]  count The read value of the table element multiplicity
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_cfg_get_multiplicity(const char *feature_name, const char *table_el_name, uint8 *count)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_cfg;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == count))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_cfg_by_name(fw_feature, table_el_name, &fw_feature_table_cfg);
            if (EOK == ret)
            {
                const uint32 multiplicity = pfe_fw_feature_table_entry_multiplicity(fw_feature_table_cfg);
                /* multiplicity is limited by pfe_fw_feature_table_entry_multiplicity to U8 */
                *count = (uint8)(multiplicity & UINT8_MAX);
            }
        }
    }
    return ret;
}

/**
 * @brief       Reads the config table element payload
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[out]  payload The read value of the table element payload
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_cfg_get_payload(const char *feature_name, const char *table_el_name, uint8 *payload)
{

    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_cfg;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == payload))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_cfg_by_name(fw_feature, table_el_name, &fw_feature_table_cfg);
            if (EOK == ret)
            {
                const uint32 mem_size = pfe_fw_feature_table_entry_allocsize(fw_feature_table_cfg);
                /* mem_size is limited to U16 by pfe_fw_feature_table_entry_allocsize */
                (void)pfe_fw_feature_table_entry_get(fw_feature_table_cfg, payload, (uint16)(mem_size & UINT16_MAX), FALSE);
            }
        }
    }
     return ret;
}

/**
 * @brief       Reads the stats table element size
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[out]  size The read value of the table element size
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_stats_get_size(const char *feature_name, const char *table_el_name, uint8 *size)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_stats;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == size))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_stats_by_name(fw_feature, table_el_name, &fw_feature_table_stats);
            if (EOK == ret)
            {
                /* pfe_fw_feature_table_entry_size output is limited to U8 */
                *size = (uint8)(pfe_fw_feature_table_entry_size(fw_feature_table_stats) & UINT8_MAX);                
            }
        }
    }
    return ret;
}

/**
 * @brief       Reads the stats table element multiplicity
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[out]  count The read value of the table element multiplicity
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_stats_get_multiplicity(const char *feature_name, const char *table_el_name, uint8 *count)
{
    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_stats;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == count))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_stats_by_name(fw_feature, table_el_name, &fw_feature_table_stats);
            if (EOK == ret)
            {
                const uint32 multiplicity = pfe_fw_feature_table_entry_multiplicity(fw_feature_table_stats);
                /* multiplicity is limited by pfe_fw_feature_table_entry_multiplicity to U8 */
                *count = (uint8)(multiplicity & UINT8_MAX);
            }
        }
    }
    return ret;
}

/**
 * @brief       Reads the stats table element payload
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[out]  payload The read value of the table element payload
 * @return      EOK or failure code.
 */
static errno_t pfe_feature_mgr_table_stats_get_payload(const char *feature_name, const char *table_el_name, uint8 *payload)
{

    pfe_fw_feature_t    *fw_feature;
    pfe_fw_tbl_handle_t fw_feature_table_stats;
    errno_t             ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == payload))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = pfe_feature_mgr_table_parent_inst(feature_name, &fw_feature);
        if (EOK == ret)
        {
            ret = pfe_fw_feature_table_stats_by_name(fw_feature, table_el_name, &fw_feature_table_stats);
            if (EOK == ret)
            {
                const uint32 mem_size = pfe_fw_feature_table_entry_allocsize(fw_feature_table_stats);
                /* mem_size is limited to U16 by pfe_fw_feature_table_entry_allocsize */
                (void)pfe_fw_feature_table_entry_get(fw_feature_table_stats, payload, (uint16)(mem_size & UINT16_MAX), TRUE);
            }
        }
    }
    return ret;
}

/**
 * @brief       Reads the table element size
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[in]   table_type In witch table the element is looked for
 * @param[out]  size The read value of the table element size
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_table_get_size(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 *size)
{
    errno_t ret = EOK;
    
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == size))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        switch(table_type)
        {
            case FW_FEATURE_TABLE_DEFAULT:
                ret = pfe_feature_mgr_table_cfg_get_size(feature_name, table_el_name, size);
                if (EOK != ret)
                {
                    ret = pfe_feature_mgr_table_stats_get_size(feature_name, table_el_name, size);
                }
                break;
            case FW_FEATURE_TABLE_CONFIG:
                ret = pfe_feature_mgr_table_cfg_get_size(feature_name, table_el_name, size);
                break;
            case FW_FEATURE_TABLE_STATS:
                ret = pfe_feature_mgr_table_stats_get_size(feature_name, table_el_name, size);
                break;
            default:
                ret = EINVAL;
                break;
        }
    }
    return ret;
}

/**
 * @brief       Reads the table element multiplicity
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[in]   table_type In witch table the element is looked for
 * @param[out]  count The read value of the table element multiplicity
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_table_get_multiplicity(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 *count)
{
    errno_t ret = EOK;
    
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == count))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        switch(table_type)
        {
            case FW_FEATURE_TABLE_DEFAULT:
                ret = pfe_feature_mgr_table_cfg_get_multiplicity(feature_name, table_el_name, count);
                if (EOK != ret)
                {
                    ret = pfe_feature_mgr_table_stats_get_multiplicity(feature_name, table_el_name, count);
                }
                break;
            case FW_FEATURE_TABLE_CONFIG:
                ret = pfe_feature_mgr_table_cfg_get_multiplicity(feature_name, table_el_name, count);
                break;
            case FW_FEATURE_TABLE_STATS:
                ret = pfe_feature_mgr_table_stats_get_multiplicity(feature_name, table_el_name, count);
                break;
            default:
                ret = EINVAL;
                break;
        }
    }
    return ret;
}

/**
 * @brief       Reads the table element payload
 * @param[in]   feature_name Name of the feature to be read
 * @param[in]   table_el_name Name of the table element to be read
 * @param[in]   table_type In witch table the element is looked for
 * @param[out]  payload The read value of the table element payload
 * @return      EOK or failure code.
 */
errno_t pfe_feature_mgr_table_get_payload(const char *feature_name, pfe_table_type_t table_type, const char *table_el_name, uint8 *payload)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == feature_name) || (NULL_PTR == table_el_name) || (NULL_PTR == payload))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        switch(table_type)
        {
            /*load the selected table*/
            case FW_FEATURE_TABLE_DEFAULT:
                ret = pfe_feature_mgr_table_cfg_get_payload(feature_name, table_el_name, payload);
                if (EOK != ret)
                {
                    ret = pfe_feature_mgr_table_stats_get_payload(feature_name, table_el_name, payload);
                }
                break;
            case FW_FEATURE_TABLE_CONFIG:
                ret = pfe_feature_mgr_table_cfg_get_payload(feature_name, table_el_name, payload);
                break;
            case FW_FEATURE_TABLE_STATS:
                ret = pfe_feature_mgr_table_stats_get_payload(feature_name, table_el_name, payload);
                break;
            default:
                ret = EINVAL;
                break;
        }
    }
    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [146/185]: src\pfe_fp.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "pfe_class.h"
#include "pfe_fp.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================*/
/**
* @brief Initializes the module
*/
/* Magic function - QNX runtime linker fails to find the rest of the functions if this
   one is not called from somewhere in the pfe_platform */
void pfe_fp_init(void)
{
    ;
}

/*==================================================================================================*/
/**
* @brief Creates the flexible parser table
* @param[in] class Classifier to create the table
* @param[in] rules_count Number of rules in the table
* @details Allocates DMEM memory for the whole table including the rules and prepares the
*          table header. Rules must be written separately by the pfe_fp_table_write_rule()
*          function. The table is reference by the returned DMEM address.
* @return 0 on failure or the DMEM address of the table.
*/
uint32 pfe_fp_create_table(pfe_class_t *class, uint16 rules_count)
{
    addr_t addr;
    uint32 size;
    pfe_ct_fp_table_t temp;
    errno_t res;

    /* Calculate needed size */
    size = (uint32)sizeof (pfe_ct_fp_table_t) + ((uint32)rules_count * sizeof (pfe_ct_fp_rule_t));
    /* Allocate DMEM */
    addr = pfe_class_dmem_heap_alloc (class, size);
    if (0U == addr)
    {
        NXP_LOG_ERROR ("Not enough DMEM memory\n");
    }
    else
    {
        /* Write the table header */
        temp.count = rules_count;
        temp.reserved16 = 0U;
        temp.rules = oal_htonl (addr + sizeof (pfe_ct_fp_table_t));
        (void)autolibc_memset (&temp.fp_stats, 0, sizeof (pfe_ct_class_flexi_parser_stats_t));
        res = pfe_class_write_dmem (class, -1, addr, (void *)&temp, sizeof (pfe_ct_fp_table_t));
        if (EOK != res)
        {
            NXP_LOG_ERROR ("Cannot write to DMEM\n");
            pfe_class_dmem_heap_free (class, addr);
            addr = 0U;
        }
    }
    /* Return the DMEM address */
    return addr;
}

/*==================================================================================================*/
/**
* @brief Writes a rule into the flexible parser table
* @param[in] class Classifier used to create the table
* @param[in] table_address Address of the table returned by the pfe_fp_create_table()
* @param[in] rule Rule to be written into the table
* @param[in] position Position of the rule in the table. Must be less than rules_count passed into pfe_fp_create_table().
* @details Function writes the rule at specified position in the previously created table.
* @return 0 on failure otherwise the DMEM address of the rule.
*/
uint32 pfe_fp_table_write_rule(pfe_class_t *class, uint32 table_address, const pfe_ct_fp_rule_t *rule, uint16 position)
{
    pfe_ct_fp_rule_t temp;
    addr_t addr;
    errno_t res;

    /* Fill in a temporary structure - handle Endians */
    temp.data = rule->data;
    temp.mask = rule->mask;
    temp.offset = rule->offset;
    temp.next_idx = rule->next_idx;
    temp.flags = rule->flags;
    /* Calculate position in the DMEM */
    addr = (addr_t)(((uint64)table_address + sizeof(pfe_ct_fp_table_t) + (position * sizeof(pfe_ct_fp_rule_t))) & UINT32_MAX);

    /* Write into the DMEM */
    res = pfe_class_write_dmem(class, -1, addr, (void *)&temp, sizeof(pfe_ct_fp_rule_t));
    if(EOK != res)
    {
        NXP_LOG_ERROR("Cannot write to DMEM\n");
        addr = 0U;
    }
    return addr;
}

/*==================================================================================================*/
/**
* @brief Destroys the flexible parser table
* @param[in] class Classifier used to create the table
* @param[in] table_address Address returned by the pfe_fp_create_table()
*/
void pfe_fp_destroy_table(const pfe_class_t *class, uint32 table_address)
{
    /* Just free the memory */
    pfe_class_dmem_heap_free(class, table_address);
}

/*==================================================================================================*/
errno_t pfe_fp_table_get_statistics(pfe_class_t *class, uint32 pe_idx, uint32 table_address, pfe_ct_class_flexi_parser_stats_t *stats)
{
    pfe_ct_fp_table_t temp;
    errno_t res;
    addr_t addr;

    (void)autolibc_memset(&temp.fp_stats, 0, sizeof(pfe_ct_class_flexi_parser_stats_t));
    addr = table_address;
    /*read DMEM*/
    PfeDevAssert((uint32)INT32_MAX >= pe_idx);
    res = pfe_class_read_dmem(class, (sint32)pe_idx, (void *)&temp, addr, sizeof(pfe_ct_fp_table_t));
    if(EOK != res)
    {
        NXP_LOG_ERROR("Cannot read from DMEM\n");
    }
    else
    {
        (void)autolibc_memcpy(stats, &temp.fp_stats, sizeof(pfe_ct_class_flexi_parser_stats_t));
    }

    return res;
}
/*==================================================================================================*/

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [147/185]: src\pfe_fw_fail_stop.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_fw_fail_stop.h"
#include "pfe_fw_fail_stop_csr.h"

struct pfe_fw_fail_stop_tag
{
    addr_t cbus_base_va;
    addr_t fw_fail_stop_base_offset;
    addr_t fw_fail_stop_base_va;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_fw_fail_stop_t fw_fail_stop_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create new SAFETY_FW_FAIL_STOP instance
 * @details     Create and initializes SAFETY_FW_FAIL_STOP instance. New instance is always enabled.
 *              Use mask and unmask function to control interrupts.
 * @param[in]   base_va SAFETY_FW_FAIL_STOP register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Interrupt which were triggered are masked here, it is periodically unmasked again in SAFETY thread
 */
pfe_fw_fail_stop_t *pfe_fw_fail_stop_create(addr_t cbus_base_va, addr_t fw_fail_stop_base)
{
    pfe_fw_fail_stop_t *fw_fail_stop;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        fw_fail_stop = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fw_fail_stop = &fw_fail_stop_instance;
        (void)autolibc_memset(fw_fail_stop, 0, sizeof(pfe_fw_fail_stop_t));
        fw_fail_stop->cbus_base_va = cbus_base_va;
        fw_fail_stop->fw_fail_stop_base_offset = fw_fail_stop_base;
        fw_fail_stop->fw_fail_stop_base_va = ADDR_BASE_OFFSET(fw_fail_stop->cbus_base_va , fw_fail_stop->fw_fail_stop_base_offset);

        /* Unmask all interrupts */
        pfe_fw_fail_stop_cfg_irq_unmask_all(fw_fail_stop->fw_fail_stop_base_va);
    }

    return fw_fail_stop;
}

/**
 * @brief       Destroy SAFETY_FW_FAIL_STOP instance
 * @param[in]   fw_fail_stop The SAFETY_FW_FAIL_STOP instance
 */
void pfe_fw_fail_stop_destroy(pfe_fw_fail_stop_t *fw_fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fw_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Mask fw_fail_stop interrupts */
        pfe_fw_fail_stop_cfg_irq_mask(fw_fail_stop->fw_fail_stop_base_va);
    }
}

/**
 * @brief       SAFETY_FW_FAIL_STOP ISR
 * @param[in]   fw_fail_stop The SAFETY_FW_FAIL_STOP instance
 * @return      EOK if interrupt has been handled
 */
errno_t pfe_fw_fail_stop_isr(const pfe_fw_fail_stop_t *fw_fail_stop)
{
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fw_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = ENOMEM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_fw_fail_stop_cfg_isr(fw_fail_stop->fw_fail_stop_base_va);
    }

    return ret;
}

/**
 * @brief       Mask SAFETY_FW_FAIL_STOP interrupts
 * @param[in]   fw_fail_stop The SAFETY_FW_FAIL_STOP instance
 */
void pfe_fw_fail_stop_irq_mask(const pfe_fw_fail_stop_t *fw_fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fw_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_fw_fail_stop_cfg_irq_mask(fw_fail_stop->fw_fail_stop_base_va);
    }
}

/**
 * @brief       Unmask SAFETY_FW_FAIL_STOP interrupts
 * @param[in]   fw_fail_stop The SAFETY_FW_FAIL_STOP instance
 */
void pfe_fw_fail_stop_irq_unmask(const pfe_fw_fail_stop_t *fw_fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == fw_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_fw_fail_stop_cfg_irq_unmask(fw_fail_stop->fw_fail_stop_base_va);
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [148/185]: src\pfe_fw_fail_stop_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_fw_fail_stop_csr.h"
#include "pfe_global_wsp.h"
#include "Eth_43_PFE_Cfg.h"

#define TRIG_EN_INTERRUPTS_CHECK    (FW_FAIL_STOP_INT | FW_FAIL_STOP_MODE_INT)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       FW_FAIL_STOP ISR
 * @details     MASK, ACK, and process triggered interrupts.
 * @param[in]   base_va FW_FAIL_STOP register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 */
errno_t pfe_fw_fail_stop_cfg_isr(addr_t base_va)
{
    uint32 reg_en, reg_src;
    errno_t ret = ENOENT;
    uint32 trig_en_interrupts;

    /* Get enabled interrupts */
    reg_en = hal_read32(base_va + WSP_FW_FAIL_STOP_MODE_INT_EN);
    /* Mask FW Failstop interrupts */
    hal_write32((reg_en & ~(FW_FAIL_STOP_INT_EN)), base_va + WSP_FW_FAIL_STOP_MODE_INT_EN);
    /* Get triggered interrupts */
    reg_src = hal_read32(base_va + WSP_FW_FAIL_STOP_MODE_INT_SRC);
    /* ACK triggered interrupts */
    hal_write32(reg_src, base_va + WSP_FW_FAIL_STOP_MODE_INT_SRC);

    /* Process interrupts which are triggered AND enabled */
    trig_en_interrupts = reg_src & reg_en & TRIG_EN_INTERRUPTS_CHECK;
    if (0U != trig_en_interrupts)
    {
        pfe_hm_report_error(HM_SRC_FW_FAIL_STOP, HM_EVT_FW_FAIL_STOP, "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_FAIL_STOP_FW_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
        ret = EOK;
    }

    /* Enable the non-triggered ones only to prevent flooding */
    hal_write32((reg_en & ~reg_src), base_va + WSP_FW_FAIL_STOP_MODE_INT_EN);

    return ret;
}

/**
 * @brief       Mask FW_FAIL_STOP interrupts
 * @param[in]   base_va Base address of the FW_FAIL_STOP register space
 */
void pfe_fw_fail_stop_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_FW_FAIL_STOP_MODE_INT_EN) & ~(FW_FAIL_STOP_INT_EN);
    hal_write32(reg, base_va + WSP_FW_FAIL_STOP_MODE_INT_EN);
}

/**
 * @brief       Unmask FW_FAIL_STOP interrupts
 * @param[in]   base_va Base address of the FW_FAIL_STOP register space
 */
void pfe_fw_fail_stop_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_FW_FAIL_STOP_MODE_INT_EN) | FW_FAIL_STOP_INT_EN;
    hal_write32(reg, base_va + WSP_FW_FAIL_STOP_MODE_INT_EN);
}

/**
 * @brief       Unmask all FW_FAIL_STOP interrupts
 * @param[in]   base_va Base address of the FW_FAIL_STOP register space
 * @note        This function is called from thread.
 */
void pfe_fw_fail_stop_cfg_irq_unmask_all(addr_t base_va)
{
    hal_write32(FW_FAIL_STOP_INT_ENABLE_ALL, base_va + WSP_FW_FAIL_STOP_MODE_INT_EN);   /*set registry value*/
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [149/185]: src\pfe_fw_feature.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "pfe_ct.h"
#include "oal.h"
#include "pfe_class.h"
#include "pfe_fw_feature.h"
#include "hal.h" 
#include "oal_util.h"

#define UINT_8_SIZE     (sizeof(uint8))
#define UINT_16_SIZE    (sizeof(uint16))
#define UINT_32_SIZE    (sizeof(uint32))

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#define SUM_WRAP_U32(A, B) ((uint32)(((uint64)(A) + (B)) & UINT32_MAX))

/**
 * @brief Creates a feature instance
 * @param[in] *features The features instance to be initialized
 * @return The created feature instance or NULL in case of failure
 */
pfe_fw_feature_t *pfe_fw_feature_create(pfe_fw_feature_t *feature)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(feature, 0U, sizeof(pfe_fw_feature_t));
    }

    return feature;
}

/**
 * @brief Destroys a feature instance previously created by pfe_fw_feature_create()
 * @param[in] feature Previously created feature
 */
void pfe_fw_feature_destroy(const pfe_fw_feature_t *feature)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)feature;
    }
}

/**
 * @brief Sets reference to low level data in obtained from PE
 * @param[in] feature Feature to set the low level data
 * @param[in] ll_data Low level data to set
 * @param[in] instances of processing
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_set_ll_data(pfe_fw_feature_t *feature, pfe_ct_feature_desc_t *ll_data, uint8 instances)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == ll_data)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        feature->ll.data = ll_data;
        feature->instances = instances;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Sets the base address for the strings
 * @param[in] feature Feature which string base address shall be set
 * @param[in] string_base String base address to be set
 * @return EOK or an error code.
 * @details All features use the same base address which is actually pointer to copy of elf-section
 *          .features loaded by PE. All strings are stored there and their addresses are stored in
 *          the low level data set by pfe_fw_feature_set_ll_data().
 */
errno_t pfe_fw_feature_set_string_base(pfe_fw_feature_t *feature, const char *string_base)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == string_base)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        feature->string_base = string_base;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Sets the functions to access PEs DMEM
 * @param[in] feature Feature to set the functions
 * @param[in] read_func Function to read the PE DMEM data
 * @param[in] write_func Function to write PE DMEM data
 * @param[in] data Class/Util reference used by read_func/write_func.
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_set_dmem_funcs(pfe_fw_feature_t *feature, dmem_read_func_t read_func, dmem_write_func_t write_func, void *data)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == read_func) || (NULL == write_func) || (NULL == data)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        feature->dmem_read_func = read_func;
        feature->dmem_write_func = write_func;
        feature->dmem_rw_func_data = data;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Returns name of the feature
 * @param[in] feature Feature to be read.
 * @param[out] name The feature name to be read.
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_get_name(const pfe_fw_feature_t *feature, const char **name)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *name = feature->string_base + oal_ntohl(feature->ll.data->name);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Returns the feature description provide by the firmware.
 * @param[in] feature Feature to be read.
 * @param[out] desc Descripton of the feature
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_get_desc(const pfe_fw_feature_t *feature, const char **desc)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == desc)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *desc = feature->string_base + oal_ntohl(feature->ll.data->description);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads the flags of the feature
 * @param[in] feature Feature to be read
 * @param[out] flags Value of the feature flags
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_get_flags(const pfe_fw_feature_t *feature, pfe_ct_feature_flags_t *flags)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == flags)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *flags = feature->ll.data->flags;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Checks whether the feature is available in Class
 * @param[in] feature Feature to check
 * @retval TRUE Feature is implemented in Class
 * @retval FALSE Feature is not implemented in Class
 */
bool_t pfe_fw_feature_is_in_class(const pfe_fw_feature_t *feature)
{
    pfe_ct_feature_flags_t flags;
    bool_t ret;
    flags = F_NONE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_fw_feature_get_flags(feature, &flags);

        ret = ((uint8)F_NONE == ((uint8)flags & (uint8)F_CLASS)) ? FALSE : TRUE;
    }
    return ret;
}

/**
 * @brief Checks whether the feature is available in Util
 * @param[in] feature Feature to check
 * @retval TRUE Feature is implemented in Util
 * @retval FALSE Feature is not implemented in Util
 */
bool_t pfe_fw_feature_is_in_util(const pfe_fw_feature_t *feature)
{
    pfe_ct_feature_flags_t flags;
    bool_t ret;
    flags = F_NONE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_fw_feature_get_flags(feature, &flags);

        ret = ((uint8)F_NONE == ((uint8)flags & (uint8)F_UTIL)) ? FALSE : TRUE;
    }
    return ret;
}

/**
 * @brief Reads the default value of the feature i.e. initial value set by the FW
 * @param[in] feature Feature to read the value
 * @param[out] def_val The read default value.
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_get_def_val(const pfe_fw_feature_t *feature, uint8 *def_val)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == def_val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *def_val = feature->ll.data->def_val;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads value of the feature enable variable
 * @param[in] Feature to read the value
 * @param[out] val Value read from the DMEM
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_get_val(const pfe_fw_feature_t *feature, uint8 *val)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = feature->dmem_read_func(feature->dmem_rw_func_data, 0U, val, (addr_t)oal_ntohl(feature->ll.data->position), sizeof(uint8));
    }
    return ret;
}

/**
 * @brief Checks whether the given feature is in enabled state
 * @param[in] feature Feature to check the enabled state
 * @retval TRUE Feature is enabled (the enable variable value is not 0)
 * @retval FALSE Feature is disabled (or its state could not be read)
 */
bool_t pfe_fw_feature_enabled(const pfe_fw_feature_t *feature)
{
    uint8 val;
    errno_t ret;
    bool_t feature_enabled;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        feature_enabled = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_fw_feature_get_val(feature, &val);

        if (EOK != ret)
        {
            feature_enabled = FALSE;
        }
        else
        {
            if (0U != val)
            {
                feature_enabled = TRUE;
            }
            else
            {
                feature_enabled = FALSE;
            }
        }
    }
    return feature_enabled;
}

/**
 * @brief Sets value of the feature enable variable in the DMEM
 * @param[in] feature Feature to set the value
 * @param[in] val Value to be set
 * @return EOK or an error code.
 */
errno_t pfe_fw_feature_set_val(const pfe_fw_feature_t *feature, uint8 val)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = feature->dmem_write_func(feature->dmem_rw_func_data, -1, (addr_t)oal_ntohl(feature->ll.data->position), (void *)&val, sizeof(uint8));
    }
    return ret;
}

/**
 * @brief Search feature entry table by name
 * @param[in] handle to the first table element
 * @param[in] name to be searched
 * @return EOK or an error code
 */
static errno_t pfe_fw_feature_table_entry_by_name(pfe_fw_tbl_handle_t *handle, const char_t *name)
{
    pfe_ct_feature_tbl_entry_t * tbl_curr;
    errno_t ret = ENOENT;

    if(NULL != handle->tbl_curr)
    {
        tbl_curr = handle->tbl_curr;

        while(tbl_curr->name[0] != '\0')
        {
            if(0 == autolibc_strcmp(name, tbl_curr->name))
            {
                handle->tbl_curr = tbl_curr;
                ret = EOK;
            }
            tbl_curr++;
        }
    }

    return ret;
}

/**
 * @brief Search feature entry in config table by name
 * @param[in] feature Feature to be searched
 * @param[in] name to be searched
 * @param[out] entry table handle of the search element
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_cfg_by_name(const pfe_fw_feature_t *feature, const char *name, pfe_fw_tbl_handle_t *entry)
{
    pfe_fw_tbl_handle_t handle;
    errno_t ret;

    handle.tbl_curr = (pfe_ct_feature_tbl_entry_t *)(uintptr_t)(feature->string_base + oal_ntohl(feature->ll.data_ext->cfg));
    handle.feature = feature;

    ret = pfe_fw_feature_table_entry_by_name(&handle, name);

    if (ret == EOK)
    {
        *entry = handle;
    }

    return ret;
}

/*
 * @brief Search feature entry in stats table by name
 * @param[in] feature Feature to be searched
 * @param[in] name to be searched
 * @param[out] entry table handle of the search element
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_stats_by_name(const pfe_fw_feature_t *feature, const char* name, pfe_fw_tbl_handle_t *entry)
{
    pfe_fw_tbl_handle_t handle;
    errno_t ret;

    handle.tbl_curr = (pfe_ct_feature_tbl_entry_t *)(uintptr_t)(feature->string_base + oal_ntohl(feature->ll.data_ext->stats));
    handle.feature = feature;

    ret = pfe_fw_feature_table_entry_by_name(&handle, name);

    if(ret == EOK)
    {
        *entry = handle;
    }
    return ret;
}

/*
 * @brief Returns first entry of the config table
 * @param[in] feature Feature from witch to get config table
 * @param[out] feature_table table handle of the first entry
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_cfg_first(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table)
{
    errno_t ret = ENOENT;

    if(0 != feature->ll.data_ext->cfg)
    {
        feature_table->feature = feature;
        feature->current_cfg = 0;
        feature_table->tbl_curr = (pfe_ct_feature_tbl_entry_t *)(uintptr_t)(feature->string_base + oal_ntohl(feature->ll.data_ext->cfg));
        ret = EOK;
    }

    return ret;
}

/*
 * @brief Returns next entry of the config table
 * @param[in] feature Feature from witch to get config table
 * @param[out] feature_table table handle of the next entry
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_cfg_next(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table)
{
    errno_t ret = ENOENT;

    if(0 != feature->ll.data_ext->cfg)
    {
        feature_table->feature = feature;
        feature->current_cfg ++;
        feature_table->tbl_curr = (pfe_ct_feature_tbl_entry_t *)(uintptr_t)(feature->string_base + oal_ntohl(feature->ll.data_ext->cfg) + (feature->current_cfg*sizeof(pfe_ct_feature_tbl_entry_t)));
        if(feature_table->tbl_curr->name[0] != '\0')
        {
            ret = EOK;
        }
    }

    return ret;
}

/*
 * @brief Returns first entry of the stats table
 * @param[in] feature Feature from witch to get stats table
 * @param[out] feature_table table handle of the first entry
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_stats_first(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table)
{
    errno_t ret = ENOENT;

    if(0 != feature->ll.data_ext->stats)
    {
        feature_table->feature = feature;
        feature->current_stats = 0;
        feature_table->tbl_curr = (pfe_ct_feature_tbl_entry_t *)(uintptr_t)(feature->string_base + oal_ntohl(feature->ll.data_ext->stats));
        ret = EOK;
    }

    return ret;
}

/*
 * @brief Returns next entry of the stats table
 * @param[in] feature Feature from witch to get stats table
 * @param[out] feature_table table handle of the next entry
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_stats_next(pfe_fw_feature_t *feature, pfe_fw_tbl_handle_t *feature_table)
{
    errno_t ret = ENOENT;

    if(0 != feature->ll.data_ext->stats)
    {
        feature_table->feature = feature;
        feature->current_stats ++;
        feature_table->tbl_curr = (pfe_ct_feature_tbl_entry_t *)(uintptr_t)(feature->string_base + oal_ntohl(feature->ll.data_ext->stats) + (feature->current_stats*sizeof(pfe_ct_feature_tbl_entry_t)));
        if(feature_table->tbl_curr->name[0] != '\0')
        {
            ret = EOK;
        }
    }

    return ret;
}

/*
 * @brief Returns the name of the element handle
 * @param[in] handle Table element handle
 * @param[out] table_name name of the element
 * @return EOK
 */
errno_t pfe_fw_feature_table_entry_name(pfe_fw_tbl_handle_t handle, const char **table_name)
{
    *table_name = handle.tbl_curr->name;

    return EOK;
}

/*
 * @brief Returns the size of the element handle
 * @param[in] handle Table element handle
 * @return size of the element
 */
uint32 pfe_fw_feature_table_entry_size(pfe_fw_tbl_handle_t handle)
{
    return handle.tbl_curr->size;
}

/*
 * @brief Returns the multiplicity of the element handle
 * @param[in] handle Table element handle
 * @return multiplicity of the element
 */
uint32 pfe_fw_feature_table_entry_multiplicity(pfe_fw_tbl_handle_t handle)
{
    return handle.tbl_curr->multiplicity;
}

/*
 * @brief Returns the allocation size of the payload
 * @param[in] handle Table element handle
 * @return allocation size of the payload
 */
uint32 pfe_fw_feature_table_entry_allocsize(pfe_fw_tbl_handle_t handle)
{
    return (uint32)handle.tbl_curr->size * handle.tbl_curr->multiplicity;
}

/*
 * @brief Sets the table entry payload
 * @param[in] handle Feature table entry on witch to set the value
 * @param[in] val    Value to be set
 * @param[in] size   Size of the value to be set
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_entry_set(pfe_fw_tbl_handle_t handle, void *val, uint16 size)
{
    errno_t ret = EINVAL;
    uint8 idx = 0;
    void   *ptr = NULL_PTR;

    switch (pfe_fw_feature_table_entry_size(handle))
    {
        case UINT_8_SIZE: 
            /* Nothing to do */
            ret = EOK;
            break;
        case UINT_16_SIZE: 
            for (idx = 0; idx < (size/pfe_fw_feature_table_entry_size(handle)); idx++)
            {
                ptr = &((uint16*) val) [idx];
                *(uint16 *)ptr = oal_ntohs(*(uint16 *)ptr);
            }
            ret = EOK;
            break;
        case UINT_32_SIZE:
            for (idx = 0; idx < (size/pfe_fw_feature_table_entry_size(handle)); idx++)
             {
                ptr = &((uint32*) val) [idx];
                *(uint32 *)ptr = oal_ntohl(*(uint32 *)ptr);
            }
            ret = EOK;
            break;
        default:
            ret = EINVAL;
            break;
     }

    if(EOK == ret)
    {
        ret = handle.feature->dmem_write_func(handle.feature->dmem_rw_func_data, -1, (addr_t)oal_ntohl(handle.tbl_curr->data), (void *)val, size);
    }

    return ret;
}

/*
 * @brief Gets the table entry payload
 * @param[in] handle Feature table entry from witch to get the payload
 * @param[in] mem    memory where we write the read values
 * @param[in] size   Size of the value to be read
 * @param[in] collect Read the values from one/all PE cores 
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_entry_get(pfe_fw_tbl_handle_t handle, void *mem, uint16 size, bool_t collect)
{
    errno_t ret = EINVAL;
    uint8 idx = 0;
    void  *ptr = NULL_PTR;

    if(FALSE == collect)
    {
        ret =  handle.feature->dmem_read_func(handle.feature->dmem_rw_func_data, 0U, mem, (addr_t)oal_ntohl(handle.tbl_curr->data), size);

        if ((EOK == ret) && (pfe_fw_feature_table_entry_size(handle) > 0))
        {
            for (idx = 0; idx < (size/pfe_fw_feature_table_entry_size(handle)); idx++)
            {
                ptr = & ((uint8 *) mem) [idx * pfe_fw_feature_table_entry_size(handle)];
                switch (pfe_fw_feature_table_entry_size(handle))
                {
                    case UINT_8_SIZE: 
                        /* Nothing to do */
                        break;
                    case UINT_16_SIZE:
                        *(uint16 *)ptr = oal_ntohs(*(uint16 *) ptr);
                        break;
                    case UINT_32_SIZE:
                        *(uint32 *)ptr = oal_ntohl(*(uint32 *) ptr);
                        break;
                    default:
                        ret = EINVAL;
                        break;
                }
            }
        }
    }
    else
    {
        if(pfe_fw_feature_table_entry_size(handle) > 0)
        {
            for(idx = 0; idx < (size/pfe_fw_feature_table_entry_size(handle)); idx++)
            {
                ptr = &((uint8 *)mem)[idx * pfe_fw_feature_table_entry_size(handle)];
                ret = pfe_fw_feature_table_entry_get_by_idx(handle, ptr, idx, collect);
            }
        }
    }

    return ret;
}

/*
 * @brief Sets the table entry payload at a specific index
 * @param[in] handle Feature table entry on witch to set the value
 * @param[in] val    Value to be set
 * @param[in] idx    Index of the vector to set the value
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_entry_set_by_idx(pfe_fw_tbl_handle_t handle, void *val, uint16 idx)
{
    errno_t ret = EINVAL;

    if( idx < pfe_fw_feature_table_entry_multiplicity(handle))
    {
        switch (pfe_fw_feature_table_entry_size(handle))
        {
            case UINT_8_SIZE: 
                /* Nothing to do */
                ret = EOK;
                break;
            case UINT_16_SIZE:
                *(uint16*)val = oal_htons(*(uint16 *) val);
                ret = EOK;
                break;
            case UINT_32_SIZE:
                *(uint32*)val = oal_htonl(*(uint32 *) val);
                ret = EOK;
                break;
            default:
                ret = EINVAL;
                break;
        }
        if(EOK == ret)
        {
            const addr_t tbl_curr_addr = oal_ntohl(handle.tbl_curr->data);
            const addr_t tbl_idx = (uint32)idx * handle.tbl_curr->size;
            const addr_t dmem_dst_addr = ADDR_BASE_OFFSET(tbl_curr_addr, tbl_idx);
            ret = handle.feature->dmem_write_func(handle.feature->dmem_rw_func_data, -1, dmem_dst_addr, (void *)val, handle.tbl_curr->size);
        }
    }

    return ret;
}

/*
 * @brief Gets the table entry payload at a specific index
 * @param[in] handle Feature table entry on witch to get the vale
 * @param[in] mem    Memory where to put the value
 * @param[in] idx    Index of the vector to set the value
 * @param[in] collect Read the data from one/all PE cores
 * @return EOK or an error code
 */
errno_t pfe_fw_feature_table_entry_get_by_idx(pfe_fw_tbl_handle_t handle, void *mem, uint16 idx, bool_t collect)
{
    errno_t ret = EINVAL;
    uint8 pe_idx_max = 1U;
    uint32 acc = 0U;
    uint8 value_u8 = 0U;
    uint16 value_u16 = 0U;
    uint32 value_u32 = 0U;
    const addr_t tbl_curr_addr = oal_ntohl(handle.tbl_curr->data);
    const addr_t tbl_idx = (uint32)idx * handle.tbl_curr->size;
    const addr_t dmem_src_addr = ADDR_BASE_OFFSET(tbl_curr_addr, tbl_idx);

    if(TRUE == collect)
    {
        pe_idx_max = handle.feature->instances;
    }

    if( idx < pfe_fw_feature_table_entry_multiplicity(handle))
    {
        for(uint8 pe_idx = 0; pe_idx < pe_idx_max; pe_idx++)
        {
            switch (pfe_fw_feature_table_entry_size(handle))
            {
                case UINT_8_SIZE:
                    ret = handle.feature->dmem_read_func(   handle.feature->dmem_rw_func_data,
                                                            pe_idx,
                                                            &value_u8,
                                                            dmem_src_addr,
                                                            handle.tbl_curr->size);
                    acc = SUM_WRAP_U32(acc, value_u8);
                    break;
                case UINT_16_SIZE:
                    ret = handle.feature->dmem_read_func(   handle.feature->dmem_rw_func_data,
                                                            pe_idx,
                                                            &value_u16,
                                                            dmem_src_addr,
                                                            handle.tbl_curr->size);
                    value_u16 = oal_htons(value_u16);
                    acc = SUM_WRAP_U32(acc, value_u16);
                    break;
                case UINT_32_SIZE:
                    ret = handle.feature->dmem_read_func(   handle.feature->dmem_rw_func_data,
                                                            pe_idx,
                                                            &value_u32,
                                                            dmem_src_addr,
                                                            handle.tbl_curr->size);
                    value_u32 = oal_htonl(value_u32);
                    acc = SUM_WRAP_U32(acc, value_u32);
                    break;
                default:
                    ret = EINVAL;
                    break;
            }

            if (EOK != ret)
            {
                break;
            }
        }

        (void)autolibc_memcpy(mem, &acc, handle.tbl_curr->size);
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [150/185]: src\pfe_gpi.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL 
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_gpi.h"
#include "pfe_gpi_csr.h"

/* PFE uses the value of 32 to represent the 6 bit encoding of the IP address mask of 0 */
#define IGQOS_IP_MASK_0 32U

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_gpi_t xxgpi_instance[PFE_XXGPI_INSTANCES];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#define IGQOS_MAX_PORT_RANGE 0x7FFFU

static errno_t pfe_gpi_null_arg_check_return(const pfe_gpi_t *gpi, errno_t err);
static void igqos_class_clear_active_all(pfe_gpi_t *gpi);
static errno_t igqos_entry_ready_timeout(const pfe_gpi_t *gpi);
static errno_t igqos_class_clear_flow_entry_table(const pfe_gpi_t *gpi);
static errno_t igqos_class_clear_lru_entry_table(const pfe_gpi_t *gpi);
static void igqos_class_set_active(pfe_gpi_t *gpi, uint8 id);
static void igqos_class_clear_active(pfe_gpi_t *gpi, uint8 id);
static bool_t igqos_class_is_active(const pfe_gpi_t *gpi, uint8 id);
static uint8 igqos_class_find_entry(const pfe_gpi_t *gpi, uint8 start, bool_t is_active);
static uint8 igqos_class_find_first_free(const pfe_gpi_t *gpi);
static uint8 igqos_class_get_first_active(pfe_gpi_t *gpi);
static uint8 igqos_class_get_next_active(pfe_gpi_t *gpi);
static uint8 igqos_ip_mask_hw_encode(uint8 ip_m);
static uint8 igqos_ip_mask_hw_decode(uint8 ip_m);
static void igqos_convert_entry_to_flow(const uint32 entry[], pfe_iqos_flow_spec_t *flow);
static void igqos_convert_flow_to_entry(const pfe_iqos_flow_spec_t *flow, uint32 entry[]);
static errno_t pfe_gpi_shp_args_checks(const pfe_gpi_t *gpi, uint8 id);
static uint32 igqos_clk_div(uint32 clk_div_log2);
static uint32 igqos_convert_isl_to_weight(uint32 isl, uint32 clk_div_log2, uint32 sys_clk_mhz, bool_t is_bps);
static uint32 igqos_convert_weight_to_isl(uint32 wgt, uint32 clk_div_log2, uint32 sys_clk_mhz, bool_t is_bps);
static uint32 igqos_find_optimal_weight(uint32 isl, uint32 sys_clk_mhz, bool_t is_bps, uint32 *wgt);
static void igqos_convert_flow_to_entry_reg0123(const pfe_iqos_flow_spec_t *flow, uint32 entry[]);
static void igqos_convert_flow_to_entry_reg45(const pfe_iqos_flow_spec_t *flow, uint32 entry[]);
static void igqos_flow_entry_fixup(pfe_iqos_flow_spec_t *flow);
static errno_t igqos_flow_entry_validate(const pfe_iqos_flow_spec_t *flow);
static errno_t igqos_flow_entry_validate_args(const pfe_iqos_flow_spec_t *flow);

/*==================================================================================================
                                       LOCAL FUNCTIONS
==================================================================================================*/

/*==================================================================================================*/
static errno_t pfe_gpi_null_arg_check_return(const pfe_gpi_t *gpi, errno_t err)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == gpi))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = err;
    }
#else
    (void)gpi;
    (void)err;
#endif /* PFE_CFG_NULL_ARG_CHECK */

    return ret;
}

/*==================================================================================================*/
static void igqos_class_clear_active_all(pfe_gpi_t *gpi)
{
    uint32 i;

    for (i = 0U; i < IGQOS_BITMAP_ARR_SZ; i++)
    {
        gpi->igqos_active_entries[i] = 0;
    }

    gpi->igqos_entry_iter = 0;
}

/*==================================================================================================*/
static errno_t igqos_entry_ready_timeout(const pfe_gpi_t *gpi)
{
    errno_t  ret     = EOK;
    uint32 timeout = 200U;
    bool_t   ready;

    while (timeout > 0U)
    {
        ready = pfe_gpi_cfg_qos_entry_ready(gpi->gpi_base_va);
        if (TRUE == ready)
        {
            break;
        }
        oal_time_usleep(5U);
        timeout--;
    }

    if ((0U == timeout) && (FALSE == ready))
    {
        ready = pfe_gpi_cfg_qos_entry_ready(gpi->gpi_base_va);
    }

    if (FALSE == ready)
    {
        ret = ETIMEDOUT;
    }

    return ret;
}

/*==================================================================================================*/
static errno_t igqos_class_clear_flow_entry_table(const pfe_gpi_t *gpi)
{
    uint32 ii;
    errno_t  ret;

    for (ii = 0U; ii < ENTRY_TABLE_SIZE; ii++)
    {
        pfe_gpi_cfg_qos_clear_flow_entry_req(gpi->gpi_base_va, ii);

        ret = igqos_entry_ready_timeout(gpi);
        if (EOK != ret)
        {
            break;
        }
    }

    return ret;
}

/*==================================================================================================*/
static errno_t igqos_class_clear_lru_entry_table(const pfe_gpi_t *gpi)
{
    uint32 ii;
    errno_t  ret;

    for (ii = 0U; ii < ENTRY_TABLE_SIZE; ii++)
    {
        pfe_gpi_cfg_qos_clear_lru_entry_req(gpi->gpi_base_va, ii);

        ret = igqos_entry_ready_timeout(gpi);
        if (EOK != ret)
        {
            break;
        }
    }

    return ret;
}

/*==================================================================================================*/
static void igqos_class_set_active(pfe_gpi_t *gpi, uint8 id)
{
    gpi->igqos_active_entries[id / BITMAP_BITS_U32] |= ((uint32)1 << (id % BITMAP_BITS_U32));
}

/*==================================================================================================*/
static void igqos_class_clear_active(pfe_gpi_t *gpi, uint8 id)
{
    gpi->igqos_active_entries[id / BITMAP_BITS_U32] &= (uint32)(~((uint32)1 << (id % BITMAP_BITS_U32)));
}

/*==================================================================================================*/
static bool_t igqos_class_is_active(const pfe_gpi_t *gpi, uint8 id)
{
    bool_t ret = TRUE;

    if ((gpi->igqos_active_entries[id / BITMAP_BITS_U32] & ((uint32)1 << (id % BITMAP_BITS_U32))) == 0U)
    {
        ret = FALSE;
    }

    return ret;
}

/*==================================================================================================*/
static uint8 igqos_class_find_entry(const pfe_gpi_t *gpi, uint8 start, bool_t is_active)
{
    uint8 ii;
    uint8 ret;

    if (unlikely(start > PFE_IQOS_FLOW_TABLE_SIZE))
    {
        ret = PFE_IQOS_FLOW_TABLE_SIZE;
    }
    else
    {
        for (ii = start; ii < PFE_IQOS_FLOW_TABLE_SIZE; ii++)
        {
            if (is_active == igqos_class_is_active(gpi, ii))
            {
                break;
            }
        }

        ret = ii; /* returns PFE_IQOS_FLOW_TABLE_SIZE if not found */
    }

    return ret;
}

/*==================================================================================================*/
static uint8 igqos_class_find_first_free(const pfe_gpi_t *gpi)
{
    return igqos_class_find_entry(gpi, 0, FALSE);
}

/*==================================================================================================*/
static uint8 igqos_class_get_first_active(pfe_gpi_t *gpi)
{
    gpi->igqos_entry_iter = igqos_class_find_entry(gpi, 0, TRUE);

    return gpi->igqos_entry_iter;
}

/*==================================================================================================*/
static uint8 igqos_class_get_next_active(pfe_gpi_t *gpi)
{
    PfeDevAssert(gpi->igqos_entry_iter < UINT8_MAX);
    gpi->igqos_entry_iter = igqos_class_find_entry(gpi, gpi->igqos_entry_iter + 1U, TRUE);

    return gpi->igqos_entry_iter;
}

/*==================================================================================================*/
/*
 * convert from the stadard IP address mask encoding to the PFE hardware
 * representation
 */
static uint8 igqos_ip_mask_hw_encode(uint8 ip_m)
{
    uint8 hw_encoded;
    if (0U != ip_m)
    {
        hw_encoded  = ip_m - 1U;
    }
    else
    {
        hw_encoded  = IGQOS_IP_MASK_0;
    }
    return hw_encoded ;
}

/*==================================================================================================*/
static uint8 igqos_ip_mask_hw_decode(uint8 ip_m)
{
    uint8 hw_decoded;
    if (IGQOS_IP_MASK_0 > ip_m)
    {
        hw_decoded = ip_m + 1U;
    }
    else
    {
        hw_decoded = 0U;
    }
    return hw_decoded;
}

/*==================================================================================================*/
static void igqos_convert_entry_to_flow(const uint32 entry[], pfe_iqos_flow_spec_t *flow)
{
    pfe_iqos_flow_args_t *args = &flow->args;
    uint32              val;

    /* entry reg0 */
    val             = entry[0];
    flow->type_mask = (pfe_iqos_flow_type_t)entry_arg_get(TYPE, val);
    args->vlan      = (uint16)entry_arg_get(VLAN_ID, val);
    args->tos       = (uint8)entry_arg_get(TOS, val);
    args->l4proto   = (uint8)entry_arg_get_lower(PROT, val);

    /* entry reg1 */
    val = entry[1];
    args->l4proto |= (uint8)(entry_arg_get_upper(PROT, val) & UINT8_MAX);
    args->sip = entry_arg_get_lower(SIP, val);

    /* entry reg2 */
    val = entry[2];
    args->sip |= entry_arg_get_upper(SIP, val);
    args->dip = entry_arg_get_lower(DIP, val);

    /* entry reg3 */
    val = entry[3];
    args->dip |= entry_arg_get_upper(DIP, val);
    args->sport_min = (uint16)entry_arg_get(SPORT_MIN, val);
    args->sport_max = (uint16)entry_arg_get_lower(SPORT_MAX, val);

    /* entry reg4 */
    val = entry[4];
    args->sport_max |= (uint16)entry_arg_get_upper(SPORT_MAX, val);
    args->dport_min = (uint16)entry_arg_get(DPORT_MIN, val);
    args->dport_max = (uint16)entry_arg_get_lower(DPORT_MAX, val);

    /* entry reg5 */
    val = entry[5];
    args->dport_max |= (uint16)entry_arg_get_upper(DPORT_MAX, val);
    args->vlan_m = (uint16)entry_arg_get(VLAN_ID_M, val);
    args->tos_m  = (uint8)entry_arg_get_lower(TOS_M, val);

    /* entry reg6 */
    val = entry[6];
    args->tos_m |= (uint8)entry_arg_get_upper(TOS_M, val);
    args->l4proto_m = (uint8)entry_arg_get(PROT_M, val);
    args->sip_m     = igqos_ip_mask_hw_decode((uint8)entry_arg_get(SIP_M, val));
    args->dip_m     = igqos_ip_mask_hw_decode((uint8)entry_arg_get(DIP_M, val));

    if (entry_arg_get(ACT_DROP, val) == 1U)
    {
        flow->action = PFE_IQOS_FLOW_DROP;
    }

    if (entry_arg_get(ACT_RES, val) == 1U)
    {
        flow->action = PFE_IQOS_FLOW_RESERVED;
    }

    /* revert h/w fixups from returned flow params */
    args->sport_max <<= 1; /* AAVB-5836 */
    args->dport_max <<= 1; /* AAVB-5836 */
}

/*==================================================================================================*/
static bool_t igqos_l4_port_range_is_valid(uint16 min, uint16 max)
{
    bool_t ret = TRUE;
    if (min > max)
    {
        ret = FALSE;
    }
    /* AAVB-5836 */
    else if (min > IGQOS_MAX_PORT_RANGE)
    {
        ret = FALSE;
    }
    else
    {
        ret = TRUE;
    }
    /* AAVB-5836 */
    if ((max > (IGQOS_MAX_PORT_RANGE-1U) ) || ((max & 0x1U) == 1U))
    {
        ret = FALSE;
    }
    else
    {
        ret = TRUE;
    }

    return ret;
}

/*==================================================================================================*/
static void igqos_flow_entry_fixup(pfe_iqos_flow_spec_t *flow)
{
    /* PFE_IQOS_ARG_VLAN */
    if (flow->args.vlan_m == 0U)
    {
        /* mask not specified */
        flow->args.vlan_m = PFE_IQOS_VLAN_ID_MASK;
    }

    /* PFE_IQOS_ARG_TOS */
    if (flow->args.tos_m == 0U)
    {
        /* mask not specified */
        flow->args.tos_m = PFE_IQOS_TOS_MASK;
    }

    /* PFE_IQOS_ARG_L4PROTO */
    if (flow->args.l4proto_m == 0U)
    {
        /* mask not specified */
        flow->args.l4proto_m = PFE_IQOS_L4PROTO_MASK;
    }

    /* PFE_IQOS_ARG_SPORT */
    flow->args.sport_max >>= 1;   /* AAVB-5836 */

    /* PFE_IQOS_ARG_DPORT */
    flow->args.dport_max >>= 1;   /* AAVB-5836 */
}

/*==================================================================================================*/
static errno_t igqos_flow_entry_validate_args(const pfe_iqos_flow_spec_t *flow)
{
    const pfe_iqos_flow_args_t *args = &flow->args;
    uint16 arg_invalid_mask = 0u;

    if ((args->vlan > PFE_IQOS_VLAN_ID_MASK) || (args->vlan_m > PFE_IQOS_VLAN_ID_MASK))
    {
        arg_invalid_mask |= PFE_IQOS_ARG_VLAN;
    }

    if (args->sip_m > PFE_IQOS_SDIP_MASK)
    {
        arg_invalid_mask |= PFE_IQOS_ARG_SIP;
    }

    if (args->dip_m > PFE_IQOS_SDIP_MASK)
    {
        arg_invalid_mask |= PFE_IQOS_ARG_DIP;
    }

    if (!igqos_l4_port_range_is_valid(args->sport_min, args->sport_max)) 
    {
        arg_invalid_mask |= PFE_IQOS_ARG_SPORT;
    }

    if (!igqos_l4_port_range_is_valid(args->dport_min, args->dport_max)) 
    {
        arg_invalid_mask |= PFE_IQOS_ARG_DPORT;
    }

    return (0u != ((uint16)flow->arg_type_mask & arg_invalid_mask)) ? EINVAL : EOK;
}

/*==================================================================================================*/
static errno_t igqos_flow_entry_validate(const pfe_iqos_flow_spec_t *flow)
{
    errno_t ret = EINVAL;

    if ((flow->type_mask <= PFE_IQOS_FLOW_TYPE_MAX) &&
        (flow->arg_type_mask <= PFE_IQOS_ARG_MAX) &&
        (flow->action < PFE_IQOS_FLOW_COUNT))
    {
        ret = igqos_flow_entry_validate_args(flow);
    }

    return ret;
}

/*==================================================================================================*/
static void igqos_convert_flow_to_entry_reg0123(const pfe_iqos_flow_spec_t *flow, uint32 entry[])
{
    const pfe_iqos_flow_args_t *args = &flow->args;
    uint32                    val;

    /* entry reg0 */
    val = entry_arg_set(TYPE, (uint32)flow->type_mask);
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_VLAN))
    {
        val |= entry_arg_set(VLAN_ID, (uint32)args->vlan);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_TOS))
    {
        val |= entry_arg_set(TOS, (uint32)args->tos);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_L4PROTO))
    {
        val |= entry_arg_set_lower(PROT, (uint32)args->l4proto);
    }
    entry[0] = val;

    /* entry reg1 */
    val = 0;
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_L4PROTO))
    {
        val |= entry_arg_set_upper(PROT, (uint32)args->l4proto);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_SIP))
    {
        val |= entry_arg_set_lower(SIP, args->sip);
    }
    entry[1] = val;

    /* entry reg2 */
    val = 0;
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_SIP))
    {
        val |= entry_arg_set_upper(SIP, args->sip);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_DIP))
    {
        val |= entry_arg_set_lower(DIP, args->dip);
    }
    entry[2] = val;

    /* entry reg3 */
    val = 0;
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_DIP))
    {
        val |= entry_arg_set_upper(DIP, args->dip);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_SPORT))
    {
        val |= entry_arg_set(SPORT_MIN, (uint32)args->sport_min);
        val |= entry_arg_set_lower(SPORT_MAX, (uint32)args->sport_max);
    }
    entry[3] = val;
}

/*==================================================================================================*/
static void igqos_convert_flow_to_entry_reg45(const pfe_iqos_flow_spec_t *flow, uint32 entry[])
{
    uint32              val;
    const pfe_iqos_flow_args_t *args = &flow->args;

    /* entry reg4 */
    val = 0;
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_SPORT))
    {
        val |= entry_arg_set_upper(SPORT_MAX, (uint32)args->sport_max);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_DPORT))
    {
        val |= entry_arg_set(DPORT_MIN, (uint32)args->dport_min);
        val |= entry_arg_set_lower(DPORT_MAX, (uint32)args->dport_max);
    }
    entry[4] = val;

    /* entry reg5 */
    /* the entry is valid by default */
    val = entry_arg_set(VALID_ENTRY, 1U);
    /* set the same as flow type flags */
    val |= entry_arg_set(TYPE_M, (uint32)flow->type_mask);

    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_DPORT))
    {
        val |= entry_arg_set_upper(DPORT_MAX, (uint32)args->dport_max);
    }

    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_VLAN))
    {
        val |= entry_arg_set(VLAN_ID_M, (uint32)args->vlan_m);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_TOS))
    {
        val |= entry_arg_set_lower(TOS_M, (uint32)args->tos_m);
    }
    entry[5] = val;
}

/*==================================================================================================*/
static void igqos_convert_flow_to_entry(const pfe_iqos_flow_spec_t *flow, uint32 entry[])
{
    const pfe_iqos_flow_args_t *args = &flow->args;
    uint32                    val;

    /* convert the entry reg 0-3 */
    igqos_convert_flow_to_entry_reg0123(flow, entry);

    /* convert the entry reg 4-5 */
    igqos_convert_flow_to_entry_reg45(flow, entry);

    /* entry reg6 */
    val = 0;
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_TOS))
    {
        val |= entry_arg_set_upper(TOS_M, (uint32)args->tos_m);
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_L4PROTO))
    {
        val |= entry_arg_set(PROT_M, (uint32)args->l4proto_m);
    }

    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_SIP))
    {
        val |= entry_arg_set(SIP_M, (uint32)igqos_ip_mask_hw_encode(args->sip_m));
    }
    else
    {
        val |= entry_arg_set(SIP_M, (uint32)igqos_ip_mask_hw_encode(0));
    }

    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_DIP))
    {
        val |= entry_arg_set(DIP_M, (uint32)igqos_ip_mask_hw_encode(args->dip_m));
    }
    else
    {
        val |= entry_arg_set(DIP_M, (uint32)igqos_ip_mask_hw_encode(0));
    }

    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_SPORT))
    {
        /* set source port 'mask' to all '1', as not configurable */
        val |= entry_arg_set(SPORT_M, mask32(GPI_QOS_FLOW_SPORT_M_WIDTH));
    }
    if (0U != (flow->arg_type_mask & PFE_IQOS_ARG_DPORT))
    {
        /* set destination port 'mask' to all '1', as not configurable */
        val |= entry_arg_set(DPORT_M, mask32(GPI_QOS_FLOW_DPORT_M_WIDTH));
    }
    if (flow->action == PFE_IQOS_FLOW_DROP)
    {
        val |= entry_arg_set(ACT_DROP, 1U);
    }
    else if (flow->action == PFE_IQOS_FLOW_RESERVED)
    {
        val |= entry_arg_set(ACT_RES, 1U);
    }
    else
    {
        /* Required by Misra */
    }
    entry[6] = val;

    /* entry reg7 - unused */
    entry[7] = 0;
}

/*==================================================================================================*/
/* shaper configuration */
static errno_t pfe_gpi_shp_args_checks(const pfe_gpi_t *gpi, uint8 id)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);

    if (ret == EOK)
    {
        if (id >= PFE_IQOS_SHP_COUNT)
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/*==================================================================================================*/
static uint32 igqos_clk_div(uint32 clk_div_log2)
{
    PfeDevAssert(clk_div_log2 < 31U);
    return ((uint32)1U << (clk_div_log2 + 1U));
}

/*==================================================================================================*/
static uint32 igqos_convert_isl_to_weight(uint32 isl, uint32 clk_div_log2, uint32 sys_clk_mhz, bool_t is_bps)
{
    uint64 wgt = (uint64)isl * igqos_clk_div(clk_div_log2);
    PfeDevAssert(wgt < (1ULL << (64U - IGQOS_PORT_SHP_FRACW_WIDTH)));
    wgt *= (1ULL << IGQOS_PORT_SHP_FRACW_WIDTH);
    wgt /= (uint64)sys_clk_mhz * 1000000ULL; /* sys clk in Hz */
    if (TRUE == is_bps)
    {
        wgt /= 8ULL;
    }

    PfeDevAssert(wgt <= UINT32_MAX);
    return (uint32)wgt;
}

/*==================================================================================================*/
static uint32 igqos_convert_weight_to_isl(uint32 wgt, uint32 clk_div_log2, uint32 sys_clk_mhz, bool_t is_bps)
{
    uint64 clk_div = igqos_clk_div(clk_div_log2);
    uint64 isl = (uint64)wgt;
    if (is_bps)
    {
        isl *= 8ULL;
    }
    PfeDevAssert(isl <= UINT32_MAX);
    PfeDevAssert(sys_clk_mhz <= (UINT32_MAX/1000000UL));
    isl *= (uint64)sys_clk_mhz * 1000000ULL; /* sys clk in Hz */
    isl /= (1ULL << IGQOS_PORT_SHP_FRACW_WIDTH);
    isl /= clk_div;

    return (uint32)isl;
}

/*==================================================================================================*/
static uint32 igqos_find_optimal_weight(uint32 isl, uint32 sys_clk_mhz, bool_t is_bps, uint32 *wgt)
{
    const uint32 w_max = IGQOS_PORT_SHP_WEIGHT_MASK;
    uint32       w, l, r, k;
    uint32       ret;

    r = IGQOS_PORT_SHP_CLKDIV_MASK; /* max clk_div_log2 value */
    l = 0;                          /* min clk_div_log2 value */

    /* check if 'isl' is out-of-range */
    w = igqos_convert_isl_to_weight(isl, l, sys_clk_mhz, is_bps);
    if (w > w_max)
    {
        NXP_LOG_WARNING("Shaper idle slope too high, weight (%u) exceeds max value\n", (uint_t)w);
        *wgt = w;
        ret  = l;
    }
    else
    {

        w = igqos_convert_isl_to_weight(isl, r, sys_clk_mhz, is_bps);
        if (w == 0U)
        {
            NXP_LOG_WARNING("Shaper idle slope too small, computed weight is 0\n");
            *wgt = w;
            ret  = r;
        }
        else
        {

            if (w <= w_max)
            {
                *wgt = w;
                ret  = r; /* optimum found */
            }
            else
            {

                /* binary search, worst case 4 iterations for r == 15 */
                while (1U < (r-l))
                {
                    k = (l + r) / 2U;
                    w = igqos_convert_isl_to_weight(isl, k, sys_clk_mhz, is_bps);

                    if (w <= w_max)
                    {
                        l = k;
                    }
                    else
                    {
                        r = k;
                    }
                    PfeDevAssert(l <= r);
                }

                k = (l + r) / 2U;

                *wgt = igqos_convert_isl_to_weight(isl, k, sys_clk_mhz, is_bps);
                ret = k;
            }
        }
    }
    return ret;
}

/*==================================================================================================
                                       GLOBAL FUNCTIONS
==================================================================================================*/
/**
 * @brief       Create new GPI instance
 * @details     Creates and initializes GPI instance. The new instance is disabled and needs
 *              to be enabled by pfe_gpi_enable().
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   gpi_base BMU base address offset within CBUS address space
 * @param[in]   cfg The BMU block configuration
 * @param[in]   xxgpi_id The ID for GPI instance to be initialized
 * @return      The BMU instance or NULL if failed
 */
pfe_gpi_t *pfe_gpi_create(addr_t cbus_base_va, addr_t gpi_base, const pfe_gpi_cfg_t *cfg, pfe_xxgpi_id_t xxgpi_id)
{
    pfe_gpi_t *gpi;
    errno_t    ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_ADDR == cbus_base_va) || (NULL == cfg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        gpi = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (unlikely(PFE_XXGPI_INSTANCES <= xxgpi_id))
        {
            NXP_LOG_ERROR("xxGPI id out of range\n");
            gpi = NULL;
        }
        else
        {
            gpi = &xxgpi_instance[xxgpi_id];
            (void)autolibc_memset(gpi, 0, sizeof(pfe_gpi_t));
            gpi->cbus_base_va    = cbus_base_va;
            gpi->gpi_base_offset = gpi_base;
            gpi->gpi_base_va     = ADDR_BASE_OFFSET(gpi->cbus_base_va, gpi->gpi_base_offset);
            gpi->sys_clk_mhz     = pfe_gpi_cfg_get_sys_clk_mhz(cbus_base_va);

            ret = pfe_gpi_reset(gpi);
            if (EOK != ret)
            {
                gpi = NULL;
            }
            else
            {
                switch (gpi_base)
                {
                    case CBUS_EGPI1_BASE_ADDR:
                    case CBUS_EGPI2_BASE_ADDR:
                    case CBUS_EGPI3_BASE_ADDR:
                        /*
                        * includes initialization of CLASS tables
                        * required by the ECC module init
                        */
                        ret = pfe_gpi_qos_reset(gpi);
                        if (EOK != ret)
                        {
                            NXP_LOG_ERROR("GPI QOS reset timed-out\n");
                            gpi = NULL;
                        }
                        break;
                    default:
                        /* Do Nothing */
                        break;
                }

                if (NULL != gpi)
                {
                    pfe_gpi_disable(gpi);

                    pfe_gpi_cfg_init(gpi->gpi_base_va, cfg);
                }
            }
        }
    }

    return gpi;
}

/**
 * @brief       Reset the GPI block
 * @param[in]   gpi The GPI instance
 */
errno_t pfe_gpi_reset(const pfe_gpi_t *gpi)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        ret = pfe_gpi_cfg_reset(gpi->gpi_base_va);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("GPI reset timed-out\n");
        }
    }

    return ret;
}

/**
 * @brief       Enable the GPI block
 * @param[in]   gpi The GPI instance
 */
void pfe_gpi_enable(const pfe_gpi_t *gpi)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        pfe_gpi_cfg_enable(gpi->gpi_base_va);
    }
}

/**
 * @brief       Disable the GPI block
 * @param[in]   gpi The GPI instance
 */
void pfe_gpi_disable(const pfe_gpi_t *gpi)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        pfe_gpi_cfg_disable(gpi->gpi_base_va);
    }
}

/**
 * @brief       Destroy GPI instance
 * @param[in]   gpi The GPI instance
 */
void pfe_gpi_destroy(pfe_gpi_t *gpi)
{
    errno_t ret;
    if (NULL != gpi)
    {
        pfe_gpi_disable(gpi);

        if ((gpi->gpi_base_offset == CBUS_EGPI1_BASE_ADDR) || (gpi->gpi_base_offset == CBUS_EGPI2_BASE_ADDR) || (gpi->gpi_base_offset == CBUS_EGPI3_BASE_ADDR))
        {
            ret = pfe_gpi_qos_reset(gpi);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("GPI QOS reset timed-out\n");
            }
        }

        ret = pfe_gpi_reset(gpi);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("GPI reset timed-out\n");
        }
    }
}

/*==================================================================================================*/
/* Ingress QoS support */
bool_t pfe_gpi_qos_is_enabled(const pfe_gpi_t *gpi)
{
    bool_t  is_enabled;
    errno_t ret        = pfe_gpi_null_arg_check_return(gpi, EINVAL);

    if (ret == EOK)
    {
        is_enabled = pfe_gpi_cfg_qos_is_enabled(gpi->gpi_base_va);
    }
    else
    {
        is_enabled = FALSE;
    }

    return is_enabled;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_reset(pfe_gpi_t *gpi)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        ret = igqos_class_clear_flow_entry_table((const pfe_gpi_t *)gpi);
        if (EOK == ret)
        {
            ret = igqos_class_clear_lru_entry_table((const pfe_gpi_t *)gpi);
            if (EOK == ret)
            {
                pfe_gpi_cfg_qos_default_init(gpi->gpi_base_va);

                /* clear driver state */
                igqos_class_clear_active_all(gpi);
            }
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_enable(pfe_gpi_t *gpi)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        if (TRUE != pfe_gpi_cfg_qos_is_enabled(gpi->gpi_base_va))
        {
            ret = pfe_gpi_qos_reset(gpi);
            if (EOK == ret)
            {
                pfe_gpi_cfg_qos_enable(gpi->gpi_base_va);
            }
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_disable(const pfe_gpi_t *gpi)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        pfe_gpi_cfg_qos_disable(gpi->gpi_base_va);
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_get_flow(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_flow_spec_t *flow)
{
    uint32 class_table_entry[8] = { 0U };
    errno_t  ret;

    if (id >= PFE_IQOS_FLOW_TABLE_SIZE)
    {
        ret = EINVAL;
    }
    else
    {
        pfe_gpi_cfg_qos_rd_fl_entry_req(gpi->gpi_base_va, id);
        ret = igqos_entry_ready_timeout(gpi);
        if (ret == EOK)
        {
            pfe_gpi_cfg_qos_rd_fl_entry_resp(gpi->gpi_base_va, class_table_entry);
            igqos_convert_entry_to_flow(class_table_entry, flow);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_rem_flow(pfe_gpi_t *gpi, uint8 id)
{
    errno_t ret;

    if (id >= PFE_IQOS_FLOW_TABLE_SIZE)
    {
        ret = EINVAL;
    }
    else
    {
        if (igqos_class_is_active(gpi, id))
        {
            pfe_gpi_cfg_qos_clear_flow_entry_req(gpi->gpi_base_va, id);

            ret = igqos_entry_ready_timeout(gpi);
            if (EOK == ret)
            {
                igqos_class_clear_active(gpi, id);
            }
        }
        else
        {
            ret = EINVAL; /* already removed */
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_add_flow(pfe_gpi_t *gpi, uint8 id, pfe_iqos_flow_spec_t *flow)
{
    uint32 class_table_entry[8];
    uint8  entry_id;
    errno_t  ret;

    if ((id >= PFE_IQOS_FLOW_TABLE_SIZE) && (id != PFE_IQOS_FLOW_TABLE_ENTRY_SKIP))
    {
        ret = EINVAL;
    }
    else if (EOK != igqos_flow_entry_validate(flow))
    {
        ret = EINVAL;
    }
    else
    {
        igqos_flow_entry_fixup(flow);

        if (id == PFE_IQOS_FLOW_TABLE_ENTRY_SKIP)
        {
            entry_id = igqos_class_find_first_free(gpi);
        }
        else
        {
            entry_id = id;
        }

        igqos_convert_flow_to_entry(flow, class_table_entry);

        pfe_gpi_cfg_qos_write_flow_entry_req(gpi->gpi_base_va, entry_id, class_table_entry);

        ret = igqos_entry_ready_timeout(gpi);
        if (EOK == ret)
        {
            igqos_class_set_active(gpi, entry_id);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_get_first_flow(pfe_gpi_t *gpi, uint8 *id, pfe_iqos_flow_spec_t *flow)
{
    errno_t ret;
    uint8 entry_id;

    entry_id = igqos_class_get_first_active(gpi);
    if (entry_id == PFE_IQOS_FLOW_TABLE_SIZE)
    {
        ret = EOVERFLOW;
    }
    else
    {
        *id = entry_id;
        ret = pfe_gpi_qos_get_flow(gpi, entry_id, flow);
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_qos_get_next_flow(pfe_gpi_t *gpi, uint8 *id, pfe_iqos_flow_spec_t *flow)
{
    errno_t ret;
    uint8 entry_id;

    entry_id = igqos_class_get_next_active(gpi);
    if (entry_id == PFE_IQOS_FLOW_TABLE_SIZE)
    {
        ret = EOVERFLOW;
    }
    else
    {
        *id = entry_id;
        ret = pfe_gpi_qos_get_flow(gpi, entry_id, flow);
    }

    return ret;
}

/*==================================================================================================*/
/* WRED configuration */
bool_t pfe_gpi_wred_is_enabled(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue)
{
    bool_t  is_enabled;
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret != EOK)
    {
        is_enabled = FALSE;
    }
    else if (queue >= PFE_IQOS_Q_COUNT)
    {
        is_enabled = FALSE;
    }
    else
    {
        is_enabled = pfe_gpi_cfg_wred_is_enabled(gpi->gpi_base_va, queue);
    }

    return is_enabled;
}

/*==================================================================================================*/
errno_t pfe_gpi_wred_enable(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        if (queue >= PFE_IQOS_Q_COUNT)
        {
            ret = EINVAL;
        }
        else if (TRUE == pfe_gpi_cfg_wred_is_enabled(gpi->gpi_base_va, queue))
        {
            ret = EOK;
        }
        else
        {
            pfe_gpi_cfg_wred_enable(gpi->gpi_base_va, queue);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_wred_disable(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        if (queue >= PFE_IQOS_Q_COUNT)
        {
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_wred_disable(gpi->gpi_base_va, queue);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_wred_set_prob(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 val)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        if ((queue >= PFE_IQOS_Q_COUNT) || (zone >= PFE_IQOS_WRED_ZONES_COUNT) || (val > PFE_IQOS_WRED_ZONE_PROB_MAX))
        {
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_wred_set_prob(gpi->gpi_base_va, queue, zone, val);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_wred_get_prob(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 *val)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret == EOK)
    {
        if ((queue >= PFE_IQOS_Q_COUNT) || (zone >= PFE_IQOS_WRED_ZONES_COUNT))
        {
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_wred_get_prob(gpi->gpi_base_va, queue, zone, val);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_wred_set_thr(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 val)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);

    if (ret == EOK)
    {
        if ((queue >= PFE_IQOS_Q_COUNT) || (thr >= PFE_IQOS_WRED_THR_COUNT))
        {
            ret = EINVAL;
        }
        else if ((queue == PFE_IQOS_Q_DMEM) && (val > PFE_IQOS_WRED_DMEM_THR_MAX))
        {
            ret = EINVAL;
        }
        else if ((queue != PFE_IQOS_Q_DMEM) && (val > PFE_IQOS_WRED_THR_MAX))
        {
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_wred_set_thr(gpi->gpi_base_va, queue, thr, val);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_wred_get_thr(const pfe_gpi_t *gpi, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 *val)
{
    errno_t ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);

    if (ret == EOK)
    {
        if ((queue >= PFE_IQOS_Q_COUNT) || (thr >= PFE_IQOS_WRED_THR_COUNT))
        {
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_wred_get_thr(gpi->gpi_base_va, queue, thr, val);
        }
    }

    return ret;
}

/*==================================================================================================*/
bool_t pfe_gpi_shp_is_enabled(const pfe_gpi_t *gpi, uint8 id)
{
    bool_t  is_enabled = FALSE;
    errno_t ret        = pfe_gpi_shp_args_checks(gpi, id);

    if (ret == EOK)
    {
        is_enabled = pfe_gpi_cfg_shp_is_enabled(gpi->gpi_base_va, id);
    }

    return is_enabled;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_enable(pfe_gpi_t *gpi, uint8 id)
{
    errno_t ret = pfe_gpi_shp_args_checks(gpi, id);

    if (ret == EOK)
    {
        if (TRUE != pfe_gpi_cfg_shp_is_enabled(gpi->gpi_base_va, id))
        {
            gpi->sys_clk_mhz  = pfe_gpi_cfg_get_sys_clk_mhz(gpi->cbus_base_va);
            gpi->clk_div_log2 = 0;
            pfe_gpi_cfg_shp_default_init(gpi->gpi_base_va, id);
            pfe_gpi_cfg_shp_enable(gpi->gpi_base_va, id);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_disable(const pfe_gpi_t *gpi, uint8 id)
{
    errno_t ret = pfe_gpi_shp_args_checks(gpi, id);

    if (ret == EOK)
    {
        pfe_gpi_cfg_shp_disable(gpi->gpi_base_va, id);
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_set_mode(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_rate_mode_t mode)
{
    errno_t ret = pfe_gpi_shp_args_checks(gpi, id);

    if (ret == EOK)
    {
        if (mode >= PFE_IQOS_SHP_RATE_MODE_COUNT)
        {
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_shp_set_mode(gpi->gpi_base_va, id, mode);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_get_mode(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_rate_mode_t *mode)
{
    errno_t ret = pfe_gpi_shp_args_checks(gpi, id);

    if (ret == EOK)
    {
        pfe_gpi_cfg_shp_get_mode(gpi->gpi_base_va, id, mode);
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_set_type(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_type_t type)
{
    errno_t ret = pfe_gpi_shp_args_checks(gpi, id);

    if (ret == EOK)
    {
        if (type >= PFE_IQOS_SHP_TYPE_COUNT)
        {
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_shp_set_type(gpi->gpi_base_va, id, type);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_get_type(const pfe_gpi_t *gpi, uint8 id, pfe_iqos_shp_type_t *type)
{
    errno_t ret = pfe_gpi_shp_args_checks(gpi, id);

    if (ret == EOK)
    {
        pfe_gpi_cfg_shp_get_type(gpi->gpi_base_va, id, type);
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_set_idle_slope(pfe_gpi_t *gpi, uint8 id, uint32 isl)
{
    pfe_iqos_shp_rate_mode_t mode = PFE_IQOS_SHP_BPS;
    uint32                 weight = 0U;
    bool_t                   is_bps;
    errno_t                  ret;

    ret = pfe_gpi_shp_args_checks(gpi, id);
    if (ret == EOK)
    {
        NXP_LOG_DEBUG("Shaper#%d - Set idle slope of: %u\n", id, (uint_t)isl);

        pfe_gpi_cfg_shp_get_mode(gpi->gpi_base_va, id, &mode);
        if (mode == PFE_IQOS_SHP_BPS)
        {
            is_bps = TRUE;
        }
        else
        {
            is_bps = FALSE;
        }

        gpi->clk_div_log2 = igqos_find_optimal_weight(isl, gpi->sys_clk_mhz, is_bps, &weight);

        NXP_LOG_DEBUG("Shaper#%d using PFE sys_clk value %u MHz, clkdiv: %u\n", id, (uint_t)(gpi->sys_clk_mhz), (uint_t)igqos_clk_div(gpi->clk_div_log2));
        NXP_LOG_DEBUG("Shaper#%d - Write weight of: %u\n", id, (uint_t)weight);

        pfe_gpi_cfg_shp_set_isl_weight(gpi->gpi_base_va, id, gpi->clk_div_log2, weight);
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_get_idle_slope(const pfe_gpi_t *gpi, uint8 id, uint32 *isl)
{
    pfe_iqos_shp_rate_mode_t mode = PFE_IQOS_SHP_BPS;
    uint32                 weight = 0U;
    bool_t                   is_bps;
    errno_t                  ret;

    ret = pfe_gpi_shp_args_checks(gpi, id);
    if (ret == EOK)
    {
        pfe_gpi_cfg_shp_get_mode(gpi->gpi_base_va, id, &mode);
        if (mode == PFE_IQOS_SHP_BPS)
        {
            is_bps = TRUE;
        }
        else
        {
            is_bps = FALSE;
        }

        NXP_LOG_DEBUG("Shaper#%d using PFE sys_clk value %u MHz, clkdiv: %u\n", id, (uint_t)(gpi->sys_clk_mhz), (uint_t)igqos_clk_div(gpi->clk_div_log2));

        pfe_gpi_cfg_shp_get_isl_weight(gpi->gpi_base_va, id, &weight);

        *isl = igqos_convert_weight_to_isl(weight, gpi->clk_div_log2, gpi->sys_clk_mhz, is_bps);

        NXP_LOG_DEBUG("Shaper#%d - Get idle slope of: %u\n", id, (uint_t)(*isl));
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_set_limits(const pfe_gpi_t *gpi, uint8 id, sint32 max_credit, sint32 min_credit)
{
    errno_t ret;

    ret = pfe_gpi_shp_args_checks(gpi, id);
    if (ret == EOK)
    {
        if ((max_credit > IGQOS_PORT_SHP_CREDIT_MAX) || (max_credit < 0))
        {
            NXP_LOG_ERROR("Max credit value exceeded\n");
            ret = EINVAL;
        }
        else if ((min_credit < -IGQOS_PORT_SHP_CREDIT_MAX) || (min_credit > 0))
        {
            NXP_LOG_ERROR("Min credit value exceeded\n");
            ret = EINVAL;
        }
        else
        {
            pfe_gpi_cfg_shp_set_limits(gpi->gpi_base_va, id, (uint32)max_credit, (uint32)-min_credit);
        }
    }

    return ret;
}

/*==================================================================================================*/
errno_t pfe_gpi_shp_get_limits(const pfe_gpi_t *gpi, uint8 id, sint32 *max_credit, sint32 *min_credit)
{
    uint32 abs_max_cred = 0U, abs_min_cred = 0U;
    errno_t  ret;

    ret = pfe_gpi_shp_args_checks(gpi, id);
    if (ret == EOK)
    {
        pfe_gpi_cfg_shp_get_limits(gpi->gpi_base_va, id, &abs_max_cred, &abs_min_cred);
        PfeDevAssert(abs_max_cred <= INT32_MAX);
        PfeDevAssert(abs_min_cred <= INT32_MAX);
        *max_credit = (sint32)abs_max_cred;
        *min_credit = -(sint32)abs_min_cred;
    }

    return ret;
}

/*==================================================================================================*/
/* note - the counter is reset to 0 after read (clear on read) */
errno_t pfe_gpi_shp_get_drop_cnt(const pfe_gpi_t *gpi, uint8 id, uint32 *cnt)
{
    errno_t ret;

    ret = pfe_gpi_shp_args_checks(gpi, id);
    if (ret == EOK)
    {
        *cnt = pfe_gpi_cfg_shp_get_drop_cnt(gpi->gpi_base_va, id);
    }

    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return GPI runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   gpi         The GPI instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_gpi_get_text_statistics(const pfe_gpi_t *gpi, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;
    errno_t  ret = pfe_gpi_null_arg_check_return(gpi, EINVAL);
    if (ret != EOK)
    {
        len = 0U;
    }
    else
    {
        len += pfe_gpi_cfg_get_text_stat(gpi->gpi_base_va, buf, buf_len, verb_level);
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get Gpi statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the Gpi block.
 * @param[in]   Gpi        The GPI instance
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic
 */
uint32 pfe_gpi_get_stat_value(const pfe_gpi_t * gpi, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == gpi))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = 0xFFFFFFFFU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = pfe_gpi_cfg_get_stat_value(gpi->gpi_base_va, stat_id);
    }
    return stat_value;
}

/**
 * @brief       Get Gpi statistic in numeric form for special registers
 * @details     This is a HW-specific function providing single statistic
 *              value from the gpi block.
 * @param[in]   gpi   The gpi instance
 * @param[out]  special_stats special statistic
 * @return      EOK if possible to get special statistics, otherwise return EINVAL
 *              when gpi or special_stats is NULL 
 */
errno_t pfe_gpi_get_special_stats(const pfe_gpi_t* gpi, pfe_gpi_special_stats_t* special_stats)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == gpi) || unlikely(NULL == special_stats))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_gpi_cfg_get_special_stats(gpi->gpi_base_va, special_stats);
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [151/185]: src\pfe_gpi_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_gpi_csr.h"
#include "pfe_bmu_csr.h"
#include "pfe_global_wsp.h"
#include "pfe_class_csr.h"
#include "pfe_feature_mgr.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static void igqos_class_read_entry_data(addr_t base_va, uint32 entry[]);
static void igqos_class_prepare_entry_data(addr_t base_va, const uint32 entry[]);
static void igqos_class_clear_entry_data(addr_t base_va);
static void igqos_class_request_entry_cmd(addr_t base_va, bool_t write, bool_t is_lru, uint32 addr);
static void igqos_class_write_flow_cmd(addr_t base_va, uint32 addr);
static void igqos_class_read_flow_cmd(addr_t base_va, uint32 addr);
static void igqos_class_write_lru_cmd(addr_t base_va, uint32 addr);
static uint32 igqos_wred_queue_enable_bit(pfe_iqos_queue_t queue);

/*==================================================================================================
                                       LOCAL FUNCTIONS
==================================================================================================*/

/*==================================================================================================*/
static uint32 igqos_wred_queue_enable_bit(pfe_iqos_queue_t queue)
{
    uint32 ret;

    switch (queue)
    {
        case PFE_IQOS_Q_DMEM:
        {
            ret = (uint32)IGQOS_QOS_WRED_DMEMQ_EN;
            break;
        }
        case PFE_IQOS_Q_LMEM:
        {
            ret = (uint32)IGQOS_QOS_WRED_LMEMQ_EN;
            break;
        }
        case PFE_IQOS_Q_RXF:
        {
            ret = (uint32)IGQOS_QOS_WRED_RXFQ_EN;
            break;
        }
        default:
        {
            ret = (uint32)IGQOS_QOS_WRED_DMEMQ_EN;
            break;
        }
    }

    return ret;
}

/*==================================================================================================*/
static void igqos_class_read_entry_data(addr_t base_va, uint32 entry[])
{
    uint32 ii;

    for (ii = 0; ii < ENTRY_DATA_REG_CNT; ii++)
    {
        const addr_t reg_offset = CSR_IGQOS_ENTRY_DATA_REG(ii);
        entry[ii] = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    }
}

/*==================================================================================================*/
static void igqos_class_prepare_entry_data(addr_t base_va, const uint32 entry[])
{
    uint32 ii;

    for (ii = 0; ii < ENTRY_DATA_REG_CNT; ii++)
    {
        const addr_t reg_offset = CSR_IGQOS_ENTRY_DATA_REG(ii);
        hal_write32(entry[ii], ADDR_BASE_OFFSET(base_va, reg_offset));
    }
}

/*==================================================================================================*/
static void igqos_class_clear_entry_data(addr_t base_va)
{
    uint32 ii;

    for (ii = 0; ii < ENTRY_DATA_REG_CNT; ii++)
    {
        const addr_t reg_offset = CSR_IGQOS_ENTRY_DATA_REG(ii);
        hal_write32(0U, ADDR_BASE_OFFSET(base_va, reg_offset));
    }
}

/*==================================================================================================*/
static void igqos_class_request_entry_cmd(addr_t base_va, bool_t write, bool_t is_lru, uint32 addr)
{
    uint32 val;

    val = CMDCNTRL_CMD_TAB_ADDR(addr);
    if (TRUE == write)
    {
        val |= CMDCNTRL_CMD_WRITE;
    }
    else
    {
        val |= CMDCNTRL_CMD_READ;
    }

    if (TRUE == is_lru)
    {
        val |= (uint32)CMDCNTRL_CMD_TAB_SELECT_LRU;
    }

    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_ENTRY_CMDCNTRL));
}

/*==================================================================================================*/
static void igqos_class_write_flow_cmd(addr_t base_va, uint32 addr)
{
    igqos_class_request_entry_cmd(base_va, TRUE, FALSE, addr);
}

/*==================================================================================================*/
static void igqos_class_read_flow_cmd(addr_t base_va, uint32 addr)
{
    igqos_class_request_entry_cmd(base_va, FALSE, FALSE, addr);
}

/*==================================================================================================*/
static void igqos_class_write_lru_cmd(addr_t base_va, uint32 addr)
{
    igqos_class_request_entry_cmd(base_va, TRUE, TRUE, addr);
}

/*==================================================================================================
                                       GLOBAL FUNCTIONS
==================================================================================================*/

/*==================================================================================================*/
/**
 * @brief       HW-specific initialization function
 * @param[in]   base_va Base address of GPI register space (virtual)
 */
void pfe_gpi_cfg_init(addr_t base_va, const pfe_gpi_cfg_t *cfg)
{
    uint32 regval;
    hal_write32(0x0U, ADDR_BASE_OFFSET(base_va, GPI_EMAC_1588_TIMESTAMP_EN));
    if (cfg->emac_1588_ts_en)
    {
        hal_write32(0xe01U, ADDR_BASE_OFFSET(base_va, GPI_EMAC_1588_TIMESTAMP_EN));
    }

    hal_write32(((cfg->alloc_retry_cycles << 16) | GPI_DDR_BUF_EN | GPI_LMEM_BUF_EN), ADDR_BASE_OFFSET(base_va, GPI_RX_CONFIG));
    hal_write32((uint32)(PFE_CFG_DDR_HDR_SIZE << 16) | cfg->lmem_header_size, ADDR_BASE_OFFSET(base_va, GPI_HDR_SIZE));
    hal_write32((PFE_CFG_DDR_BUF_SIZE << 16) | PFE_CFG_LMEM_BUF_SIZE, ADDR_BASE_OFFSET(base_va, GPI_BUF_SIZE));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU1_BASE_ADDR + BMU_ALLOC_CTRL, ADDR_BASE_OFFSET(base_va, GPI_LMEM_ALLOC_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU1_BASE_ADDR + BMU_FREE_CTRL, ADDR_BASE_OFFSET(base_va, GPI_LMEM_FREE_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU2_BASE_ADDR + BMU_ALLOC_CTRL, ADDR_BASE_OFFSET(base_va, GPI_DDR_ALLOC_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU2_BASE_ADDR + BMU_FREE_CTRL, ADDR_BASE_OFFSET(base_va, GPI_DDR_FREE_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CLASS_INQ_PKTPTR, ADDR_BASE_OFFSET(base_va, GPI_CLASS_ADDR));
    hal_write32(PFE_CFG_DDR_HDR_SIZE, ADDR_BASE_OFFSET(base_va, GPI_DDR_DATA_OFFSET));
    hal_write32(0x30U, ADDR_BASE_OFFSET(base_va, GPI_LMEM_DATA_OFFSET));
    hal_write32(cfg->lmem_header_size, ADDR_BASE_OFFSET(base_va, GPI_LMEM_SEC_BUF_DATA_OFFSET));
    hal_write32(cfg->gpi_tmlf_txthres, ADDR_BASE_OFFSET(base_va, GPI_TMLF_TX));
    hal_write32(cfg->gpi_dtx_aseq_len, ADDR_BASE_OFFSET(base_va, GPI_DTX_ASEQ));
    hal_write32(1, ADDR_BASE_OFFSET(base_va, GPI_CSR_TOE_CHKSUM_EN));
    if ((TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3)) || (cfg->g2_ordered_class_writes))
    {
        regval = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_CSR_AXI_WRITE_DONE_ADDR));
        regval |= 0x3U;
        hal_write32(regval, ADDR_BASE_OFFSET(base_va, GPI_CSR_AXI_WRITE_DONE_ADDR));
    }
    hal_write32(0xFFFFFFFFU, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_LRU_TIMER_VALUE));
}

/*==================================================================================================*/
/**
 * @brief       Reset the GPI
 * @param[in]   base_va Base address of GPI register space (virtual)
 * @retval      EOK Success
 * @retval      ETIMEDOUT Reset procedure timed-out
 */
errno_t pfe_gpi_cfg_reset(addr_t base_va)
{
    errno_t ret = EOK;
    uint32 timeout = 20U;
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_CTRL));

    reg |= 0x2U;

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, GPI_CTRL));

    do
    {
        oal_time_usleep(100U);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_CTRL));
        --timeout;
    } while (((reg & 0x2U) != 0U) && (timeout > 0U));

    if (0U == timeout)
    {
        ret = ETIMEDOUT;
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Enable the GPI module
 * @param[in]   base_va Base address of GPI register space (virtual)
 */
void pfe_gpi_cfg_enable(addr_t base_va)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_CTRL));

    hal_write32(reg | 0x1U, ADDR_BASE_OFFSET(base_va, GPI_CTRL));
}

/*==================================================================================================*/
/**
 * @brief       Disable the GPI module
 * @param[in]   base_va Base address of GPI register space (virtual)
 */
void pfe_gpi_cfg_disable(addr_t base_va)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_CTRL));

    hal_write32(reg & ~(0x1U), ADDR_BASE_OFFSET(base_va, GPI_CTRL));
}

/*==================================================================================================*/
/* Ingress QoS */
void pfe_gpi_cfg_qos_default_init(addr_t base_va)
{
    /* reset CONTROL */
    hal_write32(0, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_CONTROL));

    /* reset sub-blocks: wred, shapers */
    pfe_gpi_cfg_wred_default_init(base_va);
    pfe_gpi_cfg_shp_default_init(base_va, 0);
    pfe_gpi_cfg_shp_default_init(base_va, 1);

    /* reset TPID */
    hal_write32(((uint32)IGQOS_TPID_DOT1Q << 16) | IGQOS_TPID_DOT1Q, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_TPID));
    /* reset IGQOS CLASS */
    hal_write32(IGQOS_CLASS_TPID0_EN | IGQOS_CLASS_TPID1_EN, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_CLASS));
}

/*==================================================================================================*/
void pfe_gpi_cfg_qos_enable(addr_t base_va)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_CONTROL));

    reg |= (uint32)IGQOS_CONTROL_QOS_EN;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_CONTROL));
}

/*==================================================================================================*/
void pfe_gpi_cfg_qos_disable(addr_t base_va)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_CONTROL));

    reg &= (uint32)(~(uint32)IGQOS_CONTROL_QOS_EN);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_CONTROL));
}

/*==================================================================================================*/
bool_t pfe_gpi_cfg_qos_is_enabled(addr_t base_va)
{
    bool_t ret = FALSE;
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_CONTROL));

    if ((reg & IGQOS_CONTROL_QOS_EN) == IGQOS_CONTROL_QOS_EN)
    {
        ret = TRUE;
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Write classification table entry at given address
 * @param[in]   base_va Base address of GPI register space (virtual)
 * @param[in]   addr    Classification table entry address, from 0 to @CSR_IGQOS_ENTRY_TABLE_LEN - 1
 * @param[in]   entry[] Table entry data as array of 8 x 32b values
 * @param[in]   base_va Base address of GPI register space (virtual)
 */
void pfe_gpi_cfg_qos_write_flow_entry_req(addr_t base_va, uint32 addr, const uint32 entry[])
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        igqos_class_prepare_entry_data(base_va, entry);
        igqos_class_write_flow_cmd(base_va, addr);
    }
}

/*==================================================================================================*/
void pfe_gpi_cfg_qos_clear_flow_entry_req(addr_t base_va, uint32 addr)
{
    igqos_class_clear_entry_data(base_va);
    igqos_class_write_flow_cmd(base_va, addr);
}

/*==================================================================================================*/
void pfe_gpi_cfg_qos_clear_lru_entry_req(addr_t base_va, uint32 addr)
{
    igqos_class_clear_entry_data(base_va);
    igqos_class_write_lru_cmd(base_va, addr);
}

/*==================================================================================================*/
void pfe_gpi_cfg_qos_rd_fl_entry_req(addr_t base_va, uint32 addr)
{
    igqos_class_read_flow_cmd(base_va, addr);
}

/*==================================================================================================*/
void pfe_gpi_cfg_qos_rd_fl_entry_resp(addr_t base_va, uint32 entry[])
{
    igqos_class_read_entry_data(base_va, entry);
}

/*==================================================================================================*/
bool_t pfe_gpi_cfg_qos_entry_ready(addr_t base_va)
{
    bool_t ret = FALSE;
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_ENTRY_CMDSTATUS));

    if (0U != (reg & 0x1U))
    {
        ret = TRUE;
    }

    return ret;
}

/*==================================================================================================*/
/* WRED configuration */
void pfe_gpi_cfg_wred_default_init(addr_t base_va)
{
    uint32 val;

    /* reset the IGQOS_QOS register */
    hal_write32(0, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_QOS));

    val  = (uint32)PFE_IQOS_WRED_WEIGHT_DEFAULT << 16;
    val |= (uint32)PFE_IQOS_WRED_ZONE4_PROB_DEFAULT << 12;
    val |= (uint32)PFE_IQOS_WRED_ZONE3_PROB_DEFAULT << 8;
    val |= PFE_IQOS_WRED_ZONE2_PROB_DEFAULT << 4;
    val |= PFE_IQOS_WRED_ZONE1_PROB_DEFAULT;

    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IQGOS_DMEMQ_ZONE_PROB));
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_LMEMQ_ZONE_PROB));
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_RXFQ_ZONE_PROB));

    val = PFE_IQOS_WRED_DMEM_FULL_THR_DEFAULT;
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_DMEMQ_FULL_THRESH));

    val = ((uint32)PFE_IQOS_WRED_DMEM_MIN_THR_DEFAULT << 16) |
          PFE_IQOS_WRED_DMEM_MAX_THR_DEFAULT;
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_DMEMQ_DROP_THRESH));

    val = PFE_IQOS_WRED_FULL_THR_DEFAULT;
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_LMEMQ_FULL_THRESH));
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_RXFQ_FULL_THRESH));

    val = ((uint32)PFE_IQOS_WRED_MIN_THR_DEFAULT << 16) |
          PFE_IQOS_WRED_MAX_THR_DEFAULT;
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_LMEMQ_DROP_THRESH));
    hal_write32(val, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_RXFQ_DROP_THRESH));
}

/*==================================================================================================*/
void pfe_gpi_cfg_wred_enable(addr_t base_va, pfe_iqos_queue_t queue)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_QOS));

    reg |= igqos_wred_queue_enable_bit(queue);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_QOS));
}

/*==================================================================================================*/
void pfe_gpi_cfg_wred_disable(addr_t base_va, pfe_iqos_queue_t queue)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_QOS));

    reg &= ~igqos_wred_queue_enable_bit(queue);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_QOS));
}

/*==================================================================================================*/
bool_t pfe_gpi_cfg_wred_is_enabled(addr_t base_va, pfe_iqos_queue_t queue)
{
    bool_t ret = FALSE;
    uint32 wred_q_en = igqos_wred_queue_enable_bit(queue);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_QOS));

    if ((reg & wred_q_en) == wred_q_en)
    {
        ret = TRUE;
    }

    return ret;
}

/*==================================================================================================*/
void pfe_gpi_cfg_wred_set_prob(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 val)
{
    const addr_t reg_offset = CSR_IQGOS_ZONE_PROB((uint32)queue);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));

    reg &= ~((uint32)0xfU << ((uint8)zone * 4U));
    reg |= (((uint32)0xfU & val) << ((uint8)zone * 4U));
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, reg_offset));
}

/*==================================================================================================*/
void pfe_gpi_cfg_wred_get_prob(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_zone_t zone, uint8 *val)
{
    const addr_t reg_offset = CSR_IQGOS_ZONE_PROB((uint32)queue);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));

    reg >>= ((uint8)zone * 4U);
    reg &= (uint32)0xfU;
    *val = (uint8)reg;
}

/*==================================================================================================*/
void pfe_gpi_cfg_wred_set_thr(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 val)
{
    switch (thr)
    {
        case PFE_IQOS_WRED_FULL_THR:
        {
            const addr_t reg_offset = CSR_IQGOS_FULL_THRESH((uint32)queue);
            hal_write32(val, ADDR_BASE_OFFSET(base_va, reg_offset));
            break;
        }
        case PFE_IQOS_WRED_MIN_THR:
        {
            const addr_t reg_offset = CSR_IQGOS_DROP_THRESH((uint32)queue);
            uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
            reg = (reg & 0xFFFFUL) | ((uint32)val << 16); /* update upper 16 bits */
            hal_write32(reg, ADDR_BASE_OFFSET(base_va, reg_offset));
            break;
        }
        case PFE_IQOS_WRED_MAX_THR:
        {
            const addr_t reg_offset = CSR_IQGOS_DROP_THRESH((uint32)queue);
            uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
            reg = (reg & 0xFFFF0000UL) | ((uint32)val); /* update lower 16 bits */
            hal_write32(reg, ADDR_BASE_OFFSET(base_va, reg_offset));
            break;
        }
        default:
        {
            /* Invalid threshold */
            break;
        }
    }
}

/*==================================================================================================*/
void pfe_gpi_cfg_wred_get_thr(addr_t base_va, pfe_iqos_queue_t queue, pfe_iqos_wred_thr_t thr, uint16 *val)
{
    switch (thr)
    {
        case PFE_IQOS_WRED_FULL_THR:
        {
            const addr_t reg_offset = CSR_IQGOS_FULL_THRESH((uint32)queue);
            const uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
            *val = (uint16)(reg & UINT16_MAX);
            break;
        }
        case PFE_IQOS_WRED_MIN_THR:
        {
            const addr_t reg_offset = CSR_IQGOS_DROP_THRESH((uint32)queue);
            const uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
            *val = (uint16)((reg >> 16) & UINT16_MAX); /* upper 16 bits */
            break;
        }
        case PFE_IQOS_WRED_MAX_THR:
        {
            const addr_t reg_offset = CSR_IQGOS_DROP_THRESH((uint32)queue);
            const uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
            *val = (uint16)(reg & UINT16_MAX);         /* lower 16 bits */
            break;
        }
        default:
        {
            /* Invalid threshold */
            break;
        }
    }
}

/*==================================================================================================*/
/* Shaper configuration */
uint32 pfe_gpi_cfg_get_sys_clk_mhz(addr_t cbus_base_va)
{
    return hal_read32(ADDR_BASE_OFFSET(cbus_base_va, CBUS_GLOBAL_CSR_BASE_ADDR + WSP_CLK_FRQ)) & UINT16_MAX;
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_default_init(addr_t base_va, uint8 id)
{
    /* reset the weight reg */
    addr_t reg_offset = CSR_IGQOS_PORT_SHP_WGHT(id);
    hal_write32(0, ADDR_BASE_OFFSET(base_va, reg_offset));
    /* reset the min credit reg */
    reg_offset = GPI_PORT_SHP_MIN_CREDIT(id);
    hal_write32(0, ADDR_BASE_OFFSET(base_va, reg_offset));

    /* reset CONFIG settings for shaper #id */
    pfe_gpi_cfg_shp_set_type(base_va, id, PFE_IQOS_SHP_PORT_LEVEL);
    pfe_gpi_cfg_shp_set_mode(base_va, id, PFE_IQOS_SHP_BPS);

    /* reset CTRL */
    reg_offset = CSR_IGQOS_PORT_SHP_CTRL(id);
    hal_write32(0, ADDR_BASE_OFFSET(base_va, reg_offset));
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_enable(addr_t base_va, uint8 id)
{
    const addr_t reg_offset = CSR_IGQOS_PORT_SHP_CTRL(id);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    reg |= 0x1U;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, reg_offset));
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_disable(addr_t base_va, uint8 id)
{
    const addr_t reg_offset = CSR_IGQOS_PORT_SHP_CTRL(id);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    reg &= ~(uint32)0x1U;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, reg_offset));
}

/*==================================================================================================*/
bool_t pfe_gpi_cfg_shp_is_enabled(addr_t base_va, uint8 id)
{
    bool_t ret = FALSE;
    const addr_t reg_offset = CSR_IGQOS_PORT_SHP_CTRL(id);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));

    if (0U != (reg & 0x1U))
    {
        ret = TRUE;
    }

    return ret;
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_set_type(addr_t base_va, uint8 id, pfe_iqos_shp_type_t type)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_PORT_SHP_CONFIG));

    reg &= (uint32)(~((uint32)IGQOS_PORT_SHP_TYPE_MASK << IGQOS_PORT_SHP_TYPE_POS(id)));
    reg |= (((uint32)type & IGQOS_PORT_SHP_TYPE_MASK) << IGQOS_PORT_SHP_TYPE_POS(id));

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_PORT_SHP_CONFIG));
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_get_type(addr_t base_va, uint8 id, pfe_iqos_shp_type_t *type)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_PORT_SHP_CONFIG));

    reg >>= IGQOS_PORT_SHP_TYPE_POS(id);
    reg  &= (uint32)IGQOS_PORT_SHP_TYPE_MASK;
    switch (reg)
    {
        case 0U:
        {
            *type = PFE_IQOS_SHP_PORT_LEVEL;
            break;
        }
        case 1U:
        {
            *type = PFE_IQOS_SHP_BCAST;
            break;
        }
        case 2U:
        {
            *type = PFE_IQOS_SHP_MCAST;
            break;
        }
        default:
        {
            /* Invalid type */
            break;
        }
    }
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_set_mode(addr_t base_va, uint8 id, pfe_iqos_shp_rate_mode_t mode)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_PORT_SHP_CONFIG));

    reg &= (uint32)(~(IGQOS_PORT_SHP_MODE_PPS(id)));
    if (PFE_IQOS_SHP_PPS == mode)
    {
        reg |= (uint32)IGQOS_PORT_SHP_MODE_PPS(id);
    }

    hal_write32(reg, ADDR_BASE_OFFSET(base_va, CSR_IGQOS_PORT_SHP_CONFIG));
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_get_mode(addr_t base_va, uint8 id, pfe_iqos_shp_rate_mode_t *mode)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_PORT_SHP_CONFIG));

    if (0U != (reg & IGQOS_PORT_SHP_MODE_PPS(id)))
    {
        *mode = PFE_IQOS_SHP_PPS;
    }
    else
    {
        *mode = PFE_IQOS_SHP_BPS;
    }
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_set_isl_weight(addr_t base_va, uint8 id, uint32 clk_div_log2, uint32 weight)
{
    addr_t reg_offset = CSR_IGQOS_PORT_SHP_CTRL(id);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    reg &= (uint32)(~(IGQOS_PORT_SHP_CLKDIV_MASK << IGQOS_PORT_SHP_CLKDIV_POS));
    reg |= (clk_div_log2 & IGQOS_PORT_SHP_CLKDIV_MASK) << IGQOS_PORT_SHP_CLKDIV_POS;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, reg_offset));

    reg_offset = CSR_IGQOS_PORT_SHP_WGHT(id);
    hal_write32(weight & IGQOS_PORT_SHP_WEIGHT_MASK, ADDR_BASE_OFFSET(base_va, reg_offset));
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_get_isl_weight(addr_t base_va, uint8 id, uint32 *weight)
{
    addr_t reg_offset = CSR_IGQOS_PORT_SHP_WGHT(id);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    *weight = reg & IGQOS_PORT_SHP_WEIGHT_MASK;
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_set_limits(addr_t base_va, uint8 id, uint32 max_credit, uint32 min_credit)
{
    addr_t reg_offset = CSR_IGQOS_PORT_SHP_MIN_CREDIT(id);
    uint32 reg;

    /* reset MIN_CREDIT reg */
    hal_write32(min_credit & IGQOS_PORT_SHP_CREDIT_MASK, ADDR_BASE_OFFSET(base_va, reg_offset));

    reg_offset = CSR_IGQOS_PORT_SHP_CTRL(id);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    reg &= ~(IGQOS_PORT_SHP_CREDIT_MASK << IGQOS_PORT_SHP_MAX_CREDIT_POS);
    reg |= ((max_credit & IGQOS_PORT_SHP_CREDIT_MASK) << IGQOS_PORT_SHP_MAX_CREDIT_POS);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, reg_offset));
}

/*==================================================================================================*/
void pfe_gpi_cfg_shp_get_limits(addr_t base_va, uint8 id, uint32 *max_credit, uint32 *min_credit)
{
    addr_t reg_offset = CSR_IGQOS_PORT_SHP_MIN_CREDIT(id);
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    reg &= IGQOS_PORT_SHP_CREDIT_MASK;
    *min_credit = reg;

    reg_offset = CSR_IGQOS_PORT_SHP_CTRL(id);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
    reg >>= IGQOS_PORT_SHP_MAX_CREDIT_POS;
    reg &= IGQOS_PORT_SHP_CREDIT_MASK;
    *max_credit = reg;
}

/*==================================================================================================*/
/* read the shaper drop packets counter register, which is clear on read */
uint32 pfe_gpi_cfg_shp_get_drop_cnt(addr_t base_va, uint8 id)
{
    const addr_t reg_offset = CSR_IGQOS_STAT_SHAPER_DROP_CNT(id);
    return hal_read32(ADDR_BASE_OFFSET(base_va, reg_offset));
}

#if defined(PFE_CFG_TEXT_STATS)
/*==================================================================================================*/
/**
 * @brief       Get GPI statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the GPI block.
 * @param[in]   base_va     Base address of GPI register space (virtual)
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_gpi_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;
    uint32 reg;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Debug registers */
        if(verb_level >= 10U)
        {
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_FIFO_DEBUG   : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_FIFO_DEBUG)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_TX_DBUG_REG1 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_TX_DBUG_REG1)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_TX_DBUG_REG2 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_TX_DBUG_REG2)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_TX_DBUG_REG3 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_TX_DBUG_REG3)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_TX_DBUG_REG4 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_TX_DBUG_REG4)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_TX_DBUG_REG5 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_TX_DBUG_REG5)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_TX_DBUG_REG6 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_TX_DBUG_REG6)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_RX_DBUG_REG1 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_RX_DBUG_REG1)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_RX_DBUG_REG2 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_RX_DBUG_REG2)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "GPI_FIFO_STATUS  : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va, GPI_FIFO_STATUS)));
        }

        /*  Get version */
        if(verb_level >= 9U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_VERSION));
            len += oal_util_snprintf(buf + len, size - len, "Revision             : 0x%x\n", (reg >> 24) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "Version              : 0x%x\n", (reg >> 16) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "ID                   : 0x%x\n", reg & 0xffffU);
        }

        /*  Ingress QoS counters */
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_QUEUE_STATUS));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS queue status   : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_STAT_CLASS_DROP_CNT));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS CLASS drop cnt : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_STAT_LMEM_QUEUE_DROP_CNT));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS LMEM drop cnt  : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_STAT_DMEM_QUEUE_DROP_CNT));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS DMEM drop cnt  : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_STAT_RXF_QUEUE_DROP_CNT));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS RXF drop cnt   : 0x%x\n", reg);
        reg = pfe_gpi_cfg_shp_get_drop_cnt(base_va, 0);
        len += oal_util_snprintf(buf + len, size - len, "IGQOS SHP0 drop cnt  : 0x%x\n", reg);
        reg = pfe_gpi_cfg_shp_get_drop_cnt(base_va, 1);
        len += oal_util_snprintf(buf + len, size - len, "IGQOS SHP1 drop cnt  : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_STAT_MANAGED_PACKET_CNT));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS managed pkts   : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_STAT_UNMANAGED_PACKET_CNT));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS unmanaged pkts : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va, CSR_IGQOS_STAT_RESERVED_PACKET_CNT));
        len += oal_util_snprintf(buf + len, size - len, "IGQOS reserved pkts  : 0x%x\n", reg);

        reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_FIFO_STATUS));
        len += oal_util_snprintf(buf + len, size - len, "TX Underrun          : 0x%x\n", reg);
        hal_write32(0, ADDR_BASE_OFFSET(base_va, GPI_FIFO_STATUS));

        reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_FIFO_DEBUG));
        len += oal_util_snprintf(buf + len, size - len, "TX FIFO Packets      : 0x%x\n", reg & 0x1fU);
        len += oal_util_snprintf(buf + len, size - len, "RX FIFO Packets      : 0x%x\n", (reg >> 6) & 0x1fU);
        len += oal_util_snprintf(buf + len, size - len, "TX FIFO Level        : 0x%x\n", (reg >> 12) & 0xffU);
        len += oal_util_snprintf(buf + len, size - len, "RX FIFO Level        : 0x%x\n", (reg >> 20) & 0xffU);

        reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_DTX_ASEQ));
        len += oal_util_snprintf(buf + len, size - len, "ASEQ Length          : 0x%x\n", reg);

        reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_EMAC_1588_TIMESTAMP_EN));
        len += oal_util_snprintf(buf + len, size - len, "1588 Enable register : 0x%x\n", reg);

        reg = hal_read32(ADDR_BASE_OFFSET(base_va, GPI_OVERRUN_DROPCNT));
        len += oal_util_snprintf(buf + len, size - len, "Overrun Drop Counter : 0x%x\n", reg);
        hal_write32(0, ADDR_BASE_OFFSET(base_va, GPI_OVERRUN_DROPCNT));
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */


/*==================================================================================================*/
/**
 * @brief       Get GPI statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the GPI block.
 * @param[in]   base_va     Base address of GPI register space (virtual)
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic
 */
uint32 pfe_gpi_cfg_get_stat_value(addr_t base_va, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = PFE_INVALID_STAT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = hal_read32(ADDR_BASE_OFFSET(base_va, stat_id));
    }
    return stat_value;
}

/*==================================================================================================*/
/**
 * @brief       Get Gpi statistic in numeric form for special registers
 * @details     This is a HW-specific function providing single statistic
 *              value from the gpi block.
 * @param[in]   base_va     Base address of Gpi register space (virtual)
 * @param[out]  special_stats  Point to required special statistic
 */
void pfe_gpi_cfg_get_special_stats(addr_t base_va, pfe_gpi_special_stats_t* special_stats)
{
    /*assign special_stats*/
    special_stats->revision = (pfe_gpi_cfg_get_stat_value(base_va, GPI_VERSION) >> 24) &0xFFU;
    special_stats->version = (pfe_gpi_cfg_get_stat_value(base_va, GPI_VERSION) >> 16) &0xFFU;
    special_stats->id = pfe_gpi_cfg_get_stat_value(base_va, GPI_VERSION) & 0xFFFFU;
    special_stats->tx_fifo_packets =  (pfe_gpi_cfg_get_stat_value(base_va, GPI_FIFO_DEBUG)) & 0x1FU;
    special_stats->rx_fifo_packets = ((pfe_gpi_cfg_get_stat_value(base_va, GPI_FIFO_DEBUG)) >> 6) & 0x1FU;
    special_stats->tx_fifo_level =  ((pfe_gpi_cfg_get_stat_value(base_va, GPI_FIFO_DEBUG)) >> 12) & 0xFFU;
    special_stats->rx_fifo_level =  ((pfe_gpi_cfg_get_stat_value(base_va, GPI_FIFO_DEBUG)) >> 20) & 0xFFU;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [152/185]: src\pfe_hif.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_cbus.h"
#include "pfe_hif.h"
#include "pfe_platform_cfg.h"
#include "pfe_hif_csr.h"

struct pfe_hif_tag
{
    pfe_hif_chnl_id_t configured_channels_mask; /* configured channels */
    addr_t cbus_base_va;            /*  CBUS base virtual address */
    pfe_hif_chnl_t channels[HIF_CFG_MAX_CHANNELS];
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    bool_t disable_master_detect;   /* Shall be Master-detect disabled? */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_hif_t hif_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static void pfe_hif_destroy_chnl(pfe_hif_t *hif, sint32 count);
static errno_t pfe_hif_create_bind_chnl(pfe_hif_t *hif, pfe_hif_chnl_id_t channels_mask);

#ifdef PFE_CFG_PFE_MASTER

/*==================================================================================================*/
/**
 * @brief       Master HIF ISR
 * @param[in]   hif The HIF instance
 * @return      EOK if interrupt has been processed
 */
errno_t pfe_hif_isr(pfe_hif_t *hif)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_hif_cfg_isr(hif->cbus_base_va);
    }
    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Mask HIF interrupts
 * @details     Only affects HIF IRQs, not channel IRQs.
 * @param[in]   hif The HIF instance
 */
void pfe_hif_irq_mask(pfe_hif_t *hif)
{
    pfe_hif_cfg_irq_mask(hif->cbus_base_va);
}

/*==================================================================================================*/
/**
 * @brief       Unmask HIF interrupts
 * @details     Only affects HIF IRQs, not channel IRQs.
 * @param[in]   hif The HIF instance
 */
void pfe_hif_irq_unmask(pfe_hif_t *hif)
{
    pfe_hif_cfg_irq_unmask(hif->cbus_base_va);
}
#endif /* PFE_CFG_PFE_MASTER */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
/*==================================================================================================*/
void pfe_hif_set_master_detect_cfg(pfe_hif_t *hif, bool_t on)
{
    hif->disable_master_detect = (!on);
}

/*==================================================================================================*/
bool_t pfe_hif_get_master_detect_cfg(const pfe_hif_t *hif)
{
    return (!hif->disable_master_detect);
}
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

/*==================================================================================================*/
/**
 * @brief       Destroy created channels with attached rings
 * @param[in]   hif The HIF instance
 * @param[in]   count index of last channel to destroy. e.g value of 2 will destroy channels 2,1,0
 */
static void pfe_hif_destroy_chnl(pfe_hif_t *hif, sint32 count)
{
    sint32 ii = count;
    uint32 channels_mask = (uint32)(1U << ii);
    /*  Destroy all created channels with all attached rings */
    /*  Destroy already created channels including rings if attached */
    for (; ii >= 0; ii--)
    {
        if(0U != ((uint32)hif->configured_channels_mask & channels_mask))
        {
            pfe_hif_chnl_destroy(&hif->channels[ii]);
            hif->configured_channels_mask &= ~channels_mask;
        }
        channels_mask >>= 1U;
    }
#ifdef PFE_CFG_PFE_MASTER
    /*  Disable HIF hardware */
    pfe_hif_cfg_fini(hif->cbus_base_va);
#endif /* PFE_CFG_PFE_MASTER */
}

/*==================================================================================================*/
/**
 * @brief       Create and bind hif channel
 * @param[in]   hif The HIF instance
 * @param[in]   channels_mask Bitmask specifying channels to be managed by the instance.
 * @return      EOK if success, otherwise if failed
 */
static errno_t pfe_hif_create_bind_chnl(pfe_hif_t *hif, pfe_hif_chnl_id_t channels_mask)
{
    errno_t ret = EOK;
    sint32 ii;

    for (ii = 0; ii < (sint32)HIF_CFG_MAX_CHANNELS; ii++)
    {
        if (0U != ((uint32)channels_mask & (uint32)(0x1U << ii)))
        {
            ret = pfe_hif_chnl_create_mcal(&hif->channels[ii], hif->cbus_base_va, (uint32)ii, NULL);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Couldn't create channel\n");
                pfe_hif_destroy_chnl(hif, ii);
                break;
            }
            else
            {
                hif->configured_channels_mask |= (uint32)(1U << ii);

                /*  Disable both directions */
                pfe_hif_chnl_rx_disable(&hif->channels[ii]);
                pfe_hif_chnl_tx_disable(&hif->channels[ii]);
            }
        }
        else
        {
            (void)autolibc_memset(&hif->channels[ii], 0, sizeof(pfe_hif_chnl_t));
            hif->channels[ii].cbus_base_va = hif->cbus_base_va;
            hif->channels[ii].id = ii;
        }
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Create new HIF instance
 * @details     Creates and initializes HIF instance
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   channels_mask Bitmask specifying channels to be managed by the instance.
 * @return      The HIF instance or NULL if failed
 */
pfe_hif_t *pfe_hif_create(addr_t cbus_base_va, pfe_hif_chnl_id_t channels_mask)
{

    pfe_hif_t *hif;
    errno_t ret;
#ifdef PFE_CFG_PFE_MASTER
    sint32    ii = 0;
#endif /* PFE_CFG_PFE_MASTER */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        hif = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != ((uint32)channels_mask & (~0xFUL)))
        {
            hif = NULL;
        }
        else
        {
            hif = &hif_instance;
            (void)autolibc_memset(hif, 0, sizeof(pfe_hif_t));
            hif->cbus_base_va = cbus_base_va;

#ifdef PFE_CFG_PFE_MASTER
            /*  Do HIF HW initialization */
            ret = pfe_hif_cfg_init(hif->cbus_base_va);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("HIF configuration failed: %d\n", ret);
                pfe_hif_destroy_chnl(hif, ii);
                hif = NULL;
            }
            else
#endif /* PFE_CFG_PFE_MASTER */
            {
                ret = pfe_hif_create_bind_chnl(hif, channels_mask);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("HIF configuration failed: %d\n", ret);
                    hif = NULL;
                }
            }
        }
    }
    return hif;
}

/*==================================================================================================*/
/**
 * @brief       Get channel instance according to its ID. Return NULL if channel is not configured.
 * @details     The channel ID corresponds with indexing within
 *              the hardware (0, 1, 2 ... HIF_CFG_MAX_CHANNELS-1)
 * @param[in]   hif The HIF instance
 * @param[in]   channel_id The channel ID
 * @return      The HIF channel instance or NULL if failed or does not exists/not configured
 */
pfe_hif_chnl_t *pfe_hif_get_channel(pfe_hif_t *hif, pfe_hif_chnl_id_t channel_id)
{
    uint32 ii;
    pfe_hif_chnl_t *entry = NULL_PTR;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get array index from channel ID */
        if (0U != ((uint32)hif->configured_channels_mask & channel_id))
        {
            for (ii = 0; ii < HIF_CFG_MAX_CHANNELS; ii++)
            {
                if (0U != ((uint32)channel_id & (uint32)(1U << ii)))
                {
                    entry = &(hif->channels[ii]);
                    break;
                }
            }
        }
    }
    return entry;
}

/**
 * @brief       Get channel instance according to its PHY IF ID. PHY IF doesn't correspond to a HIF channel
 * @param[in]   hif The HIF instance
 * @param[in]   phy The PHY IF ID (PFE_PHY_IF_ID_HIF0-3)
 * @return      The HIF channel instance or NULL if failed or does not exist
 */
pfe_hif_chnl_t *pfe_hif_get_channel_phy(pfe_hif_t *hif, pfe_ct_phy_if_id_t phy)
{
    pfe_hif_chnl_t * ret = NULL_PTR;
    if((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
    {
        ret = &(hif->channels[(uint32)phy - (uint32)PFE_PHY_IF_ID_HIF0]);
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Destroy HIF instance
 * @param[in]   hif The HIF instance
 */
void pfe_hif_destroy(pfe_hif_t *hif)
{
    uint32 ii;
    uint32 channels_mask = 1U;

    if (NULL != hif)
    {

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        /* Clean Master detect flags for all HIF channels */
        pfe_hif_clear_master_up(hif);
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
        /* Clear timer ownership for all HIF channels */
        pfe_hif_clear_emac_timer_ownership(hif);

        /* Disable all HIF channels */
        pfe_hif_cfg_stop_all_chnl_dma();
#endif /* PFE_CFG_PFE_MASTER */

        for (ii=0U; ii<HIF_CFG_MAX_CHANNELS; ii++)
        {
            if(0U != ((uint32)hif->configured_channels_mask & channels_mask))
            {
#ifdef PFE_CFG_PFE_SLAVE
                /* For master: all channels were disabled above */
                /* For slave: disable only HIF channel which we have configured: */
                pfe_hif_chnl_rx_disable(&hif->channels[ii]);
                pfe_hif_chnl_tx_disable(&hif->channels[ii]);
#endif
                pfe_hif_chnl_destroy(&hif->channels[ii]);
                hif->configured_channels_mask &= ~channels_mask;
            }
            channels_mask <<= 1U;
        }

        /*  Finalize the HIF */
        pfe_hif_cfg_fini(hif->cbus_base_va);
    }
}

#ifdef PFE_CFG_PFE_MASTER
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
/*==================================================================================================*/
/**
 * @brief       Reset master detect flags in all HIF channels
 * @param[in]   hif The HIF instance
 */
void pfe_hif_clear_master_up(const pfe_hif_t *hif)
{
    uint32 ii;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (ii = 0U; ii < HIF_CFG_MAX_CHANNELS; ii++)
        {
            /* We can't use channel object because we need to set also
            not configured channels */
            (void)pfe_hif_chnl_cfg_set_master_up(hif->cbus_base_va, ii, FALSE);
        }
    }
}

/*==================================================================================================*/
/**
 * @brief       Set master detect flags in all HIF channels
 * @details     Set flag to MASTER_UP and optionally to HIF_OCCUPIED
 * @param[in]   hif The HIF instance
 */
void pfe_hif_set_master_up(const pfe_hif_t *hif)
{
    uint32 ii;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (ii = 0U; ii < HIF_CFG_MAX_CHANNELS; ii++)
        {
            /* We can't use channel object because we need to set also
           not configured channels */
            if (0U != ((uint32)hif->configured_channels_mask & ((uint32)1U << ii)))
            {
                (void)pfe_hif_chnl_cfg_set_master_up(hif->cbus_base_va, ii, TRUE);
                (void)pfe_hif_chnl_cfg_set_hif_occupied(hif->cbus_base_va, ii, TRUE);
            }
            else
            {
                (void)pfe_hif_chnl_cfg_set_master_up(hif->cbus_base_va, ii, TRUE);
            }
        }
    }
}
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

/*==================================================================================================*/
/**
 * @brief       Marks that a PFE instance associated with the HIF instance is owner of all EMAC timers
 * @param[in]   hif The HIF instance
 */
void pfe_hif_init_emac_timer_ownership(const pfe_hif_t *hif)
{
    uint32 chnl_id;
    pfe_ct_phy_if_id_t emac_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (chnl_id = 0U; chnl_id < HIF_CFG_MAX_CHANNELS; chnl_id++)
        {
            if (0U != ((uint32)hif->configured_channels_mask & ((uint32)1U << chnl_id)))
            {
                for (emac_id = PFE_PHY_IF_ID_EMAC0; emac_id <= PFE_PHY_IF_ID_EMAC2; emac_id++)
                {
                    (void)pfe_hif_chnl_cfg_set_emac_timer_ownership(hif->cbus_base_va, chnl_id, emac_id, TRUE);
                }
                break;
            }
        }
    }
}

/*==================================================================================================*/
/**
 * @brief       Clear timer ownership status for the PFE instance associated with the HIF instance
 * @param[in]   hif The HIF instance
 */
void pfe_hif_clear_emac_timer_ownership(const pfe_hif_t *hif)
{
    uint32 chnl_id;
    pfe_ct_phy_if_id_t emac_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (chnl_id = 0U; chnl_id < HIF_CFG_MAX_CHANNELS; chnl_id++)
        {
            if (0U != ((uint32)hif->configured_channels_mask & ((uint32)1U << chnl_id)))
            {
                for (emac_id = PFE_PHY_IF_ID_EMAC0; emac_id <= PFE_PHY_IF_ID_EMAC2; emac_id++)
                {
                    (void)pfe_hif_chnl_cfg_set_emac_timer_ownership(hif->cbus_base_va, chnl_id, emac_id, FALSE);
                }
                break;
            }
        }
    }
}

#if defined(PFE_CFG_TEXT_STATS)
/*==================================================================================================*/
/**
 * @brief       Return HIF runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   hif         The HIF instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 *
 */
uint32 pfe_hif_get_text_statistics(const pfe_hif_t *hif, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += pfe_hif_cfg_get_text_stat(hif->cbus_base_va, buf, buf_len, verb_level);
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */
#endif /* PFE_CFG_PFE_MASTER */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [153/185]: src\pfe_hif_chnl.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @file        pfe_hif_chnl.c
 * @brief       The HIF channel module source file.
 * @details     This file contains HIF channel-related functionality abstracted using
 *              configurable, HW-specific calls. Each HW platform shall supply its own
 *              pfe_hif_csr.h header implementing the HW-specific parts.
 *
 *              Default Mode
 *              ------------
 *              Default mode allows user to transmit and receive buffers using their
 *              physical addresses. There is no other functionality and only the
 *              default API is sufficient to handle the data-path:
 *                  - pfe_hif_chnl_can_accept_tx()
 *                  - pfe_hif_chnl_tx()
 *                  - pfe_hif_chnl_supply_rx_buffer()
 *                  - pfe_hif_chnl_rx()
 *
 *              TX example:
 *              if pfe_hif_chnl_can_accept_tx() is TRUE then
 *                pfe_hif_chnl_tx()
 *              endif
 *
 *              RX example:
 *              Supply RX buffers
 *              while pfe_hif_chnl_can_accept_rx_buf() do
 *                pfe_hif_chnl_supply_rx_buf()
 *              endwhile
 *
 *              Receive
 *              while (1)
 *                if pfe_hif_chnl_rx() then
 *                  1 Process the buffer
*                   2 pfe_hif_chnl_supply_rx_buf()
 *                endif
 *              endwhile
 *
 *              RX Buffer Management Mode
 *              -------------------------
 *              In case the PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED is set to TRUE the PFE HIF
 *              channel module provides full RX buffer management functionality. It
 *              creates pool of buffers and transparently populates the RX ring. Instead
 *              of default RX API the extended version is provided:
 *                  - pfe_hif_chnl_rx_va()
 *                  - pfe_hif_chnl_release_rx_buf()
 *
 *              Every buffer received via pfe_hif_chnl_rx_va() must be subsequently
 *              released by the pfe_hif_chnl_release_rx_va(). With the RX management
 *              support also the pfe_hif_chnl_get_meta_size() is available for
 *              sanity check implementation related to size of the pre-allocated
 *              buffer-related meta storage.
 *
 *              TX example: The same as in the Default Mode case.
 *
 *              RX example:
 *              Sanity check
 *              if my metadata size does not match pfe_hif_chnl_get_meta_size()
 *                Throw error
 *              endif
 *
 *              Receive
 *              while (1)
 *                if pfe_hif_chnl_rx_va() then
 *                  1 Use pre-allocated metadata storage to bind custom data with the buffer for better performance
 *                  2 Process the buffer
 *                  3 When finished, call the pfe_hif_chnl_release_rx_buf()
 *                endif
 *              endwhile
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "Eth_43_PFE.h"
#include "pfe_cbus.h"
#include "pfe_platform_cfg.h"
#include "pfe_hif_chnl.h"
#include "pfe_hif_ring.h"
#include "pfe_hif_csr.h"
#include "pfe_hif_nocpy_csr.h"

#define DUMMY_TX_BUF_LEN        (64U + sizeof(pfe_ct_hif_tx_hdr_t))
#define DUMMY_RX_BUF_LEN        2048U

/**
 * @brief   The list of HIF channels that are allowed to take FCI timer ownership
 */
typedef enum
{
    HIF_TIMER_OWNER_0,
    HIF_TIMER_OWNER_1,
    HIF_TIMER_OWNER_2,
    HIF_TIMER_OWNER_3,
    HIF_TIMER_OWNER_INVALID
} pfe_timer_owner_hif_id_t;

/**
 * @brief Send dummy frame modes
 * 
 */
typedef enum
{
    DUMMY_FRAME_INVALID = 0U,
    DUMMY_FRAME_IHC_SELF
} send_dummy_frame_mode_t;

typedef struct {
    uint32 rx_ring_addr;
    uint32 rx_wb_ring_addr;
    uint32 tx_ring_addr;
    uint32 tx_wb_ring_addr;

    boolean is_all_addr_zero;
    boolean is_any_addr_zero;


    uint32 rx_ring_len;
    uint32 tx_ring_len;
} HifChnlHwStateType;

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static const pfe_timer_owner_hif_id_t pfe_timer_owner_hif_ids[PFE_PHY_IF_ID_INVALID + 1U] =
{
    [PFE_PHY_IF_ID_HIF0] = HIF_TIMER_OWNER_0,
    [PFE_PHY_IF_ID_HIF1] = HIF_TIMER_OWNER_1,
    [PFE_PHY_IF_ID_HIF2] = HIF_TIMER_OWNER_2,
    [PFE_PHY_IF_ID_HIF3] = HIF_TIMER_OWNER_3,
    [PFE_PHY_IF_ID_INVALID] = HIF_TIMER_OWNER_INVALID
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/* TODO: remove support for multiple HIF channels and put this directly into the pfe_hif_t (not just pointers) */
#ifdef PFE_CFG_HIF_NOCPY_SUPPORT
static pfe_hif_ring_t rx_rings_memory_nocpy;
static pfe_hif_ring_t tx_rings_memory_nocpy;
#else
static pfe_hif_ring_t rx_rings_memory[HIF_CFG_MAX_CHANNELS];
static pfe_hif_ring_t tx_rings_memory[HIF_CFG_MAX_CHANNELS];
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
                                       GLOBAL VARIABLES
==================================================================================================*/

#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"
/* It should be static, but it is not to avoid issues with memory mapping in some compilers */
__attribute__((aligned(8))) uint8 rx_buf_mem[ETH_43_PFE_MAX_RXBUF_POOLSZ];
__attribute__((aligned(8))) uint8 dummy_tx_buf[DUMMY_TX_BUF_LEN];
__attribute__((aligned(8))) uint8 dummy_rx_buf[DUMMY_RX_BUF_LEN];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
                                       LOCAL VARIABLES
==================================================================================================*/
#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

static __attribute__((aligned(4))) uint8 rx_meta_buf_mem[ETH_43_PFE_MAX_RXBUF_META_POOLSZ];

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

static __attribute__((aligned(4))) uint8 rx_meta_buf_mem_hifnocpy[ETH_43_PFE_BMU2_BUF_CNT*ETH_43_PFE_META_BUF_SIZE];

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/*==================================================================================================
                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

#if defined(PFE_CFG_PFE_SLAVE)
static errno_t pfe_hif_chnl_reset_rx_ring(pfe_hif_chnl_t *chnl) __attribute__((cold));
static void pfe_hif_chnl_reset_tx_ring(pfe_hif_chnl_t *chnl) __attribute__((cold));
static __attribute__((cold)) errno_t pfe_hif_chnl_rx_ring_soft_reset(pfe_hif_chnl_t *chnl, uint32 ii, void *tx_buf_va);
#endif /* PFE_CFG_PFE_SLAVE */
static __attribute__((cold)) errno_t pfe_hif_chnl_create_cfg(pfe_hif_chnl_t *chnl);
static __attribute__((cold)) errno_t pfe_hif_chnl_send_dummy_frame(pfe_hif_chnl_t *chnl, void *tx_buf_va, send_dummy_frame_mode_t mode);
static __attribute__((cold)) void pfe_hif_chnl_enable(pfe_hif_chnl_t *chnl);
static __attribute__((cold)) void pfe_hif_chnl_disable(pfe_hif_chnl_t *chnl);
static __attribute__((cold)) errno_t pfe_hif_chnl_rx_pool_init(pfe_hif_chnl_t *chnl);
static __attribute__((cold)) errno_t pfe_hif_chnl_create_mcal_aux(pfe_hif_chnl_t *chnl, addr_t cbus_base_va, uint32 id, const pfe_bmu_t *bmu);

#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
static inline void rx_pool_init(rx_pool_t *pool, const void *memory,const void *meta_memory,
                                uint16 buf_size, uint16 buf_num
                               );
static void pfe_hif_chnl_refill_rx_buffers(pfe_hif_chnl_t *chnl) __attribute__((hot));
static inline void *rx_pool_get(rx_pool_t *pool);
static inline void *rx_pool_get_meta_buf(const rx_pool_t *pool, const void *buf_va);
static __attribute__((hot)) errno_t pfe_hif_chnl_add_vlan_tag(pfe_hif_chnl_t *chnl, void **buf_va, pfe_ct_hif_rx_hdr_t **hif_hdr_ptr, uint32 *vlan_header);
#if defined(PFE_CFG_NULL_ARG_CHECK)
static __attribute__((hot)) errno_t pfe_hif_chnl_rx_va_null_arg_check(pfe_hif_chnl_t *chnl, void **buf_va, uint32 *len, bool_t *lifm, void **meta);
#endif
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

static inline pfe_timer_owner_hif_id_t pfe_timer_owner_hif_from_phy_id(pfe_ct_phy_if_id_t phy);
static __attribute__((cold)) errno_t pfe_hif_chnl_bind_bd_rings(pfe_hif_chnl_t *chnl);

static void pfe_hif_chnl_get_hw_state(const pfe_hif_chnl_t *chnl, HifChnlHwStateType *hws);
#if defined(PFE_CFG_PFE_SLAVE)
static void pfe_hif_chnl_send_dummy_rx(pfe_hif_chnl_t *chnl, const void *rx_buf_va, void *tx_buf_va);
#endif /* PFE_CFG_PFE_SLAVE */

/*==================================================================================================
                                       LOCAL FUNCTIONS
==================================================================================================*/

/*=============================================================================================*/
#if defined(PFE_CFG_PFE_SLAVE)
static void pfe_hif_chnl_send_dummy_rx(pfe_hif_chnl_t *chnl, const void *rx_buf_va, void *tx_buf_va)
{
    void *buf_pa;
    uint32 len;
    bool_t lifm;

    if (0U == pfe_hif_ring_get_fill_level(chnl->rx_ring))
    {
        /*  Provide single RX buffer */
        if (EOK != pfe_hif_chnl_supply_rx_buf(chnl, rx_buf_va, DUMMY_RX_BUF_LEN))
        {
            NXP_LOG_ERROR("Can't provide dummy RX buffer\n");
        }
    }
    (void)pfe_hif_chnl_send_dummy_frame(chnl, tx_buf_va, DUMMY_FRAME_IHC_SELF);

    /*  Wait */
    oal_time_usleep(500U);

    /*  Do TX confirmations */
    while (EOK != pfe_hif_chnl_get_tx_conf(chnl)) /* wait for a confirmation */
    {
        oal_time_usleep(100U);
    }
    while (EOK == pfe_hif_chnl_get_tx_conf(chnl)) /* consume all confirmations */
    {
       /* wait */
    }

    /*  Do plain RX */
    while (EOK == pfe_hif_ring_dequeue_buf(chnl->rx_ring, &buf_pa, &len, &lifm))
    {
       /* deque all rx */
    }
}
#endif /* PFE_CFG_PFE_SLAVE */

/*==================================================================================================*/
static void pfe_hif_chnl_get_hw_state(const pfe_hif_chnl_t *chnl, HifChnlHwStateType *hws)
{
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
        hws->rx_ring_addr = pfe_hif_nocpy_cfg_get_rx_bd_ring_addr(chnl->cbus_base_va);
        hws->tx_ring_addr = pfe_hif_nocpy_cfg_get_tx_bd_ring_addr(chnl->cbus_base_va);
        hws->rx_wb_ring_addr = 0u;
        hws->tx_wb_ring_addr = 0u;
        hws->rx_ring_len = 0u;
        hws->tx_ring_len = 0u;
        hws->is_any_addr_zero = ((0U == hws->rx_ring_addr) 
                              || (0U == hws->tx_ring_addr));
        hws->is_all_addr_zero = ((0U == hws->rx_ring_addr) 
                              && (0U == hws->tx_ring_addr));
    }
    else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    {
        hws->rx_ring_addr = pfe_hif_chnl_cfg_get_rx_bd_ring_addr(chnl->cbus_base_va, chnl->id);
        hws->tx_ring_addr = pfe_hif_chnl_cfg_get_tx_bd_ring_addr(chnl->cbus_base_va, chnl->id);
        hws->rx_wb_ring_addr = pfe_hif_chnl_cfg_get_rx_wb_table_addr(chnl->cbus_base_va, chnl->id);
        hws->tx_wb_ring_addr = pfe_hif_chnl_cfg_get_tx_wb_table_addr(chnl->cbus_base_va, chnl->id);
        hws->rx_ring_len = pfe_hif_chnl_cfg_get_rx_wb_table_len(chnl->cbus_base_va, chnl->id);
        hws->tx_ring_len = pfe_hif_chnl_cfg_get_tx_wb_table_len(chnl->cbus_base_va, chnl->id);
        hws->is_any_addr_zero = ((0U == hws->rx_ring_addr) 
                              || (0U == hws->rx_wb_ring_addr) 
                              || (0U == hws->tx_ring_addr) 
                              || (0U == hws->tx_wb_ring_addr));
        hws->is_all_addr_zero = ((0U == hws->rx_ring_addr) 
                              && (0U == hws->rx_wb_ring_addr) 
                              && (0U == hws->tx_ring_addr) 
                              && (0U == hws->tx_wb_ring_addr));
    }
}


/**
 * @brief       Convert interface id to value representing HIF channel that is allowed to take timer ownership
 * @param[in]   phy interface id
 * @return      Timer owner HIF value
 */
static inline pfe_timer_owner_hif_id_t pfe_timer_owner_hif_from_phy_id(pfe_ct_phy_if_id_t phy)
{
    pfe_timer_owner_hif_id_t ret_val = HIF_TIMER_OWNER_INVALID;

    if (PFE_PHY_IF_ID_INVALID >= phy)
    {
        ret_val = pfe_timer_owner_hif_ids[phy];
    }

    return ret_val;
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
#if defined(NXP_LOG_ENABLED)

/*
 * @brief   Increment buffer allocation counter
 * @details To monitor how many BMU buffers have been allocated
 *          by a channel instance we need to provide a SW counter.
 */
static void pfe_hif_chnl_alloc_inc(pfe_hif_chnl_t *chnl)
{
    oal_mutex_lock(PFE_CHNL_A_LOCK_MUTEX_00);
    chnl->a_cnt++;
    oal_mutex_unlock(PFE_CHNL_A_LOCK_MUTEX_00);
}

/*
 * @brief   Decrement buffer allocation counter
 * @details To monitor how many BMU buffers have been allocated
 *          by a channel instance we need to provide a SW counter.
 */
static void pfe_hif_chnl_alloc_dec(pfe_hif_chnl_t *chnl)
{
    oal_mutex_lock(PFE_CHNL_A_LOCK_MUTEX_01);
    chnl->a_cnt--;
    oal_mutex_unlock(PFE_CHNL_A_LOCK_MUTEX_01);
}

/*
 * @brief   Get state of allocation counter
 * @details To monitor how many BMU buffers have been allocated
 *          by a channel instance we need to provide a SW counter.
 * @return  Current number of allocated buffers.
 */
static uint32 pfe_hif_chnl_get_alloc_cnt(pfe_hif_chnl_t *chnl)
{
    uint32 ret;

    ret = chnl->a_cnt;

    return ret;
}
#endif /* NXP_LOG_ENABLED */
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
/* Initialize Rx pool */
static inline void rx_pool_init(rx_pool_t *pool, const void *memory,const void *meta_memory,
                                uint16 buf_size, uint16 buf_num
                               )
{
    pool->base_addr = (addr_t)memory;
    pool->meta_base_addr = (addr_t)meta_memory;
    pool->buf_size = buf_size;
    pool->buf_number = buf_num;
    pool->get_idx = 0U;
}

/* This function provides one Rx buffer on each call.
   It should be used to feed buffers to channel during initialization. Then the buffers remain there
   until the channel is destroyed. There is no need to return the buffer to the pool. */
static inline void *rx_pool_get(rx_pool_t *pool)
{
    void *pvBuffer = NULL;

    if (pool->get_idx < pool->buf_number)
    {
        const uint32 buf_offset = (uint32)(pool->get_idx) * pool->buf_size;
        pvBuffer = (void *)ADDR_BASE_OFFSET(pool->base_addr, buf_offset);
        pool->get_idx++;
    }
    return pvBuffer;
}

/* Get meta buffer related to Rx buffer  */
static inline void *rx_pool_get_meta_buf(const rx_pool_t *pool, const void *buf_va)
{
    /* Calculate index of provided Rx buffer */
    const uint16 index = (uint16)((OFFSET_ADDR_BASE((addr_t)buf_va, pool->base_addr) / pool->buf_size) & UINT16_MAX);
    const uint32 buffer_offset = (uint32)index * ETH_43_PFE_META_BUF_SIZE;
    /* Calculate address of meta buffer with same index */
    return (void *)ADDR_BASE_OFFSET(pool->meta_base_addr, buffer_offset);
}
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

/**
 * @brief       Channel master ISR
 * @param[in]   chnl The channel instance
 * @return      EOK if interrupt has been handled
 */
__attribute__((hot)) errno_t pfe_hif_chnl_isr(pfe_hif_chnl_t *chnl)
{
    errno_t ret;
    pfe_hif_chnl_event_t events = HIF_CHNL_EVT_NONE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_00);

        /* Run the low-level ISR to identify and process the interrupt */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            ret = pfe_hif_nocpy_cfg_isr(chnl->cbus_base_va, &events);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            ret = pfe_hif_chnl_cfg_isr(chnl->cbus_base_va, chnl->id, &events);
        }

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_00);

        /*  Run callbacks for identified interrupts here */
        if ((uint32)HIF_CHNL_EVT_RX_IRQ == ((uint32)events & (uint32)HIF_CHNL_EVT_RX_IRQ))
        {
            if (NULL != chnl->rx_cbk.cbk)
            {
                chnl->rx_cbk.cbk(chnl->rx_cbk.arg);
            }
            else
            {
                NXP_LOG_DEBUG("Unhandled HIF_CHNL_EVT_RX_IRQ detected\n");
            }
        }

        if ((uint32)HIF_CHNL_EVT_TX_IRQ == ((uint32)events & (uint32)HIF_CHNL_EVT_TX_IRQ))
        {
            if (NULL != chnl->tx_cbk.cbk)
            {
                chnl->tx_cbk.cbk(chnl->tx_cbk.arg);
            }
            else
            {
                NXP_LOG_DEBUG("Unhandled HIF_CHNL_EVT_TX_IRQ detected\n");
            }
        }
    }

    return ret;
}

/**
 * @brief       Mask channel interrupts
 * @param[in]   chnl The channel instance
 */
void pfe_hif_chnl_irq_mask(pfe_hif_chnl_t *chnl)
{
    oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_01);

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
        /* HIF_NOCPY */
        pfe_hif_nocpy_cfg_irq_mask(chnl->cbus_base_va);
    }
    else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    {
        pfe_hif_chnl_cfg_irq_mask(chnl->cbus_base_va, chnl->id);
    }

    oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_01);
}

/**
 * @brief       Unmask channel interrupts
 * @param[in]   chnl The channel instance
 */
void pfe_hif_chnl_irq_unmask(pfe_hif_chnl_t *chnl)
{
    oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_02);
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
        /* HIF_NOCPY */
        pfe_hif_nocpy_cfg_irq_unmask(chnl->cbus_base_va);
    }
    else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    {
        pfe_hif_chnl_cfg_irq_unmask(chnl->cbus_base_va, chnl->id);
    }

    oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_02);
}

#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
/**
 * @brief   Supply fresh RX buffers to the channel
 * @details Function populates channel's RX resource with buffer from internal pool
 */
__attribute__((hot)) static void pfe_hif_chnl_refill_rx_buffers(pfe_hif_chnl_t *chnl)
{
    const void *new_buffer_va;
    const void *new_buffer_pa;
    errno_t ret;
    bool_t flags = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        while (TRUE == pfe_hif_chnl_can_accept_rx_buf(chnl))
        {
            new_buffer_va = rx_pool_get(&(chnl->rx_pool));

            if (likely(NULL != new_buffer_va))
            {
                /*  Get physical address */
                new_buffer_pa = new_buffer_va;
                ret = pfe_hif_chnl_supply_rx_buf(chnl, new_buffer_pa, ETH_43_PFE_CFG_HIF_RX_BUF_SIZE);
                if (unlikely(EOK != ret))
                {
                    NXP_LOG_WARNING("HIF channel did not accept new RX buffer\n");
                    flags =  TRUE;
                }
            }
            else
            {
                /*  No more Rx buffers available, leave remaining BD empty */
                flags =  TRUE;
            }

            if(TRUE == flags)
            {
                break;
            }
        }
    }
}
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

/**
 * @brief           Create new HIF channel instance
 * @details         Creates and initializes HIF channel instance
 * @param[inout]    chnl Pointer to channel
 * @return          EOK if success, error code otherwise
 */
static __attribute__((cold)) errno_t pfe_hif_chnl_create_cfg(pfe_hif_chnl_t *chnl)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    /* When PFE_CFG_HIF_NOCPY_SUPPORT is defined and ((*chnl)->id != PFE_HIF_CHNL_NOCPY_ID), 
     * it means this HIF channel is used in minihif scenario */
    if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
        if (NULL == chnl->bmu)
        {
            NXP_LOG_ERROR("HIF NOCPY channel requires BMU instance\n");
            ret = EINVAL;
        }
        else
        {
            ret = EOK;
        }
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */
       /* HIF_NOCPY does not need per-channel initialization */
    }
    else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_03);

        ret = pfe_hif_chnl_cfg_init(chnl->cbus_base_va, chnl->id);

        if (EOK != ret)
        {
            NXP_LOG_ERROR("HIF channel cfg init failed\n");
        }
        else
        {
            ret = pfe_hif_chnl_init(chnl);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("HIF channel init failed\n");
            }
        }
        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_03);
    }

    return ret;
}


/**
 * @brief           Auxiliary function to pfe_hif_chnl_create_mcal
 * @details         Creates and initializes HIF channel instance
 * @param[inout]    chnl Pointer to channel
 * @param[in]       bmu If set, the channel will use it to allocate RX buffers. It is mandatory
 *                  for HIF NOCPY channel abstraction.
 * @return          EOK if success, error code otherwise
 */
static __attribute__((cold)) errno_t pfe_hif_chnl_create_mcal_aux(pfe_hif_chnl_t *chnl, addr_t cbus_base_va, uint32 id, const pfe_bmu_t *bmu)
{
    errno_t ret = EOK;

    chnl->cbus_base_va = cbus_base_va;
    chnl->id = id;
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    chnl->rx_ring = &rx_rings_memory_nocpy;
    chnl->tx_ring = &tx_rings_memory_nocpy;
    chnl->bmu = bmu;
#else
    chnl->tx_ring = &tx_rings_memory[chnl->id];
    chnl->rx_ring = &rx_rings_memory[chnl->id];
    (void)bmu;
#endif
    if(EOK != pfe_hif_ring_create_mcal(chnl->rx_ring, PFE_HIF_RX_RING_CFG_LENGTH, TRUE))
    {
        NXP_LOG_ERROR("Failed to create Rx ring\n");
        ret = EFAULT;
    }
    else if(EOK != pfe_hif_ring_create_mcal(chnl->tx_ring, PFE_HIF_TX_RING_CFG_LENGTH, FALSE))
    {
        NXP_LOG_ERROR("Failed to create Tx ring\n");
        ret = EFAULT;
    }
    else if(EOK != pfe_hif_chnl_rx_pool_init(chnl))
    {
        NXP_LOG_ERROR("Failed to init Rx buffer pool\n");
        ret = EFAULT;
    }
    else if(EOK != pfe_hif_chnl_create_cfg(chnl))
    {
        NXP_LOG_ERROR("Failed to create HIF channel\n");
        ret = EFAULT;
    }
    else
    {
        pfe_hif_chnl_refill_rx_buffers(chnl);
        ret = EOK;
    }

    return ret;
}


/**
 * @brief           Create new HIF channel instance for MCAL driver
 * @details         Creates and initializes HIF channel instance
 * @param[inout]    chnl Pointer to channel
 * @param[in]       cbus_base_va CBUS base virtual address
 * @param[in]       id Channel identifier to bind SW instance to a real HW HIF channel
 * @param[in]       bmu If set, the channel will use it to allocate RX buffers. It is mandatory
 *                  for HIF NOCPY channel abstraction.
 * @return          EOK if success, error code otherwise
 */
__attribute__((cold)) errno_t pfe_hif_chnl_create_mcal(pfe_hif_chnl_t *chnl, addr_t cbus_base_va, uint32 id, const pfe_bmu_t *bmu)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if !defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            NXP_LOG_ERROR("HIF NOCPY support is not enabled\n");
            ret = ENODEV;
        }
        else if (id >= HIF_CFG_MAX_CHANNELS)
        {
            NXP_LOG_ERROR("Unsupported channel ID\n");
            ret = ENODEV;
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            if (NULL == chnl)
            {
                ret = EINVAL;
            }
            else
            {
                ret = pfe_hif_chnl_create_mcal_aux(chnl, cbus_base_va, id, bmu);
            }
        }
    }

    return ret;
}

/**
 * @brief           Create new HIF channel instance for attached minihif driver
 * @details         Creates and initializes HIF channel instance
 * @param[inout]    chnl Pointer to channel
 * @param[in]       cbus_base_va CBUS base virtual address
 * @param[in]       id Channel identifier to bind SW instance to a real HW HIF channel
 * @return          EOK if success, error code otherwise
 */
__attribute__((cold)) errno_t pfe_hif_chnl_create_minihif(pfe_hif_chnl_t *chnl, addr_t cbus_base_va, uint32 id, pfe_hif_ring_t *rx_ring, pfe_hif_ring_t *tx_ring)
{
    /* NULL or invalid arguments not expected when called from minihif driver */
    chnl->cbus_base_va = cbus_base_va;
    chnl->id = id;
    chnl->rx_ring = rx_ring;
    chnl->tx_ring = tx_ring;
    return pfe_hif_chnl_create_cfg(chnl);
}

/**
 * @brief       Get channel identifier
 * @param[in]   chnl The channel instance
 * @return      The identifier of the channel
 */
__attribute__((pure, cold)) uint32 pfe_hif_chnl_get_id(const pfe_hif_chnl_t *chnl)
{
    uint32 chnl_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        chnl_id = UINT_MAX; /* Available via oal_types.h */
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        chnl_id = chnl->id;
    }
    return chnl_id;
}

/**
 * @brief       Enable TX
 * @details     Activate the TX ring and enable TX ring interrupts
 * @param[in]   chnl The channel instance
 * @retval      EOK Success
 * @retval      EFAULT TX ring not found
 */
__attribute__((cold)) errno_t pfe_hif_chnl_tx_enable(pfe_hif_chnl_t *chnl)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL == chnl->tx_ring)
        {
            NXP_LOG_ERROR("Can't enable TX: TX ring not set\n");
            ret = EFAULT;
        }
        else
        {
            oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_04);

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
            {
                /* HIF_NOCPY */
                pfe_hif_nocpy_cfg_tx_enable(chnl->cbus_base_va);
            }
            else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
            {
                /* HIF */
                pfe_hif_chnl_cfg_tx_enable(chnl->cbus_base_va, chnl->id);
            }

            oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_04);
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Disable TX
 * @details     De-activate the TX ring and disable TX ring interrupts. All buffers
 *              previously committed for transmission via pfe_hif_chnl_tx() are marked
 *              as "transmitted" and related TX confirmations can be retrieved via
 *              pfe_hif_chnl_get_tx_conf().
 * @param[in]   chnl The channel instance
 */
__attribute__((cold)) void pfe_hif_chnl_tx_disable(pfe_hif_chnl_t *chnl)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_05);

        /* Stop data transmission */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            pfe_hif_nocpy_cfg_tx_disable(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            /* HIF */
            pfe_hif_chnl_cfg_tx_disable(chnl->cbus_base_va, chnl->id);
        }

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_05);
    }
}

/**
 * @brief       Enable RX
 * @details     Activate the RX ring and enable RX ring interrupts
 * @param[in]   chnl The channel instance
 * @retval      EOK Success
 * @retval      EFAULT RX ring not found
 */
__attribute__((cold)) errno_t pfe_hif_chnl_rx_enable(pfe_hif_chnl_t *chnl)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL == chnl->rx_ring)
        {
            NXP_LOG_ERROR("Can't enable RX: RX ring not set\n");
            ret = EFAULT;
        }
        else
        {
            oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_06);

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
            {
                /* HIF_NOCPY */
                pfe_hif_nocpy_cfg_rx_enable(chnl->cbus_base_va);
            }
            else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
            {
                /* HIF */
                pfe_hif_chnl_cfg_rx_enable(chnl->cbus_base_va, chnl->id);
            }

            oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_06);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Disable RX
 * @details     De-activate the RX ring
 * @param[in]   chnl The channel instance
 * @note        Must not be preempted by pfe_hif_chnl_supply_rx_buf()
 */
__attribute__((cold)) void pfe_hif_chnl_rx_disable(pfe_hif_chnl_t *chnl)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_07);

        /* Stop data reception */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            pfe_hif_nocpy_cfg_rx_disable(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            /* HIF */
            pfe_hif_chnl_cfg_rx_disable(chnl->cbus_base_va, chnl->id);
        }

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_07);
    }
}

static __attribute__((cold)) void pfe_hif_chnl_enable(pfe_hif_chnl_t *chnl)
{
    /* Start RX and TX */
    (void)pfe_hif_chnl_tx_enable(chnl);
    (void)pfe_hif_chnl_rx_enable(chnl);
}

static __attribute__((cold)) void pfe_hif_chnl_disable(pfe_hif_chnl_t *chnl)
{
    /* Disable RX and TX */
    pfe_hif_chnl_tx_disable(chnl);
    pfe_hif_chnl_rx_disable(chnl);
}

/**
 * @brief       Attach event callback
 * @param[in]   chnl The channel instance
 * @param[in]   event Event triggering the handler
 * @param[in]   isr The ISR
 * @param[in]   arg The ISR argument
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_hif_chnl_set_event_cbk(pfe_hif_chnl_t *chnl, pfe_hif_chnl_event_t event, pfe_hif_chnl_cbk_t cbk, void *arg)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (HIF_CHNL_EVT_TX_IRQ == event)
        {
            /*  TX callback */
            chnl->tx_cbk.arg = arg;
            chnl->tx_cbk.cbk = cbk;
        }
        else if (HIF_CHNL_EVT_RX_IRQ == event)
        {
            /*  RX callback */
            chnl->rx_cbk.arg = arg;
            chnl->rx_cbk.cbk = cbk;
        }
        else
        {
            /*  More events need to be supported here */
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Disable RX interrupt
 * @param[in]   chnl The channel instance
 * @return      EOK if success, error code otherwise
 */
__attribute__((hot)) void pfe_hif_chnl_rx_irq_mask(pfe_hif_chnl_t *chnl)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_08);

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            pfe_hif_nocpy_cfg_rx_irq_mask(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            pfe_hif_chnl_cfg_rx_irq_mask(chnl->cbus_base_va, chnl->id);
        }

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_08);
    }
}

/**
 * @brief       Enable RX interrupt
 * @param[in]   chnl The channel instance
 * @return      EOK if success, error code otherwise
 */
__attribute__((hot)) void pfe_hif_chnl_rx_irq_unmask(pfe_hif_chnl_t *chnl)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_09);
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            pfe_hif_nocpy_cfg_rx_irq_unmask(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            pfe_hif_chnl_cfg_rx_irq_unmask(chnl->cbus_base_va, chnl->id);
        }

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_09);
    }
}

/**
 * @brief       Disable TX interrupt
 * @param[in]   chnl The channel instance
 * @return      EOK if success, error code otherwise
 */
__attribute__((hot)) void pfe_hif_chnl_tx_irq_mask(pfe_hif_chnl_t *chnl)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_10);

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            pfe_hif_nocpy_cfg_tx_irq_mask(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            pfe_hif_chnl_cfg_tx_irq_mask(chnl->cbus_base_va, chnl->id);
        }

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_10);
    }
}

/**
 * @brief       Enable TX interrupt
 * @param[in]   chnl The channel instance
 * @return      EOK if success, error code otherwise
 */
__attribute__((hot)) void pfe_hif_chnl_tx_irq_unmask(pfe_hif_chnl_t *chnl)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_11);
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            pfe_hif_nocpy_cfg_tx_irq_unmask(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            pfe_hif_chnl_cfg_tx_irq_unmask(chnl->cbus_base_va, chnl->id);
        }

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_11);
    }
}

/**
 * @brief       Get TX confirmation status
 * @details     After pfe_hif_chnl_tx() call the HIF channel will transmit the
 *              supplied buffer. Once the transmission has been done a TX confirmation
 *              is generated. This function can be used to query the channel whether
 *              some new TX confirmations have been generated and are ready to be
 *              processed.
 * @param[in]   chnl The channel instance
 * @return      TRUE if channel got new TX confirmation, FALSE otherwise
 */
__attribute__((pure, hot)) bool_t pfe_hif_chnl_has_tx_conf(const pfe_hif_chnl_t *chnl)
{
    bool_t has_tx_conf;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        has_tx_conf = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        has_tx_conf = (0U == pfe_hif_ring_get_fill_level(chnl->tx_ring)) ? FALSE : TRUE;
    }
    return has_tx_conf;
}

/**
 * @brief       Query if new RX buffer can be supplied
 * @param       chnl The channel instance
 * @return      TRUE if RX resource can accept new buffer
 */
__attribute__((pure, hot)) bool_t pfe_hif_chnl_can_accept_rx_buf(const pfe_hif_chnl_t *chnl)
{
    bool_t accept_rx;
    uint32 fill_level;
    uint32 ring_len;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        accept_rx = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  A single entry must remain unused within the ring
            because HIF expects that. */
        fill_level = pfe_hif_ring_get_fill_level(chnl->rx_ring);
        ring_len = pfe_hif_ring_get_len(chnl->rx_ring);

        PfeDevAssert(ring_len >= fill_level);
        accept_rx = ((ring_len - fill_level) > 1U);
    }
    return accept_rx;
}

/**
 * @brief       Check if channel can accept a single TX request
 * @param[in]   chnl The channel instance
 * @param[in]   number Number of TX requests
 * @retval      TRUE Channel can accept 'number' TX requests (buffers)
 * @retval      FALSE Not enough space in TX FIFO
 */
__attribute__((pure, hot)) bool_t pfe_hif_chnl_can_accept_tx(const pfe_hif_chnl_t *chnl)
{
    uint32 fill_level;
    uint32 ring_len;
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  A single entry must remain unused within the ring because HIF expects that. */
        fill_level = pfe_hif_ring_get_fill_level(chnl->tx_ring);
        ring_len = pfe_hif_ring_get_len(chnl->tx_ring);
        ret = ring_len > (fill_level + 1U);
    }
    return ret;
}

/**
 * @brief       Check if the TX FIFO is empty
 * @param[in]   chnl The channel instance
 * @retval      TRUE TX FIFO is empty
 * @retval      FALSE TX FIFO contains entries waiting for transmission
 */
__attribute__((pure, hot)) bool_t pfe_hif_chnl_tx_fifo_empty(const pfe_hif_chnl_t *chnl)
{
    bool_t is_empty;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_empty = TRUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        is_empty = (0U == pfe_hif_ring_get_fill_level(chnl->tx_ring));
    }
    return is_empty;
}

/**
 * @brief       Get the RX FIFO depth
 * @param[in]   chnl The channel instance
 * @return      Size of the RX FIFO in number of entries
 */
__attribute__((pure, cold)) uint32 pfe_hif_chnl_get_rx_fifo_depth(const pfe_hif_chnl_t *chnl)
{
    uint32 rx_fifo_depth;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        rx_fifo_depth = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        rx_fifo_depth = pfe_hif_ring_get_len(chnl->rx_ring);
    }
    return rx_fifo_depth;
}

/**
 * @brief       Get the TX FIFO depth
 * @param[in]   chnl The channel instance
 * @return      Size of the TX FIFO in number of entries
 */
__attribute__((pure, cold)) uint32 pfe_hif_chnl_get_tx_fifo_depth(const pfe_hif_chnl_t *chnl)
{
    uint32 tx_fifo_depth;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        tx_fifo_depth = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tx_fifo_depth = pfe_hif_ring_get_len(chnl->tx_ring);
    }
    return tx_fifo_depth;
}

/**
 * @brief       Request transmission of a buffer
 * @note        The TX resource availability shall be checked before this function
 *              is called using the pfe_hif_chnl_can_accept_tx_buf() call.
 * @note        Function is __NOT__ reentrant
 * @param[in]   chnl The channel instance
 * @param[in]   buf_va Virtual address of the buffer to be transmitted
 * @param[in]   len Length of the buffer in bytes
 * @param[in]   lifm The last-in-frame indicator. Complete packet can consist
 *                   of multiple buffers. The last one shall be marked with
 *                   lifm=TRUE.
 * @retval      EOK Success
 * @retval      ENOSPC TX queue is full
 * @retval      EIO Internal error
 */
__attribute__((hot)) errno_t pfe_hif_chnl_tx(const pfe_hif_chnl_t *chnl, const void *buf_va, uint32 len)
{
    errno_t ret = EOK;
    uint32 lmem_header_size;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == chnl) || (NULL == buf_va)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        lmem_header_size = pfe_hif_chnl_get_lmem_hdr_size(chnl);
        /*  Enqueue the buffer into TX ring */
        ret = pfe_hif_ring_enqueue_buf(chnl->tx_ring, buf_va, len, lmem_header_size);
    }

    return ret;
}

/**
 * @brief       Get TX confirmation
 * @details     Each frame transmitted via pfe_hif_chnl_tx() will produce exactly
 *              one TX confirmation which can be retrieved by this function.
 * @param[in]   chnl The channel instance
 * @retval      EOK Next frame has been transmitted
 * @retval      EAGAIN No pending confirmations
 */
__attribute__((hot)) errno_t pfe_hif_chnl_get_tx_conf(pfe_hif_chnl_t *chnl)
{
    bool_t lifm = FALSE;
    errno_t ret = EAGAIN;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get all transmitted chunks but only the last-in-frame
            will be reported as TX confirmation. */
        while (EOK == pfe_hif_ring_dequeue_plain(chnl->tx_ring, &lifm))
        {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
#if defined(NXP_LOG_ENABLED)
            if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
            {
                /* Decrement BMU allocations counter. It is here because we expect that
                   the PFE HW just released a TX buffer previously allocated from BMU
                   pool within the pfe_hif_chnl_tx(). */
                pfe_hif_chnl_alloc_dec(chnl);
            }
#endif /* NXP_LOG_ENABLED */
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

            if (TRUE == lifm)
            {
                ret = EOK;
                break;
            }
        }
    }
    return ret;
}

#if (FALSE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
/**
 * @brief       Receive a buffer
 * @details     When channel has received some data into RX buffer then this
 *              function will retrieve it.
 * @note        The RX resource availability shall be checked before this function
 *              is called using the pfe_hif_chnl_can_accept_rx_buf() call.
 * @param[in]   chnl The channel instance
 * @param[out]  buf_pa Pointer to memory where pointer to the received data shall
 *                     be written (physical address, as seen by host)
 * @param[out]  len Pointer to memory where length in bytes of the received
 *                  data shall be written
 * @param[out]  lifm Pointer to memory where the last-in-frame flag shall be
 *                   written
 * @retval      EOK Buffer received
 * @retval      EAGAIN No more data to receive right now
 */
__attribute__((hot)) errno_t pfe_hif_chnl_rx(pfe_hif_chnl_t *chnl, void **buf_pa, uint32 *len, bool_t *lifm)
{
    errno_t err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == chnl) || (NULL == buf_pa) || (NULL == len) || (NULL == lifm) || (NULL == chnl->rx_ring)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {

        err = pfe_hif_ring_dequeue_buf(chnl->rx_ring, buf_pa, len, lifm);

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
#if defined(NXP_LOG_ENABLED)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* Increment BMU allocations counter. We have not allocated a buffer from BMU
               directly but the HW did that and then provided us the buffer. Therefore we
               need to properly handle it (release it once it has been processed). So we
               are counting it as allocated buffer here... */
            pfe_hif_chnl_alloc_inc(chnl);
        }
#endif /* NXP_LOG_ENABLED */
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

    }

    return err;
}
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */
#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)

#if defined(PFE_CFG_NULL_ARG_CHECK)
/* Check for NULL args in pfe_hif_chnl_rx_va*/
static __attribute__((hot)) errno_t pfe_hif_chnl_rx_va_null_arg_check(pfe_hif_chnl_t *chnl, void **buf_va, uint32 *len, bool_t *lifm, void **meta)
{
    errno_t ret = EOK;

    if (unlikely((NULL == chnl) || (NULL == buf_va) || (NULL == len) || (NULL == lifm) || (NULL == meta)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }

    return ret;
}
#endif /* PFE_CFG_NULL_ARG_CHECK */

/* Copy the vlan header from HIF hw*/
static __attribute__((hot)) errno_t pfe_hif_chnl_add_vlan_tag(pfe_hif_chnl_t *chnl, void **buf_va, pfe_ct_hif_rx_hdr_t **hif_hdr_ptr, uint32 *vlan_header)
{
    errno_t ret = EOK;
    uint32 flags_map[4] = {HIF_RX_HIF0_VLAN, HIF_RX_HIF1_VLAN, HIF_RX_HIF2_VLAN, HIF_RX_HIF3_VLAN};

    /* Check if pkt is tagged */
    if(chnl->id < HIF_CFG_MAX_CHANNELS)
    {
        if ((oal_ntohl((*hif_hdr_ptr)->flags) & (flags_map[chnl->id])) != (uint32)0U)
        {
            /* On HIF hw is adding the vlan tag at 12 byte offset from the beggining
                of the buffer. Copy the vlan header to the right position at offset 12
                of the pkt witch is after the hif rx header. */
            *vlan_header = (*hif_hdr_ptr)->rx_timestamp_s;
            (void)autolibc_memmove(((uint8 *)*buf_va) + (2U * MAC_ADDRESS_SIZE), ((uint8 *)*buf_va) + (sizeof(pfe_ct_hif_rx_hdr_t)), (2U * MAC_ADDRESS_SIZE) + (sizeof(*vlan_header)));
            (void)autolibc_memcpy(((uint8 *)*buf_va) + (sizeof(pfe_ct_hif_rx_hdr_t)) + (2U * MAC_ADDRESS_SIZE), vlan_header, sizeof(*vlan_header));
        }
    }
    else
    {
        NXP_LOG_ERROR("Channel id exceeds max channel\n");
        ret = EINVAL;
    }
    return ret;
}

/**
 * @brief       Receive a buffer (virtual address)
 * @details     When channel has received some data into RX buffer then this
 *              function will retrieve it.
 * @note        The RX resource availability shall be checked before this function
 *              is called using the pfe_hif_chnl_can_accept_rx_buf() call.
 * @param[in]   chnl The channel instance
 * @param[out]  buf_va Pointer to memory where pointer to the received data shall
 *                     be written (virtual address, as seen by host)
 * @param[out]  len Pointer to memory where length in bytes of the received
 *                  data shall be written
 * @param[out]  lifm Pointer to memory where the last-in-frame flag shall be
 *                   written
 * @param[out]  meta Pointer to memory where pointer to pre-allocated memory
 *                   associated with the returned buffer shall be stored. Size
 *                   of the memory can be obtained by the pfe_hif_chnl_get_meta_size().
 * @retval      EOK Buffer received
 * @retval      EAGAIN No more data to receive right now
 * @retval      ENOMEM Out of memory
 */
__attribute__((hot)) errno_t pfe_hif_chnl_rx_va(pfe_hif_chnl_t *chnl, void **buf_va, uint32 *len, bool_t *lifm, void **meta)
{
    errno_t ret;
    void *buf_pa = NULL;
    pfe_ct_hif_rx_hdr_t *hif_hdr_ptr = NULL;
    uint32 vlan_header;

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    const pfe_ct_post_cls_hdr_t *pcls_hdr = NULL;
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (pfe_hif_chnl_rx_va_null_arg_check(chnl, buf_va, len, lifm, meta) == EINVAL)
    {
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_hif_ring_dequeue_buf(chnl->rx_ring, &buf_pa, len, lifm);
        if (EOK == ret)
        {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
            {
                /* HIF NOCPY */

                /* Addresses coming from the ring are physical addresses of buffers provided by BMU. The
                   buffer contains so called post-classification header the PFE classifier is internally
                   using as well as specific HIF header. Headers start from buffer offset 0x0 and we shall
                   strip-off the post-classification header here since upper layers do not know about such
                   thing. The space can be (and will be) used as the buffer-specific metadata storage. */
                *buf_va = pfe_bmu_get_va(chnl->bmu, (addr_t)buf_pa);
#if defined(PFE_CFG_NULL_ARG_CHECK)
                if (unlikely(NULL == *buf_va))
                {
                    NXP_LOG_DEBUG("Fatal: BMU converted p0x%lx to v0x0\n", (uint32)(addr_t)buf_pa);
                }
                else
#endif /* PFE_CFG_NULL_ARG_CHECK */
                {
                    /* Get pointer to the pre-allocated memory location where
                       a buffer-related metadata can be stored. */
                    *meta = &rx_meta_buf_mem_hifnocpy[(((addr_t)*buf_va / PFE_CFG_BMU2_BUF_SIZE) % ETH_43_PFE_BMU2_BUF_CNT)*ETH_43_PFE_META_BUF_SIZE];

                    /* Get post-classification header to get data offset */
                    pcls_hdr = (pfe_ct_post_cls_hdr_t *)*buf_va;

                    /* Skip the post-classification header to gain space for metadata storage.
                       The pfe_hif_chnl_release_rx_buf() must be aware of this adjustment before
                       it will attempt to release buffer back to BMU hardware pool. This will
                       ensure the caller will receive also the HIF TX header but can reuse it
                        for custom purposes (see the pfe_hif_chnl_get_meta_size()). */
                    *buf_va = (void *)((addr_t)*buf_va + pcls_hdr->reserved[0]);

#if defined(NXP_LOG_ENABLED)
                    /* Increment BMU allocations counter. We have not allocated a buffer from BMU
                       directly but the HW did that and then provided us the buffer. Therefore we
                       need to properly handle it (release it once it has been processed). So we
                       are counting this reception as allocated buffer here... */
                    pfe_hif_chnl_alloc_inc(chnl);
#endif /* NXP_LOG_ENABLED */
                }
            }
            else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
            {
                /* Return virtual address */
                *buf_va = buf_pa;

                hif_hdr_ptr = (pfe_ct_hif_rx_hdr_t *) *buf_va;

                ret = pfe_hif_chnl_add_vlan_tag(chnl, buf_va, &hif_hdr_ptr, &vlan_header);

                /* Return pointer to the pre-allocated memory location where
                   a buffer-related metadata can be stored. */
                *meta = rx_pool_get_meta_buf(&chnl->rx_pool, *buf_va);
            }
        }
    }

    return ret;
}

/**
 * @brief       Get size of metadata storage returned by the pfe_hif_chnl_rx_va()
 * @details     When driver is willing to use the pre-allocated storage associated
 *              with every RX buffer it must not write more data than is the
 *              pre-allocated block size. To ensure that, it shall call this API
 *              to get maximum number of bytes which can be written to the 'meta'
 *              memory location returned by the pfe_hif_chnl_rx_va().
 * @param[in]   chnl The channel instance
 * @return      Size of the metadata storage pointed by the 'meta' arugument of
 *              the pfe_hif_chnl_rx_va().
 */
__attribute__((cold)) uint32 pfe_hif_chnl_get_meta_size(const pfe_hif_chnl_t *chnl)
{
    uint32 meta_size;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        meta_size = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF NOCPY */

            /* In case of HIF NOCPY we're using whole RX packet header headroom
               for metadata storage. The headroom includes post-classification
               header and the HIF header. Both can be overwritten by custom data. */
            meta_size = sizeof(pfe_ct_post_cls_hdr_t) + sizeof(pfe_ct_hif_rx_hdr_t);
        }
        else
#elif !defined(PFE_CFG_NULL_ARG_CHECK)
        (void)chnl;
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            meta_size = ETH_43_PFE_META_BUF_SIZE;
        }
    }

    return meta_size;
}

/**
 * @brief       Release an Rx buffer by putting it back to Rx ring (HIF), or back to BMU (HIF_NOCPY)
 * @param[in]   chnl The channel instance
 * @param[in]   buf_va Pointer to buffer to be released
 * @retval      EOK if success, error code otherwise
 */
__attribute__((hot)) errno_t pfe_hif_chnl_release_rx_buf(pfe_hif_chnl_t *chnl, const void *buf_va)
{
    addr_t buf_pa;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF NOCPY */

            /* Get physical address */
            buf_pa = (addr_t)pfe_bmu_get_pa(chnl->bmu, (addr_t)buf_va);

            /* Apply the correction due to post-classification header skip done
               during the buffer reception. */
            buf_pa = buf_pa - sizeof(pfe_ct_post_cls_hdr_t);

            /* Release the buffer to BMU pool. Resource protection is embedded. */
            pfe_bmu_free_buf(chnl->bmu, buf_pa);

#if defined(NXP_LOG_ENABLED)
            /* Decrement BMU allocations counter */
            pfe_hif_chnl_alloc_dec(chnl);
#endif /* NXP_LOG_ENABLED */

            ret = EOK;
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            buf_pa = (addr_t)buf_va;

            if (unlikely(NULL == (void *)buf_pa))
            {
                NXP_LOG_ERROR("VA->PA conversion failed, origin buffer VA: v0x%p\n", buf_va);
            }
            /* Release the buffer to ring */
            oal_mutex_lock(PFE_CHNL_RX_LOCK_MUTEX);
            ret = pfe_hif_ring_enqueue_buf(chnl->rx_ring, (void *)buf_pa, ETH_43_PFE_CFG_HIF_RX_BUF_SIZE, 0U);
            oal_mutex_unlock(PFE_CHNL_RX_LOCK_MUTEX);
        }
    }

    return ret;
}
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

/**
 * @brief       Supply RX buffer to be used for data reception
 * @param[in]   chnl The channel instance
 * @param[in]   buf_pa The RX buffer to be supplied (physical address, as seen
 *                     by host
 * @param[in]   size Size of the supplied buffer in bytes
 * @return      EOK Success
 * @note        Must not be preempted by pfe_hif_chnl_rx_disable()
 */
__attribute__((hot)) errno_t pfe_hif_chnl_supply_rx_buf(const pfe_hif_chnl_t *chnl, const void *buf_pa, uint32 size)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == chnl) || (NULL == buf_pa)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            (void)chnl;
            (void)buf_pa;
            (void)size;
            /* There is nothing to supply to HIF NOCPY */
            ret = EINVAL;
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            ret = pfe_hif_ring_enqueue_buf(chnl->rx_ring, buf_pa, size, 0U);
            if (unlikely(EOK != ret))
            {
                NXP_LOG_WARNING("pfe_hif_ring_enqueue_buf() failed: %d\n", ret);
            }
        }
    }

    return ret;
}

/**
 * @brief       Assign RX BD ring
 * @details     Configure RX buffer descriptor ring address of the channel.
 *              This binds channel with a RX BD ring.
 * @param[in]   chnl The channel instance
 * @retval      EOK Success
 * @retval      EFAULT Invalid ring instance
 */
__attribute__((cold)) errno_t pfe_hif_chnl_bind_rx_ring(pfe_hif_chnl_t *chnl)
{
    pfe_hif_ring_t *ring = chnl->rx_ring;
    const void *rx_ring_pa, *wb_tbl_pa;
    errno_t ret;
    uint32 wb_tbl_len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == chnl)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        rx_ring_pa = pfe_hif_ring_get_base_pa(ring);
        wb_tbl_pa = pfe_hif_ring_get_wb_tbl_pa(ring);

        if (NULL == rx_ring_pa)
        {
            NXP_LOG_ERROR("RX ring physical address is NULL\n");
            ret = EFAULT;
        }
        else
        {
            /* Access HW only if CBUS address was provided */
            if(NULL_ADDR != chnl->cbus_base_va)
            {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
                if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
                {
                    (void)wb_tbl_pa;
                    (void)wb_tbl_len;
                    /* HIF_NOCPY */
                    pfe_hif_nocpy_cfg_set_rx_bd_ring_addr(chnl->cbus_base_va, rx_ring_pa);
                }
                else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
                {
                    /* HIF */
                    pfe_hif_chnl_cfg_set_rx_bd_ring_addr(chnl->cbus_base_va, chnl->id, rx_ring_pa);
                    if (NULL != wb_tbl_pa)
                    {
                        wb_tbl_len = pfe_hif_ring_get_wb_tbl_len(ring);
                        pfe_hif_chnl_cfg_set_rx_wb_table(chnl->cbus_base_va, chnl->id, wb_tbl_pa, wb_tbl_len);
                    }
                }
            }
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Assign TX BD ring
 * @details     Configure TX buffer descriptor ring address of the channel.
 *              This binds channel with a TX BD ring.
 * @param[in]   chnl The channel instance
 * @retval      EOK Success
 * @retval      EFAULT Invalid ring instance
 */
__attribute__((cold)) errno_t pfe_hif_chnl_bind_tx_ring(pfe_hif_chnl_t *chnl)
{
    pfe_hif_ring_t *ring = chnl->tx_ring;
    const void *tx_ring_pa;
    const void *wb_tbl_pa;
    errno_t ret;
    uint32 wb_tbl_len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == chnl)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tx_ring_pa = pfe_hif_ring_get_base_pa(ring);
        wb_tbl_pa = pfe_hif_ring_get_wb_tbl_pa(ring);

        if (NULL == tx_ring_pa)
        {
            NXP_LOG_ERROR("TX ring physical address is NULL\n");
            ret = EFAULT;
        }
        else
        {
            /* Access HW only if CBUS address was provided */
            if(NULL_ADDR != chnl->cbus_base_va)
            {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
                if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
                {
                    (void)wb_tbl_pa;
                    (void)wb_tbl_len;
                    /* HIF_NOCPY */
                    pfe_hif_nocpy_cfg_set_tx_bd_ring_addr(chnl->cbus_base_va, tx_ring_pa);
                }
                else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
                {
                    /* HIF */
                    pfe_hif_chnl_cfg_set_tx_bd_ring_addr(chnl->cbus_base_va, chnl->id, tx_ring_pa);

                    if (NULL != wb_tbl_pa)
                    {
                        wb_tbl_len = pfe_hif_ring_get_wb_tbl_len(ring);
                        pfe_hif_chnl_cfg_set_tx_wb_table(chnl->cbus_base_va, chnl->id, wb_tbl_pa, wb_tbl_len);
                    }
                }
            }
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Inspect channel state
 * @details     Function reads channel HW registers to detect current channel state
 * @param[in]   chnl The channel instance
 * @return      EOK     Channel is clean
 * @return      EAGAIN  Channel has valid set-up for ungraceful reset (only for standard HIF)
 * @return      EINVAL  Channel is in unrecorevable state
 */
errno_t pfe_hif_chnl_inspect_hw_state(pfe_hif_chnl_t *chnl)
{
    errno_t ret;
    HifChnlHwStateType hws = {0u};

    /* Stop the channel */
    pfe_hif_chnl_rx_disable(chnl);
    pfe_hif_chnl_tx_disable(chnl);

    /* Detect graceful start (all channel registers are zeroed) */
    pfe_hif_chnl_get_hw_state(chnl, &hws);

    if (hws.is_all_addr_zero)
    {
        NXP_LOG_INFO("HIF%u is in clean state (1000=NOCPY)\n", (uint_t)chnl->id);
        ret = EOK;
    }
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    else if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
        NXP_LOG_INFO("HIF_NOCPY is in un-clean state\n");
        ret = EINVAL;
    }
#endif
    /* Channel state verification continues only for standard HIF: is setup complete? */
    else if (hws.is_any_addr_zero)
    {
        NXP_LOG_ERROR("HIF%u has incomplete set-up. Ungraceful reset cannot be provided.\n", (uint_t)chnl->id);
        ret = EINVAL;
    }
    /* Verify rings sizes */
    else if ( (pfe_hif_ring_get_len(chnl->rx_ring) != hws.rx_ring_len) ||
              (pfe_hif_ring_get_len(chnl->tx_ring) != hws.tx_ring_len)
            )
    {
        NXP_LOG_ERROR("HIF%u ring sizes differ from default. Ungraceful reset cannot be used\n", (uint_t)chnl->id);
        ret = EINVAL;
    }
    else
    {
        NXP_LOG_DEBUG("HIF%u has valid set-up: RX: BD p0x%08x WB p0x%08x len %u, TX: BD p0x%08x WB p0x%08x len %u\n", 
                        (uint_t)chnl->id, 
                        (uint_t)hws.rx_ring_addr, 
                        (uint_t)hws.rx_wb_ring_addr, 
                        (uint_t)hws.rx_ring_len, 
                        (uint_t)hws.tx_ring_addr, 
                        (uint_t)hws.tx_wb_ring_addr, 
                        (uint_t)hws.tx_ring_len);
        ret = EAGAIN;
    }

    return ret;
}

/**
 * @brief       Validate BDR set-up
 * @details     Function reads channel HW registers and compares the set-up of BD rings
 * @param[in]   chnl The channel instance
 * @return      TRUE if new allocated BD rings occupy the same memory regions as were
 *              left in channel registers
 */
static __attribute__((cold)) bool_t pfe_hif_chnl_validate_bdr_setup(pfe_hif_chnl_t *chnl)
{
    bool_t ret = TRUE;
    uint32 rx_ring_addr;
    uint32 rx_wb_ring_addr;
    uint32 tx_ring_addr;
    uint32 tx_wb_ring_addr;

    rx_ring_addr = pfe_hif_chnl_cfg_get_rx_bd_ring_addr(chnl->cbus_base_va, chnl->id);
    rx_wb_ring_addr = pfe_hif_chnl_cfg_get_rx_wb_table_addr(chnl->cbus_base_va, chnl->id);
    tx_ring_addr = pfe_hif_chnl_cfg_get_tx_bd_ring_addr(chnl->cbus_base_va, chnl->id);
    tx_wb_ring_addr = pfe_hif_chnl_cfg_get_tx_wb_table_addr(chnl->cbus_base_va, chnl->id);

    if (rx_ring_addr != (uint32)(addr_t)pfe_hif_ring_get_base_pa(chnl->rx_ring))
    {
        NXP_LOG_ERROR("HIF%u ungraceful reset check: RX BD addr differs\n", (uint_t)chnl->id);
        ret = FALSE;
    }
    else if (rx_wb_ring_addr != (uint32)(addr_t)pfe_hif_ring_get_wb_tbl_pa(chnl->rx_ring))
    {
        NXP_LOG_ERROR("HIF%u ungraceful reset check: RX WB addr differs\n", (uint_t)chnl->id);
        ret = FALSE;
    }
    else if (tx_ring_addr != (uint32)(addr_t)pfe_hif_ring_get_base_pa(chnl->tx_ring))
    {
        NXP_LOG_ERROR("HIF%u ungraceful reset check: TX BD addr differs\n", (uint_t)chnl->id);
        ret = FALSE;
    }
    else if (tx_wb_ring_addr != (uint32)(addr_t)pfe_hif_ring_get_wb_tbl_pa(chnl->tx_ring))
    {
        NXP_LOG_ERROR("HIF%u ungraceful reset check: TX WB addr differs\n", (uint_t)chnl->id);
        ret = FALSE;
    }
    else
    {
        ;   /*Avoid MISRA Rule 15.7*/
    }
    NXP_LOG_INFO("HIF%u ungraceful check: hw/memory setup passed\n", (uint_t)chnl->id);

    return ret;
}

static __attribute__((cold)) errno_t pfe_hif_chnl_find_tx(pfe_hif_chnl_t * chnl)
{
    uint32 ring_idx;
    uint32 ring_len;
    uint32 tx_idx = 0U;
    errno_t ret = ENOENT;

    ring_len = pfe_hif_ring_get_len(chnl->tx_ring);

    (void)pfe_hif_chnl_tx_enable(chnl);

    for (ring_idx = 0U; ring_idx < ring_len; ring_idx++)
    {
        /* Send invalid packet(s) (to be dropped on Class) */
        ret = pfe_hif_chnl_send_dummy_frame(chnl, (void *) dummy_tx_buf, DUMMY_FRAME_INVALID);
        if (EOK != ret) 
        {
            NXP_LOG_ERROR("Can't send frame\n");
            break;
        }

        /* Wait */
        oal_time_usleep(500U);

        /* Find valid WB entry. It indicates the current position of TX ring */
        ret = pfe_hif_ring_find_wb_entry(chnl->tx_ring, TRUE, &tx_idx);
        if (EOK == ret)
        {
            NXP_LOG_DEBUG("TX index found for HIF%u: %u\n", (uint_t)chnl->id, (uint_t)tx_idx);
            break;
        }

        /* The index was not here, so invalidate current BD */
        pfe_hif_ring_invalidate_direct(chnl->tx_ring, ring_idx);
    }

    if (ENOENT == ret)
    {
        NXP_LOG_ERROR("TX index not found for HIF%u.\n", (uint_t)chnl->id);
    }
    else if (EOK == ret)
    {
        PfeDevAssert(tx_idx < UINT32_MAX);
        pfe_hif_ring_invalidate_direct(chnl->tx_ring, tx_idx);
        (void)pfe_hif_ring_force_index(chnl->tx_ring, tx_idx + 1U);
    }
    else
    {
        ;   /*Avoid MISRA Rule 15.7*/
    }

    pfe_hif_chnl_tx_disable(chnl);

    return ret;
}

/* Instruct BDP to fetch BD */
static __attribute__((cold)) void pfe_hif_chnl_bdp_fetch_bd(pfe_hif_chnl_t * chnl)
{
    (void)pfe_hif_chnl_rx_enable(chnl);
    oal_time_usleep(500U);
    pfe_hif_chnl_rx_disable(chnl);
}

/* Helper function for pfe_hif_chnl_find_rx */
static __attribute__((cold)) errno_t pfe_hif_chnl_cache_bd(pfe_hif_chnl_t * chnl)
{
    uint32 ring_len;
    uint32 ring_idx;
    void *buf_va;
    void *buf_pa;
    errno_t ret = EOK;

    ring_len = pfe_hif_ring_get_len(chnl->rx_ring);

    /* To fit in RX hunter method we used (which is based on cached BD(s))
    * provide one BD and let BDP cache it.
    * We need two steps to cover the whole buffer, first with even BDs
    * and then switch to odd BDs in case of no success.
    */
   
    /* Alloc one frame buffer */
    buf_va = (void *)(&dummy_rx_buf);
    buf_pa = buf_va;    /* PA == VA */

    for (ring_idx = 0U; ring_idx < ring_len; ring_idx++)
    {
        ret = pfe_hif_chnl_supply_rx_buf(chnl, buf_pa, sizeof(dummy_rx_buf));
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Can't provide dummy RX buffer\n");
            break;
        }
    }

    if(EOK == ret)
    {
        /* First step: even BDs */
        for (ring_idx = 1U; ring_idx < ring_len; ring_idx += 2U)
        {
            pfe_hif_ring_invalidate_direct(chnl->rx_ring, ring_idx);
        }

        pfe_hif_chnl_bdp_fetch_bd(chnl);

        if (TRUE == pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(chnl->cbus_base_va, chnl->id))
        {
            /* Second step: odd BDs (in case when even BDs try was not sucessful */
            (void)pfe_hif_ring_force_index(chnl->rx_ring, 0U);

            for (ring_idx = 0U; ring_idx < ring_len; ring_idx += 2U)
            {
                /* Invalidate odd BD */
                pfe_hif_ring_invalidate_direct(chnl->rx_ring, ring_idx);
                /* Revalidate back even BD */
                pfe_hif_ring_revalidate_direct(chnl->rx_ring, ring_idx + 1U);
            }

            pfe_hif_chnl_bdp_fetch_bd(chnl);

            if (TRUE == pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(chnl->cbus_base_va, chnl->id))
            {
                /* Something got wrong */
                NXP_LOG_ERROR("HIF%u is not able to cache BD\n", (uint_t)chnl->id);
                ret = EINVAL;
            }
        }

        if(EOK == ret)
        {
            (void)pfe_hif_ring_force_index(chnl->rx_ring, 0U);
            /* Clean ring */
            for (ring_idx = 0U; ring_idx < ring_len; ring_idx++)
            {
                pfe_hif_ring_invalidate_direct(chnl->rx_ring, ring_idx);
            }
        }
    }

    return ret;
}

/* Helper function to empty cached BDs first */
static __attribute__((cold)) errno_t pfe_hif_chnl_empty_cached_bd(pfe_hif_chnl_t * chnl)
{
    uint32 ring_len;
    uint32 rx_bdp_fifo_empty_timeout = 0U;
    errno_t ret = EOK;

    ring_len = pfe_hif_ring_get_len(chnl->rx_ring);

    /* Empty cached BDs first */
    while(FALSE == pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(chnl->cbus_base_va, chnl->id))
    {
        /* Could not empty BDP fifo - most likely due to ERR051211 workaround */
        if((rx_bdp_fifo_empty_timeout ++) >= ring_len)
        {
            NXP_LOG_ERROR("HIF%u couldn\'t empty BDP FIFO\n", (uint_t)chnl->id);
            ret = ETIMEDOUT;
            break;
        }

        /* Send dummy packet to self HIF channel */
        ret = pfe_hif_chnl_send_dummy_frame(chnl, (void *) dummy_tx_buf, DUMMY_FRAME_IHC_SELF);
        if (EOK != ret)
        {
            break;
        }

        /* Wait */
        oal_time_usleep(500U);

        /* Do TX confirmations */
        ret = pfe_hif_chnl_get_tx_conf(chnl);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Can't get TX confirmation\n");
            break;
        }
    }

    return ret;
}

static __attribute__((cold)) errno_t pfe_hif_chnl_find_rx(pfe_hif_chnl_t * chnl)
{
    uint32 rx_idx = 0U;
    errno_t ret = EOK;

    if (TRUE == pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(chnl->cbus_base_va, chnl->id))
    {
        /* To fit in RX hunter method we used (which is based on cached BD(s))
        * provide one BD and let BDP cache it.
        */
        ret = pfe_hif_chnl_cache_bd(chnl);
    }

    if(EOK == ret)
    {
        /* Requires clean RX ring, with default WB BD control words (value: 0x200) */
        /* Start RX DMA */
        pfe_hif_chnl_enable(chnl);

        ret = pfe_hif_chnl_empty_cached_bd(chnl);

        if(EOK == ret)
        {
            /* Find invalid WB entry. It indicates the current (stop) position of RX ring
            * NOTE: it can also wrap around.
            */
            if (EOK != pfe_hif_ring_find_wb_entry(chnl->rx_ring, FALSE, &rx_idx))
            {
                /* Something got wrong */
                NXP_LOG_ERROR("HIF%u is not able to find correct WB entry\n", (uint_t)chnl->id);
                ret = EINVAL;
            }
            else
            {
                NXP_LOG_DEBUG("Found RX index: %u\n", (uint_t)rx_idx);
                (void)pfe_hif_ring_force_index(chnl->rx_ring, rx_idx);
            }
        }
    }

    pfe_hif_chnl_disable(chnl);

    return ret;
}

static __attribute__((cold)) errno_t pfe_hif_chnl_dummy_packet_to_self(pfe_hif_chnl_t * chnl, void ** buf_pa)
{
    errno_t ret = EOK;

    /* Fill one buffer only */
    ret = pfe_hif_chnl_supply_rx_buf(chnl, *buf_pa, sizeof(dummy_rx_buf));
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Can't provide dummy RX buffer\n");
    }
    else
    {
        /* Send dummy packet to self HIF channel */
        ret = pfe_hif_chnl_send_dummy_frame(chnl, (void *) dummy_tx_buf, DUMMY_FRAME_IHC_SELF);
    }

    return ret;
}

static __attribute__((cold)) errno_t pfe_hif_chnl_do_tx_rx(pfe_hif_chnl_t * chnl, bool_t * lifm)
{
    errno_t ret = EOK;

    /* Do TX confirmations */
    ret = pfe_hif_chnl_get_tx_conf(chnl);
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Can't provide dummy RX buffer\n");
    }
    else
    {
        /* Do plain RX */
        ret = pfe_hif_ring_dequeue_plain(chnl->rx_ring, lifm);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Can't get RX buffer dequeued\n");
        }
    }

    return ret;
}

static __attribute__((cold)) errno_t pfe_hif_chnl_rx_to_head(pfe_hif_chnl_t * chnl)
{
    uint32 ring_item_idx;
    uint32 ring_len;
    void *buf_va = NULL_PTR;
    void *buf_pa;
    bool_t lifm;
    errno_t ret = EOK;

    /* Alloc one frame buffer */
    buf_va = (void *)(&dummy_rx_buf);
    buf_pa = buf_va;    /* PA == VA */

    ring_len = pfe_hif_ring_get_len(chnl->rx_ring);

    /* Start RX DMA */
    pfe_hif_chnl_enable(chnl);

    ring_item_idx = 0U;
    while ((FALSE == pfe_hif_ring_is_on_head(chnl->rx_ring)) && (ring_len > ring_item_idx))
    {
        /* Send dummy packet to self HIF channel */
        ret = pfe_hif_chnl_dummy_packet_to_self(chnl, &buf_pa);

        if (EOK != ret)
        {
            break;
        }

        /* Wait */
        oal_time_usleep(500U);

        /* Do TX confirmations and plain RX */
        ret = pfe_hif_chnl_do_tx_rx(chnl, &lifm);
        if (EOK != ret)
        {
            break;
        }

        ring_item_idx++;
    }

    if(EOK == ret)
    {
        if (ring_len <= ring_item_idx)
        {
            NXP_LOG_ERROR("Can't reach RX ring head\n");
            ret = EINVAL;
        }
        for (ring_item_idx = 0U; ring_item_idx < ring_len; ring_item_idx++)
        {
            pfe_hif_ring_invalidate_direct(chnl->rx_ring, ring_item_idx);
        }
    }

    pfe_hif_chnl_disable(chnl);

    return ret;
}

/* Disable TX and invalidate rings*/
static __attribute__((cold)) void pfe_hif_chnl_disable_invalidate(pfe_hif_chnl_t * chnl)
{
    uint32 ring_idx;
    uint32 ring_len;
    ring_len = pfe_hif_ring_get_len(chnl->tx_ring);

    pfe_hif_chnl_tx_disable(chnl);

    for (ring_idx = 0U; ring_idx < ring_len; ring_idx++)
    {
        pfe_hif_ring_invalidate_direct(chnl->tx_ring, ring_idx);
    }   
}

static __attribute__((cold)) errno_t pfe_hif_chnl_tx_to_head(pfe_hif_chnl_t * chnl)
{
    uint32 ring_idx;
    uint32 ring_len;
    errno_t ret = EOK;

    ring_len = pfe_hif_ring_get_len(chnl->tx_ring);

    pfe_hif_chnl_rx_disable(chnl);
    (void)pfe_hif_chnl_tx_enable(chnl); /* Start TX DMA */

    ring_idx = 0U;
    while (FALSE == pfe_hif_ring_is_on_head(chnl->tx_ring) && (ring_len > ring_idx))
    {
        /* Send invalid packet (to be dropped on Class) */
        ret = pfe_hif_chnl_send_dummy_frame(chnl, (void *) dummy_tx_buf, DUMMY_FRAME_INVALID);
        if (EOK != ret)
        {
            break;
        }

        /* Wait */
        oal_time_usleep(500U);

        /* Do TX confirmations */
        ret = pfe_hif_chnl_get_tx_conf(chnl);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Can't read TX confirmation\n");
            break;
        }

        ring_idx++;
    }

    if(EOK == ret)
    {
        if (ring_len <= ring_idx)
        {
            NXP_LOG_ERROR("Can't reach TX ring head\n");
            ret = EINVAL;
        }
    }

    /* Disable TX and invalidate rings*/
    pfe_hif_chnl_disable_invalidate(chnl);

    return ret;
}

static __attribute__((cold)) errno_t pfe_hif_chnl_ungraceful_reset(pfe_hif_chnl_t * chnl)
{
    errno_t ret;

    /* Find TX index first */
    ret = pfe_hif_chnl_find_tx(chnl);
    if (EOK == ret)
    {
        NXP_LOG_INFO("HIF%u ungraceful reset: stage 1 (tx finder) passed\n", (uint_t)chnl->id);
        
        /* Next find RX index */
        ret = pfe_hif_chnl_find_rx(chnl);
    }
    
    if (EOK == ret)
    {
        NXP_LOG_INFO("HIF%u ungraceful reset: stage 2 (rx finder) passed\n", (uint_t)chnl->id);

        /* Move to RX head first */
        ret = pfe_hif_chnl_rx_to_head(chnl);
    }
    
    if (EOK == ret)
    {
        NXP_LOG_INFO("HIF%u ungraceful reset: stage 3 (rx to head) passed\n", (uint_t)chnl->id);

        /* Next move to TX index */
        ret = pfe_hif_chnl_tx_to_head(chnl);
    }
    
    if (EOK == ret)
    {
        NXP_LOG_INFO("HIF%u ungraceful reset: stage 4 (tx to head) passed\n", (uint_t)chnl->id);
        NXP_LOG_INFO("HIF%u ungraceful reset: finished\n", (uint_t)chnl->id);
    }

    return ret;
}

/* Bind BD rings to the channels. Skip for minihif.  */
static __attribute__((cold)) errno_t pfe_hif_chnl_bind_bd_rings(pfe_hif_chnl_t *chnl)
{
    errno_t ret = EOK;
    
    /*  Bind TX BD ring to channel */
    if (EOK != pfe_hif_chnl_bind_tx_ring(chnl))
    {
        /*  Destroy unattached rings */
        (void)pfe_hif_ring_destroy(chnl->tx_ring);
        ret = EFAULT;
    }
    /*  Bind RX BD ring to channel */
    else if (EOK != pfe_hif_chnl_bind_rx_ring(chnl))
    {
        /*  Destroy unattached rings */
        (void)pfe_hif_ring_destroy(chnl->tx_ring);
        (void)pfe_hif_ring_destroy(chnl->rx_ring);
        ret = EFAULT;
    }
    /* Required by MISRA*/
    else
    {
        ;   /*Avoid MISRA Rule 15.7*/
    }

    return ret;
}

/* Configure rx buffer pools based on used channel (std or nocpy) */
static __attribute__((cold)) errno_t pfe_hif_chnl_rx_pool_init(pfe_hif_chnl_t *chnl)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
        if (NULL == chnl->bmu)
        {
            NXP_LOG_ERROR("Channel requires BMU instance\n");
            ret = EFAULT;
        }
        else
        {
            /* HIF NOCPY does not need external RX buffers */
            rx_pool_init(&(chnl->rx_pool), NULL_PTR, &rx_meta_buf_mem_hifnocpy[0U], 0U, 0U);
        }
    }
    else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    {
        if(chnl->id < HIF_CFG_MAX_CHANNELS)
        {
            /* Initialize RX buffer pool. */
            NXP_LOG_INFO("Initializing RX buffer pool. Depth: %u; Buffer Size: %d; Cache Line Size: %d\n",
                        (uint_t)pfe_hif_chnl_get_rx_fifo_depth(chnl), ETH_43_PFE_CFG_HIF_RX_BUF_SIZE, HAL_CACHE_LINE_SIZE);
            rx_pool_init( &(chnl->rx_pool),
                        &rx_buf_mem[0U],
                        &rx_meta_buf_mem[0U],
                        ETH_43_PFE_CFG_HIF_RX_BUF_SIZE,
                        ETH_43_PFE_CFG_HIF_RX_BUF_NUM
                        );
        }
        else
        {
            NXP_LOG_ERROR("Channel id exceeds max channel\n");
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Initialize a channel
 * @details     Function prepares the HIF channel according to user-supplied parameters.
 *              This includes allocation of resources and configuration of the hardware.
 *              Routine must be called before RX or TX functionality is enabled.
 * @param[in]   chnl The channel instance
 * @return      EOK Success
 */
__attribute__((cold)) errno_t pfe_hif_chnl_init(pfe_hif_chnl_t *chnl)
{
    errno_t ret = EOK;
    errno_t hw_status = EOK;
#if defined(PFE_CFG_PFE_MASTER)
    static const uint32 common_hif_id = (ETH_43_PFE_COMMON_HIF == PFE_PHY_IF_ID_HIF_NOCPY)
                                          ? PFE_HIF_CHNL_NOCPY_ID
                                          : (uint32)(ETH_43_PFE_COMMON_HIF - PFE_PHY_IF_ID_HIF0);
#endif /* PFE_CFG_PFE_MASTER */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Skip this check for master driver's HIF chnl (still executed on master for minihif) */
#if defined(PFE_CFG_PFE_MASTER)
        if (common_hif_id != chnl->id)
#endif
        {
            /* Check the HIF channel state */
            hw_status = pfe_hif_chnl_inspect_hw_state(chnl);
        }
        /* In case channel is not clean, do the ungracefull recovery */
        /* NOTE: until now the new allocated BDRs must not be set to the channel HW */
        if (EAGAIN == hw_status)
        {
            /* Slave only way supporting ungraceful HIF reset */
            if (FALSE == pfe_hif_chnl_validate_bdr_setup(chnl))
            {
                NXP_LOG_ERROR("BDR setup not valid\n");
                ret = EFAULT;
            }
            else if (EOK != pfe_hif_chnl_ungraceful_reset(chnl))
            {
                /* Process ungraceful HIF reset procedure */
                NXP_LOG_ERROR("Could not perform ungraceful reset\n");
                ret = EFAULT;
            }
            else
            {
                ; /* Do nothing */
            }
        }
        else
        {
            /* Bind BD rings in the channel registers */
            ret = pfe_hif_chnl_bind_bd_rings(chnl);
        }
    }

    return ret;
}

/**
 * @brief       Get the RX BD processor state
 * @param[in]   chnl The channel instance
 * @return      TRUE if the BDP is active, FALSE otherwise
 */
__attribute__((hot)) bool_t pfe_hif_chnl_is_rx_dma_active(const pfe_hif_chnl_t *chnl)
{
    bool_t is_rx_active;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_rx_active = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* No protection here. Getting DMA status is atomic. */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            is_rx_active = pfe_hif_nocpy_cfg_is_rx_dma_active(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            /* HIF */
            is_rx_active = pfe_hif_chnl_cfg_is_rx_dma_active(chnl->cbus_base_va, chnl->id);
        }
    }

    return is_rx_active;
}

/**
 * @brief       Get the TX BD processor state
 * @param[in]   chnl The channel instance
 * @return      TRUE if the BDP is active, FALSE otherwise
 */
__attribute__((hot)) bool_t pfe_hif_chnl_is_tx_dma_active(const pfe_hif_chnl_t *chnl)
{
    bool_t is_tx_active;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_tx_active = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* No protection here. Getting DMA status is atomic. */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            is_tx_active = pfe_hif_nocpy_cfg_is_tx_dma_active(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            /* HIF */
            is_tx_active = pfe_hif_chnl_cfg_is_tx_dma_active(chnl->cbus_base_va, chnl->id);
        }
    }

    return is_tx_active;
}

/**
 * @brief       Send dummy pkt to self Hif channel
 * @param[in]   chnl The channel instance
 * @param[in]   tx_buf_va Tx buffer virtual address
 * @param[in]   mode Dummy frame send mode
 */
static __attribute__((cold)) errno_t pfe_hif_chnl_send_dummy_frame(pfe_hif_chnl_t *chnl, void *tx_buf_va, send_dummy_frame_mode_t mode)
{
    pfe_ct_hif_tx_hdr_t *tx_hdr;
    errno_t ret = EOK;

    tx_hdr = (pfe_ct_hif_tx_hdr_t *)tx_buf_va;

    switch (mode)
    {
        case DUMMY_FRAME_INVALID:
            /* send invalid frame */
            tx_hdr->e_phy_ifs = 0U;
            tx_hdr->flags = HIF_TX_NO_FLAG;
            break;

        case DUMMY_FRAME_IHC_SELF:
            /* send IHC frame to self channel */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
            {
                tx_hdr->e_phy_ifs = oal_htonl((uint32)1U << PFE_PHY_IF_ID_HIF_NOCPY);
            }
            else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
            {
                PfeDevAssert(chnl->id < HIF_CFG_MAX_CHANNELS);
                tx_hdr->e_phy_ifs = oal_htonl((uint32)1U << ((uint8)PFE_PHY_IF_ID_HIF0 + (uint8)chnl->id));
            }
            tx_hdr->flags = (pfe_ct_hif_tx_flags_t)(HIF_TX_INJECT|HIF_TX_IHC);
            tx_hdr->chid = (uint8)(chnl->id & UINT8_MAX);
            break;

        default:
            break;
    }

    /*  Send dummy packet to self HIF channel */
    if (EOK != pfe_hif_chnl_tx(chnl, tx_buf_va, DUMMY_TX_BUF_LEN))
    {
        NXP_LOG_ERROR("Dummy frame TX failed\n");
    }

    return ret;
}

#if defined(PFE_CFG_PFE_SLAVE)
/**
 * @brief       Reset the rx ring by flush the RX BDP FIFO and set the current receive address to the original.
 * @param[in]   chnl The channel instance
 * @param[in]   ii The counter number of entry
 * @param[in]   tx_buf_va Tx buffer virtual address
 * @return      EOK if success, error code otherwise
 */
static __attribute__((cold)) errno_t pfe_hif_chnl_rx_ring_soft_reset(pfe_hif_chnl_t *chnl, uint32 ii, void *tx_buf_va)
{
    errno_t ret = EOK;
    uint32 count = ii;

    /* Flush the RX BDP FIFO */
    while (FALSE == pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(chnl->cbus_base_va, chnl->id))
    {
        pfe_hif_chnl_send_dummy_rx(chnl, (void *)&dummy_rx_buf, tx_buf_va);

        /* Decrement timeout counter */
        if (count > 0U)
        {
            count--;
        }
        else
        {
            NXP_LOG_ERROR("RX BD ring flush timed-out\n");
            ret = ETIMEDOUT;
            break;
        }
    }

#if defined(PFE_CFG_PFE_SLAVE)
    /* For Slave mode, need to transmit some more dummy frames to reset the RX ring pointer to the beginning position (see AAVB-3704).
       For Master mode, don't need transmit some more dummy frames to reset the RX ring pointer to the beginning position because there
       will be a PFE HW reset done in Master driver when re-init. So the issue in (AAVB-3704) doesn't happen with Master mode. */
    if (EOK == ret)
    {
        count = ii;
        /* When a slave driver instance requires reset, the associated HIF channel remembers rx/tx ring pointers.
           So when the driver is shut down and started again, the driver and HW ring pointers are different (driver
           points to first entry in the rings while hardware points to entry given by the previous state), We need
           to reset the current receivetion ring address to the origin to synchronize the ring pointer between hardware and software */
        while (chnl->rx_ring->bd_read.rd_bd != chnl->rx_ring->base_va)
        {
            pfe_hif_chnl_send_dummy_rx(chnl, (void *)&dummy_rx_buf, tx_buf_va);

            /* Decrement timeout counter */
            if (count > 0U)
            {
                count--;
            }
            else
            {
                NXP_LOG_ERROR("RX BD ring reset timed-out\n");
                ret = ETIMEDOUT;
                break;
            }
        }
    }
#endif /* PFE_CFG_PFE_SLAVE */

    if(EOK != ret)
    {
        void *buf_pa;

        /* Drain all in case when flush process has somehow failed */
        while (EOK == pfe_hif_ring_drain_buf(chnl->rx_ring, &buf_pa))
        {
            ;
        }
    }

    return ret;
}
#endif /* PFE_CFG_PFE_SLAVE */

#if defined(PFE_CFG_PFE_SLAVE)
/**
 * @brief       Flush RX BDP buffer and Reset the current receivetion ring address to the origin
 * @details     When channel is stopped the fetched BDs are remaining in internal
 *              buffer and don't get flushed once channel is re-enabled. This
 *              causes memory corruption when channel driver is stopped and then
 *              started with other BD rings because HIF is missing possibility
 *              to reset particular channels separately without affecting the
 *              other channels.
 *              When a slave driver instance requires reset, the associated HIF
 *              channel remembers rx/tx ring pointers. So when the driver is shut
 *              down and started again, the driver and HW ring pointers are different 
 *              (driver points to first entry in the rings while hardware points
 *              to entry given by the previous state), We need to reset the current
 *              receivetion ring address to the origin to synchronize the ring pointer
 *              between hardware and software
 * @param[in]   chnl The channel instance
 * @return      EOK if success, error code otherwise
 */
static __attribute__((cold)) errno_t pfe_hif_chnl_reset_rx_ring(pfe_hif_chnl_t *chnl)
{
    void *tx_buf_va = NULL;
    uint32 ii;
    errno_t ret = EOK;

    tx_buf_va = (void *)(&dummy_tx_buf);

    /*  Activate the channel */
    (void)pfe_hif_chnl_rx_enable(chnl);
    (void)pfe_hif_chnl_tx_enable(chnl);

    /*  Get maximum number of tries */
    ii = pfe_hif_ring_get_len(chnl->rx_ring);

    /*  Try to flush the internal BD FIFO and reset the current receivetion ring address to the origin by software. */
    ret = pfe_hif_chnl_rx_ring_soft_reset(chnl, ii, tx_buf_va);

    /*  Deactivate the channel */
    (void)pfe_hif_chnl_rx_disable(chnl);
    (void)pfe_hif_chnl_tx_disable(chnl);

    return ret;
}
#endif /* PFE_CFG_PFE_SLAVE */

/**
 * @brief       Destroy HIF channel instance
 * @param[in]   chnl The channel instance
 */
__attribute__((cold)) void pfe_hif_chnl_destroy_chnl(pfe_hif_chnl_t *chnl)
{
    /*  Disable and finalize the channel */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
        /* HIF NOCPY will do the finalization */
    }
    else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    {
        oal_mutex_lock(PFE_CHNL_LOCK_MUTEX_12);

        pfe_hif_chnl_cfg_fini(chnl->cbus_base_va, chnl->id);

        oal_mutex_unlock(PFE_CHNL_LOCK_MUTEX_12);
    }
}

static __attribute__((cold)) void pfe_hif_chnl_destroy_rings(pfe_hif_chnl_t *chnl)
{
    /*  Disable the HIF channel BDP/DMA */
    pfe_hif_chnl_rx_disable(chnl);
    pfe_hif_chnl_tx_disable(chnl);

    /*  Destroy rings */
    if (NULL != chnl->rx_ring)
    {
        (void)pfe_hif_ring_destroy(chnl->rx_ring);
        chnl->rx_ring = NULL;
    }

    if (NULL != chnl->tx_ring)
    {
        if (TRUE != pfe_hif_chnl_cfg_is_tx_bdp_fifo_empty(chnl->cbus_base_va, chnl->id))
        {
            NXP_LOG_WARNING("HIF channel TX FIFO is not empty\n");
        }

        (void)pfe_hif_ring_destroy(chnl->tx_ring);
        chnl->tx_ring = NULL;
    }

    pfe_hif_chnl_destroy_chnl(chnl);
}

static __attribute__((cold)) void pfe_hif_chnl_destroy_inval_rx_ring(pfe_hif_chnl_t *chnl)
{
#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
    void *buf_pa = NULL;
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

#if (TRUE == PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED)
    /*  Drain RX buffers (the ones enqueued in RX ring) */
    while (EOK == pfe_hif_ring_drain_buf(chnl->rx_ring, &buf_pa))
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /*  HIF NOCPY buffers are provided by BMU so return them to BMU */
            pfe_bmu_free_buf(chnl->bmu, (addr_t)buf_pa);
        }
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    }

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
#if defined(NXP_LOG_ENABLED)
    if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
    {
        /* Sanity check to verify if the HIF RX ring and the upper SW layers
           have properly returned all RX and TX buffers back to the BMU. We're
           using the allocations counter here to determine delta between number
           of allocated buffers (either TX buffers we have directly allocated
           or received buffers which have been allocated by the PFE HW) and
           number of released buffers. */
        if (0U != pfe_hif_chnl_get_alloc_cnt(chnl))
        {
            NXP_LOG_WARNING("Some buffers not returned to the BMU\n");
        }
        else
        {
            NXP_LOG_INFO("All buffers returned to the BMU\n");
        }
    }
#endif /* NXP_LOG_ENABLED */
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
#endif /* PFE_HIF_CHNL_CFG_RX_BUFFERS_ENABLED */

    /* Invalidate the RX ring */
    pfe_hif_ring_invalidate(chnl->rx_ring);

#if defined(PFE_CFG_PFE_SLAVE)
    /* Here the ring should be empty. Execute HIF channel BDP shutdown (a.k.a. Graceful reset)
       procedure to ensure that channel will not keep any content in internal buffers. */
    if (EOK != pfe_hif_chnl_reset_rx_ring(chnl))
    {
        NXP_LOG_ERROR("FATAL: Could not flush RX BD FIFO\n");
    }
#endif /* PFE_CFG_PFE_SLAVE */
}

#if defined(PFE_CFG_PFE_SLAVE)
/**
 * @brief       Reset the current transmission ring address to the origin
 * @details     When a slave driver instance requires reset, the associated HIF
 *              channel remembers rx/tx ring pointers. So when the driver is shut
 *              down and started again, the driver and HW ring pointers are different 
 *              (driver points to first entry in the rings while hardware points
 *              to entry given by the previous state), We need to reset the current
 *              transmission ring address to the origin to synchronize the ring pointer
 *              between hardware and software
 * @param[in]   chnl The channel instance
 * @return      EOK if success, error code otherwise
 */

static __attribute__((cold)) void pfe_hif_chnl_reset_tx_ring(pfe_hif_chnl_t *chnl)
{
    void *tx_buf_va = NULL;
    uint32 count;

    tx_buf_va = (void *)(&dummy_tx_buf);
    
    /*  Activate the tx channel */
    (void)pfe_hif_chnl_tx_enable(chnl);

    /*  Get maximum number of tries */
    count = pfe_hif_ring_get_len(chnl->tx_ring);

    while (chnl->tx_ring->bd_read.rd_bd != chnl->tx_ring->base_va)
    {
        /*  Send dummy packet to self HIF channel */
        (void)pfe_hif_chnl_send_dummy_frame(chnl, tx_buf_va, DUMMY_FRAME_INVALID);

        /*  Wait */
        oal_time_usleep(500U);

        /*  Do TX confirmations */
        while (EOK == pfe_hif_chnl_get_tx_conf(chnl))
        {
            oal_time_usleep(100U);
        }
        /*  Decrement timeout counter */
        if (count > 0U)
        {
            count--;
        }
        else
        {
            NXP_LOG_ERROR("TX BD ring reset timed-out\n");
            break;
        }
    }

    /*  Deactivate the tx channel */
    (void)pfe_hif_chnl_tx_disable(chnl);
}
#endif /* PFE_CFG_PFE_SLAVE */

/**
 * @brief       Destroy HIF channel instance
 * @param[in]   chnl The channel instance
 */
__attribute__((cold)) void pfe_hif_chnl_destroy(pfe_hif_chnl_t *chnl)
{
    if (NULL != chnl)
    {
        /*  Disable channel interrupts */
        pfe_hif_chnl_irq_mask(chnl);
        pfe_hif_chnl_rx_irq_mask(chnl);
        pfe_hif_chnl_tx_irq_mask(chnl);

        /*  Uninstall callbacks */
        chnl->rx_cbk.cbk = NULL;
        chnl->tx_cbk.cbk = NULL;

        if (NULL != chnl->rx_ring)
        {
            pfe_hif_chnl_destroy_inval_rx_ring(chnl);
        }

#if defined(PFE_CFG_PFE_SLAVE)
        /* For Slave mode, neen to call pfe_hif_chnl_reset_tx_ring() to reset the TX ring pointer to the beginning position (see AAVB-3704).
           For Master mode, don't need to call pfe_hif_chnl_reset_tx_ring() because there will be a PFE HW reset done in Master driver when re-init.
           So the issue in (AAVB-3704) doesn't happen with Master mode. */
        if (NULL != chnl->tx_ring)
        {
            pfe_hif_chnl_reset_tx_ring(chnl);
        }

        /* Clear channel registers to signalize graceful shutdown */
        pfe_hif_chnl_cfg_set_rx_bd_ring_addr(chnl->cbus_base_va, chnl->id, (void *)0LU);
        pfe_hif_chnl_cfg_set_rx_wb_table(chnl->cbus_base_va, chnl->id, (void *)0LU, 0U);
        pfe_hif_chnl_cfg_set_tx_bd_ring_addr(chnl->cbus_base_va, chnl->id, (void *)0LU);
        pfe_hif_chnl_cfg_set_tx_wb_table(chnl->cbus_base_va, chnl->id, (void *)0LU, 0U);
#endif /* PFE_CFG_PFE_SLAVE */

        pfe_hif_chnl_destroy_rings(chnl);
    }
}

/**
 * @brief       Dump of SW client channel rings
 * @details     Dumps particular ring
 * @param[in]   chnl The client channel instance
 * @param[in]   dump_rx True if RX ring has to be dumped
 * @param[in]   dump_tx True if TX ring has to be dumped
 */
__attribute__((cold)) void pfe_hif_chnl_dump_ring(const pfe_hif_chnl_t *chnl, bool_t dump_rx, bool_t dump_tx)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if(chnl->id < PFE_HIF_CHNL_NOCPY_ID)
        {
            NXP_LOG_RAW_ERROR("Unsupported ring type, only NOCPY is supported in this configuration");
        }
        else
#endif
        {
            if(dump_rx)
            {
                pfe_hif_ring_dump(chnl->rx_ring, "RX");
            }
    
            if(dump_tx)
            {
                pfe_hif_ring_dump(chnl->tx_ring, "TX");
            }
        }
    }
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return HIF channel runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   chnl        The channel instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level, number of data written to the buffer
 * @return      Number of bytes written to the buffe
 */
__attribute__((cold)) uint32 pfe_hif_chnl_get_text_statistics(const pfe_hif_chnl_t *chnl, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            len += pfe_hif_nocpy_chnl_cfg_get_text_stat(chnl->cbus_base_va, buf, buf_len, verb_level);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            /* HIF */
            len += pfe_hif_chnl_cfg_get_text_stat(chnl->cbus_base_va, chnl->id, buf, buf_len, verb_level);
        }
    }

    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get number of transmitted packets (from PFE to HOST)
 * @param[in]   emac The channel instance
 * @return      Number of transmitted packets
 */
uint32 pfe_hif_chnl_get_tx_cnt(const pfe_hif_chnl_t *chnl)
{
    uint32 tx_cnt;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        tx_cnt = 0xffffffffU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            tx_cnt = pfe_hif_nocpy_cfg_get_tx_cnt(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            tx_cnt = pfe_hif_chnl_cfg_get_tx_cnt(chnl->cbus_base_va, chnl->id);
        }
    }

    return tx_cnt;
}

/**
 * @brief       Get number of received packets (from HOST to PFE)
 * @param[in]   emac The channel instance
 * @return      Number of received packets
 */
uint32 pfe_hif_chnl_get_rx_cnt(const pfe_hif_chnl_t *chnl)
{
    uint32 rx_cnt;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        rx_cnt = 0xffffffffU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            /* HIF_NOCPY */
            rx_cnt = pfe_hif_nocpy_cfg_get_rx_cnt(chnl->cbus_base_va);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            rx_cnt = pfe_hif_chnl_cfg_get_rx_cnt(chnl->cbus_base_va, chnl->id);
        }
    }

    return rx_cnt;
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       Allocate buffer via BMU
 * @param[in]   chnl The channel instance
 * @return      Allocated buffer pointer (virtual)
 */
__attribute__((hot)) void *pfe_hif_chnl_bmu_alloc_buf_va(pfe_hif_chnl_t *chnl)
{
    void *tx_buf_pa;
    void *ret = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tx_buf_pa = pfe_bmu_alloc_buf(chnl->bmu);
        if (unlikely(NULL == tx_buf_pa))
        {
            NXP_LOG_ERROR("BMU can't allocate TX buffer\n");
            ret = NULL;
        }
        else
        {
#if defined(NXP_LOG_ENABLED)
            /*  Increment BMU allocations counter */
            pfe_hif_chnl_alloc_inc(chnl);
#endif /* NXP_LOG_ENABLED */

            /*  Get VA */
            ret = (void *) pfe_bmu_get_va(chnl->bmu, (addr_t)tx_buf_pa);
        }
    }
    return ret;
}

/**
 * @brief       Convert virtual buffer address to physical one
 * @param[in]   chnl The channel instance
 * @param[in]   va The address to be converted
 * @return      Associated virtual address or NULL if failed
 */
__attribute__((hot)) void *pfe_hif_chnl_bmu_get_buf_pa(const pfe_hif_chnl_t *chnl, addr_t va)
{
    void *ReVal;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ReVal = NULL;
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    ReVal = (void *) pfe_bmu_get_pa(chnl->bmu, (addr_t)va);
    return ReVal;
}

/**
 * @brief       Free buffer via BMU
 * @param[in]   chnl The channel instance
 * @param[in]   va Pointer (virtual) to the buffer to be freed.
 * @note        Thread safe
 */
__attribute__((hot)) void pfe_hif_chnl_bmu_free_buf(pfe_hif_chnl_t *chnl, addr_t va)
{
    void *tx_buf_pa;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tx_buf_pa = (void *)pfe_bmu_get_pa(chnl->bmu, (addr_t)va);

        pfe_bmu_free_buf(chnl->bmu, (addr_t)tx_buf_pa);

#if defined(NXP_LOG_ENABLED)
        /*  Decrement BMU allocations counter */
        pfe_hif_chnl_alloc_dec(chnl);
#endif /* NXP_LOG_ENABLED */
    }
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       Set the value of LMEM Header size used by the HW
 * @param[in]   chnl The channel instance
 * @param[in]   lmem_header_size The size of LMEM Header
 */
void pfe_hif_chnl_set_lmem_hdr_size(pfe_hif_chnl_t *chnl, uint16 lmem_header_size)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    chnl->lmem_header_size = lmem_header_size;
#else
    (void)lmem_header_size;
    (void)chnl;
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
}

/**
 * @brief       Get the value of LMEM Header size used by the HW
 * @param[in]   chnl The channel instance
 * @return      The size of LMEM Header
 * @warning     Function shall be used only for HIF_NOCPY channels
 */
uint16 pfe_hif_chnl_get_lmem_hdr_size(const pfe_hif_chnl_t *chnl)
{
    uint16 lmem_header_size = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == chnl))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (chnl->id >= PFE_HIF_CHNL_NOCPY_ID)
        {
            lmem_header_size = chnl->lmem_header_size;
        }
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    (void)chnl;

    return lmem_header_size;
}

/**
 * @brief       Marks that a PFE instance associated with the current HIF channel is owner of an EMAC timer
 * @param[in]   local_chnl Base address of HIF register space (virtual)
 * @param[in]   hif_id The HIF ID that would take timer ownership
 * @param[in]   emac The EMAC id
 * @param[in]   value The value of EMAC timer ownership for the PFE instance associated to current HIF channel. TRUE - owner, FALSE - not owner
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_hif_chnl_set_emac_timer_ownership(addr_t cbus_base_va, pfe_ct_phy_if_id_t hif_id, pfe_ct_phy_if_id_t emac, bool_t value)
{
    errno_t ret = EOK;

    if (PFE_PHY_IF_ID_HIF_NOCPY == hif_id)
    {
        ret = pfe_hif_nocpy_cfg_set_emac_timer_ownership(emac, value);
        (void)cbus_base_va;
        (void)hif_id;
    }
    else
    {
        ret = pfe_hif_chnl_cfg_set_emac_timer_ownership(cbus_base_va, pfe_timer_owner_hif_from_phy_id(hif_id), emac, value);
    }
 
    return ret;
}

/**
 * @brief       Get EMAC timer ownership status for PFE instance associated to the current HIF channel
 * @param[in]   cbus_base_va Base address of HIF register space (virtual)
 * @param[in]   hif_id The HIF ID that would get timer ownership status
 * @param[in]   emac The EMAC id
 * @return      TRUE if PFE instance associated with the current HIF channel is timer owner of specified EMAC, FALSE otherwise
 */
bool_t pfe_hif_chnl_get_emac_timer_ownership(addr_t cbus_base_va, pfe_ct_phy_if_id_t hif_id, pfe_ct_phy_if_id_t emac)
{
    bool_t is_owner = FALSE;

    if (PFE_PHY_IF_ID_HIF_NOCPY == hif_id)
    {
        is_owner = pfe_hif_nocpy_cfg_get_emac_timer_ownership(emac);
        (void)cbus_base_va;
        (void)hif_id;
    }
    else
    {
        is_owner = pfe_hif_chnl_cfg_get_emac_timer_ownership(cbus_base_va, pfe_timer_owner_hif_from_phy_id(hif_id), emac);
    }

    return is_owner;
}

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */


===== 文件 [154/185]: src\pfe_hif_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_cbus.h"
#include "pfe_hm.h"
#include "pfe_hif_csr.h"
#include "pfe_platform_cfg.h"
#include "pfe_feature_mgr.h"
#include "Eth_43_PFE_Cfg.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

/* This macro is created to follow up the ticket AAVB-6034. It could be removed after the issue related is resolved in later ticket */
#define HIF_CH_TIMEOUT_EN (BDP_RD_CSR_RX_TIMEOUT_CH_INT_EN  | BDP_WR_CSR_RX_TIMEOUT_CH_INT_EN \
                          | BDP_RD_CSR_TX_TIMEOUT_CH_INT_EN | BDP_WD_CSR_TX_TIMEOUT_CH_INT_EN \
                          | DXR_CSR_RX_TIMEOUT_CH_INT_EN    | DXR_CSR_TX_TIMEOUT_CH_INT_EN)


#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#if defined(PFE_CFG_TEXT_STATS)
static inline void dump_hif_channel(addr_t base_va, uint32 channel_id)
{
#ifdef NXP_LOG_ENABLED
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));
    NXP_LOG_INFO("HIF_CTRL_CH%u                    : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_WR_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_BDP_WR_LOW_ADDR_CH%u      : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_WR_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_BDP_WR_HIGH_ADDR_CH%u     : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_RD_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_BDP_RD_LOW_ADDR_CH%u      : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_RD_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_BDP_RD_HIGH_ADDR_CH%u     : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_WR_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_BDP_WR_LOW_ADDR_CH%u      : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_WR_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_BDP_WR_HIGH_ADDR_CH%u     : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_RD_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_BDP_RD_LOW_ADDR_CH%u      : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_RD_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_BDP_RD_HIGH_ADDR_CH%u     : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_WRBK_BD_CHn_BUFFER_SIZE(channel_id)));
    NXP_LOG_INFO("HIF_RX_WRBK_BD_CH%u_BUFFER_SIZE  : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_CHn_START(channel_id)));
    NXP_LOG_INFO("HIF_RX_CH%u_START                : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_WRBK_BD_CHn_BUFFER_SIZE(channel_id)));
    NXP_LOG_INFO("HIF_TX_WRBK_BD_CH%u_BUFFER_SIZE  : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_CHn_START(channel_id)));
    NXP_LOG_INFO("HIF_TX_CH%u_START                : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_SRC(channel_id)));
    NXP_LOG_INFO("HIF_CH%u_INT_SRC                 : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_RD_CURR_BD_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_RD_CURR_BD_LOW_ADDR_CH%u  : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_RD_CURR_BD_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_RD_CURR_BD_HIGH_ADDR_CH%u : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_WR_CURR_BD_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_WR_CURR_BD_LOW_ADDR_CH%u  : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_WR_CURR_BD_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_WR_CURR_BD_HIGH_ADDR_CH%u : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_BDP_CHn_TX_FIFO_CNT(channel_id)));
    NXP_LOG_INFO("HIF_BDP_CH%u_TX_FIFO_CNT         : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_DMA_STATUS_0_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_DMA_STATUS_0_CH%u         : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATUS_0_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_STATUS_0_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATUS_1_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_STATUS_1_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT0_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_PKT_CNT0_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT1_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_PKT_CNT1_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT2_CHn(channel_id)));
    NXP_LOG_INFO("HIF_TX_PKT_CNT2_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_RD_CURR_BD_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_RD_CURR_BD_LOW_ADDR_CH%u  : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_RD_CURR_BD_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_RD_CURR_BD_HIGH_ADDR_CH%u : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_WR_CURR_BD_LOW_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_WR_CURR_BD_LOW_ADDR_CH%u  : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_WR_CURR_BD_HIGH_ADDR_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_WR_CURR_BD_HIGH_ADDR_CH%u : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_BDP_CHn_RX_FIFO_CNT(channel_id)));
    NXP_LOG_INFO("HIF_BDP_CH%u_RX_FIFO_CNT         : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_DMA_STATUS_0_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_DMA_STATUS_0_CH%u         : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_STATUS_0_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_STATUS_0_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT0_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_PKT_CNT0_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT1_CHn(channel_id)));
    NXP_LOG_INFO("HIF_RX_PKT_CNT1_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));
    NXP_LOG_INFO("HIF_LTC_MAX_PKT_CH_ADDR%u        : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ABS_INT_TIMER_CHn(channel_id)));
    NXP_LOG_INFO("HIF_ABS_INT_TIMER_CH%u           : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ABS_FRAME_COUNT_CHn(channel_id)));
    NXP_LOG_INFO("HIF_ABS_FRAME_COUNT_CH%u         : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_INT_COAL_EN_CHn(channel_id)));
    NXP_LOG_INFO("HIF_INT_COAL_EN_CH%u             : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
    NXP_LOG_INFO("HIF_INT_EN_CH%u                  : 0x%08x\n", (uint_t)channel_id, (uint_t)reg);
#else
    (void) base_va;
    (void) channel_id;
#endif /* NXP_LOG_ENABLED */
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

#ifdef PFE_CFG_PFE_MASTER
static void reset_ring_registers_all_chnls(const addr_t hif_base_addr)
{
    uint32 hif_id;

    for(hif_id = 0U; hif_id <= 3U; hif_id++)
    {/*go through the registers*/
        pfe_hif_chnl_cfg_set_rx_bd_ring_addr(hif_base_addr, hif_id, (void *)0LU);
        pfe_hif_chnl_cfg_set_rx_wb_table(hif_base_addr, hif_id, (void *)0LU, 0U);
        pfe_hif_chnl_cfg_set_tx_bd_ring_addr(hif_base_addr, hif_id, (void *)0LU);
        pfe_hif_chnl_cfg_set_tx_wb_table(hif_base_addr, hif_id, (void *)0LU, 0U);
    }
}
#endif /* PFE_CFG_PFE_MASTER */


/*==================================================================================================*/
/**
 * @brief       HIF ISR
 * @details     MASK, ACK, and process triggered interrupts
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Make sure the call is protected by some per-HIF mutex
 */
errno_t pfe_hif_cfg_isr(addr_t base_va)
{
    uint32 glob_src, reg_src, reg_en;
    errno_t ret = ENOENT;

    /*  Get master HIF interrupt status. This register is read-only
        and does not require ACK. */
    glob_src = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_INT_SRC));
    if (unlikely(0U != glob_src))
    {
        if ((glob_src & HIF_INT_SRC_HIF_ERR_INT) != 0U)
        {
            /*  Get enabled interrupts */
            reg_en = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));
            /*  Disable ALL */
            hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));
            /*  Get triggered interrupts */
            reg_src = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_SRC));
            /*  ACK triggered */
            hal_write32(reg_src, ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_SRC));
            /*  Enable the non-triggered ones */
            hal_write32((reg_en & ~reg_src), ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));

            /*  Process interrupts which are triggered AND enabled */
            if ((reg_src & reg_en & HIF_ERR_INT) != 0U)
            {
                pfe_hm_report_error(HM_SRC_HIF, HM_EVT_HIF_ERR, "Interrupt (0x%x)", (uint_t)reg_src);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
               (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_HIF_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
                ret = EOK;
            }
        }

        if ((glob_src & HIF_INT_SRC_HIF_TX_FIFO_ERR_INT) != 0U)
        {
            /*  Get enabled interrupts */
            reg_en = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));
            /*  Disable ALL */
            hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));
            /*  Get triggered interrupts */
            reg_src = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_SRC));
            /*  ACK triggered */
            hal_write32(reg_src, ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_SRC));
            /*  Enable the non-triggered ones */
            hal_write32((reg_en & ~reg_src), ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));

            /*  Process interrupts which are triggered AND enabled */
            if ((reg_src & reg_en & HIF_TX_FIFO_ERR_INT) != 0U)
            {
                pfe_hm_report_error(HM_SRC_HIF, HM_EVT_HIF_TX_FIFO, "Interrupt (0x%x)", (uint_t)reg_src);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
               (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_HIF_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
                ret = EOK;
            }
        }

        if ((glob_src & HIF_INT_SRC_HIF_RX_FIFO_ERR_INT) != 0U)
        {
            /*  Get enabled interrupts */
            reg_en = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));
            /*  Disable ALL */
            hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));
            /*  Get triggered interrupts */
            reg_src = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_SRC));
            /*  ACK triggered */
            hal_write32(reg_src, ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_SRC));
            /*  Enable the non-triggered ones */
            hal_write32((reg_en & ~reg_src), ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));

            /*  Process interrupts which are triggered AND enabled */
            if ((reg_src & reg_en & HIF_RX_FIFO_ERR_INT) != 0U)
            {
                pfe_hm_report_error(HM_SRC_HIF, HM_EVT_HIF_RX_FIFO, "Interrupt (0x%x)", (uint_t)reg_src);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
               (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_HIF_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
                ret = EOK;
            }
        }
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Mask HIF interrupts
 * @details     Only affects HIF IRQs, not channel IRqs.
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    /*  Disable groups */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN)) & ~(HIF_ERR_INT);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN)) & ~(HIF_TX_FIFO_ERR_INT);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN)) & ~(HIF_RX_FIFO_ERR_INT);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));
}

/*==================================================================================================*/
/**
 * @brief       Unmask HIF interrupts
 * @details     Only affects HIF IRQs, not channel IRqs.
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    /*  Enable groups */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN)) | HIF_ERR_INT;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN)) | HIF_TX_FIFO_ERR_INT;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN)) | HIF_RX_FIFO_ERR_INT;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));
}

/*==================================================================================================*/
/**
 * @brief       HIF channel ISR
 * @details     Handles all HIF channel interrupts. MASK, ACK, and process triggered interrupts.
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   events Bitmask representing indicated events
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Make sure the call is protected by some per-channel mutex
 */
errno_t pfe_hif_chnl_cfg_isr(addr_t base_va, uint32 channel_id, pfe_hif_chnl_event_t *events)
{
    uint32 reg_src, reg_en;
    errno_t ret = ENOENT;

    *events = (pfe_hif_chnl_event_t)0;

    if (unlikely(channel_id >= HIF_CFG_MAX_CHANNELS))
    {
        NXP_LOG_ERROR("Invalid channel ID in ISR\n");
        ret = EINVAL;
    }
    else
    {
        /*  Get enabled interrupts */
        reg_en = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
        /*  Disable ALL */
        hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
        /*  Get triggered interrupts */
        reg_src = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_SRC(channel_id)));
        /*  ACK triggered */
        hal_write32(reg_src, ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_SRC(channel_id)));
        /*  Enable the non-triggered ones */
        hal_write32((reg_en & ~reg_src), ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));

        /*  Process interrupts which are triggered AND enabled */
        if ((reg_src & reg_en & (BDP_CSR_RX_PKT_CH_INT|BDP_CSR_RX_CBD_CH_INT)) != 0U)
        {
            *events |= HIF_CHNL_EVT_RX_IRQ;
            ret = EOK;
        }

        /*  Process interrupts which are triggered AND enabled */
        if ((reg_src & reg_en & (BDP_CSR_TX_PKT_CH_INT|BDP_CSR_TX_CBD_CH_INT)) != 0U)
        {
            *events |= HIF_CHNL_EVT_TX_IRQ;
            ret = EOK;
        }

        if (unlikely(reg_src & reg_en
                & ( BDP_RD_CSR_RX_TIMEOUT_CH_INT|BDP_WR_CSR_RX_TIMEOUT_CH_INT
                    | BDP_RD_CSR_TX_TIMEOUT_CH_INT|BDP_WR_CSR_TX_TIMEOUT_CH_INT
                    | DXR_CSR_RX_TIMEOUT_CH_INT|DXR_CSR_TX_TIMEOUT_CH_INT)))
        {
            if ((reg_src & reg_en & BDP_RD_CSR_RX_TIMEOUT_CH_INT) != 0U)
            {
                /*  AAVB-2144 */
                NXP_LOG_INFO("BDP_RD_CSR_RX_TIMEOUT_CH%u_INT. Interrupt disabled.\n", (uint_t)channel_id);
            }

            if ((reg_src & reg_en & BDP_WR_CSR_RX_TIMEOUT_CH_INT) != 0U)
            {
                /*  AAVB-2144 */
                NXP_LOG_INFO("BDP_WR_CSR_RX_TIMEOUT_CH%u_INT. Interrupt disabled.\n", (uint_t)channel_id);
            }

            if ((reg_src & reg_en & BDP_RD_CSR_TX_TIMEOUT_CH_INT) != 0U)
            {
                /*  AAVB-2144 */
                NXP_LOG_INFO("BDP_RD_CSR_TX_TIMEOUT_CH%u_INT. Interrupt disabled.\n", (uint_t)channel_id);
            }

            if ((reg_src & reg_en & BDP_WR_CSR_TX_TIMEOUT_CH_INT) != 0U)
            {
                /*  AAVB-2144 */
                NXP_LOG_INFO("BDP_WR_CSR_TX_TIMEOUT_CH%u_INT. Interrupt disabled.\n", (uint_t)channel_id);
            }

            if ((reg_src & reg_en & DXR_CSR_RX_TIMEOUT_CH_INT) != 0U)
            {
                /*  AAVB-2144 */
                NXP_LOG_INFO("DXR_CSR_RX_TIMEOUT_CH%u_INT. Interrupt disabled.\n", (uint_t)channel_id);
            }

            if ((reg_src & reg_en & DXR_CSR_TX_TIMEOUT_CH_INT) != 0U)
            {
                /*  AAVB-2144 */
                NXP_LOG_INFO("DXR_CSR_TX_TIMEOUT_CH%u_INT. Interrupt disabled.\n", (uint_t)channel_id);
            }

            /*  Don't re-enable these interrupts. See AAVB-2144. */

            ret = EOK;
        }
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Configure and initialize the HIF channel
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @return      EOK if success, error code otherwise
 * @note        Make sure the call is protected by some per-channel mutex
 */
errno_t pfe_hif_chnl_cfg_init(addr_t base_va, uint32 channel_id)
{
    /*  Disable channel interrupts */
    hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_SRC(channel_id)));

    /*  Disable RX/TX DMA */
    pfe_hif_chnl_cfg_rx_disable(base_va, channel_id);
    pfe_hif_chnl_cfg_tx_disable(base_va, channel_id);

    /*  Disable RX coalescing */
    (void)pfe_hif_chnl_cfg_set_rx_irq_coalesce(base_va, channel_id, 0U, 0U);

    /*  Enable channel status interrupts except of the RX/TX and
        the global enable bit. */

    /*  Added the (~HIF_CH_TIMEOUT_EN) to disable the HIF timeouts reporting following AAVB-6034 
        After the issue related is fixed, this (~HIF_CH_TIMEOUT_EN) could be removed*/
    hal_write32(0xffffffffU
            & ~HIF_CH_INT_EN
            & ~BDP_CSR_RX_CBD_CH_INT_EN
            & ~BDP_CSR_RX_PKT_CH_INT_EN
            & ~BDP_CSR_TX_CBD_CH_INT_EN
            & ~BDP_CSR_TX_PKT_CH_INT_EN
            & ~HIF_CH_TIMEOUT_EN
            , ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));

    return EOK;
}

/*==================================================================================================*/
/**
 * @brief       Properly finalize a HIF channel
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @note        Make sure the call is protected by some per-channel mutex
 */
void pfe_hif_chnl_cfg_fini(addr_t base_va, uint32 channel_id)
{
    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else
    {
        /*  Disable the coalescence timer */
        hal_write32(0x0U, ADDR_BASE_OFFSET(base_va,  HIF_INT_COAL_EN_CHn(channel_id)));

        /*  Disable RX/TX */
        pfe_hif_chnl_cfg_rx_disable(base_va, channel_id);
        pfe_hif_chnl_cfg_tx_disable(base_va, channel_id);

        /*  Disable all interrupts */
        hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
    }
}

/*==================================================================================================*/
/**
 * @brief       Configure and initialize the HIF
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @return      EOK if success, error code otherwise
 * @note        Make sure the call is protected by some per-HIF mutex
 */
errno_t pfe_hif_cfg_init(addr_t base_va)
{
    errno_t ret = EOK;
#ifdef PFE_CFG_PFE_MASTER
    uint32 ii = 0u;

    /*  Disable and clear HIF interrupts. Channel interrupts are
        handled separately within pfe_hif_chnl_cfg_init(). */
    hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_SRC));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_SRC));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_SRC));

    if (FALSE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
    {
        /*  SOFT RESET */
        hal_write32(0xfu, ADDR_BASE_OFFSET(base_va,  HIF_SOFT_RESET));
        while (hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_SOFT_RESET)) != 0U)
        {
            if (++ii > 1000u)
            {
                ret = ETIMEDOUT;
                break;
            }
            else
            {
                oal_time_usleep(1000);
            }
        }
    }
    else
    {
        /* And signalize drivers that PFE soft reset was executed */
        reset_ring_registers_all_chnls(base_va);
    }

    if (EOK == ret)
    {
        hal_write32((0xffUL << 16U) | (0xffUL), ADDR_BASE_OFFSET(base_va,  HIF_TX_POLL_CTRL));
        hal_write32((0xffUL << 16U) | (0xffUL), ADDR_BASE_OFFSET(base_va,  HIF_RX_POLL_CTRL));

        /*    MICS */
        hal_write32(0U
                /* | BDPRD_AXI_WRITE_DONE */
                /* | DBPWR_AXI_WRITE_DONE */
                /* | RXDXR_AXI_WRITE_DONE */
                /* | TXDXR_AXI_WRITE_DONE */
                | HIF_TIMEOUT_EN
                | BD_START_SEQ_NUM(0x0U)
                , ADDR_BASE_OFFSET(base_va,  HIF_MISC));

        hal_write32(100000000U, ADDR_BASE_OFFSET(base_va,  HIF_TIMEOUT_REG));
        hal_write32(0x33221100U, ADDR_BASE_OFFSET(base_va,  HIF_RX_QUEUE_MAP_CH_NO_ADDR));
        hal_write32(0x0U, ADDR_BASE_OFFSET(base_va,  HIF_DMA_BURST_SIZE_ADDR)); /* 0 = 128B, 1 = 256B, 2 = 512B, 3 = 1024B */
        hal_write32(0x0U, ADDR_BASE_OFFSET(base_va,  HIF_DMA_BASE_ADDR));
        hal_write32(0x0U, ADDR_BASE_OFFSET(base_va,  HIF_LTC_PKT_CTRL_ADDR)); /* Must stay disabled. LTC hijacked for Master-detect feature */
        hal_write32(0xffffffffU & ~(HIF_ERR_INT), ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));
        hal_write32(0xffffffffU & ~(HIF_TX_FIFO_ERR_INT), ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));
        hal_write32(0xffffffffU  & ~(HIF_RX_FIFO_ERR_INT), ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));
    }
#else
    (void)base_va;
#endif /* PFE_CFG_PFE_MASTER */

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Finalize the HIF
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_cfg_fini(addr_t base_va)
{
#ifdef PFE_CFG_PFE_MASTER
    /*  Disable HIF interrupts */
    hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_EN));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_EN));
    hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_EN));
#else
    /*  Do nothing */
    (void)base_va;
#endif
}

/*==================================================================================================*/
/**
 * @brief       Get TX FIFO fill level
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @return      Number of bytes in HIF FX FIFO
 */
uint32 pfe_hif_cfg_get_tx_fifo_fill_level(addr_t base_va)
{
    const uint32 multiplier = 8;

    uint32 tmp = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_DXR_TX_FIFO_CNT));
    
    /*  Check for multiplication overflow: */
    if(tmp < (UINT32_MAX / multiplier))
    {
        tmp = tmp * multiplier;
    }
    else
    {
        NXP_LOG_ERROR("Return value overflow\n");
        tmp = UINT32_MAX;        
    }

    return tmp;
}

/*==================================================================================================*/
/**
 * @brief       Enable TX
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_chnl_cfg_tx_enable(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else
    {
        /*  Enable DMA engine */
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));

        reg |= TX_BDP_POLL_CNTR_EN;

        reg |= TX_DMA_ENABLE;
        hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));
    }
}

/*==================================================================================================*/
/**
 * @brief       Disable TX
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_chnl_cfg_tx_disable(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else
    {

        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));
        reg &= ~(TX_DMA_ENABLE|TX_BDP_POLL_CNTR_EN);
        hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));

        /*  Disable TX IRQ */
        pfe_hif_chnl_cfg_tx_irq_mask(base_va, channel_id);
    }
}

/*==================================================================================================*/
/**
 * @brief       Enable RX
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_chnl_cfg_rx_enable(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else
    {

        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));

        reg |= RX_BDP_POLL_CNTR_EN;

        reg |= RX_DMA_ENABLE;
        hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));

    }
}

/*==================================================================================================*/
/**
 * @brief       Disable RX
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_chnl_cfg_rx_disable(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else
    {
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));
        reg &= ~(RX_DMA_ENABLE|RX_BDP_POLL_CNTR_EN);
        hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_CTRL_CHn(channel_id)));

        pfe_hif_chnl_cfg_rx_irq_mask(base_va, channel_id);
    }
}


/*==================================================================================================*/
/**
 * @brief       Mask channel IRQ
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @note        Make sure the call is protected by some per-channel mutex
 */
void pfe_hif_chnl_cfg_irq_mask(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    /*  Disable group */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id))) & ~(HIF_CH_INT_EN);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Unmask channel IRQ
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @note        Make sure the call is protected by some per-channel mutex
 */
void pfe_hif_chnl_cfg_irq_unmask(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    /*  Enable group */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id))) | HIF_CH_INT_EN;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Mask channel RX IRQ
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @note        Make sure the call is protected by some per-channel mutex
 */
void pfe_hif_chnl_cfg_rx_irq_mask(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    /*  Disable RX IRQ */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
    hal_write32(reg
                & ~BDP_CSR_RX_CBD_CH_INT_EN
                & ~BDP_CSR_RX_PKT_CH_INT_EN
                , ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Unmask channel RX IRQ
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @note        Make sure the call is protected by some per-channel mutex
 */
void pfe_hif_chnl_cfg_rx_irq_unmask(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    /*  Enable RX IRQ */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
    hal_write32(reg
            | BDP_CSR_RX_CBD_CH_INT_EN
            | BDP_CSR_RX_PKT_CH_INT_EN
                , ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Mask channel TX IRQ
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @note        Make sure the call is protected by some per-channel mutex
 */
void pfe_hif_chnl_cfg_tx_irq_mask(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    /*  Disable TX IRQ */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
    hal_write32(reg
                & ~BDP_CSR_TX_CBD_CH_INT_EN
                & ~BDP_CSR_TX_PKT_CH_INT_EN
                , ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Unmask channel TX IRQ
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @note        Make sure the call is protected by some per-channel mutex
 */
void pfe_hif_chnl_cfg_tx_irq_unmask(addr_t base_va, uint32 channel_id)
{
    uint32 reg;

    /*  Enable TX IRQ */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
    hal_write32(reg
            | BDP_CSR_TX_CBD_CH_INT_EN
            | BDP_CSR_TX_PKT_CH_INT_EN,
            ADDR_BASE_OFFSET(base_va,  HIF_CHn_INT_EN(channel_id)));
}

/*==================================================================================================*/
uint32 pfe_hif_chnl_cfg_get_rx_bd_ring_addr(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_RD_LOW_ADDR_CHn(channel_id)));
}

/*==================================================================================================*/
uint32 pfe_hif_chnl_cfg_get_rx_wb_table_addr(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_WR_LOW_ADDR_CHn(channel_id)));
}

/*==================================================================================================*/
uint32 pfe_hif_chnl_cfg_get_rx_wb_table_len(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_WRBK_BD_CHn_BUFFER_SIZE(channel_id)));
}

/*==================================================================================================*/
uint32 pfe_hif_chnl_cfg_get_tx_bd_ring_addr(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_RD_LOW_ADDR_CHn(channel_id)));
}

/*==================================================================================================*/
uint32 pfe_hif_chnl_cfg_get_tx_wb_table_addr(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_WR_LOW_ADDR_CHn(channel_id)));
}

/*==================================================================================================*/
uint32 pfe_hif_chnl_cfg_get_tx_wb_table_len(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_WRBK_BD_CHn_BUFFER_SIZE(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Set RX buffer descriptor ring address
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   rx_ring_pa The RX ring address (physical, as seen by host)
 */
void pfe_hif_chnl_cfg_set_rx_bd_ring_addr(addr_t base_va, uint32 channel_id, const void *rx_ring_pa)
{
    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else
    {
        hal_write32((uint32)((addr_t)rx_ring_pa & 0xffffffffU), ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_RD_LOW_ADDR_CHn(channel_id)));
        hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_RD_HIGH_ADDR_CHn(channel_id)));
    }
}

/*==================================================================================================*/
/**
 * @brief       Set RX write-back table
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   wb_ring_pa The write-back table address (physical, as seen by host)
 * @param[in]   ring_len Number of entries in the WB table
 */
void pfe_hif_chnl_cfg_set_rx_wb_table(addr_t base_va, uint32 channel_id, const void *wb_tbl_pa, uint32 tbl_len)
{
    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else if (tbl_len > 0xffffU)
    {
        NXP_LOG_ERROR("Unsupported WB table size: %u\n", (uint_t)tbl_len);
    }
    else
    {
        hal_write32((uint32)((addr_t)wb_tbl_pa & 0xffffffffU), ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_WR_LOW_ADDR_CHn(channel_id)));
        hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_RX_BDP_WR_HIGH_ADDR_CHn(channel_id)));
        hal_write32(tbl_len, ADDR_BASE_OFFSET(base_va,  HIF_RX_WRBK_BD_CHn_BUFFER_SIZE(channel_id)));
    }
}

/*==================================================================================================*/
/**
 * @brief       Set TX buffer descriptor ring address
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   tx_ring_pa The TX ring address (physical, as seen by host)
 */
void pfe_hif_chnl_cfg_set_tx_bd_ring_addr(addr_t base_va, uint32 channel_id, const void *tx_ring_pa)
{
    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else
    {
        hal_write32((uint32)((addr_t)tx_ring_pa & 0xffffffffU), ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_RD_LOW_ADDR_CHn(channel_id)));
        hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_RD_HIGH_ADDR_CHn(channel_id)));
    }
}

/*==================================================================================================*/
/**
 * @brief       Set TX write-back table
  * @param[in]  base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   wb_ring_pa The write-back table address (physical, as seen by host)
 * @param[in]   ring_len Number of entries in the WB table
 */
void pfe_hif_chnl_cfg_set_tx_wb_table(addr_t base_va, uint32 channel_id, const void *wb_tbl_pa, uint32 tbl_len)
{
    if (channel_id >= HIF_CFG_MAX_CHANNELS)
    {
        NXP_LOG_ERROR("Unsupported channel ID: %u\n", (uint_t)channel_id);
    }
    else if (tbl_len > 0xffffU)
    {
        NXP_LOG_ERROR("Unsupported WB table size: %u\n", (uint_t)tbl_len);
    }
    else
    {
        hal_write32((uint32)((addr_t)wb_tbl_pa & 0xffffffffU), ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_WR_LOW_ADDR_CHn(channel_id)));
        hal_write32(0U, ADDR_BASE_OFFSET(base_va,  HIF_TX_BDP_WR_HIGH_ADDR_CHn(channel_id)));
        hal_write32(tbl_len, ADDR_BASE_OFFSET(base_va,  HIF_TX_WRBK_BD_CHn_BUFFER_SIZE(channel_id)));
    }
}

/*==================================================================================================*/
/**
 * @brief       Get RX ring state
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @return      TRUE when the RX ring BD processor is active or FALSE when it is idle
 */
bool_t pfe_hif_chnl_cfg_is_rx_dma_active(addr_t base_va, uint32 channel_id)
{
    uint32 reg;
    bool_t ret;

    (void)channel_id;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_ACTV));

    if (0U != reg)
    {
        ret = TRUE;
    }
    else
    {
        ret = FALSE;
    }
    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Get TX ring state
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @return      TRUE when the TX ring BD processor is active or FALSE when it is idle
 */
bool_t pfe_hif_chnl_cfg_is_tx_dma_active(addr_t base_va, uint32 channel_id)
{
    uint32 reg;
    bool_t ret;

    (void)channel_id;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_ACTV));

    if (0U != reg)
    {
        ret = TRUE;
    }
    else
    {
        ret = FALSE;
    }
    return ret;
}

/*==================================================================================================*/
/**
 * @brief       RX BDP FIFO status
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @retval      TRUE The FIFO is empty
 * @retval      FALSE The FIFO is not emtpy
 */
bool_t pfe_hif_chnl_cfg_is_rx_bdp_fifo_empty(addr_t base_va, uint32 channel_id)
{
    return (0U == hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_BDP_CHn_RX_FIFO_CNT(channel_id))));
}

/*==================================================================================================*/
/**
 * @brief       TX BDP FIFO status
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @retval      TRUE The FIFO is empty
 * @retval      FALSE The FIFO is not emtpy
 */
bool_t pfe_hif_chnl_cfg_is_tx_bdp_fifo_empty(addr_t base_va, uint32 channel_id)
{
    return (0U == hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_BDP_CHn_TX_FIFO_CNT(channel_id))));
}

/*==================================================================================================*/
/**
 * @brief       Get RX coalesce setting
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[out]  frames Number of frames
 * @param[out]  cycles Number of cycles
 */
errno_t pfe_hif_chnl_cfg_get_rx_irq_coalesce(addr_t base_va, uint32 channel_id, uint32 *frames, uint32 *cycles)
{
    uint32 ena = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_INT_COAL_EN_CHn(channel_id)));

    if (0U == (ena & (HIF_INT_COAL_TIME_ENABLE | HIF_INT_COAL_FRAME_ENABLE)))
    {
        /* Coalesce is disabled */
        *cycles = 0U;
        *frames = 0U;
    }
    else
    {
        if (0U != (ena & HIF_INT_COAL_TIME_ENABLE))
        {
            *cycles = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ABS_INT_TIMER_CHn(channel_id)));
        }
        else
        {
            *cycles = 0U;
        }

        if (0U != (ena & HIF_INT_COAL_FRAME_ENABLE))
        {
            *frames = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ABS_FRAME_COUNT_CHn(channel_id)));
        }
        else
        {
            *frames = 0U;
        }
    }

    return EOK;
}

/*==================================================================================================*/
/**
 * @brief       Set HIF channel RX coalesce setting
 * @details     The coalesce setting for HIF channel.
 *              If both frames and cycles are zero, then coalesting
 *              will be disabled.
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   frames Number of frames
 * @param[in]   cycles Number of cycles
 */
errno_t pfe_hif_chnl_cfg_set_rx_irq_coalesce(addr_t base_va, uint32 channel_id, uint32 frames, uint32 cycles)
{
    errno_t ret;

    /* Disable coalescing */
    hal_write32(0x0U, ADDR_BASE_OFFSET(base_va,  HIF_INT_COAL_EN_CHn(channel_id)));
    hal_write32(0x0U, ADDR_BASE_OFFSET(base_va,  HIF_ABS_FRAME_COUNT_CHn(channel_id)));
    hal_write32(0x0U, ADDR_BASE_OFFSET(base_va,  HIF_ABS_INT_TIMER_CHn(channel_id)));

    if ((0U == cycles) && (0U == frames))
    {
        /* Remain coalesce disabled */
        ret = EOK;
    }
    else
    {
        if (0U < frames)
        {
            /* Frame based coalescing is unsupported on S32G2 silicon */
            ret = EINVAL;
        }
        else
        {

            /* Enable time-based coalescing */
            hal_write32(HIF_INT_COAL_TIME_ENABLE, ADDR_BASE_OFFSET(base_va,  HIF_INT_COAL_EN_CHn(channel_id)));
            hal_write32(cycles, ADDR_BASE_OFFSET(base_va,  HIF_ABS_INT_TIMER_CHn(channel_id)));
            ret = EOK;
        }
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Get number of transmitted packets
 * @param[in]   base_va Base address of channel register space (virtual)
 * @param[in]   channel_id  Channel identifier
 * @return      Number of transmitted packets
 */
uint32 pfe_hif_chnl_cfg_get_tx_cnt(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT1_CHn(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Get number of received packets
 * @param[in]   base_va Base address of channel register space (virtual)
 * @param[in]   channel_id  Channel identifier
 * @return      Number of received packets
 */
uint32 pfe_hif_chnl_cfg_get_rx_cnt(addr_t base_va, uint32 channel_id)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT2_CHn(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Set master up status for HIF channels
 * @details     The LTC setting for HIF channel.
 *              WARNING: Hijacked use for Master detect feature
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   value The value shall be written to the Master up bit
 */
void pfe_hif_chnl_cfg_set_master_up(addr_t base_va, uint32 channel_id, bool_t value)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));

    reg &= ~(HIF_LTC_MAX_PKT_CHN_MASTER_UP(1));
    reg |= HIF_LTC_MAX_PKT_CHN_MASTER_UP(value);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Get master up status for HIF channels
 * @details     Read the LTC setting for HIF channel.
 *              WARNING: Hijacked use for Master detect feature
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @return      TRUE if Master up bit is set, FALSE otherwise
 */
bool_t pfe_hif_chnl_cfg_get_master_up(addr_t base_va, uint32 channel_id)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));

    return (0U == (reg & HIF_LTC_MAX_PKT_CHN_MASTER_UP(1))) ? FALSE : TRUE;
}

/*==================================================================================================*/
/**
 * @brief       Set hif occupied status for HIF channels
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   value The value shall be written to the hif occupied bit
 */
void pfe_hif_chnl_cfg_set_hif_occupied(addr_t base_va, uint32 channel_id, bool_t value)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));

    reg &= ~(HIF_LTC_MAX_PKT_CHN_HIF_OCCUPIED(1));
    reg |= HIF_LTC_MAX_PKT_CHN_HIF_OCCUPIED(value);

    hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));
}

/*==================================================================================================*/
/**
 * @brief       Get hif occupied status for HIF channels
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @return      TRUE if the hif occupied bit is set, FALSE otherwise
 */
bool_t pfe_hif_chnl_cfg_get_hif_occupied(addr_t base_va, uint32 channel_id)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));

    return (0U == (reg & HIF_LTC_MAX_PKT_CHN_HIF_OCCUPIED(1))) ? FALSE : TRUE;
}

/*==================================================================================================*/
/**
 * @brief       Marks that a PFE instance associated with a HIF channel is owner of an EMAC timer
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @param[in]   channel_id HIF Channel identifier (0-3)
 * @param[in]   emac The EMAC id
 * @param[in]   value The value of EMAC timer ownership for the PFE instance associated to HIF channel. TRUE - owner, FALSE - not owner
 * @return      EOK if success, error code when invalid EMAC ID is requested
 */
errno_t pfe_hif_chnl_cfg_set_emac_timer_ownership(addr_t base_va, uint32 channel_id, pfe_ct_phy_if_id_t emac, bool_t value)
{
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));
    errno_t ret = EOK;

    switch (emac)
    {
        case PFE_PHY_IF_ID_EMAC0:
        {
            reg &= ~HIF_LTC_MAX_PKT_CHN_EMAC0_OWNER(1);
            reg |= HIF_LTC_MAX_PKT_CHN_EMAC0_OWNER(value);
            break;
        }
        case PFE_PHY_IF_ID_EMAC1:
        {
            reg &= ~HIF_LTC_MAX_PKT_CHN_EMAC1_OWNER(1);
            reg |= HIF_LTC_MAX_PKT_CHN_EMAC1_OWNER(value);
            break;
        }
        case PFE_PHY_IF_ID_EMAC2:
        {
            reg &= ~HIF_LTC_MAX_PKT_CHN_EMAC2_OWNER(1);
            reg |= HIF_LTC_MAX_PKT_CHN_EMAC2_OWNER(value);
            break;
        }
        default:
        {
            ret = EINVAL;
            break;
        }
    }
    if (EOK == ret)
    {
        hal_write32(reg, ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));
    }

    return ret;
}

/*==================================================================================================*/
/**
 * @brief       Get EMAC timer ownership status for PFE instance associated to HIF channel
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @param[in]   channel_id HIF Channel identifier (0-3)
 * @param[in]   emac The EMAC id
 * @return      TRUE if PFE instance associated with HIF channel is timer owner of specified EMAC, FALSE otherwise
 */
bool_t pfe_hif_chnl_cfg_get_emac_timer_ownership(addr_t base_va, uint32 channel_id, pfe_ct_phy_if_id_t emac)
{
    bool_t val = FALSE;
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_LTC_MAX_PKT_CHn_ADDR(channel_id)));

    switch (emac)
    {
        case PFE_PHY_IF_ID_EMAC0:
        {
            val = (0U == (reg & HIF_LTC_MAX_PKT_CHN_EMAC0_OWNER(1))) ? FALSE : TRUE;
            break;
        }
        case PFE_PHY_IF_ID_EMAC1:
        {
            val = (0U == (reg & HIF_LTC_MAX_PKT_CHN_EMAC1_OWNER(1))) ? FALSE : TRUE;
            break;
        }
        case PFE_PHY_IF_ID_EMAC2:
        {
            val = (0U == (reg & HIF_LTC_MAX_PKT_CHN_EMAC2_OWNER(1))) ? FALSE : TRUE;
            break;
        }
        default:
        {
            val = FALSE;
            break;
        }
    }
    return val;
}

/**
 * @brief       Get RX BDP FIFO read count
 * @param[in]   base_va Base address of HIF channel register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @retval      RX BDP FIFO read count
 */
uint32 pfe_hif_chnl_cfg_get_rx_bdp_rd_fifo_cnt(addr_t base_va, uint32 channel_id)
{
    /* Return lower two bytes (count of read FIFO) from HIF_BDP_CHn_RX_FIFO_CNT register and
     * divide it by two. The value in the register is doubled. */
    return ((hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_BDP_CHn_RX_FIFO_CNT(channel_id))) & 0xffffU) / 2U);
}

#if defined(PFE_CFG_TEXT_STATS)
/*==================================================================================================*/
/**
 * @brief       Get HIF channel statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about a HIF channel.
 * @param[in]   base_va     Base address of channel register space (virtual)
 * @param[in]   channel_id  Channel identifier
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level number of data written to the buffer (0:less 1:more)
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_hif_chnl_cfg_get_text_stat(addr_t base_va, uint32 channel_id, char_t *buf, uint32 size, uint8 verb_level)
{
    /*  Fill the buffer with runtime data */
    uint32 len = 0U;
    uint32 reg;

    (void)verb_level;

    len += oal_util_snprintf(buf + len, size - len, "[CHANNEL %d]\n", channel_id);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_STATUS_0_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_RX_STATUS_0           : 0x%x\n", reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_DMA_STATUS_0_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_RX_DMA_STATUS_0       : 0x%x\n", reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT0_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT0           : 0x%x\n", reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT1_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT1           : 0x%x\n", reg);

    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATUS_0_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_TX_STATUS_0           : 0x%x\n", reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATUS_1_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_TX_STATUS_1           : 0x%x\n", reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_DMA_STATUS_0_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_TX_DMA_STATUS_0       : 0x%x\n", reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT0_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT0           : 0x%x\n", reg);
    reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT1_CHn(channel_id)));
    len += oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT1           : 0x%x\n", reg);

    return len;
}

/*==================================================================================================*/
/**
 * @brief       Get HIF statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the HIF block.
 * @param[in]   base_va     Base address of HIF register space (virtual)
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_hif_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;
    uint32 reg;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Debug registers */
        if(verb_level >= 10U)
        {
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_STATE               : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATE)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_ACTV                : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_ACTV)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_CURR_CH_NO          : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_CURR_CH_NO)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_DXR_TX_FIFO_CNT        : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_DXR_TX_FIFO_CNT)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_CTRL_WORD_FIFO_CNT1 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_CTRL_WORD_FIFO_CNT1)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_CTRL_WORD_FIFO_CNT2 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_CTRL_WORD_FIFO_CNT2)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_BVALID_FIFO_CNT     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BVALID_FIFO_CNT)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT1            : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT1)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT2            : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT2)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_STATE               : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_STATE)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_ACTV                : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_ACTV)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_CURR_CH_NO          : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_CURR_CH_NO)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_DXR_RX_FIFO_CNT        : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_DXR_RX_FIFO_CNT)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_CTRL_WORD_FIFO_CNT  : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_CTRL_WORD_FIFO_CNT)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_BVALID_FIFO_CNT     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BVALID_FIFO_CNT)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT1            : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT1)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT2            : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT2)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_CH0_INT_SRC:        : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_CH0_INT_SRC)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_BDP_CH0_TX_FIFO_CNT : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_BDP_CH0_TX_FIFO_CNT)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_DMA_STATUS_0_CH0 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_DMA_STATUS_0_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_STATUS_0_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATUS_0_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_STATUS_1_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATUS_1_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT0_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT0_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT1_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT1_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT2_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT2_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_BDP_CH0_RX_FIFO_CNT : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_BDP_CH0_RX_FIFO_CNT)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_DMA_STATUS_0_CH0 : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_DMA_STATUS_0_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_STATUS_0_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_STATUS_0_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT0_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT0_CH0)));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT1_CH0     : 0x%x\n", hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT1_CH0)));
        }

        if(verb_level>=9U)
        {
            /*  Get version */
            reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_VERSION));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "Revision                  : 0x%x\n", (reg >> 24U) & 0xffU);
            len += (uint32)oal_util_snprintf(buf + len, size - len, "Version                   : 0x%x\n", (reg >> 16U) & 0xffU);
            len += (uint32)oal_util_snprintf(buf + len, size - len, "ID                        : 0x%x\n", reg & 0xffffU);
        }

        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_STATE));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_STATE              : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_ACTV));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_ACTV               : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_CURR_CH_NO));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_CURR_CH_NO         : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_DXR_RX_FIFO_CNT));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_DXR_RX_FIFO_CNT       : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_CTRL_WORD_FIFO_CNT));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_CTRL_WORD_FIFO_CNT : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BVALID_FIFO_CNT));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_BVALID_FIFO_CNT    : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_BVALID_FIFO_CNT));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_BVALID_FIFO_CNT    : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT1));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT1           : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_PKT_CNT2));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_RX_PKT_CNT2           : 0x%x\n", reg);

        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_INT_SRC));
        len += oal_util_snprintf(buf + len, size - len, "HIF_INT_SRC               : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_ERR_INT_SRC));
        len += oal_util_snprintf(buf + len, size - len, "HIF_ERR_INT_SRC           : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_FIFO_ERR_INT_SRC));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_FIFO_ERR_INT_SRC   : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_RX_FIFO_ERR_INT_SRC));
        len += oal_util_snprintf(buf + len, size - len, "HIF_RX_FIFO_ERR_INT_SRC   : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_STATE));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_STATE              : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_ACTV));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_ACTV               : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_CURR_CH_NO));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_CURR_CH_NO         : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_DXR_TX_FIFO_CNT));
        len += oal_util_snprintf(buf + len, size - len, "HIF_DXR_TX_FIFO_CNT       : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_CTRL_WORD_FIFO_CNT1));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_CTRL_WORD_FIFO_CNT1: 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_CTRL_WORD_FIFO_CNT2));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_CTRL_WORD_FIFO_CNT2: 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_BVALID_FIFO_CNT));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_BVALID_FIFO_CNT    : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT1));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT1           : 0x%x\n", reg);
        reg = hal_read32(ADDR_BASE_OFFSET(base_va,  HIF_TX_PKT_CNT2));
        len += oal_util_snprintf(buf + len, size - len, "HIF_TX_PKT_CNT2           : 0x%x\n", reg);

        dump_hif_channel(base_va, 0U);
    }

    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

#ifdef PFE_CFG_PFE_MASTER
/**
 * @brief       Disables the Rx and Tx DMA for all HIF channels
 */
void pfe_hif_cfg_stop_all_chnl_dma(void)
{
    uint32 hif_id;

    for(hif_id = 0U; hif_id < HIF_CFG_MAX_CHANNELS; hif_id++)
    {
        pfe_hif_chnl_cfg_tx_disable(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR, hif_id);
        pfe_hif_chnl_cfg_rx_disable(PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR, hif_id);
    }
}
#endif /* PFE_CFG_PFE_MASTER */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [155/185]: src\pfe_hif_drv.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_PFE_HIF_DRV
 * @{
 *
 * @file        pfe_hif_drv.c
 * @brief       The HIF driver source file.
 * @details     This is the HIF driver with following features:
 *                  - Server-Client approach and traffic dispatching. The driver provides
 *                    possibility to register a client which will receive dedicated traffic
 *                    according to client ID assigned to a packet by the classification process
 *                    (firmware).
 *                  - TX confirmation handling. Driver passes the TX confirmation events
 *                    to particular clients once their transmit requests are processed.
 *                  - HIF interrupts handling.
 *
 * @internal
 *
 * Threading model
 * ---------------
 * There are two types of threads involved:
 *
 *  - Client
 *    An external thread running HIF client-related routines. Each HIF client is intended to
 *    run within its own thread. Creation and maintenance of client's threads is not subject
 *    of this HIF driver. The HIF driver can only notify the client using dedicated event
 *    notification mechanism.
 *
 * Resources protection
 * --------------------
 * The HIF driver is using a set of various resources which are being accessed from multiple
 * thread contexts. Here is the list with synchronization information:
 *
 *  - pfe_hif_drv_t.tx_meta
 *    Producer  : Clients
 *    Consumer  : HIF worker
 *    Protection: pfe_hif_drv_t.tx_lock
 *
 *    The common, HIF-owned TX metadata storage. Every transmitted buffer (enqueued to the HW TX
 *    ring) has associated metadata structure within this table. The order of transmitted buffers
 *    and metadata entries is maintained. HIF clients are writing to this table within the xmit
 *    calls. HIF worker is then reading the entries during TX confirmation processing. The table
 *    is thus protected using the pfe_hif_drv_t.tx_lock.
 *
 *  - pfe_hif_drv_client_t.client_tx_queue.tx_conf_fifo
 *    Producer  : HIF worker
 *    Consumer  : Particular Client
 *    Protection: n/a
 *
 *    Client-owned FIFO for TX confirmations. HIF worker is putting data into client's FIFO.
 *    Client is reading the FIFO during TX confirmation processing. This FIFO does not need
 *    resource protections (single producer/single consumer).
 *
 *  - pfe_hif_drv_client_t.client_rx_queue.rx_fifo
 *    Producer  : HIF worker
 *    Consumer  : Particular Client
 *    Protection: n/a
 *
 *    Client-owned FIFO for RX buffers. HIF worker is putting descriptors into client's RX FIFO.
 *    Client is reading the FIFO during RX processing. The FIFO does not need resource protection
 *    (single producer/single consumer).
 *
 *
 * @endinternal
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"

#ifdef PFE_CFG_MC_HIF
#include "hal.h"
#include "pfe_hif.h"
#include "pfe_hif_drv.h"
#include "pfe_platform_cfg.h"

#ifdef PFE_CFG_IEEE1588_SUPPORT
    #define PTP_MSG_SYNC        0U
    #define PTP_MSG_DELAY_REQ   1U
    #define PTP_MSG_PDELAY_REQ  2U
    #define PTP_MSG_PDELAY_RESP 3U
    #include "Eth_PFE_LLD.h"
#endif

#define HIF_CFG_WORKER_SCHEDULE_RX              (100U)
#define HIF_CFG_WORKER_SCHEDULE_TX_MAINTENANCE  (101U)
#define HIF_CFG_WORKER_SHUTDOWN                 (102U)

#define PFE_BUF_SIZE        2048U   /* must be big enough for headroom, pkt size and skb shared info */
#define PFE_PKT_HEADROOM    128U
#define PFE_MIN_PKT_SIZE    64U
#define PFE_PKT_SIZE        (PFE_BUF_SIZE - PFE_PKT_HEADROOM) /* maximum ethernet packet */

/* The length is runtime configurable per queue in MCAL and minihif driver */
#define PFE_CFG_HIF_RING_LENGTH (hif_drv->tx_meta_number)

typedef struct pfe_hif_pkt_tag pfe_hif_tx_meta_t;
typedef struct pfe_hif_pkt_tag pfe_hif_rx_meta_t;

struct __attribute__((packed)) client_rx_queue
{
    fifo_t *rx_fifo;    /* This is the client's RX ring */
    uint32 size;
    bool_t has_new_data;
};

struct __attribute__((packed)) client_tx_queue
{
    fifo_t *tx_conf_fifo; /* TX confirmation FIFO */
    uint32 size;
    bool_t has_new_data;
    bool_t has_new_ets_data;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#define PFE_HIF_DRV_IHC_CLIENT_RX_QUEUES 1U
#define PFE_HIF_DRV_IHC_CLIENT_TX_QUEUES 1U
#define PFE_HIF_DRV_IHC_CLIENT_RX_QUEUE_DEPTH 8U
#define PFE_HIF_DRV_IHC_CLIENT_TX_QUEUE_DEPTH 8U

typedef struct
{
    fifo_t rx_fifo[PFE_HIF_DRV_IHC_CLIENT_RX_QUEUES];
    fifo_t tx_conf_fifo[PFE_HIF_DRV_IHC_CLIENT_TX_QUEUES];
    void *rx_fifo_data[RXTX_FIFO_ALIGNED_DEPTH(PFE_HIF_DRV_IHC_CLIENT_RX_QUEUE_DEPTH) * PFE_HIF_DRV_IHC_CLIENT_RX_QUEUES];
    void *tx_conf_fifo_data[RXTX_FIFO_ALIGNED_DEPTH(PFE_HIF_DRV_IHC_CLIENT_TX_QUEUE_DEPTH) * PFE_HIF_DRV_IHC_CLIENT_TX_QUEUES];
} ihc_client_fifos_t;

/* IHC client FIFOs */
ihc_client_fifos_t ihc_client_fifos;

#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

/* HIF driver singleton */
pfe_hif_drv_t common_hif_drv;

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief   The HIF driver client instance structure
 */
struct __attribute__((aligned(HAL_CACHE_LINE_SIZE), packed)) pfe_hif_drv_client_tag
{
    uint32 id_mask;
    pfe_ct_phy_if_id_t phy_if_id;
    uint32 tx_qn;
    uint32 rx_qn;
    struct client_tx_queue tx_q[HIF_DRV_CLIENT_QUEUES_MAX];
    struct client_rx_queue rx_q[HIF_DRV_CLIENT_QUEUES_MAX];
    pfe_hif_drv_client_event_handler event_handler;
    pfe_hif_drv_t *hif_drv;
    void *priv;
    bool_t active;
    bool_t promisc;
#ifdef PFE_CFG_IEEE1588_SUPPORT
    /* Storage for PTP timestamps */
    pfe_hif_ptp_ts_db_t __attribute__((aligned(4))) ptpdb;   /* Must be aligned at 4 bytes */
#endif /* PFE_CFG_IEEE1588_SUPPORT */
};

/**
 * @brief   The HIF driver instance structure
 */
struct __attribute__((aligned(HAL_CACHE_LINE_SIZE), packed)) pfe_hif_drv_tag
{
/* Common */
    pfe_hif_chnl_t *channel;            /* The associated HIF channel instance */
    pfe_ct_phy_if_id_t i_phy_if;
    uint8 qno;
    bool_t started;
    bool_t rx_enabled;                  /* If TRUE then frame reception is allowed */

/* TX and TX confirmation processing */
    oal_job_t tx_job;
    pfe_hif_tx_meta_t tx_meta[ETH_43_PFE_MAX_TXBD_CNT];                   /* Storage of metadata for every transmitted buffer */
    uint32 tx_meta_rd_idx;
    uint32 tx_meta_wr_idx;
    uint32 tx_meta_number;
    bool_t tx_enabled;                                                    /* If TRUE then frame transmission is allowed */
#ifdef HIF_STATS
/* Statistics */
    uint32 counters[HIF_STATS_MAX_COUNT];
#endif

/* Table of HIF Driver Clients indexed by physical interface (pfe_phy_if_t) ID */
    pfe_hif_drv_client_t clients[HIF_CLIENTS_MAX] __attribute__((aligned(HAL_CACHE_LINE_SIZE)));

    volatile bool_t initialized;    /* If TRUE the HIF has been properly initialized */
};

typedef struct
{
    pfe_hif_drv_t *hif_drv;                                 /* HIF driver instance */
    pfe_ct_phy_if_id_t phy_if_id;                           /* Physical interface ID */
    pfe_hif_drv_client_rx_tx_count *client_queue;           /* Number of TX/RX queues */
    pfe_hif_drv_client_fifo_queue  *client_fifo_queue;      /* FIFO for the TX/RX queue */
    bool_t promisc;                                         /* TRUE if client shall be promiscuous */
    pfe_hif_drv_client_event_handler handler;               /* Client's event handler */
    void *priv;                                             /* Private data to be passed to handler */
} pfe_hif_drv_client_data;

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/* Channel management */
static errno_t pfe_hif_drv_create_data_channel(pfe_hif_drv_t *hif_drv);
static void pfe_hif_drv_destroy_data_channel(pfe_hif_drv_t *hif_drv);

/* Common static stuff */
static void pfe_hif_drv_process_rx(pfe_hif_drv_t *hif_drv);
static uint32 pfe_hif_drv_process_tx(pfe_hif_drv_t *hif_drv, uint32 budget);
static void hif_client_free_rx_queues(pfe_hif_drv_client_t *client);
static void hif_client_free_tx_queues(pfe_hif_drv_client_t *client);
static pfe_hif_drv_client_t *pfe_hif_drv_client_register_ll(pfe_hif_drv_client_t *client, pfe_hif_drv_client_data *data);
static void pfe_hif_drv_stop_tx(pfe_hif_drv_t *hif_drv);
static void pfe_hif_drv_stop_rx(pfe_hif_drv_t *hif_drv);
static void pfe_hif_drv_init_err_handler(pfe_hif_drv_t *hif_drv, uint_t err_level);
static errno_t pfe_hif_drv_attach_channels(pfe_hif_drv_t *hif_drv);
static errno_t pfe_hif_drv_client_create_rx_tx( pfe_hif_drv_client_t *client_tmp, pfe_hif_drv_client_data *client_data);
static void pfe_hif_drv_show_tx_ring_status(pfe_hif_drv_client_t *cl);
static void pfe_hif_drv_show_rx_ring_status(pfe_hif_drv_client_t *cl);
static void pfe_hif_drv_process_ets(pfe_hif_drv_client_t **client, void *current_buffer_va);
static pfe_hif_drv_client_t *pfe_hif_drv_assign_client(pfe_hif_drv_t *hif_drv, pfe_ct_hif_rx_hdr_t *hif_hdr_ptr);
static void release_rx_buffer_with_check(pfe_hif_drv_t *hif_drv, const void *current_buffer_va);
static bool_t pfe_hif_drv_process_lifm(bool_t lifm, pfe_hif_drv_t **hif_drv);

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
static void pfe_hif_drv_chnl_tx_isr(void *arg);
static void pfe_hif_drv_notify_clients(pfe_hif_drv_t *hif_drv, uint32 tx_clients);
static void pfe_hif_drv_notify_rx_clients(uint32 rx_clients, pfe_hif_drv_t *hif_drv);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
static errno_t hif_client_create_rx_queues(pfe_hif_drv_client_t *client, fifo_t *fifo);
static errno_t hif_client_create_tx_queues(pfe_hif_drv_client_t *client, fifo_t *fifo);
static errno_t pfe_hif_drv_put_data_to_tx_conf_queue(pfe_hif_drv_t *hif_drv, pfe_hif_drv_client_t *client, uint32 *tx_clients, pfe_hif_tx_meta_t *tx_metadata);

#ifdef PFE_CFG_IEEE1588_SUPPORT
static void pfe_hif_drv_cfg_IEEE1588(pfe_hif_drv_client_t *client, pfe_ct_hif_tx_hdr_t *tx_hdr, pfe_hif_tx_meta_t *tx_metadata, const hif_frame_t *const frame, void *ref_ptr);
static void pfe_hif_drv_process_ts(uint32 rx_len, pfe_ct_hif_rx_hdr_t *hif_hdr_ptr, pfe_hif_drv_client_t *client, void *current_buffer_va);
#endif /*PFE_CFG_IEEE1588_SUPPORT*/

/**
 * @brief   Indicate end of reception
 * @details Re-enable interrupts, trigger DMA, ...
 */
void pfe_hif_drv_client_rx_done(const pfe_hif_drv_client_t *client)
{
    (void)client;
}

/**
 * @brief       Deferred RX job
 */
void pfe_hif_drv_rx_job(void *arg)
{
    pfe_hif_drv_t *hif_drv = (pfe_hif_drv_t *)arg;

    if (likely(TRUE == hif_drv->rx_enabled))
    {
        pfe_hif_drv_process_rx(hif_drv);
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
        /* Enable RX interrupt */
        pfe_hif_chnl_rx_irq_unmask(hif_drv->channel);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
    }
}

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
/**
 * @brief       HIF channel TX ISR
 * @details     Will be called by HIF channel instance when TX event has occurred
 * @note        To see which context the ISR is running in please see the
 *              pfe_hif_chnl module implementation.
 */
static void pfe_hif_drv_chnl_tx_isr(void *arg)
{
    pfe_hif_drv_t *hif_drv = (pfe_hif_drv_t *)arg;

    if (unlikely(EOK != oal_job_run(&hif_drv->tx_job)))
    {
        NXP_LOG_ERROR("TX job trigger failed\n");
    }
}
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

/**
 * @brief       Deferred TX job
 */
void pfe_hif_drv_tx_job(void *arg)
{
    pfe_hif_drv_t *hif_drv = (pfe_hif_drv_t *)arg;

    if (likely(TRUE == hif_drv->tx_enabled))
    {
        /* Enter critical section */
        oal_mutex_lock(PFE_HIF_DRV_MUTEX_00);

        while (HIF_TX_POLL_BUDGET <= pfe_hif_drv_process_tx(hif_drv, HIF_TX_POLL_BUDGET))
        {
            ;
        }

        /* Leave critical section */
        oal_mutex_unlock(PFE_HIF_DRV_MUTEX_00);
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
        /* Enable TX interrupt */
        pfe_hif_chnl_tx_irq_unmask(hif_drv->channel);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
    }
}

/**
 * @brief   Indicate end of TX confirmation
 * @details Re-enable interrupts, trigger DMA, ...
 */
void pfe_hif_drv_client_tx_done(const pfe_hif_drv_client_t *client)
{
    (void)client;
}

#if defined(PFE_CFG_IEEE1588_SUPPORT)
/**
 * @brief       This function timeouts timestamps in database
 * @details     This function shall be called periodically for each client
 * @param[in]   client Client instance
 */
void pfe_hif_drv_client_ptp_ts_db_tick_iteration(pfe_hif_drv_client_t *client)
{
    if (NULL != client)
    {
        pfe_hif_ptp_ts_db_tick_iteration(&(client->ptpdb));
    }
}
#endif /* PFE_CFG_IEEE1588_SUPPORT */

static errno_t pfe_hif_drv_create_data_channel(pfe_hif_drv_t *hif_drv)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Sanity check */
        if (sizeof(pfe_hif_rx_meta_t) > pfe_hif_chnl_get_meta_size(hif_drv->channel))
        {
            NXP_LOG_ERROR("Metadata storage size (%u) is less than required (%u)\n", (uint_t)(pfe_hif_chnl_get_meta_size(hif_drv->channel)), (uint_t)sizeof(pfe_hif_rx_meta_t));
            pfe_hif_drv_destroy_data_channel(hif_drv);
            ret = ENOMEM;
        }
        else
        {
            /* Allocate the TX metadata storage and initialize indexes */
            hif_drv->tx_meta_number = pfe_hif_chnl_get_tx_fifo_depth(hif_drv->channel);
            (void)autolibc_memset(hif_drv->tx_meta, 0, sizeof(hif_drv->tx_meta));
            hif_drv->tx_meta_rd_idx = 0U;
            hif_drv->tx_meta_wr_idx = 0U;
            ret = EOK;
        }
    }

    return ret;
}


/**
 * @brief   Destroy HIF channel and release allocated resources
 * @details Will also release all RX buffers associated with RX ring and confirm
 *          all pending TX frames from the TX ring.
 */
static void pfe_hif_drv_destroy_data_channel(pfe_hif_drv_t *hif_drv)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Disable and invalidate RX and TX */
        pfe_hif_chnl_rx_disable(hif_drv->channel);
        pfe_hif_chnl_tx_disable(hif_drv->channel);
    }
}



static pfe_hif_drv_client_t *pfe_hif_drv_assign_client(pfe_hif_drv_t *hif_drv, pfe_ct_hif_rx_hdr_t *hif_hdr_ptr)
{
    pfe_hif_drv_client_t *client;
    /*
        This is leading buffer of a frame. Only the leading one
        contains HIF header data so get it (COPY!) and store it.

        To maximize resource utilization the HIF header is later
        used to store buffer-related metadata. DO NOT ACCESS this
        region after metadata has been written.
    */
    hif_hdr_ptr->flags = (pfe_ct_hif_rx_flags_t)oal_ntohl(hif_hdr_ptr->flags);
    hif_drv->i_phy_if = hif_hdr_ptr->i_phy_if;

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    if (((uint32)hif_hdr_ptr->flags & (uint32)HIF_RX_IHC) != 0U)
    {
        /* IHC client */
        client = &hif_drv->clients[HIF_CLIENTS_IHC_IDX];
    }
    else
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
    {
        /* Get client associated with ingress physical interface ID */
        client = &hif_drv->clients[hif_hdr_ptr->i_phy_if];
    }

    /* Check if standard (or IHC) client exists */
    if (FALSE == (client)->active)
    {
        /* Standard client not present. Use the AUX client as fall-back. */
        client = &hif_drv->clients[HIF_CLIENTS_AUX_IDX];
    }
    else
    {
        /* Standard client present. Check if it is promiscuous. */
        if (TRUE == (client)->promisc)
        {
            /* Client is promiscuous so shall accept all traffic */
            ;
        }
        else
        {
            /* Client is not promiscuous and shall accept only
            "management" traffic but only in case, when the
            AUX client is present. So first check, if the AUX
            is present. */
            if (TRUE == hif_drv->clients[HIF_CLIENTS_AUX_IDX].active)
            {
                /* AUX client does exist. Check if the frame is "management". */
                if (0U != ((uint32)hif_hdr_ptr->flags
                                & ((uint32)HIF_RX_PTP | (uint32)HIF_RX_ETS)))
                {
                    /* Frame is "management" and will be received by
                    the standard client */
                    ;
                }
                else
                {
                    /* Frame is not "management". Will be received by the
                    AUX client. */
                    client = &hif_drv->clients[HIF_CLIENTS_AUX_IDX];
                }
            }
            else
            {
                /* Use the standard client */
                ;
            }
        }
    }

    return client;
}

/**
 * @brief       Process egress time stamp
 */
static void pfe_hif_drv_process_ets(pfe_hif_drv_client_t **client, void *current_buffer_va)
{
#ifdef PFE_CFG_IEEE1588_SUPPORT
    const pfe_ct_ets_report_t *etsr =
            (pfe_ct_ets_report_t *)((addr_t)current_buffer_va + sizeof(pfe_ct_hif_rx_hdr_t));

    /*  Match received TS with a frame in DB. Timestamp values are already in host endian... */
    if (EOK != pfe_hif_ptp_ts_db_push_ts(   &(*client)->ptpdb, FALSE,
                                            oal_ntohs(etsr->ref_num) & 0x0FFFU,
                                            etsr->ts_sec, etsr->ts_nsec
                                        ))
    {
        NXP_LOG_ERROR("Got TS for an unknown frame\n");
    }
    else if (NULL != (*client)->event_handler)
    {
        uint32 qq;
        /* Call handlers */
        for (qq = 0U; qq < HIF_DRV_CLIENT_QUEUES_MAX; qq++)
        {
            if (TRUE == (*client)->tx_q[qq].has_new_ets_data)
            {
                (void)(*client)->event_handler(*client, (*client)->priv, EVENT_ETS, qq);
                (*client)->tx_q[qq].has_new_ets_data = FALSE;
            }
        }
    }
    else
    {
        ; /* No action required */
    }
#else
    /* Suppress compiler warnings */
    (void)(*client);
    (void)current_buffer_va;
#ifdef PFE_CFG_DEBUG
    NXP_LOG_DEBUG("Egress timestamp report received. Will be dropped.\n");
#endif
#endif /* PFE_CFG_IEEE1588_SUPPORT */
}


#ifdef PFE_CFG_IEEE1588_SUPPORT
/**
 * @brief       Process time stamp
 */
static void pfe_hif_drv_process_ts(uint32 rx_len, pfe_ct_hif_rx_hdr_t *hif_hdr_ptr, pfe_hif_drv_client_t *client, void *current_buffer_va)
{
    errno_t ret;

    if (((uint32)hif_hdr_ptr->flags & (uint32)HIF_RX_PTP) != 0U)
    {
        oal_util_ptp_header_t *ptph;
        uint16 ref = (uint16)(oal_util_get_unique_seqnum32() & 0xffffU);

        if (EOK == oal_util_parse_ptp((void *)((addr_t)current_buffer_va+sizeof(pfe_ct_hif_rx_hdr_t)),
                rx_len-sizeof(pfe_ct_hif_rx_hdr_t), &ptph))
        {
            /* Only Event messages will be pushed into database */
            if((ptph->byte1.messageType == PTP_MSG_SYNC) || (ptph->byte1.messageType == PTP_MSG_DELAY_REQ) ||
                (ptph->byte1.messageType == PTP_MSG_PDELAY_REQ) || (ptph->byte1.messageType == PTP_MSG_PDELAY_RESP))
            {
                /* Store the RX frame reference and timestamp into the DB */
                ret = pfe_hif_ptp_ts_db_push_msg(&client->ptpdb, TRUE, ref, ptph->byte1.messageType,
                        oal_ntohs(ptph->sourcePortID), oal_ntohs(ptph->sequenceID));
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Could not store received PTP message: %d\n", ret);
                }
                else
                {
                    /*  Timestamp is in little-endian format */
                    ret = pfe_hif_ptp_ts_db_push_ts(&client->ptpdb, TRUE,
                            ref, hif_hdr_ptr->rx_timestamp_s, hif_hdr_ptr->rx_timestamp_ns);

                    if (EOK == ret)
                    {
#ifdef PFE_CFG_DEBUG
                        NXP_LOG_DEBUG("New (RX) PTP frame: Type: 0x%x, Port: 0x%x, SeqID: 0x%x, Sec: 0x%x, nSec: 0x%x\n",
                            ptph->byte1.messageType, oal_ntohs(ptph->sourcePortID), oal_ntohs(ptph->sequenceID),
                                hif_hdr_ptr->rx_timestamp_s, hif_hdr_ptr->rx_timestamp_ns);
#endif /* PFE_CFG_DEBUG */
                    }
                    else
                    {
                        NXP_LOG_ERROR("Could not store received timestamp: %d\n", ret);
                    }
                }
            }
        }
        else
        {
            NXP_LOG_ERROR("PTP frame not found\n");
        }
    }
}
#endif /* PFE_CFG_IEEE1588_SUPPORT */


/**
 * @brief       Auxiliary function to evaluate ret of previous function
 * @note        Purpose is to lower CCM
 */
static void release_rx_buffer_with_check(pfe_hif_drv_t *hif_drv, const void *current_buffer_va)
{
    errno_t ret;

    ret = pfe_hif_chnl_release_rx_buf(hif_drv->channel, current_buffer_va);
    /*it is not likely that ret would be other than EOK*/
    if (unlikely(EOK != ret))
    {
        NXP_LOG_ERROR("Unable to release RX buffer%d\n", ret);
    }
}


#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
static void pfe_hif_drv_notify_rx_clients(uint32 rx_clients, pfe_hif_drv_t *hif_drv)
{
        /* Notify client(s) about new data */
    uint32 ii;
    pfe_hif_drv_client_t *client;

    ii=0U;
    while (rx_clients!=0U)
    {
        if ((rx_clients & 0x1U) != 0U)
        {
            /* Get client */
            client = &hif_drv->clients[ii];
            /* Call handler. Queue information not passed. Add if needed. */
            (void)client->event_handler(client, client->priv, EVENT_RX_PKT_IND, 0U);
        }
        ii++;
        rx_clients>>=1;
    }
}
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

/**
 * @brief       Processing of the buffer, eliminating the multi-buffer frame
 * @param[in]   lifm The last in frame boolean indicator
 * @param[in]   hif_drv The HIF driver instance
 * @return      TRUE if a multi-buffer frame is detected, FALSE otherwise.
 */
static bool_t pfe_hif_drv_process_lifm(bool_t lifm, pfe_hif_drv_t **hif_drv)
{
    bool_t return_value = FALSE;

    if((TRUE == lifm) && (FALSE == (*hif_drv)->started))
    {
        /* This is single buffer frame*/
        ;
    }
    else if((TRUE == lifm) && (TRUE == (*hif_drv)->started))
    {
        /* This is last buffer of a multi-buffer frame */
        (*hif_drv)->started = FALSE;
        return_value = TRUE;
    }
    else if(FALSE == lifm)
    {
        /* This is a multi-buffer frame */
        (*hif_drv)->started = TRUE;
        return_value = TRUE;
    }
    else
    {
        /*This should never happen*/
        ;
    }

    return return_value;
}


/**
 * @brief       The HIF RX ring processing routine
 * @param[in]   hif_drv The HIF driver instance
 * @param[in]   budget Maximum number of frames to process in a single iteration
 * @note        Runs within the RX worker thread context
 */
static void pfe_hif_drv_process_rx(pfe_hif_drv_t *hif_drv)
{
    pfe_ct_hif_rx_hdr_t *hif_hdr_ptr;
    uint32 rx_len;
    void *current_buffer_va, *meta_va;
bool_t lifm;
    pfe_hif_drv_client_t *client;
    pfe_hif_rx_meta_t *rx_metadata;
    errno_t ret;
    uint32 rx_clients = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        while (TRUE)
        {
            /* Get RX buffer */
            if (EOK != pfe_hif_chnl_rx_va(hif_drv->channel, &current_buffer_va, &rx_len, &lifm, &meta_va))
            {
                break;
            }

            hif_hdr_ptr = (pfe_ct_hif_rx_hdr_t *)current_buffer_va;

            if(TRUE == pfe_hif_drv_process_lifm(lifm, &hif_drv))
            {
                /*Multi-buffer frame detected, releasing buffer*/
                release_rx_buffer_with_check(hif_drv, current_buffer_va);
                continue;
            }

            client = pfe_hif_drv_assign_client(hif_drv, hif_hdr_ptr);

            /* Check if a client determined above is active/present */
            if (unlikely(FALSE == client->active))
            {
                /* Client is not present. Drop the frame. Resource protection is embedded. */
                NXP_LOG_WARNING("Invalid client, dropping packet\n");
                release_rx_buffer_with_check(hif_drv, current_buffer_va);
                continue;
            }

#ifdef PFE_CFG_DEBUG
            if (unlikely(hif_drv->qno >= client->rx_qn))
            {
                /* Drop the frame. Resource protection is embedded. */
                NXP_LOG_WARNING("Packet with invalid queue ID: %d\n", hif_drv->qno);
                release_rx_buffer_with_check(hif_drv, current_buffer_va);
#ifdef HIF_STATS
                hif_drv->counters[HIF_STATS_RX_FRAME_DROPS]++;
#endif /* HIF_STATS */
                continue;
            }
#endif /* PFE_CFG_DEBUG */

            if (((uint32)hif_hdr_ptr->flags & (uint32)HIF_RX_ETS) != 0UL)
            {
                /*PFE_CFG_IEEE1588_SUPPORT*/
                pfe_hif_drv_process_ets(&client, current_buffer_va);
                /* Drop the frame. Resource protection is embedded. */
                release_rx_buffer_with_check(hif_drv, current_buffer_va);
#ifdef HIF_STATS
                hif_drv->counters[HIF_STATS_RX_FRAME_ETS]++;
#endif /* HIF_STATS */

                continue;
            }

#ifdef PFE_CFG_IEEE1588_SUPPORT
            if (((uint32)hif_hdr_ptr->flags & (uint32)HIF_RX_TS) != 0U)
            {
                pfe_hif_drv_process_ts(rx_len, hif_hdr_ptr, client, current_buffer_va);
            }
#endif /*PFE_CFG_IEEE1588_SUPPORT*/
            /* Fill the RX metadata */
            rx_metadata = (pfe_hif_rx_meta_t *)meta_va;
            rx_metadata->client = client;
            rx_metadata->data = (addr_t)current_buffer_va;
            rx_metadata->len = rx_len;
            rx_metadata->flags.specific.rx_flags = hif_hdr_ptr->flags;
            rx_metadata->q_no = hif_drv->qno;
            rx_metadata->i_phy_if = hif_drv->i_phy_if;

            /* Enqueue the packet into client's RX queue. No resource protection here. */
            ret = fifo_put(client->rx_q[hif_drv->qno].rx_fifo, rx_metadata);
            if (unlikely(EOK != ret))
            {
                /* Drop the frame. Resource protection is embedded. */
                release_rx_buffer_with_check(hif_drv, current_buffer_va);

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
                if (client == &hif_drv->clients[HIF_CLIENTS_IHC_IDX])
                {
                    /* The client is IHC client */
                    NXP_LOG_WARNING("IHC client's RX queue is full. Frame dropped.\n");
                }
                else
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
                {
                    /* The client is physical interface client */
                    NXP_LOG_WARNING("Client's (%d) RX queue is full. Frame dropped.\n", client->phy_if_id);
                }
#ifdef HIF_STATS
                hif_drv->counters[HIF_STATS_CLIENT_FULL_COUNT]++;
#endif /* HIF_STATS */
                continue;
            }
            else
            {
                /*  Remember that client has a new data */
                rx_clients |= client->id_mask;
            }
        } /* end of while */
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
        pfe_hif_drv_notify_rx_clients(rx_clients, hif_drv);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
    }
}


static void hif_client_free_rx_queues(pfe_hif_drv_client_t *client)
{
    uint32 ii;
    struct client_rx_queue *queue;
    pfe_hif_pkt_t *pkt;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (ii=0U; ii<client->rx_qn; ii++)
        {
            queue = &client->rx_q[ii];
            if (likely(NULL != queue->rx_fifo))
            {
                /* Properly release all remaining Rx buffers */
                pkt = fifo_get(queue->rx_fifo);
                while (NULL != pkt)
                {
                    pfe_hif_pkt_free(pkt);
                    pkt = fifo_get(queue->rx_fifo);
                }

                fifo_destroy(queue->rx_fifo);
                queue->rx_fifo = NULL;
            }
        }
    }
}

static void hif_client_free_tx_queues(pfe_hif_drv_client_t *client)
{
    uint32 ii;
    uint32 fill_level;
    struct client_tx_queue *queue;
    errno_t err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (ii=0U; ii<client->tx_qn; ii++)
        {
            queue = &client->tx_q[ii];
            if (likely(NULL != queue->tx_conf_fifo))
            {
                err = fifo_get_fill_level(queue->tx_conf_fifo, &fill_level);
                if (unlikely(EOK != err))
                {
                    NXP_LOG_ERROR("Unable to get fifo fill level: %d\n", err);
                }

                if (0U != fill_level)
                {
                    NXP_LOG_WARNING("Client %d, TX queue %u: Queue is not empty\n", client->phy_if_id, (uint_t)ii);
                }

                fifo_destroy(queue->tx_conf_fifo);
                queue->tx_conf_fifo = NULL;
            }
        }
    }
}

static errno_t hif_client_create_rx_queues(pfe_hif_drv_client_t *client, fifo_t *fifo)
{
    uint32 ii;
    struct client_rx_queue *queue;
    fifo_t *tmp_fifo = fifo;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == client) || (NULL == fifo)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Initialize RX queues */
        (void)autolibc_memset(client->rx_q, 0, HIF_DRV_CLIENT_QUEUES_MAX * sizeof(struct client_rx_queue));

        /* Create the queues */
        for (ii=0U; ii<client->rx_qn; ii++)
        {
            queue = &client->rx_q[ii];

            /*
                This FIFO is used to store received frames until client processes it.
                HIF is putting data in there by calling 'put()' and client is reading it via 'get()'.
                Since there is only one producer and one consumer the FIFO does not need to be
                protected. See pfe_hif_drv_client_receive_pkt().
            */
            queue->rx_fifo = tmp_fifo;
            queue->size = tmp_fifo->depth;
            tmp_fifo++;
        }
        ret = EOK;
    }

    return ret;
}

static errno_t hif_client_create_tx_queues(pfe_hif_drv_client_t *client, fifo_t *fifo)
{
    uint32 ii;
    struct client_tx_queue *queue;
    fifo_t *tmp_fifo = fifo;
    errno_t ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == client) || (NULL == fifo)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Initialize TX queues */
        (void)autolibc_memset(client->tx_q, 0, HIF_DRV_CLIENT_QUEUES_MAX * sizeof(struct client_tx_queue));

        /* Create the queues */
        for (ii=0U; ii<client->tx_qn; ii++)
        {
            queue = &client->tx_q[ii];

            /* Create TX confirmation queues. Does not need to be protected since only HIF
               worker puts data in there and only a single client read it. */
            queue->tx_conf_fifo = tmp_fifo;
            queue->size = tmp_fifo->depth;
            tmp_fifo++;
        }
        ret = EOK;
    }

    return ret;
}

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
/**
 * @brief       Register special IHC client
 * @details     Routine creates new HIF driver client to be used for inter-HIF communication
 * @param[in]   hif_drv The HIF driver instance the client shall be associated with
 * @param[in]   handler Pointer to function to be called to indicate events (data available, ...).
 *                      Mandatory. Can be called from various contexts.
 * @param[in]   priv Private data to be stored within the client instance and passed as handler argument
 * @return      HIF driver client instance or NULL if failed
 */
pfe_hif_drv_client_t *
    pfe_hif_drv_ihc_client_register(
        pfe_hif_drv_t *hif_drv,
        pfe_hif_drv_client_event_handler handler,
        void *priv)
{
    pfe_hif_drv_client_t *client;
    pfe_hif_drv_client_rx_tx_count client_queue;
    pfe_hif_drv_client_fifo_queue client_fifo_queue;
    pfe_hif_drv_client_data client_data = { hif_drv, (pfe_ct_phy_if_id_t)HIF_CLIENTS_IHC_IDX, &client_queue, &client_fifo_queue, TRUE, handler, priv };

    if (NULL == handler)
    {
        NXP_LOG_ERROR("Event handler is mandatory\n");
        client = NULL;
    }
    else
    {

        /* compile time check if have only one for rx and tx */
        ct_assert(PFE_HIF_DRV_IHC_CLIENT_RX_QUEUES == 1U);
        ct_assert(PFE_HIF_DRV_IHC_CLIENT_TX_QUEUES == 1U);

        client_fifo_queue.rxq_fifo = fifo_create(PFE_HIF_DRV_IHC_CLIENT_RX_QUEUE_DEPTH, ihc_client_fifos.rx_fifo, ihc_client_fifos.rx_fifo_data);
        if (NULL == (client_fifo_queue.rxq_fifo))
        {
            NXP_LOG_ERROR("Can't create RX queues\n");
            client = NULL;
        }
        else
        {
            client_fifo_queue.txq_fifo = fifo_create(PFE_HIF_DRV_IHC_CLIENT_TX_QUEUE_DEPTH, ihc_client_fifos.tx_conf_fifo, ihc_client_fifos.tx_conf_fifo_data);
            if (NULL == (client_fifo_queue.txq_fifo))
            {
                NXP_LOG_ERROR("Can't create TX queues\n");
                client = NULL;
            }
            else
            {
                client = &hif_drv->clients[HIF_CLIENTS_IHC_IDX];    /* Client storage */

                client_queue.txq_num = PFE_HIF_DRV_IHC_CLIENT_TX_QUEUES; /* Number of TX queues */
                client_queue.rxq_num = PFE_HIF_DRV_IHC_CLIENT_RX_QUEUES; /* Number of RX queues */

                client = pfe_hif_drv_client_register_ll(client, &client_data);

                if (NULL != client)
                {
                    NXP_LOG_INFO("HIF IHC client registered\n");
                }
            }
        }
    }

    return client;
}
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

/**
 * @brief       Register auxiliary client
 * @details     Client will receive all packets not matching any other registered client and
 *              transmission via this client will fully rely on the related physical interface
 *              (HIF channel) configuration, i.e. client will NOT inject traffic.
 * @param[in]   hif_drv The HIF driver instance the client shall be associated with
 * @param[in]   txq_num Number of client's TX queues
 * @param[in]   rxq_num Number of client's RX queues
 * @param[in]   txq_fifo FIFO array for each TX queue
 * @param[in]   rxq_fifo FIFO array for each RX queue
 * @param[in]   handler Pointer to function to be called to indicate events (data available, ...).
 *                      Mandatory. Can be called from various contexts.
 * @param[in]   priv Private data to be stored within the client instance and passed as handler argument
 * @return      HIF driver client instance or NULL if failed
 */
pfe_hif_drv_client_t * pfe_hif_drv_aux_client_register(
    pfe_hif_drv_t *hif_drv,
    pfe_hif_drv_client_rx_tx_count *client_queue,
    pfe_hif_drv_client_fifo_queue  *client_fifo_queue,
    pfe_hif_drv_client_event_handler handler,
    void *priv)
{
    pfe_hif_drv_client_t *client;
    pfe_hif_drv_client_data client_data = { hif_drv, (pfe_ct_phy_if_id_t)HIF_CLIENTS_AUX_IDX, client_queue, client_fifo_queue, TRUE, handler, priv };

    if (NULL == handler)
    {
        NXP_LOG_ERROR("Event handler is mandatory\n");
        client = NULL;
    }
    else
    {
        client = &hif_drv->clients[HIF_CLIENTS_AUX_IDX];    /* Client storage */

        client = pfe_hif_drv_client_register_ll( client, &client_data);

        if (NULL != client)
        {
            NXP_LOG_INFO("HIF AUX client registered\n");
        }
    }

    return client;
}

/**
 * @brief       This function is used to register a client driver with the HIF driver.
 * @details     Routine creates new HIF driver client, associates it with given physical interface
 *              and adjusts internal HIF dispatching table to properly route ingress packets to
 *              client's queues.
 * @param[in]   hif_drv The HIF driver instance the client shall be associated with
 * @param[in]   phy_if_id Physical interface ID to be handled by the client
 * @param[in]   txq_num Number of client's TX queues
 * @param[in]   rxq_num Number of client's RX queues
 * @param[in]   txq_fifo FIFO array for each TX queue
 * @param[in]   rxq_fifo FIFO array for each RX queue
 * @param[in]   promisc If TRUE then the client will accept all received frames. If FALSE then
 *                      the client will accept only "management" traffic and rest will be delivered
 *                      to AUX, if does exist.
 * @param[in]   handler Pointer to function to be called to indicate events (data available, ...).
 *                      Mandatory. Can be called from various contexts.
 * @param[in]   priv Private data to be stored within the client instance
 *
 * @return      Client instance or NULL if failed
 */
pfe_hif_drv_client_t *
    pfe_hif_drv_client_register(
        pfe_hif_drv_t *hif_drv,
        pfe_ct_phy_if_id_t phy_if_id,
        pfe_hif_drv_client_rx_tx_count *client_queue,
        pfe_hif_drv_client_fifo_queue  *client_fifo_queue,
        bool_t promisc,
        pfe_hif_drv_client_event_handler handler,
        void *priv)
{
    pfe_hif_drv_client_t *client;
    pfe_hif_drv_client_data client_data = { hif_drv, phy_if_id, client_queue, client_fifo_queue, promisc, handler, priv };
    /*
        The HIF driver is using physical interface ID to match ingress packets with clients.
        For this purpose an array is used where particular client instances are stored
        and the HIF driver is addressing them via physical interface IDs received from classifier.
        Size of this array is limited so we only support limited number of clients and limited
        range of logical interface IDs (0 - HIF_CLIENTS_MAX).
     */
    if ((uint8)phy_if_id >= HIF_CLIENTS_MAX)
    {
        NXP_LOG_ERROR("Incompatible interface ID requested: %d\n", phy_if_id);
        client = NULL;
    }
    else if (NULL == handler)
    {
        NXP_LOG_ERROR("Event handler is mandatory\n");
        client = NULL;
    }
    else
    {
        client = &hif_drv->clients[phy_if_id];

        client = pfe_hif_drv_client_register_ll(client, &client_data);

        if (NULL != client)
        {
            NXP_LOG_INFO("HIF client %d registered\n", phy_if_id);
        }
    }
    return client;
}

/*  Create client's RX queues, initialize client's TX queues, activate client */
static errno_t pfe_hif_drv_client_create_rx_tx( pfe_hif_drv_client_t *client_tmp, pfe_hif_drv_client_data *client_data)
{
    errno_t err = EOK;
    pfe_hif_drv_client_fifo_queue  *client_fifo_queue = client_data->client_fifo_queue;
    
    /*  Create client's RX queues */
    err = hif_client_create_rx_queues(client_tmp, client_fifo_queue->rxq_fifo);
    if (unlikely(EOK != err))
    {
        NXP_LOG_ERROR("Can't create RX queues: %d\n", err);
    }
    else
    {
        /*  Initialize client's TX queues */
        err = hif_client_create_tx_queues(client_tmp, client_fifo_queue->txq_fifo);
        if (unlikely(EOK != err))
        {
            NXP_LOG_ERROR("Can't create TX queues: %d\n", err);
        }
        else
        {
#ifdef PFE_CFG_IEEE1588_SUPPORT
            /*  Initialize PTP timestamp database */
            err = pfe_hif_ptp_ts_db_init(&client_tmp->ptpdb);
            if (EOK != err)
            {
                NXP_LOG_ERROR("PTP DB init failed\n");
            }
            else
#endif /* PFE_CFG_IEEE1588_SUPPORT */
            {
                /*  Activate the client */
                client_tmp->active = TRUE;
            }
        }
    }

    return err;
}

/**
 * @brief Register and configure the client
 */
static pfe_hif_drv_client_t * pfe_hif_drv_client_register_ll( pfe_hif_drv_client_t *client, pfe_hif_drv_client_data *client_data)
{
    errno_t err;
    pfe_hif_drv_client_rx_tx_count *client_queue = client_data->client_queue;
    uint32 txq_num_temp = client_queue->txq_num;
    uint32 rxq_num_temp = client_queue->rxq_num;
    pfe_hif_drv_client_t *client_tmp = client;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == client) || (NULL_PTR == client_tmp) ||(NULL_PTR == client_data) ))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        client_tmp = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((uint8)client_data->phy_if_id >= HIF_CLIENTS_MAX)
        {
            NXP_LOG_DEBUG("Client ID out of supported range\n");
            client_tmp = NULL_PTR;
        }
        else
        {
            if (FALSE != client->active)
            {
                NXP_LOG_ERROR("Client already initialized\n");
                /* force to unregister */
                err = ECANCELED;
            }
            else
            {
                /*  Check if client is requesting more queues than supported */
                if (rxq_num_temp > HIF_DRV_CLIENT_QUEUES_MAX)
                {
                    NXP_LOG_WARNING("Client requests more (%u) RX queues than currently supported maximum (%d)\n",
                            (uint_t)rxq_num_temp, HIF_DRV_CLIENT_QUEUES_MAX);
                    rxq_num_temp = HIF_DRV_CLIENT_QUEUES_MAX;
                }

                /*  Check if client is requesting more queues than supported */
                if (txq_num_temp > HIF_DRV_CLIENT_QUEUES_MAX)
                {
                    NXP_LOG_WARNING("Client requests more (%u) TX queues than currently supported maximum (%d)\n",
                            (uint_t)txq_num_temp, HIF_DRV_CLIENT_QUEUES_MAX);
                    txq_num_temp = HIF_DRV_CLIENT_QUEUES_MAX;
                }

                /*    Initialize the instance */
                (void)autolibc_memset(client_tmp, 0, sizeof(pfe_hif_drv_client_t));

                client_tmp->id_mask = ((uint32)1U << (uint8)client_data->phy_if_id);
                client_tmp->active = FALSE;
                client_tmp->promisc = client_data->promisc;
                client_tmp->hif_drv = client_data->hif_drv;
                client_tmp->phy_if_id = client_data->phy_if_id;

                client_tmp->rx_qn = rxq_num_temp;
                client_tmp->tx_qn = txq_num_temp;
                client_tmp->event_handler = client_data->handler;
                client_tmp->priv = client_data->priv;

                err = pfe_hif_drv_client_create_rx_tx(client_tmp, client_data);
            }
            if (EOK != err)
            {
                /*  Release the client instance */
                pfe_hif_drv_client_unregister(client_tmp);
                client_tmp = NULL_PTR;
            }
        }
    }

    return client_tmp;
}

/**
 * @brief       Get hif_drv instance associated with the client
 * @param[in]   client Client instance
 * @return      Pointer to the HIF DRV instance
 */
pfe_hif_drv_t *pfe_hif_drv_client_get_drv(const pfe_hif_drv_client_t *client)
{
    pfe_hif_drv_t *ret = NULL;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = client->hif_drv;
    }
    return ret;
}

/**
 * @brief       Get private pointer provided in registration
 * @param[in]   client Client instance
 * @return      Private pointer value
 */
void *pfe_hif_drv_client_get_priv(const pfe_hif_drv_client_t *client)
{
    void *ret = NULL;
#ifdef PFE_CFG_NULL_ARG_CHECK
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = client->priv;
    }
    return ret;
}

/**
 * @brief       Unregister client from the HIF driver
 * @details     Routine removes the given HIF driver client and all associated resources. It
 *              adjusts internal HIF dispatching table and invalidates the client's entry so
 *              all ingress packets targeting the client will be dropped. HIF driver remains
 *              suspended after the call and pfe_hif_drv_start() is required to re-enable the
 *              operation.
 * @param[in]   client Client instance
 */
void pfe_hif_drv_client_unregister(pfe_hif_drv_client_t *client)
{
    bool_t enabled = FALSE;

    if (NULL_PTR != client)
    {
        if (client == &client->hif_drv->clients[HIF_CLIENTS_IHC_IDX])
        {
            NXP_LOG_INFO("Removing IHC client\n");
        }
        else if (client == &client->hif_drv->clients[HIF_CLIENTS_AUX_IDX])
        {
            NXP_LOG_INFO("Removing AUX client\n");
        }
        else
        {
            NXP_LOG_INFO("Removing client %d\n", client->phy_if_id);
        }

        /* Suspend HIF driver to ensure coherent client deregistration */
        enabled = client->hif_drv->tx_enabled || client->hif_drv->rx_enabled;
        if (enabled)
        {
            pfe_hif_drv_stop(client->hif_drv);
        }

        /* Unregister from HIF. After this the HIF RX dispatcher will not fill client's RX queues. */
        client->active = FALSE;

        /* Release queues */
        hif_client_free_rx_queues(client);
        hif_client_free_tx_queues(client);

#ifdef PFE_CFG_IEEE1588_SUPPORT
        /* Finalize the timestamp DB */
        pfe_hif_ptp_ts_db_fini(&client->ptpdb);
#endif /* PFE_CFG_IEEE1588_SUPPORT */

        if (enabled)
        {
            (void)pfe_hif_drv_start(client->hif_drv);
        }

        /* Cleanup memory */
        (void)autolibc_memset(client, 0, sizeof(pfe_hif_drv_client_t));
    }
}

/**
 * @brief       Get packet from RX queue
 * @param[in]   client Client instance
 * @param[in]   queue RX queue number
 * @return      Pointer to SW buffer descriptor containing the packet or NULL
 *              if the queue does not contain data
 *
 * @warning     Intended to be called from a single client context only, i.e.
 *              from a single thread per client.
 */
pfe_hif_pkt_t * pfe_hif_drv_client_receive_pkt(pfe_hif_drv_client_t *client, uint32 queue)
{
    pfe_hif_pkt_t *ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = fifo_get(client->rx_q[queue].rx_fifo);
    }

    /* No resource protection here */
    return ret;
}

/**
 * @brief       Check if there is another Rx packet in queue
 * @param[in]   client Client instance
 * @param[in]   queue RX queue number
 * @retval      TRUE There is at least one Rx packet in Rx queue
 * @retval      FALSE There is no Rx packet in Rx queue
 *
 * @warning     Intended to be called from a single client context only, i.e.
 *              from a single thread per client.
 */
bool_t pfe_hif_drv_client_has_rx_pkt(const pfe_hif_drv_client_t *client, uint32 queue)
{
    uint32 fill_level;
    errno_t err;
    bool_t ret = TRUE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* No resource protection here */
        err = fifo_get_fill_level((volatile fifo_t const *)client->rx_q[queue].rx_fifo, &fill_level);
        if (unlikely(EOK != err))
        {
            NXP_LOG_ERROR("Unable to get fifo fill level: %d\n", err);
            fill_level = 0U;
        }
        if (0U != fill_level)
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Release packet
 * @param[in]   pkt The packet instance
 */
void pfe_hif_pkt_free(const pfe_hif_pkt_t *pkt)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pkt) || unlikely(NULL == pkt->client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Return buffer to the pool. Resource protection is embedded. */
        release_rx_buffer_with_check(pkt->client->hif_drv, (void *)pkt->data);
    }
}

/**
 * @brief       Get TX confirmation
 * @param[in]   client Client instance
 * @param[in]   queue TX queue number
 * @return      Pointer to data associated with the transmitted buffer. See pfe_hif_drv_client_xmit_pkt().
 * @note        Only a single thread can call this function for given client+queue
 *              combination.
 */
void * pfe_hif_drv_client_receive_tx_conf(const pfe_hif_drv_client_t *client, uint32 queue)
{
    void *ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == client))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = fifo_get(client->tx_q[queue].tx_conf_fifo);
    }
    return ret;
}

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
/* Notify client(s) about new confirmations */
static void pfe_hif_drv_notify_clients(pfe_hif_drv_t *hif_drv, uint32 tx_clients)
{
    uint32 qq;
    uint32 ii;
    pfe_hif_drv_client_t *client;

    ii = 0U;
    while(tx_clients != 0U)
    {
        if ((tx_clients & 0x1U) != 0U)
        {
            /* Get client */
            client = &hif_drv->clients[ii];
            /* Call handlers */
            for (qq = 0U; qq < HIF_DRV_CLIENT_QUEUES_MAX; qq++)
            {
                if (TRUE == client->tx_q[qq].has_new_data)
                {
                    (void)client->event_handler(client, client->priv, EVENT_TXDONE_IND, qq);
                    client->tx_q[qq].has_new_data = FALSE;
                }
            }
        }
        ii++;
        tx_clients>>=1;
    }
}
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

/* Put the reference data to client's TX confirmation queue. */
static errno_t pfe_hif_drv_put_data_to_tx_conf_queue(pfe_hif_drv_t *hif_drv, pfe_hif_drv_client_t *client, uint32 *tx_clients, pfe_hif_tx_meta_t *tx_metadata)
{
    errno_t ret;

    ret = fifo_put(client->tx_q[tx_metadata->q_no].tx_conf_fifo, tx_metadata->ref_ptr);
    if (unlikely(EOK != ret))
    {
        /* Drop the confirmation */
        if (client->id_mask == (1UL << HIF_CLIENTS_AUX_IDX))
        {
            NXP_LOG_WARNING("AUX client's TX confirmation queue is full. TX confirmation dropped.\n");
        }
        else
        {
            /* The client is standard client */
            NXP_LOG_WARNING("Client's (%d) TX confirmation queue is full. TX confirmation dropped.\n",
                client->phy_if_id);
        }
#ifdef HIF_STATS
        hif_drv->counters[HIF_STATS_TX_CONFIRMATION_DROPS]++;
#endif
    }
    else
    {
        /* Remember that THIS client has a new confirmation */
        *tx_clients |= client->id_mask;
        client->tx_q[tx_metadata->q_no].has_new_data = TRUE;
        if (((uint32)tx_metadata->ets_flag & (uint32)HIF_TX_ETS) != 0UL)
        {
            client->tx_q[tx_metadata->q_no].has_new_ets_data = TRUE;
        }
    }

    return ret;
}

/**
 * @brief       The TX processing routine
 * @details     Process TX confirmations reported by HIF channel and notify
 *              particular clients if their packets were transmitted. Should
 *              be called often enough to keep the channel ready, and clients
 *              informed about their transmission requests.
 * @param[in]   hif_drv The HIF driver instance
 * @param[in]   budget Maximum number of TX confirmations to clean-up at once
 *
 * @return      Number of processed TX frame confirmations
 * @note        No TX resource protection is included. Shall be done by caller
 *              routine.
 */
static uint32 pfe_hif_drv_process_tx(pfe_hif_drv_t *hif_drv, uint32 budget)
{
    pfe_hif_tx_meta_t *tx_metadata;
    pfe_hif_drv_client_t *client;
    uint32 processed_count = 0U;
    uint32 dropped_count = 0U;
    uint32 tx_clients = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*
        * NOTE:
        *    - This statement has no functional purpose. It is purely to remove a compiler warning.
        *    - In case there is no TX confirmation received, the event_handler will not be called anyway.
        */
        tx_metadata = &hif_drv->tx_meta[hif_drv->tx_meta_rd_idx];

        do
        {
            /* Dequeue TX confirmation. This is actually only check whether
            some next frame has been transmitted. */
            if (EOK != pfe_hif_chnl_get_tx_conf(hif_drv->channel))
            {
                /* No more entries to dequeue */
                break;
            }

            /* Get metadata associated with the transmitted frame */
            tx_metadata = &hif_drv->tx_meta[hif_drv->tx_meta_rd_idx];

            /* Get client */
            client = tx_metadata->client;

            if (unlikely(NULL == client) || unlikely(client->active == FALSE))
            {
                if (0U == dropped_count)
                {
                    NXP_LOG_WARNING("Client not registered or inactive, dropping TX confirmation(s)\n");
                }

#ifdef HIF_STATS
                hif_drv->counters[HIF_STATS_TX_CONFIRMATION_DROPS]++;
#endif
                dropped_count++;

                /* Move to next entry */
                hif_drv->tx_meta_rd_idx++;
                if (hif_drv->tx_meta_rd_idx >= PFE_CFG_HIF_RING_LENGTH)
                {
                    hif_drv->tx_meta_rd_idx = 0U;
                }
                continue;
            }

            /* We have end-of-frame confirmation here */
            /* Skip next step for IHC client, it does not use tx confirmations */
            if (client->id_mask != (1UL << HIF_CLIENTS_IHC_IDX))
            {
                /* We have end-of-frame confirmation here. Put the reference data to client's TX confirmation queue. */
                (void) pfe_hif_drv_put_data_to_tx_conf_queue(hif_drv, client, &tx_clients, tx_metadata);
            }

            /* Move to next entry */
            hif_drv->tx_meta_rd_idx++;
            if (hif_drv->tx_meta_rd_idx >= PFE_CFG_HIF_RING_LENGTH)
            {
                hif_drv->tx_meta_rd_idx = 0U;
            }

        } while (++processed_count < budget);

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
        /* Notify client(s) about new confirmations */
        pfe_hif_drv_notify_clients(hif_drv, tx_clients);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

        if (unlikely(dropped_count > 0U))
        {
            NXP_LOG_INFO("%u TX confirmations dropped\n", (uint_t)dropped_count);
        }
    }
    return processed_count;
}

/**
 * @brief       Set physical interface for TX traffic injection
 * @details     Set physical interface to be used when driver will attempt to transmit
 *              a packet in "inject" mode.
 * @param[in]   client Client instance
 * @param[in]   phy_if_id The physical interface ID
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_hif_drv_client_set_inject_if(pfe_hif_drv_client_t *client, pfe_ct_phy_if_id_t phy_if_id)
{
    errno_t ret;

    if (phy_if_id >= PFE_PHY_IF_ID_INVALID)
    {
        ret = EINVAL;
    }
    else
    {
        /* Set new physical interface */
        client->phy_if_id = phy_if_id;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Initialize TX header
 * @param[in]   client Client instance
 * @param[in]   tx_header Pointer to the tx header
 * @param[in]   queue TX queue number
 * @return      EOK if success, error code otherwise.
 */
errno_t pfe_hif_drv_init_tx_header(pfe_hif_drv_client_t *client, pfe_ct_hif_tx_hdr_t *tx_header, const uint8 queue)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == client) || (NULL == tx_header)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tx_header->chid = (uint8)pfe_hif_chnl_get_id(client->hif_drv->channel);
#if (TRUE == PFE_CFG_EGRESS_PRIO_BY_FW)
        /* Firmware will assign queue/priority */
        tx_header->queue = 255U;
        (void)queue;
#else
        tx_header->queue = queue;
#endif /* PFE_CFG_HIF_PRIO_CTRL */

        tx_header->flags = (pfe_ct_hif_tx_flags_t)0U;;
#ifdef PFE_CFG_CSUM_ALL_FRAMES
        tx_header->flags |= HIF_TX_IP_CSUM | HIF_TX_TCP_CSUM | HIF_TX_UDP_CSUM;
#else
    #if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_IPV4)
        tx_header->flags |= HIF_TX_IP_CSUM;
    #endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_IPV4 */
    #if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_TCP)
        tx_header->flags |= HIF_TX_TCP_CSUM;
    #endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_TCP */
    #if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_UDP)
        tx_header->flags |= HIF_TX_UDP_CSUM;
    #endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_UDP */
    #if (STD_ON == ETH_43_PFE_ENABLE_OFFLOAD_CSUM_ICMP)
        tx_header->flags |= HIF_TX_ICMP_CSUM;
    #endif /* ETH_43_PFE_ENABLE_OFFLOAD_CSUM_ICMP */
#endif /* PFE_CFG_CSUM_ALL_FRAMES */

        if (client->id_mask == (1UL << HIF_CLIENTS_AUX_IDX))
        {
            /* Let PFE route the packet using current configuration */
            tx_header->e_phy_ifs = 0U;
        }
        else
        {
            /* Traffic from standard clients can be routed or injected */
#ifdef PFE_CFG_ROUTE_HIF_TRAFFIC
            /* Tag the frame with ID of target physical interface. PFE will
               be able to use this to route the frame using Flexible Router. */
            tx_header->cookie = oal_htonl(client->phy_if_id);
#else
            /* Let PFE inject the frame directly to egress interface */
            tx_header->e_phy_ifs = oal_htonl(1UL << (uint8)client->phy_if_id);
            tx_header->flags |= HIF_TX_INJECT;
#endif /* PFE_CFG_ROUTE_HIF_TRAFFIC */
        }
        ret = EOK;
    }
    return ret;
}

#ifdef PFE_CFG_IEEE1588_SUPPORT
/* PFE config IEEE1588 support */
static void pfe_hif_drv_cfg_IEEE1588(pfe_hif_drv_client_t *client, pfe_ct_hif_tx_hdr_t *tx_hdr, pfe_hif_tx_meta_t *tx_metadata, const hif_frame_t *const frame, void *ref_ptr)
{
    /* Check bDoTS flag in Tx metadata */
    errno_t err;
    Eth_PFE_LLD_trTxTsRef *tx_ts_ref_mcal;
    pfe_hif_drv_t *hif_drv;
    hif_drv = client->hif_drv;
    (void) hif_drv;
    const Eth_PFE_LLD_trTxRefData *ref_ptr_mcal = (Eth_PFE_LLD_trTxRefData *)ref_ptr;
    const trTxMeta *tx_meta = Eth_PFE_LLD_GetTxBufMeta(ref_ptr_mcal->u8CtrlIdx, ref_ptr_mcal->u16BufIdx);
    if (TRUE == tx_meta->bDoTS)
    {
        /* Check if frame is a PTP message and need timestamp */
        oal_util_ptp_header_t *ptph;
        uint16 refnum;

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (EOK == oal_util_parse_ptp((uint8 *)((addr_t)frame->data_va + TX_BUF_FRAME_OFFSET + pfe_hif_chnl_get_lmem_hdr_size(hif_drv->channel)), frame->len, &ptph))
#else
        if (EOK == oal_util_parse_ptp((uint8 *)((addr_t)frame->data_va + TX_BUF_FRAME_OFFSET), frame->len, &ptph))
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            /* Only Event messages will be pushed into database */
            if((ptph->byte1.messageType == PTP_MSG_SYNC) || (ptph->byte1.messageType == PTP_MSG_DELAY_REQ) ||
                (ptph->byte1.messageType == PTP_MSG_PDELAY_REQ) || (ptph->byte1.messageType == PTP_MSG_PDELAY_RESP))
            {
                /* Request TS */
                /* Sequence numbers are allowed to use only lower 12 bits */
                refnum = (uint16)(oal_util_get_unique_seqnum32() & 0x0fffU); /* Don't switch endian */
                tx_hdr->refnum = oal_htons(refnum);
                tx_hdr->flags |= HIF_TX_ETS;
                tx_metadata->ets_flag |= HIF_TX_ETS;

                /* Store the values for MCAL Tx confirmation */
                tx_ts_ref_mcal = Eth_PFE_LLD_GetTxBufTsRef(ref_ptr_mcal->u8CtrlIdx, ref_ptr_mcal->u16BufIdx);
                tx_ts_ref_mcal->u8MessageType = ptph->byte1.messageType;
                tx_ts_ref_mcal->u16SourcePortID = oal_ntohs(ptph->sourcePortID);
                tx_ts_ref_mcal->u16SequenceID = oal_ntohs(ptph->sequenceID);

                /* Store the TX frame to DB */
                err = pfe_hif_ptp_ts_db_push_msg(&client->ptpdb, FALSE, refnum, ptph->byte1.messageType,
                        oal_ntohs(ptph->sourcePortID), oal_ntohs(ptph->sequenceID));
                if (EOK != err)
                {
                    NXP_LOG_ERROR("Could not store PTP message: %d\n", err);
                    tx_hdr->flags &= ~HIF_TX_ETS;
                    tx_metadata->ets_flag &= ~HIF_TX_ETS;
                }
                else
                {
#ifdef PFE_CFG_DEBUG
                NXP_LOG_DEBUG("New (TX) PTP frame: Type: 0x%x, Port: 0x%x, SeqID: 0x%x\n",
                    ptph->byte1.messageType, oal_ntohs(ptph->sourcePortID), oal_ntohs(ptph->sequenceID));
#endif /* PFE_CFG_DEBUG */
                }
            }
        }
    }
}
#endif /* PFE_CFG_IEEE1588_SUPPORT */


/**
 * @brief       Transmit packet given as a SG list of buffers
 * @param[in]   client Client instance
 * @param[in]   queue TX queue number
 * @param[in]   frame pointer to frame
 * @param[in]   ref_ptr Reference pointer to be provided within TX confirmation.
 * @return      EOK if success, error code otherwise.
 */
errno_t pfe_hif_drv_client_xmit_pkt(pfe_hif_drv_client_t *client, uint8 queue, const hif_frame_t *const frame, void *ref_ptr)
{
    errno_t err = EOK;
    pfe_hif_tx_meta_t *tx_metadata;
    pfe_hif_drv_t *hif_drv;
    pfe_ct_hif_tx_hdr_t *tx_hdr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == client) || (NULL == frame) || (NULL == ref_ptr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        err = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Get HIF driver instance from client */
        hif_drv = client->hif_drv;

        /* Enter critical section */
        oal_mutex_lock(PFE_HIF_DRV_MUTEX_01);

        if (unlikely(FALSE == hif_drv->tx_enabled))
        {
            /* Transmission is not allowed */
            err = EPERM;
        }

        /*
            Check if we have enough TX resources. We need one for each SG entry plus
            one for HIF header.
        */
        else if (unlikely(FALSE == pfe_hif_chnl_can_accept_tx(hif_drv->channel)))
        {
            /* Channel can't accept buffers (TX ring full?). */
            err = ENOSPC;
        }
        else
        {
            /*
                HIF driver must keep local copy of the HW TX ring to gain access
                to virtual buffer addresses in case when data is being
                acknowledged to a client. For this purpose the SW descriptors
                are being used.
            */

            /* Get metadata storage */
            tx_metadata = &hif_drv->tx_meta[hif_drv->tx_meta_wr_idx];
            tx_metadata->client = client;
            tx_metadata->q_no = queue;
    
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            if (pfe_hif_chnl_get_id(hif_drv->channel) >= PFE_HIF_CHNL_NOCPY_ID)
            {
                tx_hdr = (pfe_ct_hif_tx_hdr_t *)((addr_t)frame->data_va + pfe_hif_chnl_get_lmem_hdr_size(hif_drv->channel) + 256U);
            }
            else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
            {
                tx_hdr = (pfe_ct_hif_tx_hdr_t *)((addr_t)frame->data_va);
                /* Ensure that the HIF_TX_ETS flag is cleared before transmitting any frame.
                    In case of using HIF_NOCPY, it was done in Eth_PFE_LLD_ProvideBufferDataArea */
                tx_hdr->flags &= ~HIF_TX_ETS;
            }

#ifdef PFE_CFG_IEEE1588_SUPPORT
            pfe_hif_drv_cfg_IEEE1588(client, tx_hdr, tx_metadata, frame, ref_ptr);
#endif /* PFE_CFG_IEEE1588_SUPPORT */

            tx_metadata->ref_ptr = ref_ptr;

            /*  Transmit the packet buffer */
            err = pfe_hif_chnl_tx(client->hif_drv->channel, frame->data_va,frame->len);
            if(unlikely(EOK != err))
            {
                err = ECANCELED;
            }
            else  /*all ok*/
            {
                /* Move to next entry */
                hif_drv->tx_meta_wr_idx++;
                if (hif_drv->tx_meta_wr_idx >= PFE_CFG_HIF_RING_LENGTH)
                {
                    hif_drv->tx_meta_wr_idx = 0U;
                }
            }
        }
        /* Leave the critical section */
        oal_mutex_unlock(PFE_HIF_DRV_MUTEX_01);
    }
    return err;
}

/**
 * @brief       Get PTP timestamp
 * @details     Function will return timestamp for PTP message given by set arguments
 *              if such timestamp has been captured
 * @param[in]   client The client instance
 * @param[in]   rx TRUE means to get ingress TS, FALSE means egress
 * @param[in]   type PTP message type
 * @param[in]   port PTP source port ID
 * @param[in]   seq_id PTP sequence ID
 * @param[out]  ts_sec Seconds part of the timestamp
 * @param[out]  ts_nsec Nanoseconds part of the timestamp
 * @retval      EOK Timestamp has been found and is valid
 * @retval      ENOENT Timestamp matching given criteria not found
 */
errno_t pfe_hif_drv_client_get_ts(pfe_hif_drv_client_t * const client, bool_t rx,
        uint8 type, uint16 port, uint16 seq_id, uint32 * const ts_sec, uint32 * const ts_nsec)
{
#ifdef PFE_CFG_IEEE1588_SUPPORT
    return pfe_hif_ptp_ts_db_pop(&client->ptpdb, type, port, seq_id, ts_sec, ts_nsec, rx);
#else
    NXP_LOG_ERROR("PTP support not enabled\n");
    (void)client;
    (void)rx;
    (void)type;
    (void)port;
    (void)seq_id;
    (void)ts_sec;
    (void)ts_nsec;
    return EINVAL;
#endif /* */
}

/**
 * @brief       Create new HIF driver instance
 * @param[in]   channel The HIF channel instance to be managed
 */
pfe_hif_drv_t *pfe_hif_drv_create(pfe_hif_chnl_t *channel)
{
    pfe_hif_drv_t *hif_drv;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == channel))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        hif_drv = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */

    /* Check if is OK to use metadata storage associated with buffers from pool */
    if (pfe_hif_chnl_get_meta_size(channel) < sizeof(pfe_hif_pkt_t))
    {
        NXP_LOG_ERROR("Meta storage size (%u) is less than required (%u)\n", (uint_t)(pfe_hif_chnl_get_meta_size(channel)), (uint_t)sizeof(pfe_hif_pkt_t));
        hif_drv = NULL_PTR;
    }
    else
    {
        hif_drv = &common_hif_drv;
        (void)autolibc_memset(hif_drv, 0, sizeof(pfe_hif_drv_t));
        hif_drv->channel = channel;
    }

    return hif_drv;
}

/* Helper function for pfe_hif_drv_init, destroys data channel if error occurs */
static void pfe_hif_drv_init_err_handler(pfe_hif_drv_t *hif_drv, uint_t err_level)
{
    if (err_level == 9)
    {
        if (EOK != pfe_hif_chnl_set_event_cbk(hif_drv->channel, HIF_CHNL_EVT_TX_IRQ, NULL, NULL))
        {
            NXP_LOG_ERROR("pfe_hif_chnl_set_event_cbk() failed (TX callback)\n");
        }
    }
    if (err_level >= 6)
    {
        if (EOK != pfe_hif_chnl_set_event_cbk(hif_drv->channel, HIF_CHNL_EVT_RX_IRQ, NULL, NULL))
        {
            NXP_LOG_ERROR("pfe_hif_chnl_set_event_cbk() failed (RX callback)\n");
        }
    }
    pfe_hif_drv_destroy_data_channel(hif_drv);
}

/* Attach channels in drv init */
static errno_t pfe_hif_drv_attach_channels(pfe_hif_drv_t *hif_drv)
{
    errno_t ret = EOK;

#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
    ret = pfe_hif_chnl_set_event_cbk(hif_drv->channel, HIF_CHNL_EVT_RX_IRQ, &pfe_hif_drv_rx_job, (void *)hif_drv);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

    if (EOK != ret)
    {
        NXP_LOG_ERROR("Could not register RX ISR\n");
        pfe_hif_drv_init_err_handler(hif_drv, 3U);
    }
    else
    {
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
        /* Attach channel TX ISR */
        ret = pfe_hif_chnl_set_event_cbk(hif_drv->channel, HIF_CHNL_EVT_TX_IRQ, &pfe_hif_drv_chnl_tx_isr, (void *)hif_drv);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Could not register TX ISR\n");
            pfe_hif_drv_init_err_handler(hif_drv, 6U);
        }
#endif /* PFE_CFG_HIF_IRQ_ENABLED */
    }

    return ret;
}

/**
 * @brief   HIF initialization routine
 * @details Function performs following initialization:
 *          - Initializes HIF interrupt handler(s)
 *          - Performs HIF HW initialization and enables RX/TX DMA
 */
errno_t pfe_hif_drv_init(pfe_hif_drv_t *hif_drv)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    if (hif_drv->initialized)
    {
        NXP_LOG_ERROR("HIF already initialized. Exiting.\n");
        ret = ECANCELED;    
    }
    else
    {
        /* Initialize RX/TX resources */
        hif_drv->started = FALSE;

        if (pfe_hif_drv_create_data_channel(hif_drv) != 0)
        {
            NXP_LOG_ERROR("%s: Could not initialize data channel\n", __func__);
            ret = ENOMEM;
        }
        else
        {
            ret = pfe_hif_drv_attach_channels(hif_drv);

            if (EOK == ret)
            {
                /* Create TX job */
                if (NULL == oal_job_create(&pfe_hif_drv_tx_job, (void *)hif_drv, "HIF TX JOB", OAL_PRIO_NORMAL, &hif_drv->tx_job))
                {
                    ret = EFAULT;
                    pfe_hif_drv_init_err_handler(hif_drv, 9U);
                }
                else
                {
                    hif_drv->rx_enabled = FALSE;
                    hif_drv->tx_enabled = FALSE;
                    hif_drv->initialized = TRUE;
                    ret = EOK;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Start traffic at HIF level
 * @details     Data transmission/reception is enabled
 * @param[in]   hif_drv The driver instance
 */
errno_t pfe_hif_drv_start(pfe_hif_drv_t *hif_drv)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (FALSE == hif_drv->initialized)
        {
            NXP_LOG_ERROR("HIF driver not initialized\n");
            ret = ENODEV;
        }
        else
        {
            NXP_LOG_INFO("Enabling HIF channel RX/TX\n");

            /* Enable RX */
            if (EOK != pfe_hif_chnl_rx_enable(hif_drv->channel))
            {
                NXP_LOG_ERROR("Couldn't enable RX\n");
            }
            else
            {
                hif_drv->rx_enabled = TRUE;
            }

            /* Enable TX */
            if (EOK != pfe_hif_chnl_tx_enable(hif_drv->channel))
            {
                NXP_LOG_ERROR("Couldn't enable TX\n");
            }
            else
            {
                hif_drv->tx_enabled = TRUE;
            }

            /* Enable the channel interrupts */
            NXP_LOG_INFO("Enabling channel interrupts\n");

            pfe_hif_chnl_rx_irq_unmask(hif_drv->channel);

            pfe_hif_chnl_tx_irq_unmask(hif_drv->channel);

            NXP_LOG_INFO("HIF driver is started\n");

            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Stop tx traffic at HIF level
 * @details     No resource releasing is done here. This call
 *              only ensures that tx traffic is suppressed at
 *              the HIF channel level so HIF driver is not receiving
 *              any notifications about data transfers and
 *              is not accessing any TX resources.
 * @param[in]   hif_drv The driver instance
 */
static void pfe_hif_drv_stop_tx(pfe_hif_drv_t *hif_drv)
{
    uint32 hif_stop_timeout;

    /* Stop TX */
    if (TRUE == hif_drv->tx_enabled)
    {
        NXP_LOG_DEBUG("Disabling channel TX path\n");
        pfe_hif_chnl_tx_disable(hif_drv->channel);

        hif_stop_timeout = 10;
        do
        {
            if (pfe_hif_chnl_is_tx_dma_active(hif_drv->channel))
            {
                oal_time_usleep(250);
            }
            else
            {
                break;
            }
        } while (0U != hif_stop_timeout--);

        if (pfe_hif_chnl_is_tx_dma_active(hif_drv->channel))
        {
            NXP_LOG_WARNING("Unable to stop the HIF TX DMA\n");
        }

        /* Disallow transmission (and TX confirmation) and ensure the change has been applied */
        hif_drv->tx_enabled = FALSE;

        /*
         *  ---------------------------------------------------------------------
         *    Here the TX resource is disabled. No more TX confirmations can be
         *    generated.
         *    Run the TX confirmation job to process all pending TX confirmations.
         *    ---------------------------------------------------------------------
         */

        if (EOK != oal_job_run(&hif_drv->tx_job))
        {
            NXP_LOG_ERROR("TX job trigger failed\n");
        }

        if (EOK != oal_job_drain(&hif_drv->tx_job))
        {
            NXP_LOG_ERROR("Unable to finish TX job\n");
        }

        NXP_LOG_INFO("Disabling channel TX IRQ\n");
        pfe_hif_chnl_tx_irq_mask(hif_drv->channel);

        /*
         *  -------------------------------------------------------------------------
         *  Here is ensured that:
         *      - TX nor TX confirmation tasks will be executed
         *      - TX routine is sealed by the 'tx_enabled' flag so won't be called
         *      - All TX confirmations are processed and new ones can't be generated
         *  -------------------------------------------------------------------------
         */

        /* Just a sanity check */
        if (hif_drv->tx_meta_rd_idx != hif_drv->tx_meta_wr_idx)
        {
            NXP_LOG_WARNING("TX confirmation FIFO still contains entries\n");
        }

        NXP_LOG_INFO("HIF driver TX path is stopped\n");
    }
}

/**
 * @brief       Stop rx traffic at HIF level
 * @details     No resource releasing is done here. This call
 *              only ensures that rx traffic is suppressed at
 *              the HIF channel level so HIF driver is not receiving
 *              any notifications about data transfers and
 *              is not accessing any RX resources.
 * @param[in]   hif_drv The driver instance
 */
static void pfe_hif_drv_stop_rx(pfe_hif_drv_t *hif_drv)
{
    uint32 hif_stop_timeout;

    if (TRUE == hif_drv->rx_enabled)
    {
        NXP_LOG_DEBUG("Disabling channel RX path\n");
        pfe_hif_chnl_rx_disable(hif_drv->channel);

        hif_stop_timeout = 10;
        do
        {
            if (pfe_hif_chnl_is_rx_dma_active(hif_drv->channel))
            {
                oal_time_usleep(250);
            }
            else
            {
                break;
            }
        } while (0U != hif_stop_timeout--);

        if (pfe_hif_chnl_is_rx_dma_active(hif_drv->channel))
        {
            NXP_LOG_WARNING("Unable to stop the HIF RX DMA\n");
        }

        /*
         *  -------------------------------------------------------------------
         *  Here the RX resource is disabled. No more packets can be received.
         *  Run the RX job to process all pending received packets.
         *  -------------------------------------------------------------------
         */

        /* Disallow reception and ensure the change has been applied */
        hif_drv->rx_enabled = FALSE;

        NXP_LOG_DEBUG("Disabling channel RX IRQ\n");
        pfe_hif_chnl_rx_irq_mask(hif_drv->channel);

        /*
         *  -----------------------------------------------------------------------
         *  Here is ensured that RX tasks will NOT be executed:
         *      - RX routine is sealed by the 'rx_enabled' flag so won't be called
         *      - All pending ingress packets are processed
         *      - RX interrupt is disabled
         *  -----------------------------------------------------------------------
         */

        NXP_LOG_INFO("HIF driver RX path is stopped\n");
    }
}

/**
 * @brief       Stop traffic at HIF level
 * @details     No resource releasing is done here. This call
 *              only ensures that all traffic is suppressed at
 *              the HIF channel level so HIF driver is not receiving
 *              any notifications about data transfers (RX/TX) and
 *              is not accessing any RX/TX resources.
 * @param[in]   hif_drv The driver instance
 */
void pfe_hif_drv_stop(pfe_hif_drv_t *hif_drv)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Stop RX */
        pfe_hif_drv_stop_rx(hif_drv);
        /* Stop TX */
        pfe_hif_drv_stop_tx(hif_drv);

        /*
         *  -----------------------------------------------------
         *  Now the RX and TX resource of HIF channel are frozen
         *  -----------------------------------------------------
         */
    }
}

/**
 * @brief       Exit the HIF driver
 * @details     Terminate the HIF driver and release all allocated
 *              resources.
 * @param[in]   hif_drv The driver instance
 */
void pfe_hif_drv_exit(pfe_hif_drv_t *hif_drv)
{
    uint32 ii;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */

    {
        if (FALSE == hif_drv->initialized)
        {
            NXP_LOG_WARNING("HIF is already disabled\n");
        }
        else
        {

            /* Check if a client is still registered */
            for (ii=0; ii<HIF_CLIENTS_MAX; ii++)
            {
                if (FALSE != hif_drv->clients[ii].active)
                {
                    NXP_LOG_ERROR("A client is still registered within HIF\n");
                }
            }

            NXP_LOG_INFO("HIF exiting\n");

            /* Stop the traffic */
            pfe_hif_drv_stop(hif_drv);

            /* Release HIF channel and buffers */
            pfe_hif_drv_destroy_data_channel(hif_drv);

            /* Uninstall channel event handlers */
            (void)pfe_hif_chnl_set_event_cbk(hif_drv->channel, HIF_CHNL_EVT_RX_IRQ, NULL, NULL);
            (void)pfe_hif_chnl_set_event_cbk(hif_drv->channel, HIF_CHNL_EVT_TX_IRQ, NULL, NULL);

            hif_drv->initialized = FALSE;

            NXP_LOG_INFO("HIF exited\n");
        }
    }
}

/* Destroy HIF channel */
void pfe_hif_drv_destroy(pfe_hif_drv_t *hif_drv)
{
    if (NULL_PTR != hif_drv)
    {
        pfe_hif_drv_exit(hif_drv);
        hif_drv->channel = NULL_PTR;
    }
}

/**
 * @brief       Get HIF channel instance associated with the HIF driver instance
 * @param[in]   hif_drv hif_drv instance
 * @return      Pointer to the HIF CHANNEL associated with HIF channel instance or NULL if failed
 */
pfe_hif_chnl_t *pfe_hif_drv_get_chnl(const pfe_hif_drv_t *hif_drv)
{
    pfe_hif_chnl_t *entry = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        entry = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry = hif_drv->channel;
    }
    return entry;
}

#define STR_TAB "  "

static void pfe_hif_drv_show_rx_ring_status(pfe_hif_drv_client_t *cl)
{
    uint32 ii, qid;
    struct client_rx_queue *rx_q;
    pfe_hif_pkt_t *pkt;

    for (qid=0U; qid<cl->rx_qn; qid++)
    {
        rx_q = &cl->rx_q[qid];
        NXP_LOG_INFO(STR_TAB "RX queue %u: size %u\n", (uint_t)qid, (uint_t)rx_q->size);
        if (likely(NULL == rx_q->rx_fifo))
        {
            NXP_LOG_INFO(STR_TAB STR_TAB "[empty ring]\n");
            continue;
        }

        for (ii=0U; ii<rx_q->size; ii++)
        {
            pkt = (pfe_hif_pkt_t *)fifo_peek(rx_q->rx_fifo, ii);
            if (unlikely(NULL == pkt))
            {
                NXP_LOG_INFO(STR_TAB STR_TAB "%-4u [free]\n", (uint_t)ii);
            }
            else
            {
                NXP_LOG_INFO(STR_TAB STR_TAB "%4u %d:%d:%02x:0x%03x:%*phD\n",
                        (uint_t)ii, pkt->client->phy_if_id, pkt->q_no,
                            pkt->flags.specific.rx_flags, pkt->len, 16, (void *)pkt->data);
            }
        } /* for ii */
    } /* for qid */
}

static void pfe_hif_drv_show_tx_ring_status(pfe_hif_drv_client_t *cl)
{
    uint32 ii, qid;
    struct client_tx_queue *tx_q;
    pfe_hif_pkt_t *pkt;

    for (qid=0U; qid<cl->tx_qn; qid++)
    {
        tx_q = &cl->tx_q[qid];
        NXP_LOG_INFO(STR_TAB "TX queue %u: size %u\n", (uint_t)qid, (uint_t)tx_q->size);
        if (likely(NULL == tx_q->tx_conf_fifo))
        {
            NXP_LOG_INFO(STR_TAB STR_TAB "[empty ring]\n");
            continue;
        }

        for (ii=0U; ii<tx_q->size; ii++)
        {
            pkt = (pfe_hif_pkt_t *)fifo_peek(tx_q->tx_conf_fifo, ii);
            if (unlikely(NULL == pkt))
            {
                NXP_LOG_INFO(STR_TAB STR_TAB "%-4u [free]\n", (uint_t)ii);
            }
            else
            {
                NXP_LOG_INFO(STR_TAB STR_TAB "%4u %d:%d:%02x:0x%03x:%*phD\n",
                        (uint_t)ii, pkt->client->phy_if_id, pkt->q_no,
                        pkt->flags.specific.tx_flags, pkt->len, 16, (void *)pkt->data);
            }
        } /* for ii */
    } /* for qid */
}

/**
 * @brief       Print ring status in text form
 * @param[in]   client The client instance
 * @param[in]   rx True if rx ring is needed
 * @param[in]   tx True if tx ring is needed
 */
void pfe_hif_drv_show_ring_status(pfe_hif_drv_t *hif_drv, bool_t rx, bool_t tx)
{
    pfe_hif_drv_client_t *cl;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        cl = &hif_drv->clients[0]; /* TODO: loop over all */

        NXP_LOG_INFO("client %d\n", cl->phy_if_id);
        NXP_LOG_INFO(STR_TAB "status: %sinitialized\n", (NULL != cl) ? "" : "NOT");
        NXP_LOG_INFO(STR_TAB "queue level: rx %u, tx %u\n", (uint_t)cl->rx_qn, (uint_t)cl->tx_qn);

        /* RX */
        if ((FALSE != cl->active) && (TRUE == rx))
        {
            pfe_hif_drv_show_rx_ring_status(cl);
        }

        /* TX */
        if((FALSE != cl->active) && (TRUE == tx))
        {
            pfe_hif_drv_show_tx_ring_status(cl);
        }
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /*PFE_CFG_MC_HIF*/

/** @}*/


===== 文件 [156/185]: src\pfe_hif_nocpy.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_cbus.h"
#include "pfe_hif_nocpy.h"
#include "pfe_platform_cfg.h"
#include "pfe_hif_chnl.h"
#include "pfe_hif_nocpy_csr.h"

struct pfe_hif_nocpy_tag
{
    addr_t base_va;                     /*  CBUS base virtual address */
    pfe_hif_chnl_t *channel;            /*  Associated channel instance */
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
static pfe_hif_chnl_t hif_chnl_memory;
#endif
static pfe_hif_nocpy_t hif_nocpy_instance;

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
static void pfe_hif_nocpy_free(pfe_hif_nocpy_t *hif);
static errno_t pfe_hif_nocpy_create_chnl(pfe_hif_nocpy_t *hif, const pfe_bmu_t *bmu, uint16 lmem_header_size);

/**
 * @brief       Free HIF_NOCPY instance
 * @param[in]   hif hif instance
 */
static void pfe_hif_nocpy_free(pfe_hif_nocpy_t *hif)
{
    if (NULL != hif->channel)
    {
        pfe_hif_chnl_destroy(hif->channel);
        hif->channel = NULL;
    }

    pfe_hif_nocpy_cfg_stop_all_chnl_dma();
    pfe_hif_nocpy_cfg_fini(hif->base_va);
}

/**
 * @brief       Create new HIF_NOCPY channel
 * @param[in]   hif HIF_NOCPY instance
 * @param[in]   bmu BMU providing buffers for HIF NOCPY operation
 * @return      The HIF_NOCPY instance or NULL if failed
 */
static errno_t pfe_hif_nocpy_create_chnl(pfe_hif_nocpy_t *hif, const pfe_bmu_t *bmu, uint16 lmem_header_size)
{
    errno_t ret;

    ret = pfe_hif_chnl_create_mcal(&hif_chnl_memory, hif->base_va, PFE_HIF_CHNL_NOCPY_ID, bmu);
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Can't create HIF_NOCPY channel instance\n");
        pfe_hif_nocpy_free(hif);
    }
    else
    {
        hif->channel = &hif_chnl_memory;
        pfe_hif_chnl_set_lmem_hdr_size(hif->channel, lmem_header_size);
        /*  Initialize the channel */
        ret = pfe_hif_chnl_init(hif->channel);
        if(EOK != ret)
        {
            pfe_hif_nocpy_free(hif);
        }
        else
        {
            /* Disable both directions */
            pfe_hif_chnl_rx_disable(hif->channel);
            pfe_hif_chnl_tx_disable(hif->channel);
        }
    }

    return ret;
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       Create new HIF_NOCPY instance
 * @details     Creates and initializes HIF_NOCPY instance
 * @param[in]   base_va HIF_NOCPY base virtual address
 * @param[in]   bmu BMU providing buffers for HIF NOCPY operation
 * @param[in]   lmem_header_size
 * @return      The HIF_NOCPY instance or NULL if failed
 */
pfe_hif_nocpy_t *pfe_hif_nocpy_create(addr_t base_va, const pfe_bmu_t *bmu, uint16 lmem_header_size)
{
    pfe_hif_nocpy_t *hif;
    errno_t          ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_ADDR == base_va) || (NULL == bmu)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        hif = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        hif = &hif_nocpy_instance;
        (void)autolibc_memset(hif, 0, sizeof(pfe_hif_nocpy_t));
        hif->base_va = base_va;
        hif->channel = NULL_PTR;

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)  /* Enable only if HIF_NOCPY is used */
        ret = pfe_hif_nocpy_cfg_init(hif->base_va);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("HIF_NOCPY configuration failed: %d\n", ret);
            pfe_hif_nocpy_free(hif);
            hif = NULL;
        }
        else
        {
            ret = pfe_hif_nocpy_create_chnl(hif, bmu, lmem_header_size);
            if (EOK != ret)
            {
                hif = NULL;
            }
        }
#else
        (void) bmu;
        (void) lmem_header_size;
        (void) ret;
#endif
    }

    return hif;
}

/**
 * @brief       Get channel instance according to its ID
 * @param[in]   hif The HIF instance
 * @param[in]   channel_id The channel ID. Currently only PFE_HIF_CHNL_NOCPY_ID is supported.
 * @return      The HIF channel instance or NULL if failed
 */
pfe_hif_chnl_t *pfe_hif_nocpy_get_channel(const pfe_hif_nocpy_t *hif, uint32 channel_id)
{
    pfe_hif_chnl_t *hif_nocpy_chnl;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        hif_nocpy_chnl = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (channel_id != PFE_HIF_CHNL_NOCPY_ID)
        {
            hif_nocpy_chnl = NULL;
        }
        else
        {
            hif_nocpy_chnl = hif->channel;
        }
    }
    return hif_nocpy_chnl;
}

/**
 * @brief       Destroy HIF_NOCPY instance
 * @param[in]   hif The HIF_NOCPY instance
 */
void pfe_hif_nocpy_destroy(pfe_hif_nocpy_t *hif)
{
    if (NULL != hif)
    {
        if (NULL != hif->channel)
        {
            pfe_hif_chnl_rx_disable(hif->channel);
            pfe_hif_chnl_tx_disable(hif->channel);
            pfe_hif_chnl_destroy(hif->channel);
            hif->channel = NULL;
        }

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT) /* Enabled only if the local HIF is HIF_NOCPY */
        pfe_hif_nocpy_cfg_fini(hif->base_va);
        pfe_hif_nocpy_clear_emac_timer_ownership(hif);
#endif
    }
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return HIF_NOCPY runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   hif         The HIF_NOCPY instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len         Buffer length
 * @param[in]   verb_level  Verbosity level, number of data written to the buffer
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_hif_nocpy_get_text_statistics(const pfe_hif_nocpy_t *hif, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += pfe_hif_nocpy_cfg_get_text_stat(hif->base_va, buf, buf_len, verb_level);
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Marks that a PFE instance associated with the HIF_NOCPY is owner of all EMAC timers
 * @param[in]   hif The HIF_NOCPY instance
 */
void pfe_hif_nocpy_init_emac_timer_ownership(const pfe_hif_nocpy_t *hif)
{
    pfe_ct_phy_if_id_t emac_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (emac_id = PFE_PHY_IF_ID_EMAC0; emac_id <= PFE_PHY_IF_ID_EMAC2; emac_id++)
        {
            (void)pfe_hif_nocpy_cfg_set_emac_timer_ownership(emac_id, TRUE);
        }
        (void)hif;
    }
}
/**
 * @brief       Clear timer ownership status for the PFE instance associated with the HIF_NOCPY
 * @param[in]   hif The HIF_NOCPY instance
 */
void pfe_hif_nocpy_clear_emac_timer_ownership(const pfe_hif_nocpy_t *hif)
{
    pfe_ct_phy_if_id_t emac_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == hif))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (emac_id = PFE_PHY_IF_ID_EMAC0; emac_id <= PFE_PHY_IF_ID_EMAC2; emac_id++)
        {
            (void)pfe_hif_nocpy_cfg_set_emac_timer_ownership(emac_id, FALSE);
        }
        (void)hif;
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [157/185]: src\pfe_hif_nocpy_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2023 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_cbus.h"
#include "pfe_platform_cfg.h"
#include "pfe_hif_csr.h"
#include "pfe_hif_nocpy_csr.h"
#include "pfe_bmu_csr.h"
#include "pfe_tmu_csr.h"
#include "pfe_class_csr.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */


#define ETH_43_PFE_START_SEC_VAR_INIT_8
#include "Eth_43_PFE_MemMap.h"

/* usage scope: set/get timer ownership */
static uint8 hif_nocpy_timer_ownership = 0U;

#define ETH_43_PFE_STOP_SEC_VAR_INIT_8
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       HIF NOCPY ISR
 * @details     Handles all HIF NOCPY interrupts
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Make sure the call is protected by some per-HIF mutex
 */
errno_t pfe_hif_nocpy_cfg_isr(addr_t base_va, pfe_hif_chnl_event_t *events)
{
    uint32 reg_src, reg_en;
    errno_t ret = ENOENT;

    *events = (pfe_hif_chnl_event_t)0;

    /*  Get enabled interrupts */
    reg_en = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
    /*  Disable ALL */
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
    /*  Get triggered interrupts */
    reg_src = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_SRC));
    /*  ACK triggered */
    hal_write32(reg_src, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_SRC));
    /*  Enable the non-triggered ones */
    hal_write32((reg_en & ~reg_src), ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));

    /*  Process interrupts which are triggered AND enabled */
    if ((reg_src & reg_en & (BDP_CSR_RX_PKT_INT|BDP_CSR_RX_CBD_INT)) != 0U)
    {
        *events |= HIF_CHNL_EVT_RX_IRQ;
        ret = EOK;
    }

    /*  Process interrupts which are triggered AND enabled */
    if ((reg_src & reg_en & (BDP_CSR_TX_PKT_INT|BDP_CSR_TX_CBD_INT)) != 0U)
    {
        *events |= HIF_CHNL_EVT_TX_IRQ;
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Mask HIF NOCPY interrupts
 * @param[in]   base_va Base address of HIF NOCPY register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_nocpy_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    /*  Disable group */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN)) & ~(HIF_NOCPY_INT);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
}

/**
 * @brief       Unmask HIF NOCPY interrupts
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_nocpy_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    /*  Enable group */
    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN)) | HIF_NOCPY_INT;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
}

/**
 * @brief       Configure and initialize the HIF_NOCPY
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @return      EOK if success, error code otherwise
 * @note        Make sure the call is protected by some per-HIF mutex
 */
errno_t pfe_hif_nocpy_cfg_init(addr_t base_va)
{
    uint32 regval;

    /*  Disable channel interrupts */
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_SRC));

    pfe_hif_nocpy_cfg_rx_disable(base_va);
    pfe_hif_nocpy_cfg_tx_disable(base_va);

    hal_write32(PFE_PHY_IF_ID_HIF_NOCPY, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_PORT_NO));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU1_BASE_ADDR + BMU_ALLOC_CTRL, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_LMEM_ALLOC_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CLASS_INQ_PKTPTR, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_CLASS_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + TMU_PHY_INQ_PKTPTR, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TMU_PORT0_ADDR));
    hal_write32((HIF_RX_POLL_CTRL_CYCLE << 16U) | HIF_TX_POLL_CTRL_CYCLE, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_POLL_CTRL));

    hal_write32(HIF_CTRL_BDP_POLL_CTRL_EN, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_CTRL));
    hal_write32(HIF_CTRL_BDP_POLL_CTRL_EN, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_CTRL));

    regval = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_CSR_AXI_WAIT_DONE));
    regval |= 0x1U;
    hal_write32(regval, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_CSR_AXI_WAIT_DONE));

    hal_write32(0xffffffffU
                & ~HIF_NOCPY_INT
                & ~BDP_CSR_RX_CBD_INT
                & ~BDP_CSR_RX_PKT_INT
                & ~BDP_CSR_TX_CBD_INT
                & ~BDP_CSR_TX_PKT_INT
                , ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));

    return EOK;
}

/**
 * @brief       Finalize the HIF NOCPY
 * @param[in]   base_va Base address of HIF register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_nocpy_cfg_fini(addr_t base_va)
{
    /*  Disable HIF NOCPY interrupts */
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
}

/**
 * @brief       Enable TX
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_nocpy_cfg_tx_enable(addr_t base_va)
{
    uint32 regval;

    regval = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_CTRL));
    regval |= HIF_CTRL_DMA_EN;
    regval |= HIF_CTRL_BDP_POLL_CTRL_EN;
    hal_write32(regval, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_CTRL));

}

/**
 * @brief       Disable TX
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_nocpy_cfg_tx_disable(addr_t base_va)
{
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_CTRL));
    pfe_hif_nocpy_cfg_tx_irq_mask(base_va);
}

/**
 * @brief       Enable RX
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_nocpy_cfg_rx_enable(addr_t base_va)
{
    uint32 regval;

    regval = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_CTRL));
    regval |= HIF_CTRL_DMA_EN;
    regval |= HIF_CTRL_BDP_POLL_CTRL_EN;
    hal_write32(regval, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_CTRL));

}

/**
 * @brief       Disable RX
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 */
void pfe_hif_nocpy_cfg_rx_disable(addr_t base_va)
{
    hal_write32(0U, ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_CTRL));

    pfe_hif_nocpy_cfg_rx_irq_mask(base_va);
}

/**
 * @brief       Mask RX IRQ
 * @param[in]   base_va Base address of HIF NOCPY register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_nocpy_cfg_rx_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
    hal_write32(reg
                & ~BDP_CSR_RX_CBD_INT
                & ~BDP_CSR_RX_PKT_INT
                , ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
}

/**
 * @brief       Unmask RX IRQ
 * @param[in]   base_va Base address of HIF NOCPY register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_nocpy_cfg_rx_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
    hal_write32(reg
            | BDP_CSR_RX_CBD_INT
            | BDP_CSR_RX_PKT_INT
                , ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
}

/**
 * @brief       Mask TX IRQ
 * @param[in]   base_va Base address of HIF NOCPY register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_nocpy_cfg_tx_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
    hal_write32(reg
                & ~BDP_CSR_TX_CBD_INT
                & ~BDP_CSR_TX_PKT_INT
                , ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
}

/**
 * @brief       Unmask TX IRQ
 * @param[in]   base_va Base address of HIF NOCPY register space (virtual)
 * @note        Make sure the call is protected by some per-HIF mutex
 */
void pfe_hif_nocpy_cfg_tx_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
    hal_write32(reg
            | BDP_CSR_TX_CBD_INT
            | BDP_CSR_TX_PKT_INT
                , ADDR_BASE_OFFSET(base_va, HIF_NOCPY_INT_EN));
}

/**
 * @brief       Set RX buffer descriptor ring address
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   rx_ring_pa The RX ring address (physical, as seen by host)
 */
void pfe_hif_nocpy_cfg_set_rx_bd_ring_addr(addr_t base_va, const void *rx_ring_pa)
{
    hal_write32((uint32)PFE_CFG_MEMORY_PHYS_TO_PFE((addr_t)rx_ring_pa & 0xffffffffU), ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_BDP_ADDR));
}

/**
 * @brief       Get RX buffer descriptor ring address
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @return      RX buffer descriptor ring address
 */
uint32 pfe_hif_nocpy_cfg_get_rx_bd_ring_addr(addr_t base_va)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_BDP_ADDR));
}

/**
 * @brief       Set TX buffer descriptor ring address
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @param[in]   tx_ring_pa The TX ring address (physical, as seen by host)
 */
void pfe_hif_nocpy_cfg_set_tx_bd_ring_addr(addr_t base_va, const void *tx_ring_pa)
{
    hal_write32((uint32)PFE_CFG_MEMORY_PHYS_TO_PFE((addr_t)tx_ring_pa), ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_BDP_ADDR));
}

/**
 * @brief       Get TX buffer descriptor ring address
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @return      TX buffer descriptor ring address
 */
uint32 pfe_hif_nocpy_cfg_get_tx_bd_ring_addr(addr_t base_va)
{
    return hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_BDP_ADDR));
}

/**
 * @brief       Get RX ring state
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @return      TRUE when the RX ring BD processor is active or FALSE when it is idle
 */
bool_t pfe_hif_nocpy_cfg_is_rx_dma_active(addr_t base_va)
{
    uint32 reg;
    bool_t ret = FALSE;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_STATUS));

    if (0U != (reg & (0xfUL << 18U)))
    {
        ret = TRUE;
    }

    return ret;
}

/**
 * @brief       Get TX ring state
 * @param[in]   base_va Base address of HIF_NOCPY register space (virtual)
 * @param[in]   channel_id Channel identifier
 * @return      TRUE when the TX ring BD processor is active or FALSE when it is idle
 */
bool_t pfe_hif_nocpy_cfg_is_tx_dma_active(addr_t base_va)
{
    uint32 reg;
    bool_t ret = FALSE;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_STATUS));

    if (0U != (reg & (0xfUL << 18U)))
    {
        ret = TRUE;
    }

    return ret;
}

/**
 * @brief       Get HIF_NOCOPY channel statistics in text form
 * @param[in]   base_va     Base address of HIF register space (virtual)
 * @param[in]   buf         Pointer to buffer to be written
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level number of data written to the buffer (0:less 1:more)
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_hif_nocpy_chnl_cfg_get_text_stat(addr_t base_va, const char_t *buf, uint32 size, uint8 verb_level)
{
    (void)base_va;
    (void)buf;
    (void)size;
    (void)verb_level;
    return 0U;
}

/**
 * @brief       Get number of transmitted packets
 * @param[in]   base_va Base address of channel register space (virtual)
 * @return      Number of transmitted packets
 */
uint32 pfe_hif_nocpy_cfg_get_tx_cnt(addr_t base_va)
{
    (void)base_va;
    NXP_LOG_WARNING("HIF NOCPY does not provide TX packet counter\n");
    return 0xffffffffU;
}

/**
 * @brief       Get number of received packets
 * @param[in]   base_va Base address of channel register space (virtual)
 * @return      Number of received packets
 */
uint32 pfe_hif_nocpy_cfg_get_rx_cnt(addr_t base_va)
{
    (void)base_va;
    NXP_LOG_WARNING("HIF NOCPY does not provide RX packet counter\n");
    return 0xffffffffU;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Get HIF statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the HIF block.
 * @param[in]   base_va     Base address of HIF register space (virtual)
 * @param[in]   buf         Pointer to buffer to be written
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_hif_nocpy_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;
    uint32 reg;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get version */
        if(verb_level >= 9U)
        {
            reg = hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_VERSION));
            len += oal_util_snprintf(buf + len, size - len, "Revision             : 0x%x\n", (reg >> 24U) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "Version              : 0x%x\n", (reg >> 16U) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "ID                   : 0x%x\n", reg & 0xffffU);
        }

        len += oal_util_snprintf(buf + len, size - len, "TX Current BD Addr   : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_CURR_BD_ADDR)));
        len += oal_util_snprintf(buf + len, size - len, "TX Status            : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_STATUS)));
        len += oal_util_snprintf(buf + len, size - len, "TX DMA Status        : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_DMA_STATUS)));
        len += oal_util_snprintf(buf + len, size - len, "TX Ctrl              : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_TX_CTRL)));
        len += oal_util_snprintf(buf + len, size - len, "RX Current BD Addr   : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_CURR_BD_ADDR)));
        len += oal_util_snprintf(buf + len, size - len, "RX Status            : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_STATUS)));
        len += oal_util_snprintf(buf + len, size - len, "RX DMA Status        : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_DMA_STATUS)));
        len += oal_util_snprintf(buf + len, size - len, "RX Ctrl              : 0x%08x\n", hal_read32(ADDR_BASE_OFFSET(base_va, HIF_NOCPY_RX_CTRL)));
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Marks that a PFE instance associated with a HIF_NOCPY is owner of an EMAC timer
 * @param[in]   emac The EMAC id
 * @param[in]   value The value of EMAC timer ownership for the PFE instance associated to HIF_NOCPY. TRUE - owner, FALSE - not owner
 * @return      EOK if success, error code when invalid EMAC ID is requested
 */
errno_t pfe_hif_nocpy_cfg_set_emac_timer_ownership(pfe_ct_phy_if_id_t emac, bool_t value)
{
    errno_t ret = EINVAL;

    switch(emac) 
    {
        case PFE_PHY_IF_ID_EMAC0:
        case PFE_PHY_IF_ID_EMAC1:
        case PFE_PHY_IF_ID_EMAC2:
        {
            const uint8 emac_idx = (uint8)emac - (uint8)PFE_PHY_IF_ID_EMAC0;
            if(value) 
            {
                hif_nocpy_timer_ownership |= HIF_NOCPY_TIMER_OWNERSHIP_EMAC(emac_idx);
            }
            else 
            {
                hif_nocpy_timer_ownership &= (uint8)(~HIF_NOCPY_TIMER_OWNERSHIP_EMAC(emac_idx) & UINT8_MAX);
            }
            ret = EOK;
        }
        break;

        default:
            ret = EINVAL;
        break;
    }    

    return ret;
}

/**
 * @brief       Get EMAC timer ownership status for PFE instance associated to HIF_NOCPY
 * @param[in]   emac The EMAC id
 * @return      RUE if PFE instance associated with HIF_NOCPY is timer owner of specified EMAC, FALSE otherwise
 */
bool_t pfe_hif_nocpy_cfg_get_emac_timer_ownership(pfe_ct_phy_if_id_t emac)
{
    bool_t val = FALSE;

    switch(emac) 
    {
        case PFE_PHY_IF_ID_EMAC0:
        case PFE_PHY_IF_ID_EMAC1:
        case PFE_PHY_IF_ID_EMAC2:
        {
            const uint8 emac_idx = (uint8)emac - (uint8)PFE_PHY_IF_ID_EMAC0;
            val = ((hif_nocpy_timer_ownership & HIF_NOCPY_TIMER_OWNERSHIP_EMAC(emac_idx)) != 0U);
            break;
        }
        default:
            val = FALSE;
            break;
    }

    return val;
}

/**
 * @brief       Stops and disables all HIF_NOCPY chnl DMAs
 */
void pfe_hif_nocpy_cfg_stop_all_chnl_dma(void)
{
    hal_write32(0U, PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_NOCPY_BASE_ADDR + HIF_NOCPY_TX_CTRL);
    hal_write32(0U, PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_NOCPY_BASE_ADDR + HIF_NOCPY_RX_CTRL);
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [158/185]: src\pfe_hif_ptp.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "pfe_hif_ptp.h"

/*  Entry timeout in number of ticks */
#define PFE_HIF_PTP_DB_TIMEOUT              1

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
static bool_t check_entry_type_vals (const pfe_hif_ptp_ts_db_entry_t *entry, const uint8 type,
                                     const uint16 port, const uint16 seq_id,
                                     const bool_t rx);

/*==================================================================================================
*                                        LOCAL FUNCTIONS
==================================================================================================*/
static bool_t check_entry_type_vals (const pfe_hif_ptp_ts_db_entry_t *entry, const uint8 type,
                                     const uint16 port, const uint16 seq_id,
                                     const bool_t rx)
{
    return ((entry->rx == rx) && (entry->type == type) && (entry->port == port) && (entry->seq_id == seq_id)) ? TRUE: FALSE;
}


/*==================================================================================================
*                                        GLOBAL FUNCTIONS
==================================================================================================*/
/**
 * @brief       Periodically called db maintenance function
 * @details     In AUTOSAR MCAL driver this function is called from hif drv,
 *              in other drivers from an internal thread.
 */
void pfe_hif_ptp_ts_db_tick_iteration(void *arg)
{
    pfe_hif_ptp_ts_db_t *db = (pfe_hif_ptp_ts_db_t *)arg;
    pfe_hif_ptp_ts_db_entry_t *entry;
    uint32 index;

    /* Release aged entries */
    oal_mutex_lock(PFE_HIF_PTP_TS_DB_MUTEX_00);
    for(index = db->entries.occupied_items_count; index > 0U; index--)
    {
        entry = (pfe_hif_ptp_ts_db_entry_t *)isa_item(&db->entries, index - 1U);
        if (NULL_PTR != entry)
        {
            if (entry->ticks == 0U)
            {
                NXP_LOG_INFO("Removing aged TS DB entry (Type: 0x%x, Port: 0x%x, SeqID: 0x%x)\n",
                        entry->type, entry->port, entry->seq_id);
                (void)isa_release_subscript(&db->entries, index - 1U);
                PfeDevAssert(db->count > 0U);
                db->count--;
            }
            else
            {
                entry->ticks--;
            }
        }
    }
    oal_mutex_unlock(PFE_HIF_PTP_TS_DB_MUTEX_00);
}

/**
 * @brief   Initialize TS database
 */
errno_t pfe_hif_ptp_ts_db_init(pfe_hif_ptp_ts_db_t *db)
{
    (void)autolibc_memset(db, 0, sizeof(pfe_hif_ptp_ts_db_t));

    db->entries_isa_def.item_count = PFE_HIF_PTP_DB_MAX_CAPACITY;
    db->entries_isa_def.item_size = sizeof(pfe_hif_ptp_ts_db_entry_t);
    db->entries_isa_def.flags.ordered = ISA_FLAG_STRICT_ORDER;
    db->entries_isa_def.item_indexes = db->entries_pool_index;
    db->entries_isa_def.items = db->entries_pool;

    isa_init(&db->entries, &db->entries_isa_def);

    return EOK;
}

/**
 * @brief   Finalize the TS database
 */
void pfe_hif_ptp_ts_db_fini(pfe_hif_ptp_ts_db_t *db)
{
    /*  Release all entries */
    oal_mutex_lock(PFE_HIF_PTP_TS_DB_MUTEX_01);
    (void)autolibc_memset(&db->entries, 0, sizeof(db->entries));
    (void)autolibc_memset(&db->entries_isa_def, 0, sizeof(db->entries_isa_def));
    oal_mutex_unlock(PFE_HIF_PTP_TS_DB_MUTEX_01);
}

/**
 * @brief   Add PTP message to the DB. TS will be added later.
 */
errno_t pfe_hif_ptp_ts_db_push_msg(pfe_hif_ptp_ts_db_t *db, bool_t rx,
        uint16 refnum, uint8 type, uint16 port, uint16 seq_id)
{
    errno_t ret;
    pfe_hif_ptp_ts_db_entry_t *entry;

    /* We should somehow limit number of entries.. */
    if (db->count >= PFE_HIF_PTP_DB_MAX_CAPACITY)
    {
        ret = ENOSPC;
    }
    else
    {
        /*  Link-in */
        oal_mutex_lock(PFE_HIF_PTP_TS_DB_MUTEX_02);

        entry = (pfe_hif_ptp_ts_db_entry_t*)isa_reserve(&db->entries);
        if (NULL_PTR == entry)
        {
            ret = ENOMEM;
        }
        else
        {
            /* Fill entry */
            entry->refnum = refnum;
            entry->type = type;
            entry->port = port;
            entry->seq_id = seq_id;
            entry->ts_valid = FALSE;
            entry->ticks = PFE_HIF_PTP_DB_TIMEOUT;
            entry->rx = rx;

            db->count++;

            if ((db->count > PFE_HIF_PTP_DB_WARNING_THRESHOLD) && !db->reported)
            {
                NXP_LOG_WARNING("More than %d entries in PTP DB...\n", PFE_HIF_PTP_DB_WARNING_THRESHOLD);
                db->reported = TRUE;
            }
            ret = EOK;
        }
        oal_mutex_unlock(PFE_HIF_PTP_TS_DB_MUTEX_02);
    }

    return ret;
}

/**
 * @brief       Bind TS with existing entry
 * @param[in]   db Pointer to timestamp database to store timestamp values in
 * @param[in]   rx Specifies direction of message the timestamp belongs to. Rx: rx=TRUE, Tx: rx=FALSE
 * @param[in]   refnum Reference number of the timestamp for matching with message
 * @param[in]   ts_sec Timestamp value to put in database, seconds
 * @param[in]   ts_nsec Timestamp value to put in database, nanoseconds
 * @retval      EOK Timestamp was stored
 * @retval      ENOENT No matching message was found, timestamp was not stored
 */
errno_t pfe_hif_ptp_ts_db_push_ts(pfe_hif_ptp_ts_db_t *db, bool_t rx,
        uint16 refnum, uint32 ts_sec, uint32 ts_nsec)
{
    pfe_hif_ptp_ts_db_entry_t *entry;
    bool_t found = FALSE;
    uint32 index;

    /* Find matching entry and add the timestamp */
    oal_mutex_lock(PFE_HIF_PTP_TS_DB_MUTEX_03);

    for(index = 0U; index < db->entries.occupied_items_count; index++)
    {
        entry = (pfe_hif_ptp_ts_db_entry_t *)isa_item(&db->entries, index);
        if (NULL_PTR != entry)
        {
            if ((entry->refnum == refnum) && (entry->rx == rx))
            {
                found = TRUE;
                entry->ts_sec = ts_sec;
                entry->ts_nsec = ts_nsec;
                entry->ts_valid = TRUE;
                break;
            }
        }
    }

    oal_mutex_unlock(PFE_HIF_PTP_TS_DB_MUTEX_03);

    return (found) ? EOK : ENOENT;
}

/**
 * @brief   Get TS associated with give PTP message
 */
errno_t pfe_hif_ptp_ts_db_pop(pfe_hif_ptp_ts_db_t *db,
        uint8 type, uint16 port, uint16 seq_id,
            uint32 *ts_sec, uint32 *ts_nsec, bool_t rx)
{
    errno_t ret_val = ENOENT;
    pfe_hif_ptp_ts_db_entry_t *entry;
    uint32 index;

    /* Find matching entry and get the timestamp */
    oal_mutex_lock(PFE_HIF_PTP_TS_DB_MUTEX_04);

    for(index = 0U; index < db->entries.occupied_items_count; index++)
    {
        entry = (pfe_hif_ptp_ts_db_entry_t *)isa_item(&db->entries, index);
        if (NULL_PTR != entry)
        {
            if (TRUE == check_entry_type_vals(entry, type, port, seq_id, rx))
            {
                if (entry->ts_valid == TRUE)
                {
                    ret_val = EOK;
                    *ts_sec = entry->ts_sec;
                    *ts_nsec = entry->ts_nsec;
                }
                else
                {
                    ret_val = EAGAIN;
                }
                break;
            }
        }
    }

    if (EOK == ret_val)
    {
        /*  Remove from DB */
        (void)isa_release(&db->entries, entry);

        db->count--;
        if ((db->count <= (PFE_HIF_PTP_DB_WARNING_THRESHOLD/4U)) && db->reported)
        {
            db->reported = FALSE;
        }
    }

    oal_mutex_unlock(PFE_HIF_PTP_TS_DB_MUTEX_04);

    return ret_val;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [159/185]: src\pfe_hif_ring.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @file        pfe_hif_ring.c
 * @brief       The HIF BD ring driver.
 * @details     This is the HW BD ring interface providing basic manipulation
 *              possibilities for HIF's RX and TX buffer descriptor rings.
 *              Each ring is treated as a single instance therefore module can
 *              be used to handle HIF with multiple channels (RX/TX ring pairs).
 *
 * @note        BD and WB BD rings are non-cached entities.
 *
 * @warning     No concurrency prevention is implemented here. User shall
 *              therefore ensure correct protection of ring instance manipulation
 *              at application level.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_platform_cfg.h"
#include "pfe_platform.h"
#include "pfe_cbus.h"
#include "pfe_hif_ring.h"

/* LOCAL VARIABLES */

/* Minimum is 8, 16 avoids complications with 4K boundary */
#define BD_ALIGNMENT ((16U > HAL_CACHE_LINE_SIZE) ? 16U : HAL_CACHE_LINE_SIZE)

/* Memory for buffer descriptors. Should be DMA safe, contiguous, and 64-bit aligned. */
/* Arrays should be static but are not to avoid memmap issues with some compilers */
#ifdef PFE_CFG_HIF_NOCPY_SUPPORT
    /* GCC attribute 'section' only works for a variable. So, we need to add below macro for all variables */
    /* RX BD ring */
    #define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    __attribute__((aligned(BD_ALIGNMENT))) pfe_hif_nocpy_bd_t arRxBdRing[ETH_43_PFE_MAX_RXBD_CNT];
    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    /* TX BD ring */
    #define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    __attribute__((aligned(BD_ALIGNMENT))) pfe_hif_nocpy_bd_t arTxBdRing[ETH_43_PFE_MAX_TXBD_CNT];
    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
#else
    /* RX BD ring */
    #define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    __attribute__((aligned(BD_ALIGNMENT))) pfe_hif_bd_t    arRxBdRing[ETH_43_PFE_MAX_RXBD_CNT];
    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    /* RX Write-back BD ring */
    #define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    __attribute__((aligned(BD_ALIGNMENT))) pfe_hif_wb_bd_t arRxBdWbRing[ETH_43_PFE_MAX_RXBD_CNT];
    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    /* TX BD ring */
    #define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    __attribute__((aligned(BD_ALIGNMENT))) pfe_hif_bd_t    arTxBdRing[ETH_43_PFE_MAX_TXBD_CNT];
    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    /* TX Write-back BD ring */
    #define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
    __attribute__((aligned(BD_ALIGNMENT))) pfe_hif_wb_bd_t arTxBdWbRing[ETH_43_PFE_MAX_TXBD_CNT];
    #define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BD_MEM
    #include "Eth_43_PFE_MemMap.h"
#endif

/* LOCAL FUNCTION PROTOTYPES */

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */

/* Following functions needed for both MCAL and minihif */
__attribute__((hot)) static inline void inc_read_index(pfe_hif_ring_t *ring);
__attribute__((hot)) static inline void inc_write_index(pfe_hif_ring_t *ring);
__attribute__((cold)) static errno_t pfe_hif_ring_init_ring_std(pfe_hif_ring_t *ring, void *ring_va, void *wb_ring_va, uint32 length, bool_t is_rx);
__attribute__((cold)) static errno_t pfe_hif_ring_create_std(pfe_hif_ring_t *ring, void *ring_va, void *wb_ring_va, uint32 length, bool_t rx);
__attribute__((hot)) static inline errno_t pfe_hif_ring_enqueue_buf_std(pfe_hif_ring_t *ring, const void *buf_pa, uint32 length);
__attribute__((hot)) static inline errno_t pfe_hif_ring_dequeue_plain_std(pfe_hif_ring_t *ring, bool_t *lifm);
__attribute__((cold)) static void pfe_hif_ring_invalidate_std(const pfe_hif_ring_t *ring);
__attribute__((cold)) static void pfe_hif_ring_init_bd_std(const pfe_hif_ring_t *ring);
/* Following functions needed only for MCAL */
#if !defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    __attribute__((hot)) static inline errno_t pfe_hif_ring_dequeue_buf_std(pfe_hif_ring_t *ring, void **buf_pa, uint32 *length, bool_t *lifm);
    __attribute__((hot)) static inline void dec_write_index_std(pfe_hif_ring_t *ring);
#else /* defined PFE_CFG_HIF_NOCPY_SUPPORT */
    __attribute__((cold)) static errno_t pfe_hif_ring_create_nocpy(pfe_hif_ring_t *ring, void *ring_va, uint32 length, bool_t rx);
    __attribute__((cold)) static errno_t pfe_hif_ring_init_ring_nocpy(pfe_hif_ring_t *ring, void *ring_va, uint32 length, bool_t is_rx);
    __attribute__((hot)) static inline errno_t pfe_hif_ring_enqueue_buf_nocpy(pfe_hif_ring_t *ring, const void *buf_pa, uint32 length, uint32 lmem_header_size);
    __attribute__((hot)) static inline errno_t pfe_hif_ring_dequeue_buf_nocpy(pfe_hif_ring_t *ring, void **buf_pa, uint32 *length, bool_t *lifm);
    __attribute__((hot)) static inline errno_t pfe_hif_ring_dequeue_plain_nocpy(pfe_hif_ring_t *ring, bool_t *lifm);
    __attribute__((cold)) static void pfe_hif_ring_invalidate_nocpy(const pfe_hif_ring_t *ring);
    __attribute__((cold)) static void pfe_hif_ring_init_bd_nocpy(const pfe_hif_ring_t *ring);
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/*==================================================================================================*/
__attribute__((hot)) static inline void inc_write_index(pfe_hif_ring_t *ring)
{
    uint32 idx = ring->write_idx + 1U;

    /* idx >= (2U * ring->length */
    if (idx >= (ring->length << 1U))
    {
        idx = 0U;
    }
    ring->write_idx = idx;
    if (idx >= ring->length)
    {
        idx -= ring->length;
    }

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if(TRUE == ring->nocpy)
    {
        ring->bd_write.wr_bd_nocpy = &((pfe_hif_nocpy_bd_t *)ring->base_va)[idx];
    }
    else
#endif
    {
        ring->bd_write.wr_bd = &((pfe_hif_bd_t *)ring->base_va)[idx];
        ring->wr_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[idx];
    }
}

/*==================================================================================================*/
#if !defined(PFE_CFG_HIF_NOCPY_SUPPORT)
__attribute__((hot)) static inline void dec_write_index_std(pfe_hif_ring_t *ring)
{
    uint32 idx = ring->write_idx;

    if (0U == idx)
    {
        PfeDevAssert(ring->length > 0);
        idx = (2U * ring->length) - 1U;
    }
    else
    {/*decrement index if it's not already 0*/
        idx--;
    }
    ring->write_idx = idx;
    if (idx >= ring->length)
    {
        idx -= ring->length;
    }

    ring->bd_write.wr_bd = &((pfe_hif_bd_t *)ring->base_va)[idx];
    ring->wr_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[idx];
}
#endif /* !PFE_CFG_HIF_NOCPY_SUPPORT */

/*==================================================================================================*/
__attribute__((hot)) static inline void inc_read_index(pfe_hif_ring_t *ring)
{
    uint32 idx = ring->read_idx + 1U;

    /* idx >= (2U * ring->length */
    if (idx >= (ring->length << 1U))
    {
        idx = 0U;
    }
    ring->read_idx = idx;
    if (idx >= ring->length)
    {
        idx -= ring->length;
    }
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    if(TRUE == ring->nocpy)
    {
        ring->bd_read.rd_bd_nocpy = &((pfe_hif_nocpy_bd_t *)ring->base_va)[idx];
    }
    else
#endif
    {
        ring->bd_read.rd_bd = &((pfe_hif_bd_t *)ring->base_va)[idx];
        ring->rd_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[idx];
    }
}

/**
 * @brief       Get fill level
 * @param[in]   ring The ring instance
 * @return      Number of occupied entries within the ring
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((pure, hot)) uint32 pfe_hif_ring_get_fill_level(const pfe_hif_ring_t *ring)
{
    uint32 fill_level;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        fill_level = UINT32_MAX;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        /*  In case of HIF NOCPY, the HW does not use external RX buffers but internal
            BMU-provided buffers. Thus the RX ring fill level can't be other value
            than zero. */

        if (TRUE == ring->is_rx)
        {
            fill_level = 0U;
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            if (ring->read_idx <= ring->write_idx)
            {
                fill_level = ring->write_idx - ring->read_idx;
            }
            else
            {
                fill_level = (2U * ring->length) - (ring->read_idx - ring->write_idx);
            }
        }
    }
    return fill_level;
}

/**
 * @brief       Get physical address of the start of the ring
 * @param[in]   ring The ring instance
 * @return      Pointer to the beginning address of the ring
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((pure, cold)) void *pfe_hif_ring_get_base_pa(const pfe_hif_ring_t *ring)
{
    void *base_pa = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        base_pa = ring->base_pa;
    }
    return base_pa;
}

/**
 * @brief       Get physical address of the write-back table
 * @param[in]   ring The ring instance
 * @return      Pointer to the table
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((pure, cold)) void *pfe_hif_ring_get_wb_tbl_pa(const pfe_hif_ring_t *ring)
{
    void *wb_tbl_pa = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        wb_tbl_pa = ring->wb_tbl_base_pa;
    }
    return wb_tbl_pa;
}

/**
 * @brief       Get length of the write-back table
 * @param[in]   ring The ring instance
 * @return      Length of the table in number of entries. Only valid when
 *              pfe_hif_ring_get_wb_tbl_pa() is not NULL.
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((pure, cold)) uint32 pfe_hif_ring_get_wb_tbl_len(const pfe_hif_ring_t *ring)
{
    uint32 wb_tbl_len;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        wb_tbl_len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        wb_tbl_len = ring->length;
    }
    return wb_tbl_len;
}

/**
 * @brief        Invalidate the explicit entry in the ring
 * @param[in]    ring The ring instance
 * @param[in]    index The position in the ring
 */
__attribute__((cold)) void pfe_hif_ring_invalidate_direct(const pfe_hif_ring_t *ring, uint32 index)
{
    /* Clear BD enable flag */
    (&((pfe_hif_bd_t *)ring->base_va)[index])->control.info.desc_en = 0U;

    /* Reset the write-back descriptor */
    (&((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[index])->seqnum = 0xffffU;
    (&((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[index])->control.info.desc_en = 1U;
}

/**
 * @brief        Revalidate the explicit entry in the ring
 * @param[in]    ring The ring instance
 * @param[in]    index The position in the ring
 * @note        It is expected that BD has valid set-up
 */
__attribute__((cold)) void pfe_hif_ring_revalidate_direct(const pfe_hif_ring_t *ring, uint32 index)
{
        /* Set BD enable flag */
        (&((pfe_hif_bd_t *)ring->base_va)[index])->control.info.desc_en = 1U;

        /* Set the write-back descriptor */
        (&((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[index])->control.info.desc_en = 0U;
}

/**
 * @brief        Set ring to explicit position
 * @param[in]    ring The ring instance
 * @param[in]    index The new position of the ring
 * @return        0 if OK
 */
__attribute__((cold)) errno_t pfe_hif_ring_force_index(pfe_hif_ring_t *ring, uint32 index)
{
    uint32 offset;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    offset = index % ring->length;

    ring->read_idx = offset;
    ring->bd_read.rd_bd = &((pfe_hif_bd_t *)(uint32)ring->base_va)[ring->read_idx];
    ring->rd_wb_bd = &((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ring->read_idx];

    ring->write_idx = offset;
    ring->bd_write.wr_bd = ring->bd_read.rd_bd;
    ring->wr_wb_bd = ring->rd_wb_bd;

    return ret;
}

/**
 * @brief        Search for valid entry in WB ring
 * @param[in]    ring The ring instance
 * @param[in]    valid TRUE if searhing for valid entry, FALSE otherwise
 * @param[out]    index The position of found entry in the ring
 * @return        TRUE if found
 * @note        Requires invalidated all entries before search
 */
__attribute__((cold)) errno_t pfe_hif_ring_find_wb_entry(pfe_hif_ring_t *ring, bool_t valid, uint32 *index)
{
    pfe_hif_wb_bd_t *wb;
    bool_t flag = FALSE;
    uint32 ring_idx;
    errno_t ret = ENOENT;

    for (ring_idx = 0U; ring_idx < ring->length; ring_idx++)
    {
        wb = &(((pfe_hif_wb_bd_t *)ring->wb_tbl_base_pa)[ring_idx]);

        /* valid entry: WB BD must be DISABLED. The entry was processed by HW */
        if (TRUE == valid)
        {
            if (0U == (wb->control.info.desc_en))
            {
                *index = ring_idx;
                ret = EOK;
                break;
            }
        }

        /* invalid entry: WB BD must be ENABLED. The entry was not touched by HW
         *           For invalid search we need to detect first valid entry
         *           and only then search for invalid. Reason: Invalid search
         *           is used on RX ring, which can contain multiple (cached)
         *           entries.
         */
        if (FALSE == valid)
        {
            if ((TRUE == flag) && (0U != (wb->control.info.desc_en)))
            {
                *index = ring_idx;
                ret = EOK;
                break;
            }
            if ((FALSE == flag) && (0U == (wb->control.info.desc_en)))
            {
                /* Found first valid entry, now we can find invalid one */
                flag = TRUE;
            }
        }
    }

    return ret;
}

/**
 * @brief        Check if the ring is on the head
 * @param[in]    ring The ring instance
 * @return        TRUE if the ring is on the head
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((pure, hot)) bool_t pfe_hif_ring_is_on_head(const pfe_hif_ring_t *ring)
{
    bool_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = (ring->rd_wb_bd == ring->wb_tbl_base_va);
    }
    return ret;
}

/**
 * @brief       Get length of the ring
 * @param[in]   ring The ring instance
 * @return      Ring length in number of entries
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((pure, hot)) uint32 pfe_hif_ring_get_len(const pfe_hif_ring_t *ring)
{
    uint32 ring_len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ring_len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ring_len = ring->length;
    }
    return ring_len;
}

/**
 * @brief       Add buffer to the ring
 * @details     Add buffer at current write position within the ring and increment
 *              the write index. If the current position is already occupied by an
 *              enabled buffer the call will fail.
 * @param[in]   ring The ring instance
 * @param[in]   buf_pa Physical address of buffer to be enqueued
 * @param[in]   length Length of the buffer
 * @param[in]   lmem_header_size Size of the LMEM Header, require for HIF_NOCPY
 * @retval      EOK Success
 * @retval      EIO The slot is already occupied
 * @retval      EPERM Ring is locked and does not accept enqueue requests
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((hot)) errno_t pfe_hif_ring_enqueue_buf(pfe_hif_ring_t *ring, const void *buf_pa, uint32 length, uint32 lmem_header_size)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if(TRUE == ring->nocpy)
        {
            ret = pfe_hif_ring_enqueue_buf_nocpy(ring, buf_pa, length, lmem_header_size);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            (void)lmem_header_size;
            ret = pfe_hif_ring_enqueue_buf_std(ring, buf_pa, length);
        }
    }
    return ret;
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       The HIF NOCPY variant
 * @param[in]   buf_pa This must be BMU2 allocated physical address
 */
__attribute__((hot)) static inline errno_t pfe_hif_ring_enqueue_buf_nocpy(pfe_hif_ring_t *ring, const void *buf_pa, uint32 length, uint32 lmem_header_size)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring) || (NULL == buf_pa)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (unlikely(ring->is_rx))
        {
            NXP_LOG_ERROR("There is nothing to enqueue into RX ring in case of HIF NOCPY\n");
            ret = EPERM;
        }
        else
        {
            /*  Write the HW BD. Always write all control word bits since
                 the HIF NOCPY is clearing the flags once BD is processed... */
            ring->bd_write.wr_bd_nocpy->data = (uint32)((addr_t)(PFE_CFG_MEMORY_PHYS_TO_PFE(buf_pa)) & 0xffffffffU);
            ring->bd_write.wr_bd_nocpy->control.w0.tx_buflen = (uint16)length;
            /* Fill the rest of the LMEM buffer by packet data (copy useful data after the LMEM header) */
            ring->bd_write.wr_bd_nocpy->status.w0.tx_lmem_buflen =
                        (uint16)(((PFE_CFG_LMEM_BUF_SIZE - lmem_header_size) < length)
                                  ? (PFE_CFG_LMEM_BUF_SIZE - lmem_header_size)
                                  : length);
            ring->bd_write.wr_bd_nocpy->status.w1.tx.dst_buf_offset = (uint16)lmem_header_size;
            ring->bd_write.wr_bd_nocpy->status.w1.tx.src_buf_offset = (uint16)(256U + lmem_header_size);
            /* Request the LMEM copy mode */
            ring->bd_write.wr_bd_nocpy->control.w1.info.lmem_cpy = 1U;
            ring->bd_write.wr_bd_nocpy->control.w1.info.pkt_xfer = 1U;
            ring->bd_write.wr_bd_nocpy->control.w1.info.lifm = 1U;

            /*  Write the BD 'enable' bit */
            ring->bd_write.wr_bd_nocpy->control.w1.info.desc_en = 1U;
            /*  Increment the write pointer */
            inc_write_index(ring);
            ret = EOK;
        }
    }

    return ret;
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       The "standard" HIF variant
 */
__attribute__((hot)) static inline errno_t pfe_hif_ring_enqueue_buf_std(pfe_hif_ring_t *ring, const void *buf_pa, uint32 length)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring) || (NULL == buf_pa)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (unlikely(0U != ring->bd_write.wr_bd->control.info.desc_en))
        {
            NXP_LOG_ERROR("Can't insert buffer since the BD entry is already used\n");
            ret = EIO;
        }
        else
        {
            /*  Write the HW BD */
            ring->bd_write.wr_bd->data = (uint32)((addr_t)PFE_CFG_MEMORY_PHYS_TO_PFE(buf_pa) & 0xffffffffU);
            ring->bd_write.wr_bd->buflen = (uint16)(length & (uint32)UINT16_MAX);
            ring->bd_write.wr_bd->check.status = 0U;
            ring->bd_write.wr_bd->control.info.lifm = 1U;

#ifdef EQ_DQ_RX_DEBUG
            if (ring->is_rx)
            {
                NXP_LOG_INFO("EQ: IDX:%02d, BD@p0x%p, WB@p0x%p, BUF@p0x%p\n",
                    (ring->write_idx % ring->length),
                    (void *)((addr_t)ring->wr_bd - ((addr_t)ring->base_va - (addr_t)ring->base_pa)),
                    (void *)((addr_t)ring->wr_wb_bd - ((addr_t)ring->wb_tbl_base_va - (addr_t)ring->wb_tbl_base_pa)),
                    (void *)buf_pa);
            }
#endif /* EQ_DQ_RX_DEBUG */

            /*  Write the BD 'enable' bit */
            ring->wr_wb_bd->control.info.desc_en = 1U;
            hal_wmb();
            ring->bd_write.wr_bd->control.info.desc_en = 1U;

            /*  Increment the write pointer */
            inc_write_index(ring);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Dequeue buffer form the ring
 * @details     Remove next buffer from the ring and increment the read index. If the
 *              buffer is empty then the call fails and no operation is performed.
 * @param[in]   ring The ring instance
 * @param[out]  buf_pa Pointer where pointer to the dequeued buffer shall be written
 * @param[out]  length Pointer where length of the buffer shall be written
 * @param[out]  lifm Pointer where last-in-frame information shall be written
 * @retval      EOK Buffer dequeued
 * @retval      EAGAIN Current BD is busy
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((hot)) errno_t pfe_hif_ring_dequeue_buf(pfe_hif_ring_t *ring, void **buf_pa, uint32 *length, bool_t *lifm)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        ret = pfe_hif_ring_dequeue_buf_nocpy(ring, buf_pa, length, lifm);
#else
        ret = pfe_hif_ring_dequeue_buf_std(ring, buf_pa, length, lifm);
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    }
    return ret;
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       The HIF NOCPY variant
 */
__attribute__((hot)) static inline errno_t pfe_hif_ring_dequeue_buf_nocpy(pfe_hif_ring_t *ring, void **buf_pa, uint32 *length, bool_t *lifm)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring) || (NULL == buf_pa) || (NULL == length) || (NULL == lifm)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != ring->bd_read.rd_bd_nocpy->control.w1.info.pkt_xfer)
        {
            ret = EAGAIN;
        }
        else
        {
            *buf_pa = (void *)(addr_t)PFE_CFG_MEMORY_PFE_TO_PHYS(ring->bd_read.rd_bd_nocpy->data);

            if (ring->is_rx)
            {
                *length = ring->bd_read.rd_bd_nocpy->status.w0.rx_buflen;
            }
            else
            {
                *length = ring->bd_read.rd_bd_nocpy->control.w0.tx_buflen;
            }

            *lifm = (0U != ring->bd_read.rd_bd_nocpy->control.w1.info.lifm);

            /*  Re-enable the descriptor so HIF can write another RX buffer there */
            ring->bd_read.rd_bd_nocpy->control.w1.info.pkt_xfer = 1U;
            ring->bd_read.rd_bd_nocpy->control.w1.info.desc_en = 1U;
            /*  Must clear also lifm flag to prepare BD for next use */
            ring->bd_read.rd_bd_nocpy->control.w1.info.lifm = 0U;

            /*  Increment the read pointer */
            inc_read_index(ring);
            ret = EOK;
        }
    }

    return ret;
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

#if !defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       The "standard" HIF variant
 */
__attribute__((hot)) static inline errno_t pfe_hif_ring_dequeue_buf_std(pfe_hif_ring_t *ring, void **buf_pa, uint32 *length, bool_t *lifm)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring) || (NULL == buf_pa) || (NULL == length) || (NULL == lifm)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((0U == ring->bd_read.rd_bd->control.info.desc_en) || (0U != ring->rd_wb_bd->control.info.desc_en))
        {
            ret = EAGAIN;
        }
        else /* 1 == ring->rd_bd->desc_en && 0 == ring->rd_wb_bd->desc_en */
        {
            /*  Reset BD and WB BD enable flag. It is ensured that the current BD will not be reused
                again until desc_en is reset since sequence number will become not sequential and
                thus the BD is not valid. */
            ring->bd_read.rd_bd->control.info.desc_en = 0U;
            ring->rd_wb_bd->control.info.desc_en = 1U;
            hal_wmb();

            *buf_pa = (void *)(addr_t)PFE_CFG_MEMORY_PFE_TO_PHYS(ring->bd_read.rd_bd->data);

#ifdef EQ_DQ_RX_DEBUG
            if (ring->is_rx)
            {
                NXP_LOG_INFO("DQ: IDX:%02d, BD@p0x%p, WB@p0x%p, BUF@p0x%p\n",
                    (ring->read_idx % ring->length),
                    (void *)((addr_t)ring->rd_bd - ((addr_t)ring->base_va - (addr_t)ring->base_pa)),
                    (void *)((addr_t)ring->rd_wb_bd - ((addr_t)ring->wb_tbl_base_va - (addr_t)ring->wb_tbl_base_pa)),
                    (void *)*buf_pa);
            }
#endif /* EQ_DQ_RX_DEBUG */

            *length = ring->rd_wb_bd->buflen;
            *lifm = (0U != ring->rd_wb_bd->control.info.lifm);
            /*  Increment the read pointer */
            inc_read_index(ring);
            ret = EOK;
        }
    }
    return ret;
}
#endif /* !PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       Dequeue buffer from the ring without response
 * @details     Remove next buffer from the ring and increment the read index. If the
 *              buffer is empty then the call fails and no operation is performed. Can
 *              be used to receive TX confirmations.
 * @param[in]   ring The ring instance
 * @param[out]  lifm Pointer where last-in-frame information shall be written
 * @param[out]  len Number of transmitted bytes
 * @retval      EOK Buffer dequeued
 * @retval      EAGAIN Current BD is busy
 * @note        Must not be preempted by: pfe_hif_ring_destroy()
 */
__attribute__((hot)) errno_t pfe_hif_ring_dequeue_plain(pfe_hif_ring_t *ring, bool_t *lifm)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if(TRUE == ring->nocpy)
        {
            ret = pfe_hif_ring_dequeue_plain_nocpy(ring, lifm);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            ret = pfe_hif_ring_dequeue_plain_std(ring, lifm);
        }
    }
    return ret;
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       The HIF NOCPY variant
 */
__attribute__((hot)) static errno_t pfe_hif_ring_dequeue_plain_nocpy(pfe_hif_ring_t *ring, bool_t *lifm)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (1U == ring->bd_read.rd_bd_nocpy->control.w1.info.pkt_xfer)
        {
            /*  Nothing to dequeue */
            ret = EAGAIN;
        }
        else
        {
            /*
                Return the LIFM flag

                 HIF NOCPY TX BDP will always overwrite the BD so the LIFM
                flag will be set to zero (very smart...). It must be ensured
                that the HIF NOCPY ring will be used in the one-frame=one-BD
                manner.
            */
            *lifm = TRUE;

            /*  Clear the 'TX done' flag */
            ring->bd_read.rd_bd_nocpy->control.w1.info.pkt_xfer = 1U;
            ring->bd_read.rd_bd_nocpy->control.w1.info.desc_en = 0U;

            /*  Increment the read pointer */
            inc_read_index(ring);
            ret = EOK;
        }
    }

    return ret;
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       The "standard" HIF variant
 */
__attribute__((hot)) static inline errno_t pfe_hif_ring_dequeue_plain_std(pfe_hif_ring_t *ring, bool_t *lifm)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((0U == ring->bd_read.rd_bd->control.info.desc_en) || (0U != ring->rd_wb_bd->control.info.desc_en))
        {
            ret = EAGAIN;
        }
        else
        {
            /*  Return LIFM */
            *lifm = (0U != ring->bd_read.rd_bd->control.info.lifm);

            /*  Reset BD and WB BD enable flag. It is ensured that the current BD will not be reused
                again until desc_en is reset since sequence number will become not sequential and
                thus the BD is not valid. */
            ring->bd_read.rd_bd->control.info.desc_en = 0U;
            ring->rd_wb_bd->control.info.desc_en = 1U;
            hal_wmb();

            /*  Increment the read pointer */
            inc_read_index(ring);
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Drain buffer from ring
 * @details     This call dequeues previously enqueued buffer from a ring regardless it
 *              has been processed by the HW or not. Function is intended to properly
 *              shut-down the ring in terms of possibility to retrieve all currently
 *              enqueued entries.
 * @param[in]   ring The ring instance
 * @param[out]  buf_pa buf_pa Pointer where pointer to the dequeued buffer shall be written
 * @retval      EOK Buffer has been dequeued
 * @retval      ENOENT No more buffers in the ring
 */
__attribute__((cold)) errno_t pfe_hif_ring_drain_buf(pfe_hif_ring_t *ring, void **buf_pa)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring) || (NULL == buf_pa)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (ring->is_rx)
        {
            bool_t lifm;

            /*  In this case we will do dequeue without enable until the ring is empty. This
                will ensure that application can drain RX buffers and return all BMU
                buffers back to the HW pool. */
            *buf_pa = (void *)PFE_CFG_MEMORY_PFE_TO_PHYS(ring->bd_read.rd_bd_nocpy->data);
            if (EOK == pfe_hif_ring_dequeue_plain_nocpy(ring, &lifm))
            {
                ret = EOK;
            }
            else
            {
                ret = ENOENT;
            }
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            if (0U != pfe_hif_ring_get_fill_level(ring))
            {
                /*  In case of RX ring this will return enqueued RX buffer. In
                    case of TX ring the enqueued TX buffer will be returned. */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
                *buf_pa = (void *)PFE_CFG_MEMORY_PFE_TO_PHYS(ring->bd_read.rd_bd_nocpy->data);
                ring->bd_read.rd_bd_nocpy->control.w1.info.desc_en = 0U;
                inc_read_index(ring);
#else /* PFE_CFG_HIF_NOCPY_SUPPORT */
                /*  Draining introduces sequence number corruption. Every enqueued
                    BD increments sequence number in SW and every processed BD
                    increments it in HW. In case when non-processed BDs are dequeued
                    the new ones will be enqueued with sequence number not matching
                    the current HW one. We need to adjust the SW value when draining
                    non-processed BDs. */
                if (0U != ring->wr_wb_bd->control.info.desc_en)
                {
                    /*  This BD has not been processed yet. Revert the enqueue. */
                    *buf_pa = (void *)PFE_CFG_MEMORY_PFE_TO_PHYS(ring->bd_write.wr_bd->data);
                    ring->bd_write.wr_bd->control.info.desc_en = 0U;
                    ring->wr_wb_bd->control.info.desc_en = 1U;
                    dec_write_index_std(ring);
                }
                else
                {
                    /*  Processed BD. Do standard dequeue. */
                    *buf_pa = (void *)PFE_CFG_MEMORY_PFE_TO_PHYS(ring->bd_read.rd_bd->data);
                    ring->bd_read.rd_bd->control.info.desc_en = 0U;
                    ring->rd_wb_bd->control.info.desc_en = 1U;
                    inc_read_index(ring);
                }
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
                ret = EOK;
            }
            else
            {
                ret = ENOENT;
            }
        }
    }
    return ret;
}

/**
 * @brief       Invalidate the ring
 * @details     Disable all buffer descriptors in the ring
 * @param[in]   ring The ring instance
 * @note        Must not be preempted by: pfe_hif_ring_enqueue_buf(), pfe_hif_ring_destroy()
 */
__attribute__((cold)) void pfe_hif_ring_invalidate(const pfe_hif_ring_t *ring)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if(TRUE == ring->nocpy)
        {
            pfe_hif_ring_invalidate_nocpy(ring);
        }
        else
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        {
            pfe_hif_ring_invalidate_std(ring);
        }
    }
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       The HIF NOCPY variant
 */
__attribute__((cold)) static void pfe_hif_ring_invalidate_nocpy(const pfe_hif_ring_t *ring)
{
    uint32 ii;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (ii=0U; ii < ring->length; ii++)
        {
            /*  Zero-out the EN flag */
            (((pfe_hif_nocpy_bd_t *)ring->base_va)[ii]).control.w1.info.desc_en = 0U;
        }
    }
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       The "standard" HIF variant
 */
__attribute__((cold)) static void pfe_hif_ring_invalidate_std(const pfe_hif_ring_t *ring)
{
    uint32 ii;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for (ii=0U; ii<ring->length; ii++)
        {
            /*  Zero-out the EN flag */
            (((pfe_hif_bd_t *)ring->base_va)[ii]).control.info.desc_en = 0U;

            /*  Reset the write-back descriptor */
            (((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ii]).control.info.desc_en = 1U;
        }
    }
}

/**
 * @brief       Dump of HW rings
 * @details     Dumps particular ring
 * @param[in]   ring The ring instance
 * @param[in]   name The ring name
 * @note        Must not be preempted by: pfe_hif_ring_enqueue_buf(), pfe_hif_ring_destroy()
 */
__attribute__((cold)) void pfe_hif_ring_dump(const pfe_hif_ring_t *ring, const char_t *name)
{
#ifdef NXP_LOG_ENABLED
    uint32 ii;
    const char_t *idx_str;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring) || (NULL == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_INFO("Ring %s: len %u\n", name, (uint_t)ring->length);
        NXP_LOG_INFO("  Type: %s\n", ring->is_rx ? "RX" : "TX");
        NXP_LOG_INFO("  Index w/r: %u/%u (%u/%u)\n", (uint_t)(ring->write_idx % ring->length), (uint_t)(ring->read_idx % ring->length), (uint_t)ring->write_idx, (uint_t)ring->read_idx);

        /* BD ring */
        for (ii=0U; ii < ring->length; ii++)
        {
            pfe_hif_bd_t *bd = &(((pfe_hif_bd_t *)ring->base_va)[ii]);

            if (0U == ii)
            {
                NXP_LOG_INFO("  BD va/pa v0x%p/p0x%p\n", ring->base_va, ring->base_pa);
                NXP_LOG_INFO("    pa:      idx: bufl:ctrl: status :  data  :  next :seqn\n");
            }

            if ((ring->write_idx % ring->length) == ii)
            {
                idx_str = "<-- WR";
            }
            else if ((ring->read_idx % ring->length) == ii)
            {
                idx_str = "<-- RD";
            }
            else
            {
                idx_str = "";
            }

            NXP_LOG_INFO("    p0x%p%5u: %04x:%04x:%08x:%08x:%08x%s\n",(void *)&((pfe_hif_bd_t *)ring->base_pa)[ii], (uint_t)ii, bd->buflen, bd->control.ctrl, bd->check.status, (uint_t)PFE_CFG_MEMORY_PFE_TO_PHYS(bd->data), (uint_t)bd->next, idx_str);
        }

        /* WB ring */
#if !defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        for (ii=0U; ii < ring->length; ii++)
        {
            pfe_hif_wb_bd_t *wb = &(((pfe_hif_wb_bd_t *)ring->wb_tbl_base_va)[ii]);

            if (0U == ii)
            {
                NXP_LOG_INFO("  WB va/pa v0x%p/p0x%p\n", ring->wb_tbl_base_va, ring->wb_tbl_base_pa);
                NXP_LOG_INFO("    pa:      idx:  ctl: rsvd :bufl:seqn\n");
            }

            if ((ring->read_idx % ring->length) == ii)
            {
                idx_str = "<-- RD";
            }
            else
            {
                idx_str = "";
            }

            NXP_LOG_INFO("    p0x%p%5u: %04x:%06x:%04x%s\n", (void *)&((pfe_hif_wb_bd_t *)ring->wb_tbl_base_pa)[ii], (uint_t)ii, wb->control.ctrl.ctrl,  wb->control.ctrl.rsvd, wb->buflen, idx_str);
        }
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    }
#else
        (void) name; (void) ring;/* Not used in this implementation */
#endif /* NXP_LOG_ENABLED */
}

/**
 * @brief          Create new PFE buffer descriptor ring using dedicated MCAL memory and MCAL channel type
 * @param[inout]   ring Pointer to BD ring
 * @param[in]      length Ring length
 * @param[in]      rx If TRUE the ring is RX, if FALSE the the ring is TX
 * @return         EOK if success, error code otherwise
 * @note           Must not be preempted by any of the remaining API functions
 */
__attribute__((cold)) errno_t pfe_hif_ring_create_mcal(pfe_hif_ring_t *ring, uint32 length, bool_t rx)
{
    errno_t ret_val;
    void *ring_va = NULL;
#if !defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    void *wb_ring_va;
#endif

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Assign static memory for buffer descriptors (and write-back descriptors) */
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        if (TRUE == rx)
        {
            if (likely(length <= ETH_43_PFE_MAX_RXBD_CNT))
            {
                ring_va = (void *)&arRxBdRing;
            }
        }
        else
        {
            if (likely(length <= ETH_43_PFE_MAX_TXBD_CNT))
            {
                ring_va = (void *)&arTxBdRing;
            }
        }
#else
        if (TRUE == rx)
        {
            if (likely(length <= ETH_43_PFE_MAX_RXBD_CNT))
            {
                ring_va = (void *)&arRxBdRing;
                wb_ring_va = (void *)&arRxBdWbRing;
            }
        }
        else
        {
            if (likely(length <= ETH_43_PFE_MAX_TXBD_CNT))
            {
                ring_va = (void *)&arTxBdRing;
                wb_ring_va = (void *)&arTxBdWbRing;
            }
        }
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

        if(NULL == ring_va)
        {
            NXP_LOG_ERROR("%s BD memory is too small\n", ((TRUE == rx) ? "Rx" : "Tx"));
            ret_val = EINVAL;
        }
        else
        {
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            ret_val = pfe_hif_ring_create_nocpy(ring, ring_va, length, rx);
#else
            ret_val = pfe_hif_ring_create_std(ring, ring_va, wb_ring_va, length, rx);
#endif
        }
    }

    return ret_val;
}

/**
 * @brief          Create new PFE buffer descriptor ring using provided memory pointers
 * @param[inout]   ring Pointer to BD ring
 * @param[in]      ring_va Pointer to BD ring memory
 * @param[in]      wb_ring_va Pointer to WB_BD ring memory
 * @param[in]      length Ring length
 * @param[in]      rx If TRUE the ring is RX, if FALSE the the ring is TX
 * @return         EOK if success, error code otherwise
 * @note           Must not be preempted by any of the remaining API functions
 */
__attribute__((cold)) errno_t pfe_hif_ring_create_minihif(pfe_hif_ring_t *ring, void *ring_va, void *wb_ring_va, uint32 length, bool_t rx)
{
    errno_t ret_val;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring) || (NULL == ring_va) || (NULL == wb_ring_va)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret_val = pfe_hif_ring_create_std(ring, ring_va, wb_ring_va, length, rx);
    }

    return ret_val;
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       The HIF NOCPY variant
 * @note        Used only for MCAL
 */
__attribute__((cold)) static errno_t pfe_hif_ring_create_nocpy(pfe_hif_ring_t *ring, void *ring_va, uint32 length, bool_t rx)
{
    errno_t ret_val = EINVAL;

    /*  Initialize ring structure, includes some checks */
    ret_val = pfe_hif_ring_init_ring_nocpy(ring, ring_va, length, rx);

    if (EOK != ret_val)
    {
        NXP_LOG_ERROR("Can't attach ring\n");
    }
    else
    {
        /*  Initialize the values in buffer descriptors */
        pfe_hif_ring_init_bd_nocpy(ring);

        NXP_LOG_DEBUG("%s ring created. %u entries.\nBD @ p0x%p/v0x%p.\n",
                        (ring->is_rx) ? "RX" : "TX",
                        (uint_t)ring->length,
                        (void *)ring->base_pa,
                        (void *)ring->base_va);
    }
    return ret_val;
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       The "standard" HIF variant
 * @note        Used both for MCAL and for minihif.
 */
__attribute__((cold)) static errno_t pfe_hif_ring_create_std(pfe_hif_ring_t *ring, void *ring_va, void *wb_ring_va, uint32 length, bool_t rx)
{
    errno_t ret_val = EINVAL;

    PfeDevAssert((SIZE_MAX / sizeof(pfe_hif_bd_t)) >= length);
    (void)autolibc_memset(ring_va, 0, (length * sizeof(pfe_hif_bd_t)));
    (void)autolibc_memset(wb_ring_va, 0, (length * sizeof(pfe_hif_wb_bd_t)));

    /*  Initialize ring structure, includes some checks */
    ret_val = pfe_hif_ring_init_ring_std(ring, ring_va, wb_ring_va, length, rx);

    if (EOK != ret_val)
    {
        NXP_LOG_ERROR("Can't init ring\n");
    }
    else
    {
        /*  Initialize the values in buffer descriptors */
        pfe_hif_ring_init_bd_std(ring);

        NXP_LOG_DEBUG("%s ring created. %u entries.\nBD @ p0x%p/v0x%p.\nWB @ p0x%p/v0x%p.\n",
                        (ring->is_rx) ? "RX" : "TX",
                        (uint_t)ring->length,
                        (void *)ring->base_pa,
                        (void *)ring->base_va,
                        (void *)ring->wb_tbl_base_pa,
                        (void *)ring->wb_tbl_base_va);
    }
    return ret_val;
}

/**
 * @brief       The "standard" HIF variant
 */
__attribute__((cold)) static errno_t pfe_hif_ring_init_ring_std(pfe_hif_ring_t *ring, void *ring_va, void *wb_ring_va, uint32 length, bool_t is_rx)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == ring_va) || (NULL == wb_ring_va)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* It shall be ensured that a single BD does not split across 4k boundary, minimum alignment is 8 */
        if (0U != ((addr_t)ring_va % sizeof(pfe_hif_bd_t)))
        {
            NXP_LOG_ERROR("Buffer descriptors are not aligned\n");
            ret = EINVAL;
        }
        else if (0U != ((addr_t)wb_ring_va % sizeof(pfe_hif_wb_bd_t)))
        {
            NXP_LOG_ERROR("Write-back descriptors are not aligned\n");
            ret = EINVAL;
        }
        else
        {

            /*  Just a debug check */
            if (((addr_t)&ring->heavy_data_mark - (addr_t)ring) > HAL_CACHE_LINE_SIZE)
            {
                NXP_LOG_DEBUG("Suboptimal: Data split between two cache lines\n");
            }

            (void)autolibc_memset(ring, 0, sizeof(pfe_hif_ring_t));
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
            ring->nocpy = FALSE;
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
            ring->base_va = ring_va;
            ring->base_pa = ring->base_va;
            ring->wb_tbl_base_va = wb_ring_va;
            ring->wb_tbl_base_pa = ring->wb_tbl_base_va;
            ring->length = length;
            ring->write_idx = 0U;
            ring->read_idx = 0U;
            ring->is_rx = is_rx;
            ring->bd_read.rd_bd = (pfe_hif_bd_t *)ring->base_va;
            ring->bd_write.wr_bd = (pfe_hif_bd_t *)ring->base_va;

            ring->rd_wb_bd = (pfe_hif_wb_bd_t *)ring->wb_tbl_base_va;
            ring->wr_wb_bd = (pfe_hif_wb_bd_t *)ring->wb_tbl_base_va;
            ret = EOK;
        }
    }

    return ret;
}
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       The nocopy HIF variant
 */
__attribute__((cold)) static errno_t pfe_hif_ring_init_ring_nocpy(pfe_hif_ring_t *ring, void *ring_va, uint32 length, bool_t is_rx)
{
    void *ring_pa = ring_va;
    uint32 ring_size = length * sizeof(pfe_hif_nocpy_bd_t);
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == ring_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* It shall be ensured that a single BD does not split across 4k boundary, minimum alignment is 8 */
        if (0U != ((addr_t)ring_pa % sizeof(pfe_hif_nocpy_bd_t)))
        {
            NXP_LOG_ERROR("Buffer descriptors are not aligned\n");
            ret = EINVAL;
        }
        else
        {
            /*  S32G HIFNCPY AXI MASTER can only access range 0x00000000 - 0xbfffffff */
            if (unlikely((((addr_t)ring_pa) + ring_size) >= (addr_t)0xBFFFFFFFU))
            {
                NXP_LOG_WARNING("Descriptor ring memory not in required range: starts @ p0x%p\n", ring_pa);
            }

            /*  Just a debug check */
            if (((addr_t)&ring->heavy_data_mark - (addr_t)ring) > HAL_CACHE_LINE_SIZE)
            {
                NXP_LOG_DEBUG("Suboptimal: Data split between two cache lines\n");
            }

            (void)autolibc_memset(ring, 0, sizeof(pfe_hif_ring_t));
            ring->nocpy = TRUE;
            ring->base_va = ring_va;
            ring->base_pa = ring_pa;
            ring->wb_tbl_base_va = NULL;
            ring->wb_tbl_base_pa = NULL;
            ring->length = length;
            ring->write_idx = 0U;
            ring->read_idx = 0U;
            ring->is_rx = is_rx;
            ring->bd_read.rd_bd_nocpy = (pfe_hif_nocpy_bd_t *)ring->base_va;
            ring->bd_write.wr_bd_nocpy = (pfe_hif_nocpy_bd_t *)ring->base_va;
            ring->rd_wb_bd = NULL;
            ret = EOK;
        }
    }

    return ret;
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       Initialize the values in "standard" buffer descriptors
 */
__attribute__((cold)) static void pfe_hif_ring_init_bd_std(const pfe_hif_ring_t *ring)
{
    pfe_hif_bd_t *hw_desc_va;
    const pfe_hif_bd_t *hw_desc_pa;
    pfe_hif_wb_bd_t *wb_bd_va;
    uint32 ii;

    /*  Initialize descriptors */
    PfeDevAssert((UINT32_MAX / sizeof(pfe_hif_bd_t)) >= ring->length);
    (void)autolibc_memset(ring->base_va, 0, ring->length * sizeof(pfe_hif_bd_t));

    /*  Chain the buffer descriptors */
    hw_desc_va = (pfe_hif_bd_t *)ring->base_va;
    hw_desc_pa = (pfe_hif_bd_t *)ring->base_pa;

    for (ii=0; ii < ring->length; ii++)
    {
        if (TRUE == ring->is_rx)
        {
            /*  Mark BD as RX */
            hw_desc_va[ii].control.info.dir = 1U;
        }

        /*  Enable BD interrupt */
        hw_desc_va[ii].control.info.cbd_int_en = 1U;
        hw_desc_va[ii].next = (uint32)((addr_t)PFE_CFG_MEMORY_PHYS_TO_PFE(&hw_desc_pa[ii + 1U]) & 0xffffffffU);
    }

    /*  Chain last one with the first one */
    hw_desc_va[ii-1U].next = (uint32)((addr_t)PFE_CFG_MEMORY_PHYS_TO_PFE(&hw_desc_pa[0]) & 0xffffffffU);
    hw_desc_va[ii-1U].control.info.last_bd = 1U;

    /*  Initialize write-back descriptors */
    (void)autolibc_memset(ring->wb_tbl_base_va, 0, ring->length * sizeof(pfe_hif_wb_bd_t));

    wb_bd_va = (pfe_hif_wb_bd_t *)ring->wb_tbl_base_va;
    for (ii=0U; ii<ring->length; ii++)
    {
        /*  Initialize WB BD descriptor enable flag. Once descriptor is processed,
            the PFE HW will clear it. */
        wb_bd_va->control.info.desc_en = 1U;
        wb_bd_va++;
    }
}

#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       Initialize the values in nocopy buffer descriptors
 */
__attribute__((cold)) static void pfe_hif_ring_init_bd_nocpy(const pfe_hif_ring_t *ring)
{
    pfe_hif_nocpy_bd_t *hw_desc_va;
    const pfe_hif_nocpy_bd_t *hw_desc_pa;
    uint32 ii;

    /*  Initialize memory */
    (void)autolibc_memset(ring->base_pa, 0, ring->length * sizeof(pfe_hif_nocpy_bd_t));

    /*  Chain the buffer descriptors */
    hw_desc_va = (pfe_hif_nocpy_bd_t *)ring->base_pa;
    hw_desc_pa = (pfe_hif_nocpy_bd_t *)ring->base_pa;

    for (ii=0; ii < ring->length; ii++)
    {
        if (TRUE == ring->is_rx)
        {
            /*  Mark BD as RX */
            hw_desc_va[ii].control.w1.info.dir = 0U;
            /*  Enable the descriptor */
            hw_desc_va[ii].control.w1.info.desc_en = 1U;
            hw_desc_va[ii].control.w1.info.pkt_xfer = 1U;
        }
        else
        {
            hw_desc_va[ii].control.w1.info.dir = 1U;
            hw_desc_va[ii].control.w1.info.desc_en = 0U;
            hw_desc_va[ii].control.w1.info.pkt_xfer = 1U;
        }

        /*  Enable BD interrupt */
        hw_desc_va[ii].control.w1.info.cbd_int_en = 1U;

        hw_desc_va[ii].next = (uint32)((addr_t)(&hw_desc_pa[ii + 1U]) & 0xffffffffU);
    }

    /*  Chain last one with the first one */
    hw_desc_va[ii-1U].next = (uint32)((addr_t)(&hw_desc_pa[0]) & 0xffffffffU);
    hw_desc_va[ii-1U].control.w1.info.last_bd = 1U;
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

/**
 * @brief       Destroy BD ring
 * @param[in]   ring The ring instance
 * @note        Must not be preempted by any of the remaining API functions
 */
__attribute__((cold)) errno_t pfe_hif_ring_destroy(pfe_hif_ring_t *ring)
{
    if ((NULL != ring) && (NULL != ring->base_va))
    {
        pfe_hif_ring_invalidate(ring);
        ring->base_va = NULL;
        ring->wb_tbl_base_va = NULL;
    }

    return EOK;
}

#ifdef PFE_CFG_TARGET_OS_AUTOSAR
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_TARGET_OS_AUTOSAR */


===== 文件 [160/185]: src\pfe_hm.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==============================================================================
                                INCLUDE FILES
 1) system and project includes
 2) needed interfaces from external units
 3) internal and external interfaces from this unit
==============================================================================*/
#include "pfe_cfg.h"
#include "oal.h"
#include "pfe_hm.h"

/*==============================================================================
                                 LOCAL MACROS
==============================================================================*/
#define ARRAY_LEN(x) (sizeof(x)/sizeof(x[0]))

/*==============================================================================
                               LOCAL VARIABLES
==============================================================================*/
#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static struct {
    bool_t initialized;
    pfe_hm_item_t items[PFE_HM_QUEUE_LEN];
    uint32 start;
    uint32 end;
    uint32 len;
    pfe_hm_cb_t event_cb;
} pfe_hm;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#ifdef NXP_LOG_ENABLED

typedef struct {
    pfe_hm_evt_t id;
    const char *str;
} hm_string_t;

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static const hm_string_t hm_evt_strings[] = {
    {HM_EVT_RUNTIME, "Driver runtime error"},

#ifndef PFE_CFG_PFE_SLAVE
    {HM_EVT_ECC, "ECC Errors interrupt"},

    {HM_EVT_WDT_BMU1, "BMU1 Watchdog trigered"},
    {HM_EVT_WDT_BMU2, "BMU2 Watchdog trigered"},
    {HM_EVT_WDT_CLASS, "CLASS Watchdog trigered"},
    {HM_EVT_WDT_EMAC0_GPI, "EMAC0 GPI Watchdog trigered"},
    {HM_EVT_WDT_EMAC1_GPI, "EMAC1 GPI Watchdog trigered"},
    {HM_EVT_WDT_EMAC2_GPI, "EMAC2 GPI Watchdog trigered"},
    {HM_EVT_WDT_HIF_GPI, "HIF GPI Watchdog trigered"},
    {HM_EVT_WDT_HIF_NOCPY, "HIF NOCPY Watchdog trigered"},
    {HM_EVT_WDT_HIF, "HIF Watchdog trigered"},
    {HM_EVT_WDT_TLITE, "TLITE Watchdog trigered"},
    {HM_EVT_WDT_UTIL_PE, "UTIL Watchdog trigered"},
    {HM_EVT_WDT_EMAC0_ETGPI, "EMAC0 ETGPI Watchdog trigered"},
    {HM_EVT_WDT_EMAC1_ETGPI, "EMAC1 ETGPI Watchdog trigered"},
    {HM_EVT_WDT_EMAC2_ETGPI, "EMAC2 ETGPI Watchdog trigered"},
    {HM_EVT_WDT_EXT_GPT1, "EXT GPT1 Watchdog trigered"},
    {HM_EVT_WDT_EXT_GPT2, "EXT GPT1 Watchdog trigered"},
    {HM_EVT_WDT_LMEM, "LMEM Watchdog trigered"},
    {HM_EVT_WDT_ROUTE_LMEM, "ROUTE LMEM Watchdog trigered"},

    {HM_EVT_EMAC_ECC_TX_FIFO_CORRECTABLE, "MTL Tx memory correctable error"},
    {HM_EVT_EMAC_ECC_TX_FIFO_UNCORRECTABLE, "MTL Tx memory uncorrectable error"},
    {HM_EVT_EMAC_ECC_TX_FIFO_ADDRESS, "MTL Tx memory address mismatch error"},
    {HM_EVT_EMAC_ECC_RX_FIFO_CORRECTABLE, "MTL Rx memory correctable error"},
    {HM_EVT_EMAC_ECC_RX_FIFO_UNCORRECTABLE, "MTL Rx memory uncorrectable error"},
    {HM_EVT_EMAC_ECC_RX_FIFO_ADDRESS, "MTL Rx memory address mismatch error"},
    {HM_EVT_EMAC_APP_TX_PARITY, "Application transmit interface parity error"},
    {HM_EVT_EMAC_APP_RX_PARITY, "Application receive interface parity error"},
    {HM_EVT_EMAC_MTL_PARITY, "MTL data path parity error"},
    {HM_EVT_EMAC_FSM_PARITY, "FSM state parity error"},
    {HM_EVT_EMAC_MASTER_TIMEOUT, "Master Read/Write timeout error"},
    {HM_EVT_EMAC_FSM_TX_TIMEOUT, "Tx FSM timeout error"},
    {HM_EVT_EMAC_FSM_RX_TIMEOUT, "Rx FSM timeout error"},
    {HM_EVT_EMAC_FSM_APP_TIMEOUT, "APP FSM timeout error"},
    {HM_EVT_EMAC_FSM_APP_TIMEOUT, "PTP FSM timeout error"},

    {HM_EVT_BUS_MASTER1, "Master1 bus read error"},
    {HM_EVT_BUS_MASTER2, "Master2 bus write error"},
    {HM_EVT_BUS_MASTER3, "Master3 bus write error"},
    {HM_EVT_BUS_MASTER4, "Master4 bus read error"},
    {HM_EVT_BUS_HGPI_READ, "HGPI bus read error"},
    {HM_EVT_BUS_HGPI_WRITE, "HGPI bus write error"},
    {HM_EVT_BUS_EMAC0_READ, "EMAC 0 bus read error"},
    {HM_EVT_BUS_EMAC0_WRITE, "EMAC 0 bus write error"},
    {HM_EVT_BUS_EMAC1_READ, "EMAC 1 bus read error"},
    {HM_EVT_BUS_EMAC1_WRITE, "EMAC 1 bus write error"},
    {HM_EVT_BUS_EMAC2_READ, "EMAC 2 bus read error"},
    {HM_EVT_BUS_EMAC2_WRITE, "EMAC 2 bus write error"},
    {HM_EVT_BUS_CLASS_READ, "Class bus read error"},
    {HM_EVT_BUS_CLASS_WRITE, "Class bus write error"},
    {HM_EVT_BUS_HIF_NOCPY_READ, "HIF_NOCPY bus read error"},
    {HM_EVT_BUS_HIF_NOCPY_WRITE, "HIF_NOCPY bus write error"},
    {HM_EVT_BUS_TMU, "TMU bus read error"},
    {HM_EVT_BUS_FET, "FET bus read error"},
    {HM_EVT_BUS_UTIL_PE_READ, "Util PE bus read error"},
    {HM_EVT_BUS_UTIL_PE_WRITE, "Util PE bus write error"},

    {HM_EVT_PARITY_MASTER1, "MASTER1_INT-Master1 Parity error"},
    {HM_EVT_PARITY_MASTER2, "MASTER2_INT-Master2 Parity error"},
    {HM_EVT_PARITY_MASTER3, "MASTER3_INT-Master3 Parity error"},
    {HM_EVT_PARITY_MASTER4, "MASTER4_INT-Master4 Parity error"},
    {HM_EVT_PARITY_EMAC_CBUS, "EMAC_CBUS_INT-EMACX cbus parity error"},
    {HM_EVT_PARITY_EMAC_DBUS, "EMAC_DBUS_INT-EMACX dbus parity error"},
    {HM_EVT_PARITY_CLASS_CBUS, "CLASS_CBUS_INT-Class cbus parity error"},
    {HM_EVT_PARITY_CLASS_DBUS, "CLASS_DBUS_INT-Class dbus parity error"},
    {HM_EVT_PARITY_TMU_CBUS, "TMU_CBUS_INT-TMU cbus parity error"},
    {HM_EVT_PARITY_TMU_DBUS, "TMU_DBUS_INT-TMU dbus parity error"},
    {HM_EVT_PARITY_HIF_CBUS, "HIF_CBUS_INT-HGPI cbus parity error"},
    {HM_EVT_PARITY_HIF_DBUS, "HIF_DBUS_INT-HGPI dbus parity error"},
    {HM_EVT_PARITY_HIF_NOCPY_CBUS, "HIF_NOCPY_CBUS_INT-HIF_NOCPY cbus parity error"},
    {HM_EVT_PARITY_HIF_NOCPY_DBUS, "HIF_NOCPY_DBUS_INT-HIF_NOCPY dbus parity error"},
    {HM_EVT_PARITY_UPE_CBUS, "UPE_CBUS_INT-UTIL_PE cbus parity error"},
    {HM_EVT_PARITY_UPE_DBUS, "UPE_DBUS_INT-UTIL_PE dbus parity error"},
    {HM_EVT_PARITY_HRS_CBUS, "HRS_CBUS_INT-HRS cbus parity error"},
    {HM_EVT_PARITY_BRIDGE_CBUS, "BRIDGE_CBUS_INT-BRIDGE cbus parity error"},
    {HM_EVT_PARITY_EMAC_SLV, "EMAC_SLV_INT-EMACX slave parity error"},
    {HM_EVT_PARITY_BMU1_SLV, "BMU1_SLV_INT-BMU1 slave parity error"},
    {HM_EVT_PARITY_BMU2_SLV, "BMU2_SLV_INT-BMU2 slave parity error"},
    {HM_EVT_PARITY_CLASS_SLV, "CLASS_SLV_INT-CLASS slave parity error"},
    {HM_EVT_PARITY_HIF_SLV, "HIF_SLV_INT-HIF slave parity error"},
    {HM_EVT_PARITY_HIF_NOCPY_SLV, "HIF_NOCPY_SLV_INT-HIF_NOCPY slave parity error"},
    {HM_EVT_PARITY_LMEM_SLV, "LMEM_SLV_INT-LMEM slave parity error"},
    {HM_EVT_PARITY_TMU_SLV, "TMU_SLV_INT-TMU slave parity error"},
    {HM_EVT_PARITY_UPE_SLV, "UPE_SLV_INT-UTIL_PE slave parity error"},
    {HM_EVT_PARITY_WSP_GLOBAL_SLV, "WSP_GLOBAL_SLV_INT-WSP_GLOBAL slave parity error"},
    {HM_EVT_PARITY_GPT1_SLV, "GPT1 slave parity error"},
    {HM_EVT_PARITY_GPT2_SLV, "GPT2 slave parity error"},
    {HM_EVT_PARITY_ROUTE_LMEM_SLV, "Route LMEM slave parity error"},

    {HM_EVT_FAIL_STOP_PARITY, "Fail Stop: the Parity error int"},
    {HM_EVT_FAIL_STOP_WATCHDOG, "Fail Stop: the Watchdog timer error int"},
    {HM_EVT_FAIL_STOP_BUS, "Fail Stop: the Bus error int"},
    {HM_EVT_FAIL_STOP_ECC_MULTIBIT, "Fail Stop: the ECC multi bit error int"},
    {HM_EVT_FAIL_STOP_FW, "Fail Stop: the FW failstop int"},
    {HM_EVT_FAIL_STOP_HOST, "Fail Stop: the Host Fail Stop int"},

    {HM_EVT_FW_FAIL_STOP, "FW Fail Stop mode interrupt"},
    {HM_EVT_HOST_FAIL_STOP, "Host Fail Stop mode interrupt"},

    {HM_EVT_BMU_FREE_ERR, "Failed to free buffer"},
    {HM_EVT_BMU_FULL, "All buffers are allocated, pool depleted"},
    {HM_EVT_BMU_MCAST, "BMU_MCAST_EMTPY_INT or BMU_MCAST_FULL_INT or BMU_MCAST_THRES_INT or BMU_MCAST_FREE_ERR_INT triggered"},
#endif

    {HM_EVT_PE_STALL, "PE core stalled"},
    {HM_EVT_PE_EXCEPTION, "PE core raised exception"},
    {HM_EVT_PE_ERROR, "PE core reported error"},

    {HM_EVT_HIF_ERR, "HIF error interrupt"},
    {HM_EVT_HIF_TX_FIFO, "HIF TX FIFO error interrupt"},
    {HM_EVT_HIF_RX_FIFO, "HIF RX FIFO error interrupt"},
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
#define ETH_43_PFE_START_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"
static const char *hm_src_strings[] = {
    "UNKNOWN",
    "DRIVER",
    "WDT",
    "EMAC0",
    "EMAC1",
    "EMAC2",
    "BUS",
    "PARITY",
    "FAIL_STOP",
    "FW_FAIL_STOP",
    "HOST_FAIL_STOP",
    "ECC",
    "PE_CLASS",
    "PE_UTIL",
    "PE_TMU",
    "HIF",
    "BMU",
};
#define ETH_43_PFE_STOP_SEC_VAR_INIT_32
#include "Eth_43_PFE_MemMap.h"
#endif /* NXP_LOG_ENABLED */

/*==============================================================================
                           LOCAL FUNCTION PROTOTYPES
==============================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
static errno_t pfe_hm_put(const pfe_hm_item_t *item);

/*==============================================================================
                                LOCAL FUNCTIONS
==============================================================================*/
/**
 * @brief       Put event to the HM event queue
 *
 * @param[in]   item Pointer to event which need to be written in HM queue
 * @returns     EOK if suceeded, EOVERFLOW otherwise
 */
static errno_t pfe_hm_put(const pfe_hm_item_t *item)
{
    errno_t ret = EOVERFLOW;

    (void)oal_mutex_lock(PFE_HM_MUTEX_00);

    if (pfe_hm.len < ARRAY_LEN(pfe_hm.items))
    {
        (void)autolibc_memcpy(&pfe_hm.items[pfe_hm.end], item, sizeof(pfe_hm_item_t));

        pfe_hm.len++;
        pfe_hm.end++;
        if (pfe_hm.end >= ARRAY_LEN(pfe_hm.items))
        {
            pfe_hm.end = 0U;
        }
        ret = EOK;
    }

    (void)oal_mutex_unlock(PFE_HM_MUTEX_00);

    return ret;
}

/**
 * @brief   Initializes the HM module
 */
void pfe_hm_init(void)
{
    pfe_hm.start = 0;
    pfe_hm.end = 0;
    pfe_hm.len = 0;
    pfe_hm.initialized = TRUE;
    pfe_hm.event_cb = NULL;
}

/**
 * @brief   Destroys the HM module
 */
void pfe_hm_destroy(void)
{
    if (TRUE == pfe_hm.initialized)
    {
        pfe_hm.initialized = FALSE;
    }
}

/**
 * @brief   Logs the event into the database and stdout
 *
 * @param[in]   src     Source module of the event
 * @param[in]   type    Type of the event
 * @param[in]   id      ID of the event
 * @param[in]   format  NULL or printf like formatted string
 */
void pfe_hm_report(pfe_hm_src_t src, pfe_hm_type_t type, pfe_hm_evt_t id, const char *format, ...)
{
    errno_t ret = EOVERFLOW;
    pfe_hm_item_t item;
#ifdef NXP_LOG_ENABLED
    const char *separator = "";
    const char *event_str = pfe_hm_get_event_str(id);
    const char *src_str = pfe_hm_get_src_str(src);
    va_list args;

    va_start(args, format);

    item.descr[0U] = '\0';
    if ((NULL != format) && (0U != autolibc_strlen(format)))
    {
        separator = ": ";
        nxp_vsnprintf(item.descr, ARRAY_LEN(item.descr), format, args);
        item.descr[ARRAY_LEN(item.descr)-1U] = '\0';
    }

    va_end(args);

    switch (type)
    {
        case HM_INFO:
            NXP_LOG_HM("INF_HM: (%s) event %d - %s%s%s\n", src_str, (int)id, event_str, separator, item.descr);
            break;
        case HM_WARNING:
            NXP_LOG_HM("WRN_HM: (%s) event %d - %s%s%s\n", src_str, (int)id, event_str, separator, item.descr);
            break;
        case HM_ERROR:
            if( id == HM_EVT_RUNTIME)
            {
                /* This is to make it more user-friendly than (DRIVER) event 1 - Driver runtime error */
                NXP_LOG_HM("ERR_HM RUNTIME%s%s\n", separator, item.descr);
            }
            else
            {
                NXP_LOG_HM("ERR_HM: (%s) event %d - %s%s%s\n", src_str, (int)id, event_str, separator, item.descr);
            }
            break;
        default:
            /* Do Nothing */
            break;
    }
#else
    (void)format;
#endif /* NXP_LOG_ENABLED */

    item.type = type;
    item.src = src;
    item.id = id;

    if (TRUE == pfe_hm.initialized)
    {
        ret = pfe_hm_put(&item);
        if (EOK != ret)
        {
            NXP_LOG_WARNING("HM event storage is full, no further events will be stored.\n");
        }
    }

    if (NULL != pfe_hm.event_cb)
    {
        pfe_hm.event_cb(&item);
    }
}

/**
 * @brief       Gets first event from the HM event queue
 *
 * @param[out]  item Memory area to store event to
 * @returns     EOK if suceeded, ENOENT otherwise
 */
errno_t pfe_hm_get(pfe_hm_item_t *item)
{
    errno_t ret = ENOENT;

    if (TRUE == pfe_hm.initialized)
    {
        (void)oal_mutex_lock(PFE_HM_MUTEX_01);

        if (0U != pfe_hm.len)
        {
            (void)autolibc_memcpy(item, &pfe_hm.items[pfe_hm.start], sizeof(pfe_hm_item_t));
    
            pfe_hm.len--;
            pfe_hm.start++;
            if (pfe_hm.start >= ARRAY_LEN(pfe_hm.items))
            {
                pfe_hm.start = 0;
            }
            ret = EOK;
        }

        (void)oal_mutex_unlock(PFE_HM_MUTEX_01);
    }

    return ret;
}

/**
 * @brief   Registers callback for new events
 *
 * @param[in]   cb Callback
 * @returns Successfulness of the registration
 */
bool_t pfe_hm_register_event_cb(pfe_hm_cb_t cb)
{
    bool_t ret = FALSE;

    if (NULL == pfe_hm.event_cb)
    {
        pfe_hm.event_cb = cb;
        ret = TRUE;
    }
    return ret;
}

#ifdef NXP_LOG_ENABLED
/**
 * @brief   Converts event ID to string representation
 * @param[in]   id ID of the event
 * @returns Corresponding string or empty string
 */
const char *pfe_hm_get_event_str(pfe_hm_evt_t id)
{
    uint32 i;
    const char* ret = "";
    for (i = 0; i < ARRAY_LEN(hm_evt_strings); i++)
    {
        if (hm_evt_strings[i].id == id)
        {
            ret = hm_evt_strings[i].str;
            break;
        }
    }
    return ret;
}

/**
 * @brief   Converts source ID to string representation
 * @param[in]   src Source of the event
 * @returns Corresponding string or empty string
 */
const char *pfe_hm_get_src_str(pfe_hm_src_t src)
{
    const char* ret = "";

    if ((uint32)src >= ARRAY_LEN(hm_src_strings))
    {
        ret = "";
    }
    else
    {
        ret = hm_src_strings[src];
    }

    return ret;
}
#endif /* NXP_LOG_ENABLED */
#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [161/185]: src\pfe_host_fail_stop.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2022-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_host_fail_stop.h"
#include "pfe_host_fail_stop_csr.h"


struct pfe_host_fail_stop_tag
{
    addr_t cbus_base_va;
    addr_t host_fail_stop_base_offset;
    addr_t host_fail_stop_base_va;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_host_fail_stop_t host_fail_stop_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create new SAFETY_HOST_FAIL_STOP instance
 * @details     Create and initializes SAFETY_HOST_FAIL_STOP instance. New instance is always enabled.
 *              Use mask and unmask function to control interrupts.
 * @param[in]   base_va SAFETY_HOST_FAIL_STOP register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Interrupt which were triggered are masked here, it is periodically unmasked again in SAFETY thread
 */
pfe_host_fail_stop_t *pfe_host_fail_stop_create(addr_t cbus_base_va, addr_t host_fail_stop_base)
{
    pfe_host_fail_stop_t *host_fail_stop;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        host_fail_stop = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        host_fail_stop = &host_fail_stop_instance;
        (void)autolibc_memset(host_fail_stop, 0, sizeof(pfe_host_fail_stop_t));
        host_fail_stop->cbus_base_va = cbus_base_va;
        host_fail_stop->host_fail_stop_base_offset = host_fail_stop_base;
        host_fail_stop->host_fail_stop_base_va = ADDR_BASE_OFFSET(host_fail_stop->cbus_base_va, host_fail_stop->host_fail_stop_base_offset);

        /* Unmask all interrupts */
        pfe_host_fail_stop_cfg_irq_unmask_all(host_fail_stop->host_fail_stop_base_va);
    }
    return host_fail_stop;
}

/**
 * @brief       Destroy SAFETY_HOST_FAIL_STOP instance
 * @param[in]   host_fail_stop The SAFETY_HOST_FAIL_STOP instance
 */
void pfe_host_fail_stop_destroy(pfe_host_fail_stop_t *host_fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == host_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Mask host_fail_stop interrupts */
        pfe_host_fail_stop_cfg_irq_mask(host_fail_stop->host_fail_stop_base_va);
    }
}

/**
 * @brief       SAFETY_HOST_FAIL_STOP ISR
 * @param[in]   host_fail_stop The SAFETY_HOST_FAIL_STOP instance
 * @return      EOK if interrupt has been handled
 */
errno_t pfe_host_fail_stop_isr(const pfe_host_fail_stop_t *host_fail_stop)
{
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == host_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = ENOMEM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_host_fail_stop_cfg_isr(host_fail_stop->host_fail_stop_base_va);
    }

    return ret;
}

/**
 * @brief       Mask SAFETY_HOST_FAIL_STOP interrupts
 * @param[in]   host_fail_stop The SAFETY_HOST_FAIL_STOP instance
 */
void pfe_host_fail_stop_irq_mask(const pfe_host_fail_stop_t *host_fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == host_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_host_fail_stop_cfg_irq_mask(host_fail_stop->host_fail_stop_base_va);
    }
}

/**
 * @brief       Unmask SAFETY_HOST_FAIL_STOP interrupts
 * @param[in]   host_fail_stop The SAFETY_HOST_FAIL_STOP instance
 */
void pfe_host_fail_stop_irq_unmask(const pfe_host_fail_stop_t *host_fail_stop)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == host_fail_stop))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_host_fail_stop_cfg_irq_unmask(host_fail_stop->host_fail_stop_base_va);
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [162/185]: src\pfe_host_fail_stop_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2023-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_host_fail_stop_csr.h"
#include "pfe_global_wsp.h"
#include "Eth_43_PFE_Cfg.h"

#define TRIG_EN_INTERRUPTS_CHECK    (HOST_FORCE_DEBUG_FAIL_STOP_INT | HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT)

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       HOST_FAIL_STOP ISR
 * @details     MASK, ACK, and process triggered interrupts.
 * @param[in]   base_va HOST_FAIL_STOP register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 */
errno_t pfe_host_fail_stop_cfg_isr(addr_t base_va)
{
    uint32 reg_en, reg_src;
    errno_t ret = ENOENT;
    uint32 trig_en_interrupts;

    /* Get enabled interrupts */
    reg_en = hal_read32(base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN);
    /* Mask Host Failstop interrupts */
    hal_write32((reg_en & ~(HOST_FORCE_DEBUG_FAIL_STOP_INT_EN)), base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN);
    /* Get triggered interrupts */
    reg_src = hal_read32(base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_SRC);
    /* ACK triggered interrupts */
    hal_write32(reg_src, base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_SRC);

    /* Process interrupts which are triggered AND enabled */
    trig_en_interrupts = reg_src & reg_en & TRIG_EN_INTERRUPTS_CHECK;
    if (0U != trig_en_interrupts)
    {
        pfe_hm_report_error(HM_SRC_HOST_FAIL_STOP, HM_EVT_HOST_FAIL_STOP, "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
        (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_FAIL_STOP_SW_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
        ret = EOK;
    }

    /* Enable the non-triggered ones only to prevent flooding */
    hal_write32((reg_en & ~reg_src), base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN);

    return ret;
}

/**
 * @brief       Mask HOST_FAIL_STOP interrupts
 * @param[in]   base_va Base address of the HOST_FAIL_STOP register space
 */
void pfe_host_fail_stop_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN) & ~(HOST_FORCE_DEBUG_FAIL_STOP_INT_EN);
    hal_write32(reg, base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN);
}

/**
 * @brief       Unmask HOST_FAIL_STOP interrupts
 * @param[in]   base_va Base address of the HOST_FAIL_STOP register space
 */
void pfe_host_fail_stop_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN) | HOST_FORCE_DEBUG_FAIL_STOP_INT_EN;
    hal_write32(reg, base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN);
}

/**
 * @brief       Unmask all HOST_FAIL_STOP interrupts
 * @param[in]   base_va Base address of the HOST_FAIL_STOP register space
 * @note        This function is called from thread.
 */
void pfe_host_fail_stop_cfg_irq_unmask_all(addr_t base_va)
{
    hal_write32(HOST_FORCE_DEBUG_FAIL_STOP_INT_ENABLE_ALL, base_va + WSP_HOST_FORCE_DEBUG_FAIL_STOP_MODE_INT_EN);   /*direct write*/
}
/*==================================================================================================*/

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [163/185]: src\pfe_hw_feature.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "pfe_class.h"
#include "pfe_hw_feature.h"
#include "pfe_feature_mgr.h"
#include "pfe_platform.h"
#include "pfe_cbus.h"
#include "pfe_global_wsp.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief Creates a feature instance
 * @return The created feature instance or NULL in case of failure
 */
static pfe_hw_feature_t *pfe_hw_feature_create(const char *name, const char *descr, pfe_ct_feature_flags_t flags, uint8 def_val, pfe_hw_feature_t *feature)
{
    if(NULL != feature)
    {
        (void)autolibc_memset(feature, 0, sizeof(pfe_hw_feature_t));
        feature->name = name;
        feature->description = descr;
        feature->flags = flags;
        feature->def_val = def_val;
        feature->val = def_val;
    }
    else
    {
        NXP_LOG_ERROR("Cannot allocate %u bytes of memory for feature\n", (uint_t)sizeof(pfe_hw_feature_t));
    }
    return feature;
}

errno_t pfe_hw_feature_init_all(const uint32 *cbus_base, pfe_hw_feature_t *hw_features, uint32 *hw_features_count)
{
    errno_t           ret;
    uint32          val;
    pfe_hw_feature_t *feature;
    uint8           on_g3 = 0U;

    feature = pfe_hw_feature_create(PFE_HW_FEATURE_RUN_ON_G3, "Active if running on S32G3", F_PRESENT, 0, &hw_features[0]);
    if (NULL != feature)
    {
        /*      Detect S32G silicon version */
        val = hal_read32((addr_t)CBUS_GLOBAL_CSR_BASE_ADDR + (addr_t)WSP_VERSION + (addr_t)cbus_base);
        if (0x00050300U == val)
        { /* S32G2 */
            NXP_LOG_INFO("Silicon S32G2\n");
        }
        else if (0x00000101U == val)
        { /* S32G3 */
            on_g3 = 1U;
            NXP_LOG_INFO("Silicon S32G3\n");
        }
        else
        { /* Unknown */
            NXP_LOG_ERROR("Silicon HW version is unknown: 0x%x\n", (uint_t)val);
        }

        (void)pfe_hw_feature_set_val(feature, on_g3);

        *hw_features_count = 1U;
        ret = EOK;
    }
    else
    {
        ret = ENOMEM;
    }

    if (EOK == ret)
    {
        feature = pfe_hw_feature_create("jumbo_frames", "Active if we handle jumbo frames", F_NONE, 0, &hw_features[1]);
        if (NULL != feature)
        {
            *hw_features_count = 2U;
        }
        else
        {
            ret = ENOMEM;
        }
    }

    return ret;
}
/**
 * @brief Returns name of the feature
 * @param[in] feature Feature to be read.
 * @param[out] name The feature name to be read.
 * @return EOK or an error code.
 */
errno_t pfe_hw_feature_get_name(const pfe_hw_feature_t *feature, const char **name)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *name = feature->name;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Returns the feature description provide by the firmware.
 * @param[in] feature Feature to be read.
 * @param[out] desc Descripton of the feature
 * @return EOK or an error code.
 */
errno_t pfe_hw_feature_get_desc(const pfe_hw_feature_t *feature, const char **desc)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == desc)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *desc = feature->description;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads the flags of the feature
 * @param[in] feature Feature to be read
 * @param[out] flags Value of the feature flags
 * @return EOK or an error code.
 */
errno_t pfe_hw_feature_get_flags(const pfe_hw_feature_t *feature, pfe_ct_feature_flags_t *flags)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == flags)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *flags = feature->flags;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads the default value of the feature i.e. initial value set by the FW
 * @param[in] feature Feature to read the value
 * @param[out] def_val The read default value.
 * @return EOK or an error code.
 */
errno_t pfe_hw_feature_get_def_val(const pfe_hw_feature_t *feature, uint8 *def_val)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == def_val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *def_val = feature->def_val;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads value of the feature enable variable
 * @param[in] Feature to read the value
 * @param[out] val Value read from the DMEM
 * @return EOK or an error code.
 */
errno_t pfe_hw_feature_get_val(const pfe_hw_feature_t *feature, uint8 *val)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == feature) || (NULL == val)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *val = feature->val;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Checks whether the given feature is in enabled state
 * @param[in] feature Feature to check the enabled state
 * @retval TRUE Feature is enabled (the enable variable value is not 0)
 * @retval FALSE Feature is disabled (or its state could not be read)
 */
bool_t pfe_hw_feature_enabled(const pfe_hw_feature_t *feature)
{
    uint8 val;
    errno_t ret;
    bool_t  is_enable;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_enable = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_hw_feature_get_val(feature, &val);
        if (EOK != ret)
        {
            is_enable = FALSE;
        }
        else if (0U != val)
        {
            is_enable = TRUE;
        }
        else
        {
            is_enable = FALSE;
        }
    }
    return is_enable;
}

/**
 * @brief Sets value of the feature enable variable in the DMEM
 * @param[in] feature Feature to set the value
 * @param[in] val Value to be set
 * @return EOK or an error code.
 */
errno_t pfe_hw_feature_set_val(pfe_hw_feature_t *feature, uint8 val)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == feature))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        feature->val = val;
        ret = EOK;
    }
    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [164/185]: src\pfe_idex.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/
#include "pfe_cfg.h"
#include "oal.h"

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
#include "linked_list.h"
#include "pfe_hif_drv.h"
#include "pfe_hif.h"
#include "pfe_idex.h"
#include "pfe_platform_rpc.h"
#include "pfe_platform_cfg.h"

/*==================================================================================================
*                                       LOCAL MACROS
==================================================================================================*/
#define IDEX_IS_NOCPY (4 == PFE_CFG_LOCAL_IF_VALUE)
/**
 * @brief Maximum HIF clients to handle in IDEX server
 */
#define IDEX_MAX_CLIENTS    (4)
/**
 * @brief Enable debug diagnostic messages from IDEX
 */
/* #define IDEX_CFG_VERBOSE */
/**
 * @brief RESET request/response RPC_ID for IDEX 2.0
    Using for synchronization of sequence number and for IDEX version negotiation
 */
#define IDEX_RESET_RPC_ID   (0xFFFFFFFFU)

/**
 * @brief    IDEX request timeout in milliseconds between resending [DID-AAVBR-980m-MCAL]
 */
#ifndef PFE_CFG_IDEX_RESEND_DELAY_MS
#define PFE_CFG_IDEX_RESEND_DELAY_MS   (100U)
#endif

/**
 * @brief   IDEX request maximum retry count
 */
#ifndef PFE_CFG_IDEX_RESEND_COUNT
#define PFE_CFG_IDEX_RESEND_COUNT   (40U)
#endif

/**
 * @brief TODO: The cast macros below shall be replaced by it's safer variant - cyber-security topic.
 * 
*/
#define UNSAFE_CAST_INT_TO_UINT8(value) ((uint8)(value))
#define UNSAFE_CAST_INT_TO_UINT16(value) ((uint16)(value))
#define UNSAFE_CAST_INT_TO_UINT32(value) ((uint32)(value))

/**
 * @brief Add A, B and mask integer overflow after add math operation
 */
#define ADDU32_WRAP(A, B) (uint32)(((uint64)(A) + (uint64)(B)) & UINT32_MAX)

/**
 * @brief Useful in the interrupt mode to qualify certain data as volatile
 */
#if (TRUE == PFE_CFG_HIF_IRQ_ENABLED)
#define USE_VOLATILE    volatile
#else
#define USE_VOLATILE
#endif

/*==================================================================================================
*                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/
/**
 * @brief       IDEX sequence number type
 */
typedef uint32 pfe_idex_seqnum_t;

ct_assert(sizeof(pfe_idex_seqnum_t) == sizeof(uint32));

/**
 * @brief        IDEX version number for features improvement
 */
typedef enum __attribute__((packed))
{
    IDEX_VERSION_1 = 1U,
    IDEX_VERSION_2 = 2U
} pfe_idex_version_t;

ct_assert(sizeof(pfe_idex_version_t) == sizeof(uint8));

/**
 * @brief   IDEX Frame types
 */
typedef enum __attribute__((packed))
{
    /**
     * @brief Request. Frames of this type are expected to be responded by a remote instance
     */
    IDEX_FRAME_CTRL_REQUEST = 0U,
    /**
     * @brief Response. Contains information about remote result
     */
    IDEX_FRAME_CTRL_RESPONSE = 1U,
    /*  Dummy/invalid frame, not intended to be processed when received */
    IDEX_FRAME_CTRL_DUMMY = 100
} pfe_idex_frame_type_t;

ct_assert(sizeof(pfe_idex_frame_type_t) == sizeof(uint8));

/**
 * @brief   IDEX Request message types
 */
typedef enum __attribute__((packed))
{
    /**
     * @brief Master discovery message. Not used or implemented
     */
    IDEX_MASTER_DISCOVERY = 0U,
    /**
     * @brief RPC request for calling RPC function
     */
    IDEX_RPC = 1U
} pfe_idex_request_type_t;

ct_assert(sizeof(pfe_idex_request_type_t) == sizeof(uint8));

/**
 * @brief   IDEX Response types
 */
typedef pfe_idex_request_type_t pfe_idex_response_type_t;

ct_assert(sizeof(pfe_idex_response_type_t) == sizeof(uint8));
/**
 * @brief   RESET Request/Response for IDEX 2.0
 */
typedef struct __attribute__((packed))
{
    /* Reset seq number to this value */
    pfe_idex_seqnum_t seqnum;
    /* Version of IDEX for backward and forward compatibility */
    pfe_idex_version_t version;
} pfe_idex_msg_reset_t;

ct_assert(sizeof(pfe_idex_msg_reset_t) == (sizeof(uint32) + sizeof(uint8)));

/**
 * @brief   IDEX RPC Message header
 */
typedef struct __attribute__((packed))
{
    /*  Custom RPC ID */
    uint32 rpc_id;
    /*  Return value */
    errno_t rpc_ret;
    /*  Payload length */
    uint16 plen;
} pfe_idex_msg_rpc_t;

ct_assert(sizeof(errno_t) == sizeof(uint32));

/**
 * @brief   IDEX Frame Header
 */
typedef struct __attribute__((packed))
{
    /*  Destination physical interface ID */
    pfe_ct_phy_if_id_t dst_phy_if;
    /*  Type of frame */
    pfe_idex_frame_type_t type;
} pfe_idex_frame_header_t;

ct_assert(sizeof(pfe_idex_frame_header_t) == 2);

/**
 * @brief   IDEX request states
 */
typedef enum __attribute__((packed))
{
    /*  New request which is not active. Can't be destroyed or timed-out. */
    IDEX_REQ_STATE_NEW = 0U,
    /*    Request committed for transmission. Can be timed-out. */
    IDEX_REQ_STATE_COMMITTED,
    /*  Finished request */
    IDEX_REQ_STATE_COMPLETED,
    /*  Invalid request. Will be destroyed be cleanup task. */
    IDEX_REQ_STATE_INVALID = 0xffU,
} pfe_idex_request_state_t;

ct_assert(sizeof(pfe_idex_request_state_t) == sizeof(uint8));

/**
 * @brief   IDEX Request Header. Also used as request instance.
 * @details IDEX Request Frame:
 *          +--------------------------------------------------+
 *          |   IDEX Header (pfe_idex_frame_header_t)          |
 *          +--------------------------------------------------+
 *          |   IDEX Request Header (pfe_idex_request_t)       |
 *          +--------------------------------------------------+
 *          |   IDEX Request message (pfe_idex_msg_*_t)        |
 *          +--------------------------------------------------+
 */
typedef struct __attribute__((packed))
{
    /*  Unique sequence number */
    pfe_idex_seqnum_t seqnum;
    /*  Type of message. Specifies format of the payload. */
    pfe_idex_request_type_t type;
    /*  Destination PHY */
    pfe_ct_phy_if_id_t dst_phy_id;
    /*  Request state */
    USE_VOLATILE pfe_idex_request_state_t state;
    /*    Padding only to keep compatibility, not used */
    uint8 padding[30U];
} pfe_idex_request_t;

ct_assert(sizeof(pfe_idex_request_t) == 37);

/**
 * @brief   IDEX Response Header. Also used as response instance.
 * @details IDEX Response Frame:
 *          +--------------------------------------------------+
 *          |   IDEX Header (pfe_idex_frame_header_t)          |
 *          +--------------------------------------------------+
 *          |   IDEX Response Header (pfe_idex_response_t)     |
 *          +--------------------------------------------------+
 *          |   IDEX Response message (pfe_idex_msg_*_t)       |
 *          +--------------------------------------------------+
 */
typedef struct __attribute__((packed))
{
    /*  Sequence number matching request which the response is dedicated for */
    pfe_idex_seqnum_t seqnum;
    /*  Type of message. Specifies format of the payload. */
    pfe_idex_response_type_t type;
    /*  Payload length in number of bytes */
    uint16 plen;
} pfe_idex_response_t;

ct_assert(sizeof(pfe_idex_response_t) == 7);

/**
 * @brief    This is IDEX Client structure for Master to save information about Slave
 */
typedef struct
{
    pfe_idex_seqnum_t seqnum;      /*    Current sequence number [DID-AAVBR-980c-MCAL] */
    pfe_idex_version_t version;    /*    IDEX version, for backward compatibility */
    pfe_ct_phy_if_id_t phy_id;     /*    Physical interface of the client */
    pfe_idex_response_t *response; /*    Last IDEX response for resending in case of same seqnum */
    pfe_idex_msg_rpc_t rpc_msg;    /*    Current IDEX RPC message request */
} pfe_remote_client_t;

/**
 * @brief    This is IDEX Server structure for Client to save information about Master
 */
typedef struct
{
    pfe_idex_seqnum_t seqnum;    /*    Current sequence number [DID-AAVBR-980c-MCAL] */
    pfe_idex_version_t version;  /*    IDEX version, for backward compatibility */
    pfe_ct_phy_if_id_t phy_id;   /*    Physical interface of the server */
    pfe_idex_request_t *request; /*    Current IDEX request */
    pfe_idex_msg_rpc_t *rpc_msg; /*    Current IDEX RPC message response */
} pfe_remote_server_t;

/**
 * @brief   This is IDEX instance representation type
 */
typedef struct
{
    pfe_hif_drv_client_t *ihc_client;              /*  HIF driver IHC client used for communication [DID-AAVBR-980b-MCAL] */
    pfe_idex_rpc_cbk_t rpc_cbk;                    /*  Callback to be called in case of RPC requests */
    void *rpc_cbk_arg;                             /*  RPC callback argument */
    pfe_hif_t *hif;                                /*  HIF module, for Master-up signaling */
    bool_t is_server;                              /*  IDEX is acting as server when TRUE    */
    bool_t is_up;                                  /*  TRUE if HIF connection is UP */
    struct
    {
        pfe_remote_server_t server;                    /*  Client has Server information */
        pfe_remote_client_t clients[IDEX_MAX_CLIENTS]; /*  Server has information about every client */
    } remote;
    oal_mutex_t rpc_req_lock;                      /*  Requests mutex blocking communication */
    bool_t rpc_req_lock_init;                      /*  Flag indicating that mutex is initialized */
    /**
     * @brief Free running statistics counters - can be exposed in future. Reset during pfe_idex_init()
     */
    struct {
        uint32 rx_count;
        uint32 rx_aliens;
        uint32 rx_dups;
        uint32 rx_unknowns;
        uint32 rx_fails;
        uint32 tx_count;
        uint32 tx_retries;
        uint32 tx_max_retries;
        uint32 tx_skips;
    } stats;
} pfe_idex_t;

/* IMG-EPP.HW_Technical_Reference_Manual_10.pdf page 39 */
#define IMG_EPP_MAX_PACKET_SIZE 1522

/**
 * @brief Type used to create properly sized buffer for pfe_idex_rpc calls
 */
typedef struct __attribute__((packed))
{
    pfe_ct_hif_tx_hdr_t hif_tx_hdr;
    pfe_idex_frame_header_t frame_header;
    pfe_idex_request_t req;
    pfe_idex_msg_rpc_t msg; /* IDEX RPC Message header */
    uint8 arg[IMG_EPP_MAX_PACKET_SIZE - sizeof(pfe_idex_frame_header_t) - sizeof(pfe_idex_request_t) - sizeof(pfe_idex_msg_rpc_t)];
} pfe_idex_request_frame_t;

/**
 * @brief Type used to create properly sized buffer for pfe_idex_set_rpc_ret_val calls
 */
typedef struct __attribute__((packed))
{
    pfe_ct_hif_tx_hdr_t hif_tx_hdr;
    pfe_idex_frame_header_t frame_header;
    pfe_idex_response_t resp;   /* IDEX Response Header */
    pfe_idex_msg_rpc_t msg_rpc; /* IDEX RPC Message header */
    uint8 ret[IMG_EPP_MAX_PACKET_SIZE - sizeof(pfe_idex_frame_header_t) - sizeof(pfe_idex_response_t) - sizeof(pfe_idex_msg_rpc_t)];
} pfe_idex_response_frame_t;

typedef struct __attribute__((packed))
{
    pfe_ct_hif_tx_hdr_t hif_tx_hdr;
    pfe_idex_frame_header_t frame_header;
    uint8 dummy_data[64U - sizeof(pfe_idex_frame_header_t)];  /* Dummy frame payload has to have certain minimum length, see: AAVB-9118 */
} pfe_idex_dummy_frame_t;

/*==================================================================================================
*                                     GLOBAL VARIABLES
==================================================================================================*/

/*==================================================================================================
*                                      LOCAL CONSTANTS
==================================================================================================*/

/*==================================================================================================
*                                        LOCAL VARIABLES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*  Local IDEX instance storage */
static pfe_idex_t pfe_idex = { 0U };

/**
 * @brief Current client that is waiting for response
 */
static pfe_remote_client_t *idex_current_client;

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"
pfe_idex_response_frame_t pfe_idex_response_frame;
pfe_idex_request_frame_t pfe_idex_request_frame;
pfe_idex_dummy_frame_t pfe_idex_dummy_frame;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static void pfe_idex_do_rx(pfe_hif_drv_client_t *client, pfe_idex_t *idex);
static errno_t pfe_idex_send_response(pfe_ct_phy_if_id_t dst_phy, pfe_idex_response_type_t type, pfe_idex_seqnum_t seqnum, uint16 data_len);
static errno_t pfe_idex_send_frame(pfe_ct_phy_if_id_t dst_phy, pfe_idex_frame_type_t type, const void *data, uint16 data_len);
static errno_t pfe_idex_request_send(pfe_ct_phy_if_id_t dst_phy, pfe_idex_request_type_t type, const uint32 resend_count, uint16 data_len);
static errno_t pfe_idex_ihc_handler(pfe_hif_drv_client_t *client, void *arg, uint32 event, uint32 qno);
static errno_t pfe_idex_set_rpc_cbk(pfe_idex_rpc_cbk_t cbk, void *arg);
static errno_t pfe_idex_prep_tx_header_xmit(pfe_idex_frame_header_t *idex_hdr, hif_frame_t frame, pfe_hif_chnl_t *hif_chnl);
static errno_t check_time_out(uint32 *timeout_ms, bool_t *end_sending, pfe_idex_request_t *request);
#ifdef PFE_CFG_PFE_MASTER
static bool_t get_client_index(pfe_ct_phy_if_id_t i_phy_id, uint32 * const p_client_index);
static errno_t set_idex_sequence_number(pfe_remote_client_t *client, pfe_idex_seqnum_t seqnum, bool_t *break_switch);
static void process_idex_request(pfe_idex_t *idex, pfe_idex_frame_header_t *idex_header, pfe_ct_phy_if_id_t i_phy_id, const pfe_hif_pkt_t *const pkt);
#endif /* PFE_CFG_PFE_MASTER */
#ifdef PFE_CFG_PFE_SLAVE
static void process_idex_response(pfe_idex_frame_header_t *idex_header, pfe_hif_pkt_t *const p_pkt, pfe_ct_phy_if_id_t i_phy_id);
#endif /* PFE_CFG_PFE_SLAVE */

/*==================================================================================================
*                                        LOCAL FUNCTIONS
==================================================================================================*/
/**
 * @brief       IHC client event handler
 * @details     Called by HIF when client-related event happens (packet received, packet
 *              transmitted).
 * @note        Invoked from interrupt context.
 */
static errno_t pfe_idex_ihc_handler(pfe_hif_drv_client_t *client, void *arg, uint32 event, uint32 qno)
{
    errno_t ret;
    (void)arg;
    (void)qno;
    ret = EOK;

    switch (event)
    {
        case EVENT_RX_PKT_IND:
        {
            /*  Run RX routine */
            pfe_idex_do_rx(client, &pfe_idex);
            break;
        }

        default:
        {
            NXP_LOG_WARNING("Unexpected IHC event: 0x%x\n", (uint_t)event);
            ret = EINVAL;
            break;
        }
    }

    return ret;
}

#ifdef PFE_CFG_PFE_MASTER
/**
 * @brief           Get the client index object.
 * @param[in]       i_phy_id client phy ID
 * @param[out]      p_client_index client integer ID starting at 0
 * @return          TRUE on success
 */
static bool_t get_client_index(pfe_ct_phy_if_id_t i_phy_id, uint32 * const p_client_index)
{
    bool_t ret = TRUE;

    if ((i_phy_id >= PFE_PHY_IF_ID_HIF0) && (i_phy_id <= PFE_PHY_IF_ID_HIF3))
    {
        *p_client_index = UNSAFE_CAST_INT_TO_UINT32((uint32)i_phy_id - (uint32)PFE_PHY_IF_ID_HIF0);
    }
    else
    {
        ret = FALSE;
    }
    return ret;
}
#endif /* PFE_CFG_PFE_MASTER */

#ifdef PFE_CFG_PFE_MASTER


/**
 * @brief       helper function for IDEX request processing to check idex sequence number.
 */
static errno_t set_idex_sequence_number(pfe_remote_client_t *client, pfe_idex_seqnum_t seqnum, bool_t *break_switch)
{
    errno_t ret = EOK;

    *break_switch = FALSE;

    /*In IDEX 2.0 check sequence number */
    if (client->version >= IDEX_VERSION_2)
    {
        /* Duplicated request received, only resend last response */
        if (client->seqnum == seqnum)
        {
            NXP_LOG_DEBUG("IDEX Duplicated RPC request seqnum=%u, resp_len=%u, phy_id=%u\n",
                        (uint_t)seqnum, (uint16)oal_ntohs(client->response->plen), client->phy_id);
            pfe_idex.stats.rx_dups = ADDU32_WRAP(pfe_idex.stats.rx_dups, 1U);
            if (client->response != NULL_PTR)
            {
                /* Response should be still present in pfe_idex_response_frame - no need to reload */
                /*    Send it out within IDEX frame */
                ret = pfe_idex_send_frame(client->phy_id, IDEX_FRAME_CTRL_RESPONSE, client->response,
                                        ((uint16)sizeof(pfe_idex_response_t) + (uint16)oal_ntohs(client->response->plen)));
                if (EOK != ret)
                {
                    NXP_LOG_WARNING("IDEX resending response TX failed\n");
                }
            }
            *break_switch = TRUE;
        }
        /*    New sequence number received, should be +1. Continue processing */
        else if ((client->seqnum + 1U) == seqnum)
        {
            client->seqnum = seqnum;
        }
        /* Wrong sequence number received */
        else
        {
            NXP_LOG_WARNING("Wrong sequence number %u\n", (uint_t)seqnum);
            pfe_idex.stats.rx_fails = ADDU32_WRAP(pfe_idex.stats.rx_fails, 1U);
            *break_switch = TRUE;
        }
    }
    else
    {
        client->seqnum = seqnum;
    }

    return ret;
}

/**
 * @brief       IDEX request processing.
 * @note        In interrupt mode invoked from interrupt context. Main context otherwise.
 */
static void process_idex_request(pfe_idex_t *idex, pfe_idex_frame_header_t *idex_header, pfe_ct_phy_if_id_t i_phy_id, const pfe_hif_pkt_t *const pkt)
{
    pfe_remote_client_t *   client;
    pfe_idex_request_t *    idex_req;
    uint32                client_index = 0U;
    errno_t                 ret = EOK;
    pfe_idex_msg_rpc_t *    rpc_req = NULL_PTR;
    uint32                rpc_id = 0U;
    void *                  rpc_msg_payload_ptr = NULL_PTR;
    pfe_idex_msg_reset_t *  reset_req = NULL_PTR;

    if(FALSE == get_client_index(i_phy_id, &client_index))
    {
        NXP_LOG_ERROR("Invalid HIF ID: %u\n", (uint_t) i_phy_id);
        ret = EINVAL;
    }

    if(EOK == ret)
    {
        /*  Frame is IDEX request */
        idex_req = (pfe_idex_request_t *)((addr_t)idex_header + sizeof(pfe_idex_frame_header_t));
        pfe_idex_seqnum_t seqnum = (pfe_idex_seqnum_t)oal_ntohl(idex_req->seqnum);

        client = &idex->remote.clients[client_index];
        client->phy_id = i_phy_id;

        /*    Save current IDEX client reference to global pointer */
        idex_current_client = client;

        switch (idex_req->type)
        {
        /*    IDEX_RPC REQUEST received from client    */
        case IDEX_RPC:
        {
            if (pfe_hif_pkt_get_data_len(pkt) < (sizeof(pfe_ct_hif_rx_hdr_t) + sizeof(pfe_idex_frame_header_t) + sizeof(pfe_idex_request_t) + sizeof(pfe_idex_msg_rpc_t)))
            {
                NXP_LOG_WARNING("Invalid RPC request message length\n");
                pfe_idex.stats.rx_fails = ADDU32_WRAP(pfe_idex.stats.rx_fails, 1U);
                break;
            }

            rpc_req = (pfe_idex_msg_rpc_t *)((addr_t)idex_req + sizeof(pfe_idex_request_t));
            rpc_id = (uint32)oal_ntohl(rpc_req->rpc_id);
            rpc_msg_payload_ptr = (void *)((addr_t)rpc_req + sizeof(pfe_idex_msg_rpc_t));

            /*    IDEX_RESET REQUEST received. Used for seqnumber and version synchronization [DID-AAVBR-980p-MCAL] */
            if (IDEX_RESET_RPC_ID == rpc_id)
            {
                reset_req = (pfe_idex_msg_reset_t *)rpc_msg_payload_ptr;
                client->seqnum = (pfe_idex_seqnum_t)oal_ntohl(reset_req->seqnum); /*[DID-AAVBR-980p1-MCAL] */
                client->version = reset_req->version;                             /*[DID-AAVBR-980p2-MCAL] */
    #ifdef IDEX_CFG_VERBOSE
                NXP_LOG_INFO("IDEX: RESET Request received: seqnum=%u, version=%u, phy_id=%u\n",
                            (uint_t)client->seqnum, client->version, i_phy_id);
    #endif /* IDEX_CFG_VERBOSE */

                /*    Send response with same data to acknowledge server version */
                (void)autolibc_memcpy(&pfe_idex_response_frame.msg_rpc, rpc_req, sizeof(pfe_idex_msg_rpc_t));
                (void)autolibc_memcpy(&pfe_idex_response_frame.ret, reset_req, sizeof(pfe_idex_msg_reset_t));
                ret = pfe_idex_send_response(client->phy_id, IDEX_RPC, seqnum, sizeof(pfe_idex_msg_rpc_t) + sizeof(pfe_idex_msg_reset_t));
                if (ret != EOK)
                {
                    NXP_LOG_WARNING("Problem to send RESET response\n");
                }

                break;
            } /* IDEX_RESET */

    #ifdef IDEX_CFG_VERBOSE
            NXP_LOG_INFO("IDEX: RPC Request received: cmd=%u, plen=%u, seqnum=%u, phy_id=%u\n",
                        rpc_id, (uint16)oal_ntohs(rpc_req->plen), (uint_t)oal_ntohl(idex_req->seqnum), i_phy_id);
    #endif /* IDEX_CFG_VERBOSE */

            {
                bool_t break_switch = FALSE;
                /*set sequence number*/
                ret = set_idex_sequence_number(client, seqnum, &break_switch);
                if(TRUE == break_switch)
                {
                    break;
                }
            }

            if (NULL_PTR != idex->rpc_cbk)
            {
                /*    Save RPC message for later response generation    */
                (void)autolibc_memcpy(&client->rpc_msg, rpc_req, sizeof(pfe_idex_msg_rpc_t));

                /*  Call RPC callback. Response shall be generated inside the callback using the pfe_idex_set_rpc_ret_val(). */
                idex->rpc_cbk(i_phy_id, rpc_id, rpc_msg_payload_ptr, (uint16)oal_ntohs(rpc_req->plen), idex->rpc_cbk_arg);
            }
            else
            {
    #ifdef IDEX_CFG_VERBOSE
                NXP_LOG_WARNING("RPC callback not found, request seqnum=%u ignored\n", (uint_t)oal_ntohl(idex_req->seqnum));
    #endif /* IDEX_CFG_VERBOSE */
            }

            break;
        } /* case IDEX_RPC */

        default:
        { /* Invalid request [DID-AAVBR-980t-MCAL] */
            NXP_LOG_WARNING("Unknown IDEX request type received: 0x%x\n", idex_req->type);
            pfe_idex.stats.rx_unknowns = ADDU32_WRAP(pfe_idex.stats.rx_unknowns, 1U);
            break;
        }
        }
    } /* if EOK == ret */
}
#endif /* PFE_CFG_PFE_MASTER */

#ifdef PFE_CFG_PFE_SLAVE
/**
 * @brief       IDEX response processing.
 * @note        This can be called even if slave's timeout waiting period for response from the master expires. In other
 *              words the slave can receive a delayed response from the master.
 *              In interrupt mode invoked from interrupt context. Main context otherwise..
 */
static void process_idex_response(pfe_idex_frame_header_t *idex_header, pfe_hif_pkt_t *const p_pkt, pfe_ct_phy_if_id_t i_phy_id)
{
    pfe_idex_response_t *   idex_resp;
    pfe_remote_server_t *   server = (pfe_remote_server_t *)&pfe_idex.remote.server;

#ifndef IDEX_CFG_VERBOSE
    (void)i_phy_id;
#endif

    /*  Get response header */
    idex_resp = (pfe_idex_response_t *)((addr_t)idex_header + sizeof(pfe_idex_frame_header_t));

    switch (idex_resp->type)
    {
    /* IDEX_RPC RESPONSE */
    case IDEX_RPC:
    {
        if (pfe_hif_pkt_get_data_len(p_pkt) < (sizeof(pfe_ct_hif_rx_hdr_t) + sizeof(pfe_idex_frame_header_t) + sizeof(pfe_idex_response_t) + sizeof(pfe_idex_msg_rpc_t)))
        {
            NXP_LOG_WARNING("Invalid RPC response message length\n");
            break;
        }

        /*    Response on RCP request. Finalize the associated request message */
        pfe_idex_msg_rpc_t *rpc_msg = server->rpc_msg;
        pfe_idex_msg_rpc_t *rpc_resp = (pfe_idex_msg_rpc_t *)((addr_t)idex_resp + sizeof(pfe_idex_response_t));

        pfe_idex_seqnum_t seqnum = (uint32)oal_ntohl(idex_resp->seqnum);
        uint16 payload_length = (uint16)oal_ntohs(rpc_resp->plen);

#ifdef IDEX_CFG_VERBOSE
        NXP_LOG_INFO("IDEX: RPC Response received: cmd=%u, return=%u, plen=%u, seqnum=%u, phy_id=%u",
                     (uint32)oal_ntohl(rpc_resp->rpc_id), (uint32)oal_ntohl(rpc_resp->rpc_ret), payload_length, (uint_t)seqnum, i_phy_id);
#endif /* IDEX_CFG_VERBOSE */

        /*    Sequence number in response must be the same as in request [DID-AAVBR-980c-MCAL] */
        if (server->version >= IDEX_VERSION_2)
        {
            if(seqnum != server->seqnum)
            {   /* We've most likely got an old response - a new one might come soon so don't fail here. */
                NXP_LOG_WARNING("IDEX: Wrong sequence number in RPC response: %u!=%u\n", (uint_t)seqnum, (uint_t)server->seqnum);
                break;
            }
        }

        /*    If there is waiting RPC request buffer, copy data to it and continue */
        if (NULL_PTR != rpc_msg)
        {
            /*    In rpc_msg->plen is temporarily saved buffer length */
            if (payload_length <= rpc_msg->plen)
            {
                /*    Copy payload */
                (void)autolibc_memcpy((void *)((addr_t)rpc_msg + sizeof(pfe_idex_msg_rpc_t)),
                                      (void *)((addr_t)rpc_resp + sizeof(pfe_idex_msg_rpc_t)), payload_length);
                rpc_msg->rpc_id = (uint32)oal_ntohl(rpc_resp->rpc_id);
                rpc_msg->rpc_ret = (uint32)oal_ntohl(rpc_resp->rpc_ret);
                rpc_msg->plen = payload_length;

                if(NULL_PTR != server->request)
                { /* At this moment slave's request could already timeouted and could be set to null. */
                    server->request->state = IDEX_REQ_STATE_COMPLETED;
                }
            }
            else
            {
                /* Don't send response if there is no room for required payload */
                NXP_LOG_ERROR("RPC Response buffer is too small! %u < %u\n", payload_length, rpc_msg->plen);
                if(NULL_PTR != server->request)
                { /* At this moment slave's request could already timeouted and could be set to null. */
                    server->request->state = IDEX_REQ_STATE_INVALID;
                    break;
                }
            }
        }
        break;
    } /* case IDEX_RPC RESPONSE */

    default:
    {
        NXP_LOG_WARNING("Unknown IDEX frame received %u\n", idex_header->type);
        break;
    }
    }
}
#endif /* PFE_CFG_PFE_SLAVE */

/**
 * @brief       RX processing.
 * @note        In interrupt mode invoked from interrupt context. Main context otherwise.
 */
static void pfe_idex_do_rx(pfe_hif_drv_client_t *hif_client, pfe_idex_t *idex)
{
    pfe_hif_pkt_t *             pkt;
    pfe_idex_frame_header_t *   idex_header;
    pfe_ct_phy_if_id_t          i_phy_id;

#ifdef PFE_CFG_PFE_SLAVE
    (void) idex;
#endif

    while (TRUE)
    {
        /*  Get received packet */
        pkt = pfe_hif_drv_client_receive_pkt(hif_client, 0U);
        if (NULL_PTR == pkt)
        {
            /*  No more received packets */
            break;
        }

        pfe_idex.stats.rx_count = ADDU32_WRAP(pfe_idex.stats.rx_count, 1U);

        /*  Get RX packet payload. Also skip HIF header. */
        idex_header = (pfe_idex_frame_header_t *)((addr_t)pfe_hif_pkt_get_data(pkt) + sizeof(pfe_ct_hif_rx_hdr_t));
        i_phy_id = pfe_hif_pkt_get_ingress_phy_id(pkt);

        /*    HIF is not suitable for IDEX    */
        if (((i_phy_id < PFE_PHY_IF_ID_HIF0) || (i_phy_id > PFE_PHY_IF_ID_HIF3)) && (i_phy_id != PFE_PHY_IF_ID_HIF_NOCPY))
        {
#ifdef PFE_CFG_PFE_SLAVE
            if (i_phy_id != pfe_idex.remote.server.phy_id)
#endif /* PFE_CFG_PFE_SLAVE */
            {
                NXP_LOG_WARNING("Received packet from invalid HIF number for IDEX - %d\n", i_phy_id);
                pfe_idex.stats.rx_aliens = ADDU32_WRAP(pfe_idex.stats.rx_aliens, 1U);
                break;
            }
        }

        switch (idex_header->type)
        {
#ifdef PFE_CFG_PFE_MASTER
        /* IDEX    REQUEST    */
        case IDEX_FRAME_CTRL_REQUEST:
        {
            /*  Received frame is IDEX request from client */
            process_idex_request(idex, idex_header, i_phy_id, pkt);
            break;
        } /* IDEX_FRAME_CTRL_REQUEST */
#else
        /*    IDEX RESPONSE    */
        case IDEX_FRAME_CTRL_RESPONSE:
        {
            /*  Frame is IDEX response */
            process_idex_response(idex_header, pkt, i_phy_id);
            break;
        } /* IDEX_FRAME_CTRL_RESPONSE */
#endif  /* PFE_CFG_PFE_MASTER/SLAVE */
        default:
        {
            /*  Unknown frame */
            NXP_LOG_WARNING("Unknown IDEX frame ctrl type 0x%x received\n", (uint_t)idex_header->type);
            break;
        }
        } /* switch */

        /*  Release the received packet */
        pfe_hif_pkt_free(pkt);
    }
}

#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
/**
 * @brief       IHC client polling
 * @details     Called by MainFunction when client-related event happens (packet received, packet
 *              transmitted).
 */
void pfe_idex_ihc_poll(void)
{
    /*  Run RX routine */
    pfe_idex_do_rx(pfe_idex.ihc_client, &pfe_idex);
}
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

/**
 * @brief       Send a dummy IDEX frame of constant length to specified dst_phy.
 * @param[in]   dst_phy Destination physical interface ID of client
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_idex_send_dummy_frame(pfe_ct_phy_if_id_t dst_phy)
{
    return pfe_idex_send_frame(dst_phy, IDEX_FRAME_CTRL_DUMMY, &pfe_idex_dummy_frame.dummy_data, sizeof(pfe_idex_dummy_frame.dummy_data));
}

/**
 * @param[in]   type Response type. Should match request type.
 * @param[in]   seqnum Sequence number in network endian. Should match request.
 * @param[in]   data_len Response payload length in number of bytes
 * @return      EOK if success, error code otherwise
 * @note        In interrupt mode invoked from interrupt context. Main context otherwise.
 */
static errno_t pfe_idex_send_response(pfe_ct_phy_if_id_t dst_phy, pfe_idex_response_type_t type, pfe_idex_seqnum_t seqnum, uint16 data_len)
{
    pfe_idex_response_t *resp;
    errno_t ret;
    /*    If there is response in buffer from old request, clean it */
    if (NULL_PTR != idex_current_client->response)
    {
        *idex_current_client->response = (pfe_idex_response_t){0U};

        /*    Release the response instance */
        idex_current_client->response = NULL_PTR;
    }

    /*    Create the response buffer with room for request payload */
    resp = &pfe_idex_response_frame.resp;
    *resp = (pfe_idex_response_t){0U};

    /*    Add seqnum and type */
    resp->seqnum = (uint32)oal_htonl(seqnum);
    resp->type = type;
    resp->plen = (uint16)oal_htons(data_len);

#ifdef IDEX_CFG_VERBOSE
    NXP_LOG_DEBUG("Sending response seqnum=%u\n", (uint_t)seqnum);
#endif /* IDEX_CFG_VERBOSE */

    /*  Send it out within IDEX frame */
    ret = pfe_idex_send_frame(dst_phy, IDEX_FRAME_CTRL_RESPONSE, resp, UNSAFE_CAST_INT_TO_UINT16((uint16)sizeof(pfe_idex_response_t) + data_len));
    if (EOK != ret)
    {
        NXP_LOG_WARNING("IDEX response TX failed\n");
    }
    else
    {
        pfe_idex.stats.tx_count = ADDU32_WRAP(pfe_idex.stats.tx_count, 1U);
    }

    /*    Save response in case of not successful delivery */
    idex_current_client->response = resp;

    return ret;
}

/**
 * @brief        Helper function to pfe_idex_request_send
 */
static errno_t check_time_out(uint32 *timeout_ms, bool_t *end_sending, pfe_idex_request_t *request)
{
    errno_t ret = EOK;
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
    pfe_hif_drv_t *hif_drv;

/*  Block until response is received or timeout occurred. RX and
    TX processing is expected to be done asynchronously in pfe_idex_ihc_handler(). */
    hif_drv = pfe_hif_drv_client_get_drv(pfe_idex.ihc_client);
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

    /*    Wait 1 ms between every check */
    for (*timeout_ms = PFE_CFG_IDEX_RESEND_DELAY_MS; *timeout_ms > 0U; *timeout_ms -= 1U)
    {
#if (FALSE == PFE_CFG_HIF_IRQ_ENABLED)
        pfe_hif_drv_tx_job(hif_drv);
        pfe_hif_drv_rx_job(hif_drv);
        pfe_idex_ihc_poll();
#endif /* PFE_CFG_HIF_IRQ_ENABLED */

        /*    Check the status of request */
        if (IDEX_REQ_STATE_COMPLETED == request->state)
        {
            /* Request successfully completed, we should increment counter and stop sending [DID-AAVBR-980e-MCAL] */
            ret = EOK;
            *end_sending = TRUE;
            break;
        }
        else if (IDEX_REQ_STATE_INVALID == request->state)
        {
            /* Request failed */
            ret = EFAULT;
            *end_sending = TRUE;
            break;
        }
        else
        {
            /*    Wait 1ms */
            if (FALSE == oal_irq_in_atomic())
            {
                oal_time_msleep(1U);
            }
            else
            {
                oal_time_mdelay(1U);
            }
        }
    }

    return ret;
}

/**
 * @brief        Create, send IDEX request and wait for response
 * @details        THIS IS BLOCKING FUNCTION! [DID-AAVBR-980d-MCAL]
 *                 Slave will create IDEX request and send it to Master
 *                 Function is waiting for response with Pooling mode on request status
 * @param[in]   dst_phy Destination physical interface ID
 * @param[in]   type Request type
 * @param[in]   data_len Request payload length in number of bytes
 * @return      EOK if success, error code otherwise
 * @note        Invoked from the main context.
 */
static errno_t pfe_idex_request_send(pfe_ct_phy_if_id_t dst_phy, pfe_idex_request_type_t type, const uint32 resend_count, uint16 data_len)
{
    pfe_remote_server_t *   server = (pfe_remote_server_t *)&pfe_idex.remote.server;
    uint32                timeout_ms = PFE_CFG_IDEX_RESEND_DELAY_MS;
    uint32                sending_counter;
    pfe_idex_request_t *    request;
    errno_t                 ret = EINVAL;
    bool_t                  end_sending = FALSE;

    /*    Create the request instance with room for request payload */
    request = &pfe_idex_request_frame.req;

    /*    Only initialize header, payload will be added below */
    *request = (pfe_idex_request_t){0U};

    /*    Assign sequence number, type, and destination PHY ID */
    request->seqnum = (uint32)oal_htonl(server->seqnum);
    request->type = type;
    request->dst_phy_id = dst_phy;
    request->state = IDEX_REQ_STATE_NEW;
    /*    Payload is already present in pfe_idex_request_frame.arg */
    server->request = request;
    /*    Mark request as commited and start sending */
    request->state = IDEX_REQ_STATE_COMMITTED;
    /*    Sending request. Try to send configured number of times     */
    for (sending_counter = 0U; sending_counter < resend_count; sending_counter++)
    {
        /*    Request transmitted. Will be released once it is processed. */
        ret = pfe_idex_send_frame(dst_phy, IDEX_FRAME_CTRL_REQUEST, request, UNSAFE_CAST_INT_TO_UINT16((uint16)sizeof(pfe_idex_request_t) + data_len));

        if (EOK != ret)
        {
            /*    Sending of request failed. Should return ERROR */
            NXP_LOG_ERROR("IDEX request TX failed\n");
            break;
        }
        pfe_idex.stats.tx_count = ADDU32_WRAP(pfe_idex.stats.tx_count, 1U);

        ret = check_time_out(&timeout_ms, &end_sending, request);
        if (TRUE == end_sending)
        {
            break;
        }


        NXP_LOG_DEBUG("IDEX RESENDING REQUEST seqnum=%u counter=%u state=%u", (uint_t)server->seqnum, (uint_t)(sending_counter + 1U), (uint_t)request->state);
        /*    IDEX protocol stats */
        pfe_idex.stats.tx_retries = ADDU32_WRAP(pfe_idex.stats.tx_retries, 1U);
        pfe_idex.stats.tx_max_retries = ((pfe_idex.stats.tx_max_retries < (sending_counter + 1U)) ? ADDU32_WRAP(sending_counter, 1U) : pfe_idex.stats.tx_max_retries);
    }

    if (EOK == ret)
    {
        /*    Sending was not successful, timeout occurred [DID-AAVBR-980h-MCAL] */
        if ((0U == timeout_ms) || (resend_count == sending_counter))
        {
            NXP_LOG_WARNING("IDEX request %u timed-out, retransmitted %u times\n", (uint_t)oal_ntohl(request->seqnum), sending_counter);
            ret = ETIMEDOUT;
        }

        /*    End of sending, increment seqnum */
        server->seqnum += 1U;
        *request = (pfe_idex_request_t){0U};       
        server->request = NULL_PTR;

        /* The slave has finished here, but still there can be an unexpected response from master */
    }
    else
    {
        /* Send was unsuccessful, mark connection down */
        pfe_idex_down();
    }
    
    return ret;
}

static errno_t pfe_idex_prep_tx_header_xmit(pfe_idex_frame_header_t *idex_hdr, hif_frame_t frame, pfe_hif_chnl_t *hif_chnl)
{
    errno_t                 ret = EINVAL;
    pfe_ct_hif_tx_hdr_t *   tx_hdr;

    /* Let PFE route the frame as IHC packet with known destination */
#if (TRUE == IDEX_IS_NOCPY)
    tx_hdr = (pfe_ct_hif_tx_hdr_t *)((addr_t)idex_hdr + pfe_hif_chnl_get_lmem_hdr_size(hif_chnl) + 256U);
    /* TX buffer for HIF NOCPY is allocated directly from BMU2.
    We need to clear the buffer to avoid unexpected data */
    (void)autolibc_memset(tx_hdr, 0U, sizeof(pfe_ct_hif_tx_hdr_t));
#else
    tx_hdr = (pfe_ct_hif_tx_hdr_t *)idex_hdr;
#endif /* IDEX_IS_NOCPY */
    tx_hdr->chid = UNSAFE_CAST_INT_TO_UINT8(hif_chnl->id);
    tx_hdr->e_phy_ifs = oal_htonl(1UL << (uint8)frame.dst_phy);
    tx_hdr->flags = (pfe_ct_hif_tx_flags_t)(UNSAFE_CAST_INT_TO_UINT32(HIF_TX_INJECT | HIF_TX_IHC));

    /*  Send it out [DID-AAVBR-980b-MCAL] */
    ret = pfe_hif_drv_client_xmit_pkt(pfe_idex.ihc_client, 0U, &frame, (void *)idex_hdr);
    if (EOK != ret)
    {
        NXP_LOG_ERROR("IDEX frame TX failed. Err %u\n", ret);
#if (TRUE == IDEX_IS_NOCPY)
        pfe_hif_chnl_bmu_free_buf(hif_chnl, (addr_t)idex_hdr);
#endif /* IDEX_IS_NOCPY */
    }
    else
    {
        /*  Frame transmitted. Will be released once TX confirmation is received. */
        ;
    }
    return ret;
}
/**
 * @brief       Send IDEX frame to HIF using IHC. If IDEX is down, then no frame will be sent through the channel.
 * @param[in]   dst_phy Destination physical interface ID
 * @param[in]   type Type of frame
 * @param[in]   data Pointer to frame payload
 * @param[in]   data_len Payload length in number of bytes
 * @return      EOK success, error code otherwise
 * @note        Invoked from interrupt/main context.
 */
static errno_t pfe_idex_send_frame(pfe_ct_phy_if_id_t dst_phy, pfe_idex_frame_type_t type, const void *data, uint16 data_len)
{
    pfe_idex_frame_header_t *   idex_hdr;
    errno_t                     ret = EOK;
    hif_frame_t                 frame = {0U};
    pfe_hif_drv_t *             hif_drv;
    pfe_hif_chnl_t *            hif_chnl;
#if (TRUE == IDEX_IS_NOCPY)
    void *payload;
    uint16 buf_offset;
#endif /* IDEX_IS_NOCPY */

    if (FALSE == pfe_idex.is_up)
    {
        pfe_idex.stats.tx_skips = ADDU32_WRAP(pfe_idex.stats.tx_skips, 1U);
        ret = EINVAL;
    }

    /*  Get IDEX frame buffer */
    hif_drv = pfe_hif_drv_client_get_drv(pfe_idex.ihc_client);
    if ((EOK == ret) && (NULL_PTR == hif_drv))  /* EOK check here to not further increase HIS level metrics */
    {
        NXP_LOG_ERROR("Get hif_drv instance associated with the client failed\n");
        ret = ENOENT;
    }
    else if(EOK == ret)                         /* EOK check here to not further increase HIS level metrics */
    {
        hif_chnl = pfe_hif_drv_get_chnl(hif_drv);
        if (NULL_PTR == hif_chnl)
        {
            NXP_LOG_ERROR("Get channel associated with the hif_drv instance failed\n");
            ret = ENOENT;
        }
        else
        {
#if (TRUE == IDEX_IS_NOCPY)
            idex_hdr = (pfe_idex_frame_header_t *)pfe_hif_chnl_bmu_alloc_buf_va(hif_chnl);
            if (NULL_PTR == idex_hdr)
            {
                NXP_LOG_ERROR("Memory allocation failed\n");
                ret = ENOMEM;
            }
            else
            {
                /* Fill the header */
                idex_hdr->dst_phy_if = dst_phy;
                idex_hdr->type = type;
                /* TX buffer for HIF NOCPY is allocated directly from BMU2.
                The whole IDEX frame needs to fit into it, so the IDEX header and payload are copied into the TX buffer. */
                buf_offset = pfe_hif_chnl_get_lmem_hdr_size(hif_chnl) + 256U + (uint16)sizeof(pfe_ct_hif_tx_hdr_t);
                (void)autolibc_memcpy((void *)((addr_t)idex_hdr + buf_offset), idex_hdr, sizeof(pfe_idex_frame_header_t));
                /* Add payload */
                payload = (void *)((addr_t)idex_hdr + sizeof(pfe_idex_frame_header_t));
                (void)autolibc_memcpy((void *)((addr_t)payload + buf_offset), data, data_len);
#else
            /*  Get IDEX frame buffer, see pfe_idex_request_frame_t, pfe_idex_response_frame_t */
            idex_hdr = (pfe_idex_frame_header_t *)((addr_t)data - sizeof(pfe_idex_frame_header_t));

            /* Fill the header */
            idex_hdr->dst_phy_if = dst_phy;
            idex_hdr->type = type;

            /* see pfe_idex_request_frame_t, pfe_idex_response_frame_t */
            idex_hdr = (pfe_idex_frame_header_t *)((addr_t)idex_hdr - sizeof(pfe_ct_hif_tx_hdr_t));
#endif /* IDEX_IS_NOCPY */
                /*  Define frame */
            frame.dst_phy = dst_phy;
            frame.data_va = idex_hdr;
            frame.len = (uint32)sizeof(pfe_ct_hif_tx_hdr_t) + (uint32)sizeof(pfe_idex_frame_header_t) + (uint32)data_len;
            ret = pfe_idex_prep_tx_header_xmit(idex_hdr, frame, hif_chnl);
#if (TRUE == IDEX_IS_NOCPY)
            }
#endif /* IDEX_IS_NOCPY */
        }
    }

    return ret;
}

/**
 * @brief       Set IDEX RPC callback
 * @details     The callback will be called at any time when RPC request
 *              will be received.
 * @param[in]   cbk Callback to be called
 * @param[in]   arg Custom argument to be passed to the callback
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_idex_set_rpc_cbk(pfe_idex_rpc_cbk_t cbk, void *arg)
{
    pfe_idex_t *idex = &pfe_idex;

    idex->rpc_cbk_arg = arg;
    idex->rpc_cbk = cbk;

    return EOK;
}

/**
 * @brief       IDEX initialization routine
 * @details     The callback will be called at any time when RPC request
 *              will be received.
 * @param[in]   hif_drv The HIF driver instance to be used to transport the data
 * @param[in]   master Physical interface via which the master driver can be reached
 * @param[in]   hif The Platform HIF instance
 * @param[in]   cbk Callback to be called
 * @param[in]   arg Custom argument to be passed to the callback
 * @param[in]   txcf_cbk Set to NULL, is ignored
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_idex_init(pfe_hif_drv_t *hif_drv, pfe_ct_phy_if_id_t master, pfe_hif_t *hif,
                      pfe_idex_rpc_cbk_t cbk, void *arg)
{
    pfe_idex_t *    idex = &pfe_idex;
    errno_t         ret = EOK;

    (void)master; /* To prevent unused variable warning when logging is off */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if ((NULL_PTR == hif_drv) || (NULL_PTR == hif))
    {
        NXP_LOG_ERROR("NULL_PTR argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(idex, 0U, sizeof(pfe_idex_t));
        (void)autolibc_memset(&pfe_idex_dummy_frame, 0, sizeof(pfe_idex_dummy_frame));

#ifdef PFE_CFG_PFE_MASTER
        /*    IDEX is in Server mode */
        NXP_LOG_INFO("IDEX-master @ interface %d\n", master);
        idex->is_server = TRUE;
        idex->hif = hif;
#elif defined(PFE_CFG_PFE_SLAVE)
        /* IDEX is Client    */
        NXP_LOG_INFO("IDEX-slave @ master-interface %d\n", master);
        idex->is_server = FALSE;
        /*    Set init seqnum to 0    */
        idex->remote.server.seqnum = 0U;
        idex->remote.server.phy_id = master;
        idex->remote.server.version = IDEX_VERSION_1;

        /* Not used argument variable */
        (void)hif;
#else
#error Impossible configuration
#endif /* PFE_CFG_PFE_MASTER/PFE_CFG_PFE_SLAVE */

        idex->rpc_req_lock_init = TRUE;

        /*    Register IHC client */
        idex->ihc_client = pfe_hif_drv_ihc_client_register(hif_drv, &pfe_idex_ihc_handler, NULL_PTR);

        if (NULL_PTR == idex->ihc_client)
        {
            NXP_LOG_ERROR("Can't register IHC client\n");
            pfe_idex_fini();
            ret = EFAULT;
        }

        if (EOK == ret)
        {
            ret = pfe_idex_set_rpc_cbk(cbk, arg);
        }

        if (EOK == ret)
        {
            idex->is_up = TRUE;
#if defined(PFE_CFG_PFE_SLAVE)
            /*    Send RESET request message to server [DID-AAVBR-980f-MCAL] */
            pfe_idex_msg_reset_t rst_msg;
            rst_msg.seqnum = (uint32)oal_htonl(idex->remote.server.seqnum);
            rst_msg.version = IDEX_VERSION_2;

#ifdef IDEX_CFG_VERBOSE
            NXP_LOG_INFO("IDEX: RESET Request sending: seqnum=%u, version=%u, phy_id=%u\n",
                         (uint_t)idex->remote.server.seqnum, rst_msg.version, master);

#endif /* IDEX_CFG_VERBOSE */
            /*    Sending RESET request. This is blocking communication    */
            ret = pfe_idex_rpc(master, IDEX_RESET_RPC_ID, &rst_msg, sizeof(pfe_idex_msg_reset_t), &rst_msg, sizeof(pfe_idex_msg_reset_t));
            if (EOK != ret)
            {
                /* IDEX Reset was not successful. Client will use Legacy configuration [DID-AAVBR-980g-MCAL] */
                NXP_LOG_INFO("IDEX: RESET Request not successful [%d]. Server is probably using old version of IDEX\n", ret);
                ret = EOK;
            }
            else
            {
                idex->remote.server.version = rst_msg.version;
#ifdef IDEX_CFG_VERBOSE
                NXP_LOG_INFO("IDEX: RESET Response received: seqnum=%u, version=%u\n",
                             (uint_t)idex->remote.server.seqnum, rst_msg.version);
#endif /* IDEX_CFG_VERBOSE */
            }

            if (IDEX_VERSION_2 == idex->remote.server.version)
            {
                NXP_LOG_INFO("IDEX: v2 protocol used, Resend:count=%u,delay=%ums\n", PFE_CFG_IDEX_RESEND_COUNT, PFE_CFG_IDEX_RESEND_DELAY_MS);
            }
#endif /* PFE_CFG_PFE_MASTER/PFE_CFG_PFE_SLAVE */
        }
    } /* PFE_CFG_NULL_ARG_CHECK */

    return ret;
}

/**
 * @brief       Finalize IDEX module
 */
void pfe_idex_fini(void)
{
    pfe_idex_t *idex = &pfe_idex;

    idex->is_up = FALSE;

#ifdef PFE_CFG_PFE_MASTER
    pfe_hif_clear_master_up(idex->hif);
    idex->hif = NULL_PTR;
#endif /* PFE_CFG_PFE_MASTER */

    idex->rpc_cbk = NULL_PTR;
    idex->rpc_cbk_arg = NULL_PTR;

    if (NULL_PTR != idex->ihc_client)
    {
        pfe_hif_drv_client_unregister(idex->ihc_client);
        idex->ihc_client = NULL_PTR;
    }

    /*    Free IDEX Server buffer for every client response */
    if (TRUE == idex->is_server)
    {
        for (uint8 i = 0; i < IDEX_MAX_CLIENTS; i++)
        {
            if (NULL_PTR != idex->remote.clients[i].response)
            {
                *idex->remote.clients[i].response = (pfe_idex_response_t){0U};
                idex->remote.clients[i].response = NULL_PTR;
            }
        }
    }

    idex->rpc_req_lock_init = FALSE;
}

/**
 * @brief       Execute RPC against IDEX master. Blocking call. [DID-AAVBR-980a-MCAL]
 * @param[in]   id Request identifier to be passed to remote RPC callback
 * @param[in]   buf Buffer containing RPC argument data
 * @param[in]   buf_len Length of RPC argument data in the buffer
 * @param[in]   resp Response buffer. In case of successful call (EOK) the
 *              response data is written here.
 * @param[in]   resp_len Response buffer length. If response is bigger than this
 *              number of bytes, the buffer will not be written and error code
 *              indicating no memory condition ENOMEM will be returned.
 * @return      EOK if success, error code otherwise
 * @note        Invoked from the main context.
 */
errno_t pfe_idex_master_rpc(uint32 id, const void *buf, uint16 buf_len, void *resp, uint16 resp_len)
{
    const pfe_idex_t *idex = &pfe_idex;
    errno_t ret = EPERM;

    /* RPC message can be sent to Master only from IDEX client */
    if (idex->is_server == FALSE)
    {
        ret = pfe_idex_rpc(idex->remote.server.phy_id, id, buf, buf_len, resp, resp_len);
    }

    return ret;
}

/**
 * @brief       Execute RPC. Blocking call.
 * @param[in]   dst_phy Physical interface ID where the request shall be sent
 * @param[in]   id Request identifier to be passed to remote RPC callback
 * @param[in]   buf Buffer containing RPC argument data
 * @param[in]   buf_len Length of RPC argument data in the buffer
 * @param[in]   resp Response buffer. In case of successful call (EOK) the
 *              response data is written here.
 * @param[in]   resp_len Response buffer length. If response is bigger than this
 *              number of bytes, the buffer will not be written and error code
 *              indicating no memory condition ENOMEM will be returned.
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_idex_rpc(pfe_ct_phy_if_id_t dst_phy, uint32 id, const void *buf, uint16 buf_len, void *resp, uint16 resp_len)
{
    errno_t         ret = EOK;
    const uint16  request_buf_size = UNSAFE_CAST_INT_TO_UINT16((uint16)sizeof(pfe_idex_msg_rpc_t) + buf_len);
    const uint16  response_buf_size = UNSAFE_CAST_INT_TO_UINT16((uint16)sizeof(pfe_idex_msg_rpc_t) + resp_len);
    /*    If we have version 2 or RESET message, try to resend multiple times    */
    const uint32  resend_count = (((pfe_idex.remote.server.version >= IDEX_VERSION_2) || (id == IDEX_RESET_RPC_ID)) ? PFE_CFG_IDEX_RESEND_COUNT : 1U);

    if(((request_buf_size + sizeof(pfe_idex_frame_header_t) + sizeof(pfe_idex_request_t)) > IMG_EPP_MAX_PACKET_SIZE)
        || ((response_buf_size + sizeof(pfe_idex_frame_header_t) + sizeof(pfe_idex_request_t)) > IMG_EPP_MAX_PACKET_SIZE)
      )
    {
        NXP_LOG_ERROR("Buffers too big for request/response transport\n");
        ret = ENOMEM;
    }

    if(EOK == ret)
    {
        /* clear response frame content */
        (void)autolibc_memset(&pfe_idex_response_frame.msg_rpc, 0U, response_buf_size);

        /* start assemble the request frame */
        (void)autolibc_memset(&pfe_idex_request_frame.msg, 0U, request_buf_size);

        /*    Allocate memory for request and also response */
        pfe_idex_msg_rpc_t *msg_req = &pfe_idex_request_frame.msg;
        pfe_idex_msg_rpc_t *msg_resp = &pfe_idex_response_frame.msg_rpc;

        msg_req->rpc_id = (uint32)oal_htonl(id);
        msg_req->plen = (uint16)oal_htons(buf_len);
        msg_req->rpc_ret = (uint32)oal_htonl(EOK);

        /*    Set buffer for expected RPC response */
        msg_resp->plen = resp_len;
        pfe_idex.remote.server.rpc_msg = msg_resp;

        /*    Copy data to payload of request message */
        (void)autolibc_memcpy(&pfe_idex_request_frame.arg, buf, buf_len);

#ifdef IDEX_CFG_VERBOSE
        NXP_LOG_INFO("IDEX: RPC Request sending: cmd=%u, seqnum=%u, phy_id=%u, size:%u\n",
                    (uint_t)id, pfe_idex.remote.server.seqnum, dst_phy, buf_len);

#endif /* IDEX_CFG_VERBOSE */

        /*    This is a BLOCKING function */
        ret = pfe_idex_request_send(dst_phy, IDEX_RPC, resend_count, request_buf_size);
        if (EOK != ret)
        {
            /*    Transport error [DID-AAVBR-980k-MCAL] */
            NXP_LOG_ERROR("RPC transport failed: %d\n", ret);
        }
        else
        {
            /*    Sanity checks */
            if (id != msg_resp->rpc_id)
            {
                NXP_LOG_WARNING("RPC response ID does not match the request %u != %u\n", msg_resp->rpc_id, id);
                ret = EINVAL;
            }
            else
            {
                /*    Check the remote return value from the response */
                ret = msg_resp->rpc_ret;

                /*    Copy RPC response data to caller's buffer [DID-AAVBR-980i-MCAL] */
                if (0U == msg_resp->plen)
                {
#ifdef IDEX_CFG_VERBOSE
                    NXP_LOG_DEBUG("RPC response without payload received\n");
#endif /* IDEX_CFG_VERBOSE */
                }
                else if (msg_resp->plen > resp_len) /* if the response is too big */
                {
                    NXP_LOG_ERROR("Caller's buffer is too small\n");
                    ret = ENOMEM;
                }
                else /* there is response, it is not too big and we have buffer */
                {
                    const void * payload;
                    payload = (void *)((addr_t)msg_resp + sizeof(pfe_idex_msg_rpc_t));
                    (void)autolibc_memcpy(resp, payload, msg_resp->plen);

#ifdef IDEX_CFG_VERBOSE
                    NXP_LOG_DEBUG("%d bytes of RPC response received\n", msg_resp->plen);
#endif /* IDEX_CFG_VERBOSE */
                }
            }
        }

        pfe_idex.remote.server.rpc_msg = NULL_PTR;
    }

    return ret;
}

/**
 * @brief       Set RPC response
 * @details     Function can ONLY be called within RPC callback (pfe_idex_rpc_cbk_t)
 *              to indicate the execution result.
 * @param[in]   retval Error code to be presented to RPC initiator
 * @param[in]   resp Buffer containing response data to be presented to
 *              the initiator. Can be NULL_PTR to return no data.
 * @param[in]   resp_len Size of the response in the buffer. Can be zero.
 * @return      EOK success, error code otherwise
 */
errno_t pfe_idex_set_rpc_ret_val(errno_t retval, void *resp, uint16 resp_len)
{
    pfe_remote_client_t *   client = idex_current_client;
    pfe_idex_msg_rpc_t *    rpc_resp;
    errno_t                 ret;

    rpc_resp = &pfe_idex_response_frame.msg_rpc;

    /* start assemble the response frame */
    (void)autolibc_memset(&pfe_idex_response_frame, 0U, sizeof(pfe_idex_response_frame));

    /*  Construct response message */
    rpc_resp->rpc_id = client->rpc_msg.rpc_id; /* Already in correct endian */
    rpc_resp->plen = oal_htons(resp_len);
    rpc_resp->rpc_ret = oal_htonl(retval);

    (void)autolibc_memcpy(&pfe_idex_response_frame.ret, resp, resp_len);

#ifdef IDEX_CFG_VERBOSE
    NXP_LOG_INFO("IDEX: RPC Response sending: cmd=%u, seqnum=%u, resp_len=%u, retval=%u\n",
                 (uint_t)oal_ntohl(rpc_resp->rpc_id), (uint_t)client->seqnum, resp_len, retval);
#endif /* IDEX_CFG_VERBOSE */

    /*  Send the response */
    ret = pfe_idex_send_response(
        client->phy_id,                                                          /* Destination */
        IDEX_RPC,                                                                /* Response type */
        client->seqnum,                                                          /* Response sequence number */
        UNSAFE_CAST_INT_TO_UINT16((uint16)sizeof(pfe_idex_msg_rpc_t) + resp_len) /* Response payload length */
    );
    if (EOK != ret)
    {
        NXP_LOG_ERROR("IDEX RPC response failed\n");
    }

    return ret;
}

/**
* @brief    Mark IDEX communication channel as DOWN
*/
void pfe_idex_down(void)
{
    pfe_idex.is_up = FALSE;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */


===== 文件 [165/185]: src\pfe_if_db.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2017-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "linked_list.h"
#include "pfe_if_db.h"
#include "pfe_platform_cfg.h"
#include "isa.h"

typedef union
/* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
{
    uint8 if_id;
    void *iface;
    char_t *name;
    pfe_ct_phy_if_id_t owner;
/* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
} crit_arg_t;   /*  Current criterion argument */

struct pfe_if_db_tag
{
    pfe_if_db_type_t type;
    uint32 next_item;                  /*  Current entry to be returned. See ...get_first() and ...get_next() */
    pfe_if_db_get_criterion_t cur_crit; /*  Current criterion */
    /* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
    crit_arg_t cur_crit_arg;    /*  Current criterion argument */
};

struct pfe_if_db_entry_tag
{
    pfe_ct_phy_if_id_t owner;

    union
    /* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
    {
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
        pfe_log_if_t *log_if;
#endif
        pfe_phy_if_t *phy_if;
        void *iface;
    /* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
    } info;
};

typedef struct
{
    uint32 session_id;
    uint32 seed;
    uint8 ref_cnt;
    bool_t is_locked;
} if_db_context_t;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

static pfe_if_db_entry_t pfe_if_db_phy_ifs[(uint8)PFE_PHY_IF_ID_MAX + 1U];
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
static pfe_isa_t pfe_if_db_log_ifs;
static pfe_isa_index_t pfe_if_db_log_ifs_index[PFE_CFG_MAX_LOG_IFS];
static pfe_if_db_entry_t pfe_if_db_log_ifs_pool[PFE_CFG_MAX_LOG_IFS];
#endif /* PFE_CFG_PFE_MASTER */

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static const pfe_isa_definition_t pfe_if_db_log_ifs_isa_def =
{
    .item_count = PFE_CFG_MAX_LOG_IFS,
    .item_size = (uint32)sizeof(pfe_if_db_entry_t),
    .flags = { .ordered = ISA_FLAG_STRICT_ORDER },
    .item_indexes = pfe_if_db_log_ifs_index,
    .items = pfe_if_db_log_ifs_pool
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_PFE_MASTER */

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief   Global intefrace DB lock. Module-local singleton.
 */
static if_db_context_t if_db_context;


#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static bool_t pfe_if_db_match_criterion(const pfe_if_db_t *db, pfe_if_db_get_criterion_t crit, const crit_arg_t *arg, const pfe_if_db_entry_t *entry);
static errno_t pfe_if_db_check_precondition(const if_db_context_t *pr_if_db_context, uint32 session_id);
static pfe_if_db_entry_t *pfe_if_db_get_single_entry(const pfe_if_db_t *db, pfe_if_db_get_criterion_t crit, crit_arg_t argument, uint32 *next_iter);
static errno_t pfe_if_db_assign_arg(void *arg, pfe_if_db_get_criterion_t crit, crit_arg_t *argument, pfe_if_db_entry_t **db_entry);

#if defined(PFE_CFG_NULL_ARG_CHECK)
static inline bool_t pfe_if_db_null_ptr_check(const pfe_if_db_t *db,pfe_if_db_entry_t **db_entry);
#endif /* PFE_CFG_NULL_ARG_CHECK */

#if defined(PFE_CFG_NULL_ARG_CHECK)
/**
 * @brief       Check arguments for NULL_PTR value
 * @param[in]   db Pointer to be checked
 * @param[in]   db_entry Pointer to be checked
 * @return      TRUE returned when at least one pointer is NULLL_PTR, FALSE otherwise
*/
static inline bool_t pfe_if_db_null_ptr_check(const pfe_if_db_t *db,pfe_if_db_entry_t **db_entry)
{
    return (bool_t)((NULL_PTR == db) || (NULL_PTR == db_entry));
}
#endif /* PFE_CFG_NULL_ARG_CHECK */

/**
 * @brief       Check argument for NULL value and assign argument to interface or name
 * @param[in]   arg Pointer to criterion argument
 * @param[in]   crit Get criterion
 * @param[out]  argument Argument to modify
 * @param[out]  entry The entry or NULL if not found
 * @return      EOK entry returned is valid
*/
/* coverity[misra_c_2012_rule_8_13_violation:FALSE] */
/* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
static errno_t pfe_if_db_assign_arg(void *arg, pfe_if_db_get_criterion_t crit, crit_arg_t *argument, pfe_if_db_entry_t **db_entry)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == arg))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        *db_entry = NULL_PTR;
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)*db_entry;
        if(IF_DB_CRIT_BY_INSTANCE == crit)
        {
            argument->iface = arg;
        }
        else
        {
            /* coverity[misra_c_2012_rule_8_13_violation:FALSE] Typecast from void pointer to char_t is allowed in this case */
            argument->name = (char_t *)arg;
        }
    }

    return ret;
}

/**
 * @brief       Check preconditions before performing operation
 * @param[in]   pr_if_db_context
 * @retval      EOK Preconditions are fulfilled
 * @retval      PERM Preconditions are not fulfilled
 * @warning     context should be locked before call
 */
static errno_t pfe_if_db_check_precondition(const if_db_context_t *pr_if_db_context, uint32 session_id)
{
    errno_t ret;

    if(FALSE == pr_if_db_context->is_locked)
    {
        ret = EPERM;
        NXP_LOG_DEBUG("DB access not permitted\n");
    }
    else if(session_id != pr_if_db_context->session_id)
    {
        NXP_LOG_DEBUG("Incorrect session ID\n");
        ret = EPERM;
    }
    else
    {
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Match entry with latest criterion provided via pfe_if_db_get_first()
 * @param[in]   db The interface DB instance
 * @param[in]   crit Criterion to search
 * @param[in]   arg Criterion arguments
 * @param[in]   entry The entry to be matched
 * @retval      TRUE Entry matches the criterion
 * @retval      FALSE Entry does not match the criterion
 */
/* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
static bool_t pfe_if_db_match_criterion(const pfe_if_db_t *db, pfe_if_db_get_criterion_t crit, const crit_arg_t *arg, const pfe_if_db_entry_t *entry)
{
    bool_t match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == db) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (crit)
        {
            case IF_DB_CRIT_ALL:
            {
                match = TRUE;
                break;
            }

            case IF_DB_CRIT_BY_ID:
            {
                if (PFE_IF_DB_PHY == db->type)
                {
                    match = (arg->if_id == (uint8)pfe_phy_if_get_id(entry->info.phy_if));
                }
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
                else
                {
                    match = (arg->if_id == (uint8)pfe_log_if_get_id(entry->info.log_if));
                }
#endif /* PFE_CFG_PFE_MASTER */

                break;
            }

            case IF_DB_CRIT_BY_INSTANCE:
            {
                match = (arg->iface == entry->info.iface);
                break;
            }

            case IF_DB_CRIT_BY_NAME:
            {
                if (PFE_IF_DB_PHY == db->type)
                {
                    match = (0 == autolibc_strcmp(arg->name, pfe_phy_if_get_name(entry->info.phy_if)));
                }
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
                else
                {
                    match = (0 == autolibc_strcmp(arg->name, pfe_log_if_get_name(entry->info.log_if)));
                }
#endif /* PFE_CFG_PFE_MASTER */

                break;
            }

            case IF_DB_CRIT_BY_OWNER:
            {
                match = (arg->owner == entry->owner);
                break;
            }

            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                match = FALSE;
                break;
            }
        }
    }
    return match;
}

/**
 * @brief       Get any record from the DB matching given criterion without changing previous
 *              search criteria
 * @param[in]   db The interface DB instance
 * @param[in]   crit Get criterion
 * @param[in]   argument Pointer to criterion argument
 * @param[inout]  next_iter non NULL pointer to variable holding the iteration index
 * @return      entry The entry or NULL if not found
 */
/* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
static pfe_if_db_entry_t *pfe_if_db_get_single_entry(const pfe_if_db_t *db, pfe_if_db_get_criterion_t crit, crit_arg_t argument, uint32 *next_iter)
{
    bool_t match = FALSE;
    pfe_if_db_entry_t *entry;
    uint32 ii = *next_iter;

    if (PFE_IF_DB_PHY == db->type)
    {
        /*  Get first matching entry */
        for (; ii <= (uint32)PFE_PHY_IF_ID_MAX; ii++)
        {
            entry = &pfe_if_db_phy_ifs[ii];
            if (NULL_PTR != entry->info.iface)
            {
                /* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
                if (TRUE == pfe_if_db_match_criterion(db, crit, &argument, entry))
                {
                    match = TRUE;
                    break;
                }
            }
        }
    }
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
    else /* PFE_IF_DB_LOG */
    {
        /*  Get first matching entry */
        for (; ii < pfe_if_db_log_ifs.occupied_items_count; ii++)
        {
            /* Get data */
            entry = (pfe_if_db_entry_t *)isa_item(&pfe_if_db_log_ifs, ii);

            if (NULL_PTR != entry)
            {
                /* coverity[misra_c_2012_rule_19_2_violation:FALSE] */
                if (TRUE == pfe_if_db_match_criterion(db, crit, &argument, entry))
                {
                    match = TRUE;
                    break;
                }
            }
        }
    }
#endif /* PFE_CFG_PFE_MASTER */

    if (TRUE == match)
    {
            /* next item index where to start next lookup */
            /* moved out of the for loop due to MISRA 14.2 */
            ii++;
    }
    else
    {
        /* No match found */
        entry = NULL_PTR;
    }

    *next_iter = ii;

    return entry;
}

/**
 * @brief       Create DB
 * @param[in]   Database type: Logical or Physical interfaces
 * @return      The DB instance or NULL if failed
 */
pfe_if_db_t * pfe_if_db_create(pfe_if_db_type_t type)
{
    static pfe_if_db_t pfe_if_db_instance[PFE_XXX_IF_DB_INSTANCES];
    pfe_if_db_t *db;

    if (unlikely((type != PFE_IF_DB_PHY) && (type != PFE_IF_DB_LOG)))
    {
        NXP_LOG_ERROR("Unrecognized DB type\n");
        db = NULL;
    }
    else
    {
        db = &pfe_if_db_instance[type];
        (void)autolibc_memset(db, 0, sizeof(pfe_if_db_t));
        db->next_item = 0U;
        db->type = type;
        oal_mutex_lock(PFE_IF_DB_CONTEXT_MUTEX_00);

        if(PFE_IF_DB_PHY == type)
        {
            (void)autolibc_memset(pfe_if_db_phy_ifs, 0, sizeof(pfe_if_db_phy_ifs));
        }
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
        else
        {
            /* PFE_IF_DB_LOG */
            isa_init(&pfe_if_db_log_ifs, &pfe_if_db_log_ifs_isa_def);
            (void)autolibc_memset(pfe_if_db_log_ifs_pool, 0, sizeof(pfe_if_db_log_ifs_pool));
        }
#endif /* PFE_CFG_PFE_MASTER */

        /* Create global DB lock */
        if (0U == if_db_context.ref_cnt)
        {
            /* Initialize data to safe values */
            if_db_context.is_locked = FALSE;
            if_db_context.session_id = 0U;

            /* Initialize seed to some value */
            if_db_context.seed = 123U;
        }

        /* Increment reference counter */
        ++if_db_context.ref_cnt;

        oal_mutex_unlock(PFE_IF_DB_CONTEXT_MUTEX_00);
    }
    return db;
}

/**
 * @brief       Destroy DB
 * @param[in]   db The DB instance
 */
void pfe_if_db_destroy(const pfe_if_db_t *db)
{
    oal_mutex_lock(PFE_IF_DB_CONTEXT_MUTEX_01);

    if(PFE_IF_DB_PHY == db->type)
    {
        (void)autolibc_memset(pfe_if_db_phy_ifs, 0, sizeof(pfe_if_db_phy_ifs));
    }
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
    else
    {
        /* PFE_IF_DB_LOG */
        isa_init(&pfe_if_db_log_ifs, &pfe_if_db_log_ifs_isa_def);
    }
#endif

    /* Decrement reference counter */
    if(0U < if_db_context.ref_cnt)
    {
        --if_db_context.ref_cnt;
    }

    oal_mutex_unlock(PFE_IF_DB_CONTEXT_MUTEX_01);

    /* Destroy global DB lock */
    if(0U == if_db_context.ref_cnt)
    {
        if_db_context.is_locked = TRUE;
    }
}

/**
 * @brief       Get physical interface instance from database entry
 * @param[in]   entry The entry
 * @return      Physical interface instance
 */
/* coverity[misra_c_2012_rule_1_2_violation:FALSE] */
__attribute__((pure)) pfe_phy_if_t *pfe_if_db_entry_get_phy_if(const pfe_if_db_entry_t *entry)
{
    pfe_phy_if_t *phy_if_entry;
    if (NULL != entry)
    {
        phy_if_entry = entry->info.phy_if;
    }
    else
    {
        phy_if_entry = NULL;
    }
    return phy_if_entry;
}

#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
/**
 * @brief       Get logical interface instance from database entry
 * @param[in]   entry The entry
 * @return      Logical interface instance
 */
/* coverity[misra_c_2012_rule_1_2_violation:FALSE] */
__attribute__((pure)) pfe_log_if_t *pfe_if_db_entry_get_log_if(const pfe_if_db_entry_t *entry)
{
    pfe_log_if_t *log_if_entry;
    if (NULL != entry)
    {
        log_if_entry = entry->info.log_if;
    }
    else
    {
        log_if_entry = NULL;
    }
    return log_if_entry;
}
#endif

/**
 * @brief       Add interface instance to DB
 * @param[in]   db The interface DB instance
 * @param[in]   session_id ID of active session
 * @param[in]   iface The interface instance
 * @param[in]   owner Owner of the entry
 * @retval      EOK Success
 * @retval      ENOMEM Memory allocation failed
 * @retval      EPERM Attempt to insert already existing entry/Incorrect session ID
 */
/* coverity[misra_c_2012_rule_8_13_violation:FALSE] db cannot be const as the function modifies it when built in master mode. */
errno_t pfe_if_db_add(pfe_if_db_t *db, uint32 session_id, void *iface, pfe_ct_phy_if_id_t owner)
{
    pfe_if_db_entry_t  *new_entry = NULL;
    errno_t            ret = EINVAL;
    pfe_ct_phy_if_id_t id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_IF_DB_PHY == db->type)
        {
            id = pfe_phy_if_get_id((pfe_phy_if_t *)iface);

            /* check duplicates */
            if (NULL_PTR == pfe_if_db_phy_ifs[id].info.iface)
            {
                new_entry = &pfe_if_db_phy_ifs[id];
                ret = EOK;
            }
            else
            {
                /* don't allow duplicates */
                ret = EPERM;
            }
        }
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
        else
        {
            /* PFE_IF_DB_LOG */
            ret = pfe_if_db_get_first(db, session_id, IF_DB_CRIT_BY_INSTANCE, iface, &new_entry);

            /* Check condition if operation on DB is allowed */
            if (EOK != pfe_if_db_check_precondition(&if_db_context, session_id))
            {
                ret = EPERM;
            }
            else
            {
                if ((NULL_PTR == new_entry) && (EOK == ret))
                {
                    oal_mutex_lock(PFE_IF_DB_CONTEXT_MUTEX_02);
                    /* coverity[misra_c_2012_rule_11_5_violation:FALSE] */
                    new_entry = (pfe_if_db_entry_t *)isa_reserve(&pfe_if_db_log_ifs);
                    if (NULL_PTR == new_entry)
                    {
                        ret = ENOMEM;
                    }
                    else
                    {
                        (void)autolibc_memset(new_entry, 0, sizeof(pfe_if_db_entry_t));
                    }
                    oal_mutex_unlock(PFE_IF_DB_CONTEXT_MUTEX_02);
                }
                else
                {
                    /*  Don't allow duplicates */
                    ret = EPERM;
                }
            }
        }
#else
        (void)session_id;
#endif /* PFE_CFG_PFE_MASTER */

        if (NULL_PTR != new_entry)
        {
            /*  Store values */
            new_entry->info.iface = iface;
            new_entry->owner = owner;
        }
    }
    return ret;
}

/**
 * @brief       Remove entry from DB
 * @param[in]   db The interface DB instance
 * @param[in]   session_id ID of active session
 * @param[in]   entry Entry to be removed. If the call is successful the entry
 *                    becomes invalid and shall not be accessed.
 * @return      EOK if success, error code otherwise
 * @retval      EPERM Incorrect session ID or DB not locked
 */
/* coverity[misra_c_2012_rule_8_13_violation:FALSE] */
errno_t pfe_if_db_remove(pfe_if_db_t *db, uint32 session_id, pfe_if_db_entry_t *entry)
{
    errno_t ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == db) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check condition if operation on DB is allowed */
        if (EOK != pfe_if_db_check_precondition(&if_db_context, session_id))
        {
            ret = EPERM;
        }
        else
        {
            if (PFE_IF_DB_PHY == db->type)
            {   /* coverity[misra_c_2012_rule_18_3_violation:FALSE] */
                if ((&pfe_if_db_phy_ifs[(uint32)PFE_PHY_IF_ID_EMAC0] <= entry) &&
                    (&pfe_if_db_phy_ifs[(uint32)PFE_PHY_IF_ID_MAX + 1U] > entry))
                {
                    /* invalidate inteface to mark interface removed state */
                    entry->info.iface = NULL_PTR;
                    ret = EOK;
                }
                else
                {
                    ret = ENOENT;
                }
            }
#ifdef PFE_CFG_PFE_MASTER /* Only MASTER has access to log_if */
            else
            {
                sint32 item_index;

                /* PFE_IF_DB_LOG */
                oal_mutex_lock(PFE_IF_DB_CONTEXT_MUTEX_03);
                item_index = isa_release(&pfe_if_db_log_ifs, entry);
                if (ISA_ITEM_NOT_FOUND != item_index)
                {
                    if ((uint32)item_index < db->next_item)
                    {
                        /*  If removed item had lower 'item_index' than 'next_item' then we need decrease
                            'next_item' value. Adjust next_item value so we can call remove() between
                            get_first() and get_next() calls.
                        */
                        db->next_item--;
                    }
                    ret = EOK;
                }
                else
                {
                    ret = ENOENT;
                }
                oal_mutex_unlock(PFE_IF_DB_CONTEXT_MUTEX_03);
            }
#endif
        }
    }
    return ret;
}

/**
 * @brief       Get first record from the DB matching given criterion
 * @details     Intended to be used with pfe_if_db_get_next
 * @param[in]   db The interface DB instance
 * @param[in]   session_id ID of active session
 * @param[in]   crit Get criterion
 * @param[in]   arg Pointer to criterion argument
 * @param[out]  entry The entry or NULL if not found
 * @return      EOK entry returned is valid
 * @return      EPERM db was locked by someone else, entry returned is not valid
 * @warning     The returned entry must not be accessed after pfe_if_db_remove(entry)
 *              or pfe_if_db_drop_all() has been called.
 */
errno_t pfe_if_db_get_first(pfe_if_db_t *db, uint32 session_id, pfe_if_db_get_criterion_t crit, void *arg, pfe_if_db_entry_t **db_entry)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(TRUE == pfe_if_db_null_ptr_check( db, db_entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check condition if operation on DB is allowed */
        if (EOK != pfe_if_db_check_precondition(&if_db_context, session_id))
        {
            ret = EPERM;
        }
        else
        {
            /*  Remember criterion and argument for possible subsequent pfe_log_if_db_get_next() calls */
            db->cur_crit = crit;
            switch (db->cur_crit)
            {
                case IF_DB_CRIT_ALL:
                {
                    break;
                }

                case IF_DB_CRIT_BY_ID:
                {
                    /* coverity[misra_c_2012_rule_11_6_violation:FALSE] */
                    db->cur_crit_arg.if_id = (uint8)((addr_t)arg & 0xffU);
                    break;
                }

                case IF_DB_CRIT_BY_INSTANCE:
                {
                    ret = pfe_if_db_assign_arg( arg, crit, &db->cur_crit_arg, db_entry);
                    break;
                }

                case IF_DB_CRIT_BY_NAME:
                {
                    ret = pfe_if_db_assign_arg( arg, crit, &db->cur_crit_arg, db_entry);
                    break;
                }

                case IF_DB_CRIT_BY_OWNER:
                {
                    /* coverity[misra_c_2012_rule_11_6_violation:FALSE] */
                    const addr_t owner = (addr_t)arg & 0xffU;
                    PfeDevAssert((addr_t)PFE_PHY_IF_ID_INVALID >= owner);
                    /* coverity[misra_c_2012_rule_10_5_violation:FALSE] */
                    db->cur_crit_arg.owner = (pfe_ct_phy_if_id_t)owner;
                    break;
                }

                default:
                {
                    NXP_LOG_ERROR("Unknown criterion\n");
                    ret = EPERM;
                    break;
                }
            }

            if (ret == EOK)
            {
                db->next_item = 0U;
                *db_entry = pfe_if_db_get_single_entry(db, db->cur_crit, db->cur_crit_arg, &db->next_item);
            }
        }
    }
    return ret;
}

/**
 * @brief       Get first record from the DB matching given criterion without changing previous
 *              search criteria
 * @details     Intended to be used for nested DB search where only a single match is expected (i.g. by
 *              unique ID). The function does not change saved criterion from the pfe_if_db_get_first()
 *              call thus the pfe_if_db_get_next() will be able to continue the search initiated by
 *              the pfe_if_db_get_first() call.
 * @param[in]   db The interface DB instance
 * @param[in]   session_id ID of active session
 * @param[in]   crit Get criterion
 * @param[in]   arg Pointer to criterion argument
 * @param[out]  entry The entry or NULL if not found
 * @return      EOK entry returned is valid
 * @return      EPERM db was locked by someone else, entry returned is not valid
 * @warning     The returned entry must not be accessed after pfe_if_db_remove(entry)
 *              or pfe_if_db_drop_all() has been called.
 */
errno_t pfe_if_db_get_single(const pfe_if_db_t *db, uint32 session_id, pfe_if_db_get_criterion_t crit, void *arg, pfe_if_db_entry_t **db_entry)
{
    crit_arg_t argument = {0};
    errno_t    ret = EOK;
    uint32   iter;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(TRUE == pfe_if_db_null_ptr_check( db, db_entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Convert argument to database known format */
        switch (crit)
        {
            case IF_DB_CRIT_ALL:
            {
                break;
            }

            case IF_DB_CRIT_BY_ID:
            {
                /* coverity[misra_c_2012_rule_11_6_violation:FALSE] */
                argument.if_id = (uint8)((addr_t)arg & 0xffU);
                break;
            }

            case IF_DB_CRIT_BY_INSTANCE:
            {
                ret = pfe_if_db_assign_arg( arg, crit, &argument, db_entry);
                break;
            }

            case IF_DB_CRIT_BY_NAME:
            {
                ret = pfe_if_db_assign_arg( arg, crit, &argument, db_entry);
                break;
            }

            case IF_DB_CRIT_BY_OWNER:
            {
                /* coverity[misra_c_2012_rule_11_6_violation:FALSE] */
                const addr_t owner = (addr_t)arg & 0xffU;
                PfeDevAssert((addr_t)PFE_PHY_IF_ID_INVALID >= owner);
                /* coverity[misra_c_2012_rule_10_5_violation:FALSE] */
                argument.owner = (pfe_ct_phy_if_id_t)owner;
                break;
            }

            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                ret = EPERM;
                break;
            }
        }
        if (ret == EOK)
        {
            /* Check condition if operation on DB is allowed */
            if (EOK != pfe_if_db_check_precondition(&if_db_context, session_id))
            {
                ret = EPERM;
            }
            if (ret != EPERM)
            {
                iter = 0U;
                *db_entry = pfe_if_db_get_single_entry(db, crit, argument, &iter);
            }
        }
    }
    return ret;
}

/**
 * @brief       Get next record from the DB
 * @details     Intended to be used with pfe_if_db_get_first.
 * @param[in]   db The interface DB instance
 * @param[in]   session_id ID of active session
 * @param[out]  entry The entry or NULL if not found
 * @return      EOK entry returned is valid
 * @return      EPERM db was locked by someone else, entry returned is not valid
 * @warning     The returned entry must not be accessed after pfe_if_db_remove(entry)
 *              or pfe_if_db_drop_all() has been called.
 */
errno_t pfe_if_db_get_next(pfe_if_db_t *db, uint32 session_id, pfe_if_db_entry_t **db_entry)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == db_entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check condition if operation on DB is allowed */
        if (EOK != pfe_if_db_check_precondition(&if_db_context, session_id))
        {
            ret = EPERM;
        }
        else
        {
            *db_entry = pfe_if_db_get_single_entry(db, db->cur_crit, db->cur_crit_arg, &db->next_item);
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Lock the DB with session ID
 * @param[out]  session_id ID of locked session
 * @return      EOK if success, error if lock is already locked
 */
errno_t pfe_if_db_lock(uint32 *session_id)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == session_id))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Lock global if DB mutex */
        oal_mutex_lock(PFE_IF_DB_CONTEXT_MUTEX_05);

        if (FALSE == if_db_context.is_locked)
        {
            /* Increment seed id */
            ++if_db_context.seed;

            /* Store session ID and reserve 0 - 15 for named sessions */
            if_db_context.session_id = if_db_context.seed << 4U;

            /* Pass session id to caller*/
            *session_id = if_db_context.session_id;
            if_db_context.is_locked = TRUE;

            ret = EOK;
        }
        else
        {
            ret = ENOLCK;
        }

        /* Unlock global if DB mutex */
        oal_mutex_unlock(PFE_IF_DB_CONTEXT_MUTEX_05);
    }
    return ret;
}

/**
 * @brief       Lock the DB with owner ID
 * @param[in]   owner_id ID of owner in range 0 - 15
 * @return      EOK if success, error if lock is already locked or id is not in range
 */
errno_t pfe_if_db_lock_owned(uint32 owner_id)
{
    errno_t ret = ENOLCK;

    oal_mutex_lock(PFE_IF_DB_CONTEXT_MUTEX_06);
    if((FALSE == if_db_context.is_locked) && (16U > owner_id))
    {
        /* Session ID is in ok range store it*/
        if_db_context.session_id = owner_id;
        if_db_context.is_locked = TRUE;
        ret = EOK;
    }
    oal_mutex_unlock(PFE_IF_DB_CONTEXT_MUTEX_06);

    return ret;
}

/**
 * @brief       Unlock the DB with owner ID/session ID
 * @param[in]   owner_id ID of owner or session
 * @return      EOK if success, error if lock is already locked or id is not in range
 */
errno_t pfe_if_db_unlock(uint32 session_id)
{
    errno_t ret = ENOLCK;

    oal_mutex_lock(PFE_IF_DB_CONTEXT_MUTEX_07);
    if((TRUE == if_db_context.is_locked) && (session_id == if_db_context.session_id))
    {
        /* Discard key and set locked to FALSE*/
        if_db_context.session_id = (~if_db_context.session_id) << 4U;

        /* Set is locked to FALSE */
        if_db_context.is_locked = FALSE;
        ret = EOK;
    }
    oal_mutex_unlock(PFE_IF_DB_CONTEXT_MUTEX_07);

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [166/185]: src\pfe_l2br.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @file        pfe_l2br.c
 * @brief       The L2 bridge module source file.
 * @details     This file contains L2 bridge-related functionality.
 *
 *              The bridge consists of multiple bridge domains:
 *              1.) The default domain
 *              2.) Set of particular standard VLAN domains
 *              3.) The fall-back domain
 *
 *              The default domain
 *              ------------------
 *              Default domain is used by the classification process when packet
 *              without VLAN tag has been received and hardware assigned a default
 *              VLAN ID.
 *
 *              The standard domain
 *              -------------------
 *              Standard VLAN domain. Specifies what to do when packet with VLAN
 *              ID matching the domain is received.
 *
 *              The fall-back domain
 *              -------------------
 *              This domain is used when packet with unknown VLAN ID (does not match
 *              any standard domain) is received.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "linked_list.h"

#include "oal.h"
#include "hal.h"

#include "pfe_cbus.h"
#include "pfe_l2br_table.h"
#include "pfe_feature_mgr.h"

#ifdef PFE_CFG_L2BRIDGE_ENABLE
#include "pfe_l2br.h"
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
#include "isa.h"
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

#define PFE_GET_IFC_MASK(id) ((uint64)1ULL << (uint8)id)

/* Flags for 2-field MAC table entry (flags) */
#define MAC_VALID_FLAG          (1U << 3)   /*!< MAC_ENTRY_VALID_FLAG */
#define MAC_COL_PTR_VALID_FLAG  (1U << 2)   /*!< MAC_ENTRY_COL_PTR_VALID_FLAG */
#define MAC_RESERVED1_FLAG      (1U << 1)   /*!< MAC_ENTRY_RESERVED1_FLAG */
#define MAC_RESERVED2_FLAG      (1U << 0)   /*!< MAC_ENTRY_RESERVED2_FLAG */

/* Valid flags for 2-field MAC table entry (pfe_mac2f_table_entry_t.field_valids) */
#define MAC_ENTRY_MAC_VALID         (1U << 0)  /*!< (Field1 = MAC Valid) */
#define MAC_ENTRY_VLAN_VALID        (1U << 1)  /*!< (Field2 = VLAN Valid) */
#define MAC_ENTRY_RESERVED1_VALID   (1U << 2)  /*!< RESERVED */
#define MAC_ENTRY_RESERVED2_VALID   (1U << 3)  /*!< RESERVED */
#define MAC_ENTRY_RESERVED3_VALID   (1U << 4)  /*!< RESERVED */
#define MAC_ENTRY_RESERVED4_VALID   (1U << 5)  /*!< RESERVED */
#define MAC_ENTRY_RESERVED5_VALID   (1U << 6)  /*!< RESERVED */
#define MAC_ENTRY_RESERVED6_VALID   (1U << 7)  /*!< RESERVED */

#define SUM_WRAP_U32(A, B) ((uint32)(((uint64)(A) + (B)) & UINT32_MAX))

/**
 * @brief   The L2 Bridge Domain representation type
 */
struct pfe_l2br_domain_tag
{
    uint16 vlan;
    uint8  stats_index;
    union
    {
        pfe_ct_vlan_table_result_t action_data;
        uint64 action_data_u64val;
    } u;

    pfe_l2br_table_entry_t vlan_entry;          /*!< This is entry within VLAN table representing the domain */
    pfe_l2br_t *bridge;
    bool_t is_default;                          /*!< If TRUE then this is default bridge domain */
    bool_t is_fallback;                         /*!< If TRUE the this is fall-back bridge domain */
    pfe_l2br_domain_if_get_crit_t cur_crit;     /*!< Current 'get' criterion (to get interfaces) */
    uint8 cur_item;                          /*!< The current interface list item */
    union /* Placeholder union for future use */
    {
        pfe_ct_phy_if_id_t id;
        pfe_phy_if_t *phy_if;
    } cur_crit_arg;                             /*!< Current criterion argument */
    uint64 ifaces;                            /*!< List of associated interfaces as masks */
};

struct pfe_l2br_static_entry_tag
{
    union
    {
        pfe_ct_mac_table_result_t action_data;
        uint64 action_data_u64val;
    } u;
    uint16 vlan;
    pfe_mac_addr_t mac;                     /*!< Mac address to be matched */
    pfe_l2br_table_entry_t entry;           /*!< This is entry within MAC table representing the static entry */
    pfe_l2br_t *bridge;
};

/**
 * @brief   The L2 Bridge instance structure
 */
struct pfe_l2br_tag
{
    pfe_class_t *class;
    pfe_l2br_table_t *mac_table;
    pfe_l2br_table_t *vlan_table;
    pfe_l2br_domain_t *default_domain;
    pfe_l2br_domain_t *fallback_domain;
    pfe_isa_t domains;                          /*!< List of standard domains */
    pfe_isa_index_t domains_pool_index[PFE_CFG_L2BR_DOMAINS_MAX];
    pfe_l2br_domain_t domains_pool[PFE_CFG_L2BR_DOMAINS_MAX];
    uint32 domain_stats_table_addr;
    uint16 domain_stats_table_size;
    #ifdef PFE_CFG_L2BR_STATICS_ENABLE
    pfe_isa_t static_entries;                   /*!< List of static entries */
    pfe_isa_index_t static_entries_pool_index[PFE_CFG_L2BR_STATICS_MAX];
    pfe_l2br_static_entry_t static_entries_pool[PFE_CFG_L2BR_STATICS_MAX];
    #endif /* PFE_CFG_L2BR_STATICS_ENABLE */
    uint16 def_vlan;                          /*!< Default VLAN */
    uint32 dmem_fb_bd_base;                   /*!< Address within classifier memory where the fall-back bridge domain structure is located */
    uint32 dmem_def_bd_base;                  /*!< Address within classifier memory where the default bridge domain structure is located */
    uint32 dmem_vlan_hash_base;               /*!< Address within classifier memory where the vlan hash table is located */
    pfe_l2br_domain_get_crit_t cur_crit;        /*!< Current 'get' criterion (to get domains) */
    pfe_l2br_static_ent_get_crit_t cur_crit_ent;/*!< Current 'get' criterion (to get static entry) */
    uint32 curr_domain;                       /*!< The current domain list item */
    #ifdef PFE_CFG_L2BR_STATICS_ENABLE
    uint32 curr_static_ent;                   /*!< The current static entry list item */
    #endif /* PFE_CFG_L2BR_STATICS_ENABLE */
    union
    {
        uint16 vlan;
        pfe_phy_if_t *phy_if;
    } cur_domain_crit_arg;                      /*!< Current domain criterion argument */
    struct
    {
        uint16 vlan;
        pfe_mac_addr_t mac;
    } cur_static_ent_crit_arg;                  /*!< Current static entry argument */
};

/**
 * @brief   MAC table flush types
 */
typedef enum
{
    PFE_L2BR_FLUSH_ALL_MAC,
    PFE_L2BR_FLUSH_STATIC_MAC,
    PFE_L2BR_FLUSH_LEARNED_MAC
} pfe_l2br_flush_types;

#define VLAN_STATS_VEC_SIZE 128

#define ETH_43_PFE_START_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"

static uint8 stats_index[VLAN_STATS_VEC_SIZE];

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_l2br_t l2_bridge_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#ifdef PFE_CFG_L2BR_STATICS_ENABLE
static const pfe_isa_definition_t l2_bridge_instance_statics_isa_def =
{
    .item_count = PFE_CFG_L2BR_STATICS_MAX,
    .item_size = sizeof(pfe_l2br_static_entry_t),
    .flags = { .ordered = ISA_FLAG_STRICT_ORDER },
    .item_indexes = l2_bridge_instance.static_entries_pool_index,
    .items = l2_bridge_instance.static_entries_pool
};
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

/* index to PHY IF ID conversion array */
static const pfe_ct_phy_if_id_t pfe_index_to_phy_if_id[] =
{
    PFE_PHY_IF_ID_EMAC0,
    PFE_PHY_IF_ID_EMAC1,
    PFE_PHY_IF_ID_EMAC2,
    PFE_PHY_IF_ID_HIF,
    PFE_PHY_IF_ID_HIF_NOCPY,
    PFE_PHY_IF_ID_UTIL,
    PFE_PHY_IF_ID_HIF0,
    PFE_PHY_IF_ID_HIF1,
    PFE_PHY_IF_ID_HIF2,
    PFE_PHY_IF_ID_HIF3
};
/* bridge domains storage ISA properties definition */
static const pfe_isa_definition_t l2_bridge_instance_domains_isa_def =
{
    .item_count = PFE_CFG_L2BR_DOMAINS_MAX,
    .item_size = sizeof(pfe_l2br_domain_t),
    .flags = { .ordered = ISA_FLAG_STRICT_ORDER },
    .item_indexes = l2_bridge_instance.domains_pool_index,
    .items = l2_bridge_instance.domains_pool
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_bd_write_to_class(const pfe_l2br_t *bridge, uint32 base, const pfe_ct_bd_entry_t *class_entry);
static errno_t pfe_l2br_update_hw_entry(pfe_l2br_domain_t *domain);
static pfe_l2br_domain_t *pfe_l2br_create_default_domain(pfe_l2br_t *bridge, uint16 vlan);
static pfe_l2br_domain_t *pfe_l2br_create_fallback_domain(pfe_l2br_t *bridge);
static bool_t pfe_l2br_domain_match_if_criterion(const pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface);
static bool_t pfe_l2br_domain_match_criterion(const pfe_l2br_t *bridge, pfe_l2br_domain_t *domain);
static errno_t pfe_l2br_set_mac_aging_timeout(pfe_class_t *class, const uint16 timeout);
static errno_t pfe_l2br_config_domain(const pfe_l2br_t *bridge, pfe_l2br_domain_t *domain);
static void pfe_l2br_create_mandatory_domains(const pfe_class_t *class, pfe_l2br_t **bridge, uint16 def_vlan, uint16 def_aging_time);
static errno_t pfe_l2br_flush_all_mac_table(pfe_l2br_t *bridge);
static errno_t pfe_l2br_flush_learned_mac_table(const pfe_l2br_t *bridge, pfe_l2br_table_entry_t *entry, pfe_l2br_table_iterator_t *l2t_iter);
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
static bool_t pfe_l2br_static_entry_match_criterion(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t *static_ent);
static errno_t pfe_l2br_static_entry_destroy_nolock(pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent);
static errno_t pfe_l2br_flush_static_mac_table(pfe_l2br_t *bridge);
static errno_t pfe_l2br_set_static_entry(pfe_l2br_t *bridge, uint16 vlan, const pfe_mac_addr_t mac, uint32 new_fw_list, pfe_l2br_static_entry_t **static_entry);
static errno_t pfe_l2br_domain_flush_by_if_static(const pfe_l2br_domain_t *domain, pfe_l2br_t *bridge, uint32 iface_bitflag);
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */
static errno_t pfe_l2br_domain_destroy_instance(pfe_l2br_domain_t *domain);
static void pfe_l2br_table_destroy_entry_iterator(pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry);
static void pfe_l2br_table_create_entry_iterator(pfe_l2br_t *bridge, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_domain_flush_by_if_dynamic_static(const pfe_l2br_domain_t *domain, pfe_l2br_t *bridge, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry, uint32 iface_bitflag);
static errno_t pfe_l2br_add_vlan_to_collision_space(pfe_l2br_domain_t *domain, l2br_vlan_hash_entry_t *vlan_new_entry, uint8 prev_entry_pos);
static void pfe_l2br_domain_destroy_log(pfe_l2br_domain_t *domain);

/**
 * @brief       Write bridge domain structure to classifier memory
 * @param[in]   bridge The bridge instance
 * @param[in]   base Memory location where to write
 * @param[in]   class_entry Pointer to the structure to be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
static errno_t pfe_bd_write_to_class(const pfe_l2br_t *bridge, uint32 base, const pfe_ct_bd_entry_t *class_entry)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == class_entry) || (NULL_PTR == bridge) || (0U == base)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_class_write_dmem(bridge->class, -1, (addr_t)base, (const void *)class_entry, sizeof(pfe_ct_bd_entry_t));
    }
    return ret;
}

/**
 * @brief       Write bridge domain structure to classifier memory
 * @param[in]   domain Pointer to the structure to be written
 * @param[in]   base Memory location where to write
 */
static void pfe_l2br_update_hw_ll_entry(pfe_l2br_domain_t *domain, uint32 base)
{
    pfe_ct_bd_entry_t sw_bd;

    /* Sanity check */
    ct_assert(sizeof(pfe_ct_bd_entry_t) <= sizeof(uint64));

    (void)autolibc_memset(&sw_bd, 0, sizeof(pfe_ct_bd_entry_t));

    /* Convert VLAN table result to fallback domain representation */
    sw_bd.val = domain->u.action_data.val;

    /* Convert to network endian */
    *(uint64*)&sw_bd = cpu_to_be64(*(uint64*)&sw_bd);

    /* Update classifier memory (all PEs) */
    if (EOK != pfe_bd_write_to_class(domain->bridge, base, &sw_bd))
    {
        NXP_LOG_DEBUG("Class memory write failed\n");
    }
}

/**
 * @brief       Get hash of a vlan id
 * @param[in]   vlan_id from witch the hash is computed
 * @retval      Hash of the vlan id
 */
static inline uint8 fp_l2br_vlan_table_get_hash(uint16 vlan_id)
{
    return (uint8)(vlan_id & 0x3FU);
}

/**
 * @brief       Write vlan entry to classifier memory
 * @param[in]   bridge The bridge instance
 * @param[in]   pos Entry position in vlan table
 * @param[in]   class_entry Pointer to the structure to be written
 */
static void pfe_vlan_write_to_class(const pfe_l2br_t *bridge, uint32 pos, const l2br_vlan_hash_entry_t *class_entry)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == class_entry) || (NULL_PTR == bridge)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK != pfe_class_write_dmem(bridge->class,
                                        -1,
                                        ADDR_BASE_OFFSET(bridge->dmem_vlan_hash_base, (uint64)pos * sizeof(l2br_vlan_hash_entry_t)),
                                        (const void *)class_entry,
                                        sizeof(l2br_vlan_hash_entry_t)))
        {
            NXP_LOG_ERROR("Class memory write failed\n");
        }
    }
}

/**
 * @brief       Read vlan entry from classifier memory
 * @param[in]   bridge The bridge instance
 * @param[in]   pos Entry position in vlan table
 * @param[out]  class_entry Pointer to the structure to be read
 */
static void pfe_vlan_read_from_class(const pfe_l2br_t *bridge, uint32 pos, l2br_vlan_hash_entry_t *class_entry)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == class_entry) || (NULL_PTR == bridge)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK != pfe_class_read_dmem( bridge->class,
                                        0,
                                        class_entry,
                                        ADDR_BASE_OFFSET(bridge->dmem_vlan_hash_base, (uint64)pos * sizeof(l2br_vlan_hash_entry_t)),
                                        sizeof(l2br_vlan_hash_entry_t)))
        {
            NXP_LOG_ERROR("Class memory read failed\n");
        }
    }
}

/**
 * @brief       Fill vlan entry based on domain information
 * @param[in]   domain Pointer to vlan domain entry
 * @param[out]  entry Pointer to the class structure
 */
static void pfe_l2br_vlan_action_to_entry(const pfe_l2br_domain_t *domain, l2br_vlan_hash_entry_t *entry)
{
    uint64 tmp64;

    entry->vlan = oal_htons(domain->vlan);

    /* Convert VLAN table result to fallback domain representation */
    entry->entry.val = domain->u.action_data.val;

    /* Convert to network endian */
    tmp64 = cpu_to_be64(entry->entry.val);
    (void)autolibc_memcpy(&entry->entry.val, &tmp64, sizeof(uint64));

    entry->flags = MAC_VALID_FLAG;
    entry->field_valids = MAC_ENTRY_VLAN_VALID;
}

/**
 * @brief       Find and update a given vlan domain to vlan class memory.
 * @param[in]   domain Pointer to vlan domain structure to update.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT Vlan is not in class memory
 */
errno_t pfe_l2br_update_vlan_hash_entry(pfe_l2br_domain_t *domain)
{
    l2br_vlan_hash_entry_t vlan_new_entry, vlan_current_entry;
    uint8 pos;
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(&vlan_new_entry, 0, sizeof(l2br_vlan_hash_entry_t));
        (void)autolibc_memset(&vlan_current_entry, 0, sizeof(l2br_vlan_hash_entry_t));

        pfe_l2br_vlan_action_to_entry(domain, &vlan_new_entry);

        /* Read the entry at the vlan hash position */
        pos = fp_l2br_vlan_table_get_hash(domain->vlan);
        pfe_vlan_read_from_class(domain->bridge, pos, &vlan_current_entry);

        /* If the vlan exists in hash update the entry */
        if (vlan_current_entry.vlan == vlan_new_entry.vlan)
        {
            vlan_current_entry.entry.val = vlan_new_entry.entry.val;
            vlan_current_entry.flags |= MAC_VALID_FLAG;
            vlan_current_entry.field_valids |= MAC_ENTRY_VLAN_VALID;

            pfe_vlan_write_to_class(domain->bridge, pos, &vlan_current_entry);
            ret = EOK;
        }
        else
        {
            /* Entry is full with other entry find a place in collision */
            if (0U != (vlan_current_entry.flags & MAC_VALID_FLAG))
            {
                /* Go through all callisions */
                while (0U != (vlan_current_entry.flags & MAC_COL_PTR_VALID_FLAG))
                {
                    pos = (uint8) (oal_ntohs(vlan_current_entry.col_ptr) & UINT8_MAX);
                    pfe_vlan_read_from_class(domain->bridge, pos, &vlan_current_entry);
                    if (vlan_new_entry.vlan == vlan_current_entry.vlan)
                    {
                        pfe_vlan_write_to_class(domain->bridge, pos, &vlan_new_entry);
                        /* Found the entry in the collision domain */
                        ret = EOK;
                        break;
                    }
                }
            }
        }
    }

    return ret;
}

/* Find a place to add entry into the collision space */
static errno_t pfe_l2br_add_vlan_to_collision_space(pfe_l2br_domain_t *domain,
                                                    l2br_vlan_hash_entry_t *vlan_new_entry,
                                                    uint8 prev_entry_pos)
{
    l2br_vlan_hash_entry_t vlan_current_entry, vlan_tmp_entry;  
    errno_t ret = EOK;
    uint8 hash_size = 0U;
    uint8 coll_space = 0U;
    uint8 pos = prev_entry_pos;

    (void)autolibc_memset(&vlan_current_entry, 0, sizeof(l2br_vlan_hash_entry_t));
    (void)autolibc_memset(&vlan_tmp_entry, 0, sizeof(l2br_vlan_hash_entry_t));

    ret = pfe_feature_mgr_table_get_payload("software_vlan_table", FW_FEATURE_TABLE_CONFIG, "size", &hash_size);
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Wrong vlan software table config size\n");
    }
    else
    {
        ret = pfe_feature_mgr_table_get_payload("software_vlan_table", FW_FEATURE_TABLE_CONFIG, "coll_space", &coll_space);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Wrong vlan software table config collision space\n");
        }            
    }

    if (ret == EOK)
    {
        pfe_vlan_read_from_class(domain->bridge, pos, &vlan_current_entry);
        vlan_tmp_entry = vlan_current_entry;

        if (pos < coll_space)
        {
            /* prev_entry_pos entry was not in colision space (only one entry with given hash).
             * Start searching for free slot from the beginning of collision space. */
            pos = coll_space;
            pfe_vlan_read_from_class(domain->bridge, pos, &vlan_tmp_entry);
        }
        /* Find the first free postion in the collision space */
        while ((vlan_tmp_entry.flags & MAC_VALID_FLAG) != 0U) 
        {
            pos ++;
            if (pos >= hash_size)
            {
                ret =  ENOMEM;
                break;
            }
            pfe_vlan_read_from_class(domain->bridge, pos, &vlan_tmp_entry);
        }
        if (pos < hash_size)
        {
            /* Write the new entry to pos */
            pfe_vlan_write_to_class(domain->bridge, pos, vlan_new_entry);

            /* Update prev vlan id with collision pointer to the new vlan entry */
            vlan_current_entry.flags |= MAC_COL_PTR_VALID_FLAG;
            vlan_current_entry.col_ptr = (uint16)pos << 8;  /* swap endianess (U16) */;
            pfe_vlan_write_to_class(domain->bridge, prev_entry_pos, &vlan_current_entry);
        }
    }

    return ret;
}

/**
 * @brief       Find the position and add a given vlan domain to vlan class memory.
 * @param[in]   domain Pointer to vlan domain structure to add.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      EEXIST Vlan already exists in class memory
 * @retval      ENOMEM No memory left to add a new entry
 */
errno_t pfe_l2br_add_vlan_hash_entry(pfe_l2br_domain_t *domain)
{
    l2br_vlan_hash_entry_t vlan_new_entry, vlan_current_entry;
    uint8 pos;
    errno_t  ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {

        (void)autolibc_memset(&vlan_new_entry, 0, sizeof(l2br_vlan_hash_entry_t));
        (void)autolibc_memset(&vlan_current_entry, 0, sizeof(l2br_vlan_hash_entry_t));

        pfe_l2br_vlan_action_to_entry(domain, &vlan_new_entry);

        /* Read the entry at the vlan hash position */
        pos = fp_l2br_vlan_table_get_hash(domain->vlan);
        pfe_vlan_read_from_class(domain->bridge, pos, &vlan_current_entry);

        /* Check if the VLAN does not exitst as a first entry at hash position */
        if (vlan_current_entry.vlan == vlan_new_entry.vlan)
        {
            ret = EEXIST;
        }
        else
        {
            /* Entry is full with other entry find a place in collision */
            if ((vlan_current_entry.flags & MAC_VALID_FLAG) != 0U)
            {
                /* Go through all callisions*/
                while ((vlan_current_entry.flags & MAC_COL_PTR_VALID_FLAG) != 0U)
                {
                    pos = (uint8 ) (oal_ntohs(vlan_current_entry.col_ptr) & UINT8_MAX);
                    pfe_vlan_read_from_class(domain->bridge, pos, &vlan_current_entry);
                    if (vlan_new_entry.vlan == vlan_current_entry.vlan)
                    {
                        /* Found the entry in the collision domain */
                        break;
                    }
                }

                ret = pfe_l2br_add_vlan_to_collision_space(domain, &vlan_new_entry, pos);
            }
            else
            {
                /* Write the new entry in hash */
                pfe_vlan_write_to_class(domain->bridge, pos, &vlan_new_entry);
            }
        }
    }

    return ret;
}

/**
 * @brief       Delete a given vlan domain from vlan class memory.
 * @param[in]   domain Pointer to vlan domain structure to be removed.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 **/
errno_t pfe_l2br_delete_vlan_hash_entry(pfe_l2br_domain_t *domain)
{
    l2br_vlan_hash_entry_t vlan_zero_entry, vlan_current_entry, vlan_prev_entry, vlan_tmp_entry;
    uint8 pos, prev_entry_pos, next_entry_pos;
    bool_t erase_collision_entry = FALSE;
    errno_t  ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {

        (void)autolibc_memset(&vlan_zero_entry, 0, sizeof(l2br_vlan_hash_entry_t));
        (void)autolibc_memset(&vlan_current_entry, 0, sizeof(l2br_vlan_hash_entry_t));
        (void)autolibc_memset(&vlan_prev_entry, 0, sizeof(l2br_vlan_hash_entry_t));
        (void)autolibc_memset(&vlan_tmp_entry, 0, sizeof(l2br_vlan_hash_entry_t));

        pos = fp_l2br_vlan_table_get_hash(domain->vlan);
        pfe_vlan_read_from_class(domain->bridge, pos, &vlan_current_entry);

        /* If the entry is in hash */
        if (domain->vlan == oal_ntohs(vlan_current_entry.vlan))
        {
            /* If the entry has collision */
            if ((vlan_current_entry.flags & MAC_COL_PTR_VALID_FLAG) != 0U)
            {
                next_entry_pos = (uint8 ) (oal_ntohs(vlan_current_entry.col_ptr) & UINT8_MAX);
                pfe_vlan_read_from_class(domain->bridge, next_entry_pos, &vlan_tmp_entry);
                erase_collision_entry = TRUE;
            }
            /* Write to hash the next collision entry */
            pfe_vlan_write_to_class(domain->bridge, pos, &vlan_tmp_entry);

            if (TRUE == erase_collision_entry)
            {
                pfe_vlan_write_to_class(domain->bridge, next_entry_pos, &vlan_zero_entry);
            }
        }
        else
        {
            /* Go through all collisions */
            while ((vlan_current_entry.flags & MAC_COL_PTR_VALID_FLAG) != 0U)
            {
                prev_entry_pos = pos;
                vlan_prev_entry = vlan_current_entry;

                pos = (uint8 ) (oal_ntohs(vlan_current_entry.col_ptr) & UINT8_MAX);
                pfe_vlan_read_from_class(domain->bridge, pos, &vlan_current_entry);

                /* Entry found */
                if (domain->vlan == oal_ntohs(vlan_current_entry.vlan))
                {
                    /* There is an entry after in collision */
                    if ((vlan_current_entry.flags & MAC_COL_PTR_VALID_FLAG) != 0U)
                    {
                        vlan_prev_entry.col_ptr = vlan_current_entry.col_ptr;
                    }
                    else
                    {
                        vlan_prev_entry.flags = 0;
                        vlan_prev_entry.col_ptr = 0;
                    }
                    /* Update collision pointer on the prev position */
                    pfe_vlan_write_to_class(domain->bridge, prev_entry_pos, &vlan_prev_entry);

                    pfe_vlan_write_to_class(domain->bridge, pos, &vlan_zero_entry);
                    break;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Update HW entry according to domain setup
 * @details     Function is intended to propagate domain configuration from host SW instance
 *              form to PFE HW/FW representation.
 * @param[in]   domain The domain instance
 * @return      EOK or error code in case of failure
 */
static errno_t pfe_l2br_update_hw_entry(pfe_l2br_domain_t *domain)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* In case of fall-back domain the classifier memory must be updated too */
        if (TRUE == domain->is_fallback)
        {
            /* Update classifier memory (all PEs) */
            pfe_l2br_update_hw_ll_entry(domain, domain->bridge->dmem_fb_bd_base);
            if (TRUE == pfe_feature_mgr_is_available("software_vlan_table"))
            {
                (void)pfe_l2br_update_vlan_hash_entry(domain);
            }
            ret = EOK;
        }
        else
        {
            /* In case of fall-back domain the classifier memory must be updated too */
            if (TRUE == domain->is_default)
            {
                /* Update classifier memory (all PEs) */
                pfe_l2br_update_hw_ll_entry(domain, domain->bridge->dmem_def_bd_base);
                if (TRUE == pfe_feature_mgr_is_available("software_vlan_table"))
                {
                    (void)pfe_l2br_update_vlan_hash_entry(domain);
                }
            }
            /* Update standard or default domain entry */
            ret = pfe_l2br_table_entry_set_action_data(&domain->vlan_entry, domain->u.action_data_u64val);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Can't set action data: %d\n", ret);
                ret = ENOEXEC;
            }
            else
            {
                if (TRUE == pfe_feature_mgr_is_available("software_vlan_table"))
                {
                    ret = pfe_l2br_update_vlan_hash_entry(domain);
                }
                else
                {
                    /* Propagate change to HW table */
                    ret = pfe_l2br_table_update_entry(domain->bridge->vlan_table, &domain->vlan_entry);
                }
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Can't update VLAN table entry: %d\n", ret);
                    ret = ENOEXEC;
                }
            }
        }
    }
    return ret;
}

/**
 * @brief       Get the next free index in the vlan stats table
 * @return      The index
 */
static uint8 pfe_l2br_domain_get_free_stats_index(const pfe_l2br_t *bridge)
{
    /*Index 0 is reseved for fallback domain and domains outside stats range.
     * The fallback domain does not call pfe_l2br_domain_create*/
    uint16 index = 1;

    while (index < bridge->domain_stats_table_size)
    {
        if (stats_index[index] == 0U)
        {
            stats_index[index] = 1U;
            break;
        }
        index ++;
    }

    /* domain outside stats range. */
    if (index == bridge->domain_stats_table_size)
    {
        index = 0;
    }

    return index;
}

/**
 * @brief       Free the index in the stats table
 * @param[in]   Index of the table
 */
static void pfe_l2br_domain_free_stats_index(uint8 index)
{
    stats_index[index] = 0U;
}

/**
 * @brief       Create the vlan stats table
 * @details     Create and allocate in dmem the space for stats table that
 *              include all configured vlans
 * @param[in]   Class instance
 * @param[in]   Number of configured vlan
 * @return      DMEM address of the table
 */
static uint32 pfe_l2br_create_vlan_stats_table(pfe_class_t *class, uint16 vlan_count)
{
    addr_t                   addr;
    uint32                 size;
    pfe_ct_vlan_statistics_t temp;
    errno_t                  res;
    pfe_ct_class_mmap_t      mmap;

    /* Calculate needed size */
    size = (uint32)((uint32)vlan_count * sizeof(pfe_ct_vlan_stats_t));
    /* Allocate DMEM */
    addr = pfe_class_dmem_heap_alloc(class, size);
    if (0U == addr)
    {
        NXP_LOG_ERROR("Not enough DMEM memory\n");
    }
    else
    {
        res = pfe_class_get_mmap(class, 0, &mmap);

        if (EOK != res)
        {
            NXP_LOG_ERROR("Cannot get class memory map\n");
            addr = (uint32)res;
        }
        else
        {
            /* Write the table header */
            temp.vlan_count = oal_htons(vlan_count);
            temp.vlan = oal_htonl(addr);
            temp.reserved16 = 0U;
            /*It is safe to write the table pointer because PEs are gracefully stopped
     * and configuration read*/
            res = pfe_class_write_dmem(class, -1, oal_ntohl(mmap.vlan_statistics), (void *)&temp, sizeof(pfe_ct_vlan_statistics_t));
            if (EOK != res)
            {
                NXP_LOG_ERROR("Cannot write to DMEM\n");
                pfe_class_dmem_heap_free(class, addr);
                addr = 0U;
            }
        }
    }
    /* Return the DMEM address */
    return addr;
}

/**
 * @brief       Destroy the vlan stats table
 * @details     Free from dmem the space filled by the table
 * @param[in]   Table address
 * @param[in]   Class instance
 */
static errno_t pfe_l2br_destroy_vlan_stats_table(pfe_class_t *class, uint32 table_address)
{
    pfe_ct_vlan_statistics_t temp = { 0 };
    pfe_ct_class_mmap_t      mmap;
    errno_t                  res;

    if (0U == table_address)
    {
        res = EOK;
    }
    else
    {
        res = pfe_class_get_mmap(class, 0, &mmap);

        if (EOK != res)
        {
            NXP_LOG_ERROR("Cannot get class memory map\n");
        }
        else
        {
            /*It is safe to write the table pointer because PEs are gracefully stopped
     * and configuration read*/
            res = pfe_class_write_dmem(class, -1, oal_ntohl(mmap.vlan_statistics), (void *)&temp, sizeof(pfe_ct_vlan_statistics_t));
            if (EOK != res)
            {
                NXP_LOG_ERROR("Cannot write to DMEM\n");
            }
            else
            {
                pfe_class_dmem_heap_free(class, table_address);
            }
        }
    }
    return res;
}

/* Attempt to destroy domain, in case of failure throw LOG_ERROR */
static void pfe_l2br_domain_destroy_log(pfe_l2br_domain_t *domain)
{
    if (EOK != pfe_l2br_domain_destroy(domain))
    {
        NXP_LOG_ERROR("Unable to destroy bridge domain\n");
    }
}

/**
 * @brief       Config for bridge domain
 * @param[in]   bridge The L2 bridge instance
 * @param[in]   domain the bridge domain
 * @retval      EOK Success
 * @retval      ENOEXEC Command failed
 */
static errno_t pfe_l2br_config_domain(const pfe_l2br_t *bridge, pfe_l2br_domain_t *domain)
{
    errno_t ret = EOK;

    /*  Prepare VLAN table entry. At the beginning the bridge entry does not contain
        any ports. */
    if (NULL_PTR == pfe_l2br_table_entry_create(bridge->vlan_table, &domain->vlan_entry))
    {
        NXP_LOG_DEBUG("Can't create vlan table entry\n");
        pfe_l2br_domain_destroy_log(domain);
        ret = ENOEXEC;
    }
    else
    {
        /*  Set VLAN */
        ret = pfe_l2br_table_entry_set_vlan(&domain->vlan_entry, domain->vlan);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("Can't set vlan: %d\n", ret);
            pfe_l2br_domain_destroy_log(domain);
        }
        else
        {
            domain->u.action_data.item.forward_list = 0U;
            domain->u.action_data.item.untag_list = 0U;
            domain->u.action_data.item.ucast_hit_action = (uint64)L2BR_ACT_DISCARD;
            domain->u.action_data.item.ucast_miss_action = (uint64)L2BR_ACT_DISCARD;
            domain->u.action_data.item.mcast_hit_action = (uint64)L2BR_ACT_DISCARD;
            domain->u.action_data.item.mcast_miss_action = (uint64)L2BR_ACT_DISCARD;
            domain->u.action_data.item.stats_index = pfe_l2br_domain_get_free_stats_index(bridge);

            if (domain->u.action_data.item.stats_index == 0U)
            {
                NXP_LOG_ERROR("No more space for vlan statistics.The stats will be added to vlan 0 fallback\n");
            }

            domain->stats_index = (uint8)domain->u.action_data.item.stats_index;

            /*  Set action data */
            ret = pfe_l2br_table_entry_set_action_data(&domain->vlan_entry, domain->u.action_data_u64val);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Can't set action data: %d\n", ret);
                pfe_l2br_domain_destroy_log(domain);
            }
            else
            {
                if (TRUE == pfe_feature_mgr_is_available("software_vlan_table"))
                {
                    ret = pfe_l2br_add_vlan_hash_entry(domain);
                }
                else
                {
                    /*  Add new VLAN table entry */
                    ret = pfe_l2br_table_add_entry(domain->bridge->vlan_table, &domain->vlan_entry);
                }

                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Could not add VLAN table entry: %d\n", ret);
                    pfe_l2br_domain_destroy_log(domain);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Create L2 bridge domain instance
 * @details     By default, new domain is configured to drop all matching packets. Use the
 *              pfe_l2br_domain_set_[ucast/mcast]_action() to finish the configuration. The
 *              instance is automatically bound to the bridge and can be retrieved by
 *              the pfe_l2br_get_first_domain()/pfe_l2br_get_next_domain() calls.
 * @param[in]   bridge The L2 bridge instance
 * @param[in]   vlan VLAN ID to identify the bridge domain
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 * @retval      ETIMEDOUT Timed out
 * @retval      EPERM Operation not permitted (domain already created)
 */
errno_t pfe_l2br_domain_create(pfe_l2br_t *bridge, uint16 vlan)
{
    pfe_l2br_domain_t *domain;
    errno_t            ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Check if the domain is not duplicate */
        if (NULL_PTR != pfe_l2br_get_first_domain(bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)vlan))
        {
            NXP_LOG_ERROR("Domain with vlan %d does already exist\n", vlan);
            ret = EPERM;
        }
        else
        {
            domain = (pfe_l2br_domain_t *)isa_reserve(&bridge->domains);
            if (NULL_PTR == domain)
            {
                NXP_LOG_DEBUG("isa_reserve() failed\n");
                ret = ENOMEM;
            }
            else
            {
                (void)autolibc_memset(domain, 0, sizeof(pfe_l2br_domain_t));
                domain->bridge = bridge;
                domain->vlan = vlan;
                domain->is_default = FALSE;
                ret = pfe_l2br_config_domain(bridge, domain);
            }
        }
    }

    return ret;
}

static errno_t pfe_l2br_domain_destroy_instance(pfe_l2br_domain_t *domain)
{
    errno_t ret = EOK;

    if (TRUE == domain->is_fallback)
    {
        /*  Disable the fall-back domain traffic */
        ret = pfe_l2br_domain_set_ucast_action(domain, L2BR_ACT_DISCARD, L2BR_ACT_DISCARD);
        if (EOK == ret)
        {
            ret = pfe_l2br_domain_set_mcast_action(domain, L2BR_ACT_DISCARD, L2BR_ACT_DISCARD);
        }
    }

    /*  Remove the domain instance from global list if it has been added there */
    pfe_l2br_domain_free_stats_index(domain->stats_index);

    return ret;
}

/**
 * @brief       Destroy L2 bridge domain instance
 * @param[in]   bridge The bridge domain instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_l2br_domain_destroy(pfe_l2br_domain_t *domain)
{
    errno_t                ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remove all associated interfaces */
        if (0U != domain->ifaces)
        {
            NXP_LOG_INFO("Non-empty bridge domain is being destroyed\n");
        }

        if (PFE_L2BR_TABLE_INVALID != domain->vlan_entry.type)
        {
            if (TRUE == pfe_feature_mgr_is_available("software_vlan_table"))
            {
                ret = pfe_l2br_delete_vlan_hash_entry(domain);
            }
            else
            {
                /*  Remove entry from the table */
                ret = pfe_l2br_table_del_entry(domain->bridge->vlan_table, &domain->vlan_entry);
            }

            if (EOK != ret)
            {
                NXP_LOG_ERROR("Can't delete entry from VLAN table: %d\n", ret);
                ret = ENOEXEC;
            }
            else
            {
                /*  Release the table entry instance */
                (void)pfe_l2br_table_entry_destroy(&domain->vlan_entry);
            }
        }

        if (EOK == ret)
        {
            ret = pfe_l2br_domain_destroy_instance(domain);
            const sint64 domain_subscript = isa_release(&domain->bridge->domains, domain);
            if ((domain_subscript >= 0) && (domain_subscript < (sint64)domain->bridge->curr_domain))
            {
                /*  Decrease the iterator so we can call destroy() between get_first()
                    and get_next() calls. */
                domain->bridge->curr_domain--;
            }
        }
    }

    return ret;
}

/**
 * @brief       Create default L2 bridge domain instance
 * @details     Create default bridge domain (empty, no interface assigned)
 * @param[in]   bridge The L2 bridge instance
 * @param[in]   vlan VLAN ID to identify the bridge domain
 * @return      The instance or NULL if failed
 */
static pfe_l2br_domain_t *pfe_l2br_create_default_domain(pfe_l2br_t *bridge, uint16 vlan)
{
    errno_t             ret;
    pfe_l2br_domain_t * domain;
    pfe_ct_class_mmap_t class_mmap;
    uint32 vlan_hash_addr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        domain = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK != pfe_class_get_mmap(bridge->class, 0, &class_mmap))
        {
            NXP_LOG_ERROR("Could not get memory map\n");
            domain = NULL_PTR;
        }
        else
        {

            bridge->dmem_def_bd_base = oal_ntohl(class_mmap.dmem_def_bd_base);

            if (EOK == pfe_feature_mgr_enable("software_vlan_table"))
            {
                ret = pfe_feature_mgr_table_get_payload("software_vlan_table", FW_FEATURE_TABLE_CONFIG, "vlan_hash", (uint8*) &vlan_hash_addr);
                if (EOK == ret)
                {
                    bridge->dmem_vlan_hash_base = vlan_hash_addr;
                    NXP_LOG_INFO("Software vlan hash table @ p0x%x\n", (uint_t)vlan_hash_addr);
                }
                else
                {
                    /*Fall back to hardware vlan table*/
                    (void)pfe_feature_mgr_disable("software_vlan_table");
                    NXP_LOG_INFO("Hardware vlan hash table\n");
                }
            }
            else
            {
                NXP_LOG_INFO("Hardware vlan hash table\n");
            }

            ret = pfe_l2br_domain_create(bridge, vlan);

            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Can't create default domain\n");
                domain = NULL_PTR;
            }
            else
            {
                domain = pfe_l2br_get_first_domain(bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)vlan);
                if (NULL_PTR == domain)
                {
                    NXP_LOG_ERROR("Default domain not found\n");
                }
                else
                {
                    domain->is_default = TRUE;
                    if (EOK != pfe_l2br_update_hw_entry(domain))
                    {
                        (void)isa_release(&bridge->domains, domain);
                        domain = NULL_PTR;
                    }
                }
            }
        }
    }
    return domain;
}

/**
 * @brief       Create fall-back L2 bridge domain instance
 * @details     Create fall-back bridge domain (empty, no interface assigned)
 * @param[in]   bridge The L2 bridge instance
 * @return      The instance or NULL if failed
 */
static pfe_l2br_domain_t *pfe_l2br_create_fallback_domain(pfe_l2br_t *bridge)
{
    pfe_ct_class_mmap_t class_mmap;
    pfe_l2br_domain_t * domain;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        domain = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        domain = (pfe_l2br_domain_t *)isa_reserve(&bridge->domains);
        if (NULL == domain)
        {
            NXP_LOG_DEBUG("Memory allocation failed\n");
        }
        else
        {
            (void)autolibc_memset(domain, 0, sizeof(pfe_l2br_domain_t));
            domain->bridge = bridge;
            /* domain->vlan_entry is not valid for fallback */
            domain->is_fallback = TRUE;
            domain->ifaces = 0U;

            if (EOK != pfe_class_get_mmap(bridge->class, 0, &class_mmap))
            {
                NXP_LOG_ERROR("Could not get memory map\n");
                (void)isa_release(&bridge->domains, domain);
                domain = NULL;
            }
            else
            {
                bridge->dmem_fb_bd_base = oal_ntohl(class_mmap.dmem_fb_bd_base);

                NXP_LOG_INFO("Fall-back bridge domain @ 0x%x (class)\n", (uint_t)bridge->dmem_fb_bd_base);
                NXP_LOG_INFO("Default bridge domain @ 0x%x (class)\n", (uint_t)bridge->dmem_def_bd_base);

                domain->u.action_data.item.forward_list = 0U;
                domain->u.action_data.item.untag_list = 0U;
                domain->u.action_data.item.ucast_hit_action = (uint64)L2BR_ACT_DISCARD;
                domain->u.action_data.item.ucast_miss_action = (uint64)L2BR_ACT_DISCARD;
                domain->u.action_data.item.mcast_hit_action = (uint64)L2BR_ACT_DISCARD;
                domain->u.action_data.item.mcast_miss_action = (uint64)L2BR_ACT_DISCARD;

                if (EOK != pfe_l2br_update_hw_entry(domain))
                {
                    (void)isa_release(&bridge->domains, domain);
                    domain = NULL;
                }
            }
        }
    }
    return domain;
}

/**
 * @brief       Set unicast actions
 * @param[in]   domain The bridge domain instance
 * @param[in]   hit Action to be taken when destination MAC address (uni-cast) of a packet
 *                  matching the domain is found in the MAC table
 * @param[in]   miss Action to be taken when destination MAC address (uni-cast) of a packet
 *                   matching the domain is not found in the MAC table
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_l2br_domain_set_ucast_action(pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t hit, pfe_ct_l2br_action_t miss)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        domain->u.action_data.item.ucast_hit_action = (uint64)hit;
        domain->u.action_data.item.ucast_miss_action = (uint64)miss;

        ret = pfe_l2br_update_hw_entry(domain);
    }
    return ret;
}

/**
 * @brief       Get unicast actions
 * @param[in]   domain The bridge domain instance
 * @param[out]  hit Pointer to memory where hit action shall be written
 * @param[out]  miss Pointer to memory where miss action shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_l2br_domain_get_ucast_action(const pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t *hit, pfe_ct_l2br_action_t *miss)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain) || (NULL == hit) || (NULL == miss)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *hit = (pfe_ct_l2br_action_t)(domain->u.action_data.item.ucast_hit_action);
        *miss = (pfe_ct_l2br_action_t)(domain->u.action_data.item.ucast_miss_action);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Set multi-cast actions
 * @param[in]   domain The bridge domain instance
 * @param[in]   hit Action to be taken when destination MAC address (multi-cast) of a packet
 *                  matching the domain is found in the MAC table
 * @param[in]   miss Action to be taken when destination MAC address (multi-cast) of a packet
 *                   matching the domain is not found in the MAC table
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_l2br_domain_set_mcast_action(pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t hit, pfe_ct_l2br_action_t miss)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        domain->u.action_data.item.mcast_hit_action = (uint64)hit;
        domain->u.action_data.item.mcast_miss_action = (uint64)miss;
        ret = pfe_l2br_update_hw_entry(domain);
    }
    return ret;
}

/**
 * @brief       Get multicast actions
 * @param[in]   domain The bridge domain instance
 * @param[out]  hit Pointer to memory where hit action shall be written
 * @param[out]  miss Pointer to memory where miss action shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_l2br_domain_get_mcast_action(const pfe_l2br_domain_t *domain, pfe_ct_l2br_action_t *hit, pfe_ct_l2br_action_t *miss)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain) || (NULL == hit) || (NULL == miss)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *hit = (pfe_ct_l2br_action_t)(domain->u.action_data.item.mcast_hit_action);
        *miss = (pfe_ct_l2br_action_t)(domain->u.action_data.item.mcast_miss_action);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Add an interface to bridge domain
 * @param[in]   domain The bridge domain instance
 * @param[in]   iface Interface to be added
 * @param[in]   tagged TRUE means the interface is 'tagged', FALSE stands for 'un-tagged'
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 * @retval      EEXIST Already added
 */
errno_t pfe_l2br_domain_add_if(pfe_l2br_domain_t *domain, pfe_phy_if_t *iface, bool_t tagged)
{
    errno_t                ret;
    pfe_ct_phy_if_id_t     id;
    uint64               ifc_mask;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        id = pfe_phy_if_get_id(iface);
        ifc_mask = PFE_GET_IFC_MASK(id);

        /*  Check duplicates */
        if (0U == (domain->ifaces & ifc_mask))
        {
            /*  Add it to this domain = update VLAN table entry */
            domain->u.action_data.item.forward_list |= ifc_mask;

            if (FALSE == tagged)
            {
                domain->u.action_data.item.untag_list |= ifc_mask;
            }

            ret = pfe_l2br_update_hw_entry(domain);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Can't update VLAN table entry: %d\n", ret);
                ret = ENOEXEC;
            }
            else
            {
                /*  Remember the interface instance in global list */
                domain->ifaces |= ifc_mask;
                ret = EOK;
            }
        }
        else
        {
            NXP_LOG_INFO("Interface %d already added\n", id);
            ret = EEXIST;
        }
    }
    return ret;
}

/**
 * @brief       Remove interface from bridge domain
 * @param[in]   domain The bridge domain instance
 * @param[in]   iface Interface to be deleted
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_l2br_domain_del_if(pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface)
{
    errno_t                ret;
    pfe_ct_phy_if_id_t     id;
    uint64               ifc_mask;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remove the interface instance from global list if it has been added there */
        id = pfe_phy_if_get_id(iface);
        ifc_mask = PFE_GET_IFC_MASK(id);

        /*  Check interface presence */
        if (0U != (domain->ifaces & ifc_mask))
        {
            /*  Update HW */
            domain->u.action_data.item.forward_list &= ~ifc_mask;
            domain->u.action_data.item.untag_list &= ~ifc_mask;

            ret = pfe_l2br_update_hw_entry(domain);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("VLAN table entry update failed: %d\n", ret);
                ret = ENOEXEC;
            }
            else
            {
                /* Delete the interface instance from global list */
                domain->ifaces &= ~ifc_mask;
                ret = EOK;
            }
        }
        else
        {
            NXP_LOG_DEBUG("Interface not found\n");
            ret = ENOENT;
        }
    }

    return ret;
}

#ifdef PFE_CFG_L2BR_STATICS_ENABLE
static errno_t pfe_l2br_domain_flush_by_if_static(const pfe_l2br_domain_t *domain, pfe_l2br_t *bridge, uint32 iface_bitflag)
{
    uint32 index;
    errno_t ret = EOK;
    pfe_l2br_static_entry_t *sentry = NULL_PTR;

    /*  Flush interface-related static entries */
    index = 0U;
    while(index < bridge->static_entries.occupied_items_count)
    {
        /*  Get static entry */
        sentry = (pfe_l2br_static_entry_t *)isa_item(&bridge->static_entries, index);
        if (NULL_PTR == sentry)
        {
            NXP_LOG_ERROR("NULL static entry detected!\n");
            index++;
        }
        else
        {
            /*  Check static entry */
            if ((sentry->vlan == domain->vlan) && (0U != (sentry->u.action_data.item.forward_list & iface_bitflag)))
            {
                /*  Remove static entry. isa_release() is inside... */
                ret = pfe_l2br_static_entry_destroy_nolock(bridge, sentry);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Unable to remove static entry: %d\n", ret);
                    index++;
                }
            }
            else
            {
                /* check next entry */
                index++;
            }
        }
    }

    return ret;
}
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

static errno_t pfe_l2br_domain_flush_by_if_dynamic_static(const pfe_l2br_domain_t *domain, pfe_l2br_t *bridge, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry, uint32 iface_bitflag)
{
    errno_t ret = EOK;
    errno_t ret_query = EOK;
    uint16 entry_vlan = 0U;
    pfe_ct_mac_table_result_t entry_action_data = {.val = 0U};
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
    ret = pfe_l2br_domain_flush_by_if_static(domain, bridge, iface_bitflag);
    if (EOK == ret)
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */
    {
        /*  Flush interface-related dynamic entries */
        ret_query = pfe_l2br_table_get_first(bridge->mac_table, l2t_iter, L2BR_TABLE_CRIT_VALID, entry);
        while (EOK == ret_query)
        {
            entry_vlan = (uint16)(pfe_l2br_table_entry_get_vlan(entry) & UINT16_MAX);
            entry_action_data.val = (uint32)(pfe_l2br_table_entry_get_action_data(entry) & UINT32_MAX);

            /*  Check entry */
            if ((entry_vlan == domain->vlan) && (0U != (entry_action_data.item.forward_list & iface_bitflag)))
            {
                /*  Remove entry */
                ret = pfe_l2br_table_del_entry(bridge->mac_table, entry);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Could not delete MAC table entry: %d\n", ret);
                }
            }

            /* Get the next entry */
            ret_query = pfe_l2br_table_get_next(bridge->mac_table, l2t_iter, entry);
        }
    }

    return ret;
}

/**
 * @brief       Flush all MAC table entries of given bridge domain which are related to target interface.
 * @param[in]   domain The L2 bridge domain instance
 * @param[in]   iface The interface
 * @retval      EOK if success, error code if failure
 */
errno_t pfe_l2br_domain_flush_by_if(const pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface)
{
    errno_t                    ret = EOK;
    pfe_l2br_table_entry_t     entry;
    pfe_l2br_table_iterator_t  l2t_iter;
    uint32                   iface_bitflag = 0U;
    pfe_l2br_t *               bridge = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain) || (NULL == domain->bridge) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {

        bridge = domain->bridge;

        /*  Initalize auxiliary tools for MAC table searching */
        iface_bitflag = (uint32)1UL << (uint32)pfe_phy_if_get_id(iface);
        (void)pfe_l2br_table_entry_create(bridge->mac_table, &entry);
        (void)pfe_l2br_iterator_create(&l2t_iter);

        ret = pfe_l2br_domain_flush_by_if_dynamic_static(domain, bridge, &l2t_iter, &entry, iface_bitflag);

        /*  Release entry storage */
        (void)pfe_l2br_table_entry_destroy(&entry);

        /*  Release iterator */
        (void)pfe_l2br_iterator_destroy(&l2t_iter);
    }
    return ret;
}

/**
 * @brief       Get list of associated physical interfaces
 * @param[in]   domain The domain instance
 * @return      Bitmask representing physical interface IDs. Every bit represents ID
 *              corresponding to its position. Bit (1 << 3) represents ID=3. The IDs
 *              match the pfe_ct_phy_if_id_t values.
 */
__attribute__((pure)) uint32 pfe_l2br_domain_get_if_list(const pfe_l2br_domain_t *domain)
{
    uint32 ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = domain->u.action_data.item.forward_list;
    }
    return ret;
}

/**
 * @brief       Get list of associated physical interfaces in 'untag' mode
 * @param[in]   domain The domain instance
 * @return      Bitmask representing physical interface IDs. Every bit represents ID
 *              corresponding to its position. Bit (1 << 3) represents ID=3. The IDs
 *              match the pfe_ct_phy_if_id_t values.
 */
__attribute__((pure)) uint32 pfe_l2br_domain_get_untag_if_list(const pfe_l2br_domain_t *domain)
{
    uint32 untag_if_list;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        untag_if_list = 0;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        untag_if_list = domain->u.action_data.item.untag_list;
    }
    return untag_if_list;
}

/**
 * @brief       Match entry with latest criterion provided via pfe_l2br_domain_get_first_if()
 * @param[in]   domain The L2 bridge domain instance
 * @param[in]   iface The interface to be matched
 * @retval      TRUE Interface matches the criterion
 * @retval      FALSE Interface does not match the criterion
 */
static bool_t pfe_l2br_domain_match_if_criterion(const pfe_l2br_domain_t *domain, const pfe_phy_if_t *iface)
{
    bool_t match;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (domain->cur_crit)
        {
            case L2BD_IF_CRIT_ALL:
                match = TRUE;
                break;

            case L2BD_IF_BY_PHY_IF_ID:
                match = (domain->cur_crit_arg.id == pfe_phy_if_get_id(iface));
                break;

            case L2BD_IF_BY_PHY_IF:
                match = (domain->cur_crit_arg.phy_if == iface);
                break;

            default:
                NXP_LOG_ERROR("Unknown criterion\n");
                match = FALSE;
                break;
        }
    }
    return match;
}

/**
 * @brief       Get first interface belonging to the domain matching given criterion
 * @param[in]   domain The domain instance
 * @param[in]   crit Get criterion
 * @param[in]   arg Pointer to criterion argument
 * @return      The interface instance or NULL if not found
 * @internal
 * @warning     Do not call this function from within the l2br module since it modifies
 *              internal state. Caller does rely on fact that there are no unexpected,
 *              hidden calls of this function.
 * @endinternal
 */
pfe_phy_if_t *pfe_l2br_domain_get_first_if(pfe_l2br_domain_t *domain, pfe_l2br_domain_if_get_crit_t crit, void *arg)
{
    pfe_phy_if_t *         phy_if = NULL;
    bool_t                 known_crit = TRUE;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    bool_t                 is_arg_valid = TRUE;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    static const pfe_ct_phy_if_id_t phys[] =
    {
        PFE_PHY_IF_ID_EMAC0,
        PFE_PHY_IF_ID_EMAC1,
        PFE_PHY_IF_ID_EMAC2,
        PFE_PHY_IF_ID_HIF,
        PFE_PHY_IF_ID_HIF_NOCPY,
        PFE_PHY_IF_ID_UTIL,
        PFE_PHY_IF_ID_HIF0,
        PFE_PHY_IF_ID_HIF1,
        PFE_PHY_IF_ID_HIF2,
        PFE_PHY_IF_ID_HIF3
    };
    uint32 phy_idx = 0U;
        
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remember criterion and argument for possible subsequent pfe_l2br_get_next_domain() calls */
        domain->cur_crit = crit;
        switch (domain->cur_crit)
        {
            case L2BD_IF_CRIT_ALL:
                break;

            case L2BD_IF_BY_PHY_IF_ID:
                phy_idx = (uint32) arg;
                PfeDevAssert(phy_idx <= (uint32)PFE_PHY_IF_ID_MAX);
                domain->cur_crit_arg.id = phys[phy_idx];
                break;

            case L2BD_IF_BY_PHY_IF:
#if defined(PFE_CFG_NULL_ARG_CHECK)
                if (unlikely(NULL == arg))
                {
                    NXP_LOG_ERROR("NULL argument received\n");
                    phy_if = NULL;
                    is_arg_valid = FALSE;
                }
                else
#endif /* PFE_CFG_NULL_ARG_CHECK */
                {
                    domain->cur_crit_arg.phy_if = (pfe_phy_if_t *)arg;
                }
                break;

            default:
                NXP_LOG_ERROR("Unknown criterion\n");
                known_crit = FALSE;
                break;
        }

#if defined(PFE_CFG_NULL_ARG_CHECK)
        if (TRUE == is_arg_valid)
#endif /* PFE_CFG_NULL_ARG_CHECK */
        {
            if (TRUE == known_crit)
            {
                /*  Get first matching entry */
                domain->cur_item = 0U;
                phy_if = pfe_l2br_domain_get_next_if(domain);
            }
        }
    }
    return phy_if;
}

/**
 * @brief       Get next interface from the domain
 * @details     Intended to be used with pfe_l2br_domain_get_first_if().
 * @param[in]   domain The domain instance
 * @return      The interface instance or NULL if not found
 */
pfe_phy_if_t *pfe_l2br_domain_get_next_if(pfe_l2br_domain_t *domain)
{
    pfe_phy_if_t *phy_if;
    uint64     ifc_mask;
    uint64     ifaces;
    bool_t       match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ifc_mask = PFE_GET_IFC_MASK(domain->cur_item);
        PfeDevAssert(ifc_mask > 0U);
        ifaces = domain->ifaces;
        /* don't consider interfaces already examined */
        ifaces &= ~(ifc_mask - 1ULL);
        while ((sizeof(pfe_index_to_phy_if_id) / sizeof(pfe_ct_phy_if_id_t)) > domain->cur_item)
        {
            if (0U != (ifaces & ifc_mask))
            {
                /*  Get interface instance */
                phy_if = pfe_phy_if_get_phy(pfe_index_to_phy_if_id[domain->cur_item]);
                if (NULL_PTR != phy_if)
                {
                    if (TRUE == pfe_l2br_domain_match_if_criterion(domain, phy_if))
                    {
                        match = TRUE;
                        break;
                    }
                }
            }
            ifaces &= ~ifc_mask;
            ifc_mask <<= (uint8)1U;
            /* point to next interface bit mask for next pfe_l2br_domain_get_next_if call */
            domain->cur_item++;
        }
    }

    if (FALSE == match)
    {
        phy_if = NULL_PTR;
    }

    return phy_if;
}

/**
 * @brief       Get VLAN ID
 * @param[in]   domain The domain instance
 * @param[out]  vlan Pointer to memory where the VLAN ID shall be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_l2br_domain_get_vlan(const pfe_l2br_domain_t *domain, uint16 *vlan)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == domain) || (NULL == vlan)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *vlan = domain->vlan;
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Query if domain is default domain
 * @param[in]   domain The domain instance
 * @retval      TRUE Is default
 * @retval      FALSE Is not default
 */
__attribute__((pure)) bool_t pfe_l2br_domain_is_default(const pfe_l2br_domain_t *domain)
{
    bool_t is_deft;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_deft = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        is_deft = domain->is_default;
    }
    return is_deft;
}

/**
 * @brief       Query if domain is fall-back domain
 * @param[in]   domain The domain instance
 * @retval      TRUE Is fall-back
 * @retval      FALSE Is not fall-back
 */
__attribute__((pure)) bool_t pfe_l2br_domain_is_fallback(const pfe_l2br_domain_t *domain)
{
    bool_t is_fallback;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_fallback = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        is_fallback = domain->is_fallback;
    }
    return is_fallback;
}

#ifdef PFE_CFG_L2BR_STATICS_ENABLE
/**
 * @brief       Add L2 bridge static entry
 * @param[in]   vlan VLAN ID to identify the bridge domain
 * @param[in]   mac Static entry MAC address
 * @param[in]   new_fw_list forward list of static entry
 * @param[in]   static_entry pointer store config static entry
 * @retval      EOK Success
 * @retval      EPERM Operation not permitted (static entry already created)
 */
static errno_t pfe_l2br_set_static_entry(pfe_l2br_t *bridge, uint16 vlan, const pfe_mac_addr_t mac, uint32 new_fw_list, pfe_l2br_static_entry_t **static_entry)
{
    errno_t ret;

    /* Create an entry in the MAC table */
    if (NULL_PTR == pfe_l2br_table_entry_create(bridge->mac_table, &(*static_entry)->entry))
    {
        NXP_LOG_ERROR("pfe_l2br_table_entry_create() failed\n");
        ret = ENOMEM;
    }
    else
    {
        /* Configure action data */
        (*static_entry)->u.action_data.val = 0;
        (*static_entry)->u.action_data.item.static_flag = 1;
        (*static_entry)->u.action_data.item.fresh_flag = 0U;
        (*static_entry)->u.action_data.item.local_l3 = 0U;
        (*static_entry)->u.action_data.item.forward_list = new_fw_list;

        if (EOK != pfe_l2br_table_entry_set_vlan(&(*static_entry)->entry, vlan))
        {
            NXP_LOG_ERROR("Couldn't set vlan\n");
            ret = EINVAL;
        }
        else if (EOK != pfe_l2br_table_entry_set_mac_addr(&(*static_entry)->entry, mac))
        {
            NXP_LOG_ERROR("Couldn't set mac address\n");
            ret = EINVAL;
        }
        else if (EOK != pfe_l2br_table_entry_set_action_data(&(*static_entry)->entry, (*static_entry)->u.action_data_u64val))
        {
            NXP_LOG_ERROR("Couldn't set action data\n");
            ret = EINVAL;
        }
        else if (EOK != pfe_l2br_table_add_entry(bridge->mac_table, &(*static_entry)->entry))
        {
            NXP_LOG_ERROR("Couldn't set action data\n");
            ret  = EINVAL;
        }
        else
        {
            ret = EOK;
        }
    }

    if(EOK != ret)
    {
        (void)isa_release(&bridge->static_entries, *static_entry);
    }

    return ret;
}

#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

/**
 * @brief       Create L2 bridge static entry
 * @param[in]   vlan VLAN ID to identify the bridge domain
 * @param[in]   mac Static entry MAC address
 * @param[in]   new_fw_list forward list of static entry
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOMEM Failure when allocating memory
 * @retval      ETIMEDOUT Timed out
 * @retval      EPERM Operation not permitted (static entry already created)
 */
errno_t pfe_l2br_static_entry_create(pfe_l2br_t *bridge, uint16 vlan, const pfe_mac_addr_t mac, uint32 new_fw_list)
{
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
    pfe_l2br_static_entry_t *static_entry;
    pfe_l2br_static_entry_t *static_ent_tmp;
    uint32                index;
    bool_t                  match = FALSE;
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */
    errno_t                 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
    {
        /*  Get first matching entry */
        for(index = 0U; index < bridge->static_entries.occupied_items_count; index++)
        {
            /*  Get data */
            static_ent_tmp = (pfe_l2br_static_entry_t *)isa_item(&bridge->static_entries, index);
            if(NULL != static_ent_tmp)
            {
                if (static_ent_tmp->vlan == vlan)
                {
                    if (0 == autolibc_memcmp(static_ent_tmp->mac, mac, sizeof(pfe_mac_addr_t)))
                    {
                        match = TRUE;
                        break;
                    }
                }
            }
        }

        if (TRUE == match)
        {
            NXP_LOG_ERROR("Duplicit entry\n");
            /* Entry is duplicit */
            ret = EPERM;
        }
        else
        {
            static_entry = (pfe_l2br_static_entry_t *)isa_reserve(&bridge->static_entries);
            if (NULL_PTR == static_entry)
            {
                NXP_LOG_ERROR("No more L2 bridge static entries available\n");
                ret = ENOMEM;
            }
            else
            {
                (void)autolibc_memset(static_entry, 0, sizeof(pfe_l2br_static_entry_t));
                static_entry->vlan = vlan;
                (void)autolibc_memcpy(static_entry->mac, mac, sizeof(pfe_mac_addr_t));

                ret = pfe_l2br_set_static_entry(bridge, vlan, mac, new_fw_list, &static_entry);
                if (EOK != ret)
                {
                    (void)isa_release(&bridge->static_entries, static_entry);
                    static_entry = NULL_PTR;
                }
            }
        }
    }
#else
    (void)bridge;
    (void)vlan;
    (void)mac;
    (void)new_fw_list;

    ret = EINVAL;
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

    return ret;
}

#ifdef PFE_CFG_L2BR_STATICS_ENABLE
static errno_t pfe_l2br_static_entry_destroy_nolock(pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == bridge) || (NULL_PTR == static_ent)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_l2br_table_del_entry(bridge->mac_table, &static_ent->entry);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Static entry couldn't be deleted from HW table (errno %d)\n", ret);
        }

        (void)isa_release(&bridge->static_entries, static_ent);
    }
    return ret;
}
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

/**
 * @brief       Destroy L2 bridge static entry
 * @param[in]   bridge Bridge instance
 * @param[in]   static_ent Static entry to be deleted
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ETIMEDOUT Timed out
 */
errno_t pfe_l2br_static_entry_destroy(pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
    {
        ret = pfe_l2br_static_entry_destroy_nolock(bridge, static_ent);
    }
#else
    (void)bridge;
    (void)static_ent;

    ret = EINVAL;
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

    return ret;
}

/**
 * @brief       Change L2 static entry forward list
 * @param[in]   bridge Bridge instance
 * @param[in]   static_ent Static entry to change
 * @param[in]   new_fw_list New forward list
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT Entry couldn't be updated
 */
errno_t pfe_l2br_static_entry_replace_fw_list(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent, uint32 new_fw_list)
{
    errno_t  ret;
    uint32 tmp;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tmp = static_ent->u.action_data.item.forward_list;
        static_ent->u.action_data.item.forward_list = new_fw_list;

        if (EOK != pfe_l2br_table_entry_set_action_data(&static_ent->entry, static_ent->u.action_data_u64val))
        {
            static_ent->u.action_data.item.forward_list = tmp;
            NXP_LOG_ERROR("Couldn't set action data\n");
            ret = EINVAL;
        }

        else if (EOK != pfe_l2br_table_update_entry(bridge->mac_table, &static_ent->entry))
        {
            static_ent->u.action_data.item.forward_list = tmp;
            NXP_LOG_ERROR("Couldn't update entry\n");
            ret = ENOENT;
        }
        else
        {
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief Sets the local L3 flag (marks/unmarks the MAC address as local one)
 * @param[in]       bridge Bridge instance
 * @param[in]       static_ent Static entry to change
 * @param[in]       local Value to be set
 * @retval EOK      Success
 * @retval EINVAL   Invalid or missing argument
 * @retval          ENOENT Entry couldn't be updated
 */
errno_t pfe_l2br_static_entry_set_local_flag(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent, bool_t local)
{
    uint32 tmp;
    errno_t  ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Make changes */
        tmp = static_ent->u.action_data.item.local_l3;
        static_ent->u.action_data.item.local_l3 = ((FALSE != local) ? 1U : 0U);
        /* Propagate changes to l2br table */
        if (EOK != pfe_l2br_table_entry_set_action_data(&static_ent->entry, static_ent->u.action_data_u64val))
        {
            static_ent->u.action_data.item.local_l3 = tmp;
            NXP_LOG_ERROR("Couldn't set action data\n");
            ret = EINVAL;
        }
        /* Write to the HW */
        else if (EOK != pfe_l2br_table_update_entry(bridge->mac_table, &static_ent->entry))
        {
            static_ent->u.action_data.item.local_l3 = tmp;
            NXP_LOG_ERROR("Couldn't update entry\n");
            ret = ENOENT;
        }
        else
        {
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief Sets the src_discard flag (enables/disables discard of frames with given SRC MAC address)
 * @param[in]       bridge Bridge instance
 * @param[in]       static_ent Static entry to change
 * @param[in]       src_discard Value to be set
 * @retval EOK      Success
 * @retval EINVAL   Invalid or missing argument
 * @retval          ENOENT Entry couldn't be updated
 */
errno_t pfe_l2br_static_entry_set_src_discard_flag(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent, bool_t src_discard)
{
    uint32 tmp;
    errno_t  ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Make changes */
        tmp = static_ent->u.action_data.item.src_discard;
        static_ent->u.action_data.item.src_discard = ((FALSE != src_discard) ? 1U : 0U);
        /* Propagate changes to l2br table */
        if (EOK != pfe_l2br_table_entry_set_action_data(&static_ent->entry, static_ent->u.action_data_u64val))
        {
            static_ent->u.action_data.item.src_discard = tmp;
            NXP_LOG_ERROR("Couldn't set action data\n");
            ret = EINVAL;
        }
        /* Write to the HW */
        else if (EOK != pfe_l2br_table_update_entry(bridge->mac_table, &static_ent->entry))
        {
            static_ent->u.action_data.item.src_discard = tmp;
            NXP_LOG_ERROR("Couldn't update entry\n");
            ret = ENOENT;
        }
        else
        {
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief Sets the dst_discard flag (enables/disables discard of frames with given SRC MAC address)
 * @param[in]       bridge Bridge instance
 * @param[in]       static_ent Static entry to change
 * @param[in]       dst_discard Value to be set
 * @retval EOK      Success
 * @retval EINVAL   Invalid or missing argument
 * @retval          ENOENT Entry couldn't be updated
 */
errno_t pfe_l2br_static_entry_set_dst_discard_flag(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t* static_ent, bool_t dst_discard)
{
    uint32 tmp;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Make changes */
        tmp = static_ent->u.action_data.item.dst_discard;
        static_ent->u.action_data.item.dst_discard = ((FALSE != dst_discard)? 1U : 0U);
        /* Propagate changes to l2br table */
        ret = pfe_l2br_table_entry_set_action_data(&static_ent->entry, static_ent->u.action_data_u64val);
        if (EOK != ret)
        {
            static_ent->u.action_data.item.dst_discard = tmp;
            NXP_LOG_ERROR("Couldn't set action data\n");
            ret = EINVAL;
        }
        else
        {
            /* Write to the HW */
            if (EOK != pfe_l2br_table_update_entry(bridge->mac_table, &static_ent->entry))
            {
                static_ent->u.action_data.item.dst_discard = tmp;
                NXP_LOG_ERROR("Couldn't update entry\n");
                ret = ENOENT;
            }
        }
    }

    return ret;
}

/**
 * @brief Reads the state of local L3 flag
 * @param[in]   bridge Bridge instance
 * @param[in]   static_ent Static entry to read from
 * @param[out]  local State of the local L3 flag
 * @retval EOK      Success
 * @retval EINVAL   Invalid or missing argument
 */
errno_t pfe_l2br_static_entry_get_local_flag(const pfe_l2br_t *bridge, const pfe_l2br_static_entry_t* static_ent, bool_t *local)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent) || (NULL == local)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#else
    (void)bridge;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *local = ((0U != static_ent->u.action_data.item.local_l3) ? TRUE : FALSE);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads the state of src_discard flag
 * @param[in]   bridge Bridge instance
 * @param[in]   static_ent Static entry to read from
 * @param[out]  src_discard State of the src_discard flag
 * @retval EOK      Success
 * @retval EINVAL   Invalid or missing argument
 */
errno_t pfe_l2br_static_entry_get_src_discard_flag(pfe_l2br_t *bridge, const pfe_l2br_static_entry_t* static_ent, bool_t *src_discard)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent) || (NULL == src_discard)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#else
    (void)bridge;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *src_discard = ((0U != static_ent->u.action_data.item.src_discard) ? TRUE : FALSE);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads the state of dst_discard flag
 * @param[in]   bridge Bridge instance
 * @param[in]   static_ent Static entry to read from
 * @param[out]  dst_discard State of the dst_discard flag
 * @retval EOK      Success
 * @retval EINVAL   Invalid or missing argument
 */
errno_t pfe_l2br_static_entry_get_dst_discard_flag(const pfe_l2br_t *bridge, const pfe_l2br_static_entry_t* static_ent, bool_t *dst_discard)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent) || (NULL == dst_discard)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#else
    (void)bridge;
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *dst_discard = ((0U != static_ent->u.action_data.item.dst_discard) ? TRUE : FALSE);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief Reads the forward list
 * @param[in]   bridge Bridge instance
 * @param[in]   static_ent Static entry to read from
 * @return      Bitmask representing egress physical interfaces. Every bit represents ID
 *              corresponding to its position. Bit (1 << 3) represents ID=3. The IDs
 *              match the pfe_ct_phy_if_id_t values.
 */
__attribute__((pure)) uint32 pfe_l2br_static_entry_get_fw_list(const pfe_l2br_static_entry_t* static_ent)
{
    uint32 fw_list;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == static_ent)
    {
        NXP_LOG_ERROR("NULL argument received\n");
        fw_list = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fw_list = static_ent->u.action_data.item.forward_list;
    }
    return fw_list;
}

/**
 * @brief       Get vlan from L2 static entry
 * @param[in]   static_ent Static entry
 * @return      Vlan of static entry
 */
__attribute__((pure)) uint16 pfe_l2br_static_entry_get_vlan(const pfe_l2br_static_entry_t *static_ent)
{
    return static_ent->vlan;
}

/**
 * @brief       Get MAC from L2 static entry
 * @param[in]   static_ent Static entry
 * @return      Mac of static entry
 */
void pfe_l2br_static_entry_get_mac(const pfe_l2br_static_entry_t *static_ent, pfe_mac_addr_t mac)
{
    (void)autolibc_memcpy(mac, static_ent->mac, sizeof(pfe_mac_addr_t));
}

/**
 * @brief       Get first L2 static entry based on criterion
 * @param[in]   bridge Bridge instance
 * @param[in]   crit Static entry to change forward list
 * @param[in]   arg1 Argument for criterion
 * @param[in]   arg2 Argument for criterion
 * @return      Static entry on success or NULL on failure
 */
pfe_l2br_static_entry_t *pfe_l2br_static_entry_get_first(pfe_l2br_t *bridge, pfe_l2br_static_ent_get_crit_t crit, void* arg1,const void *arg2)
{
    pfe_l2br_static_entry_t *static_ent;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        static_ent = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
        bridge->cur_crit_ent = crit;

        switch (bridge->cur_crit_ent)
        {
            case L2SENT_CRIT_ALL:
                break;

            case L2SENT_CRIT_BY_MAC:
                (void)autolibc_memcpy((void *)bridge->cur_static_ent_crit_arg.mac, arg2, sizeof(pfe_mac_addr_t));
                break;

            case L2SENT_CRIT_BY_VLAN:
                bridge->cur_static_ent_crit_arg.vlan = (uint16)(((addr_t)arg1) & UINT16_MAX);
                break;

            case L2SENT_CRIT_BY_MAC_VLAN:
                bridge->cur_static_ent_crit_arg.vlan = (uint16)(((addr_t)arg1) & UINT16_MAX);
                (void)autolibc_memcpy((void *)bridge->cur_static_ent_crit_arg.mac, arg2, sizeof(pfe_mac_addr_t));
                break;

            default:
                NXP_LOG_DEBUG("Invalid static entry type");
                break;
        }

        /*  Get first matching entry */
        bridge->curr_static_ent = 0U;
        static_ent = pfe_l2br_static_entry_get_next(bridge);
#else
      (void)bridge;
      (void)crit;
      (void)arg1;
      (void)arg2;

      static_ent = NULL_PTR;
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */
    }
    return static_ent;
}
/**
 * @brief       Get next L2 static entry
 * @param[in]   bridge Bridge instance
 * @return      Static entry on success or NULL on failure
 * @warning     Intended to be called after pfe_l2br_static_entry_get_first.
 */
pfe_l2br_static_entry_t *pfe_l2br_static_entry_get_next(pfe_l2br_t *bridge)
{
    pfe_l2br_static_entry_t *static_ent;
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
    bool_t                   match = FALSE;
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        static_ent = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
        while (bridge->curr_static_ent < bridge->static_entries.occupied_items_count)
        {
            /*  Get data */
            static_ent = (pfe_l2br_static_entry_t *)isa_item(&bridge->static_entries, bridge->curr_static_ent);

            /*  Remember current item to know where to start later */
            bridge->curr_static_ent++;

            if (NULL_PTR != static_ent)
            {
                if (TRUE == pfe_l2br_static_entry_match_criterion(bridge, static_ent))
                {
                    match = TRUE;
                    break;
                }
            }
        }

        if (TRUE != match)
        {
            static_ent = NULL_PTR;
        }
#else
      (void)bridge;

      static_ent = NULL_PTR;
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */
    }
    return static_ent;
}

#ifdef PFE_CFG_L2BR_STATICS_ENABLE
/**
 * @brief       Match static entry
 * @param[in]   bridge The bridge instance
 * @param[in]   static_ent Static entry to be matched to criterion parameters
 */
static bool_t pfe_l2br_static_entry_match_criterion(const pfe_l2br_t *bridge, pfe_l2br_static_entry_t *static_ent)
{
    bool_t match = FALSE;;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == static_ent)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (bridge->cur_crit_ent)
        {
            case L2SENT_CRIT_ALL:
                match = TRUE;
                break;

            case L2SENT_CRIT_BY_MAC:
                if (0 == autolibc_memcmp(static_ent->mac, bridge->cur_static_ent_crit_arg.mac, sizeof(pfe_mac_addr_t)))
                {
                    match = TRUE;
                }
                break;

            case L2SENT_CRIT_BY_VLAN:
                match = (static_ent->vlan == bridge->cur_static_ent_crit_arg.vlan);
                break;

            case L2SENT_CRIT_BY_MAC_VLAN:
                match = (static_ent->vlan == bridge->cur_static_ent_crit_arg.vlan);
                if (TRUE == match)
                {
                    if (0 == autolibc_memcmp(static_ent->mac, bridge->cur_static_ent_crit_arg.mac, sizeof(pfe_mac_addr_t)))
                    {
                        match = TRUE;
                    }
                    else
                    {
                        match = FALSE;
                    }
                }
                break;

            default:
                NXP_LOG_ERROR("Unknown criterion\n");
                match = FALSE;
                break;
        }
    }

    return match;
}

/*
 * @brief       Flush static MAC table entries
 * @param[in]   bridge The bridge instance
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_l2br_flush_static_mac_table(pfe_l2br_t *bridge)
{
    uint32 index;
    errno_t ret = EOK;
    pfe_l2br_static_entry_t *sentry;

    /*  Remove all static entries from local DB */
    for(index = bridge->static_entries.occupied_items_count; index > 0U; index--)
    {
        /*  Get data */
        sentry = (pfe_l2br_static_entry_t *)isa_item(&bridge->static_entries, index - 1U);

        /*  Destroy entry. isa_release() is inside... */
        ret = pfe_l2br_static_entry_destroy_nolock(bridge, sentry);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("Unable to remove static entry: %d\n", ret);
        }
    }

    return ret;
}
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

/*
 * @brief       Flush all MAC table entries
 * @param[in]   bridge The bridge instance
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_l2br_flush_all_mac_table(pfe_l2br_t *bridge)
{
    errno_t ret = EOK;
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
    uint32 index;
    pfe_l2br_static_entry_t *sentry;

    /*  Remove all static entries from local DB. This must be done before
    the pfe_l2br_table_flush() because otherwise would report "entry
    not found" messages. */
    for(index = bridge->static_entries.occupied_items_count; index > 0U; index--)
    {
        /*  Get data */
        sentry = (pfe_l2br_static_entry_t *)isa_item(&bridge->static_entries, index - 1U);

        /*  Destroy entry. isa_release() is inside... */
        ret = pfe_l2br_static_entry_destroy_nolock(bridge, sentry);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("Unable to remove static entry: %d\n", ret);
        }
    }
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */

    /*  Flush MAC table */
#if 0 /* AAVB-3136: THIS DOES NOT WORK. PFE GETS STUCK. */
    ret = pfe_l2br_table_flush(bridge->mac_table);
#else
    ret = pfe_l2br_table_init(bridge->mac_table);
#endif /* AAVB-3136 */
    if (EOK != ret)
    {
        NXP_LOG_ERROR("MAC table flush failed: %d\n", ret);
    }
    else
    {
        NXP_LOG_INFO("MAC table flushed\n");
    }
    return ret;
}

/*
 * @brief       Flush learned MAC table entries
 * @param[in]   bridge The bridge instance
 * @param[in]   entry Entry will be written at this location
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_l2br_flush_learned_mac_table(const pfe_l2br_t *bridge, pfe_l2br_table_entry_t *entry, pfe_l2br_table_iterator_t *l2t_iter)
{
    errno_t ret = EOK;
    errno_t query_ret;

    /*  Go through all entries */
    query_ret = pfe_l2br_table_get_first(bridge->mac_table, l2t_iter, L2BR_TABLE_CRIT_VALID, entry);
    while (EOK == query_ret)
    {
        if (FALSE == pfe_l2br_table_entry_is_static(entry))
        {
            /*  Remove non-static entry from table */
            ret = pfe_l2br_table_del_entry(bridge->mac_table, entry);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Could not delete MAC table entry: %d\n", ret);
            }
        }

        query_ret = pfe_l2br_table_get_next(bridge->mac_table, l2t_iter, entry);
    }

    return ret;
}
static void pfe_l2br_table_create_entry_iterator(pfe_l2br_t *bridge, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry)
{
    /*  Create entry storage */
    (void)pfe_l2br_table_entry_create(bridge->mac_table, entry);

    /*   Create iterator */
    (void)pfe_l2br_iterator_create(l2t_iter);
}

static void pfe_l2br_table_destroy_entry_iterator(pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry)
{
    /*  Release entry storage */
    (void)pfe_l2br_table_entry_destroy(entry);

    /*  Release iterator */
    (void)pfe_l2br_iterator_destroy(l2t_iter);
}
/*
 * @brief       Flush MAC table entries
 * @param[in]   bridge The bridge instance
 * @param[in]   type Type of the flush
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_l2br_flush(pfe_l2br_t *bridge, pfe_l2br_flush_types type)
{
    errno_t                    ret = EOK;
    pfe_l2br_table_entry_t     entry;
    pfe_l2br_table_iterator_t  l2t_iter;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_l2br_table_create_entry_iterator(bridge, &l2t_iter, &entry);

        switch (type)
        {
            case PFE_L2BR_FLUSH_STATIC_MAC:
            {
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
                ret = pfe_l2br_flush_static_mac_table(bridge);
#else
                ret = EINVAL;
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */
                break;
            }

            case PFE_L2BR_FLUSH_ALL_MAC:
            {
                /*  Remove all static entries from local DB. This must be done before
                the pfe_l2br_table_flush() because otherwise would report "entry
                not found" messages. */
                ret = pfe_l2br_flush_all_mac_table(bridge);
                break;
            }

            case PFE_L2BR_FLUSH_LEARNED_MAC:
            {
                ret = pfe_l2br_flush_learned_mac_table(bridge, &entry, &l2t_iter);
                break;
            }

            default:
            {
                NXP_LOG_DEBUG("Invalid flush type");
                ret = EINVAL;
                break;
            }
        }

        pfe_l2br_table_destroy_entry_iterator(&l2t_iter, &entry);
    }
    return ret;
}

/**
 * @brief       Flush all learned MAC table entries
 * @param[in]   bridge The bridge instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_l2br_flush_learned(pfe_l2br_t *bridge)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_l2br_flush(bridge, PFE_L2BR_FLUSH_LEARNED_MAC);
    }
    return ret;
}

/**
 * @brief       Flush all static MAC table entries
 * @param[in]   bridge The bridge instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_l2br_flush_static(pfe_l2br_t *bridge)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_l2br_flush(bridge, PFE_L2BR_FLUSH_STATIC_MAC);
    }
    return ret;
}

/**
 * @brief       Flush all MAC table entries
 * @param[in]   bridge The bridge instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_l2br_flush_all(pfe_l2br_t *bridge)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_l2br_flush(bridge, PFE_L2BR_FLUSH_ALL_MAC);
    }
    return ret;
}
/**
 * @brief       Create L2 bridge domain instance
 * @param[in]   class The classifier instance
 * @param[in]   bridge The bridge instance
 * @param[in]   def_vlan Default VLAN
 * @param[in]   def_aging_time Default aging timeout in seconds.
 * @return      The instance or NULL if failed
 */
static void pfe_l2br_create_mandatory_domains(const pfe_class_t *class, pfe_l2br_t **bridge, uint16 def_vlan, uint16 def_aging_time)
{
    /*  Create default domain */
    (*bridge)->default_domain = pfe_l2br_create_default_domain(*bridge, def_vlan);
    if (NULL == (*bridge)->default_domain)
    {
        NXP_LOG_DEBUG("Could not create default domain\n");
        (void)pfe_l2br_destroy(*bridge);
        *bridge = NULL;
    }
    else
    {
        /*  Create fallback domain */
        (*bridge)->fallback_domain = pfe_l2br_create_fallback_domain(*bridge);
        if (NULL == (*bridge)->fallback_domain)
        {
            NXP_LOG_DEBUG("Could not create fallback domain\n");
            (void)pfe_l2br_destroy(*bridge);
            *bridge = NULL;
        }
        else
        {
            /*  Configure classifier */
            (void)pfe_class_set_default_vlan(class, def_vlan);

            if (EOK != pfe_l2br_set_mac_aging_timeout((*bridge)->class, def_aging_time))
            {
                NXP_LOG_DEBUG("Could not set mac aging timeout\n");
                (void)pfe_l2br_destroy(*bridge);
                *bridge = NULL;
            }

            /*  If the FW aging is off, turn it on */
            else if (FALSE == pfe_feature_mgr_is_available("l2_bridge_aging"))
            {
                if (EOK != pfe_feature_mgr_enable("l2_bridge_aging"))
                {
                    NXP_LOG_ERROR("Could not enable L2 bridge aging in FW\n");
                    (void)pfe_l2br_destroy(*bridge);
                    *bridge = NULL;
                }
            }
            else
            {
                /* Required by MISRA */
            }
        }
    }
}

/**
 * @brief       Create L2 bridge instance
 * @param[in]   class The classifier instance
 * @param[in]   def_vlan Default VLAN
 * @param[in]   def_aging_time Default aging timeout in seconds.
 * @param[in]   mac_table The MAC table instance
 * @param[in]   vlan_table The VLAN table instance
 * @return      The instance or NULL if failed
 */
pfe_l2br_t *pfe_l2br_create(pfe_class_t *class, uint16 def_vlan, uint16 def_aging_time, uint16 vlan_stats_size,
                            pfe_l2br_table_t *mac_table, pfe_l2br_table_t *vlan_table)
{
    pfe_l2br_t *bridge;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == class) || (NULL_PTR == mac_table) || (NULL_PTR == vlan_table)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        bridge = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        bridge = &l2_bridge_instance;
        (void)autolibc_memset(bridge, 0, sizeof(pfe_l2br_t));
        bridge->class = class;
        bridge->mac_table = mac_table;
        bridge->vlan_table = vlan_table;
        bridge->def_vlan = def_vlan;
#ifdef PFE_CFG_L2BR_STATICS_ENABLE
        /* create static entries ISA */
        isa_init(&l2_bridge_instance.static_entries, &l2_bridge_instance_statics_isa_def);
#endif /* PFE_CFG_L2BR_STATICS_ENABLE */
        /* create domains ISA */
        isa_init(&l2_bridge_instance.domains, &l2_bridge_instance_domains_isa_def);
        bridge->domain_stats_table_size = vlan_stats_size;
        (void)autolibc_memset(&stats_index, 0, sizeof(stats_index));
        bridge->domain_stats_table_addr = pfe_l2br_create_vlan_stats_table(class, vlan_stats_size);
        pfe_l2br_create_mandatory_domains(class, &bridge, def_vlan, def_aging_time);
    }

    return bridge;
}

/**
 * @brief       Destroy L2 Bridge instance
 * @param[in]   bridge The bridge instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_l2br_destroy(pfe_l2br_t *bridge)
{
    errno_t ret;
    if (NULL != bridge)
    {
        if (NULL != bridge->default_domain)
        {
            if (EOK == pfe_l2br_domain_destroy(bridge->default_domain))
            {
                bridge->default_domain = NULL;
            }
            else
            {
                NXP_LOG_DEBUG("Could not destroy default domain\n");
            }
        }

        if (NULL != bridge->fallback_domain)
        {
            if (EOK == pfe_l2br_domain_destroy(bridge->fallback_domain))
            {
                bridge->fallback_domain = NULL;
            }
            else
            {
                NXP_LOG_DEBUG("Could not destroy fallback domain\n");
            }
        }

        if (FALSE == isa_isempty(&bridge->domains))
        {
            NXP_LOG_WARNING("Bridge is being destroyed but still contains some active domains\n");
        }

        if (EOK != pfe_l2br_destroy_vlan_stats_table(bridge->class, bridge->domain_stats_table_addr))
        {
            NXP_LOG_DEBUG("Could not destroy vlan stats\n");
        }

        ret = EOK;
    }
    else
    {
        NXP_LOG_DEBUG("Argument is NULL\n");
        ret = EINVAL;
    }

    return ret;
}

/**
 * @brief       Get the default bridge domain instance
 * @param[in]   bridge The bridge instance
 * @return      The domain instance or NULL if failed
 */
__attribute__((pure)) pfe_l2br_domain_t *pfe_l2br_get_default_domain(const pfe_l2br_t *bridge)
{
    pfe_l2br_domain_t *default_domain;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        default_domain = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        default_domain = bridge->default_domain;
    }
    return default_domain;
}

/**
 * @brief       Get the fall-back bridge domain instance
 * @param[in]   bridge The bridge instance
 * @return      The domain instance or NULL if failed
 */
__attribute__((pure)) pfe_l2br_domain_t *pfe_l2br_get_fallback_domain(const pfe_l2br_t *bridge)
{
    pfe_l2br_domain_t *fallback_domain;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        fallback_domain = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        fallback_domain = bridge->fallback_domain;
    }
    return fallback_domain;
}

/**
 * @brief       Match entry with latest criterion provided via pfe_l2br_get_first_domain()
 * @param[in]   bridge The L2 bridge instance
 * @param[in]   domain The domain to be matched
 * @retval      TRUE Domain matches the criterion
 * @retval      FALSE Domain does not match the criterion
 */
static bool_t pfe_l2br_domain_match_criterion(const pfe_l2br_t *bridge, pfe_l2br_domain_t *domain)
{
    bool_t          match = FALSE;
    uint64        ifaces;
    uint64        ifc_mask;
    uint32        ifc_idx;
    pfe_phy_if_t    *phy_if;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == domain)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (bridge->cur_crit)
        {
            case L2BD_CRIT_ALL:
                match = TRUE;
                break;

            case L2BD_CRIT_BY_VLAN:
                match = (domain->vlan == bridge->cur_domain_crit_arg.vlan);
                break;

            case L2BD_BY_PHY_IF:
                /*  Find out if domain contains given interface */
                ifc_mask = (uint64)1ULL;
                ifaces = domain->ifaces;
                for (ifc_idx = 0U; (sizeof(pfe_index_to_phy_if_id) / sizeof(pfe_ct_phy_if_id_t)) > ifc_idx; ifc_idx++)
                {
                    if (0U != (ifaces & ifc_mask))
                    {
                        /*  Get interface instance */
                        phy_if = pfe_phy_if_get_phy(pfe_index_to_phy_if_id[ifc_idx]);

                        if (phy_if == bridge->cur_domain_crit_arg.phy_if)
                        {
                            match = TRUE;
                            break;
                        }
                    }
                    ifaces &= ~ifc_mask;
                    ifc_mask <<= (uint8)1U;
                }
                break;

            default:
                NXP_LOG_ERROR("Unknown criterion\n");
                match = FALSE;
                break;
        }
    }
    return match;
}

/**
 * @brief       Get first L2 bridge domain instance according to given criterion
 * @param[in]   bridge The L2 bridge instance
 * @param[in]   crit Get criterion
 * @param[in]   arg Pointer to criterion argument
 * @return      The domain instance or NULL if not found
 */
pfe_l2br_domain_t *pfe_l2br_get_first_domain(pfe_l2br_t *bridge, pfe_l2br_domain_get_crit_t crit, void *arg)
{
    pfe_l2br_domain_t *domain = NULL;
    bool_t             known_crit = TRUE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remember criterion and argument for possible subsequent pfe_l2br_get_next_domain() calls */
        bridge->cur_crit = crit;
        switch (bridge->cur_crit)
        {
            case L2BD_CRIT_ALL:
                break;

            case L2BD_CRIT_BY_VLAN:
                bridge->cur_domain_crit_arg.vlan = (uint16)((addr_t)arg & 0xffffU);
                break;

            case L2BD_BY_PHY_IF:
                bridge->cur_domain_crit_arg.phy_if = (pfe_phy_if_t *)arg;
                break;

            default:
                NXP_LOG_ERROR("Unknown criterion\n");
                known_crit = FALSE;
                break;
        }

        if (TRUE == known_crit)
        {
            /*  Get first matching entry */
            bridge->curr_domain = 0U;

            domain = pfe_l2br_get_next_domain(bridge);
        }
    }
    return domain;
}

/**
 * @brief       Get next domain from the bridge
 * @details     Intended to be used with pfe_l2br_get_first_domain().
 * @param[in]   bridge The L2 bridge instance
 * @return      The domain instance or NULL if not found
 * @warning     The returned entry must not be accessed after fci_l2br_domain_destroy(entry) has been called.
 */
pfe_l2br_domain_t *pfe_l2br_get_next_domain(pfe_l2br_t *bridge)
{
    pfe_l2br_domain_t *domain = NULL;
    bool_t             match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        while (bridge->curr_domain < bridge->domains.occupied_items_count)
        {
            /*  Get data */
            domain = (pfe_l2br_domain_t *)isa_item(&bridge->domains, bridge->curr_domain);

            /*  Remember current item to know where to start later */
            bridge->curr_domain++;

            if (NULL != domain)
            {
                if (TRUE == pfe_l2br_domain_match_criterion(bridge, domain))
                {
                    match = TRUE;
                    break;
                }
            }
        }

        if (TRUE != match)
        {
            domain = NULL;
        }
    }
    return domain;
}

/**
 * @brief Configures the l2 bridge mac aging timeout
 * @param[in] class The classifier instance
 * @param[in] timeout Timeout time in seconds.
 * @return Either EOK or error code.
 */
static errno_t pfe_l2br_set_mac_aging_timeout(pfe_class_t *class, const uint16 timeout)
{
    pfe_ct_class_mmap_t  mmap;
    pfe_ct_misc_config_t misc_config;
    errno_t  ret;
    uint32 ff_addr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        misc_config.l2_mac_aging_timeout = oal_htons(timeout);

        /* Get the memory map */
        /* All PEs share the same memory map therefore we can read
        arbitrary one (in this case 0U)
        Also mac aging algorithm will work only on core 0*/
        ret = pfe_class_get_mmap(class, 0, &mmap);
        if (EOK == ret)
        {
            /* Get the misc address */
            ff_addr = oal_ntohl(mmap.common.misc_config);
            /* Write new address of misc config */
            ret = pfe_class_write_dmem(class, 0, (addr_t)ff_addr, (void *)&misc_config, sizeof(pfe_ct_misc_config_t));
        }
    }
    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return L2 Bridge runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   bridge      The L2 Bridge instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_l2br_get_text_statistics(const pfe_l2br_t *bridge, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;
    pfe_l2br_table_entry_t entry;
    pfe_l2br_table_iterator_t l2t_iter;
    errno_t ret;
    uint32 count = 0U;

    /* We keep unused parameter verb_level for consistency with rest of the *_get_text_statistics() functions */
    (void)verb_level;

    /* Get memory */
    (void)pfe_l2br_table_entry_create(bridge->mac_table, &entry);
    /* Get the first entry */
    (void)pfe_l2br_iterator_create(&l2t_iter);

    ret = pfe_l2br_table_get_first(bridge->mac_table, &l2t_iter, L2BR_TABLE_CRIT_VALID, &entry);
    while (EOK == ret)
    {
        /* Print out the entry */
        len += pfe_l2br_table_entry_to_str(&entry, buf + len, buf_len - len);
        count++;
        /* Get the next entry */
        ret = pfe_l2br_table_get_next(bridge->mac_table, &l2t_iter, &entry);
    }
    len += oal_util_snprintf(buf + len, buf_len - len, "\n MAC entries count: %u\n", count);
    /* Free memory */
    (void)pfe_l2br_table_entry_destroy(&entry);
    (void)pfe_l2br_iterator_destroy(&l2t_iter);
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       This function is to get the number of entries
 * @param[in]   bridge   The L2Bridge instance
 * @return      The number of entries
 */
uint32 pfe_l2br_get_number_entries(const pfe_l2br_t *bridge)
{
    pfe_l2br_table_entry_t entry;
    pfe_l2br_table_iterator_t l2t_iter;
    errno_t ret;
    uint32 number_entries = 0;

    #if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
    #endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_l2br_table_entry_create(bridge->mac_table, &entry);
        (void)pfe_l2br_iterator_create(&l2t_iter);

        ret = pfe_l2br_table_get_first(bridge->mac_table, &l2t_iter, L2BR_TABLE_CRIT_VALID, &entry);

        while (EOK == ret)
        {
            number_entries = SUM_WRAP_U32(number_entries, 1U);
            /* Get the next entry */
            ret = pfe_l2br_table_get_next(bridge->mac_table, &l2t_iter, &entry);
        }
    }
    
    return number_entries;
}

/**
 * @brief       This function is to get statistic for a specific entry from table
 * @param[in]   bridge   The L2Bridge instance
 * @param[out]  stat     Structure to get statistic counters
 * @param[in]   index_entry  index of requested entry
 * @return      EOK if possible to get index-based statistic, otherwise EINVAL or EFAULT
 */
errno_t pfe_l2br_get_stats(const pfe_l2br_t *bridge, Eth_43_PFE_L2BridgeStatsType* stat, uint32 index_entry)
{
    pfe_l2br_table_entry_t entry;
    pfe_l2br_table_iterator_t l2t_iter;
    errno_t ret = EOK;
    uint32 count = 0;
    errno_t order_entry;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_l2br_table_entry_create(bridge->mac_table, &entry);
        (void)pfe_l2br_iterator_create(&l2t_iter);

        order_entry = pfe_l2br_table_get_first(bridge->mac_table, &l2t_iter, L2BR_TABLE_CRIT_VALID, &entry);
        
        if(EOK != order_entry)
        {
            ret = EFAULT;
        }
    
        while (EOK == order_entry)
        {   

            if(index_entry == count)
            {
                if (PFE_L2BR_TABLE_MAC2F == entry.type)
                {
                    stat->mac_address[0] = entry.u.mac2f_entry.mac[0];
                    stat->mac_address[1] = entry.u.mac2f_entry.mac[1];
                    stat->mac_address[2] = entry.u.mac2f_entry.mac[2];
                    stat->mac_address[3] = entry.u.mac2f_entry.mac[3];
                    stat->mac_address[4] = entry.u.mac2f_entry.mac[4];
                    stat->mac_address[5] = entry.u.mac2f_entry.mac[5];
                    stat->vlan = entry.u.mac2f_entry.vlan;
                    stat->action_data = entry.u.mac2f_entry.action_data;
                    stat->col_ptr =  entry.u.mac2f_entry.col_ptr;
                    stat->flags = entry.u.mac2f_entry.flags;
                }
                if (PFE_L2BR_TABLE_VLAN == entry.type)
                {
                    stat->vlan = entry.u.vlan_entry.vlan;
                    stat->action_data = (uint32)(entry.u.vlan_entry.action_data & UINT32_MAX);
                    stat->col_ptr = entry.u.vlan_entry.col_ptr;
                    stat->flags = entry.u.vlan_entry.flags;
                }   

                break;
            }
            
            count++;

            /*Get next entry*/
            order_entry = pfe_l2br_table_get_next(bridge->mac_table, &l2t_iter, &entry);  
        }
    }
        
    return ret;
}
/**
 * @brief       Get Entry from L2 static entry
 * @param[in]   static_ent Static entry
 * @return      entry
 */
pfe_l2br_table_entry_t *pfe_l2br_static_entry_get_entry(pfe_l2br_static_entry_t *static_ent)
{
    pfe_l2br_table_entry_t *new_entry;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == static_ent))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        new_entry = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        new_entry = &static_ent->entry;
    }
    return new_entry;
}

/**
 * @brief       Get L2 bridge domain(vlan) statistics
 * @param[in]   class       The classifier instance
 * @param[in]   vlan_index  Index in vlan statistics table
 * @param[out]  stat        Statistic structure
 * @retval      EOK         Success
 * @retval      ENOMEM       Not possible to allocate memory for read
 */
errno_t pfe_l2br_get_domain_stats(const pfe_l2br_t *bridge, pfe_ct_vlan_stats_t *stat, uint8 vlan_index)
{
    uint32             i;
    uint32             num_of_pes;
    errno_t              ret = EOK;
    pfe_ct_vlan_stats_t  stats;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == bridge) || (NULL == stat)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(stat, 0, sizeof(pfe_ct_vlan_stats_t));

        const uint16 offset = (uint16)sizeof(pfe_ct_vlan_stats_t) * (uint16)vlan_index;

        num_of_pes = pfe_class_get_num_of_pes(bridge->class);

        for(i = 0; i < num_of_pes; i++)
        {
            (void)autolibc_memset(&stats, 0, sizeof(stats));

            /* Gather memory from all PEs*/
            ret = pfe_class_read_dmem(  (void *)bridge->class,
                                        (sint32)i,
                                        &stats,
                                        ADDR_BASE_OFFSET(bridge->domain_stats_table_addr, offset),
                                        sizeof(pfe_ct_vlan_stats_t));
            if(ret != EOK)
            {
                break;
            }

            /* Calculate total statistics. Values may wrap. */
            const uint32 ingress_add = oal_ntohl(stats.ingress);
            const uint32 egress_add = oal_ntohl(stats.egress);
            const uint32 ingress_bytes_add = oal_ntohl(stats.ingress_bytes);
            const uint32 egress_bytes_add = oal_ntohl(stats.egress_bytes);
            stat->ingress = SUM_WRAP_U32(stat->ingress, ingress_add);
            stat->egress = SUM_WRAP_U32(stat->egress, egress_add);
            stat->ingress_bytes = SUM_WRAP_U32(stat->ingress_bytes, ingress_bytes_add);
            stat->egress_bytes = SUM_WRAP_U32(stat->egress_bytes,egress_bytes_add);            
        }

        /* Convert statistics back to network endian */
        stat->ingress       = oal_htonl(stat->ingress);
        stat->egress        = oal_htonl(stat->egress);
        stat->ingress_bytes = oal_htonl(stat->ingress_bytes);
        stat->egress_bytes  = oal_htonl(stat->egress_bytes);
    }

    return ret;
}

/**
 * @brief       Clear vlan statistics
 * @param[in]   class       The classifier instance
 * @param[in]   vlan_index  Index in vlan statistics table
 * @retval      EOK Success
 * @retval      NOMEM Not possible to allocate memory for read
 */
errno_t pfe_l2br_clear_domain_stats(const pfe_l2br_t *bridge, uint8 vlan_index)
{
    errno_t             ret;
    pfe_ct_vlan_stats_t stat = { 0 };

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == bridge))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        const uint16 offset = (uint16)sizeof(pfe_ct_vlan_stats_t) * (uint16)vlan_index;
        ret = pfe_class_write_dmem( (void *)bridge->class,
                                    -1,
                                    ADDR_BASE_OFFSET(bridge->domain_stats_table_addr, offset),
                                    &stat,
                                    sizeof(pfe_ct_vlan_stats_t));
    }
    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return L2 Bridge domain(vlan) statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   bridge      The L2 Bridge instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_l2br_domain_get_text_statistics(pfe_l2br_t *bridge, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;
    errno_t ret;
    pfe_ct_vlan_stats_t stats = {0};
    pfe_l2br_domain_t *domain = NULL;

    /* We keep unused parameter verb_level for consistency with rest of the *_get_text_statistics() functions */
    (void)verb_level;

    domain = pfe_l2br_get_first_domain(bridge, L2BD_CRIT_ALL, NULL);

    while (domain != NULL)
    {
        ret = pfe_l2br_get_domain_stats (bridge, &stats, domain->stats_index);
        if(EOK != ret)
        {
            NXP_LOG_ERROR("Get domain statistics failed\n");
            break;
        }
        len += oal_util_snprintf(buf + len, buf_len - len, "Vlan [%4d] ingress: %12d       egress: %12d\n", domain->vlan, oal_ntohl(stats.ingress), oal_ntohl(stats.egress));
        len += oal_util_snprintf(buf + len, buf_len - len, "      ingress_bytes: %12d egress_bytes: %12d\n", oal_ntohl(stats.ingress_bytes), oal_ntohl(stats.egress_bytes));
        domain = pfe_l2br_get_next_domain(bridge);
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get L2 bridge domain(vlan) statistics
 * @param[in]   domain      The classifier instance
 * @return      Index in vlan statistics table
 */

uint8 pfe_l2br_get_vlan_stats_index(const pfe_l2br_domain_t *domain)
{
    uint8 stats_idx;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == domain))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stats_idx = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stats_idx = domain->stats_index;
    }
    return stats_idx;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_L2BRIDGE_ENABLE */


===== 文件 [167/185]: src\pfe_l2br_table.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_l2br_table.h"
#include "pfe_l2br_table_csr.h"

/*  MAC address type must be 48-bits long */
ct_assert((sizeof(pfe_mac_addr_t) * 8) == 48);

/**
 * @brief HASH registers associated with a table
 */
typedef struct
{
    addr_t cmd_reg;             /* REQ1_CMD_REG */
    addr_t mac1_addr_reg;       /* REQ1_MAC1_ADDR_REG */
    addr_t mac2_addr_reg;       /* REQ1_MAC2_ADDR_REG */
    addr_t mac3_addr_reg;       /* REQ1_MAC3_ADDR_REG */
    addr_t mac4_addr_reg;       /* REQ1_MAC4_ADDR_REG */
    addr_t mac5_addr_reg;       /* REQ1_MAC5_ADDR_REG */
    addr_t entry_reg;           /* REQ1_ENTRY_REG */
    addr_t status_reg;          /* REQ1_STATUS_REG */
    addr_t direct_reg;          /* REQ1_DIRECT_REG */
    addr_t free_entries_reg;    /* FREE LIST ENTRIES */
    addr_t free_head_ptr_reg;   /* FREE LIST HEAD PTR */
    addr_t free_tail_ptr_reg;   /* FREE LIST TAIL PTR */
} pfe_mac_table_regs_t;

/**
 * @brief   The L2 Bridge table instance structure
 */
struct pfe_l2br_table_tag
{
    addr_t cbus_base_va;                        /*!< CBUS base virtual address                  */
    pfe_l2br_table_type_t type;                 /*!< Table type                                 */
    pfe_mac_table_regs_t regs;                  /*!< Registers (VA)                             */
    uint16 hash_space_depth;                  /*!< Hash space depth in number of entries      */
    uint16 coll_space_depth;                  /*!< Collision space depth in number of entries */
};

/**
 * @brief   Flags for 2-field MAC table entry (pfe_mac2f_table_entry_t.flags)
 */
typedef enum
{
    MAC2F_ENTRY_VALID_FLAG = (1U << 3),         /*!< MAC2F_ENTRY_VALID_FLAG         */
    MAC2F_ENTRY_COL_PTR_VALID_FLAG = (1U << 2), /*!< MAC2F_ENTRY_COL_PTR_VALID_FLAG */
    MAC2F_ENTRY_RESERVED1_FLAG = (1U << 1),     /*!< MAC2F_ENTRY_RESERVED1_FLAG     */
    MAC2F_ENTRY_RESERVED2_FLAG = (1U << 0)      /*!< MAC2F_ENTRY_RESERVED2_FLAG     */
} pfe_mac2f_table_entry_flags_t;

/**
 * @brief   Valid flags for 2-field MAC table entry (pfe_mac2f_table_entry_t.field_valids)
 */
typedef enum
{
    MAC2F_ENTRY_MAC_VALID = (1U << 0),          /*!< (Field1 = MAC Valid)   */
    MAC2F_ENTRY_VLAN_VALID = (1U << 1),         /*!< (Field2 = VLAN Valid)  */
    MAC2F_ENTRY_RESERVED1_VALID = (1U << 2),    /*!< RESERVED               */
    MAC2F_ENTRY_RESERVED2_VALID = (1U << 3),    /*!< RESERVED               */
    MAC2F_ENTRY_RESERVED3_VALID = (1U << 4),    /*!< RESERVED               */
    MAC2F_ENTRY_RESERVED4_VALID = (1U << 5),    /*!< RESERVED               */
    MAC2F_ENTRY_RESERVED5_VALID = (1U << 6),    /*!< RESERVED               */
    MAC2F_ENTRY_RESERVED6_VALID = (1U << 7),    /*!< RESERVED               */
} pfe_mac2f_table_entry_valid_bits_t;

/**
 * @brief   Flags for VLAN table entry (pfe_vlan_table_entry_t.flags)
 */
typedef enum
{
    VLAN_ENTRY_VALID_FLAG = (1U << 3),          /*!< VLAN_ENTRY_VALID_FLAG          */
    VLAN_ENTRY_COL_PTR_VALID_FLAG = (1U << 2),  /*!< VLAN_ENTRY_COL_PTR_VALID_FLAG  */
    VLAN_ENTRY_RESERVED1_FLAG = (1U << 1),      /*!< VLAN_ENTRY_RESERVED1_FLAG      */
    VLAN_ENTRY_RESERVED2_FLAG = (1U << 0)       /*!< VLAN_ENTRY_RESERVED2_FLAG      */
} pfe_vlan_table_entry_flags_t;

/**
 * @brief   Valid flags for VLAN table entry (pfe_vlan_table_entry_t.field_valids)
 */
typedef enum
{
    VLAN_ENTRY_VLAN_VALID = (1U << 0),      /*!< (Field1 = VLAN Valid)      */
    VLAN_ENTRY_RESERVED1_VALID = (1U << 1), /*!< RESERVED                   */
    VLAN_ENTRY_RESERVED2_VALID = (1U << 2), /*!< RESERVED                   */
    VLAN_ENTRY_RESERVED3_VALID = (1U << 3), /*!< RESERVED                   */
    VLAN_ENTRY_RESERVED4_VALID = (1U << 4), /*!< RESERVED                   */
    VLAN_ENTRY_RESERVED5_VALID = (1U << 5), /*!< RESERVED                   */
    VLAN_ENTRY_RESERVED6_VALID = (1U << 6), /*!< RESERVED                   */
    VLAN_ENTRY_RESERVED7_VALID = (1U << 7), /*!< RESERVED                   */
} pfe_vlan_table_entry_valid_bits_t;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_l2br_table_t mactab_instance;
static pfe_l2br_table_t vlantab_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#if defined(PFE_CFG_NULL_ARG_CHECK)
static errno_t pfe_l2br_check_ptrs_val(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
#endif
static errno_t pfe_l2br_table_init_cmd(pfe_l2br_table_t *l2br);
static errno_t pfe_l2br_table_write_cmd(pfe_l2br_table_t *l2br, uint32 addr, pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_table_read_cmd(pfe_l2br_table_t *l2br, uint32 addr, pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_wait_for_cmd_done(const pfe_l2br_table_t *l2br, uint32 *status_val);
static errno_t pfe_l2br_entry_to_cmd_args(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
static uint32 pfe_l2br_table_get_col_ptr(const pfe_l2br_table_entry_t *entry);
static void pfe_l2br_get_data(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
static bool_t pfe_l2br_table_entry_match_criterion(const pfe_l2br_table_t *l2br, const pfe_l2br_table_iterator_t *l2t_iter, const pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_table_do_update_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_table_do_del_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_table_do_add_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_table_do_search_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_table_flush_cmd(pfe_l2br_table_t *l2br);
static uint8 pfe_l2br_entry_get_hash(const pfe_l2br_table_entry_t *entry);
static void pfe_l2br_iterator_save_macvlan(pfe_l2br_table_iterator_t *l2t_iter, const pfe_l2br_table_entry_t *entry);
static bool_t pfe_l2br_iterator_is_macvlan_match(const pfe_l2br_table_iterator_t *l2t_iter, const pfe_l2br_table_entry_t *entry);
static errno_t pfe_l2br_table_col_entries_init(pfe_l2br_table_t *l2br);
static errno_t pfe_l2br_table_compile_update_cmd(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, uint32 *cmd);
static errno_t pfe_l2br_table_compile_del_cmd(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, uint32 *cmd);
static errno_t pfe_l2br_table_compile_add_cmd(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, uint32 *cmd);
static errno_t pfe_l2br_table_compile_search_cmd(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, uint32 *cmd);
static errno_t pfe_l2br_table_read_collision_space(pfe_l2br_table_t *l2br, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry, bool_t *skip);

#if defined(PFE_CFG_NULL_ARG_CHECK)
/* Check pointers for NULL_PTR */
static errno_t pfe_l2br_check_ptrs_val(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    errno_t ret = EOK;
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        ret = EINVAL;
    }
    return ret;
}
#endif /* PFE_CFG_NULL_ARG_CHECK */

/**
 * @brief       Match entry with latest criterion provided via pfe_l2br_table_get_first()
 * @param[in]   l2br The L2 Bridge Table instance
 * @param[in]   entry The entry to be matched
 * @retval      True Entry matches the criterion
 * @retval      False Entry does not match the criterion
 */
static bool_t pfe_l2br_table_entry_match_criterion(const pfe_l2br_table_t *l2br, const pfe_l2br_table_iterator_t *l2t_iter, const pfe_l2br_table_entry_t *entry)
{
    bool_t match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
    switch (l2t_iter->cur_crit)
    {
        case L2BR_TABLE_CRIT_ALL:
        {
            match = TRUE;
            break;
        }

        case L2BR_TABLE_CRIT_VALID:
        {
            switch (l2br->type)
            {
                case PFE_L2BR_TABLE_MAC2F:
                {
                    match = (0U != (entry->u.mac2f_entry.flags & (uint32)MAC2F_ENTRY_VALID_FLAG));
                    break;
                }

                case PFE_L2BR_TABLE_VLAN:
                {
                    match = (0U != (entry->u.vlan_entry.flags & (uint32)VLAN_ENTRY_VALID_FLAG));
                    break;
                }

                default:
                {
                    NXP_LOG_ERROR("Invalid table type\n");
                    break;
                }
            }

            break;
        }

        default:
        {
            NXP_LOG_ERROR("Unknown criterion\n");
            break;
        }
    }
    }
    return match;
}

/**
 * @brief       Get action data
 */
static void pfe_l2br_get_data(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    uint64 vlan_action_data;
    uint32 mac_action_data;

    /*  Get action data */
    if (PFE_L2BR_TABLE_MAC2F == l2br->type)
    {
        mac_action_data = hal_read32(l2br->regs.entry_reg) & 0x7fffffffU;
        entry->u.mac2f_entry.action_data = mac_action_data;
    }
    else
    {
        vlan_action_data = (uint64)hal_read32(l2br->regs.entry_reg);
        vlan_action_data |= ((uint64)hal_read32(l2br->regs.direct_reg) << 32U);
        entry->u.vlan_entry.action_data = (vlan_action_data & 0x7fffffffffffffULL);
    }
}

/**
 * @brief       Get collision pointer
 * @param[in]   entry The table entry instance
 * @return      Collision pointer or 0 if not found
 */
static uint32 pfe_l2br_table_get_col_ptr(const pfe_l2br_table_entry_t *entry)
{
    uint32 ret = 0U;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (entry->type)
        {
            case PFE_L2BR_TABLE_MAC2F:
            {
                if (0U != (entry->u.mac2f_entry.flags & (uint32)MAC2F_ENTRY_COL_PTR_VALID_FLAG))
                {
                    ret = entry->u.mac2f_entry.col_ptr;
                }

                break;
            }

            case PFE_L2BR_TABLE_VLAN:
            {
                if (0U != (entry->u.vlan_entry.flags & (uint32)VLAN_ENTRY_COL_PTR_VALID_FLAG))
                {
                    ret = entry->u.vlan_entry.col_ptr;
                }

                break;
            }

            default:
            {
                NXP_LOG_ERROR("Invalid table type\n");
                ret = 0U;
                break;
            }
        }
    }

    return ret;
}

/**
 * @brief       Convert entry to command arguments
 * @details     Function will write necessary data to registers as preparation
 *              of subsequent command (ADD/DEL/UPDATE/SEARCH).
 * @param[in]   entry The entry
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 */
static errno_t pfe_l2br_entry_to_cmd_args(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    uint32 *entry32 = (uint32 *)entry;
    uint64 action_data = 0ULL;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Prepare command arguments */
        if (PFE_L2BR_TABLE_MAC2F == l2br->type)
        {
            /*  Write MAC (in network byte order) and VLAN */
            hal_write32(oal_htonl(entry32[0]), l2br->regs.mac1_addr_reg);
            hal_write32((uint32)oal_htons(entry32[1] & 0x0000ffffU) | (entry32[1] & 0xffff0000U), l2br->regs.mac2_addr_reg);

            /*  Write action entry */
            hal_write32(entry->u.mac2f_entry.action_data & 0x7fffffffU, l2br->regs.entry_reg);
            ret = EOK;
        }
        else if (PFE_L2BR_TABLE_VLAN == l2br->type)
        {
            /*  Write VLAN */
            hal_write32(entry->u.vlan_entry.vlan, l2br->regs.mac1_addr_reg);

            /*  Write action entry */
            action_data = entry->u.vlan_entry.action_data & 0xffffffffU;
            hal_write32(action_data, l2br->regs.entry_reg);
            action_data = (entry->u.vlan_entry.action_data >> 32U) & 0x7fffffU;
            hal_write32(action_data, l2br->regs.direct_reg);
            ret = EOK;
        }
        else
        {
            NXP_LOG_ERROR("Invalid table type\n");
            ret = EINVAL;
        }
    }
    return ret;
}

/* Compile update command */
static errno_t pfe_l2br_table_compile_update_cmd(   pfe_l2br_table_t *l2br,
                                                    pfe_l2br_table_entry_t *entry,
                                                    uint32 *cmd)
{
    errno_t ret = EINVAL;

    if (PFE_L2BR_TABLE_MAC2F == l2br->type)
    {
        if ((FALSE == entry->mac_addr_set) && (FALSE == entry->vlan_set))
        {
            NXP_LOG_DEBUG("MAC or VLAN must be set\n");
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_UPDATE | (((uint32)entry->u.mac2f_entry.field_valids & 0x1fU) << 8U);
            ret = EOK;
        }
    }
    else if (PFE_L2BR_TABLE_VLAN == l2br->type)
    {
        if (FALSE == entry->vlan_set)
        {
            NXP_LOG_DEBUG("VLAN must be set\n");
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_UPDATE | (((uint32)entry->u.vlan_entry.field_valids & 0x1fU) << 8U);
            ret = EOK;
        }
    }
    else
    {
        NXP_LOG_ERROR("Invalid table type\n");
    }

    return ret;
}

/**
 * @brief       Update entry in table
 * @warning     This function shouldn't be called directly. Call equivalent function with register lock.
 */
static errno_t pfe_l2br_table_do_update_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    uint32 status, cmd;
    errno_t ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Prepare command arguments */
        ret = pfe_l2br_entry_to_cmd_args(l2br, entry);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Entry-to-args conversion failed: %d\n", ret);
        }
        else
        {
            ret = pfe_l2br_table_compile_update_cmd(l2br, entry, &cmd);
            if (ret == EOK)
            {
                /*  Issue the UPDATE command */
                hal_write32(cmd, l2br->regs.cmd_reg);

                ret = pfe_l2br_wait_for_cmd_done(l2br, &status);
                if ((EOK == ret) && (0U != (status & STATUS_REG_SIG_ENTRY_NOT_FOUND)))
                {
                    NXP_LOG_DEBUG("Attempting to update non-existing entry\n");
                    ret = ENOENT;
                }
                else if ((EOK == ret) && (0U == (status & STATUS_REG_SIG_ENTRY_ADDED)))
                {
                    NXP_LOG_ERROR("Table entry UPDATE CMD failed\n");
                    ret = ENOEXEC;
                }
                else
                {
                    /* No action */
                }
            }
        }
    }
    return ret;
}

/* Compile DEL command */
static errno_t pfe_l2br_table_compile_del_cmd(  pfe_l2br_table_t *l2br,
                                                pfe_l2br_table_entry_t *entry,
                                                uint32 *cmd)
{
    errno_t ret = EINVAL;
    if (PFE_L2BR_TABLE_MAC2F == l2br->type)
    {
        if ((FALSE == entry->mac_addr_set) && (FALSE == entry->vlan_set))
        {
            NXP_LOG_DEBUG("MAC or VLAN must be set\n");
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_DELETE | (((uint32)entry->u.mac2f_entry.field_valids & 0x1fU) << 8U);
            ret = EOK;
        }
    }
    else if (PFE_L2BR_TABLE_VLAN == l2br->type)
    {
        if (FALSE == entry->vlan_set)
        {
            NXP_LOG_DEBUG("VLAN must be set\n");
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_DELETE | (((uint32)entry->u.vlan_entry.field_valids & 0x1fU) << 8U);
            ret = EOK;
        }
    }
    else
    {
        NXP_LOG_ERROR("Invalid table type\n");
    }
    return ret;
}

/**
 * @brief       Delete entry from table
 * @warning     This function shouldn't be called directly. Call equivalent function with register lock.
 */
static errno_t pfe_l2br_table_do_del_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    uint32 status, cmd;
    errno_t ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Prepare command arguments */
        ret = pfe_l2br_entry_to_cmd_args(l2br, entry);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Entry-to-args conversion failed: %d\n", ret);
        }
        else
        {
            /*  Argument registers are prepared. Compile the DEL command. */
            ret = pfe_l2br_table_compile_del_cmd(l2br, entry, &cmd);
            if (ret == EOK)
            {
                /*  Issue the DEL command */
                hal_write32(cmd, l2br->regs.cmd_reg);
                ret = pfe_l2br_wait_for_cmd_done(l2br, &status);
                if (EOK == ret)
                {
                    if (0U != (status & STATUS_REG_SIG_ENTRY_NOT_FOUND))
                    {
                        NXP_LOG_DEBUG("Attempting to delete non-existing entry\n");
                    }
                }
            }
        }
    }
    return ret;
}

/* Compile ADD command */
static errno_t pfe_l2br_table_compile_add_cmd(  pfe_l2br_table_t *l2br,
                                                pfe_l2br_table_entry_t *entry,
                                                uint32 *cmd)
{
    errno_t ret = EINVAL;

    if (PFE_L2BR_TABLE_MAC2F == l2br->type)
    {
        if (((FALSE == entry->mac_addr_set) && (FALSE == entry->vlan_set)) || (FALSE == entry->action_data_set))
        {
            NXP_LOG_DEBUG("MAC/VLAN and action must be set\n");
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_ADD | ((entry->u.mac2f_entry.field_valids & 0x1fU) << 8U) | (entry->u.mac2f_entry.port << 16U);
            ret = EOK;
        }
    }
    else if (PFE_L2BR_TABLE_VLAN == l2br->type)
    {
        if ((FALSE == entry->vlan_set) || (FALSE == entry->action_data_set))
        {
            NXP_LOG_DEBUG("VLAN and action must be set\n");
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_ADD | ((entry->u.vlan_entry.field_valids & 0x1fU) << 8U) | (entry->u.vlan_entry.port << 16U);
            ret = EOK;
        }
    }
    else
    {
        NXP_LOG_ERROR("Invalid table type\n");
    }

    return ret;
}

/**
 * @brief       Add entry to table
 * @warning     This function shouldn't be called directly. Call equivalent function with register lock.
 */
static errno_t pfe_l2br_table_do_add_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    uint32 status, cmd;
    errno_t ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
    {
#endif /* PFE_CFG_NULL_ARG_CHECK */
        /*  Prepare command arguments */
        ret = pfe_l2br_entry_to_cmd_args(l2br, entry);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Entry-to-args conversion failed: %d\n", ret);
        }
        else
        {
            ret = pfe_l2br_table_compile_add_cmd(l2br, entry, &cmd);
            if (ret == EOK)
            {
                /*  Issue the ADD command */
                hal_write32(cmd, l2br->regs.cmd_reg);

                ret = pfe_l2br_wait_for_cmd_done(l2br, &status);
                if (EOK == ret)
                {
                    if (0U == (status & STATUS_REG_SIG_ENTRY_ADDED))
                    {
                        NXP_LOG_ERROR("Table entry ADD CMD failed\n");
                        ret = ENOEXEC;
                    }
                }
            }
        }
#if defined(PFE_CFG_NULL_ARG_CHECK)
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    return ret;
}

/* Compile search command */
static errno_t pfe_l2br_table_compile_search_cmd(   pfe_l2br_table_t *l2br,
                                                    pfe_l2br_table_entry_t *entry,
                                                    uint32 *cmd)
{
    errno_t ret = EOK;

    if (PFE_L2BR_TABLE_MAC2F == l2br->type)
    {
        if ((FALSE == entry->mac_addr_set) && (FALSE == entry->vlan_set))
        {
            NXP_LOG_DEBUG("MAC or VLAN must be set\n");
            ret = EINVAL;
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_SEARCH | ((entry->u.mac2f_entry.field_valids & 0x1fU) << 8U) | (entry->u.mac2f_entry.port << 16U);
        }
    }
    else if (PFE_L2BR_TABLE_VLAN == l2br->type)
    {
        if (FALSE == entry->vlan_set)
        {
            NXP_LOG_DEBUG("VLAN must be set\n");
            ret = EINVAL;
        }
        else
        {
            *cmd = (uint32)L2BR_CMD_SEARCH | ((entry->u.vlan_entry.field_valids & 0x1fU) << 8U) | (entry->u.vlan_entry.port << 16U);
        }
    }
    else
    {
        NXP_LOG_ERROR("Invalid table type\n");
        ret = EINVAL;
    }

    return ret;
}

/**
 * @brief       Search for entry in table
 * @warning     This function shouldn't be called directly. Call equivalent function with register lock.
 */
static errno_t pfe_l2br_table_do_search_entry_nolock(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    uint32 status, cmd;
    errno_t ret = EINVAL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
    {
#endif /* PFE_CFG_NULL_ARG_CHECK */

        /*  Prepare command arguments */
        ret = pfe_l2br_entry_to_cmd_args(l2br, entry);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Entry-to-args conversion failed: %d\n", ret);
        }
        else
        {
            ret = pfe_l2br_table_compile_search_cmd(l2br, entry, &cmd);
            if (ret == EOK)
            {
                /*  Issue the SEARCH command */
                hal_write32(cmd, l2br->regs.cmd_reg);

                ret = pfe_l2br_wait_for_cmd_done(l2br, &status);
                if (EOK == ret)
                {
                    if (0U != (status & STATUS_REG_SIG_ENTRY_NOT_FOUND))
                    {
                        NXP_LOG_DEBUG("L2BR table entry not found\n");
                        ret = ENOENT;
                    }
                    else if (0U == (status & STATUS_REG_MATCH))
                    {
                        NXP_LOG_DEBUG("L2BR table entry mismatch\n");
                        ret = ENOENT;
                    }
                    else
                    {
                        pfe_l2br_get_data(l2br, entry);
                    }
                }
            }
        }
#if defined(PFE_CFG_NULL_ARG_CHECK)
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    return ret;
}


/**
 * @brief       Update table entry
 * @details     Associates new action data with the entry.
 * @param[in]   l2br The L2 Bridge Table instance
 * @param[in]   entry Entry to be updated
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      ENOENT Entry not found
 * @retval      ENOEXEC Command failed
 * @retval      ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_update_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    errno_t ret = EOK;

    ret = pfe_l2br_table_do_update_entry_nolock(l2br, entry);

    return ret;
}

/**
 * @brief       Delete entry from table
 * @details     Entry is removed from table if exists. If does not exist, the call
 *              returns success (EOK).
 * @param[in]   l2br The L2 Bridge Table instance
 * @param[in]   data Entry to be deleted
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_del_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    errno_t ret = EOK;

    ret = pfe_l2br_table_do_del_entry_nolock(l2br, entry);

    return ret;
}

/**
 * @brief       Add entry to table
 * @param[in]   l2br The L2 Bridge Table instance
 * @param[in]   data Entry to be added
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      ENOEXEC Command failed
 * @retval      ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_add_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    errno_t ret = EOK;

    ret = pfe_l2br_table_do_add_entry_nolock(l2br, entry);

    return ret;
}

/**
 * @brief           Search entry in table
 * @param[in]       l2br The L2 Bridge Table instance
 * @param[in,out]   data Reference entry to be used for lookup. This entry will be updated by
 *                       values read from the table.
 * @retval          EOK Success
 * @retval          EINVAL Invalid/missing argument
 * @retval          ENOENT Entry not found
 * @retval          ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_search_entry(pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    errno_t ret = EOK;

    ret = pfe_l2br_table_do_search_entry_nolock(l2br, entry);

    return ret;
}

/**
 * @brief           Create iterator instance to go through the table
 * @param[in]       loop_inst The iterator to be initialized
 * @return          iterator on success, NULL on failure
 */
pfe_l2br_table_iterator_t *pfe_l2br_iterator_create(pfe_l2br_table_iterator_t *loop_inst)
{
    if (NULL != loop_inst)
    {
        loop_inst->cur_hash_addr = 0;
        loop_inst->cur_coll_addr = 0;
        loop_inst->next_coll_addr = 0;
        loop_inst->cur_crit = L2BR_TABLE_CRIT_ALL;

        (void)autolibc_memset(&loop_inst->cur_macvlan, 0, sizeof(loop_inst->cur_macvlan));
    }

    return loop_inst;
}

/**
 * @brief           Destroy table iterator
 * @param[in]       inst Iterator instance to be destroyed
 * @retval          EOK on success
 */
errno_t pfe_l2br_iterator_destroy(const pfe_l2br_table_iterator_t *inst)
{
    (void)inst;
    return EOK;
}

/**
 * @brief           Compute hash of the entry.
 * @details         It is assumed that this function uses same algorithms as PFE HW.
 * @param[in]       entry Entry to be hashed
 * @param[out]      hash [passback] Hash of the entry
 * @retval          hash of the entry
 */
static uint8 pfe_l2br_entry_get_hash(const pfe_l2br_table_entry_t *entry)
{
    uint16 hash = 0U;
    
    #if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        hash = EINVAL;
    }
    else
    #endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            /*  NOTE: It is assumed that MAC entry (as provided by pfe_l2br_table_read_cmd()) has reverse byte order of MAC address bytes */
            const uint16 *p = (uint16*)(entry->u.mac2f_entry.mac);
            hash = oal_htons(p[0]) ^ oal_htons(p[1]) ^ oal_htons(p[2]) ^ (uint16)(entry->u.mac2f_entry.vlan);
            hash &= 0x00FFU;
        }
        else
        {
            hash = (uint16)entry->u.vlan_entry.vlan & 0x003FU; /* max hash value is 63 */
        }
    }
    return (uint8)hash;
}

/**
 * @brief           Save macvlan data to iterator
 * @param[in,out]   l2t_iter Iterator which shall be updated
 * @param[in]       entry Entry to be used as a source of macvlan data
 */
static void pfe_l2br_iterator_save_macvlan(pfe_l2br_table_iterator_t *l2t_iter, const pfe_l2br_table_entry_t *entry)
{
    #if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == l2t_iter) || (NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else 
    #endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            (void)autolibc_memcpy(l2t_iter->cur_macvlan.mac, entry->u.mac2f_entry.mac, sizeof(pfe_mac_addr_t));
            l2t_iter->cur_macvlan.vlan = (uint16)entry->u.mac2f_entry.vlan;
        }
        else
        {
            l2t_iter->cur_macvlan.vlan = (uint16)entry->u.vlan_entry.vlan;
        }
    }
}

/**
 * @brief           Check whether iterator macvlan data matches data of provided entry.
 * @param[in]       l2t_iter Iterator with macvlan data
 * @param[in]       entry Entry to be checked
 * @retval          TRUE Data match
 * @retval          FALSE Data don't match
 */
static bool_t pfe_l2br_iterator_is_macvlan_match(const pfe_l2br_table_iterator_t *l2t_iter, const pfe_l2br_table_entry_t *entry)
{
    bool_t is_match = FALSE;

    #if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == l2t_iter) || (NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        is_match = FALSE;
    }
    else
    #endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            if (0 == autolibc_memcmp(l2t_iter->cur_macvlan.mac, entry->u.mac2f_entry.mac, sizeof(pfe_mac_addr_t)))
            {
                if (l2t_iter->cur_macvlan.vlan == entry->u.mac2f_entry.vlan)
                {
                    is_match = TRUE;
                }
            }
        }
        else
        {
            if (l2t_iter->cur_macvlan.vlan == entry->u.vlan_entry.vlan)
            {
                is_match = TRUE;
            }
        }
    }
    return is_match;
}

/**
 * @brief           Get first entry from table
 * @param[in]       l2br The L2 Bridge Table instance
 * @param[out]      l2_iter Iterator
 * @param[in]       crit Get criterion
 * @param[out]      entry Entry will be written at this location
 * @retval          EOK Success
 * @retval          EINVAL Invalid/missing argument
 * @retval          ENOENT Entry not found
 * @retval          ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_get_first(pfe_l2br_table_t *l2br, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_get_criterion_t crit, pfe_l2br_table_entry_t *entry)
{
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remember criterion and argument for possible subsequent pfe_l2br_table_get_next() calls */
        l2t_iter->cur_crit = crit;

        /*  Get entries from address 0x0 */
        (void)autolibc_memset(&l2t_iter->cur_macvlan, 0, sizeof(l2t_iter->cur_macvlan)); 
        for (l2t_iter->cur_hash_addr=0U, l2t_iter->cur_coll_addr=0U; l2t_iter->cur_hash_addr<l2br->hash_space_depth; l2t_iter->cur_hash_addr++)
        {
            ret = pfe_l2br_table_read_cmd(l2br, l2t_iter->cur_hash_addr, entry);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Can not read table entry from location %d\n", (int_t)l2t_iter->cur_hash_addr);
                ret = ENOENT;
                break;
            }
            else
            {
                l2t_iter->cur_coll_addr = l2t_iter->cur_hash_addr; /* cur_coll_addr is utilized to store address of previous valid MAC entry from HW, regardless of hash/coll space */
                pfe_l2br_iterator_save_macvlan(l2t_iter, entry);
                ret = ENOENT;
                if (TRUE == pfe_l2br_table_entry_match_criterion(l2br, l2t_iter, entry))
                {
                    /*  Remember entry to be processed next */
                    l2t_iter->next_coll_addr = pfe_l2br_table_get_col_ptr(entry);
                    l2t_iter->cur_hash_addr++;
                    ret = EOK;
                    break;
                }
            }
        }
    }

    return ret;
}

/*  Read entry from collision space */
static errno_t pfe_l2br_table_read_collision_space( pfe_l2br_table_t *l2br,
                                                    pfe_l2br_table_iterator_t *l2t_iter,
                                                    pfe_l2br_table_entry_t *entry,
                                                    bool_t *skip)
{
    errno_t ret;

    ret = pfe_l2br_table_read_cmd(l2br, l2t_iter->next_coll_addr, entry);
    if (EOK == ret)
    {
        PfeDevAssert(l2t_iter->cur_hash_addr > 0U);
        /*  check hash ; by design of the lookup routine, iterator's actual cur_hash_addr is already +1 ahead */
        if ((l2t_iter->cur_hash_addr - 1U) == pfe_l2br_entry_get_hash(entry))
        {
            /*  === hash OK === ; candidate MAC entry found */
            l2t_iter->cur_coll_addr = l2t_iter->next_coll_addr; /* cur_coll_addr is utilized to store address of previous valid MAC entry from HW, regardless of hash/coll space */
            pfe_l2br_iterator_save_macvlan(l2t_iter, entry);
        }
        else
        {
            /*  === hash NOT OK === ; try to re-read previous valid MAC entry */
            ret = pfe_l2br_table_read_cmd(l2br, l2t_iter->cur_coll_addr, entry);
            if (EOK == ret)
            {
                /*  check hash ; by design of the lookup routine, iterator's actual cur_hash_addr is already +1 ahead */
                if ((l2t_iter->cur_hash_addr - 1U) == pfe_l2br_entry_get_hash(entry))
                {
                    /* --- hash OK --- */
                    if (pfe_l2br_iterator_is_macvlan_match(l2t_iter, entry))
                    {
                        /*  acquire new (hopefully valid) collision pointer from re-read previous MAC entry and go get data from the new collision pointer */
                        l2t_iter->next_coll_addr = pfe_l2br_table_get_col_ptr(entry);
                        *skip = TRUE;
                    }
                    else
                    {
                        /*  previous MAC entry has different macvlan ; candidate MAC entry found */
                        pfe_l2br_iterator_save_macvlan(l2t_iter, entry);
                    }
                }
                else
                {
                    /* --- hash NOT OK --- ; collision list is compromised. Abandon it and move to the next hash space slot. */
                    l2t_iter->next_coll_addr = 0U;
                    *skip = TRUE;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief           Get next entry from table
 * @param[in]       l2br The L2 Bridge Table instance
 * @param[in,out]   l2t_iter Iterator
 * @param[out]      entry Entry will be written at this location
 * @retval          EOK Success
 * @retval          EINVAL Invalid/missing argument
 * @retval          ENOENT Entry not found
 * @retval          ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_get_next(pfe_l2br_table_t *l2br, pfe_l2br_table_iterator_t *l2t_iter, pfe_l2br_table_entry_t *entry)
{
    errno_t ret;
    errno_t RetVal = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(pfe_l2br_check_ptrs_val(l2br, entry) == EINVAL))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        RetVal = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get entries from last address */
        while ((l2t_iter->cur_hash_addr < l2br->hash_space_depth) || (0U != l2t_iter->next_coll_addr) )
        {
            bool_t skip = FALSE;
            bool_t stop = FALSE;
            if (0U == l2t_iter->next_coll_addr)
            {
                /*  Read from hash space */
                ret = pfe_l2br_table_read_cmd(l2br, l2t_iter->cur_hash_addr, entry);
                if (EOK == ret)
                {
                    /*  candidate MAC entry found */
                    l2t_iter->cur_coll_addr = l2t_iter->cur_hash_addr; /* cur_coll_addr is utilized to store address of previous valid MAC entry from HW, regardless of hash/coll space */
                    l2t_iter->cur_hash_addr++;
                    pfe_l2br_iterator_save_macvlan(l2t_iter, entry);
                }
            }
            else
            {
                /*  Read from collision space */
                ret = pfe_l2br_table_read_collision_space(l2br, l2t_iter, entry, &skip);
            }

            if (skip == FALSE)
            {
                if (EOK != ret)
                {
                    NXP_LOG_DEBUG("Can not read table entry\n");
                    RetVal = EINVAL;
                    stop = TRUE;
                }
                else
                {
                    if (TRUE == pfe_l2br_table_entry_match_criterion(l2br, l2t_iter, entry))
                    {
                        l2t_iter->next_coll_addr = pfe_l2br_table_get_col_ptr(entry);
                        RetVal = EOK;
                        stop = TRUE;
                    }
                    else
                    {
                        RetVal = EINVAL;
                    }
                }
                if (stop == TRUE)
                {
                    break;
                }
            }
        }
    }
    return RetVal;
}

/**
 * @brief       Wait for command completion
 * @details     Function will wait until previously issued command has completed.
 * @param[in]   l2br The L2 Bridge Table instance
 * @param[out]  status_val If not NULL, the function will write content of status register there.
 * @retval      EOK Success
 * @retval      ETIMEDOUT Timed out
 */
static errno_t pfe_l2br_wait_for_cmd_done(const pfe_l2br_table_t *l2br, uint32 *status_val)
{
    uint32 ii = 100U;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == l2br))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Wait for command completion */
        while (0U == (hal_read32(l2br->regs.status_reg) & STATUS_REG_CMD_DONE))
        {
            ii--;
            oal_time_usleep(10);

            if (0U == ii)
            {
                break;
            }
        }

        if (NULL != status_val)
        {
            *status_val = hal_read32(l2br->regs.status_reg);
        }

        /*  Clear the STATUS register */
        hal_write32(0xffffffffU, l2br->regs.status_reg);

        if (0U == ii)
        {
            ret = ETIMEDOUT;
        }
        else
        {
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Direct MEM WRITE command
 * @param[in]   l2br The L2 Bridge table instance
 * @param[in]   addr Address within the table (index of entry to be written)
 * @param[in]   wdata Entry data. Shall match the table type. Shall be pfe_mac2f_table_entry_t
 *                    or pfe_vlan_table_entry_t.
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      ETIMEDOUT Command timed-out
 */
static errno_t pfe_l2br_table_write_cmd(pfe_l2br_table_t *l2br, uint32 addr, pfe_l2br_table_entry_t *entry)
{
    uint32 *wdata = (uint32 *)entry;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (addr >= ((uint32)l2br->hash_space_depth + l2br->coll_space_depth))
        {
            NXP_LOG_ERROR("Hash table address 0x%x is out of range\n",(uint_t)addr);
            ret = EINVAL;
        }
        else
        {
            if (PFE_L2BR_TABLE_MAC2F == l2br->type)
            {
                ct_assert(sizeof(pfe_mac2f_table_entry_t) == 16);
                wdata = (uint32 *)&entry->u.mac2f_entry;
                ret = EOK;
            }
            else if (PFE_L2BR_TABLE_VLAN == l2br->type)
            {
                ct_assert(sizeof(pfe_vlan_table_entry_t) == 16);
                wdata = (uint32 *)&entry->u.vlan_entry;
                ret = EOK;
            }
            else
            {
                NXP_LOG_ERROR("Invalid table type\n");
                ret = EINVAL;
            }

            if (EOK == ret)
            {
                /*  Issue the WRITE command */
                hal_write32(wdata[0], l2br->regs.mac1_addr_reg);    /* wdata[31:0]    */
                hal_write32(wdata[1], l2br->regs.mac2_addr_reg);    /* wdata[63:32]   */
                hal_write32(wdata[2], l2br->regs.mac3_addr_reg);    /* wdata[95:64]   */
                hal_write32(wdata[3], l2br->regs.mac4_addr_reg);    /* wdata[127:96]  */

                hal_write32((uint32)L2BR_CMD_MEM_WRITE | (addr << 16U), l2br->regs.cmd_reg);

                ret = pfe_l2br_wait_for_cmd_done(l2br, NULL);
            }
        }
    }
    return ret;
}

/**
 * @brief       Direct MEM READ command
 * @param[in]   l2br The L2 Bridge table instance
 * @param[in]   addr Address within the table (index of entry to be read)
 * @param[out]  data Pointer to memory where entry will be written. See pfe_mac_2f_table_entry_t
 *                   or pfe_vlan_table_entry_t.
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      ETIMEDOUT Command timed-out
 */
static errno_t pfe_l2br_table_read_cmd(pfe_l2br_table_t *l2br, uint32 addr, pfe_l2br_table_entry_t *entry)
{
    errno_t ret = EOK;
    uint32 *rdata;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (addr >= ((uint32)l2br->hash_space_depth + l2br->coll_space_depth))
        {
            NXP_LOG_ERROR("Hash table address 0x%x is out of range\n", (uint_t)addr);
            ret = EINVAL;
        }
        else
        {
            if (PFE_L2BR_TABLE_MAC2F == l2br->type)
            {
                ct_assert(sizeof(pfe_mac2f_table_entry_t) == 16);
                rdata = (uint32 *)&entry->u.mac2f_entry;
            }
            else if (PFE_L2BR_TABLE_VLAN == l2br->type)
            {
                ct_assert(sizeof(pfe_vlan_table_entry_t) == 16);
                rdata = (uint32 *)&entry->u.vlan_entry;
            }
            else
            {
                NXP_LOG_ERROR("Invalid table type\n");
                ret = EINVAL;
            }

            if (ret == EOK)
            {
                /*  Issue the READ command */
                hal_write32((uint32)L2BR_CMD_MEM_READ | ((uint32)addr << 16), l2br->regs.cmd_reg);

                ret = pfe_l2br_wait_for_cmd_done(l2br, NULL);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Table read failed: %d\n", ret);
                }
                else
                {
                    rdata[0] = hal_read32(l2br->regs.mac1_addr_reg);
                    rdata[1] = hal_read32(l2br->regs.mac2_addr_reg);
                    rdata[2] = hal_read32(l2br->regs.mac3_addr_reg);
                    rdata[3] = hal_read32(l2br->regs.mac4_addr_reg);

                    if (PFE_L2BR_TABLE_MAC2F == l2br->type)
                    {
                        uint32 data32 = oal_htonl(rdata[0]);
                        uint16 data16 = oal_htons(rdata[1] & 0xffffU);

                        (void)autolibc_memcpy(&entry->u.mac2f_entry.mac[0], &data32, sizeof(uint32));
                        (void)autolibc_memcpy(&entry->u.mac2f_entry.mac[4], &data16, sizeof(uint16));

                        entry->mac_addr_set = TRUE;
                    }

                    entry->type = l2br->type;
                    entry->vlan_set = TRUE;
                    entry->action_data_set = TRUE;
                }
            }
        }
    }
    
    return ret;
}

/* Initialize collision entries in hash table */
static errno_t pfe_l2br_table_col_entries_init(pfe_l2br_table_t *l2br)
{
    errno_t ret = EOK;
    pfe_l2br_table_entry_t entry = {0U};

    for (uint32 ii=0U; ii < l2br->coll_space_depth; ii++)
    {
        if (PFE_L2BR_TABLE_MAC2F == l2br->type)
        {
            entry.u.mac2f_entry.col_ptr = l2br->hash_space_depth + ii + 1U;
            entry.u.mac2f_entry.flags = (uint32)MAC2F_ENTRY_COL_PTR_VALID_FLAG;
            ret = pfe_l2br_table_write_cmd(l2br, l2br->hash_space_depth + ii, (void *)&entry);
        }
        else if (PFE_L2BR_TABLE_VLAN == l2br->type)
        {
            entry.u.vlan_entry.col_ptr = l2br->hash_space_depth + ii + 1U;
            entry.u.vlan_entry.flags = (uint32)VLAN_ENTRY_COL_PTR_VALID_FLAG;
            ret = pfe_l2br_table_write_cmd(l2br, l2br->hash_space_depth + ii, (void *)&entry);
        }
        else
        {
            NXP_LOG_ERROR("Invalid table type\n");
            ret = EINVAL;
        }

        if (ret != EOK)
        {
            break;
        }
    }

    return ret;
}

/**
 * @brief       Issue the INIT command
 * @param[in]   l2br The L2 bridge table instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      ENOEXEC Command failed
 * @retval      ETIMEDOUT Command timed-out
 */
static errno_t pfe_l2br_table_init_cmd(pfe_l2br_table_t *l2br)
{
    errno_t ret = EOK;
    uint32 status;


#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == l2br))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Issue the INIT command */
        hal_write32(L2BR_CMD_INIT, l2br->regs.cmd_reg);
        ret = pfe_l2br_wait_for_cmd_done(l2br, &status);
        if (EOK == ret)
        {
            if (0U == (status & STATUS_REG_SIG_INIT_DONE))
            {
                NXP_LOG_ERROR("Table INIT CMD failed\n");
                ret = ENOEXEC;
            }
            else
            {
                hal_write32(0U, l2br->regs.mac1_addr_reg);
                hal_write32(0U, l2br->regs.mac2_addr_reg);
                hal_write32(0U, l2br->regs.mac3_addr_reg);
                hal_write32(0U, l2br->regs.mac4_addr_reg);
                hal_write32(0U, l2br->regs.mac5_addr_reg);

                ret = pfe_l2br_table_col_entries_init(l2br);

                if (ret == EOK)
                {
                    hal_write32(l2br->hash_space_depth, l2br->regs.free_head_ptr_reg);
                    const uint32 space_depth_total = (uint32)l2br->hash_space_depth + l2br->coll_space_depth; 
                    PfeDevAssert(space_depth_total > 0U);
                    hal_write32(space_depth_total - 1U, l2br->regs.free_tail_ptr_reg);
                    hal_write32(l2br->coll_space_depth, l2br->regs.free_entries_reg);
                }
                else
                {
                    NXP_LOG_ERROR("Init failed: %d\n", ret);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Issue the FLUSH command
 * @details     It is possible to exted with option to flush only entries of certain VLAN
 * @param[in]   l2br The L2 bridge table instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      ENOEXEC Command failed
 * @retval      ETIMEDOUT Command timed-out
 */
static errno_t pfe_l2br_table_flush_cmd(pfe_l2br_table_t *l2br)
{
    uint32 cmd;
    errno_t ret;

    /*  Prepare command arguments */
    if ((PFE_L2BR_TABLE_MAC2F == l2br->type) || (PFE_L2BR_TABLE_VLAN == l2br->type))
    {
        cmd = (uint32)L2BR_CMD_FLUSH | ((uint32)1U << 14);

        hal_write32(0U, l2br->regs.mac1_addr_reg);
        hal_write32(0U, l2br->regs.mac2_addr_reg);
        hal_write32(0U, l2br->regs.mac3_addr_reg);
        hal_write32(0U, l2br->regs.mac4_addr_reg);
        hal_write32(0U, l2br->regs.mac5_addr_reg);

        /*  Issue the FLUSH command */
        hal_write32(cmd, l2br->regs.cmd_reg);

        ret = pfe_l2br_wait_for_cmd_done(l2br, NULL);
    }
    else
    {
        NXP_LOG_ERROR("Invalid table type\n");
        ret = EINVAL;
    }

    return ret;
}

/**
 * @brief       Create L2 bridge table instance
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   type Type of the table. See pfe_l2br_table_type_t.
 * @return      The L2 Bridge table instance or NULL if failed
 */
pfe_l2br_table_t *pfe_l2br_table_create(addr_t cbus_base_va, pfe_l2br_table_type_t type)
{
    errno_t ret;
    pfe_l2br_table_t *l2br = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (type)
        {
            case PFE_L2BR_TABLE_MAC2F:
            {
                l2br = &mactab_instance;
                (void)autolibc_memset(l2br, 0, sizeof(pfe_l2br_table_t));
                PfeDevAssert(cbus_base_va < (PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + PFE_CFG_CBUS_LENGTH));
                l2br->regs.cmd_reg = cbus_base_va + HOST_MAC2F_CMD_REG;
                l2br->regs.mac1_addr_reg = cbus_base_va + HOST_MAC2F_MAC1_ADDR_REG;
                l2br->regs.mac2_addr_reg = cbus_base_va + HOST_MAC2F_MAC2_ADDR_REG;
                l2br->regs.mac3_addr_reg = cbus_base_va + HOST_MAC2F_MAC3_ADDR_REG;
                l2br->regs.mac4_addr_reg = cbus_base_va + HOST_MAC2F_MAC4_ADDR_REG;
                l2br->regs.mac5_addr_reg = cbus_base_va + HOST_MAC2F_MAC5_ADDR_REG;
                l2br->regs.entry_reg = cbus_base_va + HOST_MAC2F_ENTRY_REG;
                l2br->regs.status_reg = cbus_base_va + HOST_MAC2F_STATUS_REG;
                l2br->regs.direct_reg = cbus_base_va + HOST_MAC2F_DIRECT_REG;
                l2br->regs.free_entries_reg = cbus_base_va + HOST_MAC2F_FREE_LIST_ENTRIES;
                l2br->regs.free_head_ptr_reg = cbus_base_va + HOST_MAC2F_FREE_LIST_HEAD_PTR;
                l2br->regs.free_tail_ptr_reg = cbus_base_va + HOST_MAC2F_FREE_LIST_TAIL_PTR;
                l2br->hash_space_depth = MAC2F_TABLE_HASH_ENTRIES;
                l2br->coll_space_depth = MAC2F_TABLE_COLL_ENTRIES;
                break;
            }

            case PFE_L2BR_TABLE_VLAN:
            {
                l2br = &vlantab_instance;
                (void)autolibc_memset(l2br, 0, sizeof(pfe_l2br_table_t));
                l2br->regs.cmd_reg = cbus_base_va + HOST_VLAN_CMD_REG;
                l2br->regs.mac1_addr_reg = cbus_base_va + HOST_VLAN_MAC1_ADDR_REG;
                l2br->regs.mac2_addr_reg = cbus_base_va + HOST_VLAN_MAC2_ADDR_REG;
                l2br->regs.mac3_addr_reg = cbus_base_va + HOST_VLAN_MAC3_ADDR_REG;
                l2br->regs.mac4_addr_reg = cbus_base_va + HOST_VLAN_MAC4_ADDR_REG;
                l2br->regs.mac5_addr_reg = cbus_base_va + HOST_VLAN_MAC5_ADDR_REG;
                l2br->regs.entry_reg = cbus_base_va + HOST_VLAN_ENTRY_REG;
                l2br->regs.status_reg = cbus_base_va + HOST_VLAN_STATUS_REG;
                l2br->regs.direct_reg = cbus_base_va + HOST_VLAN_DIRECT_REG;
                l2br->regs.free_entries_reg = cbus_base_va + HOST_VLAN_FREE_LIST_ENTRIES;
                l2br->regs.free_head_ptr_reg = cbus_base_va + HOST_VLAN_FREE_LIST_HEAD_PTR;
                l2br->regs.free_tail_ptr_reg = cbus_base_va + HOST_VLAN_FREE_LIST_TAIL_PTR;
                l2br->hash_space_depth = VLAN_TABLE_HASH_ENTRIES;
                l2br->coll_space_depth = VLAN_TABLE_COLL_ENTRIES;
                break;
            }

            default:
            {
                NXP_LOG_ERROR("Invalid table type\n");
                break;
            }
        }

        if (NULL != l2br)
        {
            l2br->type = type;
            l2br->cbus_base_va = cbus_base_va;

            /*  Initialize the table */
            ret = pfe_l2br_table_init_cmd(l2br);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Table initialization failed: %d\n", ret);
                l2br = NULL;
            }
        }
    }

    return l2br;
}

/**
 * @brief       Initialize table
 * @details     Remove all table entries and prepare the table for usage
 * @param[in]   l2br The L2 bridge table instance
 * @retval      EOK if success, error code otherwise
 */
errno_t pfe_l2br_table_init(pfe_l2br_table_t *l2br)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == l2br))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_l2br_table_init_cmd(l2br);
    }

    return ret;
}

/**
 * @brief       Flush table
 * @details     Remove all table entries
 * @param[in]   l2br The L2 bridge table instance
 * @retval      EOK if success, error code otherwise
 */
errno_t pfe_l2br_table_flush(pfe_l2br_table_t *l2br)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == l2br))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_l2br_table_flush_cmd(l2br);
    }
    return ret;
}

/**
 * @brief       Create and initialize L2 bridge table entry instance
 * @note        When not needed entry shall be released by pfe_l2br_table_entry_destroy()
 * @param[in]   l2br The L2 bridge table instance
 * @param[in]   entry The bridge table entry instance to be initialized
 * @return      Bridge table entry instance or NULL if failed
 */
pfe_l2br_table_entry_t *pfe_l2br_table_entry_create(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry)
{
    pfe_l2br_table_entry_t *ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == l2br) || unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != entry)
        {
            (void)autolibc_memset(entry, 0, sizeof(pfe_l2br_table_entry_t));
            entry->type = l2br->type;
            entry->action_data_set = FALSE;
            entry->mac_addr_set = FALSE;
            entry->vlan_set = FALSE;
        }
        ret = entry;
    }

    return ret;
}

/**
 * @brief       Destroy entry created by pfe_l2br_table_entry_create()
 * @param[in]   entry The entry to be destroyed
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 */
errno_t pfe_l2br_table_entry_destroy(const pfe_l2br_table_entry_t *entry)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
    (void)entry;
    ret = EOK;
    }
    return ret;
}

/**
 * @brief       Set MAC address
 * @param[in]   entry The entry
 * @param[in]   mac_addr MAC address to be associated with the entry
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 * @retval      EPERM Operation not permitted
 */
errno_t pfe_l2br_table_entry_set_mac_addr(pfe_l2br_table_entry_t *entry,const pfe_mac_addr_t mac_addr)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            (void)autolibc_memcpy(entry->u.mac2f_entry.mac, mac_addr, sizeof(pfe_mac_addr_t));
            entry->u.mac2f_entry.field_valids |= (uint32)MAC2F_ENTRY_MAC_VALID;
            ret = EOK;
        }
        else if (PFE_L2BR_TABLE_VLAN == entry->type)
        {
            NXP_LOG_DEBUG("Unsupported entry type\n");
            ret = EPERM;
        }
        else
        {
            NXP_LOG_DEBUG("Invalid entry type\n");
            ret = EINVAL;
        }
        if (EOK == ret)
        {
            entry->mac_addr_set = TRUE;
        }
    }
    return ret;
}

/**
 * @brief       Set VLAN
 * @param[in]   entry The entry
 * @param[in]   mac_addr VLAN tag to be associated with the entry (13-bit)
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 */
errno_t pfe_l2br_table_entry_set_vlan(pfe_l2br_table_entry_t *entry, uint16 vlan)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            entry->u.mac2f_entry.vlan = ((uint32)vlan & (uint32)0x1fffU);
            entry->u.mac2f_entry.field_valids |= (uint32) MAC2F_ENTRY_VLAN_VALID;
            ret = EOK;
        }
        else if (PFE_L2BR_TABLE_VLAN == entry->type)
        {
            entry->u.vlan_entry.vlan = ((uint32)vlan & (uint32)0x1fffU);
            entry->u.vlan_entry.field_valids |= (uint32) VLAN_ENTRY_VLAN_VALID;
            ret = EOK;
        }
        else
        {
            NXP_LOG_DEBUG("Invalid entry type\n");
            ret = EINVAL;
        }

        if (EOK == ret)
        {
            entry->vlan_set = TRUE;
        }
    }
    return ret;
}


/**
 * @brief       Get vlan from L2 table entry
 * @param[in]   pfe_l2br_table_entry_t table entry
 * @return      Vlan of table entry
 */
__attribute__((pure)) uint32 pfe_l2br_table_entry_get_vlan(const pfe_l2br_table_entry_t *entry)
{
    return entry->u.mac2f_entry.vlan;
}

/**
 * @brief       Associate action data with table entry
 * @details     Action data vector is available as output of entry match event.
 * @param[in]   entry The entry
 * @param[in]   action The action data
 * @retval      EOK Success
 * @retval      EINVAL Invalid/missing argument
 */
errno_t pfe_l2br_table_entry_set_action_data(pfe_l2br_table_entry_t *entry, uint64 action_data)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            if (action_data > 0x7fffffffU)
            {
                NXP_LOG_DEBUG("Action data too long. Max 31bits allowed for MAC table.\n");
            }

            entry->u.mac2f_entry.action_data = (uint32)(action_data & 0x7fffffffU);
            ret = EOK;
        }
        else if (PFE_L2BR_TABLE_VLAN == entry->type)
        {
            if (action_data > 0x7fffffffffffffULL)
            {
                NXP_LOG_DEBUG("Action data too long. Max 55bits allowed for VLAN table.\n");
            }

            entry->u.vlan_entry.action_data = (uint64)(action_data & 0x7fffffffffffffULL);
            ret = EOK;
        }
        else
        {
            NXP_LOG_DEBUG("Invalid entry type\n");
            ret = EINVAL;
        }
        if (EOK == ret)
        {
            entry->action_data_set = TRUE;
        }
    }
    return ret;
}

/**
 * @brief       Get action data from table entry
 * @details     Action data vector is available as output of entry match event.
 * @param[in]   entry The entry
 * @return      The action data
 */

__attribute__((pure)) uint64 pfe_l2br_table_entry_get_action_data(const pfe_l2br_table_entry_t *entry)
{
    return entry->u.mac2f_entry.action_data;
}

/**
 * @brief       Set 'fresh' bit value
 * @param[in]   entry The entry
 * @param[in]   is_fresh The 'fresh' bit value to be set
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT Entry not found
 * @retval      ENOEXEC Command failed
 * @retval      ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_entry_set_fresh(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, bool_t is_fresh)
{
    uint32 action_data;
    pfe_ct_mac_table_result_t *mac_entry = (pfe_ct_mac_table_result_t *)&action_data;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((l2br->type != PFE_L2BR_TABLE_MAC2F) || (entry->type != PFE_L2BR_TABLE_MAC2F))
        {
            /*  Only MAC table entries can be currently 'fresh' */
            ret = EINVAL;
        }
        else
        {
            /*  Update the action entry */
            action_data = entry->u.mac2f_entry.action_data;
            mac_entry->item.fresh_flag = (TRUE == is_fresh) ? 1U : 0U;
            entry->u.mac2f_entry.action_data = action_data;

            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Get 'fresh' bit value
 * @details     Fresh bit within an entry indicates that entry is actively being
 *              used by packet classification process within the PFE. Can be used
 *              to measure time since the entry has been used last time.
 * @param[in]   entry The entry
 * @return      TRUE if entry is fresh, FALSE otherwise
 */
__attribute__((pure)) bool_t pfe_l2br_table_entry_is_fresh(const pfe_l2br_table_entry_t *entry)
{
    uint32 action_data;
    pfe_ct_mac_table_result_t *mac_entry;
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        action_data = entry->u.mac2f_entry.action_data;
        mac_entry = (pfe_ct_mac_table_result_t *)&action_data;

        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            ret = (0U != mac_entry->item.fresh_flag);
        }
        else
        {
            NXP_LOG_DEBUG("Invalid entry type\n");
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Set 'static' bit value
 * @details     Setting the static bit makes the entry static meaning that it is not subject
 *              of aging.
 * @param[in]   entry The entry
 * @param[in]   is_static The 'static' bit value to be set
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT Entry not found
 * @retval      ENOEXEC Command failed
 * @retval      ETIMEDOUT Command timed-out
 */
errno_t pfe_l2br_table_entry_set_static(const pfe_l2br_table_t *l2br, pfe_l2br_table_entry_t *entry, bool_t is_static)
{
    uint32 action_data;
    pfe_ct_mac_table_result_t *mac_entry = (pfe_ct_mac_table_result_t *)&action_data;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == l2br) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((l2br->type != PFE_L2BR_TABLE_MAC2F) || (entry->type != PFE_L2BR_TABLE_MAC2F))
        {
            /*  Only MAC table entries can be currently 'static' */
            ret = EINVAL;
        }
        else 
        {
            /*  Update the action entry */
            action_data = entry->u.mac2f_entry.action_data;
            mac_entry->item.static_flag = (TRUE == is_static) ? 1U : 0U;
            entry->u.mac2f_entry.action_data = action_data;

            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Get 'static' bit value
 * @details     Static bit indicates that entry is static and is not subject of aging.
 * @param[in]   entry The entry
 * @return      TRUE if entry is fresh, FALSE otherwise
 */
__attribute__((pure)) bool_t pfe_l2br_table_entry_is_static(const pfe_l2br_table_entry_t *entry)
{
    uint32 action_data = entry->u.mac2f_entry.action_data;
    const pfe_ct_mac_table_result_t *mac_entry = (pfe_ct_mac_table_result_t *)&action_data;
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_L2BR_TABLE_MAC2F == entry->type)
        {
            ret = (0U != mac_entry->item.static_flag);
        }
        else
        {
            NXP_LOG_DEBUG("Invalid entry type\n");
            ret = FALSE;
        }
    }
    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Convert entry to string representation
 * @param[in]   entry The entry
 * @param[in]   buf Buffer to write the final string to
 * @param[in]   buf_len Buffer length
 */
uint32 pfe_l2br_table_entry_to_str(const pfe_l2br_table_entry_t *entry, char_t *buf, uint32 buf_len)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == buf)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        return 0U;
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    if (PFE_L2BR_TABLE_MAC2F == entry->type)
    {
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "[MAC+VLAN Table Entry]\n");
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "MAC Address: %02x:%02x:%02x:%02x:%02x:%02x\n",
                entry->u.mac2f_entry.mac[0],
                entry->u.mac2f_entry.mac[1],
                entry->u.mac2f_entry.mac[2],
                entry->u.mac2f_entry.mac[3],
                entry->u.mac2f_entry.mac[4],
                entry->u.mac2f_entry.mac[5]);
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "VLAN       : 0x%x\n", entry->u.mac2f_entry.vlan);
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Action Data: 0x%x\n", entry->u.mac2f_entry.action_data);
#if 0
        /* Currently not used - action data stores the port information, FW does not have access to port field */
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Port       : 0x%x\n", entry->u.mac2f_entry.port);
#endif
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Col Ptr    : 0x%x\n", entry->u.mac2f_entry.col_ptr);
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Flags      : 0x%x\n", entry->u.mac2f_entry.flags);
    }
    else if (PFE_L2BR_TABLE_VLAN == entry->type)
    {
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "[VLAN Table Entry]\n");
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "VLAN       : 0x%x\n", entry->u.vlan_entry.vlan);
        /*  Native type used to fix compiler warning */
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Action Data: 0x%"PRINT64"x\n", (uint64)entry->u.vlan_entry.action_data);
#if 0
        /* Currently not used - action data stores the port information, FW does not have access to port field */
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Port       : 0x%x\n", entry->u.vlan_entry.port);
#endif
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Col Ptr    : 0x%x\n", entry->u.vlan_entry.col_ptr);
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Flags      : 0x%x\n", entry->u.vlan_entry.flags);
    }
    else
    {
        len += (uint32)nxp_snprintf(buf + len, buf_len - len, "Invalid entry type\n");
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [168/185]: src\pfe_log_if.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"

#ifndef PFE_CFG_PFE_SLAVE
#include "hal.h"
#include "pfe_cbus.h"
#include "pfe_ct.h"
#include "pfe_log_if.h"
#include "pfe_class.h"
#include "pfe_platform_cfg.h"
#include "isa.h"

struct pfe_log_if_tag
{
    pfe_phy_if_t *parent;                       /*!< Parent physical interface */
    pfe_class_t *class;                         /*!< Classifier */
    addr_t dmem_base;                           /*!< Place in CLASS/DMEM where HW logical interface structure is stored */
    char_t name[PFE_CFG_LOG_IF_NAME_LENGTH_MAX];/*!< Interface name */
    pfe_ct_log_if_t log_if_class;               /*!< Cached copy of the DMEM structure */
    pfe_ct_phy_if_id_t owner;
    LLIST_t phy_if_binding;                     /*!< binding to physical interface */
};

#define ETH_43_PFE_START_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"

/* logical interfaces pool initialization state */
static bool_t pfe_log_ifs_initialized = FALSE;

#define ETH_43_PFE_STOP_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_ct_class_algo_stats_t pfe_class_algo_stats[PFE_CLASS_PE_COUNT];
static pfe_isa_t pfe_log_ifs;
static pfe_isa_index_t pfe_log_ifs_index[PFE_CFG_MAX_LOG_IFS];
static pfe_log_if_t pfe_log_ifs_pool[PFE_CFG_MAX_LOG_IFS];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static const pfe_isa_definition_t pfe_log_ifs_isa_def =
{
    .item_count = PFE_CFG_MAX_LOG_IFS,
    .item_size = sizeof(pfe_log_if_t),
    .flags = { .ordered = ISA_FLAG_STRICT_ORDER },
    .item_indexes = pfe_log_ifs_index,
    .items = pfe_log_ifs_pool
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_log_if_write_to_class_nostats(const pfe_log_if_t *iface, const pfe_ct_log_if_t *class_if);
static errno_t pfe_log_if_write_to_class(const pfe_log_if_t *iface, const pfe_ct_log_if_t *class_if);
static errno_t pfe_log_if_match_rule1(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len);
static errno_t pfe_log_if_match_rule2(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len);
static errno_t pfe_log_if_match_rule3(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len);
static errno_t pfe_log_if_match_rule4(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len);
static errno_t pfe_log_if_add_match_rule_validate_arg(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len);
static uint32 pfe_log_if_strnlen(const char_t *str, uint32 strsz);
static pfe_log_if_t* pfe_log_ifs_init_db(pfe_phy_if_t *parent, const char_t *name, pfe_log_if_t  *iface);

/**
 * @brief Computes length of the string.
 * @details Function searches for the null character and counts bytes until it
 *          finds it or stops after strsz characters is exhausted
 * @param[in] str String to determine the length for.
 * @param[in] strsz maximum number of characters search through
 * @return String length or strsz when null character not found
 */
static uint32 pfe_log_if_strnlen(const char_t *str, uint32 strsz)
{
    uint32 length = 0U;

    if(NULL_PTR != str)
    {
        while((str[length] != '\0') && (length < strsz))
        {
            length++;
        }
    }

    return length;
}

/**
 * @brief           Add match rule
 * @param[in, out]  iface The interface instance
 * @param[in]       rule Rule to be added. See pfe_ct_if_m_rules_t. Function accepts
 *                       only single rule per call.
 * @param[in]       arg Pointer to buffer containing rule argument data. The argument
 *                      data shall be in network byte order. Type of the argument can
 *                      be retrieved from the pfe_ct_if_m_args_t.
 * @param[in]       arg_len Length of the rule argument. Due to sanity check.
 * @retval          EOK Success
 * @retval          EINVAL Invalid or missing argument
 */
static errno_t pfe_log_if_match_rule1(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len)
{
    errno_t ret = EINVAL;
    pfe_ct_if_m_args_t m_args;

    switch (rule)
    {
        case IF_MATCH_VLAN:
        {
            if (arg_len == sizeof(m_args.vlan))
            {
                iface->log_if_class.m_args.vlan = *((const uint16 *)arg);
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_PROTO:
        {
            if (arg_len == sizeof(m_args.proto))
            {
                iface->log_if_class.m_args.proto = *((uint8 *)arg);
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_SPORT:
        {
            if (arg_len == sizeof(m_args.sport))
            {
                iface->log_if_class.m_args.sport = *((uint16 *)arg);
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_DPORT:
        {
            if (arg_len == sizeof(m_args.dport))
            {
                iface->log_if_class.m_args.dport = *((uint16 *)arg);
                ret = EOK;
            }

            break;
        }
        default:
        {
            /* Required by Misra */
            break;
        }
    }

    return ret;
}

/**
 * @brief           Add match rule
 * @param[in, out]  iface The interface instance
 * @param[in]       rule Rule to be added. See pfe_ct_if_m_rules_t. Function accepts
 *                       only single rule per call.
 * @param[in]       arg Pointer to buffer containing rule argument data. The argument
 *                      data shall be in network byte order. Type of the argument can
 *                      be retrieved from the pfe_ct_if_m_args_t.
 * @param[in]       arg_len Length of the rule argument. Due to sanity check.
 * @retval          EOK Success
 * @retval          EINVAL Invalid or missing argument
 */
static errno_t pfe_log_if_match_rule3(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len)
{
    errno_t ret = EINVAL;
    pfe_ct_if_m_args_t m_args;

    switch (rule)
    {
        case IF_MATCH_ETHTYPE:
        {
            if (arg_len == sizeof(m_args.ethtype))
            {
                iface->log_if_class.m_args.ethtype = *((const uint16 *)arg);
                ret = EOK;
            }

            break;
        }
        case IF_MATCH_FP0:
        {
            if (arg_len == sizeof(m_args.fp0_table))
            {
                iface->log_if_class.m_args.fp0_table = *((PFE_PTR(pfe_ct_fp_table_t) *)arg);
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_FP1:
        {
            if (arg_len == sizeof(m_args.fp1_table))
            {
                iface->log_if_class.m_args.fp1_table = *((PFE_PTR(pfe_ct_fp_table_t) *)arg);
                ret = EOK;
            }

            break;
        }
        default:
        {
            /* Required by Misra */
            break;
        }
    }

    return ret;
}

/**
 * @brief           Add match rule
 * @param[in, out]  iface The interface instance
 * @param[in]       rule Rule to be added. See pfe_ct_if_m_rules_t. Function accepts
 *                       only single rule per call.
 * @param[in]       arg Pointer to buffer containing rule argument data. The argument
 *                      data shall be in network byte order. Type of the argument can
 *                      be retrieved from the pfe_ct_if_m_args_t.
 * @param[in]       arg_len Length of the rule argument. Due to sanity check.
 * @retval          EOK Success
 * @retval          EINVAL Invalid or missing argument
 */
static errno_t pfe_log_if_match_rule4(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len)
{
    errno_t ret = EINVAL;
    pfe_ct_if_m_args_t m_args;

    switch (rule)
    {
        case IF_MATCH_SMAC:
        {
            if (arg_len == sizeof(m_args.smac))
            {
                (void)autolibc_memcpy((void*)(iface->log_if_class.m_args.smac), (const void*)arg, sizeof(m_args.smac));
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_DMAC:
        {
            if (arg_len == sizeof(m_args.dmac))
            {
                (void)autolibc_memcpy((void*)(iface->log_if_class.m_args.dmac), (const void*)arg, sizeof(m_args.dmac));
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_HIF_COOKIE:
        {
            if (arg_len == sizeof(m_args.hif_cookie))
            {
                iface->log_if_class.m_args.hif_cookie = *((const uint32*)arg);
                ret = EOK;
            }

            break;
        }

        default:
        {
            /* Required by Misra */
            break;
        }
    }

    return ret;
}

/**
 * @brief       Add match rule
 * @param[in]   iface The interface instance
 * @param[in]   rule Rule to be added. See pfe_ct_if_m_rules_t. Function accepts
 *                   only single rule per call.
 * @param[in]   arg Pointer to buffer containing rule argument data. The argument
 *                  data shall be in network byte order. Type of the argument can
 *                  be retrieved from the pfe_ct_if_m_args_t.
 * @param[in]   arg_len Length of the rule argument. Due to sanity check.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
static errno_t pfe_log_if_match_rule2(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len)
{
    errno_t ret = EINVAL;
    pfe_ct_if_m_args_t m_args;

    switch (rule)
    {
        case IF_MATCH_SIP6:
        {
            if (arg_len == sizeof(m_args.ipv.v6.sip))
            {
                (void)autolibc_memcpy((void*)(iface->log_if_class.m_args.ipv.v6.sip), (const void*)arg, sizeof(m_args.ipv.v6.sip));
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_DIP6:
        {
            if (arg_len == sizeof(m_args.ipv.v6.dip))
            {
                (void)autolibc_memcpy((void*)(iface->log_if_class.m_args.ipv.v6.dip), (const void*)arg, sizeof(m_args.ipv.v6.dip));
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_SIP:
        {
            if (arg_len == sizeof(m_args.ipv.v4.sip))
            {
                (void)autolibc_memcpy((void*)(&iface->log_if_class.m_args.ipv.v4.sip), (const void*)arg, sizeof(m_args.ipv.v4.sip));
                ret = EOK;
            }

            break;
        }

        case IF_MATCH_DIP:
        {
            if (arg_len == sizeof(m_args.ipv.v4.dip))
            {
                (void)autolibc_memcpy((void*)(&iface->log_if_class.m_args.ipv.v4.dip), (const void*)arg, sizeof(m_args.ipv.v4.dip));
                ret = EOK;
            }

            break;
        }

        default:
        {
            /* Required by Misra */
            break;
        }
    }

    return ret;
}

/**
 * @brief       Write interface structure to classifier memory skipping interface statistics
 * @param[in]   iface The interface instance
 * @param[in]   class_if Pointer to the structure to be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
static errno_t pfe_log_if_write_to_class_nostats(const pfe_log_if_t *iface, const pfe_ct_log_if_t *class_if)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class_if) || (NULL == iface) || (0U == iface->dmem_base)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Be sure that class_stats are at correct place */
        ct_assert_offsetof((sizeof(pfe_ct_log_if_t) - sizeof(pfe_ct_class_algo_stats_t)) == offsetof(pfe_ct_log_if_t, class_stats));
        ret = pfe_class_write_dmem(iface->class, -1, iface->dmem_base, (const  void *)class_if,
                                sizeof(pfe_ct_log_if_t) - sizeof(pfe_ct_class_algo_stats_t));
    }

    return ret;
}

/**
 * @brief       Write interface structure to classifier with statistics
 * @param[in]   iface The interface instance
 * @param[in]   class_if Pointer to the structure to be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
static errno_t pfe_log_if_write_to_class(const pfe_log_if_t *iface, const pfe_ct_log_if_t *class_if)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class_if) || (NULL == iface) || (0U == iface->dmem_base)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_class_write_dmem(iface->class, -1, iface->dmem_base, (const  void *)class_if, sizeof(pfe_ct_log_if_t));
    }
    return ret;
}

/**
 * @brief       Get linked list entry used for binding with PHY IF
 * @param[in]   iface The interface instance
 * @retval      NULL for invalid iface
 * @retval      Pointer to linked list entry used for binding with PHY IF
 * @note        For internal use only !
 */
LLIST_t *pfe_log_if_get_phy_if_binding_list_entry(const pfe_log_if_t *iface)
{
    LLIST_t *entry;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        entry = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
      entry = (LLIST_t *)&iface->phy_if_binding;
    }

    return entry;
}

/**
 * @brief     Obtain LOG IF from PHY IF binding linked list entry
 * @param[in] entry PHY IF list linked list entry
 * @retval    NULL for invalid entry
 * @retval    Pointer to LOF IF associated with supplied linked list entry
 */
pfe_log_if_t *pfe_log_if_from_phy_if_binding_list_entry(const LLIST_t *entry)
{
    pfe_log_if_t *log_if;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        log_if = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
      log_if = LLIST_Data(entry, pfe_log_if_t, phy_if_binding);
    }

    return log_if;
}

/**
 * @brief Initialise necessary storages and variables for all logical interfaces
 */
errno_t pfe_log_ifs_init(void)
{
  errno_t ret = EOK;

  if (FALSE == pfe_log_ifs_initialized)
  {
      /* Initialise LOG IFs ISA storage */
      isa_init(&pfe_log_ifs, &pfe_log_ifs_isa_def);
      pfe_log_ifs_initialized = TRUE;

      NXP_LOG_DEBUG("Pool configured to support %d logical interfaces\n", PFE_CFG_MAX_LOG_IFS);
  }
  else
  {
      NXP_LOG_WARNING("pfe_log_ifs_init() already called\n");
  }

  return ret;
}

/**
 * @brief Uninitialise necessary storages and variables for all logical interfaces
 */
void pfe_log_ifs_deinit(void)
{
    if (TRUE == pfe_log_ifs_initialized)
    {
        /* Invalidate LOG IFs ISA storage */
        (void)autolibc_memset(&pfe_log_ifs, 0, sizeof(pfe_log_ifs));
        pfe_log_ifs_initialized = FALSE;
    }
}

/**
 * @brief       Initialize new logical interface instance
 * @param[in]   parent The parent physical interface
 * @param[in]   name Name of the interface
 * @param[in]   iface instance of the log_if interface
 * @return      iface instance or NULL_PTR in case of failure
 */
static pfe_log_if_t* pfe_log_ifs_init_db(pfe_phy_if_t *parent, const char_t *name, pfe_log_if_t  *iface)
{
    (void)autolibc_strncpy(iface->name, name, sizeof(iface->name));

    /* Get the DMEM for logical interface */
    iface->dmem_base = pfe_class_dmem_heap_alloc(iface->class, sizeof(pfe_ct_log_if_t));
    if(0U == iface->dmem_base)
    {
        NXP_LOG_ERROR("No DMEM\n");
        (void)isa_release(&pfe_log_ifs, iface);
        iface = NULL_PTR;
    }
    else
    {
        /*  Initialize the local and CLASS logical interface structure */
        (void)autolibc_memset(&iface->log_if_class, 0, sizeof(pfe_ct_log_if_t));
        iface->log_if_class.next = 0;
        iface->log_if_class.id = (uint8)(iface - pfe_log_ifs_pool);
        iface->log_if_class.m_rules = (pfe_ct_if_m_rules_t)IF_MATCH_NONE;

        /* Be sure that statistics are zeroed (endianness doesn't mater for this) */
        iface->log_if_class.class_stats.accepted  = 0;
        iface->log_if_class.class_stats.rejected  = 0;
        iface->log_if_class.class_stats.discarded = 0;
        iface->log_if_class.class_stats.processed = 0;

        /* Write to class with stats (overriding the statistics with 0) */
        if (EOK != pfe_log_if_write_to_class(iface, &iface->log_if_class))
        {
            NXP_LOG_ERROR("Could not update DMEM (%s)\n", iface->name);
            pfe_class_dmem_heap_free(iface->class, iface->dmem_base);
            (void)isa_release(&pfe_log_ifs, iface);
            iface = NULL_PTR;
        }
        else
        {
            /*  Bind logical IF with physical IF */
            if (EOK != pfe_phy_if_add_log_if(parent, iface))
            {
                NXP_LOG_ERROR("Can't bind %s to %s\n", iface->name, pfe_phy_if_get_name(parent));
                pfe_class_dmem_heap_free(iface->class, iface->dmem_base);
                (void)isa_release(&pfe_log_ifs, iface);
                iface = NULL_PTR;
            }
        }
    }

    return iface;
}

/**
 * @brief       Create new logical interface instance
 * @param[in]   parent The parent physical interface
 * @param[in]   name Name of the interface
 * @return      The interface instance or NULL if failed
 */
pfe_log_if_t *pfe_log_if_create(pfe_phy_if_t *parent, const char_t *name)
{
    pfe_log_if_t  *iface;
    uint32      length;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == parent) || (NULL_PTR == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        iface = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* check name for validity */
        length = pfe_log_if_strnlen(name, sizeof(iface->name));
        if((sizeof(iface->name) <= length) || (0U == length))
        {
            NXP_LOG_ERROR("LOG IF name string is invalid\n");
            iface = NULL_PTR;
        }
        /* check if ISA storage is initialized */
        else if (TRUE == pfe_log_ifs_initialized)
        {
            iface = (pfe_log_if_t *)isa_reserve(&pfe_log_ifs);
            if (NULL_PTR == iface)
            {
                NXP_LOG_ERROR("Could not reserve ISA item for LOG IF\n");
            }
            else
            {
                (void)autolibc_memset(iface, 0, sizeof(*iface));
                iface->parent = parent;
                iface->class = pfe_phy_if_get_class(parent);
                iface = pfe_log_ifs_init_db(parent, name, iface);
            }
        }
        else
        {
            NXP_LOG_ERROR("LOG IF ISA pool not initialized\n");
            iface = NULL_PTR;
        }
    }

    return iface;
}

/**
 * @brief       Get interface ID
 * @param[in]   iface The interface instance
 * @return      The interface ID
 */
__attribute__((pure)) uint8 pfe_log_if_get_id(const pfe_log_if_t *iface)
{
    uint8 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0xffU;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = iface->log_if_class.id;
    }

    return ret;
}

/**
 * @brief       Get parent physical interface
 * @param[in]   iface The interface instance
 * @return      Physical interface instance or NULL if failed
 */
__attribute__((pure)) pfe_phy_if_t *pfe_log_if_get_parent(const pfe_log_if_t *iface)
{
    pfe_phy_if_t *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ptr = iface->parent;
    }
    return ptr;
}

/**
 * @brief       Set 'next' pointer of the logical interface
 * @details     The value is used to form a simple linked list of logical interface structures
 *              within the classifier memory. Classifier can then walk through the list with
 *              every packet, try to find a matching logical interface, and perform subsequent
 *              actions (for instance distribute the packet to the right destination given by
 *              the logical interface configuration). Note that last entry in the list shall
 *              have the 'next' value set to zero.
 * @param[in]   iface The interface instance
 * @param[in]   next_dmem_ptr Addr in DMEM where next logical interface is stored (lined list entry)
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_log_if_set_next_dmem_ptr(pfe_log_if_t *iface, addr_t next_dmem_ptr)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = EOK;
        iface->log_if_class.next = oal_htonl((uint32)next_dmem_ptr);
        if (EOK != pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class))
        {
            NXP_LOG_ERROR("Interface update failed\n");
            ret = ENOEXEC;
        }
    }

    return ret;
}

/**
 * @brief       Get 'next' pointer of the logical interface (DMEM)
 * @param[in]   iface The interface instance
 * @param[in]   next_dmem_ptr Pointer where the value shall be stored
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_log_if_get_next_dmem_ptr(pfe_log_if_t *iface, addr_t *next_dmem_ptr)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == next_dmem_ptr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *next_dmem_ptr = oal_ntohl(iface->log_if_class.next);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get pointer to logical interface within DMEM
 * @param[in]   iface The interface instance (HOST)
 * @param[in]   dmem_base Pointer where the interface instance (DMEM) pointer will be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_get_dmem_base(const pfe_log_if_t *iface, addr_t *dmem_base)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == dmem_base)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *dmem_base = iface->dmem_base;
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Destroy interface instance
 * @param[in]   iface The interface instance
 */
void pfe_log_if_destroy(pfe_log_if_t *iface)
{
    errno_t ret;

    if (NULL_PTR != iface)
    {
        ret = pfe_phy_if_del_log_if(iface->parent, iface);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Could not remove %s from parent instance: %d\n", iface->name, ret);
        }

        iface->name[0] = '\0';

        (void)autolibc_memset(&iface->log_if_class, 0, sizeof(pfe_ct_log_if_t));
        if (EOK != pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class))
        {
            NXP_LOG_ERROR("Iface invalidation failed\n");
        }

        if (NULL_ADDR != iface->dmem_base)
        {
            pfe_class_dmem_heap_free(iface->class, iface->dmem_base);
        }

        (void)isa_release(&pfe_log_ifs, iface);
    }
}

/**
 * @brief       Check if match is OR
 * @details     Set new match rules. All previously configured ones will be
 *              overwritten.
 * @param[in]   iface The interface instance
 * @retval      TRUE match is OR type
 * @retval      FALSE match is AND type
 */
bool_t pfe_log_if_is_match_or(pfe_log_if_t *iface)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = ((uint32)IF_FL_MATCH_OR ==
                ((uint32)(oal_ntohl(iface->log_if_class.flags)) & (uint32)IF_FL_MATCH_OR));
    }

    return ret;
}

/**
 * @brief       Set match type to OR match
 * @details     Logical interface rules will be matched with OR logic
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_set_match_or(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_00);
        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags |= oal_htonl(IF_FL_MATCH_OR);

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }
        oal_mutex_unlock(PFE_LOG_IF_MUTEX_00);
    }

    return ret;
}

/**
 * @brief       Set match type to AND match
 * @details     Logical interface rules will be matched with AND logic
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_set_match_and(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_01);

        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags &= oal_htonl(~(uint32)IF_FL_MATCH_OR);

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_01);
    }

    return ret;
}

/**
 * @brief       Set match rules
 * @details     Set new match rules. All previously configured ones will be
 *              overwritten.
 * @param[in]   iface The interface instance
 * @param[in]   rules Rules to be set. See pfe_ct_if_m_rules_t.
 * @param[in]   args Pointer to the structure with arguments.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_set_match_rules(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rules, const pfe_ct_if_m_args_t *args)
{
    errno_t ret;
    pfe_ct_if_m_rules_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL == args)
        {
            /*  Argument is mandatory */
            ret = EINVAL;
        }
        else
        {
            /*  TODO: this function is not needed by any API, remove it or add a mutex here
                if call of this function is added to an API */

            /*  Copy the argument */
            (void)autolibc_memcpy(&iface->log_if_class.m_args, args, sizeof(pfe_ct_if_m_args_t));

            /*  Backup current rules to temporary variable */
            tmp = iface->log_if_class.m_rules;
            iface->log_if_class.m_rules = (pfe_ct_if_m_rules_t)oal_htonl(rules);
            ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
            if (EOK != ret)
            {
                /*  Revert */
                iface->log_if_class.m_rules = tmp;
            }
        }
    }

    return ret;
}

/**
 * @brief       Validate and copy argument
 * @param[in]   iface The interface instance
 * @param[in]   rule Rule to be added. See pfe_ct_if_m_rules_t. Function accepts
 *                   only single rule per call.
 * @param[in]   arg Pointer to buffer containing rule argument data. The argument
 *                  data shall be in network byte order. Type of the argument can
 *                  be retrieved from the pfe_ct_if_m_args_t.
 * @param[in]   arg_len Length of the rule argument. Due to sanity check.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
static errno_t pfe_log_if_add_match_rule_validate_arg(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len)
{
    errno_t ret;

    ret = pfe_log_if_match_rule1(iface, rule, arg, arg_len);
    if (EINVAL == ret)
    {
        ret = pfe_log_if_match_rule2(iface, rule, arg, arg_len);
        if (EINVAL == ret)
        {
            ret = pfe_log_if_match_rule3(iface, rule, arg, arg_len);
            if (EINVAL == ret)
            {
                ret = pfe_log_if_match_rule4(iface, rule, arg, arg_len);
                if (EINVAL == ret)
                {
                    if (arg_len != 0U)
                    {
                        NXP_LOG_DEBUG("Unexpected argument\n");
                    }
                    else
                    {
                        ret = EOK;
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Add match rule
 * @param[in]   iface The interface instance
 * @param[in]   rule Rule to be added. See pfe_ct_if_m_rules_t. Function accepts
 *                   only single rule per call.
 * @param[in]   arg Pointer to buffer containing rule argument data. The argument
 *                  data shall be in network byte order. Type of the argument can
 *                  be retrieved from the pfe_ct_if_m_args_t.
 * @param[in]   arg_len Length of the rule argument. Due to sanity check.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_add_match_rule(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule, const void *arg, uint32 arg_len)
{
    errno_t ret;
    pfe_ct_if_m_rules_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U == (uint32)rule)
        {
            ret = EINVAL;
        }

        /*  Check if only single rule is requested */
        else if (0U != ((uint32)rule & ((uint32)rule-1U)))
        {
            ret = EINVAL;
        }
        else
        {
            oal_mutex_lock(PFE_LOG_IF_MUTEX_03);

            ret = pfe_log_if_add_match_rule_validate_arg(iface, rule, arg, arg_len);

            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Invalid matching rule argument\n");
            }
            else
            {
                tmp = iface->log_if_class.m_rules;
                iface->log_if_class.m_rules |= (pfe_ct_if_m_rules_t)oal_htonl(rule);
                ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
                if (EOK != ret)
                {
                    /*  Revert */
                    iface->log_if_class.m_rules = tmp;
                }
            }

            oal_mutex_unlock(PFE_LOG_IF_MUTEX_03);
        }
    }

    return ret;
}

/**
 * @brief       Delete match rule(s)
 * @param[in]   iface The interface instance
 * @param[in]   rule Rule or multiple rules to be deleted. See pfe_ct_if_m_rules_t.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_del_match_rule(pfe_log_if_t *iface, pfe_ct_if_m_rules_t rule)
{
    errno_t ret;
    pfe_ct_if_m_rules_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_04);

        tmp = iface->log_if_class.m_rules;
        iface->log_if_class.m_rules &= (pfe_ct_if_m_rules_t)oal_htonl(~rule);
        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.m_rules = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_04);
    }

    return ret;
}

/**
 * @brief       Get match rules
 * @param[in]   iface The interface instance
 * @param[in]   rules Pointer to location where rules shall be written
 * @param[in]   args Pointer to location where rules arguments shall be written. Can be NULL.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_get_match_rules(pfe_log_if_t *iface, pfe_ct_if_m_rules_t *rules, pfe_ct_if_m_args_t *args)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == rules)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *rules = (pfe_ct_if_m_rules_t)oal_ntohl(iface->log_if_class.m_rules);

        if (NULL != args)
        {
            (void)autolibc_memcpy(args, &iface->log_if_class.m_args, sizeof(pfe_ct_if_m_args_t));
        }
        ret = EOK;
    }

    return ret;
}

/**
 * @brief           Get mask of egress interfaces
 * @param[in]       iface The interface instance
 * @param[in,out]   egress mask (in host format), constructed like
 *                  egress |= 1 << phy_if_id (for each configured phy_if)
 * @retval          EOK Success
 */
errno_t pfe_log_if_get_egress_ifs(pfe_log_if_t *iface, uint32 *egress)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == egress)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *egress = (uint32)oal_ntohl(iface->log_if_class.e_phy_ifs);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief           Set mask of egress interfaces
 * @param[in]       iface The interface instance
 * @param[in]       egress mask (in host format), constructed like
 *                  egress |= 1 << phy_if_id (for each configured phy_if)
 * @retval          EOK Success
 */
errno_t pfe_log_if_set_egress_ifs(pfe_log_if_t *iface, uint32 egress)
{
    uint32 tmp;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tmp = oal_ntohl(iface->log_if_class.e_phy_ifs);

        iface->log_if_class.e_phy_ifs = oal_htonl(egress);
        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.e_phy_ifs = oal_htonl(tmp);
        }
    }

    return ret;
}

/**
 * @brief       Add egress physical interface
 * @details     Logical interfaces can be used to classify and route
 *              packets. When ingress packet is not classified using any
 *              other classification mechanism (L3 router, L2 bridge, ...)
 *              then matching ingress logical interface is considered
 *              to provide list of physical interfaces the packet shall be
 *              forwarded to. This function provides way to add physical
 *              interface into the list.
 * @param[in]   iface The interface instance
 * @param[in]   phy_if The physical interface to be added to the list of
 *                     egress interfaces.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_log_if_add_egress_if(pfe_log_if_t *iface, const pfe_phy_if_t *phy_if)
{
    errno_t ret;
    uint32 tmp;
    pfe_ct_phy_if_id_t phy_if_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == phy_if)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        phy_if_id = pfe_phy_if_get_id(phy_if);
        if (PFE_PHY_IF_ID_INVALID <= phy_if_id)
        {
            NXP_LOG_ERROR("Invalid PHY IF ID\n");
            ret = EINVAL;
        }
        else
        {
            tmp = oal_ntohl(iface->log_if_class.e_phy_ifs);

            iface->log_if_class.e_phy_ifs = oal_htonl(tmp | (1UL << (uint8)phy_if_id));
            ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
            if (EOK != ret)
            {
                /*  Revert */
                iface->log_if_class.e_phy_ifs = oal_htonl(tmp);
            }
        }
    }

    return ret;
}

/**
 * @brief       Remove egress physical interface
 * @details     See the pfe_log_if_add_egress_if().
 * @param[in]   iface The interface instance
 * @param[in]   phy_if The physical interface to be removed
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_log_if_del_egress_if(pfe_log_if_t *iface, const pfe_phy_if_t *phy_if)
{
    errno_t ret;
    uint32 tmp;
    pfe_ct_phy_if_id_t phy_if_id;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == phy_if)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        phy_if_id = pfe_phy_if_get_id(phy_if);
        if (PFE_PHY_IF_ID_INVALID <= phy_if_id)
        {
            NXP_LOG_ERROR("Invalid PHY IF ID\n");
            ret = EINVAL;
        }
        else
        {
            tmp = oal_ntohl(iface->log_if_class.e_phy_ifs);

            iface->log_if_class.e_phy_ifs = oal_htonl(tmp & (uint32)(~(1UL << (uint8)phy_if_id)));
            ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
            if (EOK != ret)
            {
                /*  Revert */
                iface->log_if_class.e_phy_ifs = oal_htonl(tmp);
            }
        }
    }

    return ret;
}

/**
 * @brief       Enable the interface
 * @details     Only enabled logical interfaces will be used by firmware
 *              to match ingress frames.
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_enable(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_05);

        NXP_LOG_DEBUG("Enabling %s\n", iface->name);

        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp | oal_htonl(IF_FL_ENABLED));

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_05);
    }

    return ret;
}

/**
 * @brief       Disable the interface
 * @details     Only enabled logical interfaces will be used by firmware
 *              to match ingress frames.
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_disable(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_06);

        NXP_LOG_DEBUG("Disabling %s\n", iface->name);

        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp & (oal_htonl(~(uint32)IF_FL_ENABLED)));

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_06);

    }

    return ret;
}

/**
 * @brief       Check if interface is enabled
 * @param[in]   iface The interface instance
 * @return      TRUE if enabled, FALSE otherwise
 */
__attribute__((pure)) bool_t pfe_log_if_is_enabled(const pfe_log_if_t *iface)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = (0U != ((uint32)(oal_ntohl(iface->log_if_class.flags)) & (uint32)IF_FL_ENABLED));
    }

    return ret;
}

/**
 * @brief       Enable promiscuous mode
 * @details     Function sets logical interface to promiscuous mode and
 *              also enables promiscuous mode on underlying physical
 *              interface.
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_promisc_enable(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_09);

        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags |= oal_htonl(IF_FL_PROMISC);

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_09);
    }

    return ret;
}

/**
 * @brief       Disable promiscuous mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_promisc_disable(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_10);

        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp & (oal_htonl(~(uint32)IF_FL_PROMISC)));

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_10);
    }

    return ret;
}

/**
 * @brief       Check if interface is in promiscuous mode
 * @param[in]   iface The interface instance
 * @return      TRUE if promiscuous mode is enabled, FALSE otherwise
 */
__attribute__((pure)) bool_t pfe_log_if_is_promisc(pfe_log_if_t *iface)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = (0U != ((uint32)(oal_ntohl(iface->log_if_class.flags)) & (uint32)IF_FL_PROMISC));
    }

    return ret;
}

/**
 * @brief       Enable discarding frames accepted by logical interface
 * @details     Function configures logical interface to discard all accepted frames instead of
 *              passing them to the configured egress interfaces.
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_discard_enable(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_11);

        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp | oal_htonl(IF_FL_DISCARD));

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_11);
    }

    return ret;
}

/**
 * @brief       Disable discarding frames accepted by logical interface
 * @details     Function configures logical interface to stop to discard all accepted frames
 *              and to pass them to the configured egress interfaces.
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_log_if_discard_disable(pfe_log_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_LOG_IF_MUTEX_12);

        tmp = iface->log_if_class.flags;
        iface->log_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp & oal_htonl(~(uint32)IF_FL_DISCARD));

        ret = pfe_log_if_write_to_class_nostats(iface, &iface->log_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            iface->log_if_class.flags = tmp;
        }

        oal_mutex_unlock(PFE_LOG_IF_MUTEX_12);
    }

    return ret;
}

/**
 * @brief       Check if interface is configured to discard accepted frames
 * @param[in]   iface The interface instance
 * @return      TRUE if discarding is enabled, FALSE otherwise
 */
__attribute__((pure)) bool_t pfe_log_if_is_discard(pfe_log_if_t *iface)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = (0U != ((uint32)(oal_ntohl(iface->log_if_class.flags)) & (uint32)IF_FL_DISCARD));
    }

    return ret;
}

/**
 * @brief       Get interface name
 * @param[in]   iface The interface instance
 * @return      Pointer to name string or "(unknown)" when called with NULL_PTR
 */
__attribute__((pure)) const char_t *pfe_log_if_get_name(const pfe_log_if_t *iface)
{
    const char_t *str;

    if (NULL_PTR != iface)
    {
        str = iface->name;
    }
    else
    {
        NXP_LOG_WARNING("NULL argument received for pfe_log_if_get_name\n");
        str = "(unknown)";
    }

    return str;
}

/**
 * @brief       Get log interface statistics
 * @param[in]   iface The interface instance
 * @param[out]  stat Statistic structure
 * @retval      EOK Success
 * @retval      NOMEM Not possible to allocate memory for read
 */
errno_t pfe_log_if_get_stats(const pfe_log_if_t *iface, pfe_ct_class_algo_stats_t *stat)
{
    uint32 i;
    uint32 u32reVal;
    errno_t ret;
    addr_t offset = 0;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == stat)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(stat, 0, sizeof(pfe_ct_class_algo_stats_t));

        /* Store offset to stats */
        offset = offsetof(pfe_ct_log_if_t, class_stats);

        /* Gather memory from all PEs*/
        ret = pfe_class_gather_read_dmem(iface->class, &pfe_class_algo_stats, ADDR_BASE_OFFSET(iface->dmem_base, offset), sizeof(pfe_class_algo_stats), sizeof(pfe_ct_class_algo_stats_t));

        /* Calculate total statistics */
        u32reVal = pfe_class_get_num_of_pes(iface->class);
        for(i = 0U; i < u32reVal; i++)
        {
            /* Store statistics */
            stat->accepted = stat->accepted + oal_ntohl(pfe_class_algo_stats[i].accepted);
            stat->discarded = stat->discarded + oal_ntohl(pfe_class_algo_stats[i].discarded);
            stat->processed = stat->processed + oal_ntohl(pfe_class_algo_stats[i].processed);
            stat->rejected = stat->rejected + oal_ntohl(pfe_class_algo_stats[i].rejected);
        }

        /* Convert statistics back to network endian */
        stat->accepted  = oal_htonl(stat->accepted);
        stat->discarded = oal_htonl(stat->discarded);
        stat->processed = oal_htonl(stat->processed);
        stat->rejected  = oal_htonl(stat->rejected);
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* ! PFE_CFG_PFE_SLAVE */


===== 文件 [169/185]: src\pfe_mac_db.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_mac_db.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static bool_t pfe_mac_db_criterion_eval(const pfe_mac_db_list_entry_t *entry, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner);
static inline bool_t pfe_mac_db_check_crit_by_type(const pfe_mac_addr_t addr, pfe_mac_type_t type);


/**
 * @brief       Check if entry match with the rule
 * @param[in]   addr The address to check
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @return      TRUE if entry match with the rule, FALSE otherwise
 */
static inline bool_t pfe_mac_db_check_crit_by_type(const pfe_mac_addr_t addr, pfe_mac_type_t type)
{
    bool_t ret = FALSE;
    if ((type == PFE_TYPE_ANY) ||
        ((type == PFE_TYPE_MC) && (TRUE  == pfe_emac_is_multi(addr))) ||
        ((type == PFE_TYPE_BC) && (TRUE  == pfe_emac_is_broad(addr))) ||
        ((type == PFE_TYPE_UC) && (FALSE  == pfe_emac_is_multi(addr)))
       )
    {
        ret = TRUE;
    }
    return ret;
}

/**
 * @brief       Evaluate given DB entry against specified criterion
 * @param[in]   entry DB entry to evaluate
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner Required owner of MAC address
 * @return      TRUE if entry does match with criterion, FALSE otherwise
 */
static bool_t pfe_mac_db_criterion_eval(const pfe_mac_db_list_entry_t *entry, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner)
{
    bool_t ret = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (crit == MAC_DB_CRIT_BY_OWNER)
        {
            /* Return the first address where owner match */
            if (entry->owner == owner)
            {
                /* Break if entry match with the rule */
                ret = TRUE;
            }
        }
        else if (crit == MAC_DB_CRIT_BY_TYPE)
        {
            /* Break if entry match with the rule */
            ret = pfe_mac_db_check_crit_by_type(entry->addr, type);
        }
        else if (crit == MAC_DB_CRIT_BY_OWNER_AND_TYPE)
        {
            if (entry->owner == owner)
            {
                /* Break if entry match with the rule */
                ret = pfe_mac_db_check_crit_by_type(entry->addr, type);
            }
        }
        else if (crit == MAC_DB_CRIT_ALL)
        {
            /* Break if entry match with the rule */
            ret = TRUE;
        }
        else
        {
            NXP_LOG_WARNING("Unknown criterion\n");
        }
    }

    return ret;
}

/**
 * @brief       Create instance of MAC database
 * @param[in]   db Pointer to MAC database instance
 * @return      Execution status, EOK if success, error code otherwise
 */
errno_t pfe_mac_db_create(pfe_mac_db_t *db)
{
    errno_t ret;
    
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {        
        (void)autolibc_memset(db, 0, sizeof(pfe_mac_db_t));
        db->crit.crit = MAC_DB_CRIT_INVALID;
        db->next_item = 0U;

        db->isa_def.item_count = PFE_CFG_MAC_DB_ENTRIES_MAX;
        db->isa_def.item_size = sizeof(pfe_mac_db_list_entry_t);
        db->isa_def.flags.ordered = ISA_FLAG_STRICT_ORDER;
        db->isa_def.item_indexes = db->mac_list_idx;
        db->isa_def.items = db->mac_list_pool;
        
        isa_init(&db->mac_list, &db->isa_def);
        ret = EOK;
    }
    return ret;
}

/**
 * @brief       Search for specific MAC address in the database and return pointer on related entry
 * @param[in]   db Pointer to MAC database instance
 * @param[in]   addr MAC address to search for
 * @param[in]       owner The identification of driver instance
 * @return      Pointer to related entry, NULL if address not found
 */
static pfe_mac_db_list_entry_t *pfe_mac_db_find_by_addr(const pfe_mac_db_t *db, const pfe_mac_addr_t addr,
                            pfe_drv_id_t owner)
{
    pfe_mac_db_list_entry_t *entry;
    const pfe_isa_t *isa = &db->mac_list;
    bool_t found = FALSE;

    for(uint32 mac_idx = 0U; mac_idx < isa->occupied_items_count; mac_idx++)
    {
        entry = (pfe_mac_db_list_entry_t *) isa_item(isa, mac_idx);
        if ((NULL_PTR != entry) && (entry->owner == owner) && (0 == autolibc_memcmp(addr, entry->addr, sizeof(pfe_mac_addr_t))))
        {
            found = TRUE;
            break;
        }
    }
    
    if (FALSE == found)
    {
        entry = NULL_PTR;
    }

    return entry;
}

/**
 * @brief           Add new MAC address into database
 * @param[in]       db Pointer to MAC database instance
 * @param[in]       addr The MAC address to add
 * @param[in]       owner The identification of driver instance
 * @return          Execution status, EOK if success, error code otherwise
 */
errno_t pfe_mac_db_add_addr(pfe_mac_db_t *db, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret;
    pfe_mac_db_list_entry_t *entry;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Add only if the same address does not already exist in DB */
        entry = pfe_mac_db_find_by_addr(db, addr, owner);
        if (NULL_PTR == entry)
        {       
            /* Add address to local list */
            entry = (pfe_mac_db_list_entry_t *) isa_reserve(&db->mac_list);
            if (NULL_PTR == entry)
            {
                NXP_LOG_WARNING("Memory allocation failed\n");
                ret = ENOMEM;
            }
            else
            {
                (void)autolibc_memcpy(entry->addr, addr, sizeof(pfe_mac_addr_t));
                entry->owner = owner;

                ret = EOK;
            }
        }
        else
        {
            ret = EEXIST;
        }
    }

    return ret;
}

/**
 * @brief           Delete new address from database
 * @param[in]       db Pointer to MAC database instance
 * @param[in]       addr The MAC address to delete from database
 * @param[in]       owner Required owner of MAC address
 * @return          Execution status, EOK if success, error code otherwise
 */
errno_t pfe_mac_db_del_addr(pfe_mac_db_t *db, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret = ENOENT;
    pfe_mac_db_list_entry_t *entry;
    pfe_isa_t *isa = &db->mac_list;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry = pfe_mac_db_find_by_addr(db, addr, owner);
        if (NULL_PTR == entry)
        {
            NXP_LOG_DEBUG("MAC address was not found\n");
        }
        else
        {
            const sint32 item_index = isa_release(isa, entry);
            
            if (ISA_ITEM_NOT_FOUND != item_index)
            {
                if ((uint32)item_index < db->next_item)
                {
                    /*  If removed item had lower 'item_index' than 'next_item' then we need to decrease
                        'next_item' value. Adjust next_item value so we can call remove() between
                        get_first() and get_next() calls.
                    */
                    db->next_item--;
                }
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
 * @brief       Flush all addresses matching with input rule
 * @param[in]   db Pointer to MAC database instance
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner Required owner of MAC address
 * @return      EOK success, error code otherwise
 */
errno_t pfe_mac_db_flush(pfe_mac_db_t *db, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner)
{
    errno_t ret = EOK;
    const pfe_mac_db_list_entry_t *entry;
    pfe_isa_t *isa = &db->mac_list;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remove associated MAC addresses due to flush mode */
        uint32 mac_idx = 0U;
        while(mac_idx < isa->occupied_items_count)
        {
            entry = (pfe_mac_db_list_entry_t *) isa_item(isa, mac_idx);
            if (NULL_PTR != entry)
            {
                if (TRUE == pfe_mac_db_criterion_eval(entry, crit, type, owner))
                {
                    (void) isa_release_subscript(isa, mac_idx);
                    if (mac_idx < db->next_item)
                    {
                        /*  If removed item had lower 'item_index' than 'next_item' then we need to decrease
                            'next_item' value. Adjust next_item value so we can call flush() between
                            get_first() and get_next() calls.
                        */
                        db->next_item--;
                    }
                }
                else
                {
                    mac_idx++;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Get first MAC address from database matching by input rule. Function stores database context
 *              for following call of pfe_mac_get_next_addr(). Function should not be called internally
 *              inside this module
 * @param[in]   db Pointer to MAC database instance
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner Required owner of MAC address
 * @param[out]  addr Returned MAC address
 * @return      Execution status, EOK success, error code otherwise
 */
errno_t pfe_mac_db_get_first_addr(pfe_mac_db_t *db, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner, pfe_mac_addr_t addr)
{
    errno_t ret = ENOENT;
    const pfe_mac_db_list_entry_t *entry = NULL_PTR;
    const pfe_isa_t *isa = &db->mac_list;
    bool_t found = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for(db->next_item = 0U; db->next_item < isa->occupied_items_count; db->next_item++)
        {
            entry = (pfe_mac_db_list_entry_t *) isa_item(isa, db->next_item);
            if ((NULL_PTR != entry))
            {
                if (TRUE == pfe_mac_db_criterion_eval(entry, crit, type, owner))
                {
                    found = TRUE;
                    break;
                }
            }            
        }

        if (TRUE == found)
        {
            (void) autolibc_memcpy(addr, entry->addr, sizeof(pfe_mac_addr_t));
            db->next_item++;
            db->crit.crit = crit;
            db->crit.owner = owner;
            db->crit.type = type;
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Get next MAC address from database. Function expect that pfe_mac_get_first_addr() was
 *              executed before and stores database context. Function should not be called internally
 *              inside this module
 * @param[in]   db Pointer to MAC database instance
 * @param[out]  addr Returned MAC address
 * @return      Execution status, EOK success, error code otherwise
 */
errno_t pfe_mac_db_get_next_addr(pfe_mac_db_t *db, pfe_mac_addr_t addr)
{
    errno_t ret = EOK;
    const pfe_mac_db_list_entry_t *entry = NULL_PTR;
    const pfe_isa_t *isa = &db->mac_list;
    bool_t found = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == db) || (NULL_PTR == addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        while(db->next_item < isa->occupied_items_count)
        {
            entry = (pfe_mac_db_list_entry_t *) isa_item(isa, db->next_item);
            db->next_item++;
            if ((NULL_PTR != entry))
            {
                if (TRUE == pfe_mac_db_criterion_eval(entry, db->crit.crit, db->crit.type, db->crit.owner))
                {
                    found = TRUE;
                    break;
                }
            }
        }

        if (TRUE == found)
        {
            (void) autolibc_memcpy(addr, entry->addr, sizeof(pfe_mac_addr_t));
        }
        else
        {
            ret = ENOENT;
        }
    }

    return ret;
}

/**
 * @brief       Search for specific MAC address in the database and return pointer on related entry
 * @param[in]   db Pointer to MAC database instance
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner Required owner of MAC address
 * @param[out]  match_entry Returned db entry, may be NULL if not interested
 * @return      EOK     success
 * @return      ENOENT  not found
 * @return      EINVAL  NULL argument received
 */
errno_t pfe_mac_db_find_by_crit(pfe_mac_db_t *db, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner, pfe_mac_db_list_entry_t *match_entry)
{
    errno_t ret = ENOENT;
    const pfe_mac_db_list_entry_t *entry = NULL_PTR;
    const pfe_isa_t *isa = &db->mac_list;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == db))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for(uint32 db_idx = 0U; db_idx < isa->occupied_items_count; db_idx++)
        {
            entry = (pfe_mac_db_list_entry_t *) isa_item(isa, db_idx);
            if ((NULL_PTR != entry))
            {
                if (TRUE == pfe_mac_db_criterion_eval(entry, crit, type, owner))
                {
                    if (NULL_PTR != match_entry)
                    {
                        (void) autolibc_memcpy(match_entry->addr, entry->addr, sizeof(pfe_mac_addr_t));
                        match_entry->owner = entry->owner;
                    }
                    ret = EOK;
                    break;
                }
            }            
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [170/185]: src\pfe_minihif_drv.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *
 *  This file contains sample code only. It is not part of the production code deliverables.
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_PFE_MINIHIF_DRV
 * @{
 *
 * @file        pfe_minihif_drv.c
 * @brief       The miniHIF driver source file.
 * @details     This is the miniHIF driver with functionality limited to only simple
 *              packet transmission and reception.
 *
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "pfe_platform_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_hif_chnl.h"
#include "pfe_platform.h"
#include "pfe_log_if.h"
#include "pfe_cbus.h"
#include "Eth_43_PFE.h"
#include "pfe_minihif_drv.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Check if rings were attached
 * @param[in, out]  hif_drv The driver instance
 */
static errno_t check_rings(pfe_minihif_drv_t *hif_drv)
{
    errno_t ret;

    if(FALSE == hif_drv->rx_ring_created)
    {
        NXP_LOG_ERROR("RX BD ring was not attached\n");
        ret = EFAULT;
    }
    else if(FALSE == hif_drv->rx_ring_created)
    {
        NXP_LOG_ERROR("TX BD ring was not attached\n");
        ret = EFAULT;
    }
    else
    {
        ret = EOK;
    }

    return ret;
}
/**
 * @brief       Enable the phy_if associated with the HIF channel
 * @param[in, out]  hif_drv The driver instance
 */
static errno_t turn_hif_phyif_on_off(pfe_minihif_drv_t *hif_drv, bool_t enable)
{
    const pfe_platform_t *pPlatform;
    pfe_phy_if_t *prHif;
    errno_t ret = EOK;

    /*  Get the physical interface for our HIF channel */
    pPlatform = (const pfe_platform_t *)Eth_43_PFE_GetPlatform();
    prHif = pfe_platform_get_phy_if_by_id(pPlatform, hif_drv->id);
    if(NULL == prHif)
    {
        NXP_LOG_ERROR("Can't get physical interface for the HIF\n");
        ret = EFAULT;
    }
    /* Enable HIF physical interfaces */
    else 
    {
        if(TRUE == enable)
        {
            if(EOK != pfe_phy_if_enable(prHif))
            {
                NXP_LOG_ERROR("Failed to enable physical interface for the HIF\n");
                ret = EFAULT;
            }
        }
        else /* FALSE == enable */
        {
            if(EOK != pfe_phy_if_disable(prHif))
            {
                NXP_LOG_ERROR("Failed to disable physical interface for the HIF\n");
                ret = EFAULT;
            }
        }
    }

    return ret;
}

/**
 * @brief       Create the driver instance
 * @param[in]   hif_drv The driver instance
 * @param[in]   id The HIF ID in range from PFE_PHY_IF_ID_HIF0 to PFE_PHY_IF_ID_HIF3
 * @param[in]   bd_access Shall be FALSE as this implementation does not support datapath API
 * @retval      EOK if success, error code otherwise
 */
errno_t pfe_minihif_drv_create(pfe_minihif_drv_t *hif_drv, pfe_ct_phy_if_id_t id, bool_t bd_access)
{
    errno_t ret;

    if(unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
    {
        if(TRUE == bd_access)
        {
            NXP_LOG_ERROR("This implementation does not support datapath API\n");
            ret = EINVAL;
        }
        else
        {
            if((id < PFE_PHY_IF_ID_HIF0) || (id > PFE_PHY_IF_ID_HIF3))
            {
                NXP_LOG_ERROR("Unsupported HIF channel\n");
                ret = EINVAL;
            }
            else
            {
                hif_drv->id = id;
                hif_drv->rx_ring_created = FALSE;
                hif_drv->tx_ring_created = FALSE;
                hif_drv->init_done = FALSE;
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
 * @brief       Attach ring to the driver instance
 * @param[in]   hif_drv The driver instance
 * @param[in]   is_rx ring is for Tx or Rx
 * @param[in]   bd_base_va Pointer to buffer descriptor base address
 * @param[in]   wb_bd_base_va Pointer to write-back buffer descriptor base address
 * @param[in]   length ring length
 * @retval      EOK if success, error code otherwise
 */
errno_t pfe_minihif_drv_attach_ring(pfe_minihif_drv_t *hif_drv, bool_t is_rx, void *bd_base_va, void *wb_bd_base_va, uint32 length)
{
    pfe_hif_ring_t *ring;
    errno_t ret;

    if(unlikely((NULL == hif_drv)
              || (NULL == bd_base_va)
              || ((NULL == wb_bd_base_va) && (hif_drv->id != PFE_PHY_IF_ID_HIF_NOCPY))
                )
       )
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
    {
        if(TRUE == is_rx)
        {
            ring = &hif_drv->rx_ring;
        }
        else
        {
            ring = &hif_drv->tx_ring;
        }
        ret = pfe_hif_ring_create_minihif(ring, bd_base_va, wb_bd_base_va, length, is_rx);
        if(likely(EOK == ret))
        {
            if(TRUE == is_rx)
            {
                hif_drv->rx_ring_created = TRUE;
            }
            else
            {
                hif_drv->tx_ring_created = TRUE;
            }
        }
        else
        {
            NXP_LOG_ERROR("Could not create BD ring\n");
        }
    }
    return ret;
}

/**
 * @brief       Initialize the minihif driver
 * @param[in]   hif_drv The driver instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_minihif_drv_init(pfe_minihif_drv_t *hif_drv)
{
    errno_t ret;

    if(unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret =  EINVAL;
    }
    else
    {
        /* Check prerequisities */
        if(EOK != check_rings(hif_drv))
        {
            ret = EINVAL;
        }
        else
        {
            PfeDevAssert((uint32)hif_drv->id >= (uint32)PFE_PHY_IF_ID_HIF0);

            if(EOK != turn_hif_phyif_on_off(hif_drv, FALSE))
            {
                ret = EFAULT;
            }
            /* Create channel*/
            else if(EOK != pfe_hif_chnl_create_minihif  (   &hif_drv->channel, 
                                                            PFE_CFG_CBUS_PHYS_BASE_ADDR_CPU + CBUS_HIF_BASE_ADDR, 
                                                            (uint32)hif_drv->id - (uint32)PFE_PHY_IF_ID_HIF0,
                                                            &hif_drv->rx_ring, 
                                                            &hif_drv->tx_ring
                                                        )
                   )
            {
                NXP_LOG_ERROR("pfe_minihif_drv_init() failed to create minihif channel\n");
                ret = EFAULT;
            }
            else if(EOK != turn_hif_phyif_on_off(hif_drv, TRUE))
            {
                pfe_hif_chnl_destroy_chnl(&hif_drv->channel);
                ret = EFAULT;
            }
            else
            {
                pfe_hif_chnl_rx_disable(&hif_drv->channel);
                pfe_hif_chnl_tx_disable(&hif_drv->channel);
                hif_drv->init_done = TRUE;
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
 * @brief       Enables data reception
 * @param[in]   hif_drv The driver instance
 */
errno_t pfe_minihif_drv_start_rx(pfe_minihif_drv_t *hif_drv)
{
    errno_t ret;

    if(unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if(FALSE == hif_drv->init_done)
    {
        NXP_LOG_ERROR("Minihif not initialized\n");
        ret = EINVAL;
    }
    else
    {
        ret = pfe_hif_chnl_rx_enable(&hif_drv->channel);
    }

    return ret;
}

/**
 * @brief       Enabled data transmission
 * @param[in]   hif_drv The driver instance
 */
errno_t pfe_minihif_drv_start_tx(pfe_minihif_drv_t *hif_drv)
{
    errno_t ret;

    if(unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if(FALSE == hif_drv->init_done)
    {
        NXP_LOG_ERROR("Minihif not initialized\n");
        ret = EINVAL;
    }
    else
    {
        ret = pfe_hif_chnl_tx_enable(&hif_drv->channel);
    }

    return ret;
}

/**
 * @brief       Disable minihif chnl Rx and Tx
 * @param[in]   hif_drv The driver instance
 */
errno_t pfe_minihif_drv_stop(pfe_minihif_drv_t *hif_drv)
{
    errno_t ret;

    if(unlikely(NULL == hif_drv))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if(FALSE == hif_drv->init_done)
    {
        NXP_LOG_ERROR("Minihif not initialized\n");
        ret = EINVAL;
    }
    else
    {
        pfe_hif_chnl_tx_disable(&hif_drv->channel);
        pfe_hif_chnl_rx_disable(&hif_drv->channel);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get HIF ID
 * @param[in]   hif_drv The driver instance
 * @return      Returns HIF channel ID if configured, otherwise PFE_PHY_IF_ID_INVALID is returned
 */
pfe_ct_phy_if_id_t pfe_minihif_get_hif_id(const pfe_minihif_drv_t *hif_drv)
{
    pfe_ct_phy_if_id_t ret;

    if(NULL == hif_drv)
    {
        ret = PFE_PHY_IF_ID_INVALID;
    }
    else if((hif_drv->id < PFE_PHY_IF_ID_HIF0) || (hif_drv->id > PFE_PHY_IF_ID_HIF3))
    {
        ret = PFE_PHY_IF_ID_INVALID;
    }
    else
    {
        ret = hif_drv->id;
    }
    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/


===== 文件 [171/185]: src\pfe_mirror.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  Copyright 2021-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "fpp.h"
#include "oal.h"
#include "hal.h"
#include "pfe_class.h"
#include "pfe_mirror.h"
#include "fpp_ext.h"
#if PFE_CFG_MIRRORS_MAX > 0
#include "isa.h"
#endif /* PFE_CFG_MIRRORS_MAX */

struct pfe_mirror_tag
{
    char name[MIRROR_NAME_SIZE];  /* String identifier */
    addr_t phys_addr;             /* Address of the DMEM representation */
    pfe_ct_mirror_t phys;         /* Physical representation */
    sint8 ref_counter;           /* Summary count of all leased references (pointers) to this mirror instance and to its DMEM representation. */
};

typedef struct
{
    pfe_class_t *class;
#if PFE_CFG_MIRRORS_MAX > 0
    uint32 next_item;
    pfe_isa_t mirrors;
    pfe_mirror_t mirrors_pool[PFE_CFG_MIRRORS_MAX];
    pfe_isa_index_t mirrors_index[PFE_CFG_MIRRORS_MAX];
#endif /* PFE_CFG_MIRRORS_MAX */

} pfe_mirror_db_t;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_mirror_db_t pfe_mirror_db;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#if PFE_CFG_MIRRORS_MAX > 0
#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/* HIF TX headers storage ISA properties definition */
static const pfe_isa_definition_t pfe_mirror_db_isa_def =
{
    .item_count = PFE_CFG_MIRRORS_MAX,
    .item_size = sizeof(pfe_mirror_t),
    .flags = { .ordered = ISA_FLAG_ANY_ORDER },
    .item_indexes = pfe_mirror_db.mirrors_index,
    .items = pfe_mirror_db.mirrors_pool
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_MIRRORS_MAX */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*local functions definitions*/
#if PFE_CFG_MIRRORS_MAX > 0
static pfe_mirror_t *pfe_mirror_allocate_mem(const char *name, pfe_mirror_t *mirror);
static pfe_mirror_t *pfe_mirror_db_get_by_crit(pfe_mirror_db_crit_t crit, const void *arg);
#endif /*PFE_CFG_MIRRORS_MAX > 0*/
/**
 * @brief Initialize the module
 * @param[in] class Reference to the classifier instance
 * @note Can be called only once unless pfe_mirror_deinit() is called.
 * @return Either EOK or error code in case of failure
 * @retval EPERM Already called, cannot be called more than once.
 * @retval EINVAL Invalid input argument (NULL).
 * @retval ENOMEM Could not allocate the needed memory.
 */
errno_t pfe_mirror_init(pfe_class_t *class)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == class))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        if(NULL_PTR != pfe_mirror_db.class)
        {
            ret = EPERM;
        }
        else
        {
            (void)autolibc_memset(&pfe_mirror_db, 0, sizeof(pfe_mirror_db));
            pfe_mirror_db.class = class;
#if PFE_CFG_MIRRORS_MAX > 0
            isa_init(&pfe_mirror_db.mirrors, &pfe_mirror_db_isa_def);
#endif /* PFE_CFG_MIRRORS_MAX */
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief Deinitialize the module - free all internally used resources
 */
void pfe_mirror_deinit(void)
{
    if(NULL_PTR != pfe_mirror_db.class)
    {
#if PFE_CFG_MIRRORS_MAX > 0
        /* Check whether the database is empty */
        if(FALSE == isa_isempty(&pfe_mirror_db.mirrors))
        {   /* Not empty */
            NXP_LOG_ERROR("There are still entries in the database\n");
        }
#endif /* PFE_CFG_MIRRORS_MAX */
        (void)autolibc_memset(&pfe_mirror_db, 0, sizeof(pfe_mirror_db));
    }
}

#if PFE_CFG_MIRRORS_MAX > 0
/**
 * @brief Queries mirrors database for the mirror instance corresponding to the search criterion
 * @param[in] crit Criterion to be used (MIRROR_ANY is used to get 1st entry)
 * @param[in] arg Criterion argument (data)
 * @return The matching mirror instance or NULL if there is no matching mirror in the database
 */
static pfe_mirror_t *pfe_mirror_db_get_by_crit(pfe_mirror_db_crit_t crit, const void *arg)
{
    pfe_mirror_t *mirror;
    bool_t match = FALSE;

    /* Iterate */
    while((pfe_mirror_db.next_item < pfe_mirror_db.mirrors.occupied_items_count) && (match == FALSE))
    {
        mirror = (pfe_mirror_t *)isa_item(&pfe_mirror_db.mirrors, pfe_mirror_db.next_item);
        if(NULL_PTR == mirror)
        {
            break;
        }
        else
        {
            pfe_mirror_db.next_item++;
            switch(crit)
            {
                case MIRROR_ANY:
                    /* Special criterion - return the 1st in the database */
                    match = TRUE;
                    break;
                case MIRROR_BY_NAME:
                    if(0 == autolibc_strcmp(mirror->name, (const char *)arg))
                    {   /* Match */
                        match = TRUE;
                    }
                    break;
                case MIRROR_BY_PHYS_ADDR:
                    if(mirror->phys_addr == (addr_t) arg)
                    {   /* Match */
                        match = TRUE;
                    }
                    break;
                default :
                    NXP_LOG_ERROR("Wrong criterion %u\n", crit);
                    pfe_mirror_db.next_item = pfe_mirror_db.mirrors.occupied_items_count;
                    break;
            }
        }
    }
    if(FALSE == match)
    {
        mirror = NULL_PTR;
    }

    return mirror;
}
#endif /* PFE_CFG_MIRRORS_MAX */

/**
 * @brief Obtain the 1st mirror matching the specified criteria
 * @param[in] crit Matching criterion for the mirrors
 * @param[in] arg Criterion specific argument (value)
 * @return Either the 1st found mirror instance or NULL if there is no matching mirror
 * @note  When execution thread which called this function finishes working with the provided instance,
 *        it must call pfe_mirror_put() for the given instance to "release" it.
 */
pfe_mirror_t *pfe_mirror_get_first(pfe_mirror_db_crit_t crit, const void *arg)
{
    pfe_mirror_t *mirror = NULL_PTR;
#if PFE_CFG_MIRRORS_MAX > 0
    if(NULL_PTR != pfe_mirror_db.class)
    {
        pfe_mirror_db.next_item = 0U;
        mirror = pfe_mirror_db_get_by_crit(crit, arg);
        if (NULL != mirror)
        {
            mirror->ref_counter++;
        }
    }
#else
    (void)crit;
    (void)arg;
#endif /* PFE_CFG_MIRRORS_MAX */
    return mirror;
}

/**
 * @brief Returns the next mirror matching the criterion passed to pfe_mirror_db_get_by_crit()
 * @note  Only the MIRROR_ANY criterion is supported because mirrors are forced to have
 *        unique name and address and there are no other criteria to match. It is expected
 *        that the pfe_mirror_get_first(MIRROR_ANY, NULL) is used to obtain the 1st mirror
 *        and pfe_mirror_get_next() is used to get list of all mirrors.
 * @return Either next mirror or NULL if there are no more mirrors.
 * @note  When execution thread which called this function finishes working with the provided instance,
 *        it must call pfe_mirror_put() for the given instance to "release" it.
 */
pfe_mirror_t *pfe_mirror_get_next(void)
{
    pfe_mirror_t *mirror = NULL_PTR;
#if PFE_CFG_MIRRORS_MAX > 0
    if(NULL_PTR != pfe_mirror_db.class)
    {
        /* We do not support any other criteria than MIRROR_ANY. */
        mirror = pfe_mirror_db_get_by_crit(MIRROR_ANY, NULL_PTR);
        if (NULL != mirror)
        {
            mirror->ref_counter++;
        }
    }
#endif /* PFE_CFG_MIRRORS_MAX */

    return mirror;
}

#if PFE_CFG_MIRRORS_MAX > 0
/**
 * @brief Allocates memory for a new mirror instance
 * @param[in] name Unique name (identifier)
 * @param[in] mirror Pointer to the mirror instance
 * @return Mirror instance or NULL in case of failure
 */
static pfe_mirror_t *pfe_mirror_allocate_mem(const char *name, pfe_mirror_t *mirror)
{
    /* ISA entry available */
    (void)autolibc_memset(mirror, 0, sizeof(*mirror));
    /* Allocate DMEM */
    mirror->phys_addr = pfe_class_dmem_heap_alloc(pfe_mirror_db.class, sizeof(pfe_ct_mirror_t));
    if(0U == mirror->phys_addr)
    {
        /* No DMEM */
        NXP_LOG_ERROR("Not enough DMEM for mirror\n");
        (void)isa_release(&pfe_mirror_db.mirrors, mirror);
        mirror = NULL_PTR;
    }
    else
    {
        /* Remember name */
        (void)autolibc_strncpy(mirror->name, name, sizeof(mirror->name));
        mirror->ref_counter = 1;  /* Init to 1, because this function already returns a pointer (reference) of the newly created mirror. */
    }

    return mirror;
}
#endif /*PFE_CFG_MIRRORS_MAX > 0*/

/**
 * @brief Creates a new mirror instance
 * @param[in] name Unique name (identifier)
 * @return Mirror instance or NULL in case of failure
 * @note When execution thread which called this function finishes working with the provided instance,
 *       it must call pfe_mirror_ref_release() for the given instance to "release" it.
 */
pfe_mirror_t *pfe_mirror_create(const char *name)
{
    pfe_mirror_t *mirror = NULL_PTR;
#if PFE_CFG_MIRRORS_MAX > 0
    uint32     length;
#endif /* PFE_CFG_MIRRORS_MAX */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif
    {
#if PFE_CFG_MIRRORS_MAX > 0
        /* check name for validity */
        length = autolibc_strnlen(name, sizeof(mirror->name));
        if((sizeof(mirror->name) <= length) || (0U == length))
        {
            NXP_LOG_ERROR("PFE mirror name string is invalid\n");
        }
        else if(NULL_PTR != pfe_mirror_db.class)
        {
            /* Do not allow duplicates */
            if(NULL_PTR == pfe_mirror_get_first(MIRROR_BY_NAME, (void *)name))
            {
                /* No such entry in the database, we may add a new one */
                mirror = (pfe_mirror_t *)isa_reserve(&pfe_mirror_db.mirrors);
                if(NULL_PTR != mirror)
                {
                    mirror = pfe_mirror_allocate_mem(name, mirror);
                }
            }
        }
        else
        {
            ;
        }
#else
      (void)name;
#endif /* PFE_CFG_MIRRORS_MAX */
    }

    return mirror;
}

/**
 * @brief Destroys the selected mirror
 * @param[in] mirror Mirror instance
 * @warning Make sure the mirror is not in use.
 * @retval OK Success
 * @retval EBUSY Mirror instance is currently utilized. It must not be destroyed now.
 */
errno_t pfe_mirror_destroy(pfe_mirror_t *mirror)
{
    errno_t ret = EOK;

#if PFE_CFG_MIRRORS_MAX > 0
    if(NULL_PTR != mirror)
    {
        /* Count '1' or lower is considered OK for deletion.
         * Count '1' means only one existing reference - the reference in the thread which is calling this destroy function. */
        if (1 >= mirror->ref_counter)
        {
            pfe_class_dmem_heap_free(pfe_mirror_db.class, mirror->phys_addr);
            (void)isa_release(&pfe_mirror_db.mirrors, mirror);
            ret = EOK;
        }
        else
        {
            ret = EBUSY;
        }
    }
#else
    (void)mirror;
#endif /* PFE_CFG_MIRRORS_MAX */

    return ret;
}

/**
 * @brief Decrements reference counter of a mirror instance.
 * @param[in] mirror Mirror instance. Can be NULL.
 * @important When a code outside of this module obtains pointer to some mirror instance
 *            via _get_first()/_get_next(), then call this function in that code when
 *            the code is done working with the instance.
 * @note It is assumed this function is complementary to _get_first() / _get_next().
 *       This assumption ensures the target mirror instance stays valid (cannot be concurrently deleted)
 *       thanks to its high reference count.
 */
void pfe_mirror_put(pfe_mirror_t *mirror)
{
    if (likely(NULL_PTR != mirror))
    {
        mirror->ref_counter--;
    }
}

/**
 * @brief Decrements reference counter of a mirror instance. Finds the mirror instance by address of its DMEM representation.
 * @param[in] address Address of mirror instance DMEM representation.
 * @note See notes of pfe_mirror_put()
 */
void pfe_mirror_put_by_address(addr_t address)
{
    pfe_mirror_t *mirror = NULL;

    mirror = pfe_mirror_get_first(MIRROR_BY_PHYS_ADDR, (void *)address);
    pfe_mirror_put(mirror);  /* Decrement reference counter. This is what this function does. */
    pfe_mirror_put(mirror);  /* Notify mirror module we are done working with the mirror instance. This complements the previous _get_first(). */
}

/**
 * @brief Retrieves DMEM address used by the mirror instance
 * @param[in] mirror Mirror instance
 * @return DMEM address used by the mirror
 */
uint32 pfe_mirror_get_address(const pfe_mirror_t *mirror)
{
    uint32 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == mirror))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif
    {
        ret = mirror->phys_addr;
    }
    return ret;
}

/**
 * @brief Retrieves mirror name
 * @param[in] mirror Mirror instance
 * @return Mirror name - this string shall not be modified outside; NULL in case of failure
 */
const char *pfe_mirror_get_name(const pfe_mirror_t *mirror)
{
    const char *str;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == mirror))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        str = NULL_PTR;
    }
    else
#endif
    {
        str = mirror->name;
    }

    return str;
}

/**
 * @brief Configures egress port for mirrored frames
 * @param[in] mirror Mirror instance
 * @param[in] egress Egress port for mirrored frames
 * @return EOK when success or error code otherwise
 */
errno_t pfe_mirror_set_egress_port(pfe_mirror_t *mirror, pfe_ct_phy_if_id_t egress)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == mirror))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* No endian conversion is needed since the size is 8-bits */
        mirror->phys.e_phy_if = egress;
        ret = pfe_class_write_dmem(pfe_mirror_db.class, -1, mirror->phys_addr, &mirror->phys, sizeof(pfe_ct_mirror_t));
    }

    return ret;
}

/**
 * @brief Retrieves egress port for mirrored frames
 * @param[in] mirror Mirror instance
 * @return The egress port
 */
pfe_ct_phy_if_id_t pfe_mirror_get_egress_port(const pfe_mirror_t *mirror)
{
    pfe_ct_phy_if_id_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == mirror))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = PFE_PHY_IF_ID_INVALID;
    }
    else
#endif
    {
        /* No endian conversion is needed since the size is 8-bits */
        ret = mirror->phys.e_phy_if;
    }

    return ret;
}

/**
 * @brief Configures flexible filter to select mirrored frames
 * @param[in] mirror Mirror instance
 * @param[in] filter_adress Address of flexible filter to select mirrored frames (0 to disable the filter)
 * @return EOK when success or error code otherwise
 */
errno_t pfe_mirror_set_filter(pfe_mirror_t *mirror, uint32 filter_address)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == mirror))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        /* Set the address of the filter table (convert endian) */
        mirror->phys.flexible_filter = oal_htonl(filter_address);
        ret = pfe_class_write_dmem(pfe_mirror_db.class, -1, mirror->phys_addr, &mirror->phys, sizeof(pfe_ct_mirror_t));
    }

    return ret;
}

/**
 * @brief Retrieves flexible filter to select mirrored frames
 * @param[in] mirror Mirror instance
 * @return Address of flexible filter to select mirrored frames (0 = disabled the filter)
 */
uint32 pfe_mirror_get_filter(const pfe_mirror_t *mirror)
{
    uint32 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == mirror))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif
    {
        ret = oal_ntohl(mirror->phys.flexible_filter);
    }
    /* Set the address of the filter table (convert endian) */

    return ret;
}

/**
 * @brief Configures mirrored frame modifications
 * @param[in] mirror Mirror instance
 * @param[in] actions Actions to be done on mirrored frame (network endian)
 * @param[in] args Arguments for actions (all fields in network endian)
 * @return EOK when success or error code otherwise
 */
errno_t pfe_mirror_set_actions(pfe_mirror_t *mirror, pfe_ct_route_actions_t actions, const pfe_ct_route_actions_args_t *args)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == mirror))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        mirror->phys.actions = actions;
        if(RT_ACT_NONE != actions)
        {
            (void)autolibc_memcpy(&mirror->phys.args, args, sizeof(pfe_ct_route_actions_args_t));
        }
        ret = pfe_class_write_dmem(pfe_mirror_db.class, -1, mirror->phys_addr, &mirror->phys, sizeof(pfe_ct_mirror_t));
    }

    return ret;
}

/**
 * @brief Queries mirrored frame modifications
 * @param[in] mirror Mirror instance
 * @param[out] actions Actions to be done on mirrored frame (network endian)
 * @param[out] args Arguments for actions (all fields in network endian)
 * @return EOK when success or error code otherwise
 */
errno_t pfe_mirror_get_actions(const pfe_mirror_t *mirror, pfe_ct_route_actions_t *actions, pfe_ct_route_actions_args_t *args)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == mirror)||(NULL == args)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif
    {
        ret = EOK;
        *actions = mirror->phys.actions;
        if(RT_ACT_NONE != mirror->phys.actions)
        {   /* Arguments are needed */
            (void)autolibc_memcpy(args, &mirror->phys.args, sizeof(pfe_ct_route_actions_args_t));
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [172/185]: src\pfe_parity.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2019-2023 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_parity.h"
#include "pfe_parity_csr.h"

struct pfe_parity_tag
{
    addr_t cbus_base_va;
    addr_t parity_base_offset;
    addr_t parity_base_va;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_parity_t parity_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Create new PARITY instance
 * @details     Create and initializes PARITY instance. New instance is always enabled.
 *              Use mask and unmask function to control interrupts.
 * @param[in]   base_va PARITY register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Interrupt which were triggered are masked here, it is periodically unmasked again in SAFETY thread
 */
pfe_parity_t *pfe_parity_create(addr_t cbus_base_va, addr_t parity_base)
{
    pfe_parity_t *parity;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        parity = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        parity = &parity_instance;
        (void)autolibc_memset(parity, 0, sizeof(pfe_parity_t));
        parity->cbus_base_va = cbus_base_va;
        parity->parity_base_offset = parity_base;
        parity->parity_base_va = (ADDR_BASE_OFFSET(parity->cbus_base_va, parity->parity_base_offset));

        /* Unmask all interrupts */
        pfe_parity_cfg_irq_unmask_all(parity->parity_base_va);
    }

    return parity;
}

/**
 * @brief       Destroy PARITY instance
 * @param[in]   parity The PARITY instance
 */
void pfe_parity_destroy(pfe_parity_t *parity)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == parity))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Mask parity interrupts */
        pfe_parity_cfg_irq_mask(parity->parity_base_va);
    }
}

/**
 * @brief       PARITY ISR
 * @param[in]   parity The PARITY instance
 * @return      EOK if interrupt has been handled
 */
errno_t pfe_parity_isr(const pfe_parity_t *parity)
{
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == parity))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = ENOMEM;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        ret = pfe_parity_cfg_isr(parity->parity_base_va);
    }

    return ret;
}

/**
 * @brief       Mask PARITY interrupts
 * @param[in]   parity The PARITY instance
 */
void pfe_parity_irq_mask(const pfe_parity_t *parity)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == parity))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_parity_cfg_irq_mask(parity->parity_base_va);
    }
}

/**
 * @brief       Unmask PARITY interrupts
 * @param[in]   parity The PARITY instance
 */
void pfe_parity_irq_unmask(const pfe_parity_t *parity)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == parity))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_parity_cfg_irq_unmask(parity->parity_base_va);
    }
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [173/185]: src\pfe_parity_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2019-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_parity_csr.h"
#include "pfe_global_wsp.h"
#include "Eth_43_PFE_Cfg.h"

#define WSP_PARITY_INT_SRC_NUMBER   31U
#define TRIG_EN_INTERRUPTS_CHECK   (MASTER1_INT | MASTER2_INT | MASTER3_INT | MASTER4_INT | \
                                    EMAC_CBUS_INT | EMAC_DBUS_INT | CLASS_CBUS_INT | CLASS_DBUS_INT | \
                                    TMU_CBUS_INT | TMU_DBUS_INT | HIF_CBUS_INT | HIF_DBUS_INT | \
                                    HIF_NOCPY_CBUS_INT | HIF_NOCPY_DBUS_INT | UPE_CBUS_INT | UPE_DBUS_INT | \
                                    HRS_CBUS_INT | BRIDGE_CBUS_INT | EMAC_SLV_INT | BMU1_SLV_INT | \
                                    BMU2_SLV_INT | CLASS_SLV_INT | HIF_SLV_INT | HIF_NOCPY_SLV_INT | \
                                    LMEM_SLV_INT | TMU_SLV_INT | UPE_SLV_INT | WSP_GLOBAL_SLV_INT | \
                                    GPT1_SLV_INT | GPT2_SLV_INT | ROUTEMEM_SLV_INT \
                                   )

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       PARITY ISR
 * @details     MASK, ACK, and process triggered interrupts.
 * @param[in]   base_va PARITY register space base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 */
errno_t pfe_parity_cfg_isr(addr_t base_va)
{
    uint32 reg_en, reg_src;
    errno_t ret = ENOENT;
    uint32 trig_en_interrupts;
    uint8 index = 0U;
    static const pfe_hm_evt_t event_id[WSP_PARITY_INT_SRC_NUMBER] =
    {
        HM_EVT_PARITY_MASTER1,
        HM_EVT_PARITY_MASTER2,
        HM_EVT_PARITY_MASTER3,
        HM_EVT_PARITY_MASTER4,
        HM_EVT_PARITY_EMAC_CBUS,
        HM_EVT_PARITY_EMAC_DBUS,
        HM_EVT_PARITY_CLASS_CBUS,
        HM_EVT_PARITY_CLASS_DBUS,
        HM_EVT_PARITY_TMU_CBUS,
        HM_EVT_PARITY_TMU_DBUS,
        HM_EVT_PARITY_HIF_CBUS,
        HM_EVT_PARITY_HIF_DBUS,
        HM_EVT_PARITY_HIF_NOCPY_CBUS,
        HM_EVT_PARITY_HIF_NOCPY_DBUS,
        HM_EVT_PARITY_UPE_CBUS,
        HM_EVT_PARITY_UPE_DBUS,
        HM_EVT_PARITY_HRS_CBUS,
        HM_EVT_PARITY_BRIDGE_CBUS,
        HM_EVT_PARITY_EMAC_SLV,
        HM_EVT_PARITY_BMU1_SLV,
        HM_EVT_PARITY_BMU2_SLV,
        HM_EVT_PARITY_CLASS_SLV,
        HM_EVT_PARITY_HIF_SLV,
        HM_EVT_PARITY_HIF_NOCPY_SLV,
        HM_EVT_PARITY_LMEM_SLV,
        HM_EVT_PARITY_TMU_SLV,
        HM_EVT_PARITY_UPE_SLV,
        HM_EVT_PARITY_WSP_GLOBAL_SLV,
        HM_EVT_PARITY_GPT1_SLV,
        HM_EVT_PARITY_GPT2_SLV,
        HM_EVT_PARITY_ROUTE_LMEM_SLV,
    };

    /* Get enabled interrupts */
    reg_en = hal_read32(ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_EN));
    /* Mask parity interrupts */
    hal_write32((reg_en & ~(PARITY_INT_EN)), ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_EN));
    /* Get triggered interrupts */
    reg_src = hal_read32(ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_SRC));
    /* ACK triggered interrupts */
    hal_write32(reg_src, ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_SRC));

    /* Process interrupts which are triggered AND enabled */
    trig_en_interrupts = reg_src & reg_en & TRIG_EN_INTERRUPTS_CHECK;
    if (0U != trig_en_interrupts)
    {
        trig_en_interrupts >>= 1U;
        while (0U != trig_en_interrupts)
        {
            if (0U != (trig_en_interrupts & 1UL))
            {
                PfeDevAssert(index < WSP_PARITY_INT_SRC_NUMBER);
                pfe_hm_report_error(HM_SRC_PARITY, event_id[index], "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
                (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_PFE_PARITY_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
            }
            trig_en_interrupts >>= 1U;
            index++;
        }
        ret = EOK;
    }

    /* Enable the non-triggered ones only to prevent flooding */
    hal_write32((reg_en & ~reg_src), ADDR_BASE_OFFSET(base_va,  WSP_PARITY_INT_EN));

    return ret;
}

/**
 * @brief       Mask PARITY interrupts
 * @param[in]   base_va Base address of the PARITY register space
 */
void pfe_parity_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_EN)) & ~(PARITY_INT_EN);
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_EN));
}

/**
 * @brief       Unmask PARITY interrupts
 * @param[in]   base_va Base address of the PARITY register space
 */
void pfe_parity_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_EN)) | PARITY_INT_EN;
    hal_write32(reg, ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_EN));
}

/**
 * @brief       Unmask all PARITY interrupts
 * @param[in]   base_va Base address of the PARITY register space
 * @note        This function is called from thread.
 */
void pfe_parity_cfg_irq_unmask_all(addr_t base_va)
{
    hal_write32(PARITY_INT_ENABLE_ALL, ADDR_BASE_OFFSET(base_va, WSP_PARITY_INT_EN));
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


===== 文件 [174/185]: src\pfe_pe.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_platform.h"
#include "elf_cfg.h"
#include "elf.h"
#include "pfe_cbus.h"
#include "pfe_pe.h"
#include "pfe_hm.h"
#include "pfe_class_csr.h"
#include "Eth_43_PFE_Cfg.h"

#define BYTES_TO_4B_ALIGNMENT(x)    (4U - ((x) & 0x3U))
#define INVALID_FEATURES_BASE       0xFFFFFFFFU
#define ALIGNMENT_CHECKMASK         0x3U
#define ALIGNMENT_PACKEDNUMBER      4U

/**
 * @brief   Mutex protecting access to common mem_access_* registers
 */
#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"


/* usage scope: pfe_pe_load_firmware*/
static pfe_ct_pe_mmap_t tmp_mmap;
static uint8 tmp_features[ETH_43_PFE_FEATURES_SECTION_BUFF_SIZE];
static uint8 tmp_messages[ETH_43_PFE_MESSAGES_SECTION_BUFF_SIZE];

typedef struct
{
    pfe_pe_mem_t mem;       /*Memory to access*/
    uint32 val;           /*Value to write (BE)*/
    addr_t addr;            /*Write address (should be aligned to 32 bits)*/
    uint8 size;           /*Number of bytes to write (maximum 4)*/
    uint8 offset;         /*Number of bytes the addr needs to be aligned (maximum 3)*/
}pfe_pe_mem_data_t;

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_pe_get_state_monitor_nolock(pfe_pe_t *pe, pfe_ct_pe_sw_state_monitor_t *state_monitor);
static bool_t pfe_pe_is_active_nolock(pfe_pe_t *pe);
static void pfe_pe_memcpy_from_host_to_dmem_32_nolock(
        pfe_pe_t *pe, addr_t dst_addr, const void *src_ptr, uint32 len);
/* FW loading functions */
static void pfe_pe_fw_memcpy_bulk(pfe_pe_t *pe, pfe_pe_mem_t mem, addr_t dst_addr, const void *src_ptr, uint32 len);
static void pfe_pe_fw_memset_bulk(pfe_pe_t *pe, pfe_pe_mem_t mem, uint32 val, addr_t addr, uint32 size);
static void pfe_pe_fw_memcpy_single(pfe_pe_t *pe, pfe_pe_mem_t mem, addr_t dst_addr, const void *src_ptr, uint32 len);
static void pfe_pe_fw_memset_single(pfe_pe_t *pe, pfe_pe_mem_t mem, uint32 val, addr_t addr, uint32 size);
static void pfe_pe_free_mem(pfe_pe_t *pe, uint32 pe_num);
static errno_t pfe_pe_upload_sections(pfe_pe_t *pe, uint32 pe_num, const ELF_File_t *elf_file);
static void print_fw_issue(const pfe_ct_pe_mmap_t *fw_mmap);
static uint8 pfe_pe_fw_load_cycles(const pfe_pe_t *pe, uint8 pe_num);
static errno_t pfe_pe_load_elf_section(pfe_pe_t *pe, const void *sdata, addr_t load_addr, addr_t size, uint32 type);
static addr_t pfe_pe_get_elf_sect_load_addr(const ELF_File_t *elf_file, const Elf32_Shdr *shdr);
static errno_t pfe_pe_fw_ops_valid(pfe_pe_t *pe1, const pfe_pe_t *pe2);
static errno_t pfe_pe_fw_install_ops(pfe_pe_t *pe, uint8 pe_num);
static uint32 pfe_pe_mem_read(pfe_pe_t *pe, pfe_pe_mem_t mem, addr_t addr, uint8 size);
static void pfe_pe_mem_write(pfe_pe_t *pe, pfe_pe_mem_data_t memdata);
static inline uint32 pfe_pe_get_u32_from_byteptr(const uint8 *src_byteptr, uint32 len);
static errno_t pfe_pe_load_dmem_section_nolock(pfe_pe_t *pe, const void *sdata, addr_t addr, addr_t size, uint32 type);
static errno_t pfe_pe_load_imem_section_nolock(pfe_pe_t *pe, const void *data, addr_t addr, addr_t size, uint32 type);
static bool_t pfe_pe_is_dmem(const pfe_pe_t *pe, addr_t addr, uint32 size);
static bool_t pfe_pe_is_imem(const pfe_pe_t *pe, addr_t addr, uint32 size);
static errno_t pfe_pe_mem_process_lock(pfe_pe_t *pe, PFE_PTR(pfe_ct_pe_misc_control_t) misc_dmem);
static inline bool_t pfe_pe_check_pe_times (pfe_pe_t *pe, uint32 idx, uint8 best_pe_loader_cnt, uint8 pe_num);
static errno_t pfe_pe_load_firmware_aux(pfe_pe_t *pe, uint32 pe_num, const void *elf);
static errno_t pfe_pe_copy_firmware_sections(const ELF_File_t *elf_file, uint32 * features_size, uint32 * messages_size);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"


static const fw_load_ops_t fw_load_ops[] =
{
    /* These OPs can load 8 CLASS cores only */
    {
        .pe_loaded_cnt = 8U,
        .can_load_util = (bool_t)FALSE,
        .pe_memset = pfe_pe_fw_memset_bulk,
        .pe_memcpy = pfe_pe_fw_memcpy_bulk,
    },
    /* These OPs can load  1 CLASS/UTIL core only */
    {
        .pe_loaded_cnt = 1U,
        .can_load_util = (bool_t)TRUE,
        .pe_memset = pfe_pe_fw_memset_single,
        .pe_memcpy = pfe_pe_fw_memcpy_single,
    },
};

#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static const pfe_hm_src_t hm_types[] = {
    HM_SRC_UNKNOWN,
    HM_SRC_PE_CLASS,
    HM_SRC_PE_TMU,
    HM_SRC_PE_UTIL
};

/**
 * @brief       Try to upload all sections of the .elf
 * @param[in]   pe The PE instances
 * @param[in]   pe_num Number of PE instances
 * @param[in]   elf_file The elf file object to be uploaded
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_pe_upload_sections(pfe_pe_t *pe, uint32 pe_num, const ELF_File_t *elf_file)
{
    uint32 ii, pe_idx;
    addr_t load_addr;
    const void *buf;
    errno_t ret = EOK;

    for (ii = 0U; ii < elf_file->Header.r32.e_shnum; ii++)
    {
        if (0U == (ENDIAN_SW_4B(elf_file->arSectHead32[ii].sh_flags) & (uint32)(((uint32)SHF_WRITE) | ((uint32)SHF_ALLOC) | ((uint32)SHF_EXECINSTR))))
        {
            /*  Skip the section */
            continue;
        }

        buf = (void*)((addr_t)elf_file->pvData + ENDIAN_SW_4B(elf_file->arSectHead32[ii].sh_offset));
        /* Translate elf virtual address to load address */
        load_addr = pfe_pe_get_elf_sect_load_addr(elf_file, &elf_file->arSectHead32[ii]);
        if(0U == load_addr)
        {   /* Failed */
            ret = EINVAL;
            pfe_pe_free_mem(pe, pe_num);
            break;
        }

        for(pe_idx = 0U; pe_idx < pfe_pe_fw_load_cycles(&pe[0], (uint8)(pe_num & UINT8_MAX)); ++pe_idx)
        {
        /*  Upload the section */
            const uint32 sh_type = ENDIAN_SW_4B(elf_file->arSectHead32[ii].sh_type);
            const uint32 sh_size = ENDIAN_SW_4B(elf_file->arSectHead32[ii].sh_size) & UINT32_MAX;
            ret = pfe_pe_load_elf_section(&pe[pe_idx], buf, load_addr, sh_size, sh_type);
            if (EOK != ret)
            {
                const uint32 sh_addr = ENDIAN_SW_4B(elf_file->arSectHead32[ii].sh_addr);
                const uint32 sh_name = ENDIAN_SW_4B(elf_file->arSectHead32[ii].sh_name) & UINT32_MAX;
                NXP_LOG_ERROR("Couldn't upload firmware section %s, %u bytes @ 0x%08x. Reason: %d\n",
                              &(elf_file->acSectNames[sh_name]), (uint_t)sh_size, (uint_t)sh_addr, ret);
                pfe_pe_free_mem(pe, pe_num);
                break;
            }
        }
        if (EOK != ret)
        {
            break;
        }
    }

    return ret;
}

/**
 * @brief       Free memory when see failed condition.
 * @param[in]   pe_num number of the PE instance
  * @param[in]  pe     the PE instance
 */
static void pfe_pe_free_mem(pfe_pe_t *pe, uint32 pe_num)
{
    uint32 ii;

    for (ii = 0; ii < pe_num; ++ii)
    {
        pe[ii].mmap_data = NULL;
        pe[ii].fw_msg_section = NULL;
        pe[ii].fw_msg_section_size = 0U;
        pe[ii].fw_feature_section = NULL;
        pe[ii].fw_feature_section_size = 0U;

    }
}

/**
 * @brief       Get state monitor of the PE
 * @param[in]   pe The PE instance
 * @param[out]  state_monitor Address to write the state monitor data to
 * @return      EOK if succeeded
 */
static errno_t pfe_pe_get_state_monitor_nolock(pfe_pe_t *pe, pfe_ct_pe_sw_state_monitor_t *state_monitor)
{
    errno_t ret;

    if(NULL == pe->mmap_data)
    {
        NXP_LOG_WARNING("PE %u: Firmware not loaded\n", pe->id);
        ret = EIO;
    }
    else
    {
    /*  Get state */
        pfe_pe_memcpy_from_dmem_to_host_32_nolock(
                pe,
                state_monitor,
                oal_ntohl(pe->mmap_data->common.state_monitor),
                sizeof(pfe_ct_pe_sw_state_monitor_t));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Query if PE is active
 * @details     PE is active if it is running (executing firmware code) and is not gracefully stopped
 * @param[in]   pe The PE instance
 * @return      TRUE if PE is active, FALSE if not
 */
static bool_t pfe_pe_is_active_nolock(pfe_pe_t *pe)
{
    pfe_ct_pe_sw_state_monitor_t state_monitor = {0};
    bool_t ret = FALSE;

    if (pfe_pe_get_state_monitor_nolock(pe, &state_monitor) == EOK)
    {
        if ((PFE_FW_STATE_STOPPED != state_monitor.state) && (PFE_FW_STATE_UNINIT != state_monitor.state))
        {
            ret = TRUE;
        }
        /*  PFE_FW_STATE_INIT == state_monitor.state is considered as running because
        the transition to next state is short */
    }

    return ret;
}


/**
* @brief Lock PE access
* @param[in] pe PE which access shall be locked
*/
void pfe_pe_lock_family(pfe_pe_t *pe)
{
    if (unlikely(*(pe->miflock)))
    {
        NXP_LOG_ERROR("Lock already indicated.\n");
    }

    /*  Indicate the 'lock' status */
    *(pe->miflock) = TRUE;
}

/**
* @brief Unlock PE access
* @param[in] pe PE which access shall be unlocked
*/
void pfe_pe_unlock_family(pfe_pe_t *pe)
{
    /* Indicate the 'unlock' status */
    *(pe->miflock) = FALSE;
}

/**
 * @brief       Process to lock PE memory
 * @param[in]   pe The PE instance
 * @param[in]   misc_dmem The miscellaneous control command structure
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_pe_mem_process_lock(pfe_pe_t *pe, PFE_PTR(pfe_ct_pe_misc_control_t) misc_dmem)
{
    errno_t ret;
    pfe_ct_pe_misc_control_t misc_ctrl = {0};
    uint32 timeout = 10;

    /*  Read the misc control structure from DMEM */
    pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, &misc_ctrl, misc_dmem, sizeof(pfe_ct_pe_misc_control_t));

    if (0U != misc_ctrl.graceful_stop_request)
    {
        if (0U != misc_ctrl.graceful_stop_confirmation)
        {
            NXP_LOG_ERROR("Locking locked memory\n");
        }
        else
        {
            NXP_LOG_ERROR("Duplicate stop request\n");
        }

        ret = EPERM;
    }
    else
    {
        /*  Writing the non-zero value triggers the request */
        misc_ctrl.graceful_stop_request = 0xffU;
        /*  PE will respond with setting this to non-zero value */
        misc_ctrl.graceful_stop_confirmation = 0x0U;
        /*  Use 'nolock' variant here. Accessing this data can't lead to conflicts. */
        pfe_pe_memcpy_from_host_to_dmem_32_nolock(
                pe, misc_dmem, &misc_ctrl, sizeof(pfe_ct_pe_misc_control_t));

        if (FALSE == pfe_pe_is_active_nolock(pe))
        {
            /*  Access to PE memories is considered to be safe. PE memory
                interface is locked. */
            ret = EOK;
        }
        else
        {
            ret = EOK;
            /*  Wait for response */
            do
            {
                if (0U == timeout)
                {
                    NXP_LOG_ERROR("Timed-out\n");

                    /*  Cancel the request */
                    misc_ctrl.graceful_stop_request = 0U;

                    /*  Use 'nolock' variant here. Accessing this data can't lead to conflicts. */
                    pfe_pe_memcpy_from_host_to_dmem_32_nolock(
                            pe, misc_dmem, &misc_ctrl, sizeof(pfe_ct_pe_misc_control_t));

                    ret = ETIME;
                    break;
                }

                oal_time_usleep(10U);
                timeout--;
                pfe_pe_memcpy_from_dmem_to_host_32_nolock(
                        pe, &misc_ctrl, misc_dmem, sizeof(pfe_ct_pe_misc_control_t));

            } while (0U == misc_ctrl.graceful_stop_confirmation);
            /*  Access to PE memory interface is locked */
        }
    }
    return ret;
}

/**
 * @brief       Acquire lock of PE memory
 * @details     While locked, the PE can't access internal memory. Invoke the PE graceful
 *              stop request and wait for confirmation. Also lock the PE memory interface.
 * @param[in]   pe The PE instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_pe_memlock_acquire_nolock(pfe_pe_t *pe)
{
    errno_t ret;
    PFE_PTR(pfe_ct_pe_misc_control_t) misc_dmem;

    if (NULL == pe->mmap_data)
    {
        ret = ENOEXEC;
    }
    else
    {
        misc_dmem = oal_ntohl(pe->mmap_data->common.pe_misc_control);
        if (0U == misc_dmem)
        {
            ret = EINVAL;
        }
        else
        {
            ret = pfe_pe_mem_process_lock(pe, misc_dmem);
        }
    }

    return ret;
}

/**
 * @brief       Release lock of PE memory
 * @details     While locked, the PE can't access internal memory. Here the memory
 *              and the memory interface will be unlocked.
 * @param[in]   pe The PE instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_pe_memlock_release_nolock(pfe_pe_t *pe)
{
    errno_t ret;
    PFE_PTR(pfe_ct_pe_misc_control_t) misc_dmem;
    pfe_ct_pe_misc_control_t misc_ctrl = {0};

    if (NULL == pe->mmap_data)
    {
        ret = ENOEXEC;
    }
    else
    {
        ret = EOK;
        misc_dmem = oal_ntohl(pe->mmap_data->common.pe_misc_control);
        if (0U == misc_dmem)
        {
            ret = EINVAL;
        }
        else
        {
            /*  Cancel the stop request */
            misc_ctrl.graceful_stop_request = 0U;

            /*  Use 'nolock' variant here. Accessing this data can't lead to conflicts. */
            pfe_pe_memcpy_from_host_to_dmem_32_nolock(
                    pe, misc_dmem, &misc_ctrl, sizeof(pfe_ct_pe_misc_control_t));
        }
    }

    return ret;
}

/**
 * @brief       Get number of cycles to load PEs with configured load ops
 * @param[in]   pe The PE instance
 * @param[in]   pe_num Number of PEs that are being loaded
 * @return      Number of cycles to load all PEs
 */
static uint8 pfe_pe_fw_load_cycles(const pfe_pe_t *pe, uint8 pe_num)
{
    uint8 ret = 1U;

    if (NULL != pe->fw_load_ops)
    {
        if(pe_num >= pe->fw_load_ops->pe_loaded_cnt)
        {
            ret = pe_num/pe->fw_load_ops->pe_loaded_cnt;
        }
    }

    return ret;
}

/**
 * @brief       Compare two PEs with regards of FW loading
 * @param[in]   pe1 The PE instance
 * @param[in]   pe2 The PE instance
 * @return      EOK on success
 */
static errno_t pfe_pe_fw_ops_valid(pfe_pe_t *pe1, const pfe_pe_t *pe2)
{
    errno_t ret = EINVAL;

    if ((pe1->type == pe2->type) &&
        (pe1->mem_access_addr == pe2->mem_access_addr) &&
        (pe1->mem_access_rdata == pe2->mem_access_rdata) &&
        (pe1->mem_access_wdata == pe2->mem_access_wdata))
    {
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       pfe_pe_fw_install_ops auxiliary function
 * @param[in]   pe The PE instance
 * @param[in]   idx index
 * @param[in]   best_pe_loader_cnt best PE loader count
 * @param[in]   pe_num Number of PEs that are being loaded
 * @return      TRUE if condition is true
 */
static inline bool_t pfe_pe_check_pe_times (pfe_pe_t *pe, uint32 idx, uint8 best_pe_loader_cnt, uint8 pe_num)
{
    bool_t ret = FALSE;

    ret = (((pe_num == fw_load_ops[idx].pe_loaded_cnt) ||
            (1U == fw_load_ops[idx].pe_loaded_cnt)) &&
           (fw_load_ops[idx].pe_loaded_cnt > best_pe_loader_cnt) &&
           (((pe[0].type == PE_TYPE_UTIL) && (fw_load_ops[idx].can_load_util == TRUE)) ||
           (pe[0].type != PE_TYPE_UTIL)));

    return ret;
}

/**
 * @brief       Get fastest possible FW load operations
 * @param[in]   pe The PE instance
 * @param[in]   pe_num Number of PEs that are being loaded
 * @return      EOK on success
 */
static errno_t pfe_pe_fw_install_ops(pfe_pe_t *pe, uint8 pe_num)
{
    errno_t ret;
    uint32 idx = 0U, pe_idx = 0U;
    uint8 best_pe_loader_cnt = 0U;
    const fw_load_ops_t* pe_loader = NULL;

    for (idx = 0U; idx < (sizeof(fw_load_ops)/sizeof(fw_load_ops[0U])); ++idx)
    {
        ret = EINVAL;
        if (pfe_pe_check_pe_times(pe, idx, best_pe_loader_cnt, pe_num))
        {
            if (1U < fw_load_ops[idx].pe_loaded_cnt)
            {
                for (pe_idx = 1U; pe_idx < pe_num; ++pe_idx)
                {
                    /* To be sure that PEs are equivalent compare them here */
                    ret = pfe_pe_fw_ops_valid(&pe[0], &pe[pe_idx]);

                    if (EOK != ret)
                    {
                        NXP_LOG_ERROR("PEs are not identical\n");
                        break;
                    }
                }

                if (EOK == ret)
                {
                    best_pe_loader_cnt = fw_load_ops[idx].pe_loaded_cnt;
                    pe_loader = &fw_load_ops[idx];
                }
            }
            else
            {
                best_pe_loader_cnt = fw_load_ops[idx].pe_loaded_cnt;
                pe_loader = &fw_load_ops[idx];
            }
        }
    }

    ret = ENODEV;
    for (pe_idx = 0U; pe_idx < pe_num; ++pe_idx)
    {
        pe[pe_idx].fw_load_ops = pe_loader;
    }

    if(NULL != pe_loader)
    {
        ret = EOK;
        NXP_LOG_INFO("Selected FW loading OPs to load %d PEs in parallel\n", pe_loader->pe_loaded_cnt);
    }

    return ret;
}

/**
 * @brief       Memcpy FW data to PEs
 * @warning     This is supposed to be called only during initial FW loading.
 *              Expectation is that everything is 4B aligned and size is divisible by 4.
 *              This function loads 8 PEs at the same time.
 * @param[in]   pe The PE instance
 * @param[in]   mem Memory type
 * @param[in]   dst_addr Destination PE address
 * @param[in]   src_ptr Source host address
 * @param[in]   len Copied length
 */
static void pfe_pe_fw_memcpy_bulk(pfe_pe_t *pe, pfe_pe_mem_t mem, addr_t dst_addr, const void *src_ptr, uint32 len)
{
    uint32 addr_temp;
    uint32 *data = (uint32*)src_ptr;
    uint32 memsel;

    if (PFE_PE_DMEM == mem)
    {
        memsel = PE_IBUS_ACCESS_DMEM;
    }
    else
    {
        memsel = PE_IBUS_ACCESS_IMEM;
    }

    /*  Sanity check if we can safely access the memory interface */
    if (unlikely(!(*(pe->miflock))))
    {
        NXP_LOG_ERROR("Accessing unlocked PE memory interface (write).\n");
    }

    addr_temp = PE_IBUS_WRITE | memsel | PE_IBUS_WREN(0xf);

    /*
     * IF we use gray code order in the unroll we will save very large number of instructions
     *  So optimal order is
     *  0 -> 1 -> 3 -> 2 -> 6 -> 7 -> 5 -> 4
     */

    for (uint32 mem_offs = 0U; mem_offs < len; mem_offs += 4U)
    {
        const addr_t mem_addr = ADDR_BASE_OFFSET(dst_addr, mem_offs);
        hal_write32(oal_htonl(data[mem_offs / 4U]), pe->mem_access_wdata);
        /* Just do un-rool manually to save time */
        addr_temp &= (0xff060000U);
        addr_temp |= mem_addr;
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 21U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp &= ~((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 22U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp &= ~((uint32)1U << 21U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp &= ~((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
    }
}

/**
 * @brief       Memset PEs memory
 * @warning     This is supposed to be called only during initial FW loading.
 *              Expectation is that everything is 4B aligned and size is divisible by 4.
 *              This function loads 8 PEs at the same time.
 * @param[in]   pe The PE instance
 * @param[in]   mem Memory type
 * @param[in]   val Value to set the memory
 * @param[in]   addr Destination PE address
 * @param[in]   size Copied length
 */
static void pfe_pe_fw_memset_bulk(pfe_pe_t *pe, pfe_pe_mem_t mem, uint32 val, addr_t addr, uint32 size)
{
    uint32 addr_temp;
    uint32 memsel;

    if (PFE_PE_DMEM == mem)
    {
        memsel = PE_IBUS_ACCESS_DMEM;
    }
    else
    {
        memsel = PE_IBUS_ACCESS_IMEM;
    }

    /*  Sanity check if we can safely access the memory interface */
    if (unlikely(!(*(pe->miflock))))
    {
        NXP_LOG_ERROR("Accessing unlocked PE memory interface (write).\n");
    }

    hal_write32(oal_htonl(val), pe->mem_access_wdata);

    addr_temp = PE_IBUS_WRITE | memsel | PE_IBUS_WREN(0xf);

    /*
     * IF we use gray code order in the unroll we will save very large number of instructions
     *  So optimal order is
     *  0 -> 1 -> 3 -> 2 -> 6 -> 7 -> 5 -> 4
     */

    for (uint32 mem_offs = 0U; mem_offs < size; mem_offs += 4U)
    {
        const addr_t mem_addr = ADDR_BASE_OFFSET(addr, mem_offs);
        /* Just do un-rool to save time manually to save time */
        addr_temp &= (0xff060000U);
        addr_temp |= mem_addr;
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 21U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp &= ~((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 22U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp |= ((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp &= ~((uint32)1U << 21U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
        addr_temp &= ~((uint32)1U << 20U);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
    }
}

/**
 * @brief       Memset PEs memory
 * @warning     This is supposed to be called only during initial FW loading.
 *              Expectation is that everything is 4B aligned and size is divisible by 4.
 *              This function can load single PE only.
 * @param[in]   pe The PE instance
 * @param[in]   mem Memory type
 * @param[in]   dst_addr Destination PE address
 * @param[in]   src_ptr Source host address
 * @param[in]   len Copied length
 */
static void pfe_pe_fw_memcpy_single(pfe_pe_t *pe, pfe_pe_mem_t mem, addr_t dst_addr, const void *src_ptr, uint32 len)
{
    uint32 addr_temp;
    uint32 *data = (uint32*)src_ptr;
    uint32 memsel;

    if (PFE_PE_DMEM == mem)
    {
        memsel = PE_IBUS_ACCESS_DMEM;
    }
    else
    {
        memsel = PE_IBUS_ACCESS_IMEM;
    }

    /*  Sanity check if we can safely access the memory interface */
    if (unlikely(!(*(pe->miflock))))
    {
        NXP_LOG_ERROR("Accessing unlocked PE memory interface (write).\n");
    }

    addr_temp = PE_IBUS_WRITE | memsel | PE_IBUS_WREN(0xf) | PE_IBUS_PE_ID(pe->id);

    for (uint32 mem_offs = 0U; mem_offs < len; mem_offs += 4U)
    {
        const addr_t mem_addr = ADDR_BASE_OFFSET(dst_addr, mem_offs);
        hal_write32(oal_htonl(data[mem_offs / 4U]), pe->mem_access_wdata);
        addr_temp &= (0xfff60000U);
        addr_temp |= mem_addr;
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
    }
}

/**
 * @brief       Memset PEs memory
 * @warning     This is supposed to be called only during initial FW loading.
 *              Expectation is that everything is 4B aligned and size is divisible by 4.
 *              This function can load single PE only.
 * @param[in]   pe The PE instance
 * @param[in]   mem Memory type
 * @param[in]   val Value to set the memory
 * @param[in]   addr Destination PE address
 * @param[in]   size Copied length
 */
static void pfe_pe_fw_memset_single(pfe_pe_t *pe, pfe_pe_mem_t mem, uint32 val, addr_t addr, uint32 size)
{
    uint32 addr_temp;
    uint32 memsel;

    if (PFE_PE_DMEM == mem)
    {
        memsel = PE_IBUS_ACCESS_DMEM;
    }
    else
    {
        memsel = PE_IBUS_ACCESS_IMEM;
    }

    /*  Sanity check if we can safely access the memory interface */
    if (unlikely(!(*(pe->miflock))))
    {
        NXP_LOG_ERROR("Accessing unlocked PE memory interface (write).\n");
    }

    hal_write32(oal_htonl(val), pe->mem_access_wdata);

    addr_temp = PE_IBUS_WRITE | memsel | PE_IBUS_WREN(0xf) | PE_IBUS_PE_ID(pe->id);

    /* We could potentially do some manual unroll here */
    for (uint32 mem_offs = 0U; mem_offs < size; mem_offs += 4U)
    {
        const addr_t mem_addr = ADDR_BASE_OFFSET(addr, mem_offs);
        addr_temp &= (0xfff60000U);
        addr_temp |= mem_addr;
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
    }
}

/**
 * @brief       Read data from PE memory
 * @param[in]   pe The PE instance
 * @param[in]   mem Memory to access
 * @param[in]   addr Read address (should be aligned to 32 bits)
 * @param[in]   size Number of bytes to read (maximum 4)
 * @return      The data read (BE).
 */
static uint32 pfe_pe_mem_read(pfe_pe_t *pe, pfe_pe_mem_t mem, addr_t addr, uint8 size)
{
    uint32 val;
    uint32 mask;
    uint32 memsel;
    uint8 size_temp = size;
    addr_t adrr_temp = addr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        val = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (size_temp != 4U)
        {
            mask = ((uint32)1U << (size_temp * 8U)) - 1U;
        }
        else
        {
            mask = 0xffffffffU;
        }

        if (PFE_PE_DMEM == mem)
        {
            memsel = PE_IBUS_ACCESS_DMEM;
        }
        else
        {
            memsel = PE_IBUS_ACCESS_IMEM;
        }

        adrr_temp = (adrr_temp & 0xfffffU)
                    | PE_IBUS_READ
                    | memsel
                    | PE_IBUS_PE_ID(pe->id)
                    | PE_IBUS_WREN(0U);

        /*  Sanity check if we can safely access the memory interface */
        if (unlikely(!(*(pe->miflock))))
        {
            NXP_LOG_ERROR("Accessing unlocked PE memory interface (read).\n");
        }

        hal_write32((uint32)adrr_temp, pe->mem_access_addr);
        val = oal_ntohl(hal_read32(pe->mem_access_rdata));

        if (unlikely(adrr_temp & 0x3U))
        {
            /*  Move the value to the desired address offset */
            val = (val >> (8U * (adrr_temp & 0x3U)));
        }
        val = val & mask;
    }

    return val;
}

/**
 * @brief       Write data into PE memory
 * @param[in]   pe The PE instance
 * @param[in]   memdata Parameters of the memory to access
 */
static void pfe_pe_mem_write(pfe_pe_t *pe, pfe_pe_mem_data_t memdata)
{
    uint8 bytesel = 0U;
    uint32 memsel = 0U;
    uint8 offset_temp = memdata.offset;
    uint32 val_temp = memdata.val;
    uint8 size_temp = memdata.size;
    addr_t addr_temp = memdata.addr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (unlikely((0U != offset_temp)))
        {
            PfeDevAssert(offset_temp >= size_temp);
            PfeDevAssert(offset_temp <= 3U);
            /* Move the value to the desired address offset */
            val_temp = memdata.val << (8U * (addr_temp & ALIGNMENT_CHECKMASK));
            /* Enable writes of depicted bytes */
            bytesel = (uint8)((1U << (offset_temp - size_temp)) & UINT8_MAX);
        }
        else
        {
            PfeDevAssert(size_temp <= 4U);
            /*  Destination is aligned */
            bytesel = (uint8)(PE_IBUS_BYTES(size_temp) & UINT8_MAX);
        }

        if (PFE_PE_DMEM == memdata.mem)
        {
            memsel = PE_IBUS_ACCESS_DMEM;
        }
        else
        {
            memsel = PE_IBUS_ACCESS_IMEM;
        }

        addr_temp = (addr_temp & 0xfffffU)
                | PE_IBUS_WRITE
                | memsel
                | PE_IBUS_PE_ID(pe->id)
                | PE_IBUS_WREN(bytesel);

        /*  Sanity check if we can safely access the memory interface */
        if (unlikely(!(*(pe->miflock))))
        {
            NXP_LOG_ERROR("Accessing unlocked PE memory interface (write).\n");
        }

        hal_write32(oal_htonl(val_temp), pe->mem_access_wdata);
        hal_write32((uint32)addr_temp, pe->mem_access_addr);
    }
}

/**
 * @brief       Read 'len' limited upto 4 bytes to uint32 val
 * @note        Function expects the source data to be in host endian format
 *              and reads only required number of bytes to avoid out-of-bound issues
 * @param[in]   src_byteptr Buffer source address (virtual)
 * @param[in]   len Number of bytes to read
 * @return      The data read (LE).
 */
static inline uint32 pfe_pe_get_u32_from_byteptr(const uint8 *src_byteptr, uint32 len)
{
    uint32 val;

    switch (len)
    {
        case 1:
            val = *src_byteptr;
            break;
        case 2:
            val = *(uint16 *)src_byteptr;
            break;
        case 3:
            val = *(uint16 *)src_byteptr;
            val += ((uint32)*(src_byteptr + 2U)) << 16U;
            break;
        default:
            val = *(uint32 *)src_byteptr;
            break;
    }

    return val;
}

/**
 * @brief       Write 'len' bytes to DMEM
 * @note        Function expects the source data to be in host endian format.
 * @param[in]   pe The PE instance
 * @param[in]   src_ptr Buffer source address (virtual)
 * @param[in]   dst_addr DMEM destination address (must be 32-bit aligned)
 * @param[in]   len Number of bytes to read
 */
static void pfe_pe_memcpy_from_host_to_dmem_32_nolock(
        pfe_pe_t *pe, addr_t dst_addr, const void *src_ptr, uint32 len)
{
    /* Avoid void pointer arithmetics */
    const uint8 *src_byteptr = src_ptr;
    uint32 len_temp = len;
    pfe_pe_mem_data_t mem_data = {.mem = PFE_PE_DMEM, .addr = dst_addr, .val = 0, .offset = 0, .size = 0 };

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* First loop is for the unaligned dst_addr */
        /* It fills the offset with one by one byte taken from src_ptr */
        while ((0U != (mem_data.addr & ALIGNMENT_CHECKMASK)) && (0U != len_temp))
        {
            mem_data.offset = BYTES_TO_4B_ALIGNMENT(mem_data.addr);
            mem_data.val = *src_byteptr;
            mem_data.size = 1U;
            pfe_pe_mem_write(pe, mem_data);
            mem_data.addr += 1U;
            src_byteptr += 1U;
            len_temp -= 1U;
        }
        /* Second loops if to write the data with 4 bytes each time to the aligned address */
        while (ALIGNMENT_PACKEDNUMBER <= len_temp)
        {
            /*  4-byte writes */
            mem_data.offset = 0U;
            mem_data.val = *(uint32 *)src_byteptr;
            mem_data.size = 4U;
            pfe_pe_mem_write(pe, mem_data);
            len_temp -= 4U;
            src_byteptr += 4U;
            mem_data.addr += 4U;
        }
        /* The last step is to write the trailing last data to the aligned address */
        if (0U != len_temp)
        {
            /*  The rest */
            mem_data.offset = 0U;
            mem_data.val = pfe_pe_get_u32_from_byteptr(src_byteptr, len_temp);
            mem_data.size = len_temp;
            pfe_pe_mem_write(pe, mem_data);
        }
    }
}

/**
 * @brief       Write 'len' bytes to DMEM
 * @note        Function expects the source data to be in host endian format.
 * @param[in]   pe The PE instance
 * @param[in]   src_ptr Buffer source address (virtual)
 * @param[in]   dst_addr DMEM destination address (must be 32-bit aligned)
 * @param[in]   len Number of bytes to read
 */
void pfe_pe_memcpy_from_host_to_dmem_32(pfe_pe_t *pe, addr_t dst_addr, const void *src_ptr, uint32 len)
{
    errno_t ret;

    /* Lock family */
    if (PE_TYPE_CLASS == pe->type)
    {
        oal_mutex_lock(PFE_CLASS_PE_MUTEX_00);
    }
    else
    {
        oal_mutex_lock(PFE_UTIL_PE_MUTEX_00);
    }
    pfe_pe_lock_family(pe);

    /* Acquire memlock for all PE cores. They will stop processing frames and wait.
       This will ensure data coherence. */
    ret = pfe_pe_memlock_acquire_nolock(pe);
    if (EOK != ret)
    {
        NXP_LOG_DEBUG("Memory lock failed\n");
    }
    else
    {
        pfe_pe_memcpy_from_host_to_dmem_32_nolock(pe, dst_addr, src_ptr, len);

        if (EOK != pfe_pe_memlock_release_nolock(pe))
        {
            NXP_LOG_DEBUG("Memory unlock failed\n");
        }
    }
    /* Unlock family */
    pfe_pe_unlock_family(pe);
    if (PE_TYPE_CLASS == pe->type)
    {
        oal_mutex_unlock(PFE_CLASS_PE_MUTEX_00);
    }
    else
    {
        oal_mutex_unlock(PFE_UTIL_PE_MUTEX_00);
    }
}

/**
 * @brief       Read 'len' bytes from DMEM
 * @param[in]   pe The PE instance
 * @param[in]   src_addr DMEM source address (must be 32-bit aligned)
 * @param[in]   dst_ptr Destination address (virtual)
 * @param[in]   len Number of bytes to read
 *
 */
void pfe_pe_memcpy_from_dmem_to_host_32_nolock(pfe_pe_t *pe, void *dst_ptr, addr_t src_addr, uint32 len)
{
    uint32 val;
    /* Avoid void pointer arithmetics */
    uint8 *dst_byteptr = dst_ptr;
    addr_t src_temp = src_addr;
    uint32 len_temp = len;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* First loop, read each byte until the src_temp is aligned with four */
        while ((0U != (src_temp & ALIGNMENT_CHECKMASK)) && (0U != len_temp))
        {
            /*  Read unaligned bytes to align the source address */
            val = pfe_pe_mem_read(pe, PFE_PE_DMEM, (uint32)src_temp, 1U);
            (void)autolibc_memcpy((void*)dst_byteptr, (const void*)&val, 1U);
            dst_byteptr += 1U;
            src_temp += 1U;
            len_temp -= 1U;
        }

        /* Second loop, read four bytes each time until the length of the data is under four */
        while (ALIGNMENT_PACKEDNUMBER <= len_temp)
        {
            /*  4-byte reads */
            val = pfe_pe_mem_read(pe, PFE_PE_DMEM, (uint32)src_temp, 4U);
            *((uint32 *)dst_byteptr) = val;
            len_temp-=4U;
            src_temp+=4U;
            dst_byteptr+=4U;
        }

        /* The last step, read the trailing last bytes of the data length */
        if (0U != len_temp)
        {
            /*  The rest */
            val = pfe_pe_mem_read(pe, PFE_PE_DMEM, (uint32)src_temp, (uint8)len_temp);
            (void)autolibc_memcpy((void*)dst_byteptr, (const void*)&val, len_temp);
        }
    }
}

/**
 * @brief       Read 'len' bytes from DMEM
 * @param[in]   pe The PE instance
 * @param[in]   src_addr DMEM source address (must be 32-bit aligned)
 * @param[in]   dst_ptr Destination address (virtual)
 * @param[in]   len Number of bytes to read
 *
 */
void pfe_pe_memcpy_from_dmem_to_host_32(pfe_pe_t *pe, void *dst_ptr, addr_t src_addr, uint32 len)
{
    errno_t ret;

    /* Lock family */
    if (PE_TYPE_CLASS == pe->type)
    {
        oal_mutex_lock(PFE_CLASS_PE_MUTEX_01);
    }
    else
    {
        oal_mutex_lock(PFE_UTIL_PE_MUTEX_01);
    }
    pfe_pe_lock_family(pe);

    /* Acquire memlock for all PE cores. They will stop processing frames and wait.
       This will ensure data coherence. */
    ret = pfe_pe_memlock_acquire_nolock(pe);
    if (EOK != ret)
    {
        NXP_LOG_DEBUG("Memory lock failed\n");
    }
    else
    {
        pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, dst_ptr, src_addr, len);

        if (EOK != pfe_pe_memlock_release_nolock(pe))
        {
            NXP_LOG_DEBUG("Memory unlock failed\n");
        }
    }
    /* Unlock family */
    pfe_pe_unlock_family(pe);
    if (PE_TYPE_CLASS == pe->type)
    {
        oal_mutex_unlock(PFE_CLASS_PE_MUTEX_01);
    }
    else
    {
        oal_mutex_unlock(PFE_UTIL_PE_MUTEX_01);
    }
}

/**
 * @brief       Read 'len' bytes from DMEM from each PE
 * @details     Reads PE internal data memory (DMEM) into a host memory through indirect
 *              access registers. The result from each PE are stored consecutively in memory
 *              pointed by dst.
 * @param[in]   pe Array of the PE instances
 * @param[in]   src_addr DMEM source address (physical within PE, must be 32bit aligned)
 * @param[in]   dst_ptr Destination address (virtual) the size required to store the data is pe_count*len
 * @param[in]   buffer_len Destination buffer length
 * @param[in]   read_len Number of bytes to read (from one PE)
 *
 */
errno_t pfe_pe_gather_memcpy_from_dmem_to_host_32(pfe_pe_t *pe, sint32 pe_count, void *dst_ptr, addr_t src_addr, uint32 buffer_len, uint32 read_len)
{
    sint32 ii = 0U;
    boolean is_mem_lock_error = FALSE;
    errno_t ret = EOK;
    errno_t ret_store = EOK;

    /* Lock family */
    /* NOTE: Use the mutex lock for CLASS PE here because the pfe_pe_gather_memcpy_from_dmem_to_host_32() is only called from CLASS FW */
    oal_mutex_lock(PFE_CLASS_PE_MUTEX_06);
    pfe_pe_lock_family(pe);

    /* Acquire memlock for all PE cores. They will stop processing frames and wait.
       This will ensure data coherence. */
    for (ii = 0; ii < pe_count; ii++)
    {
        ret = pfe_pe_memlock_acquire_nolock(&pe[ii]);
        if (EOK != ret)
        {
            is_mem_lock_error = TRUE;
            NXP_LOG_ERROR("Memory lock failed for PE instance %d\n", (int_t)ii);
            /* Save the error */
            ret_store = ret;
        }
    }

    /* Only read from PEs if all PEs are locked */
    if (is_mem_lock_error == FALSE)
    {
        /* Perform the read from required PEs */
        for (ii = 0; ii < pe_count; ii++)
        {
            /* Check if there is still memory  */
            if (buffer_len >= ((read_len * (uint32)ii) + read_len))
            {
                pfe_pe_memcpy_from_dmem_to_host_32_nolock(&pe[ii],
                        (void *)((uint8*)dst_ptr + (read_len * (uint32)ii)),
                            src_addr, read_len);
            }
            else
            {
                /* Memory limit reached. Save the error. */
                ret_store = ENOMEM;
                break;
            }
        }
    }

    /* Release memlock for all PE cores */
    for (ii = 0; ii < pe_count; ii++)
    {
        ret = pfe_pe_memlock_release_nolock(&pe[ii]);
        if(EOK != ret)
        {
            NXP_LOG_ERROR("Memory unlock failed\n");
            /* Save the error */
            ret_store = ret;
        }
    }

    /* If there was any error during the whole process, then return it. */
    ret = ret_store;

    /* Unlock family */
    pfe_pe_unlock_family(pe);
    oal_mutex_unlock(PFE_CLASS_PE_MUTEX_06);

    return ret;
}

/**
 * @brief       Load an elf section into DMEM
 * @details     Size and load address need to be at least 32-bit aligned
 * @param[in]   pe The PE instance
 * @param[in]   sdata Pointer to the elf section data
 * @param[in]   addr Load address of the section
 * @param[in]   size Size of the section
 * @param[in]   type Section type
 * @retval      EOK Success
 * @retval      EINVAL Unsupported section type or wrong input address alignment
 */
static errno_t pfe_pe_load_dmem_section_nolock(pfe_pe_t *pe, const void *sdata, addr_t addr, addr_t size, uint32 type)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == sdata)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
    {
#endif /* PFE_CFG_NULL_ARG_CHECK */

    if (((addr_t)(sdata) & 0x3U) != (addr & 0x3U))
    {
        NXP_LOG_ERROR("Load address 0x%p and elf file address 0x%p don't have the same alignment\n", (void *)addr, sdata);
        ret = EINVAL;
    }
    else
    {
        if ((addr & 0x3U) != 0U)
        {
            NXP_LOG_ERROR("Load address 0x%p is not 32bit aligned\n", (void *)addr);
            ret = EINVAL;
        }
        else
        {
            switch (type)
            {
                case 0x7000002aU: /* MIPS.abiflags */
                {
                    /* Skip the section */
                    break;
                }
                case (uint32)SHT_PROGBITS:
                {
                    /*  Write section data */
                    pe->fw_load_ops->pe_memcpy(pe, PFE_PE_DMEM, OFFSET_ADDR_BASE(addr, pe->dmem_elf_base_va), sdata, size);
                    break;
                }

                case (uint32)SHT_NOBITS:
                {
                    pe->fw_load_ops->pe_memset(pe, PFE_PE_DMEM, 0U, addr, size);
                    break;
                }

                default:
                {
                    NXP_LOG_ERROR("Unsupported section type: 0x%x\n", (uint_t)type);
                    ret = EINVAL;
                    break;
                }
            }
        }
    }
#if defined(PFE_CFG_NULL_ARG_CHECK)
    }
#endif

    return ret;
}

/**
 * @brief       Load an elf section into IMEM
 * @details     Code needs to be at least 16bit aligned and only PROGBITS sections are supported
 * @param[in]   pe The PE instance
 * @param[in]   data Pointer to the elf section data
 * @param[in]   addr Load address of the section
 * @param[in]   size Size of the section
 * @param[in]   type Type of the section
 * @retval      EOK Success
 * @retval      EFAULT Wrong input address alignment
 * @retval      EINVAL Unsupported section type
 */
static errno_t pfe_pe_load_imem_section_nolock(pfe_pe_t *pe, const void *data, addr_t addr, addr_t size, uint32 type)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == data)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = EOK;
        /*  Check alignment first */
        if (((addr_t)(data) & 0x3U) != (addr & 0x1U))
        {
            NXP_LOG_ERROR("Load address 0x%p and elf file address 0x%p) don't have the same alignment\n",
                    (void *)addr, data);
            ret = EFAULT;
        }
        else if ((addr & 0x1U) != 0U)
        {
            NXP_LOG_ERROR("Load address 0x%p is not 16bit aligned\n", (void *)addr);
            ret = EFAULT;
        }
        else if ((size & 0x1U) != 0U)
        {
            NXP_LOG_ERROR("Load size 0x%p is not 16bit aligned\n", (void *)size);
            ret = EFAULT;
        }
        else
        {
            switch (type)
            {
                case 0x7000002aU: /* MIPS.abiflags */
                {
                    /* Skip the section */
                    break;
                }
                case (uint32)SHT_PROGBITS:
                {
                    /*  Write section data */
                    pe->fw_load_ops->pe_memcpy(pe, PFE_PE_IMEM, OFFSET_ADDR_BASE(addr, pe->imem_elf_base_va), data, size);
                    break;
                }

                default:
                {
                    NXP_LOG_ERROR("Unsupported section type: 0x%x\n", (uint_t)type);
                    ret = EINVAL;
                    break;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Check if memory region belongs to DMEM
 * @param[in]   pe The PE instance
 * @param[in]   addr Address to be checked
 * @param[in]   size Length of the region to be checked
 * @return      TRUE if given range belongs to DMEM
 */
static bool_t pfe_pe_is_dmem(const pfe_pe_t *pe, addr_t addr, uint32 size)
{
    addr_t reg_end;
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        reg_end = ADDR_BASE_OFFSET(pe->dmem_elf_base_va, pe->dmem_size);

        if ((addr >= pe->dmem_elf_base_va) && (ADDR_BASE_OFFSET(addr, size) < reg_end))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }
    return ret;
}

/**
 * @brief       Check if memory region belongs to IMEM
 * @param[in]   pe The PE instance
 * @param[in]   addr Address to be checked
 * @param[in]   size Length of the region to be checked
 * @return      TRUE if given range belongs to IMEM
 */
static bool_t pfe_pe_is_imem(const pfe_pe_t *pe, addr_t addr, uint32 size)
{
    addr_t reg_end;
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        reg_end = ADDR_BASE_OFFSET(pe->imem_elf_base_va, pe->imem_size);

        if ((addr >= pe->imem_elf_base_va) && (ADDR_BASE_OFFSET(addr, size) < reg_end))
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }

    return ret;
}

/**
 * @brief       Write elf section to PE memory
 * @details     Function expects the section data is in host endian format
 * @param[in]   pe The PE instance
 * @param[in]   sdata Pointer to the data described by 'shdr'
 * @param[in]   load_addr Address where to load the section
 * @param[in]   size Size of the section to load
 * @param[in]   type Type of the section to load
 */
static errno_t pfe_pe_load_elf_section(pfe_pe_t *pe, const void *sdata, addr_t load_addr, addr_t size, uint32 type)
{
    errno_t ret_val;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == sdata)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */

    if (pfe_pe_is_dmem(pe, load_addr, size))
    {
        /*  Section belongs to DMEM */
        ret_val = pfe_pe_load_dmem_section_nolock(pe, sdata, load_addr, size, type);
    }
    else if (pfe_pe_is_imem(pe, load_addr, size))
    {
        /*  Section belongs to IMEM */
        ret_val = pfe_pe_load_imem_section_nolock(pe, sdata, load_addr, size, type);
    }
    else
    {
        NXP_LOG_ERROR("Unsupported memory range %p\n", (void *)load_addr);
        ret_val = EINVAL;
    }

    return ret_val;
}

/**
 * @brief Translates section virtual address into load address
 * @param[in] elf_file Elf file containing the section to translate the address
 * @param[in] shdr Section header of the section to translate the address
 * @details Elf file section header contains only section virtual address which is used by the
 *          running software. The virtual address needs to be translated to load address which
 *          is address where the section is loaded into memory. In most cases the virtual and
 *          load address are equal.
 * @return Load address of the given section or 0 on failure.
 */
static addr_t pfe_pe_get_elf_sect_load_addr(const ELF_File_t *elf_file, const Elf32_Shdr *shdr)
{
    addr_t virt_addr = ENDIAN_SW_4B(shdr->sh_addr);
    addr_t load_addr = 0U;
    bool_t stt = FALSE;

    /* Go through all program headers to find one containing the section */
    for (uint_t ii=0U; ii<elf_file->Header.r32.e_phnum; ii++)
    {
        const Elf32_Phdr *phdr = &elf_file->arProgHead32[ii];
        if((virt_addr >= ENDIAN_SW_4B(phdr->p_vaddr)) &&
        (ADDR_BASE_OFFSET(virt_addr, ENDIAN_SW_4B(shdr->sh_size)) <= ADDR_BASE_OFFSET(ENDIAN_SW_4B(phdr->p_vaddr), ENDIAN_SW_4B(phdr->p_memsz))))
        {   /* Address belongs into this segment */
            /* Calculate the offset between segment load and virtual address */
            const uint32 offset = OFFSET_ADDR_BASE(ENDIAN_SW_4B(phdr->p_paddr), ENDIAN_SW_4B(phdr->p_vaddr));
            /* Same offset applies also for sections in the segment */
            load_addr = ADDR_BASE_OFFSET(virt_addr, offset);
            stt = TRUE;
            break;
        }
    }

    if(FALSE == stt)
    {
        /* No segment containing the section was found ! */
        NXP_LOG_ERROR("Translation of 0x%"PRINTADDR_T"x failed, fallback used\n", virt_addr);
    }

    return load_addr;
}

/**
 * @brief         Create new PE instance
 * @param[in]     cbus_base_va CBUS base address (virtual)
 * @param[in]     type Type of PE to create @see pfe_pe_type_t
 * @param[in]     id PE ID
 * @param[in,out] pe The PE instance
 * @param[in]     miflock pointer to miflock diagnostic flag of this PE core
 * @return        The PE instance or NULL if failed
 */
pfe_pe_t * pfe_pe_create(addr_t cbus_base_va, pfe_ct_pe_type_t type, uint8 id, pfe_pe_t *pe, bool_t *miflock)
{
    pfe_pe_t *tmp_pe = pe;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_ADDR == cbus_base_va) || (NULL == pe) || (NULL == miflock)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        tmp_pe = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((type != PE_TYPE_INVALID) && (type < PE_TYPE_MAX))
        {
            (void)autolibc_memset(tmp_pe, 0, sizeof(pfe_pe_t));
            tmp_pe->type = type;
            tmp_pe->cbus_base_va = cbus_base_va;
            tmp_pe->id = id;
            tmp_pe->fw_msg_section = NULL;
            tmp_pe->mmap_data = NULL;
            tmp_pe->miflock = miflock;
        }
    }

    return tmp_pe;
}

/**
 * @brief       Set DMEM base address for .elf mapping
 * @warning     Not intended to be called when PE is running
 * @param[in]   pe The PE instance
 * @param[in]   elf_base DMEM base virtual address within .elf
 * @param[in]   len DMEM memory length
 */
void pfe_pe_set_dmem(pfe_pe_t *pe, addr_t elf_base, addr_t len)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pe->dmem_elf_base_va = elf_base;
        pe->dmem_size = len;
    }
}

/**
 * @brief       Set IMEM base address for .elf mapping
 * @warning     Not intended to be called when PE is running
 * @param[in]   pe The PE instance
 * @param[in]   elf_base_va IMEM base virtual address within .elf
 * @param[in]   len IMEM memory length
 */
void pfe_pe_set_imem(pfe_pe_t *pe, addr_t elf_base, addr_t len)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pe->imem_elf_base_va = elf_base;
        pe->imem_size = len;
    }
}

/**
 * @brief       Set LMEM base address
 * @param[in]   pe The PE instance
 * @param[in]   elf_base_va LMEM base virtual address within .elf
 * @param[in]   len LMEM memory length
 */
void pfe_pe_set_lmem(pfe_pe_t *pe, addr_t elf_base, addr_t len)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pe->lmem_base_addr_pa = elf_base;
        pe->lmem_size = len;
    }
}

/**
 * @brief       Set indirect access registers
 * @param[in]   pe The PE instance
 * @param[in]   wdata_reg The WDATA register address as appears on CBUS
 * @param[in]   rdata_reg The RDATA register address as appears on CBUS
 * @param[in]   addr_reg The ADDR register address as appears on CBUS
 */
void pfe_pe_set_iaccess(pfe_pe_t *pe, uint32 wdata_reg, uint32 rdata_reg, uint32 addr_reg)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pe->mem_access_addr =  ADDR_BASE_OFFSET(pe->cbus_base_va, addr_reg);
        pe->mem_access_rdata = ADDR_BASE_OFFSET(pe->cbus_base_va, rdata_reg);
        pe->mem_access_wdata = ADDR_BASE_OFFSET(pe->cbus_base_va, wdata_reg);
    }
}

/*print firmware issues*/
static void print_fw_issue(const pfe_ct_pe_mmap_t *fw_mmap)
{
#ifdef NXP_LOG_ENABLED
    NXP_LOG_ERROR("Unsupported firmware detected: Found revision %d.%d.%d (fwAPI:%s), required fwAPI %s\n",
            fw_mmap->common.version.major, fw_mmap->common.version.minor, fw_mmap->common.version.patch, fw_mmap->common.version.cthdr,
            TOSTRING(PFE_CFG_PFE_CT_H_MD5));
#else
    (void)fw_mmap;
#endif
}

/**
 * @brief       Default Init PEs memory when no Firmware to load
 *              This is to avoid in case firmware class/util intenional no need to load
 *              PFs memory still need to be intialize properly to avoid FCC related errors
 * @param[in]   pe The PE instances
 * @param[in]   pe_num Number of PE instances
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_pe_mem_default_init(pfe_pe_t *pe, uint32 pe_num)
{
    uint32 pe_idx;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Lock family */
        /* NOTE: Use the mutex lock for UTIL PE here because the pfe_pe_mem_default_init() is only called from UTIL FW */
        oal_mutex_lock(PFE_UTIL_PE_MUTEX_03);
        pfe_pe_lock_family(pe);

        ret =  pfe_pe_fw_install_ops(pe, (uint8)(pe_num & UINT8_MAX));
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Couldn't find PE load operations: %d\n", ret);
        }

        for (pe_idx = 0; pe_idx < pfe_pe_fw_load_cycles(&pe[0], (uint8)(pe_num & UINT8_MAX)); ++pe_idx)
        {
            /* Check that we have the ops */
            if(NULL == pe[pe_idx].fw_load_ops)
            {
                ret = ENODEV;
            }

            pe[pe_idx].fw_load_ops->pe_memset(&pe[pe_idx], PFE_PE_DMEM, 0, 0, pe[pe_idx].dmem_size);
            pe[pe_idx].fw_load_ops->pe_memset(&pe[pe_idx], PFE_PE_IMEM, 0, 0, pe[pe_idx].imem_size);
        }

        /* Unlock family */
        pfe_pe_unlock_family(pe);
        oal_mutex_unlock(PFE_UTIL_PE_MUTEX_03);
    }

    return ret;
}
/**
 * @brief       Auxiliary of pfe_pe_load_firmware function
 * @param[in]   pe The PE instances
 * @param[in]   pe_num Number of PE instances
 * @param[in]   elf The elf file object to be uploaded
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_pe_load_firmware_aux(pfe_pe_t *pe, uint32 pe_num, const void *elf)
{
    errno_t ret = EOK;
    uint32 section_idx = 0U;
    uint32 ii, mask_sectIdx;
    uint32 features_size = 0, messages_size = 0;
    void *features_mem = NULL, *messages_mem = NULL;
    const Elf32_Shdr *shdr = NULL;
    bool_t bFwVersionMatch = TRUE;
    bool_t bElfBigEndian = TRUE;
    uint32 mmap_size = 0U;
    const ELF_File_t *elf_file = (ELF_File_t *)elf;

    /*  Attempt to get section containing firmware memory map data */
    if (TRUE == ELF_SectFindName(elf_file, ".pfe_pe_mmap", &section_idx, NULL, NULL))
    {
        /* Mask out the flag to get section id */
        mask_sectIdx = (~(ELF_NAMED_SECT_IDX_FLAG) & section_idx);

        /*  Load section to RAM */
        shdr = &elf_file->arSectHead32[mask_sectIdx];

        /* Get the mmap size, used to load correct data from FW file*/
        (void)autolibc_memcpy(
                (void*)&mmap_size,
                (const void*)((addr_t)elf_file->pvData + ENDIAN_SW_4B(shdr->sh_offset)),
                sizeof(uint32));

        /* Convert mmap size endian ! */
        mmap_size = oal_ntohl(mmap_size);

        /*  Firmware version check */
        static const char_t mmap_version_str[] = TOSTRING(PFE_CFG_PFE_CT_H_MD5);

        (void)autolibc_memcpy(
                (void*)&tmp_mmap,
                (const void*)((addr_t)elf_file->pvData + ENDIAN_SW_4B(shdr->sh_offset)),
                mmap_size);

        if(0 != autolibc_strcmp(mmap_version_str, tmp_mmap.common.version.cthdr))
        {
            bFwVersionMatch = FALSE;
            ret = EINVAL;
            print_fw_issue(&tmp_mmap);
            pfe_pe_free_mem(pe, pe_num);
        }
        else
        {
            NXP_LOG_INFO("pfe_ct.h file version\"%s\"\n", mmap_version_str);
        }
    }
    else
    {
        NXP_LOG_WARNING("Section not found (.pfe_pe_mmap). Memory map will not be available.\n");
    }

    if (TRUE == bFwVersionMatch)
    {
        /* Copy requested firmware sections */
        ret = pfe_pe_copy_firmware_sections(elf_file, &features_size, &messages_size);
        if (EOK == ret)
        {
            features_mem = &tmp_features;
            messages_mem = &tmp_messages;
            /*  .elf data must be in BIG ENDIAN */
            if (1U == elf_file->Header.e_ident[EI_DATA])
            {
                NXP_LOG_DEBUG("Unexpected .elf format (little endian)\n");
                bElfBigEndian = FALSE;
                ret = EINVAL;
                pfe_pe_free_mem(pe, pe_num);
            }

            if (TRUE == bElfBigEndian)
            {
                /*  Try to upload all sections of the .elf */
                ret = pfe_pe_upload_sections(pe, pe_num, elf_file);
                if (EOK == ret)
                {
                    for (ii = 0; ii < pe_num; ++ii)
                    {
                        /*  Indicate that mmap_data is available */
                        pe[ii].mmap_data = &tmp_mmap;

                        pe[ii].fw_msg_section_size = messages_size;
                        /*  Indicate that fw_msg_section is available */
                        pe[ii].fw_msg_section = messages_mem;

                        pe[ii].fw_feature_section_size = features_size;

                        /*  Indicate that fw_feature_section is available */
                        pe[ii].fw_feature_section = features_mem;
                        pe[ii].fw_features_base = INVALID_FEATURES_BASE; /* Invalid value */

                        /* Clear the internal copy of the index on each FW load because
                        FW will also start from 0 */
                        pe[ii].last_message_write_index = 0U;
                        pe[ii].message_record_addr = 0U;
                    }
                }
            }
        }
    }
    return ret;
}

/**
 * @brief       Auxiliary function to copy requested sectrions from fw elf file
 * @param[in]   elf_file The elf file object to be sections coppied from
 * @param[out]   features_size pointer to uint32 to return readed features section size
 * @param[out]   messages_size pointer to uint32 to return readed messages section size
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_pe_copy_firmware_sections(const ELF_File_t *elf_file, uint32 * features_size, uint32 * messages_size)
{
    errno_t ret = EOK;
    uint32 section_idx = 0U;
    uint32 mask_sectIdx;
    const Elf32_Shdr *shdr = NULL;    
    void *features_mem = NULL, *messages_mem = NULL;

     /*  Attempt to get section containing firmware diagnostic data */
    if (TRUE == ELF_SectFindName(elf_file, ".messages", &section_idx, NULL, NULL))
    {
        /* Mask out the flag to get section id */
        mask_sectIdx = (~(ELF_NAMED_SECT_IDX_FLAG)&section_idx);

        /*  Load section to RAM */
        shdr = &elf_file->arSectHead32[mask_sectIdx];
        messages_mem = (uint8 *)elf_file->pvData + ENDIAN_SW_4B(shdr->sh_offset);
        *messages_size = ENDIAN_SW_4B(shdr->sh_size);
        if (*messages_size <= ETH_43_PFE_MESSAGES_SECTION_BUFF_SIZE)
        {
            /* Copy section data to RAM from FW file */
            (void)autolibc_memcpy(
                (void *)&tmp_messages,
                (const void *)messages_mem,
                *messages_size);
        }
        else
        {
            NXP_LOG_ERROR("Not enougth memory to copy FW section .messages. Increase option FwMessagesBufferSize to at least %u.\n", (uint_t) *messages_size);
            *messages_size = 0;
            ret = EINVAL;
        }
    }
    else
    {
        NXP_LOG_WARNING("Section not found (.messages). FW error reporting will not be available.\n");
        ret = EINVAL;
    }
    /*  Attempt to get section containing firmware supported features */
    if (TRUE == ELF_SectFindName(elf_file, ".features", &section_idx, NULL, NULL))
    {
        /* Mask out the flag to get section id */
        mask_sectIdx = (~(ELF_NAMED_SECT_IDX_FLAG)&section_idx);

        /*  Load section to RAM */
        shdr = &elf_file->arSectHead32[mask_sectIdx];
        features_mem = (void *)((addr_t)elf_file->pvData + ENDIAN_SW_4B(shdr->sh_offset));
        *features_size = ENDIAN_SW_4B(shdr->sh_size);
        if (*features_size <= ETH_43_PFE_FEATURES_SECTION_BUFF_SIZE)
        {
            /* Copy section data to RAM from FW file */
            (void)autolibc_memcpy(
                (void *)&tmp_features,
                (const void *)features_mem,
                *features_size);
        }
        else
        {
            NXP_LOG_ERROR("Not enougth memory to copy FW section .features. Increase option FwFeaturesBufferSize to at least %u.\n", (uint_t)*features_size);
            *features_size = 0;
            ret = EINVAL;
        }
    }
    else
    {
        NXP_LOG_WARNING("Section not found (.features). FW features management will not be available.\n");
        ret = EINVAL;
    }
    return ret;
}

/**
 * @brief       Upload firmware into PEs memory
 * @param[in]   pe The PE instances
 * @param[in]   pe_num Number of PE instances
 * @param[in]   elf The elf file object to be uploaded
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_pe_load_firmware(pfe_pe_t *pe, uint32 pe_num, const void *elf)
{
    uint32 pe_idx;
    errno_t ret = EOK;
    bool_t bOpsExist = TRUE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == elf)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Lock family */
        if (PE_TYPE_CLASS == pe->type)
        {
            oal_mutex_lock(PFE_CLASS_PE_MUTEX_02);
        }
        else
        {
            oal_mutex_lock(PFE_UTIL_PE_MUTEX_02);
        }
        pfe_pe_lock_family(pe);

        ret =  pfe_pe_fw_install_ops(pe, (uint8)(pe_num & UINT8_MAX));
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Couldn't find PE load operations: %d\n", ret);
        }

        for(pe_idx = 0; pe_idx < pfe_pe_fw_load_cycles(&pe[0], (uint8)(pe_num & UINT8_MAX)); ++pe_idx)
        {
            /* Check that we have the ops */
            if(NULL == pe[pe_idx].fw_load_ops)
            {
                bOpsExist = FALSE;
                ret = ENODEV;
                break;
            }

            pe[pe_idx].fw_load_ops->pe_memset(&pe[pe_idx], PFE_PE_DMEM, 0, 0, pe[pe_idx].dmem_size);
            pe[pe_idx].fw_load_ops->pe_memset(&pe[pe_idx], PFE_PE_IMEM, 0, 0, pe[pe_idx].imem_size);
        }
        if (TRUE == bOpsExist)
        {
            ret = pfe_pe_load_firmware_aux(pe,pe_num,elf);
        }
        /* Unlock family */
        pfe_pe_unlock_family(pe);
        if (PE_TYPE_CLASS == pe->type)
        {
            oal_mutex_unlock(PFE_CLASS_PE_MUTEX_02);
        }
        else
        {
            oal_mutex_unlock(PFE_UTIL_PE_MUTEX_02);
        }

    }
    return ret;
}

/**
 * @brief       Get pointer to PE's memory where memory map data is stored
 * @param[in]   pe The PE instance
 * @param[out]  mmap Pointer where memory map shall be written (values are in network byte order)
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT Requested data not available
 */
errno_t pfe_pe_get_mmap(const pfe_pe_t *pe, pfe_ct_pe_mmap_t *mmap)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == mmap)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != pe->mmap_data)
        {
            (void)autolibc_memcpy(mmap, (const void *)pe->mmap_data, sizeof(pfe_ct_pe_mmap_t));
            ret = EOK;
        }
        else
        {
            ret = ENOENT;
        }
    }

    return ret;
}

/**
 * @brief       Destroy PE instances
 * @param[in]   pe The list of PE instances
 * @param[in]   pe_num The number of PE instances
 */
void pfe_pe_destroy(pfe_pe_t *pe, uint32 pe_num)
{
    uint32 pe_idx;

    if ((NULL != pe) && (0U < pe_num))
    {
        for (pe_idx = 0 ; pe_idx < pe_num; ++pe_idx)
        {
            pe[pe_idx].mmap_data = NULL;
            pe[pe_idx].fw_msg_section = NULL;
            pe[pe_idx].fw_msg_section_size = 0U;
            pe[pe_idx].fw_feature_section = NULL;
            pe[pe_idx].fw_feature_section_size = 0U;
            pe[pe_idx].miflock = NULL;
        }
    }
}

/**
* @brief Returns a string base from the features description section
* @param[in] pe PE to be used
* @return Either the string base or NULL.
*/
char *pfe_pe_get_fw_feature_str_base(const pfe_pe_t *pe)
{
    char *str;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        str = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        str = NULL;
        if(INVALID_FEATURES_BASE != pe->fw_features_base)
        {
            str = (char *)(pe->fw_feature_section);
        }
    }

    return str;
}

/**
* @brief Returns feature description from special .elf section
* @param[in] pe PE to be used
* @param[in] id Id of the feature - its position in the section.
* @param[out] entry Pointer to the description is stored here
* @retun Either error code on failure or EOK
*/
errno_t pfe_pe_get_fw_feature_entry(pfe_pe_t *pe, uint32 id, pfe_ct_feature_desc_t **entry)
{
    uint32 entry_ptr;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == pe))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check whether the section with features description is available */
        if(NULL == pe->fw_feature_section)
        {   /* Avoid running uninitialized */
            ret = ENOENT;
        }
        else
        {
            /* Get the pointer to the descriptions and count of the features
               (do it only once and remember the values) */
            if(INVALID_FEATURES_BASE == pe->fw_features_base)
            {
                pfe_ct_pe_mmap_t pfe_pe_mmap = { 0U };

                /* The mmap has not been queried for error record yet. Query map for
                   the error record address. */
                if (EOK != pfe_pe_get_mmap(pe, &pfe_pe_mmap))
                {
                    NXP_LOG_ERROR("Could not get memory map\n");
                    ret = ENOENT;
                }
                else
                {
                    /* Remember the features record address and size */
                    pe->fw_features_base = oal_ntohl(pfe_pe_mmap.common.version.features);
                    if(pe->fw_features_base > pe->fw_feature_section_size)
                    {
                        NXP_LOG_ERROR("Invalid address of features record 0x%x\n", (uint_t)pe->fw_features_base);
                        pe->fw_features_base = INVALID_FEATURES_BASE;
                        ret = EIO;
                    }
                    else
                    {
                        pe->fw_features_size = oal_ntohl(pfe_pe_mmap.common.version.features_count);
                    }
                }
            }

            /* Check if the requested id does exist */
            if(EOK == ret)
            {
                if(id < pe->fw_features_size)
                {
                    /* Entry at given id does exist so return it */
                    entry_ptr = oal_ntohl(*(uint32 *)ADDR_BASE_OFFSET((addr_t)pe->fw_feature_section, ((uint64)id * sizeof(PFE_PTR(pfe_ct_feature_desc_t))) + pe->fw_features_base));

                    *entry = (pfe_ct_feature_desc_t *)((addr_t)pe->fw_feature_section + entry_ptr);

                    ret = EOK;
                }
                else
                {
                    ret = ENOENT;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Reads out errors reported by the PE Firmware and prints them on debug console
 * @param[in]   pe PE which error report shall be read out
 * @return      EOK on success or error code
 */
errno_t pfe_pe_get_fw_messages_nolock(pfe_pe_t *pe)
{
#ifdef NXP_LOG_ENABLED
    pfe_ct_message_record_t message_record; /* Copy of the PE error record */
    uint32 read_start;                /* Starting position in error record to read */
    uint32 i;
    uint32 message_count;
    pfe_ct_pe_mmap_t pfe_pe_mmap;

    if(NULL == pe->fw_msg_section)
    {
        /* Avoid running uninitialized */
        return ENOENT;
    }

    if(0U == pe->message_record_addr)
    {
        /* The memory map has not been queried for error record yet. Get
           the map and query it for the error record address. */
        if (EOK != pfe_pe_get_mmap(pe, &pfe_pe_mmap))
        {
            NXP_LOG_ERROR("Could not get memory map\n");
            return ENOENT;
        }

        /* Remember the error record address */
        pe->message_record_addr = oal_ntohl(pfe_pe_mmap.common.message_record);
    }

    pfe_pe_memcpy_from_dmem_to_host_32_nolock(
            pe, &message_record, pe->message_record_addr, sizeof(pfe_ct_message_record_t));

    /* Get the number of new errors */
    message_count = oal_ntohl(message_record.write_index) - pe->last_message_write_index;

    /* First unread error */
    read_start = pe->last_message_write_index;

    /* Where to continue next time */
    pe->last_message_write_index = oal_ntohl(message_record.write_index);
    if(0U != message_count)
    {
        /* New errors reported - go through them */
        if(message_count > FP_MESSAGE_RECORD_SIZE)
        {
            NXP_LOG_WARNING("FW message log overflow by %u\n",
                    (uint_t)message_count - FP_MESSAGE_RECORD_SIZE + 1U);

            /* Overflow has occurred - the write_index contains oldest record */
            read_start = oal_ntohl(message_record.write_index);
            message_count = FP_MESSAGE_RECORD_SIZE;
        }

        for(i = 0U; i < message_count; i++)
        {
            uint32 message_addr;
            uint32 message_line;
            const pfe_ct_message_t *message_ptr;
            const char_t *message_str;
            const char_t *message_file;
            uint32 message_val;
            pfe_ct_message_level_t message_level;

            message_addr = oal_ntohl(message_record.messages[(read_start + i)
                                                      & (FP_MESSAGE_RECORD_SIZE - 1U)]);
            message_val = oal_ntohl(message_record.values[(read_start + i)
                                                      & (FP_MESSAGE_RECORD_SIZE - 1U)]);
            message_level = message_record.level[(read_start + i) & (FP_MESSAGE_RECORD_SIZE - 1U)];
            if(message_addr > pe->fw_msg_section_size)
            {
                NXP_LOG_ERROR("Invalid error address from FW 0x%x\n", (uint_t)message_addr);
                break;
            }

            /* Get to the error message through the .errors section */
            message_ptr = (pfe_ct_message_t *)((addr_t)pe->fw_msg_section + message_addr);
            if(oal_ntohl(message_ptr->message) > pe->fw_msg_section_size)
            {
                NXP_LOG_ERROR("Invalid error message from FW 0x%x",
                        (uint_t)oal_ntohl(message_ptr->message));
                break;
            }

            message_str = (char_t *)((addr_t)pe->fw_msg_section + oal_ntohl(message_ptr->message));
            if(oal_ntohl(message_ptr->file) > pe->fw_msg_section_size)
            {
                NXP_LOG_ERROR("Invalid file name from FW 0x%x",
                        (uint_t)oal_ntohl(message_ptr->file));
                break;
            }

            message_file =  (char_t *)((addr_t)pe->fw_msg_section + oal_ntohl(message_ptr->file));
            message_line = oal_ntohl(message_ptr->line);

            switch (message_level)
            {
                case PFE_MESSAGE_EXCEPTION:
                case PFE_MESSAGE_ERROR:
                    pfe_hm_report_error(hm_types[pe->type], HM_EVT_PE_ERROR,
                            "PE%d: %s line %u: %s (0x%x)\n",
                            pe->id, message_file, (uint_t)message_line, message_str, (uint_t)message_val);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
                   (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_PE_FW_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
                    break;
                case PFE_MESSAGE_WARNING:
                    NXP_LOG_WARNING("PE%d: %s line %u: %s (0x%x)\n",
                            pe->id, message_file, (uint_t)message_line, message_str, (uint_t)message_val);
                    break;
                case PFE_MESSAGE_INFO:
                    NXP_LOG_INFO("PE%d: %s line %u: %s (0x%x)\n",
                        pe->id, message_file, (uint_t)message_line, message_str, (uint_t)message_val);
                    break;
                case PFE_MESSAGE_DEBUG:
                    NXP_LOG_DEBUG("PE%d: %s line %u: %s (0x%x)\n",
                        pe->id, message_file, (uint_t)message_line, message_str, (uint_t)message_val);
                    break;
                default:
                    NXP_LOG_ERROR("Invalid error level from FW 0x%x\n",
                        message_level);
                    break;
            }
        }
    }
#else
    (void)pe;
#endif /* NXP_LOG_ENABLED */
    return EOK;
}

/**
 * @brief Reads and validates PE mmap
 * @param[in] pe The PE instance
 */
errno_t pfe_pe_check_mmap(const pfe_pe_t *pe)
{
    pfe_ct_pe_mmap_t pfe_pe_mmap;
    errno_t ret;

    /*  Get mmap base from PE[0] since all PEs have the same memory map */
    if (EOK != pfe_pe_get_mmap(pe, &pfe_pe_mmap))
    {
        NXP_LOG_ERROR("Could not get memory map\n");
        ret = ENOENT;
    }
    else
    {
        ret = EOK;
        NXP_LOG_INFO("[FW VERSION] %d.%d.%d, Build: %s, %s (%s), ID: 0x%x\n",
            pfe_pe_mmap.common.version.major,
            pfe_pe_mmap.common.version.minor,
            pfe_pe_mmap.common.version.patch,
            (char_t *)pfe_pe_mmap.common.version.build_date,
            (char_t *)pfe_pe_mmap.common.version.build_time,
            (char_t *)pfe_pe_mmap.common.version.vctrl,
            (uint_t)pfe_pe_mmap.common.version.id);
    }

    return ret;
}

/**
 * @brief       Copies PE (global) statistics into a prepared buffer
 * @param[in]   pe      PE which statistics shall be read
 * @param[in]   addr    Address within the PE DMEM where the statistics are located
 * @param[out]  stats   Buffer where to copy the statistics from the PE DMEM
 * @retval      EOK     Success
 * @retval      EINVAL  Invalid argument
 */
errno_t pfe_pe_get_pe_stats_nolock(pfe_pe_t *pe, uint32 addr, pfe_ct_pe_stats_t *stats)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == stats)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(0U == addr))
    {
        NXP_LOG_ERROR("NULL argument for DMEM received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, stats, addr, sizeof(pfe_ct_pe_stats_t));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Check if PE is stalled
 * @details     PE is stalled when the firmware is running and the firmware state counter is not
 *              updated periodically. This function shouldn't be called very often so the
 *              PE can change state between calls.
 * @param[in]   pe The PE instance
 * @return      TRUE if PE is stalled, FALSE if not
 */
bool_t pfe_pe_check_stalled_nolock(pfe_pe_t *pe)
{
    pfe_ct_pe_sw_state_monitor_t state_monitor;
    bool_t ret = FALSE;
    static const char *states[] = {
        "UNINIT",
        "INIT",
        "FRAMEWAIT",
        "FRAMEPARSE",
        "FRAMECLASSIFY",
        "FRAMEDISCARD",
        "FRAMEMODIFY",
        "FRAMESEND",
        "STOPPED",
        "EXCEPTION",
        "FAIL_STOP"
    };

    if (pfe_pe_get_state_monitor_nolock(pe, &state_monitor) != EOK)
    {
        ret = FALSE;
    }
    else
    {
        if ((PFE_FW_STATE_EXCEPTION == state_monitor.state) && (state_monitor.state != pe->prev_state))
        {
            pfe_hm_report_error(hm_types[pe->type], HM_EVT_PE_EXCEPTION, "Core %d raised exception in state %s", pe->id, states[state_monitor.state]);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
            (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_PE_EXCEPTION_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
            ret = TRUE;
        }
        if ((FALSE == pe->stalled) && (state_monitor.state != PFE_FW_STATE_UNINIT) &&
                (state_monitor.counter == pe->counter))
        {
            pfe_hm_report_error(hm_types[pe->type], HM_EVT_PE_STALL, "Core %d stalled in state %s", pe->id, states[state_monitor.state]);
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
            (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_PE_STALL_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
            pe->stalled = TRUE;
            ret = TRUE;
        }

        pe->counter = state_monitor.counter;
        pe->prev_state = state_monitor.state;
    }
    return ret;
}


/**
 * @brief       Copies PE classification algorithms statistics into a prepared buffer
 * @param[in]   pe      PE which statistics shall be read
 * @param[in]   addr    Address within the PE DMEM where the statistics are located
 * @param[out]  stats   Buffer where to copy the statistics from the PE DMEM
 * @retval      EOK     Success
 * @retval      EINVAL  Invalid argument
 */
errno_t pfe_pe_get_classify_stats_nolock(pfe_pe_t *pe, uint32 addr, pfe_ct_classify_stats_t *stats)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == stats)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(0U == addr))
    {
        NXP_LOG_ERROR("NULL argument for DMEM received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, stats, addr, sizeof(pfe_ct_classify_stats_t));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Copies classification algorithm or logical interface statistics into a prepared buffer
 * @param[in]   pe      PE which statistics shall be read
 * @param[in]   addr    Address within the PE DMEM where the statistics are located
 * @param[out]  stats   Buffer where to copy the statistics from the PE DMEM
 * @retval      EOK     Success
 * @retval      EINVAL  Invalid argument
 */
errno_t pfe_pe_get_class_algo_stats_nolock(pfe_pe_t *pe, uint32 addr, pfe_ct_class_algo_stats_t *stats)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == pe) || (NULL == stats)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else if (unlikely(0U == addr))
    {
        NXP_LOG_ERROR("NULL argument for DMEM received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, stats, addr, sizeof(pfe_ct_class_algo_stats_t));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Provides current state of PE firmware
 * @param[in]   pe          The PE instance
 * @return      Current state of PE firmware
 *
 */
pfe_ct_pe_sw_state_t pfe_pe_get_fw_state(pfe_pe_t *pe)
{
    pfe_ct_pe_sw_state_monitor_t state_monitor = { 0U };

    /* We don't need coherent data here so only lock the memory interface without locking the PE memory.
       NOTE: Use the mutex lock for CLASS PE here because the pfe_pe_get_fw_state() is only called from CLASS FW. */
    oal_mutex_lock(PFE_CLASS_PE_MUTEX_07);
    pfe_pe_lock_family(pe);
    if (pfe_pe_get_state_monitor_nolock(pe, &state_monitor) != EOK)
    {
        state_monitor.state = PFE_FW_STATE_UNINIT;
    }
    pfe_pe_unlock_family(pe);
    oal_mutex_unlock(PFE_CLASS_PE_MUTEX_07);

    return state_monitor.state;
}

/**
 * @brief       Read "put" buffer
 * @param[in]   pe The PE instance
 * @param[out]  buf Pointer to memory where buffer shall be written
 * @retval      EOK Success and buffer is valid
 * @retval      EAGAIN Buffer is invalid
 * @retval      ENOENT Buffer not found
 */
errno_t pfe_pe_get_data_nolock(pfe_pe_t *pe, pfe_ct_buffer_t *buf)
{
    uint8 flags = 0U;
    errno_t ret = ENOENT;
    pfe_ct_pe_mmap_t mmap_data = { 0U };
    const pfe_ct_class_mmap_t *class_mmap_data;

    /*  Get mmap base from PE[0] since all PEs have the same memory map */
    if (EOK != pfe_pe_get_mmap(pe, &mmap_data))
    {
        NXP_LOG_ERROR("Could not get memory map\n");
    }
    else
    {
        class_mmap_data = &mmap_data.class_pe;

        if (0U != class_mmap_data->put_buffer)
        {
            /*  Get "put" buffer status */
            pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, &flags,
                    oal_ntohl(class_mmap_data->put_buffer) + offsetof(pfe_ct_buffer_t, flags),
                        sizeof(uint8));

            if (0U != flags)
            {
                /*  Copy buffer to local memory */
                pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, buf, oal_ntohl(class_mmap_data->put_buffer), sizeof(pfe_ct_buffer_t));

                /*  Clear flags */
                flags = 0U;

                pfe_pe_memcpy_from_host_to_dmem_32_nolock(pe,
                        oal_ntohl(class_mmap_data->put_buffer) + offsetof(pfe_ct_buffer_t, flags),
                            &flags, sizeof(uint8));

                ret = EOK;
            }
            else
            {
                ret = EAGAIN;
            }
        }
    }


    return ret;
}

/**
 * @brief       Write "get" buffer
 * @param[in]   pe The PE instance
 * @param[out]  buf Pointer to data to be written
 * @retval      EOK Success and buffer is valid
 * @retval      EAGAIN Buffer is occupied
 * @retval      ENOENT Buffer not found
 */
errno_t pfe_pe_put_data_nolock(pfe_pe_t *pe, pfe_ct_buffer_t *buf)
{
    uint8 flags = 0U;
    errno_t ret = ENOENT;
    pfe_ct_pe_mmap_t mmap_data = { 0U };
    const pfe_ct_class_mmap_t *class_mmap_data;

    if (EOK != pfe_pe_get_mmap(pe, &mmap_data))
    {
        NXP_LOG_ERROR("Could not get memory map\n");
    }
    else
    {
        class_mmap_data = &mmap_data.class_pe;
        if (0U != class_mmap_data->get_buffer)
        {
            /*  Get "get" buffer status */
            pfe_pe_memcpy_from_dmem_to_host_32_nolock(pe, &flags,
                    oal_ntohl(class_mmap_data->get_buffer) + offsetof(pfe_ct_buffer_t, flags),
                        sizeof(uint8));

            if (0U == flags)
            {
                /*  Send data to PFE */
                buf->flags |= 1U;

                pfe_pe_memcpy_from_host_to_dmem_32_nolock(pe,
                        oal_ntohl(class_mmap_data->get_buffer), buf, sizeof(pfe_ct_buffer_t));

                ret = EOK;
            }
            else
            {
                ret = EAGAIN;
            }
        }
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [175/185]: src\pfe_phy_if.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */
/*==================================================================================================
*                                        INCLUDE FILES
* 1) system and project includes
* 2) needed interfaces from external units
* 3) internal and external interfaces from this unit
==================================================================================================*/

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"

#ifndef PFE_CFG_PFE_SLAVE
#include "hal.h"

#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_ct.h"
#include "pfe_phy_if.h"
#include "linked_list.h"
#include "pfe_feature_mgr.h"

/*==================================================================================================
*                          LOCAL TYPEDEFS (STRUCTURES, UNIONS, ENUMS)
==================================================================================================*/
struct pfe_phy_if_tag
{
    pfe_phy_if_type_t type;
    pfe_ct_phy_if_id_t id;
    const char_t *name;
    pfe_class_t *class;
    addr_t dmem_base;
    pfe_ct_phy_if_t phy_if_class;
    LLIST_t log_ifs;
    bool_t is_enabled;
    pfe_ct_block_state_t block_state; /* Copy of value in phy_if_class for faster access */
    pfe_mac_db_t mac_db; /* MAC database */
    union
    {
        pfe_emac_t *emac;
        pfe_hif_chnl_t *hif_ch;
        void *instance;
    } port;
};

/*==================================================================================================
*                                       LOCAL MACROS
==================================================================================================*/

/*==================================================================================================
*                                     GLOBAL VARIABLES
==================================================================================================*/

/*==================================================================================================
*                                      LOCAL CONSTANTS
==================================================================================================*/

/*==================================================================================================
*                                        LOCAL VARIABLES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_ct_phy_if_stats_t pfe_phy_if_stats[PFE_CLASS_PE_COUNT];
static pfe_phy_if_t pfe_phy_ifs[PFE_PHY_IF_ID_MAX + 1U];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================
*                                   LOCAL FUNCTION PROTOTYPES
==================================================================================================*/
#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_phy_if_write_to_class_nostats(const pfe_phy_if_t *iface, const pfe_ct_phy_if_t *class_if);
static errno_t pfe_phy_if_write_to_class(const pfe_phy_if_t *iface, const pfe_ct_phy_if_t *class_if);
static bool_t pfe_phy_if_has_log_if_nolock(const pfe_phy_if_t *iface, const pfe_log_if_t *log_if);
static errno_t pfe_phy_if_disable_nolock(pfe_phy_if_t *iface);
static errno_t pfe_phy_if_set_flag_nolock(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag);
static errno_t pfe_phy_if_clear_flag_nolock(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag);
static pfe_ct_if_flags_t pfe_phy_if_get_flag_nolock(const pfe_phy_if_t *iface, pfe_ct_if_flags_t flag);
static errno_t pfe_phy_if_enable_hw_block(const pfe_phy_if_t *iface);
static void pfe_phy_if_update_op_mode_nolock(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode);
static errno_t chain_new_log_if(pfe_phy_if_t * const p_phy_if, pfe_log_if_t * const p_log_if);
static errno_t del_log_if_from_ll(pfe_phy_if_t * const p_phy_if, const pfe_log_if_t * const p_log_if, pfe_log_if_t * const p_prev_entry, addr_t next_dmem_ptr);
static void if_release_entry(const pfe_phy_if_t * const p_phy_if, const pfe_log_if_t * const p_log_if);
static errno_t if_loopback_disable(pfe_phy_if_t * const p_phy_if);
static errno_t if_del_mac_addr(pfe_phy_if_t * const p_iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner);

#if defined(PFE_CFG_TEXT_STATS)
static uint32 pfe_phy_if_stat_to_str(const pfe_ct_phy_if_stats_t *stat, char *buf, uint32 buf_len, uint8 verb_level);
#endif /* defined(PFE_CFG_TEXT_STATS) */

/*==================================================================================================
*                                        LOCAL FUNCTIONS
==================================================================================================*/
/**
 * @brief       Write interface structure to classifier memory skipping interface statistics
 * @param[in]   iface The interface instance
 * @param[in]   class_if Pointer to the structure to be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
static errno_t pfe_phy_if_write_to_class_nostats(const pfe_phy_if_t *iface, const pfe_ct_phy_if_t *class_if)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class_if) || (NULL == iface) || (0U == iface->dmem_base)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Be sure that phy_stats are at correct place */
        ct_assert_offsetof((sizeof(pfe_ct_phy_if_t) - sizeof(pfe_ct_phy_if_stats_t)) == offsetof(pfe_ct_phy_if_t, phy_stats));
        ret = pfe_class_write_dmem(iface->class, -1, iface->dmem_base, (const  void *)class_if,
                                sizeof(pfe_ct_phy_if_t) - sizeof(pfe_ct_phy_if_stats_t));
    }

    return ret;
}

/**
 * @brief       Write interface structure to classifier memory with statistics
 * @param[in]   iface The interface instance
 * @param[in]   class_if Pointer to the structure to be written
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
static errno_t pfe_phy_if_write_to_class(const pfe_phy_if_t *iface, const pfe_ct_phy_if_t *class_if)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class_if) || (NULL == iface) || (0U == iface->dmem_base)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_class_write_dmem(iface->class, -1, iface->dmem_base, (const  void *)class_if, sizeof(pfe_ct_phy_if_t));
    }
    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Converts statistics of a physical interface or classification algorithm into a text form
 * @param[in]   stat        Statistics to convert
 * @param[out]  buf         Buffer where to write the text
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written into the output buffer
 */
static uint32 pfe_phy_if_stat_to_str(const pfe_ct_phy_if_stats_t *stat, char *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

    (void)verb_level;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == stat) || (NULL == buf)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "Ingress frames:   %u\n", oal_ntohl(stat->ingress));
        len += oal_util_snprintf(buf + len, buf_len - len, "Egress frames:    %u\n", oal_ntohl(stat->egress));
        len += oal_util_snprintf(buf + len, buf_len - len, "Malformed frames: %u\n", oal_ntohl(stat->malformed));
        len += oal_util_snprintf(buf + len, buf_len - len, "Discarded frames: %u\n", oal_ntohl(stat->discarded));
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief Chains log_if to phy_if's LL
 * @param p_phy_if phy_if to link log_if to
 * @param p_log_if log_if to be linked to phy_if's log_if LL
 * @return errno_t EOK on success, error code otherwise
 */
static errno_t chain_new_log_if(pfe_phy_if_t * const p_phy_if, pfe_log_if_t * const p_log_if)
{
    errno_t ret = EINVAL;
    const pfe_log_if_t *tmp_entry;
    addr_t log_if_dmem_base = 0U;

    /*  Check duplicates */
    if (TRUE == pfe_phy_if_has_log_if_nolock(p_phy_if, p_log_if))
    {
        NXP_LOG_WARNING("%s already added\n", pfe_log_if_get_name(p_log_if));
        ret = EEXIST;
    }
    else
    {
        /*  Get current first item of the list */
        tmp_entry = pfe_log_if_from_phy_if_binding_list_entry(p_phy_if->log_ifs.prNext);

        log_if_dmem_base = 0U;
        if (EOK != pfe_log_if_get_dmem_base(tmp_entry, &log_if_dmem_base))
        {
            NXP_LOG_ERROR("Could not get DMEM base (%s, parent: %s)\n",
                    pfe_log_if_get_name(tmp_entry), p_phy_if->name);
            ret = ENOEXEC;
        }
        else
        {
#if defined(PFE_CFG_NULL_ARG_CHECK)
            if (0U == log_if_dmem_base)
            {
                NXP_LOG_ERROR("LogIf base is NULL (%s)\n", pfe_log_if_get_name(tmp_entry));
                ret = ENOEXEC;
            }
            else
#endif /* PFE_CFG_NULL_ARG_CHECK */
            {
                /*  Change 'next' pointer of the new entry */
                if (EOK != pfe_log_if_set_next_dmem_ptr(p_log_if, log_if_dmem_base))
                {
                    NXP_LOG_ERROR("Can't set next linked list pointer (%s, parent: %s)\n",
                            pfe_log_if_get_name(p_log_if), p_phy_if->name);
                    ret = ENOEXEC;
                }
                else
                {
                    /* Next LL item added successfully */
                    ret = EOK;
                }
            }
        }
    }

    return ret;
}

static bool_t pfe_phy_if_has_log_if_nolock(const pfe_phy_if_t *iface, const pfe_log_if_t *log_if)
{
    LLIST_t *curItem;
    const pfe_log_if_t *entry;
    bool_t ret = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == iface) || (NULL_PTR == log_if)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        LLIST_ForEach(curItem, &iface->log_ifs)
        {
            entry = pfe_log_if_from_phy_if_binding_list_entry(curItem);
            if (log_if == entry)
            {
                ret = TRUE;
                break;
            }
        }
    }

    return ret;
}

static void pfe_phy_if_check_next_pointer_of_deleted_entry(pfe_phy_if_t *iface, const pfe_log_if_t *prev_entry, addr_t *log_if_dmem_base)
{
    *log_if_dmem_base = 0U;
    if (EOK != pfe_log_if_get_dmem_base(prev_entry, log_if_dmem_base))
    {
        NXP_LOG_ERROR("Could not get DMEM base (%s, parent: %s)\n",
                pfe_log_if_get_name(prev_entry), iface->name);

        /*  Don't leave here as the previous entry is set up to bypass the deleted entry */
    }

    iface->phy_if_class.def_log_if = oal_htonl((uint32)(*log_if_dmem_base));
}

/**
 * @brief Remove log_if from LL
 * @param p_phy_if phy_if with log_ifs in a LL
 * @param p_log_if log_if to be removed
 * @param p_prev_entry prev log_if LL item
 * @param next_dmem_ptr next dmem ptr
 * @return errno_t
 */
static errno_t del_log_if_from_ll(pfe_phy_if_t * const p_phy_if, const pfe_log_if_t * const p_log_if, pfe_log_if_t * const p_prev_entry, addr_t next_dmem_ptr)
{
    errno_t ret = EOK;
    addr_t log_if_dmem_base = 0U;

    (void) p_log_if;

    if (NULL_PTR == p_prev_entry)
    {
        if (0U == next_dmem_ptr)
        {
            /*  No next entry, no previous entry. Just remove. */
            NXP_LOG_WARNING("Removing default logical interface (%s, parent: %s)\n",
                    pfe_log_if_get_name(p_log_if), p_phy_if->name);

            /*  Invalidate head and default interface */
            p_phy_if->phy_if_class.def_log_if = oal_htonl((uint32)0U);
            p_phy_if->phy_if_class.log_ifs = oal_htonl((uint32)0U);
        }
        else
        {
            /*  Next pointer is OK, just move the head. Default interface is the latest one so no change here. */
            p_phy_if->phy_if_class.log_ifs = oal_htonl((uint32)next_dmem_ptr);
        }
    }
    else
    {
        /*  Set 'next' pointer of previous entry to 'next' pointer of deleted entry */
        if (EOK != pfe_log_if_set_next_dmem_ptr(p_prev_entry, next_dmem_ptr))
        {
            NXP_LOG_ERROR("Can't set next linked list pointer (%s, parent: %s)\n",
                    pfe_log_if_get_name(p_prev_entry), p_phy_if->name);
            ret = ENOEXEC;
        }
        else
        {
            /*  If 'next' pointer of deleted entry is NULL then we're removing default interface */
            if (0U == next_dmem_ptr)
            {
                NXP_LOG_INFO("Removing default logical interface (%s, parent: %s). Will be replaced by %s.\n",
                        pfe_log_if_get_name(p_log_if), p_phy_if->name, pfe_log_if_get_name(p_prev_entry));

                pfe_phy_if_check_next_pointer_of_deleted_entry(p_phy_if, p_prev_entry, &log_if_dmem_base);
            }
        }
    }

    return ret;
}

/**
 * @brief Release log_if entry from phy_if
 * @param p_phy_if phy_if to release log_if from
 * @param p_log_if log_if to be released from phy_if
 */
static void if_release_entry(const pfe_phy_if_t * const p_phy_if, const pfe_log_if_t * const p_log_if)
{
    addr_t log_if_dmem_base = 0U;
    LLIST_t *curItem;

    if (EOK != pfe_log_if_get_dmem_base(p_log_if, &log_if_dmem_base))
    {
        NXP_LOG_ERROR("Could not get DMEM base (%s, parent: %s)\n",
                pfe_log_if_get_name(p_log_if), p_phy_if->name);
    }

    NXP_LOG_INFO("%s (p0x%p) removed from %s (p0x%p)\n",
            pfe_log_if_get_name(p_log_if), (void *)log_if_dmem_base,
                p_phy_if->name, (void *)p_phy_if->dmem_base);

    /*  Remove entry from local list */
    curItem = pfe_log_if_get_phy_if_binding_list_entry(p_log_if);
    LLIST_Remove(curItem);
}

/**
 * @brief       Maintain bridge operational mode
 * @param[in]   iface The interface instance
 * @param[in]   mode Mode to be set. See pfe_ct_if_op_mode_t.
 * @note        Control HW bridge lookup mode based on operational mode of all PHYs.
 */
static void pfe_phy_if_update_op_mode_nolock(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode)
{
    uint32 if_bitmap;
    bool_t br_mode = FALSE;

    /* Set bitmap based on PHY ID */
    if_bitmap = 1UL << (uint32)iface->id;
    if ((IF_OP_VLAN_BRIDGE == mode) || (IF_OP_L2L3_VLAN_BRIDGE == mode))
    {
        br_mode = TRUE;
    }

    pfe_class_update_hw_bridge_lookup(iface->class, if_bitmap, br_mode);
}

/**
 * @brief       Check if hw_block is enabled
 * @param[in]   iface The interface instance
 * @retval      TRUE if enabled
 * @retval      FALSE if disabled
 */
static errno_t pfe_phy_if_enable_hw_block(const pfe_phy_if_t *iface)
{
    errno_t ret = EOK;

    /*  Enable also associated HW block */
    if (NULL == iface->port.instance)
    {
        /*  No HW block associated */
        ;
    }
    else
    {
        if (PFE_PHY_IF_EMAC == iface->type)
        {
            pfe_emac_enable(iface->port.emac);
        }
        else if (PFE_PHY_IF_HIF == iface->type)
        {
            ret = pfe_hif_chnl_rx_enable(iface->port.hif_ch);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Can't enable HIF channel RX: %d\n", ret);
            }
            else
            {
                ret = pfe_hif_chnl_tx_enable(iface->port.hif_ch);
                if (EOK != ret)
                {
                    NXP_LOG_DEBUG("Can't enable HIF channel TX: %d\n", ret);
                }
            }
        }
        else
        {
            NXP_LOG_DEBUG("Invalid interface type\n");
            ret = EINVAL;
        }
    }

    return ret;
}

static errno_t pfe_phy_if_disable_nolock(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_DEBUG("Disabling %s\n", iface->name);

        /*  Disable interface instance. Backup flags and write the changes. */
        tmp = iface->phy_if_class.flags;
        iface->phy_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp & oal_htonl(~(uint32)IF_FL_ENABLED));
        ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
        if (EOK != ret)
        {
            /*  Failed. Revert flags. */
            NXP_LOG_ERROR("Phy IF configuration failed\n");
            iface->phy_if_class.flags = tmp;
        }
        else
        {
            /*  Mark the interface as disabled */
            iface->is_enabled = FALSE;

            /*  Disable also associated HW block */
            if (NULL == iface->port.instance)
            {
                /*  No HW block associated */
                ;
            }
            else
            {
                if (PFE_PHY_IF_EMAC == iface->type)
                {
                    pfe_emac_disable(iface->port.emac);
                }
                else if (PFE_PHY_IF_HIF == iface->type)
                {
                    pfe_hif_chnl_rx_disable(iface->port.hif_ch);
                    pfe_hif_chnl_tx_disable(iface->port.hif_ch);
                }
                else
                {
                    NXP_LOG_DEBUG("Invalid interface type\n");
                    ret = EINVAL;
                }
            }

            /* Disable HW bridge lookup if the last interface is disabled */
            pfe_phy_if_update_op_mode_nolock(iface, IF_OP_DEFAULT);
        }
    }

    return ret;
}

/**
 * @brief       Set physical interface flag (nolock variant)
 * @param[in]   iface The interface instance
 * @param[in]   flag The flag to set
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_phy_if_set_flag_nolock(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;
    bool_t check_feat_mgr = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  For selected flags: check that the underlying FW feature is available (enabled) in FW */
        const char* feat_name = ((IF_FL_VLAN_CONF_CHECK == flag) ? ("vlan_conf_check") :
                                ((IF_FL_PTP_CONF_CHECK == flag) ? ("ptp_conf_check") : (NULL_PTR)));

        if(NULL_PTR != feat_name)
        {
            check_feat_mgr = pfe_feature_mgr_is_available(feat_name);
        }
        if ((NULL_PTR != feat_name) && (FALSE == check_feat_mgr))
        {
            NXP_LOG_INFO("Feature '%s' is not available (not enabled in FW).\n", feat_name);
            ret = EPERM;
        }
        else
        {
            /* Set the flag. */
            tmp = iface->phy_if_class.flags;
            iface->phy_if_class.flags |= oal_htonl(flag);
            ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
            if (EOK != ret)
            {
                /*  Failed. Revert flags. */
                NXP_LOG_ERROR("Could not write interface flag (set)\n");
                iface->phy_if_class.flags = tmp;
            }
        }
    }

    return ret;
}

/**
 * @brief       Clear physical interface flag (nolock variant)
 * @param[in]   iface The interface instance
 * @param[in]   flag The flag to clear
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_phy_if_clear_flag_nolock(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;
    bool_t check_feat_mgr = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  For selected flags: check that the underlying FW feature is available (enabled) in FW */
        const char* feat_name = ((IF_FL_VLAN_CONF_CHECK == flag) ? ("vlan_conf_check") :
                                ((IF_FL_PTP_CONF_CHECK == flag) ? ("ptp_conf_check") : (NULL_PTR)));

        if(NULL_PTR != feat_name)
        {
            check_feat_mgr = pfe_feature_mgr_is_available(feat_name);
        }
        if ((NULL_PTR != feat_name) && (FALSE == check_feat_mgr))
        {
            NXP_LOG_INFO("Feature '%s' is not available (not enabled in FW).\n", feat_name);
            ret = EPERM;
        }
        else
        {
            /* Set the flag. */
            tmp = iface->phy_if_class.flags;
            iface->phy_if_class.flags &= oal_htonl(~(uint32)flag);
            ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
            if (EOK != ret)
            {
                /*  Failed. Revert flags. */
                NXP_LOG_ERROR("Could not write interface flag (clear)\n");
                iface->phy_if_class.flags = tmp;
            }
        }
    }

    return ret;
}

/**
 * @brief       Get physical interface flag (nolock variant)
 * @param[in]   iface The interface instance
 * @param[in]   flag The flag to check
 * @return      Flag if 'flag' is set, zero (IF_FL_NONE) otherwise
 */
static pfe_ct_if_flags_t pfe_phy_if_get_flag_nolock(const pfe_phy_if_t *iface, pfe_ct_if_flags_t flag)
{
    pfe_ct_if_flags_t ret_flag;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_flag = IF_FL_NONE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret_flag = (pfe_ct_if_flags_t)(oal_ntohl(iface->phy_if_class.flags) & flag);
    }
    return ret_flag;
}

/**
 * @brief
 * @param p_phy_if Disables loopback on phy_if
 * @return errno_t EOK on success, error code otherwise
 */
static errno_t if_loopback_disable(pfe_phy_if_t * const p_phy_if)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

    /* Disable instance loopback mode. Backup flags and write the changes. */
    tmp = p_phy_if->phy_if_class.flags;
    p_phy_if->phy_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp & oal_htonl(~(uint32)IF_FL_LOOPBACK));
    ret = pfe_phy_if_write_to_class_nostats(p_phy_if, &p_phy_if->phy_if_class);
    if (EOK != ret)
    {
        /* Failed. Revert flags. */
        NXP_LOG_ERROR("Phy IF configuration failed\n");
        p_phy_if->phy_if_class.flags = tmp;
    }
    else
    {
        /* Set up also associated HW block */
        if (NULL_PTR == p_phy_if->port.instance)
        {
            /* No HW block associated */
            ;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == p_phy_if->type)
            {
                pfe_emac_disable_loopback(p_phy_if->port.emac);
            }
            else if (PFE_PHY_IF_HIF == p_phy_if->type)
            {
                /* HIF does not offer loopback ability */
                ;
            }
            else
            {
                NXP_LOG_ERROR("Invalid interface type\n");
                ret = EINVAL;
            }
        }
    }
    return ret;
}

/**
 * @brief Removes a MAC from phy_if
 * @param p_iface phy_if to remove the addr from
 * @param addr MAC to be removed from phy_if
 * @param owner Drv owner
 * @return errno_t EOK on success, error code otherwise
 */
static errno_t if_del_mac_addr(pfe_phy_if_t * const p_iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret = EOK;
    errno_t temp_ret = EOK;

    if (PFE_PHY_IF_EMAC == p_iface->type)
    {
        ret = pfe_mac_db_del_addr(&p_iface->mac_db, addr, owner);
        if(EOK != ret)
        {
            NXP_LOG_WARNING("Unable to remove MAC address from phy_if MAC database: %d\n", ret);
        }
        else
        {
            if (FALSE == pfe_emac_is_broad(addr))
            {
                ret = pfe_emac_del_addr(p_iface->port.emac, addr, owner);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Unable to del MAC address: %d\n", ret);

                    /* Removal of MAC address from emac failed, put it back to DB */
                    temp_ret = pfe_mac_db_add_addr(&p_iface->mac_db, addr, owner);

                    ret = ENOENT;
                }
                if (EOK != temp_ret)
                {
                    NXP_LOG_ERROR("Unable to put back the MAC address into phy_if MAC database: %d\n", temp_ret);
                }
            }
        }
    }
    else if (PFE_PHY_IF_HIF == p_iface->type)
    {
        /*  HIF does not offer MAC filtering ability */
        ret = EINVAL;
    }
    else
    {
        NXP_LOG_ERROR("Invalid interface type\n");
        ret = EINVAL;
    }

    if (EOK == ret)
    {
        NXP_LOG_INFO("Address %02x:%02x:%02x:%02x:%02x:%02x removed from %s\n", addr[0], addr[1], addr[2], addr[3], addr[4], addr[5], p_iface->name);
    }

    return ret;
}

/*==================================================================================================
*                                       GLOBAL FUNCTIONS
==================================================================================================*/
/**
 * @brief       Create new physical interface instance
 * @param[in]   class The classifier instance
 * @param[in]   id The PFE firmware is using HW interface identifiers to distinguish
 *              between particular interfaces. The set of available IDs (the
 *              pfe_ct_phy_if_id_t) shall remain compatible with the firmware.
 * @param[in]   name Name of the interface
 * @return      The interface instance or NULL if failed
 */
pfe_phy_if_t *pfe_phy_if_create(pfe_class_t *class, pfe_ct_phy_if_id_t id, const char_t *name)
{
    uint32 i;
    pfe_phy_if_t *iface;
    pfe_ct_class_mmap_t pfe_pe_mmap = {0U};

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == class) || (NULL == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        iface = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        iface = &pfe_phy_ifs[id];
        (void)autolibc_memset(iface, 0, sizeof(*iface));

        iface->type = PFE_PHY_IF_INVALID;
        iface->id = id;
        iface->class = class;
        iface->is_enabled = FALSE;
        LLIST_Init(&iface->log_ifs);

        if (EOK != pfe_mac_db_create(&iface->mac_db))
        {
            NXP_LOG_ERROR("Could not create MAC db\n");
            pfe_phy_if_destroy(iface);
            iface = NULL_PTR;
        }
        else if (EOK != pfe_class_get_mmap(class, 0, &pfe_pe_mmap))
        {
            NXP_LOG_ERROR("Could not get memory map\n");
            pfe_phy_if_destroy(iface);
            iface = NULL_PTR;
        }
        else if (oal_ntohl(pfe_pe_mmap.dmem_phy_if_size) < ((1UL + (uint8)id) * sizeof(pfe_ct_phy_if_t)))
        {
            NXP_LOG_ERROR("PhyIf storage is too small\n");
            pfe_phy_if_destroy(iface);
            iface = NULL_PTR;
        }
        else
        {
            /*  Get physical interface instance address within DMEM array */
            iface->dmem_base = oal_ntohl(pfe_pe_mmap.dmem_phy_if_base) + ((uint16)id * sizeof(pfe_ct_phy_if_t));
            iface->name = name;
            /*  Initialize the interface structure in classifier */
            iface->phy_if_class.id = id;
            iface->phy_if_class.block_state = IF_BS_FORWARDING;
            iface->phy_if_class.mgmt_interface = PFE_PHY_IF_ID_INVALID;
            for(i = 0U; i < PFE_CT_MIRRORS_COUNT; i++)
            {
                iface->phy_if_class.rx_mirrors[i] = 0;
                iface->phy_if_class.tx_mirrors[i] = 0;
            }
            iface->phy_if_class.flags = (pfe_ct_if_flags_t)oal_htonl((uint32)IF_FL_ALLOW_Q_IN_Q|(uint32)IF_FL_FF_ALL_TCP);

            /* Be sure that statistics are zeroed (endianness doesn't mater for this) */
            iface->phy_if_class.phy_stats.ingress   = 0;
            iface->phy_if_class.phy_stats.egress    = 0;
            iface->phy_if_class.phy_stats.discarded = 0;
            iface->phy_if_class.phy_stats.malformed = 0;

            /*  Write the configuration to classifier */
            if (EOK != pfe_phy_if_write_to_class(iface, &iface->phy_if_class))
            {
                NXP_LOG_ERROR("Phy IF configuration failed\n");
                pfe_phy_if_destroy(iface);
                iface = NULL_PTR;
            }
        }
    }

    return iface;
}

/**
 * @brief       Destroy interface instance
 * @param[in]   iface The interface instance
 */
void pfe_phy_if_destroy(pfe_phy_if_t *iface)
{
    if (NULL_PTR != iface)
    {
        if (FALSE == LLIST_IsEmpty(&iface->log_ifs))
        {
            /*  Do not allow orphaned logical interfaces */
            NXP_LOG_ERROR("%s still contains logical interfaces. Destroy them first.\n", iface->name);
        }
        else
        {
            /* Disable HW bridge lookup if the last interface was destroyed */
            pfe_phy_if_update_op_mode_nolock(iface, IF_OP_DEFAULT);
            iface->name = NULL;
            (void)autolibc_memset(iface, 0, sizeof(*iface));
        }
    }

    return;
}

/**
 * @brief       Return classifier instance associated with interface
 * @param[in]   iface The interface instance
 * @return      The classifier instance
 */
__attribute__((pure)) pfe_class_t *pfe_phy_if_get_class(const pfe_phy_if_t *iface)
{
    pfe_class_t *class;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        class = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        class = iface->class;
    }
    return class;
}

/**
 * @brief       Add logical interface
 * @details     First added logical interface will become the default one. Default is used
 *              when packet is not matching any other logical interface within the physical one.
 * @param[in]   iface The physical interface instance
 * @param[in]   log_if The logical interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 * @retval      EEXIST Entry exists
 * @note        API to be used only by pfe_log_if module
 */
errno_t pfe_phy_if_add_log_if(pfe_phy_if_t *iface, pfe_log_if_t *log_if)
{
    errno_t ret = EOK;
    addr_t log_if_dmem_base = 0U;
    LLIST_t *phy_if_binding_entry;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == iface) || (NULL_PTR == log_if)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == LLIST_IsEmpty(&iface->log_ifs))
        {
            /*
                No logical interface assigned yet
            */

            /*  Get DMEM address to the logical interface structure */
            if (EOK != pfe_log_if_get_dmem_base(log_if, &log_if_dmem_base))
            {
                NXP_LOG_ERROR("Could not get DMEM base (%s, parent: %s)\n",
                        pfe_log_if_get_name(log_if), iface->name);
                ret = ENOEXEC;
            }
            else
            {
#if defined(PFE_CFG_NULL_ARG_CHECK)
                if (0U == log_if_dmem_base)
                {
                    NXP_LOG_ERROR("LogIf base is NULL (%s)\n", pfe_log_if_get_name(log_if));
                    ret = ENOEXEC;
                }
                else
#endif /* PFE_CFG_NULL_ARG_CHECK */
                {
                    /*  First added interface will become the default one */
                    iface->phy_if_class.def_log_if = oal_htonl((uint32)log_if_dmem_base);
                }
            }
        }
        else
        {
            /*
                Chain new logIf in (at the begin) => modify first phy_if_binding .next pointer
            */
            ret = chain_new_log_if(iface, log_if);
        }
        if (EOK == ret)
        {
            /*  Get DMEM pointer to the new logIf */
            log_if_dmem_base = 0U;
            if (EOK != pfe_log_if_get_dmem_base(log_if, &log_if_dmem_base))
            {
                NXP_LOG_ERROR("Could not get logIf DMEM base (%s, parent: %s)\n",
                        pfe_log_if_get_name(log_if), iface->name);
                ret = ENOEXEC;
            }
            else
            {
                /*  Set list head to the new logIf */
                const uint32 log_ifs = PFE_CFG_CLASS_ELF_DMEM_BASE | (log_if_dmem_base & (PFE_CFG_CLASS_DMEM_SIZE - 1U));
                iface->phy_if_class.log_ifs = oal_htonl(log_ifs);

                /*  Store physical interface changes (.phy_if_class) to DMEM */
                if (EOK != pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class))
                {
                    NXP_LOG_ERROR("Unable to update structure in DMEM (%s)\n", iface->name);
                    ret = ENOEXEC;
                }
                else
                {
                    /*  Now the new logIf is head of the list and classifier will see that */
                    NXP_LOG_DEBUG("%s (p0x%p) added to %s (p0x%p)\n",
                            pfe_log_if_get_name(log_if), (void *)log_if_dmem_base,
                                iface->name, (void *)iface->dmem_base);
                    /*  Add instance to local list of logical interfaces */
                    phy_if_binding_entry = pfe_log_if_get_phy_if_binding_list_entry(log_if);
                    LLIST_AddAtBegin(phy_if_binding_entry, &iface->log_ifs);
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Check if physical interface contains given logical interface
 * @param[in]   iface The physical interface instance
 * @param[in]   log_if The logical interface instance
 * @return      TRUE if logical interface is bound to the physical one. False
 *              otherwise.
 */
bool_t pfe_phy_if_has_log_if(pfe_phy_if_t *iface, const pfe_log_if_t *log_if)
{
    bool_t match;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == log_if)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        match = pfe_phy_if_has_log_if_nolock(iface, log_if);
    }

    return match;
}

/**
 * @brief       Provides default log_if of specified phy_if
 * @param[in]   iface The physical interface instance
 * @return      On success it returns default logical interface (log_if) instance
 *              associated with given physical interface. NULL is returned when default
 *              log_if is not found.
 */
pfe_log_if_t *pfe_phy_if_get_default_log_if(const pfe_phy_if_t *iface)
{
    pfe_log_if_t *ret = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (FALSE == LLIST_IsEmpty(&iface->log_ifs))
        {
            ret = pfe_log_if_from_phy_if_binding_list_entry(iface->log_ifs.prNext);
        }
    }

    return ret;
}

/**
 * @brief       Delete associated logical interface
 * @param[in]   iface The physical interface instance
 * @param[in]   log_if The logical interface instance to be deleted
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 * @retval      ENOENT Entry not found
 * @note        API to be used only by pfe_log_if module
 */
errno_t pfe_phy_if_del_log_if(pfe_phy_if_t *iface, const pfe_log_if_t *log_if)
{
    pfe_log_if_t *entry;
    pfe_log_if_t *prev_entry = NULL_PTR;
    LLIST_t *curItem;
    bool_t found = FALSE;
    addr_t next_dmem_ptr = 0U;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_PTR == iface) || (NULL_PTR == log_if)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        LLIST_ForEach(curItem, &iface->log_ifs)
        {
            entry = pfe_log_if_from_phy_if_binding_list_entry(curItem);
            if (log_if == entry)
            {
                found = TRUE;
                break;
            }
            else
            {
                prev_entry = entry;
            }
        }

        if (FALSE == found)
        {
            NXP_LOG_WARNING("%s not found in %s\n", pfe_log_if_get_name(log_if), iface->name);
            ret = ENOENT;
        }
        else
        {
            /*  Bypass the entry within the linked list in DMEM */
            next_dmem_ptr = 0U;
            if (EOK != pfe_log_if_get_next_dmem_ptr(entry, &next_dmem_ptr))
            {
                NXP_LOG_ERROR("Could not get DMEM base (%s, parent: %s)\n",
                        pfe_log_if_get_name(entry), iface->name);
                ret = ENOEXEC;
            }
            else
            {
                ret = del_log_if_from_ll(iface, log_if, prev_entry, next_dmem_ptr);

                if (EOK == ret)
                {
                    /*  Store physical interface changes (.phy_if_class) to DMEM */
                    if (EOK != pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class))
                    {
                        NXP_LOG_ERROR("Unable to update structure in DMEM (%s)\n", iface->name);
                        ret = ENOEXEC;
                    }
                    else
                    {
                        if_release_entry(iface, log_if);
                    }
                }
            }
        }
    }

    return ret;
}

/**
 * @brief Set the block state
 * @param[in] iface The interface instance
 * @param[out] block_state Block state to set
 * @return EOK on success or an error code
 */
errno_t pfe_phy_if_set_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t block_state)
{
    errno_t ret;
    pfe_ct_block_state_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Set the requested state */
        tmp = iface->block_state;
        iface->block_state = block_state;
        iface->phy_if_class.block_state = block_state;
        /* Write changes into the HW */
        ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);

        if (EOK != ret)
        {   /* Failure to update the HW */
            /* Restore previous value */
            iface->block_state = tmp;
            iface->phy_if_class.block_state = tmp;
            /* Report an error */
            NXP_LOG_DEBUG("Can't write PHY IF structure to classifier\n");
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief Get the block state
 * @param[in] iface The interface instance
 * @param[out] block_state Current block state
 * @return EOK On success or an error code
 */
errno_t pfe_phy_if_get_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t *block_state)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* The value is being stored in the iface structure and kept up-to-date
        with the value in FW thus it can be simply returned */
        *block_state = iface->block_state;
    }

    return ret;
}

/**
 * @brief       Get operational mode
 * @param[in]   iface The interface instance
 * @retval      Current phy_if mode. See pfe_ct_if_op_mode_t.
 */
pfe_ct_if_op_mode_t pfe_phy_if_get_op_mode(pfe_phy_if_t *iface)
{
    pfe_ct_if_op_mode_t ret;

    /*  Update the interface structure */
    ret = iface->phy_if_class.mode;

    return ret;
}

/**
 * @brief       Set operational mode
 * @param[in]   iface The interface instance
 * @param[in]   mode Mode to be set. See pfe_ct_if_op_mode_t.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_set_op_mode(pfe_phy_if_t *iface, pfe_ct_if_op_mode_t mode)
{
    pfe_ct_class_mmap_t mmap;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
#if !defined(PFE_CFG_L2BRIDGE_ENABLE)
        if ((IF_OP_VLAN_BRIDGE == mode) || (IF_OP_L2L3_VLAN_BRIDGE == mode))
        {
            NXP_LOG_WARNING("L2bridge mode is disabled\\n");
            ret = EINVAL;
        }
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
#if !defined(PFE_CFG_RTABLE_ENABLE)
        if (IF_OP_ROUTER == mode)
        {
            NXP_LOG_WARNING("Routing is disabled\n");
            ret = EINVAL;
        }
#endif /* PFE_CFG_RTABLE_ENABLE */
        /*  Get memory map */
        ret = pfe_class_get_mmap(iface->class, 0, &mmap);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("Can't get memory map\n");
            ret = EINVAL;
        }
        else
        {
            /*  Update the interface structure */
            /* Disable HW bridge lookup if the last interface was destroyed */
            pfe_phy_if_update_op_mode_nolock(iface, mode);

            iface->phy_if_class.mode = mode;
            ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Can't write PHY IF structure to classifier\n");
                ret = EINVAL;
            }
        }
    }

    return ret;
}

/**
 * @brief       Bind interface with EMAC
 * @param[in]   iface The interface instance
 * @param[in]   emac The EMAC instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      EPERM Operation not permitted
 */
errno_t pfe_phy_if_bind_emac(pfe_phy_if_t *iface, pfe_emac_t *emac)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == emac) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_INVALID == iface->type)
        {
            iface->type = PFE_PHY_IF_EMAC;
            iface->port.emac = emac;

            if (TRUE == iface->is_enabled)
            {
                ret = pfe_phy_if_enable(iface);
            }
            else
            {
                ret = pfe_phy_if_disable(iface);
            }
        }
        else
        {
            NXP_LOG_DEBUG("Interface already bound\n");
            ret = EPERM;
        }
    }

    return ret;
}

/**
 * @brief       Get associated EMAC instance
 * @param[in]   iface The interface instance
 * @return      Associated EMAC instance or NULL if failed
 */
pfe_emac_t *pfe_phy_if_get_emac(const pfe_phy_if_t *iface)
{
    pfe_emac_t *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_EMAC == iface->type)
        {
            ptr = iface->port.emac;
        }
        else
        {
            NXP_LOG_DEBUG("Invalid interface type\n");
            ptr = NULL;
        }
    }

    return ptr;
}

/**
 * @brief       Bind interface with HIF channel
 * @param[in]   iface The interface instance
 * @param[in]   hif The HIF channel instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      EPERM Operation not permitted
 */
errno_t pfe_phy_if_bind_hif(pfe_phy_if_t *iface, pfe_hif_chnl_t *hif)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == hif) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_INVALID == iface->type)
        {
            iface->type = PFE_PHY_IF_HIF;
            iface->port.hif_ch = hif;
            ret = EOK;
        }
        else
        {
            NXP_LOG_DEBUG("Interface already bound\n");
            ret = EPERM;
        }
    }

    return ret;
}

/**
 * @brief       Get associated HIF channel instance
 * @param[in]   iface The interface instance
 * @return      Associated HIF channel instance or NULL if failed
 */
pfe_hif_chnl_t *pfe_phy_if_get_hif(const pfe_phy_if_t *iface)
{
    pfe_hif_chnl_t *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_HIF == iface->type)
        {
            ptr = iface->port.hif_ch;
        }
        else
        {
            NXP_LOG_DEBUG("Invalid interface type\n");
            ptr = NULL;
        }
    }

    return ptr;
}

/**
 * @brief       Initialize util physical interface
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      EPERM Operation not permitted
 */
errno_t pfe_phy_if_bind_util(pfe_phy_if_t *iface)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_INVALID == iface->type)
        {
            iface->type = PFE_PHY_IF_UTIL;
            /* Configure instance to NULL */
            /* With NULL nothing will be done on en/dis promisc en/dis etc.. */
            iface->port.instance = NULL;
        }
        else
        {
            NXP_LOG_DEBUG("Interface already bound\n");
            ret = EPERM;
        }
    }

    return ret;
}

/**
 * @brief       Check if interface is enabled
 * @param[in]   iface The interface instance
 * @retval      TRUE if enabled
 * @retval      FALSE if disabled
 */
bool_t pfe_phy_if_is_enabled(pfe_phy_if_t *iface)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = iface->is_enabled;
    }

    return ret;
}

/**
 * @brief       Enable interface (RX/TX)
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        NXP_LOG_DEBUG("Enabling %s\n", iface->name);

        /*  Enable interface instance. Backup flags and write the changes. */
        tmp = iface->phy_if_class.flags;
        iface->phy_if_class.flags |= oal_htonl(IF_FL_ENABLED);
        ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
        if (EOK != ret)
        {
            /*  Failed. Revert flags. */
            NXP_LOG_ERROR("Phy IF configuration failed\n");
            iface->phy_if_class.flags = tmp;
        }
        else
        {
            /*  Mark the interface as enabled */
            iface->is_enabled = TRUE;

            ret = pfe_phy_if_enable_hw_block(iface);

            if (EOK != ret)
            {
                /*  HW configuration failure. Backup flags and disable the instance. */
                tmp = iface->phy_if_class.flags;
                iface->phy_if_class.flags &= (pfe_ct_if_flags_t)oal_htonl(~(uint32)IF_FL_ENABLED);
                ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
                if (EOK != ret)
                {
                    /*  Failed. Revert flags. */
                    NXP_LOG_ERROR("Phy IF configuration failed\n");
                    iface->phy_if_class.flags = tmp;
                }
                else
                {
                    iface->is_enabled = FALSE;
                }
            }
            else
            {
                /* Enable HW bridge lookup if required */
                pfe_phy_if_update_op_mode_nolock(iface, iface->phy_if_class.mode);
            }
        }
    }

    return ret;
}

/**
 * @brief       Disable interface (RX/TX)
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_disable(pfe_phy_if_t *iface)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_phy_if_disable_nolock(iface);
    }

    return ret;
}


/**
 * @brief       Set management interface
 * @param[in]   iface The interface instance
 * @param[in]   mgmt_interface The management interface
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_set_mgmt_interface(pfe_phy_if_t *iface, pfe_ct_phy_if_id_t mgmt_interface)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        iface->phy_if_class.mgmt_interface = mgmt_interface;
        /*  Write the configuration to classifier */
        if (EOK != pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class))
        {
            NXP_LOG_ERROR("Phy IF configuration mgmt interface failed\n");
            ret = EINVAL;
        }
        else
        {
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Get management interface
 * @param[in]   iface The interface instance
 * @retval      Phy interface ID used as PTP management interface.
 */
pfe_ct_phy_if_id_t pfe_phy_if_get_mgmt_interface(pfe_phy_if_t *iface)
{
    pfe_ct_phy_if_id_t mgmt_interface = PFE_PHY_IF_ID_INVALID;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Update the interface structure */
        mgmt_interface = iface->phy_if_class.mgmt_interface;
    }

    return mgmt_interface;
}

/**
 * @brief       Set physical interface flag
 * @param[in]   iface The interface instance
 * @param[in]   flag The flag to set
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_phy_if_set_flag(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_phy_if_set_flag_nolock(iface, flag);
    }

    return ret;
}

/**
 * @brief       Clear physical interface flag
 * @param[in]   iface The interface instance
 * @param[in]   flag The flag to clear
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_phy_if_clear_flag(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_phy_if_clear_flag_nolock(iface, flag);
    }

    return ret;
}

/**
 * @brief       Get physical interface flag
 * @param[in]   iface The interface instance
 * @param[in]   flag The flag to check
 * @return      Flag if 'flag' is set, zero (IF_FL_NONE) otherwise
 */
pfe_ct_if_flags_t pfe_phy_if_get_flag(pfe_phy_if_t *iface, pfe_ct_if_flags_t flag)
{
    pfe_ct_if_flags_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = IF_FL_NONE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_phy_if_get_flag_nolock(iface, flag);
    }

    return ret;
}

/**
 * @brief       Check if phy_if in promiscuous mode
 * @param[in]   iface The interface instance
 * @retval      TRUE promiscuous mode is enabled
 * @retval      FALSE  promiscuous mode is disbaled
 */
bool_t pfe_phy_if_is_promisc(pfe_phy_if_t *iface)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = (0U != (oal_ntohl(iface->phy_if_class.flags) & (uint32)IF_FL_PROMISC));
    }

    return ret;
}

/**
 * @brief               Enable loopback mode
 * @param[in]   iface The interface instance
 * @retval              EOK Success
 * @retval              EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loopback_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*      Enable instance loopback mode. Backup flags and write the changes. */
        tmp = iface->phy_if_class.flags;
        iface->phy_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp | oal_htonl(IF_FL_LOOPBACK));
        ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
        if (EOK != ret)
        {
            /*      Failed. Revert flags. */
            NXP_LOG_ERROR("Phy IF configuration failed\n");
            iface->phy_if_class.flags = tmp;
        }
        else
        {
            /*      Set up also associated HW block */
            if (NULL == iface->port.instance)
            {
                /*      No HW block associated */
                ;
            }
            else
            {
                if (PFE_PHY_IF_EMAC == iface->type)
                {
                    pfe_emac_enable_loopback(iface->port.emac);
                }
                else if (PFE_PHY_IF_HIF == iface->type)
                {
                    /*      HIF/UTIL does not offer filtering ability */
                    ;
                }
                else
                {
                    NXP_LOG_ERROR("Invalid interface type\n");
                    ret = EINVAL;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief               Disable loopback mode
 * @param[in]   iface The interface instance
 * @retval              EOK Success
 * @retval              EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loopback_disable(pfe_phy_if_t *iface)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = if_loopback_disable(iface);
    }

    return ret;
}

/**
 * @brief       Enable promiscuous mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_promisc_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Enable instance promiscuous mode. Backup flags and write the changes. */
        tmp = iface->phy_if_class.flags;
        iface->phy_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp | oal_htonl(IF_FL_PROMISC));
        ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
        if (EOK != ret)
        {
            /*  Failed. Revert flags. */
            NXP_LOG_ERROR("Phy IF configuration failed\n");
            iface->phy_if_class.flags = tmp;
        }
        else
        {
            /*  Set up also associated HW block */
            if (NULL == iface->port.instance)
            {
                /*  No HW block associated */
                ;
            }
            else
            {
                if (PFE_PHY_IF_EMAC == iface->type)
                {
                    pfe_emac_enable_promisc_mode(iface->port.emac);
                }
                else if (PFE_PHY_IF_HIF == iface->type)
                {
                    /*  HIF/UTIL does not offer filtering ability */
                    ;
                }
                else
                {
                    NXP_LOG_ERROR("Invalid interface type\n");
                    ret = EINVAL;
                }
            }
        }
    }


    return ret;
}

/**
 * @brief       Disable promiscuous mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_promisc_disable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Disable instance promiscuous mode. Backup flags and write the changes. */
        tmp = iface->phy_if_class.flags;
        iface->phy_if_class.flags = (pfe_ct_if_flags_t)((uint32)tmp & oal_htonl(~(uint32)IF_FL_PROMISC));
        ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
        if (EOK != ret)
        {
            /*  Failed. Revert flags. */
            NXP_LOG_ERROR("Phy IF configuration failed\n");
            iface->phy_if_class.flags = tmp;
        }
        else
        {
            /*  Set up also associated HW block */
            if (NULL == iface->port.instance)
            {
                /*  No HW block associated */
                ;
            }
            else
            {
                if (PFE_PHY_IF_EMAC == iface->type)
                {
                    pfe_emac_disable_promisc_mode(iface->port.emac);
                }
                else if (PFE_PHY_IF_HIF == iface->type)
                {
                    /*  HIF does not offer filtering ability */
                    ;
                }
                else
                {
                    NXP_LOG_ERROR("Invalid interface type\n");
                    ret = EINVAL;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Enable loadbalance mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loadbalance_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_HIF != iface->type)
        {
            /* Only HIF offers loadbalancing */
            NXP_LOG_ERROR("Invalid interface type\n");
            ret = EINVAL;
        }
        else
        {
            /*  Enable instance load balance mode. Backup flags and write the changes. */
            tmp = iface->phy_if_class.flags;
            iface->phy_if_class.flags |= oal_htonl(IF_FL_LOAD_BALANCE);
            ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
            if (EOK != ret)
            {
                /*  Failed. Revert flags. */
                NXP_LOG_ERROR("Phy IF configuration for IF_FL_LOAD_BALANCE failed\n");
                iface->phy_if_class.flags = tmp;
            }
        }
    }

    return ret;
}

/**
 * @brief       Disable loadbalance mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loadbalance_disable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_flags_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (PFE_PHY_IF_HIF != iface->type)
        {
            /* Only HIF offers loadbalancing */
            NXP_LOG_ERROR("Invalid interface type\n");
            ret = EINVAL;
        }
        else
        {
            /*  Disable instance loadbalance mode. Backup flags and write the changes. */
            tmp = iface->phy_if_class.flags;
            iface->phy_if_class.flags &= (pfe_ct_if_flags_t)oal_htonl(~(uint32)IF_FL_LOAD_BALANCE);
            ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
            if (EOK != ret)
            {
                /*  Failed. Revert flags. */
                NXP_LOG_ERROR("Phy IF configuration for IF_FL_LOAD_BALANCE failed\n");
                iface->phy_if_class.flags = tmp;
            }
        }
    }

    return ret;
}

/**
 * @brief       Enable ALLMULTI mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_allmulti_enable(pfe_phy_if_t * iface)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Set up also associated HW block */
        if (NULL == iface->port.instance)
        {
            /*  No HW block associated */
            ;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                pfe_emac_enable_allmulti_mode(iface->port.emac);
            }
            else if (PFE_PHY_IF_HIF == iface->type)
            {
                /*  HIF/UTIL does not offer filtering ability */
                ;
            }
            else
            {
                NXP_LOG_ERROR("Invalid interface type\n");
                ret = EINVAL;
            }
        }
    }
    return ret;
}

/**
 * @brief       Disable ALLMULTI mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_allmulti_disable(pfe_phy_if_t *iface)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Set up also associated HW block */
        if (NULL == iface->port.instance)
        {
            /*  No HW block associated */
            ;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                pfe_emac_disable_allmulti_mode(iface->port.emac);
            }
            else if (PFE_PHY_IF_HIF == iface->type)
            {
                /*  HIF does not offer filtering ability */
                ;
            }
            else
            {
                NXP_LOG_ERROR("Invalid interface type\n");
                ret = EINVAL;
            }
        }
    }
    return ret;
}

/**
 * @brief   Get rx/tx flow control config
 * @param[in]   iface The interface instance
 * @param[out]  tx_ena tx flow control status
 * @param[out]  rx_ena rx flow control status
 * @return      EOK on success
 */
errno_t pfe_phy_if_get_flow_control(pfe_phy_if_t *iface, bool_t* tx_ena, bool_t* rx_ena)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL == iface->port.instance)
        {
            /*      No HW block associated */
            ;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                pfe_emac_get_flow_control(iface->port.emac, tx_ena, rx_ena);
            }
            else
            {
                ;
            }
        }
    }
    return ret;
}

/**
 * @brief       Set tx flow control
 * @param[in]   iface The interface instance
 * @param[in]   tx_ena TRUE: enable flow control, FALSE: disable flow control
 * @return      EOK on success
 */
errno_t pfe_phy_if_set_tx_flow_control(pfe_phy_if_t *iface, bool_t tx_ena)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL == iface->port.instance)
        {
            /*      No HW block associated */
            ;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                if (TRUE == tx_ena)
                {
                    pfe_emac_enable_tx_flow_control(iface->port.emac);
                }
                else
                {
                    pfe_emac_disable_tx_flow_control(iface->port.emac);
                }
            }
            else
            {
                ;
            }
        }
    }

    return ret;
}

/**
 * @brief       Set rx flow control
 * @param[in]   iface The interface instance
 * @param[in]   rx_ena TRUE: enable flow control, FALSE: disable flow control
 * @return      EOK on success
 */
errno_t pfe_phy_if_set_rx_flow_control(pfe_phy_if_t *iface, bool_t rx_ena)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL == iface->port.instance)
        {
            /*      No HW block associated */
            ;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                if (TRUE == rx_ena)
                {
                    pfe_emac_enable_rx_flow_control(iface->port.emac);
                }
                else
                {
                    pfe_emac_disable_rx_flow_control(iface->port.emac);
                }
            }
            else
            {
                ;
            }
        }
    }

    return ret;
}

/**
 * @brief       Add MAC address
 * @param[in]   iface The interface instance
 * @param[in]   addr The MAC address to add
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      EEXIST The address already exists in local database
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_phy_if_add_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret = EOK;
    errno_t temp_ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Configure also associated HW block */
        if (NULL == iface->port.instance)
        {
            /*  No HW block associated */
            ;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                ret = pfe_mac_db_add_addr(&iface->mac_db, addr, owner);
                if((EOK == ret) && (FALSE == pfe_emac_is_broad(addr)))
                {
                    ret = pfe_emac_add_addr(iface->port.emac, addr, owner);
                    if (EEXIST == ret)
                    {
                        NXP_LOG_WARNING("Adding MAC address which already exists in EMAC\n");
                        ret = EOK;
                    }
                    else if (EOK != ret)
                    {
                        NXP_LOG_ERROR("Unable to add MAC address: %d\n", ret);
                        /* Delete the MAC address from database */
                        temp_ret = pfe_mac_db_del_addr(&iface->mac_db, addr, owner);
                        ret = ENOEXEC;
                    }
                    else
                    {
                        NXP_LOG_DEBUG("Address %02x:%02x:%02x:%02x:%02x:%02x added to %s\n", addr[0], addr[1], addr[2], addr[3], addr[4], addr[5], iface->name);
                    }
                    if (EOK != temp_ret)
                    {
                        NXP_LOG_ERROR("Unable to delete MAC address: %d\n", temp_ret);
                    }
                }
            }
            else if (PFE_PHY_IF_HIF == iface->type)
            {
                /*  HIF does not offer MAC filtering ability */
                ret = EINVAL;
            }
            else
            {
                NXP_LOG_ERROR("Invalid interface type\n");
                ret = EINVAL;
            }
        }
    }

    return ret;
}

/**
 * @brief       Delete MAC address
 * @param[in]   iface The interface instance
 * @param[in]   addr The MAC address to delete
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT Address not found
 */
errno_t pfe_phy_if_del_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Configure also associated HW block */
        if (NULL == iface->port.instance)
        {
            /*  No HW block associated */
            ;
        }
        else
        {
            ret = if_del_mac_addr(iface, addr, owner);
        }
    }

    return ret;
}

/**
 * @brief       Get handle of internal MAC database
 * @param[in]   iface The interface instance
 * @retval      Database handle.
 */
pfe_mac_db_t *pfe_phy_if_get_mac_db(pfe_phy_if_t *iface)
{
    pfe_mac_db_t *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ptr = &iface->mac_db;
    }

    return ptr;
}

/**
 * @brief       Reinit MAC address query and get the first MAC address from mac addr db.
 * @param[in]   iface The interface instance.
 * @param[out]  addr The MAC address will be written here.
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT No address found
 */
errno_t pfe_phy_if_get_mac_addr_first(pfe_phy_if_t *iface, pfe_mac_addr_t addr, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get MAC address from associated HW block */
        if (NULL == iface->port.instance)
        {
            /*  No HW block associated */
            ret = ENOENT;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                ret = pfe_mac_db_get_first_addr(&iface->mac_db, crit, type, owner, addr);
                if(EOK != ret)
                {
                    NXP_LOG_WARNING("%s: Unable to get MAC address: %d\n", iface->name, ret);
                }
            }
            else if (PFE_PHY_IF_HIF == iface->type)
            {
                /*  HIF does not have MAC address storage (yet) */
                ret = ENOENT;
            }
            else
            {
                /*  Unknown type, nothing to verify */
                ret = EINVAL;
            }
        }
    }

    return ret;
}

/**
 * @brief       Get the next MAC address from mac addr db.
 * @param[in]   iface The interface instance.
 * @param[out]  addr The MAC address will be written here.
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT No address found
 *
 * @note        Call pfe_phy_if_get_mac_addr_first() to initiate a query session.
 *              Then repeatedly call this function till there are no more MAC addresses to get.
 */
errno_t pfe_phy_if_get_mac_addr_next(pfe_phy_if_t *iface, pfe_mac_addr_t addr)
{
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get MAC address from associated HW block */
        if (NULL == iface->port.instance)
        {
            /*  No HW block associated */
            ret = ENOENT;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                ret = pfe_mac_db_get_next_addr(&iface->mac_db, addr);
                if(EOK != ret)
                {
                    NXP_LOG_WARNING("%s: Unable to get MAC address: %d\n", iface->name, ret);
                }
            }
            else if (PFE_PHY_IF_HIF == iface->type)
            {
                /*  HIF does not have MAC address storage (yet) */
                ret = ENOENT;
            }
            else
            {
                /*  Unknown type, nothing to verify */
                ret = EINVAL;
            }
        }
    }

    return ret;
}

/**
 * @brief       Delete MAC addresses added by owner with defined type
 * @param[in]   iface The interface instance
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_phy_if_flush_mac_addrs(pfe_phy_if_t *iface, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Configure also associated HW block */
        if (NULL == iface->port.instance)
        {
            /*  No HW block associated */
            ret = EOK;
        }
        else
        {
            if (PFE_PHY_IF_EMAC == iface->type)
            {
                ret = pfe_emac_flush_mac_addrs(iface->port.emac, crit, type, owner);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Unable to flush multicast MAC addresses (owner ID %d): %d\n", owner, ret);
                    ret = ENOEXEC;
                }
                else
                {
                    ret = pfe_mac_db_flush(&iface->mac_db, crit, type, owner);
                    if(EOK != ret)
                    {
                        NXP_LOG_ERROR("Unable to flush MAC address from phy_if MAC database: %d\n", ret);
                    }
                }
            }
            else if (PFE_PHY_IF_HIF == iface->type)
            {
                /*  HIF does not offer MAC filtering ability */
                ret = EOK;
            }
            else
            {
                NXP_LOG_ERROR("Invalid interface type\n");
                ret = EINVAL;
            }

            if (EOK == ret)
            {
                NXP_LOG_DEBUG("All multicast addresses owned by driver instance ID %d were flushed from %s\n", owner, iface->name);
            }
        }
    }

    return ret;
}

/**
 * @brief Sets the SPD (security policy database for IPsec) of the physical interface
 * @param[in] iface Inteface which SPD shall be set
 * @param[in] spd_addr Address of the SPD in the DMEM to be set (value 0 disables the IPsec feature for given interface)
 * @return EOK or an error value in case of failure
 */
errno_t pfe_phy_if_set_spd(pfe_phy_if_t *iface, uint32 spd_addr)
{
    errno_t ret;
    /* Update configuration */
    iface->phy_if_class.ipsec_spd = oal_htonl(spd_addr);
    /* Propagate the change into the classifier */
    ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
    return ret;
}

/**
 * @brief Returns the SPD address used by the physical interface
 * @param[in] iface Physical interface which shall be queried
 * @return Address of the SPD being used by the given physical interface. Value 0 means that no
 * *       SPD is in use thus the IPsec feature is disabled for the given interface.
 */
uint32 pfe_phy_if_get_spd(const pfe_phy_if_t *iface)
{
    return oal_ntohl(iface->phy_if_class.ipsec_spd);
}

/**
 * @brief       Set Flexible Filter rule table
 * @param[in]   iface The interface instance
 * @param[in]   table The table address. Zero means to disable the filter.
 * @retval      EOK Success
 * @retval      ENOENT Table not found
 * @retval      EINVAL Invalid argument
 *
 */
errno_t pfe_phy_if_set_ftable(pfe_phy_if_t *iface, uint32 table)
{
    errno_t ret;
    addr_t tmp;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (0U != table)
        {
            NXP_LOG_INFO("%s: Enabling Flexible Filter\n", iface->name);
        }
        else
        {
            NXP_LOG_INFO("%s: Disabling Flexible Filter\n", iface->name);
        }

        /*  Update the interface structure */
        tmp = iface->phy_if_class.filter;
        iface->phy_if_class.filter = oal_htonl(table);
        ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
        if (EOK != ret)
        {
            /*  Revert */
            NXP_LOG_DEBUG("Can't write PHY IF structure to classifier\n");
            iface->phy_if_class.filter = tmp;
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get Flexible Filter rule table
 * @param[in]   iface The interface instance
 * @return      Table address or zero if there is no table
 *
 */
uint32 pfe_phy_if_get_ftable(pfe_phy_if_t *iface)
{
    uint32 addr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        addr = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Update the interface structure */
        addr = oal_ntohl(iface->phy_if_class.filter);
    }

    return addr;
}

/**
 * @brief       Get phy interface statistics
 * @param[in]   iface The interface instance
 * @param[out]  stat Statistic structure
 * @retval      EOK Success
 * @retval      NOMEM Not possible to allocate memory for read
 */
errno_t pfe_phy_if_get_stats(pfe_phy_if_t *iface, pfe_ct_phy_if_stats_t *stat)
{
    uint32 i;
    uint32 u32retVal;
    errno_t ret;
    addr_t offset = 0;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == stat)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memset(stat,0,sizeof(pfe_ct_phy_if_stats_t));

        /* Store offset to stats */
        offset = offsetof(pfe_ct_phy_if_t,phy_stats);

        /* Gather memory from all PEs*/
        ret = pfe_class_gather_read_dmem(iface->class, &pfe_phy_if_stats, ADDR_BASE_OFFSET(iface->dmem_base, offset), sizeof(pfe_phy_if_stats), sizeof(pfe_ct_phy_if_stats_t));

        /* Calculate total statistics */
        u32retVal = pfe_class_get_num_of_pes(iface->class);
        for(i = 0U; i < u32retVal; i++)
        {
            /* Store statistics */
            stat->discarded = stat->discarded + oal_ntohl(pfe_phy_if_stats[i].discarded);
            stat->egress    = stat->egress + oal_ntohl(pfe_phy_if_stats[i].egress);
            stat->ingress   = stat->ingress + oal_ntohl(pfe_phy_if_stats[i].ingress);
            stat->malformed = stat->malformed + oal_ntohl(pfe_phy_if_stats[i].malformed);
        }

        /* Convert statistics back to network endian */
        stat->discarded = oal_htonl(stat->discarded);
        stat->egress    = oal_htonl(stat->egress);
        stat->ingress   = oal_htonl(stat->ingress);
        stat->malformed = oal_htonl(stat->malformed);
    }

    return ret;
}

/**
 * @brief Configures the selected RX mirror of the given interface
 * @param[in] iface Interface to be configured
 * @param[in] sel Selector of the RX mirror (0 to PFE_CT_MIRRORS_COUNT - 1)
 * @param[in] mirror Mirror to be configured.
 *                   Value NULL disables the selected RX mirror
 *  @return EOK when success or error code otherwise
 */
errno_t pfe_phy_if_set_rx_mirror(pfe_phy_if_t *iface, uint32 sel, const pfe_mirror_t *mirror)
{
    errno_t ret;
    uint32 tmp;
    uint32 address = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(sel >= PFE_CT_MIRRORS_COUNT)
        {
            ret = EINVAL;
        }
        else
        {
            if(NULL != mirror)
            {
                address = pfe_mirror_get_address(mirror);
            }
            /* Update configuration */
            tmp = iface->phy_if_class.rx_mirrors[sel]; /* Backup */
            iface->phy_if_class.rx_mirrors[sel] = oal_htonl(address);
            /* Propagate the change into the classifier */
            ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
            if(EOK != ret)
            {  /* Restore */
                iface->phy_if_class.rx_mirrors[sel] = tmp;
            }
            else
            {
                /* Increment internal ref counter of the new mirror object.
                 * The complementary decrement is realized when this mirror becomes "old mirror object" (when it is getting removed from the interface). */
                (void)pfe_mirror_get_first(MIRROR_BY_PHYS_ADDR, (void *)(addr_t)address);
                /* Decrement internal ref counter of the old mirror object. */
                pfe_mirror_put_by_address((addr_t)oal_ntohl(tmp));
            }
        }
    }

    return ret;
}

/**
 * @brief Configures the selected TX mirror of the given interface
 * @param[in] iface Interface to be configured
 * @param[in] sel Selector of the TX mirror (0 to PFE_CT_MIRRORS_COUNT - 1)
 * @param[in] mirror Mirror to be configured.
 *                   Value NULL disables the selected RX mirror
 *  @return EOK when success or error code otherwise
 */
errno_t pfe_phy_if_set_tx_mirror(pfe_phy_if_t *iface, uint32 sel, const pfe_mirror_t *mirror)
{
    errno_t ret;
    uint32 tmp;
    uint32 address = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(sel >= PFE_CT_MIRRORS_COUNT)
        {
            ret = EINVAL;
        }
        else
        {
            if(NULL != mirror)
            {
                address = pfe_mirror_get_address(mirror);
            }

            /* Update configuration */
            tmp = iface->phy_if_class.tx_mirrors[sel]; /* Backup */
            iface->phy_if_class.tx_mirrors[sel] = oal_htonl(address);
            /* Propagate the change into the classifier */
            ret = pfe_phy_if_write_to_class_nostats(iface, &iface->phy_if_class);
            if(EOK != ret)
            {  /* Restore */
                iface->phy_if_class.tx_mirrors[sel] = tmp;
            }
            else
            {
                /* Increment internal ref counter of the new mirror object.
                 * The complementary decrement is realized when this mirror becomes "old mirror object" (when it is getting removed from the interface). */
                (void)pfe_mirror_get_first(MIRROR_BY_PHYS_ADDR, (void *)(addr_t)address);
                /* Decrement internal ref counter of the old mirror object. */
                pfe_mirror_put_by_address((addr_t)oal_ntohl(tmp));
            }
        }
    }

    return ret;
}

/**
 * @brief Returns the selected TX mirror of the given interface
 * @param[in] iface Interface to be queried
 * @param[in] sel Selector of the TX mirror (0 to PFE_CT_MIRRORS_COUNT - 1)
 * @return The mirror reference or NULL if no mirror is configured
 */
pfe_mirror_t *pfe_phy_if_get_tx_mirror(const pfe_phy_if_t *iface, uint32 sel)
{
    uint32 address;
    pfe_mirror_t *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(sel >= PFE_CT_MIRRORS_COUNT)
        {
            ptr = NULL;
        }
        else
        {
            address = oal_ntohl(iface->phy_if_class.tx_mirrors[sel]);
            ptr = pfe_mirror_get_first(MIRROR_BY_PHYS_ADDR, (void *)(addr_t)address);
        }
    }

    return ptr;
}

/**
 * @brief Returns address of the selected RX mirror of the given interface
 * @param[in] iface Interface to be queried
 * @param[in] sel Selector of the RX mirror (0 to PFE_CT_MIRRORS_COUNT - 1)
 * @return The mirror reference or NULL if no mirror is configured
 */
pfe_mirror_t *pfe_phy_if_get_rx_mirror(const pfe_phy_if_t *iface, uint32 sel)
{
    uint32 address;
    pfe_mirror_t *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(sel >= PFE_CT_MIRRORS_COUNT)
        {
            ptr = NULL;
        }
        else
        {
            address = oal_ntohl(iface->phy_if_class.rx_mirrors[sel]);
            ptr = pfe_mirror_get_first(MIRROR_BY_PHYS_ADDR, (void *)(addr_t)address);
        }
    }

    return ptr;
}

/**
 * @brief       Get HW ID of the interface
 * @param[in]   iface The interface instance
 * @return      Interface ID
 */
__attribute__((pure)) pfe_ct_phy_if_id_t pfe_phy_if_get_id(const pfe_phy_if_t *iface)
{
    pfe_ct_phy_if_id_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = PFE_PHY_IF_ID_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = iface->id;
    }
    return ret;
}

/**
 * @brief       Get type of the interface
 * @param[in]   iface The interface instance
 * @return      Interface type
 */
__attribute__((pure)) pfe_phy_if_type_t pfe_phy_if_get_type(const pfe_phy_if_t *iface)
{
    pfe_phy_if_type_t if_type;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        if_type = PFE_PHY_IF_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if_type = iface->type;
    }
    return if_type;
}

/**
 * @brief       Get physical interface instance for HW ID
 * @param[in]   iface_id The interface HW ID
 * @return      Interface instance OR null if iface_id is not a valid id
 */
__attribute__((pure)) pfe_phy_if_t *pfe_phy_if_get_phy(pfe_ct_phy_if_id_t iface_id)
{
    pfe_phy_if_t *phy_if;

    if (PFE_PHY_IF_ID_MAX >= iface_id)
    {
        phy_if = &pfe_phy_ifs[(uint32)iface_id];
    }
    else
    {
        phy_if = NULL_PTR;
    }

    return phy_if;
}

/**
 * @brief       Get name
 * @param[in]   iface The interface instance
 * @return      Pointer to interface name string or "(unknown)" when called with NULL_PTR
 */
__attribute__((pure)) const char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface)
{
    const char_t *str;

    if (NULL_PTR != iface)
    {
        str = iface->name;
    }
    else
    {
        NXP_LOG_WARNING("NULL argument received for pfe_phy_if_get_name\n");
        str = "(unknown)";
    }

    return str;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return physical interface runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   iface       The physical interface instance
 * @param[in]   buf         A pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_phy_if_get_text_statistics(const pfe_phy_if_t *iface, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;
    pfe_ct_phy_if_t phy_if_class = {0U};
    uint32 i = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Repeat read for all PEs (just because of statistics) */
        while(i < pfe_class_get_num_of_pes(iface->class))
        {
            /*
                Read current interface configuration from classifier. Since all class PEs are running the
                same code, also the data are the same (except statistics counters...).
                Returned data will be in __NETWORK__ endian format.
            */
            if (EOK != pfe_class_read_dmem(iface->class, i, &phy_if_class, iface->dmem_base, sizeof(pfe_ct_phy_if_t)))
            {
                len += oal_util_snprintf(buf + len, buf_len - len, "[PhyIF 0x%x]: Unable to read DMEM\n", iface->id);
            }
            else
            {
                len += oal_util_snprintf(buf + len, buf_len - len, "[PhyIF 0x%x '%s']\n", iface->id, pfe_phy_if_get_name(iface));
                len += oal_util_snprintf(buf + len, buf_len - len, "LogIfBase (DMEM) : 0x%x\n", oal_ntohl(phy_if_class.log_ifs));
                len += oal_util_snprintf(buf + len, buf_len - len, "DefLogIf  (DMEM) : 0x%x\n", oal_ntohl(phy_if_class.def_log_if));
                (void)pfe_phy_if_stat_to_str(&phy_if_class.phy_stats, buf + len, buf_len - len, verb_level);
            }
            ++i;
        }
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* ! PFE_CFG_PFE_SLAVE */


===== 文件 [176/185]: src\pfe_phy_if_slave.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @file        pfe_phy_if_slave.c
 * @brief       The PFE physical interface module source file (slave).
 * @details     This file contains physical interface-related functionality for
 *              the slave driver variant. All physical interface instance
 *              manipulation is done via RPC in way that local driver only
 *              sends requests to master driver which performs the actual
 *              requested operations.
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"

#ifdef PFE_CFG_PFE_SLAVE
#include "hal.h"
#include "pfe_platform_cfg.h"
#include "pfe_ct.h"
#include "linked_list.h"
#include "pfe_phy_if.h"
#include "pfe_idex.h" /* The RPC provider */
#include "pfe_platform_rpc.h" /* The RPC codes and data structures */

struct pfe_phy_if_tag
{
    pfe_ct_phy_if_id_t id;
    const char_t *name;
    pfe_mac_db_t mac_db; /* MAC database */
    bool_t is_enabled;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_phy_if_t pfe_phy_ifs[PFE_PHY_IF_ID_MAX + 1U];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/*==================================================================================================*/
static errno_t pfe_phy_if_db_lock(void)
{
    errno_t ret;

    ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_IF_LOCK, NULL, 0, NULL, 0U);
    if (EOK != ret)
    {
        NXP_LOG_DEBUG("Unable to lock interface DB: %d\n", ret);
    }

    return ret;
}

/*==================================================================================================*/
static errno_t pfe_phy_if_db_unlock(void)
{
    errno_t ret;

    ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_IF_UNLOCK, NULL, 0, NULL, 0U);
    if (EOK != ret)
    {
        NXP_LOG_DEBUG("Unable to lock interface DB: %d\n", ret);
    }

    return ret;
}

/**
 * @brief       Create new physical interface instance
 * @param[in]   class The classifier instance
 * @param[in]   id The PFE firmware is using HW interface identifiers to distinguish
 *              between particular interfaces. The set of available IDs (the
 *              pfe_ct_phy_if_id_t) shall remain compatible with the firmware.
 * @param[in]   name Name of the interface
 * @return      The interface instance or NULL if failed
 */
pfe_phy_if_t *pfe_phy_if_create(pfe_class_t *class, pfe_ct_phy_if_id_t id, const char_t *name)
{
    pfe_phy_if_t *iface;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == name))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        iface = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)class;

        iface = &pfe_phy_ifs[id];
        (void)autolibc_memset(iface, 0, sizeof(*iface));
        iface->id = id;
        if (EOK != pfe_mac_db_create(&iface->mac_db))
        {
            NXP_LOG_ERROR("Could not create MAC database\n");
            (void)autolibc_memset(iface, 0, sizeof(*iface));
            iface = NULL_PTR;
        }
        else
        {
            iface->name = name;
        }
    }

    return iface;
}

/**
 * @brief       Destroy interface instance
 * @param[in]   iface The interface instance
 */
void pfe_phy_if_destroy(pfe_phy_if_t *iface)
{
    pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t arg;
    errno_t ret;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t));

    if (NULL_PTR != iface)
    {
        /*  Ask the master driver to remove all associated MAC addresses */
        (void)pfe_phy_if_db_lock();
        arg.phy_if_id = iface->id;
        arg.crit = MAC_DB_CRIT_BY_OWNER;
        arg.type = PFE_TYPE_ANY;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_FLUSH_MAC_ADDRS, &arg, (uint16)sizeof(arg), NULL_PTR, 0U);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("PFE_PLATFORM_RPC_PFE_PHY_IF_FLUSH_MAC_ADDRS failed: %d\n", ret);
        }
        (void)pfe_phy_if_db_unlock();

        iface->name = NULL;

        (void)autolibc_memset(iface, 0, sizeof(*iface));
    }
}

/**
 * @brief       Get operational mode
 * @param[in]   iface The interface instance
 * @retval      Current phy_if mode. See pfe_ct_if_op_mode_t.
 */
pfe_ct_if_op_mode_t pfe_phy_if_get_op_mode(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_ct_if_op_mode_t mode = IF_OP_DEFAULT;
    pfe_platform_rpc_pfe_phy_if_get_op_mode_arg_t arg = {0};
    pfe_platform_rpc_pfe_phy_if_get_op_mode_ret_t rpc_ret;

    (void)autolibc_memset(&rpc_ret, 0, sizeof(pfe_platform_rpc_pfe_phy_if_get_op_mode_ret_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        mode = IF_OP_DEFAULT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to change the operation mode */
        arg.phy_if_id = (uint8)iface->id;

        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_GET_OP_MODE, &arg, (uint16)sizeof(arg), &rpc_ret, (uint16)sizeof(rpc_ret));
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_GET_OP_MODE failed: %d\n", ret);
        }
        else
        {
            mode = rpc_ret.mode;
        }

        (void)pfe_phy_if_db_unlock();
    }

    return mode;
}

/**
 * @brief Set the block state
 * @param[in] iface The interface instance
 * @param[out] block_state Block state to set
 * @return EOK on success or an error code
 */
errno_t pfe_phy_if_set_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t block_state)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to change the block state */
        arg.phy_if_id = iface->id;
        arg.block_state = block_state;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief Get the block state
 * @param[in] iface The interface instance
 * @param[out] block_state Current block state
 * @return EOK On success or an error code
 */
errno_t pfe_phy_if_get_block_state(pfe_phy_if_t *iface, pfe_ct_block_state_t *block_state)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_get_block_state_arg_t arg = {0};
    pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t rpc_ret;

    (void)autolibc_memset(&rpc_ret, 0, sizeof(pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == block_state)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* GLOBAL_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to get the block state */
        arg.phy_if_id = ((uint8)iface->id);

        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE, &arg, (uint16)sizeof(arg), &rpc_ret, (uint16)sizeof(rpc_ret));
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE failed: %d\n", ret);
        }
        else
        {
            *block_state = rpc_ret.state;
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Check if interface is enabled
 * @param[in]   iface The interface instance
 * @retval      TRUE if enabled
 * @retval      FALSE if disabled
 */
bool_t pfe_phy_if_is_enabled(pfe_phy_if_t *iface)
{
    errno_t ret;
    bool_t status = FALSE;
    pfe_platform_rpc_pfe_phy_if_is_enabled_arg_t arg = {0};
    pfe_platform_rpc_pfe_phy_if_is_enabled_ret_t rpc_ret = {0};

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        status = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to enable the interface */
        arg.phy_if_id = ((uint8)iface->id);
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_IS_ENABLED, &arg, (uint16)sizeof(arg), &rpc_ret, (uint16)sizeof(rpc_ret));
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_IS_ENABLED failed: %d\n", ret);
        }
        else
        {
            status = rpc_ret.status;
        }

        (void)pfe_phy_if_db_unlock();
    }

    return status;
}

/**
 * @brief       Enable interface (RX/TX)
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_enable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_enable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to enable the interface */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ENABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_ENABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

errno_t pfe_phy_if_disable_nolock(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_disable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_disable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to disable the interface */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_DISABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_DISABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Disable interface (RX/TX)
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_disable(pfe_phy_if_t *iface)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_phy_if_disable_nolock(iface);
    }

    return ret;
}

/**
 * @brief       Check if phy_if in promiscuous mode
 * @param[in]   iface The interface instance
 * @retval      TRUE promiscuous mode is enabled
 * @retval      FALSE  promiscuous mode is disbaled
 */
bool_t pfe_phy_if_is_promisc(pfe_phy_if_t *iface)
{
    errno_t ret;
    bool_t status = FALSE;
    pfe_platform_rpc_pfe_phy_if_is_promisc_arg_t arg = {0};
    pfe_platform_rpc_pfe_phy_if_is_promisc_ret_t rpc_ret = {0};

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        status = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to enable the interface */
        arg.phy_if_id = ((uint8)iface->id);
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_IS_PROMISC, &arg, (uint16)sizeof(arg), &rpc_ret, (uint16)sizeof(rpc_ret));
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_IS_ENABLED failed: %d\n", ret);
        }
        else
        {
            status = rpc_ret.status;
        }

        (void)pfe_phy_if_db_unlock();
    }

    return status;
}

/**
 * @brief       Enable promiscuous mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_promisc_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_promisc_enable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_promisc_enable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to enable the promiscuous mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_ENABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_PROMICS_ENABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Disable promiscuous mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_promisc_disable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_promisc_disable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_promisc_disable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to disable the promiscuous mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_DISABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_PROMICS_DISABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Enable loopback mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loopback_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_loopback_enable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_loopback_enable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /* Ask the master driver to enable the loopback mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_ENABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_ENABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Disable loopback mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loopback_disable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_loopback_disable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /* Ask the master driver to disable the loopback mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_DISABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_PROMICS_DISABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Enable loadbalance mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loadbalance_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_loadbalance_enable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /* Ask the master driver to enable the loadbalance mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Disable loadbalance mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_loadbalance_disable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_loadbalance_disable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /* Ask the master driver to disable the loadbalance mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Enable ALLMULTI mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_allmulti_enable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_allmulti_enable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_allmulti_enable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to enable the allmulti mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_ENABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_ENABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Disable ALLMULTI mode
 * @param[in]   iface The interface instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 */
errno_t pfe_phy_if_allmulti_disable(pfe_phy_if_t *iface)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_allmulti_disable_arg_t arg;

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_allmulti_disable_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to disable the allmulti mode */
        arg.phy_if_id = iface->id;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_DISABLE, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_DISABLE failed: %d\n", ret);
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Add new MAC address
 * @param[in]   iface The interface instance
 * @param[in]   addr The MAC address to add
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      EEXIST The address already exists in local database
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_phy_if_add_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t arg;

    ct_assert(sizeof(pfe_mac_addr_t) == sizeof(arg.mac_addr));

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t));
    (void)owner; /* Owner will be added directly to the RPC */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();
        /*  Add address to local database */
        ret = pfe_mac_db_add_addr(&iface->mac_db, addr, owner);
        if(EOK == ret)
        {
            /*  Ask the master driver to add the MAC address */
            (void)autolibc_memcpy(&arg.mac_addr[0], addr, sizeof(arg.mac_addr));
            arg.phy_if_id = iface->id;
            ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ADD_MAC_ADDR, &arg, (uint16)sizeof(arg), NULL, 0U);
            if(EEXIST == ret)
            {
                NXP_LOG_WARNING("Adding MAC address which already exists in master driver\n");
                ret = EOK;
            }
            else if (EOK != ret)
            {
                NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_ADD_MAC_ADDR failed: %d\n", ret);
                ret = pfe_mac_db_del_addr(&iface->mac_db, addr, owner);
                if(EOK != ret)
                {
                    NXP_LOG_WARNING("Unable to remove MAC address from phy_if MAC database: %d\n", ret);
                }
            }
            else
            {
                NXP_LOG_DEBUG("Address %02x:%02x:%02x:%02x:%02x:%02x added to %s\n", addr[0], addr[1], addr[2], addr[3], addr[4], addr[5], iface->name);
            }
        }
        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Delete MAC address
 * @param[in]   iface The interface instance
 * @param[in]   addr The MAC address to delete
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT Address not found
 */
errno_t pfe_phy_if_del_mac_addr(pfe_phy_if_t *iface, const pfe_mac_addr_t addr, pfe_drv_id_t owner)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_del_mac_addr_arg_t arg;

    ct_assert(sizeof(pfe_mac_addr_t) == sizeof(arg.mac_addr));

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_del_mac_addr_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        ret = pfe_mac_db_del_addr(&iface->mac_db, addr, owner);
        if(EOK != ret)
        {
            NXP_LOG_WARNING("Unable to remove MAC address from phy_if MAC database: %d\n", ret);
        }
        else
        {
            /*  Ask the master driver to delete the MAC address */
            (void)autolibc_memcpy(&arg.mac_addr[0], addr, sizeof(arg.mac_addr));
            arg.phy_if_id = iface->id;
            ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_DEL_MAC_ADDR, &arg, (uint16)sizeof(arg), NULL, 0U);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_DEL_MAC_ADDR failed: %d\n", ret);

                /* Removal of MAC address by master failed, put it back to DB */
                ret = pfe_mac_db_add_addr(&iface->mac_db, addr, owner);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Unable to put back the MAC address into phy_if MAC database: %d\n", ret);
                }
            }
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Get handle of internal MAC database
 * @param[in]   iface The interface instance
 * @retval      Database handle.
 */
pfe_mac_db_t *pfe_phy_if_get_mac_db(pfe_phy_if_t *iface)
{
    pfe_mac_db_t *mac_db;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        mac_db = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        mac_db = &iface->mac_db;
    }

    return mac_db;
}

/**
 * @brief       Get MAC address
 * @param[in]   iface The interface instance
 * @param[out]  addr The MAC address will be written here
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner The identification of driver instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOENT No address found
 */
errno_t pfe_phy_if_get_mac_addr_first(pfe_phy_if_t *iface, pfe_mac_addr_t addr, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_mac_db_get_first_addr(&iface->mac_db, crit, type, owner, addr);
        if(EOK != ret)
        {
            NXP_LOG_WARNING("%s: Unable to get MAC address: %d\n", iface->name, ret);
        }
    }

    return ret;
}

/**
 * @brief       Delete MAC addresses added by owner with defined type
 * @param[in]   iface The interface instance
 * @param[in]   crit All, Owner, Type or Owner&Type criterion
 * @param[in]   type Required type of MAC address (Broadcast, Multicast, Unicast, ANY) criterion
 * @param[in]   owner Required owner of MAC address
 * @retval      EOK Success
 * @retval      EINVAL Invalid or missing argument
 * @retval      ENOEXEC Command failed
 */
errno_t pfe_phy_if_flush_mac_addrs(pfe_phy_if_t *iface, pfe_mac_db_crit_t crit, pfe_mac_type_t type, pfe_drv_id_t owner)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t arg;
    (void)owner; /* Owner will be added directly to the RPC */

    (void)autolibc_memset(&arg, 0, sizeof(pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t));

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        /*  Ask the master driver to flush owner's MAC addresses due to flush mode */
        arg.phy_if_id = iface->id;
        arg.crit = crit;
        arg.type = type;
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_FLUSH_MAC_ADDRS, &arg, (uint16)sizeof(arg), NULL, 0U);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_FLUSH_MAC_ADDRS failed: %d\n", ret);
        }
        else
        {
            /*  Remove MAC addresses also from local database */
            ret = pfe_mac_db_flush(&iface->mac_db, crit, type, owner);
            if(EOK != ret)
            {
                NXP_LOG_DEBUG("Unable to flush MAC address from phy_if MAC database: %d\n", ret);
            }
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

/**
 * @brief       Get HW ID of the interface
 * @param[in]   iface The interface instance
 * @return      Interface ID
 */
__attribute__((pure)) pfe_ct_phy_if_id_t pfe_phy_if_get_id(const pfe_phy_if_t *iface)
{
    pfe_ct_phy_if_id_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = PFE_PHY_IF_ID_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = iface->id;
    }

    return ret;
}

/**
 * @brief       Get physical interface instance for HW ID
 * @param[in]   iface_id The interface HW ID
 * @return      Interface instance OR null if iface_id is not a valid id
 */
__attribute__((pure)) pfe_phy_if_t *pfe_phy_if_get_phy(pfe_ct_phy_if_id_t iface_id)
{
    pfe_phy_if_t *phy_if;

    if (PFE_PHY_IF_ID_MAX >= (uint32)iface_id)
    {
        phy_if = &pfe_phy_ifs[iface_id];
    }
    else
    {
        phy_if = NULL_PTR;
    }

    return phy_if;
}

/**
 * @brief       Get name
 * @param[in]   iface The interface instance
 * @return      Pointer to interface name string or "(unknown)" when called with NULL_PTR
 */
__attribute__((pure)) const char_t *pfe_phy_if_get_name(const pfe_phy_if_t *iface)
{
    const char_t *str;

    if (NULL_PTR != iface)
    {
        str = iface->name;
    }
    else
    {
        NXP_LOG_WARNING("NULL argument received for pfe_phy_if_get_name\n");
        str = "(unknown)";
    }

    return str;
}

/**
 * @brief       Get phy interface statistics
 * @param[in]   iface The interface instance
 * @param[out]  stat Statistic structure
 * @retval      EOK Success
 * @retval      NOMEM Not possible to allocate memory for read
 */
errno_t pfe_phy_if_get_stats(pfe_phy_if_t *iface, pfe_ct_phy_if_stats_t *stat)
{
    errno_t ret;
    pfe_platform_rpc_pfe_phy_if_stats_arg_t arg = {0};
    pfe_platform_rpc_pfe_phy_if_stats_ret_t rpc_ret = {0};

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == iface) || (NULL == stat)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)pfe_phy_if_db_lock();

        arg.phy_if_id = ((uint8)iface->id);
        ret = pfe_idex_master_rpc((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_STATS, &arg, (uint16)sizeof(arg), &rpc_ret, (uint16)sizeof(rpc_ret));
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("PFE_PLATFORM_RPC_PFE_PHY_IF_IS_STATS failed: %d\n", ret);
        }
        else
        {
            (void)autolibc_memcpy(stat,&rpc_ret.stats,sizeof(rpc_ret.stats));
        }

        (void)pfe_phy_if_db_unlock();
    }

    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return physical interface runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   iface       The physical interface instance
 * @param[in]   buf         A pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_phy_if_get_text_statistics(const pfe_phy_if_t *iface, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

    (void)verb_level;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == iface))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "[PhyIF 0x%x]: Unable to read DMEM (not implemented)\n", iface->id);
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_PFE_SLAVE */


===== 文件 [177/185]: src\pfe_platform_master.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"

#ifdef PFE_CFG_PFE_MASTER
#include "elf_cfg.h"
#include "elf.h"

#include "hal.h"

#include "pfe_hm.h"
#include "pfe_cbus.h"
#include "pfe_hif.h"
#include "pfe_platform_cfg.h"
#include "pfe_platform.h"
#include "pfe_ct.h"
#include "pfe_idex.h"
#include "pfe_feature_mgr.h"
#include "pfe_global_wsp.h"
#include "pfe_gpi_csr.h"
#include "pfe_hif_csr.h"
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    #include "pfe_hif_nocpy_csr.h"
#endif
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    #include "pfe_platform_rpc.h" /* RPC codes and arguments */
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
#ifdef PFE_CFG_FLEX_PARSER_AND_FILTER
    #include "pfe_fp.h"
#endif /* PFE_CFG_FLEX_PARSER_AND_FILTER */
#ifdef PFE_CFG_FCI_ENABLE
    #include "fci.h"
#endif /* PFE_CFG_FCI_ENABLE */

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BMU_MEM
#include "Eth_43_PFE_MemMap.h"
/* This is the PFE system buffers. The linker/MemMap should be configured to align this section to its size.
The size depend on tresos configuration. Refer to Integration Manual for more information. */
uint8 pfe_bmu_buffers[PFE_CFG_BMU2_BUF_COUNT * PFE_CFG_BMU2_BUF_SIZE];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BMU_MEM
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

static pfe_platform_t pfe = {.probed = FALSE};

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
#define ETH_43_PFE_START_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
/* When BMU is created, bmu empty interrupt will occur. We need this variable to detect whether BMU was created successfully or not  */
volatile bool_t bDetectBmuInit = FALSE;
#define ETH_43_PFE_STOP_SEC_VAR_INIT_BOOLEAN
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_BMU_IRQ_ENABLED */

#ifdef PFE_CFG_RTABLE_ENABLE
#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief   Routing table heap alignment
 */
#define RT_ALIGNMENT 2048U

__attribute__((aligned(RT_ALIGNMENT))) uint8 pfe_rtable_buffers[(PFE_CFG_RT_HASH_SIZE + PFE_CFG_RT_COLLISION_SIZE) * sizeof(pfe_ct_rtable_entry_t)];
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED_BUF_MEM
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_RTABLE_ENABLE */

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static void pfe_platform_destroy_pfe_log_ifs(pfe_platform_t *platform);
static void pfe_platform_destroy_pfe_phy_ifs(pfe_platform_t *platform);
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
static errno_t check_irq_vector(pfe_platform_t *platform, const pfe_platform_config_t *config);
#endif /* PFE_CFG_BMU_IRQ_ENABLED */

typedef struct
{
    const char_t *name;
    pfe_ct_phy_if_id_t id;
    pfe_mac_addr_t __attribute__((aligned(4))) mac;
    struct
    {
        pfe_emac_t *emac;
        pfe_gpi_t *gpi;
        pfe_hif_chnl_t *chnl;
    } phy;
} pfe_platform_pfy_if;
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
/**
 * @brief       BMU interrupt service routine
 * @details     Manage BMU interrupt
 * @details     See the oal_irq_handler_t
 */
static bool_t pfe_platform_bmu_isr(void *arg)
{
    const pfe_platform_t *platform = (pfe_platform_t *)arg;
    bool_t handled = FALSE;

    if (NULL != platform->bmu[0U])
    {
        pfe_bmu_irq_mask(platform->bmu[0U]);
    }

    if (NULL != platform->bmu[1U])
    {
        pfe_bmu_irq_mask(platform->bmu[1U]);
    }

    if (EOK == pfe_bmu_isr(platform->bmu[0U]))
    {
        handled |= TRUE;
    }

    if (EOK == pfe_bmu_isr(platform->bmu[1U]))
    {
        handled |= TRUE;
    }

    if (NULL != platform->bmu[0U])
    {
        pfe_bmu_irq_unmask(platform->bmu[0U]);
    }

    if (NULL != platform->bmu[1U])
    {
        pfe_bmu_irq_unmask(platform->bmu[1U]);
    }

    return handled;
}
#endif /* PFE_CFG_BMU_IRQ_ENABLED */

#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
/**
 * @brief       IDEX RPC callback
 * @details     All requests from slave drivers are coming and being processed
 *              within this callback. Any request policing should be implemented
 *              here.
 * @warning     Don't block or sleep within the body
 * @param[in]   sender RPC originator identifier. The physical interface ID
 *                     where the request is coming from.
 * @param[in]   id Request identifier
 * @param[in]   buf Pointer to request argument. Can be NULL.
 * @param[in]   buf_len Length of request argument. Can be zero.
 * @param[in]   arg Custom argument provided via pfe_idex_set_rpc_cbk()
 * @note        This callback runs in dedicated context/thread.
 */
void pfe_platform_idex_rpc_cbk(pfe_ct_phy_if_id_t sender, uint32 id, void *buf, uint16 buf_len, void *arg)
{
    pfe_platform_t *platform = (pfe_platform_t *)arg;
    pfe_phy_if_t *phy_if_arg = NULL;
    pfe_if_db_entry_t *entry = NULL;
    errno_t ret = EOK;

    (void)buf_len;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == platform))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check if phy_if should be extracted from argument */
        if( ((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ID_COMPATIBLE_FIRST <= id) &&
            ((uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ID_COMPATIBLE_LAST >= id)
          )
        {
            ret = pfe_if_db_get_first(  platform->phy_if_db, (uint32)sender, IF_DB_CRIT_BY_ID,
                                        (void *)(addr_t)((pfe_platform_rpc_pfe_phy_if_generic_t*)buf)->phy_if_id, &entry);
            if((EOK == ret) && (NULL != entry))
            {
                phy_if_arg = pfe_if_db_entry_get_phy_if(entry);
            }
            else
            {
                /* Entry doesn't exist */
                ret = ENOENT;
            }
        }

        switch (id)
        {
            case (uint32)PFE_PLATFORM_RPC_PFE_IF_LOCK:
            {
                ret = pfe_if_db_lock_owned((uint32)sender);

                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }
                /* start timeout*/
                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_IF_UNLOCK:
            {
                ret = pfe_if_db_unlock((uint32)sender);

                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }
                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_CREATE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_CREATE\n");

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ENABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_ENABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_enable(phy_if_arg);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_DISABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_DISABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_disable(phy_if_arg);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_ENABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_ENABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_promisc_enable(phy_if_arg);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_DISABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_PROMISC_DISABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_promisc_disable(phy_if_arg);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_ENABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_ENABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_loopback_enable(phy_if_arg);
                }

                /*      Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_DISABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_LOOPBACK_DISABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_loopback_disable(phy_if_arg);
                }

                /*      Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_ENABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_loadbalance_enable(phy_if_arg);
                }

                /*      Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_LOADBALANCE_DISABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_loadbalance_disable(phy_if_arg);
                }

                /*      Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_ENABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_ENABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_allmulti_enable(phy_if_arg);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_DISABLE:
            {
                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_ALLMULTI_DISABLE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_allmulti_disable(phy_if_arg);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_ADD_MAC_ADDR:
            {
                pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t *rpc_arg = (pfe_platform_rpc_pfe_phy_if_add_mac_addr_arg_t *)buf;
                pfe_mac_addr_t mac_addr;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_ADD_MAC_ADDR\n");

                if (EOK == ret)
                {
                    ct_assert(sizeof(pfe_mac_addr_t) == sizeof(rpc_arg->mac_addr));
                    (void)autolibc_memcpy(&mac_addr, rpc_arg->mac_addr, sizeof(pfe_mac_addr_t));
                    ret = pfe_phy_if_add_mac_addr(phy_if_arg, mac_addr, sender);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_DEL_MAC_ADDR:
            {
                pfe_platform_rpc_pfe_phy_if_del_mac_addr_arg_t *rpc_arg = (pfe_platform_rpc_pfe_phy_if_del_mac_addr_arg_t *)buf;
                pfe_mac_addr_t mac_addr;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_DEL_MAC_ADDR\n");

                if (EOK == ret)
                {
                    ct_assert(sizeof(pfe_mac_addr_t) == sizeof(rpc_arg->mac_addr));
                    (void)autolibc_memcpy(&mac_addr, rpc_arg->mac_addr, sizeof(pfe_mac_addr_t));
                    ret = pfe_phy_if_del_mac_addr(phy_if_arg, mac_addr, sender);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_FLUSH_MAC_ADDRS:
            {
                pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t *rpc_arg = (pfe_platform_rpc_pfe_phy_if_flush_mac_addrs_arg_t *)buf;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_FLUSH_MAC_ADDRS\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_flush_mac_addrs(phy_if_arg, rpc_arg->crit, rpc_arg->type, sender);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE:
            {
                pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t *rpc_arg = (pfe_platform_rpc_pfe_phy_if_set_block_state_arg_t *)buf;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_SET_BLOCK_STATE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_set_block_state(phy_if_arg, rpc_arg->block_state);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE:
            {
                pfe_platform_rpc_pfe_phy_if_get_block_state_ret_t rpc_ret = {IF_BS_FORWARDING};
                pfe_ct_block_state_t block_state = IF_BS_FORWARDING;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_GET_BLOCK_STATE\n");

                if (EOK == ret)
                {
                    ret = pfe_phy_if_get_block_state(phy_if_arg, &block_state);
                    rpc_ret.state = block_state;
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_GET_OP_MODE:
            {
                pfe_platform_rpc_pfe_phy_if_get_op_mode_ret_t rpc_ret = {IF_OP_DEFAULT};
                pfe_ct_if_op_mode_t mode = IF_OP_DEFAULT;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_GET_OP_MODE\n");

                if (EOK == ret)
                {
                    mode = pfe_phy_if_get_op_mode(phy_if_arg);
                    rpc_ret.mode = mode;
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_IS_ENABLED:
            {
                pfe_platform_rpc_pfe_phy_if_is_enabled_ret_t rpc_ret = {0};
                bool_t status = FALSE;


                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_IS_ENABLED\n");

                if (EOK == ret)
                {
                    status = pfe_phy_if_is_enabled(phy_if_arg);
                    rpc_ret.status = status;
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_IS_PROMISC:
            {
                pfe_platform_rpc_pfe_phy_if_is_promisc_ret_t rpc_ret = {0};
                bool_t status = FALSE;


                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_IS_PROMISC\n");

                if (EOK == ret)
                {
                    status = pfe_phy_if_is_promisc(phy_if_arg);
                    rpc_ret.status = status;
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_STATS:
            {
                pfe_platform_rpc_pfe_phy_if_stats_ret_t rpc_ret = {0};

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_STATS\n");

                if (EOK == ret)
                {
                    ct_assert(sizeof(pfe_ct_phy_if_stats_t) == sizeof(rpc_ret.stats));
                    ret = pfe_phy_if_get_stats(phy_if_arg, &rpc_ret.stats);
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

            case (uint32)PFE_PLATFORM_RPC_PFE_PHY_IF_GET_STAT_VALUE:
            {
                pfe_platform_rpc_pfe_phy_if_get_stat_value_arg_t *rpc_arg = (pfe_platform_rpc_pfe_phy_if_get_stat_value_arg_t *)buf;
                pfe_platform_rpc_pfe_phy_if_get_stat_value_ret_t rpc_ret = {0};
                uint32 stat_val = 0U;
                pfe_emac_t *emac;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_GET_STAT_VALUE\n");

                if (EOK == ret)
                {
                    if (2U < rpc_arg->phy_if_id)
                    {
                        NXP_LOG_ERROR("RPC: PFE_PLATFORM_RPC_PFE_PHY_IF_GET_STAT_VALUE: invalid EMAC id: %d\n", rpc_arg->phy_if_id);
                        /*  Report execution status to caller */
                        if (EOK != pfe_idex_set_rpc_ret_val(EINVAL, NULL, 0U))
                        {
                            NXP_LOG_ERROR("Could not send RPC response\n");
                        }
                        break;
                    }
                    else
                    {
                        emac = pfe.emac[rpc_arg->phy_if_id];
                        stat_val = pfe_emac_get_stat_value(emac, rpc_arg->stat_id);
                        rpc_ret.stat_val = stat_val;
                    }
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }

    #if defined(PFE_CFG_FCI_ENABLE)
            case (uint32)PFE_PLATFORM_RPC_PFE_FCI_PROXY:
            {
                pfe_platform_rpc_pfe_fci_proxy_arg_t *rpc_arg = (pfe_platform_rpc_pfe_fci_proxy_arg_t *)buf;
                pfe_platform_rpc_pfe_fci_proxy_ret_t rpc_ret = {0};

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_PFE_FCI_PROXY\n");

                if (EOK == ret)
                {
                    ct_assert(sizeof(msg_type_t) == sizeof(rpc_arg->type));
                    ct_assert(sizeof(fci_msg_cmd_t) == sizeof(rpc_arg->msg_cmd));

                    /* Construct platform-specific FCI message. Use received platform-independent data. */
                    fci_msg_t msg;
                    autolibc_memcpy(&msg.type,    &rpc_arg->type,   sizeof(msg.type));
                    autolibc_memcpy(&msg.msg_cmd, &rpc_arg->msg_cmd,sizeof(msg.msg_cmd));
                    fci_msg_t rep_msg = {.type=FCI_MSG_CMD, .msg_cmd={0}};

                    /* Set sender / originator's interface */
                    msg.msg_cmd.sender = (uint32)sender;

                    /* Process the FCI message. */
                    ret = fci_process_ipc_message(&msg, &rep_msg);

                    /* Fill the RPC reply. */
                    rpc_ret.msg_cmd = rep_msg.msg_cmd;
                }

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }
    #endif /* PFE_CFG_FCI_ENABLE */

            case (uint32)PFE_PLATFORM_RPC_MDIO_PROXY:
            {
                pfe_platform_rpc_mdio_proxy_arg_t *rpc_arg = (pfe_platform_rpc_mdio_proxy_arg_t *)buf;
                pfe_platform_rpc_mdio_proxy_ret_t rpc_ret = {0};
                pfe_emac_t *emac;
                uint32 key;

                NXP_LOG_DEBUG("RPC: PFE_PLATFORM_RPC_MDIO_PROXY\n");
                if (EOK == ret)
                {
                    if (2U < rpc_arg->emac_id)
                    {
                        NXP_LOG_ERROR("RPC: PFE_PLATFORM_RPC_MDIO_PROXY: invalid EMAC id: %d\n", rpc_arg->emac_id);
                        /*  Report execution status to caller */
                        if (EOK != pfe_idex_set_rpc_ret_val(EINVAL, NULL, 0U))
                        {
                            NXP_LOG_ERROR("Could not send RPC response\n");
                        }
                    }
                    else
                    {
                        emac = pfe.emac[rpc_arg->emac_id];
                        /* Lock the MDIO bus */
                        ret = pfe_emac_mdio_lock(emac, &key);
                        if (EOK == ret)
                        {
                            /* Process the MDIO OP message */
                            switch (rpc_arg->op)
                            {
                                case PFE_PLATFORM_RPC_MDIO_OP_READ_CL22:
                                {
                                    ret = pfe_emac_mdio_read22(emac, rpc_arg->pa, (uint8)rpc_arg->ra, &rpc_ret.val, key);
                                    /*  Report execution status to caller */
                                    if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                                    {
                                        NXP_LOG_ERROR("Could not send RPC response\n");
                                    }
                                    break;
                                }
                                case PFE_PLATFORM_RPC_MDIO_OP_WRITE_CL22:
                                {
                                    ret = pfe_emac_mdio_write22(emac, rpc_arg->pa, (uint8)rpc_arg->ra, rpc_arg->val, key);
                                    /*  Report execution status to caller */
                                    if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                                    {
                                        NXP_LOG_ERROR("Could not send RPC response\n");
                                    }
                                    break;
                                }
                                case PFE_PLATFORM_RPC_MDIO_OP_READ_CL45:
                                {
                                    ret = pfe_emac_mdio_read45(emac, rpc_arg->pa, rpc_arg->dev, rpc_arg->ra, &rpc_ret.val, key);
                                    /*  Report execution status to caller */
                                    if (EOK != pfe_idex_set_rpc_ret_val(ret, &rpc_ret, (uint16)sizeof(rpc_ret)))
                                    {
                                        NXP_LOG_ERROR("Could not send RPC response\n");
                                    }
                                    break;
                                }
                                case PFE_PLATFORM_RPC_MDIO_OP_WRITE_CL45:
                                {
                                    ret = pfe_emac_mdio_write45(emac, rpc_arg->pa, rpc_arg->dev, rpc_arg->ra, rpc_arg->val, key);
                                    /*  Report execution status to caller */
                                    if (EOK != pfe_idex_set_rpc_ret_val(ret, NULL, 0U))
                                    {
                                        NXP_LOG_ERROR("Could not send RPC response\n");
                                    }
                                    break;
                                }
                                default:
                                {
                                    NXP_LOG_ERROR("Invalid MDIO operation\n");
                                    /*  Report execution status to caller */
                                    if (EOK != pfe_idex_set_rpc_ret_val(EINVAL, NULL, 0U))
                                    {
                                        NXP_LOG_ERROR("Could not send RPC response\n");
                                    }
                                    break;
                                }
                            }
                            /* Unlock the locked MDIO bus */
                            (void)pfe_emac_mdio_unlock(emac, key);
                        }
                        else
                        {
                            NXP_LOG_ERROR("Lock the MDIO bus failed\n");
                            /*  Report execution status to caller */
                            if (EOK != pfe_idex_set_rpc_ret_val(EPERM, NULL, 0U))
                            {
                                NXP_LOG_ERROR("Could not send RPC response\n");
                            }
                        }
                    }
                }
                break;
            }

            default:
            {
                NXP_LOG_WARNING("Unsupported RPC code: %u\n", (uint_t)id);

                /*  Report execution status to caller */
                if (EOK != pfe_idex_set_rpc_ret_val(EINVAL, NULL, 0U))
                {
                    NXP_LOG_ERROR("Could not send RPC response\n");
                }

                break;
            }
        }
    }
}
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

/**
 * @brief       Assign HIF to the platform
 */
static errno_t pfe_platform_create_hif(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    errno_t ret;
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    /* Set FCI ownership configuration */
    platform->hif_fci_owner_chnls_mask = config->hif_fci_owner_chnls_mask;
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
    platform->hif = pfe_hif_create(platform->cbus_baseaddr + CBUS_HIF_BASE_ADDR, config->hif_chnls_mask);
    if (NULL == platform->hif)
    {
        NXP_LOG_ERROR("Couldn't create HIF instance\n");
        ret = ENODEV;
    }
    else
    {
    #ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        pfe_hif_set_master_detect_cfg(platform->hif, !config->disable_master_detect);
    #endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

        pfe_hif_irq_unmask(platform->hif);

    #ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        /* Clean Master detect flags for all HIF channels */
        pfe_hif_clear_master_up(platform->hif);
    #endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */

#if !defined (PFE_CFG_HIF_NOCPY_SUPPORT) /* Applicable only if HIF is a local HIF */
        /* Give local instance ownership of all EMAC timers */
        pfe_hif_init_emac_timer_ownership(platform->hif);
#endif

        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Release HIF-related resources
 */
static void pfe_platform_destroy_hif(pfe_platform_t *platform)
{
    if (NULL != platform->hif)
    {
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
        /* Clean Master detect flags for all HIF channels */
        pfe_hif_clear_master_up(platform->hif);
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
        pfe_hif_irq_mask(platform->hif);
        pfe_hif_destroy(platform->hif);
        platform->hif = NULL;
    }
}

/**
 * @brief       Assign HIF NOCPY to the platform
 */
static errno_t pfe_platform_create_hif_nocpy(pfe_platform_t *platform)
{
    uint16 lmem_header_size;
    errno_t ReVal;

    if(PFE_S32G3_VERSION == platform->pfe_version)
    {   /* S32G3 */
        lmem_header_size = 48U;
    }
    else
    {   /* S32G2 */
        lmem_header_size = 112U;
    }

    platform->hif_nocpy = pfe_hif_nocpy_create(pfe.cbus_baseaddr + CBUS_HIF_NOCPY_BASE_ADDR, platform->bmu[1U], lmem_header_size);

    if (NULL == platform->hif_nocpy)
    {
        NXP_LOG_ERROR("Couldn't create HIF NOCPY instance\n");
        ReVal = ENODEV;
    }
    else
    {

#if defined (PFE_CFG_HIF_NOCPY_SUPPORT) /* Applicable only if the local HIF is HIF_NOCPY */
        /* Give local instance ownership of all EMAC timers*/
        pfe_hif_nocpy_init_emac_timer_ownership(platform->hif_nocpy);
#endif
        ReVal = EOK;
    }

    return ReVal;
}

#if defined (PFE_CFG_HIF_NOCPY_SUPPORT)
/**
 * @brief       Release HIF-related resources
 */
static void pfe_platform_destroy_hif_nocpy(pfe_platform_t *platform)
{
    if (NULL != platform->hif_nocpy)
    {
        if (NULL != platform->irq_hif_nocpy)
        {
            oal_irq_destroy(platform->irq_hif_nocpy);
            platform->irq_hif_nocpy = NULL;
        }

        pfe_hif_nocpy_destroy(platform->hif_nocpy);
        platform->hif_nocpy = NULL;
    }
}
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */

#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
/**
 * @brief       Check irq assignment BMU to the platform
 */
static errno_t check_irq_vector(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    if (NULL == platform->irq_bmu)
    {
        NXP_LOG_ERROR("Could not create BMU IRQ vector %u\n", (uint_t)config->irq_vector_bmu);
        ret = ENODEV;
    }
    else
    {
        if (EOK != oal_irq_add_handler(platform->irq_bmu, &pfe_platform_bmu_isr, platform, NULL))
        {
            NXP_LOG_ERROR("Could not add IRQ handler for the BMU[0]\n");
            ret = ENODEV;
        }
        else
        {
            pfe_bmu_irq_unmask(platform->bmu[0U]);
            pfe_bmu_irq_unmask(platform->bmu[1U]);
            bDetectBmuInit = TRUE;
            ret = EOK;
        }
    }

    return ret;
}
#endif /* PFE_CFG_BMU_IRQ_ENABLED */

/**
 * @brief       Assign BMU to the platform
 */
static errno_t pfe_platform_create_bmu(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    pfe_bmu_cfg_t bmu_cfg = {0U};
    errno_t ret = EOK;

    /*  Must be aligned to BUF_COUNT * BUF_SIZE (assured by fixed configuration) */
    bmu_cfg.pool_pa = (PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_LMEM_BASE_ADDR + PFE_CFG_BMU1_LMEM_BASEADDR);
    NXP_LOG_INFO("BMU1 buffer base: p0x%"PRINTADDR_T"\n", bmu_cfg.pool_pa);
    bmu_cfg.max_buf_cnt = PFE_CFG_BMU1_BUF_COUNT;
    bmu_cfg.buf_size = PFE_CFG_BMU1_BUF_SIZE;
    bmu_cfg.bmu_ucast_thres = 0x200U;
    bmu_cfg.bmu_mcast_thres = 0x200U;
    bmu_cfg.int_mem_loc_cnt = 64U;
    bmu_cfg.buf_mem_loc_cnt = 64U;

    platform->bmu[1U] = NULL;
    platform->bmu[0U] = pfe_bmu_create(platform->cbus_baseaddr, CBUS_BMU1_BASE_ADDR, &bmu_cfg, 0U);
    if (NULL == platform->bmu[0U])
    {
        NXP_LOG_ERROR("Couldn't create BMU1 instance\n");
        ret = ENODEV;
    }
    else if (2U > platform->bmu_count)
    {
        NXP_LOG_WARNING("Only single BMU was configured.\n");
        ret = EOK;
    }
    /*  Must be aligned to BUF_COUNT * BUF_SIZE */
    else if(0U != ((addr_t)pfe_bmu_buffers % (PFE_CFG_BMU2_BUF_COUNT * PFE_CFG_BMU2_BUF_SIZE)))
    {
        NXP_LOG_ERROR("The BMU memory is not properly aligned\n");
        ret = EINVAL;
    }
    else
    {
        platform->bmu_buffers_size = PFE_CFG_BMU2_BUF_COUNT * PFE_CFG_BMU2_BUF_SIZE;
        platform->bmu_buffers_va = pfe_bmu_buffers;
        bmu_cfg.pool_va = (addr_t)platform->bmu_buffers_va;
        bmu_cfg.pool_pa = (addr_t)platform->bmu_buffers_va;

        /*  S32G: Some of PFE AXI MASTERs can only access range p0x00020000 - p0xbfffffff */
        if (((addr_t)bmu_cfg.pool_pa < 0x00020000U) || (((addr_t)bmu_cfg.pool_pa + platform->bmu_buffers_size) > 0xbfffffffU))
        {
            NXP_LOG_WARNING("BMU2 buffers not in required range: starts @ p0x%"PRINTADDR_T"\n", bmu_cfg.pool_pa);
        }
        else
        {
            NXP_LOG_INFO("BMU2 buffer base: p0x%"PRINTADDR_T" (0x%"PRINTADDR_T" bytes)\n", bmu_cfg.pool_pa, platform->bmu_buffers_size);
        }

        bmu_cfg.max_buf_cnt = PFE_CFG_BMU2_BUF_COUNT;
        bmu_cfg.buf_size = PFE_CFG_BMU2_BUF_SIZE;
        bmu_cfg.bmu_ucast_thres = 0x800U;
        bmu_cfg.bmu_mcast_thres = 0x200U;
        bmu_cfg.int_mem_loc_cnt = 1024U;
        bmu_cfg.buf_mem_loc_cnt = 1024U;

        platform->bmu[1U] = pfe_bmu_create(platform->cbus_baseaddr, CBUS_BMU2_BASE_ADDR, &bmu_cfg, 1U);
        if (NULL == platform->bmu[1U])
        {
            NXP_LOG_ERROR("Couldn't create BMU2 instance\n");
            ret = ENODEV;
        }
#if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
        else
        {
            platform->irq_bmu = oal_irq_create((sint32)config->irq_vector_bmu, (oal_irq_flags_t)0, "PFE BMU IRQ");
            ret = check_irq_vector(platform, config);
        }
#endif /* PFE_CFG_BMU_IRQ_ENABLED */
    }
    (void)config;

    return ret;
}

/**
 * @brief       Release BMU-related resources
 */
static void pfe_platform_destroy_bmu(pfe_platform_t *platform)
{
    uint32 ii;

    for (ii=0; ii<pfe.bmu_count; ii++)
    {
        if (platform->bmu[ii] != NULL)
        {
            pfe_bmu_destroy(platform->bmu[ii]);
            platform->bmu[ii] = NULL;
        }
    }

    #if (TRUE == PFE_CFG_BMU_IRQ_ENABLED)
    if (NULL != platform->irq_bmu)
    {
        oal_irq_destroy(platform->irq_bmu);
        platform->irq_bmu = NULL;
    }
    bDetectBmuInit = FALSE;
    #endif /* PFE_CFG_BMU_IRQ_ENABLED */

    platform->bmu_buffers_va = NULL;
}

/**
 * @brief       Assign GPI to the platform
 */
static errno_t pfe_platform_create_gpi(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    pfe_gpi_cfg_t gpi_cfg_tmp;
    uint32 aseq_len = 0x50U;
    errno_t ret;

    if(PFE_S32G3_VERSION == platform->pfe_version)
    {   /* S32G3 */
        gpi_cfg_tmp.lmem_header_size = 48U;
        gpi_cfg_tmp.g2_ordered_class_writes = FALSE;
        aseq_len = 0x10U;
    }
    else
    {   /* S32G2 */
        gpi_cfg_tmp.lmem_header_size = 112U;
        gpi_cfg_tmp.g2_ordered_class_writes = config->g2_ordered_class_writes;
    }

    /*  GPI1 */
    gpi_cfg_tmp.alloc_retry_cycles = 0x200U;
    gpi_cfg_tmp.gpi_tmlf_txthres = 0x178U;
    gpi_cfg_tmp.gpi_dtx_aseq_len = aseq_len; /* See AAVB-2028 */
    gpi_cfg_tmp.emac_1588_ts_en = TRUE;

    platform->gpi[0U] = pfe_gpi_create(platform->cbus_baseaddr, CBUS_EGPI1_BASE_ADDR, &gpi_cfg_tmp, PFE_GPI_1);
    if (NULL == platform->gpi[0])
    {
        NXP_LOG_ERROR("Couldn't create GPI1 instance\n");
        ret = ENODEV;
    }
    else
    {
        /*  GPI2 */
        gpi_cfg_tmp.alloc_retry_cycles = 0x200U;
        gpi_cfg_tmp.gpi_tmlf_txthres = 0x178U;
        gpi_cfg_tmp.gpi_dtx_aseq_len = aseq_len; /* See AAVB-2028 */
        gpi_cfg_tmp.emac_1588_ts_en = TRUE;

        platform->gpi[1U] = pfe_gpi_create(platform->cbus_baseaddr, CBUS_EGPI2_BASE_ADDR, &gpi_cfg_tmp, PFE_GPI_2);
        if (NULL == platform->gpi[1U])
        {
            NXP_LOG_ERROR("Couldn't create GPI2 instance\n");
            ret = ENODEV;
        }
        else
        {
            /*  GPI3 */
            gpi_cfg_tmp.alloc_retry_cycles = 0x200U;
            gpi_cfg_tmp.gpi_tmlf_txthres = 0x178U;
            gpi_cfg_tmp.gpi_dtx_aseq_len = aseq_len; /* See AAVB-2028 */
            gpi_cfg_tmp.emac_1588_ts_en = TRUE;

            platform->gpi[2U] = pfe_gpi_create(platform->cbus_baseaddr, CBUS_EGPI3_BASE_ADDR, &gpi_cfg_tmp, PFE_GPI_3);
            if (NULL == platform->gpi[2U])
            {
                NXP_LOG_ERROR("Couldn't create GPI3 instance\n");
                ret = ENODEV;
            }
            else
            {
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
 * @brief       Release GPI-related resources
 */
static void pfe_platform_destroy_gpi(pfe_platform_t *platform)
{
    uint32 ii;

    for (ii=0U; ii<platform->gpi_count; ii++)
    {
        if (NULL != platform->gpi[ii])
        {
            pfe_gpi_destroy(platform->gpi[ii]);
            platform->gpi[ii] = NULL;
        }
    }
}

/**
 * @brief       Assign ETGPI to the platform
 */
static errno_t pfe_platform_create_etgpi(pfe_platform_t *platform)
{
    pfe_gpi_cfg_t gpi_cfg_tmp;
    errno_t ret;
    uint32 aseq_len = 0x40U;

    if(PFE_S32G3_VERSION == platform->pfe_version)
    {   /* S32G3 */
        gpi_cfg_tmp.lmem_header_size = 48U;
        gpi_cfg_tmp.g2_ordered_class_writes = FALSE;
        aseq_len = 0x10U;
    }
    else
    {   /* S32G2 */
        gpi_cfg_tmp.lmem_header_size = 112U;
#ifdef PFE_CFG_G2_ORDERED_CLASS_WRITES
        gpi_cfg_tmp.g2_ordered_class_writes = TRUE;
#else
        gpi_cfg_tmp.g2_ordered_class_writes = FALSE;
#endif
    }

    /*  ETGPI1 */
    gpi_cfg_tmp.alloc_retry_cycles = 0x200U;
    gpi_cfg_tmp.gpi_tmlf_txthres = 0xbcU;
    gpi_cfg_tmp.gpi_dtx_aseq_len = aseq_len;
    gpi_cfg_tmp.emac_1588_ts_en = TRUE;

    platform->etgpi[0U] = pfe_gpi_create(platform->cbus_baseaddr, CBUS_ETGPI1_BASE_ADDR, &gpi_cfg_tmp, PFE_ETGPI_1);
    if (NULL == platform->etgpi[0U])
    {
        NXP_LOG_ERROR("Couldn't create ETGPI1 instance\n");
        ret = ENODEV;
    }
    else
    {
        /*  ETGPI2 */
        gpi_cfg_tmp.alloc_retry_cycles = 0x200U;
        gpi_cfg_tmp.gpi_tmlf_txthres = 0xbcU;
        gpi_cfg_tmp.gpi_dtx_aseq_len = aseq_len;
        gpi_cfg_tmp.emac_1588_ts_en = TRUE;

        platform->etgpi[1U] = pfe_gpi_create(platform->cbus_baseaddr, CBUS_ETGPI2_BASE_ADDR, &gpi_cfg_tmp, PFE_ETGPI_2);
        if (NULL == platform->etgpi[1U])
        {
            NXP_LOG_ERROR("Couldn't create ETGPI2 instance\n");
            ret = ENODEV;
        }
        else
        {
            /*  ETGPI3 */
            gpi_cfg_tmp.alloc_retry_cycles = 0x200U;
            gpi_cfg_tmp.gpi_tmlf_txthres = 0xbcU;
            gpi_cfg_tmp.gpi_dtx_aseq_len = aseq_len;
            gpi_cfg_tmp.emac_1588_ts_en = TRUE;

            platform->etgpi[2U] = pfe_gpi_create(platform->cbus_baseaddr, CBUS_ETGPI3_BASE_ADDR, &gpi_cfg_tmp, PFE_ETGPI_3);
            if (NULL == platform->etgpi[2U])
            {
                NXP_LOG_ERROR("Couldn't create ETGPI3 instance\n");
                ret = ENODEV;
            }
            else
            {
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
 * @brief       Release ETGPI-related resources
 */
static void pfe_platform_destroy_etgpi(pfe_platform_t *platform)
{
    uint32 ii;

    for (ii=0U; ii<platform->etgpi_count; ii++)
    {
        if (platform->etgpi[ii] != NULL)
        {
            pfe_gpi_destroy(platform->etgpi[ii]);
            platform->etgpi[ii] = NULL;
        }
    }
}

/**
 * @brief       Assign HGPI to the platform
 */
static errno_t pfe_platform_create_hgpi(pfe_platform_t *platform)
{
    pfe_gpi_cfg_t hgpi_cfg;
    errno_t ret;
    uint32 aseq_len = HGPI_ASEQ_LEN;

    if(PFE_S32G3_VERSION == platform->pfe_version)
    {   /* S32G3 */
        hgpi_cfg.lmem_header_size = 48U;
        hgpi_cfg.g2_ordered_class_writes = FALSE;
        aseq_len = 0x10;
    }
    else
    {   /* S32G2 */
        hgpi_cfg.lmem_header_size = 112U;
#ifdef PFE_CFG_G2_ORDERED_CLASS_WRITES
        hgpi_cfg.g2_ordered_class_writes = TRUE;
#else
        hgpi_cfg.g2_ordered_class_writes = FALSE;
#endif
    }

    hgpi_cfg.alloc_retry_cycles = 0x200U;
    hgpi_cfg.gpi_tmlf_txthres = 0x178U;
    hgpi_cfg.gpi_dtx_aseq_len = aseq_len;
    hgpi_cfg.emac_1588_ts_en = FALSE;

    platform->hgpi[0U] = pfe_gpi_create(platform->cbus_baseaddr, CBUS_HGPI_BASE_ADDR, &hgpi_cfg, PFE_HGPI_1);
    if (NULL == platform->hgpi[0U])
    {
        NXP_LOG_ERROR("Couldn't create HGPI instance\n");
        ret = ENODEV;
    }
    else
    {
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Release GPI-related resources
 */
static void pfe_platform_destroy_hgpi(pfe_platform_t *platform)
{
    uint32 ii;

    for (ii=0U; ii<platform->hgpi_count; ii++)
    {
        if (NULL != platform->hgpi[ii])
        {
            pfe_gpi_destroy(platform->hgpi[ii]);
            platform->hgpi[ii] = NULL;
        }
    }
}

/**
 * @brief       Assign CLASS to the platform
 */
static errno_t pfe_platform_create_class_object(pfe_platform_t *platform, pfe_class_cfg_t class_cfg)
{
    errno_t ret = EOK;
    ELF_File_t elf;
    const uint8 *temp;

    if(PFE_S32G3_VERSION == platform->pfe_version)
    {   /* S32G3 */
        class_cfg.lmem_header_size = 48U;
        class_cfg.ro_header_size = 512U;
    }
    else
    {   /* S32G2 */
        class_cfg.lmem_header_size = 112U;
        class_cfg.ro_header_size = 256U;
    }

    platform->classifier = pfe_class_create(platform->cbus_baseaddr, platform->class_pe_count, &class_cfg);

    if (NULL == platform->classifier)
    {
        NXP_LOG_ERROR("Couldn't create classifier instance\n");
        ret = ENODEV;
    }
    else
    {
        temp = (uint8 *)platform->fw->class_data;

        if ((temp[0] == 0x7fU) &&
            (temp[1] == (uint8)('E')) &&
            (temp[2] == (uint8)('L')) &&
            (temp[3] == (uint8)('F')))
        {
            /*  FW is ELF file */
            NXP_LOG_INFO("Firmware .elf detected\n");

            if (FALSE == ELF_Open(&elf, platform->fw->class_data))
            {
                NXP_LOG_ERROR("Can't parse CLASS firmware\n");
                ret = EIO;
            }
            else
            {
                NXP_LOG_INFO("Uploading CLASS firmware\n");
                ret = pfe_class_load_firmware(platform->classifier, &elf);

                ELF_Close(&elf);

                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Error during upload of CLASS firmware: %d\n", ret);
                    ret = EIO;
                }
            }
        }
        else
        {
            NXP_LOG_ERROR("Only ELF format is supported\n");
            ret = ENODEV;
        }
    }
    return ret;
}
/**
 * @brief       Assign CLASS to the platform
 */
static errno_t pfe_platform_create_class(pfe_platform_t *platform, const pfe_platform_config_t *conf)
{
    errno_t ret;
    pfe_class_cfg_t class_cfg =
    {
        .resume = FALSE,
        .toe_mode = FALSE,
        .pe_sys_clk_ratio = PFE_CFG_CLMODE,
        .pkt_parse_offset = 6U, /* This is actually the sizeof(struct hif_hdr) to skip the HIF header */
        .g2_ordered_class_writes = conf->g2_ordered_class_writes,
    };

    if (FALSE != conf->g2_ordered_class_writes)
    {
        if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
        {
            NXP_LOG_WARNING("The option 'g2_ordered_class_writes' has no effect on S32G3\n");
        }
        else
        {
            NXP_LOG_WARNING("The option 'g2_ordered_class_writes' is enabled\n");
        }
    }

    if (NULL == platform->fw)
    {
        NXP_LOG_ERROR("The CLASS firmware is NULL\n");
        ret = ENODEV;
    }

    else if (NULL == platform->fw->class_data)
    {
        NXP_LOG_ERROR("The CLASS firmware is not loaded\n");
        ret = EIO;
    }
    else
    {
        ret = pfe_platform_create_class_object(platform, class_cfg);
    }

    return ret;
}

/**
 * @brief       Release CLASS-related resources
 */
static void pfe_platform_destroy_class(pfe_platform_t *platform)
{
    if (NULL != platform->classifier)
    {
        pfe_class_destroy(platform->classifier);
        platform->classifier = NULL;
    }
}

#if !defined(PFE_CFG_L2BRIDGE_ENABLE)
/**
 * @brief       Init L2 Bridge Memory default
 */
static errno_t pfe_platform_init_l2br_mem(pfe_platform_t *platform)
{
    errno_t ret = EOK;
    pfe_l2br_table_t *mactab = NULL;
    pfe_l2br_table_t *vlantab = NULL;
    mactab = pfe_l2br_table_create(platform->cbus_baseaddr, PFE_L2BR_TABLE_MAC2F);
    if (NULL == mactab)
    {
        NXP_LOG_ERROR("Couldn't create default VLAN table instance\n");
        ret = ENODEV;
    }
    vlantab = pfe_l2br_table_create(platform->cbus_baseaddr, PFE_L2BR_TABLE_VLAN);
    if (NULL == vlantab)
    {
        NXP_LOG_ERROR("Couldn't create default VLAN table instance\n");
        ret = ENODEV;
    }

    return ret;
}
#endif

#if defined(PFE_CFG_L2BRIDGE_ENABLE)
/**
 * @brief       Assign L2 Bridge to the platform
 */
static errno_t pfe_platform_create_l2_bridge(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    uint16 vlan_id = config->vlan_id;
    uint16 vlan_stats_size = config->vlan_stats_size;
    errno_t ret;

    platform->mactab = pfe_l2br_table_create(platform->cbus_baseaddr, PFE_L2BR_TABLE_MAC2F);
    if (NULL == platform->mactab)
    {
        NXP_LOG_ERROR("Couldn't create MAC table instance\n");
        ret = ENODEV;
    }
    else
    {

        platform->vlantab = pfe_l2br_table_create(platform->cbus_baseaddr, PFE_L2BR_TABLE_VLAN);
        if (NULL == platform->vlantab)
        {
            NXP_LOG_ERROR("Couldn't create VLAN table instance\n");
            ret = ENODEV;
        }
        else
        {
            if((vlan_id == 0U) || (vlan_id >= 4095U))
            {
                NXP_LOG_WARNING("VLAN ID incorrect or not set. Using default VLAN ID = 0x01.\n");
                vlan_id = 0x01;
            }

            if ((vlan_stats_size < 2U) || (vlan_stats_size > 128U))
            {
                NXP_LOG_WARNING("VLAN stats size incorrect or not set. Using default VLAN stats size = 20.\n");
                vlan_stats_size = 20;
            }

            platform->l2_bridge = pfe_l2br_create(platform->classifier, vlan_id, 300U, vlan_stats_size, platform->mactab, platform->vlantab);
            if (NULL == platform->l2_bridge)
            {
                NXP_LOG_ERROR("Could not create L2 Bridge\n");
                ret = ENODEV;
            }
            else
            {
                ret = EOK;
            }
        }
    }

    return ret;
}

/**
 * @brief       Release L2 Bridge-related resources
 */
static void pfe_platform_destroy_l2_bridge(pfe_platform_t *platform)
{
    if (NULL != platform->l2_bridge)
    {
        (void)pfe_l2br_destroy(platform->l2_bridge);
        platform->l2_bridge = NULL;
    }

    if (NULL != platform->mactab)
    {
        platform->mactab = NULL;
    }

    if (NULL != platform->vlantab)
    {
        platform->vlantab = NULL;
    }
}
#endif /* PFE_CFG_L2BRIDGE_ENABLE */

#if defined(PFE_CFG_RTABLE_ENABLE)

/**
 * @brief       Assign Routing Table to the platform
 */
static errno_t pfe_platform_create_rtable(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    addr_t htable_mem;
    addr_t pool_mem;
    uint32 pool_offs;
    errno_t ret;
    pfe_class_table_sizes_t temp_table;

    if (config->rtable_hash_size > PFE_CFG_RT_HASH_ENTRIES_MAX_CNT)
    {
        NXP_LOG_ERROR("Required HASH size exceeds allowed range.\n");
        ret = EINVAL;
    }
    else
    {
        pool_offs = config->rtable_hash_size * pfe_rtable_get_entry_size();

        platform->rtable_size = (config->rtable_hash_size + config->rtable_collision_size) * pfe_rtable_get_entry_size();
        platform->rtable_va = pfe_rtable_buffers;

        htable_mem = (addr_t)platform->rtable_va;
        pool_mem = (addr_t)platform->rtable_va + pool_offs;

        if (NULL == platform->classifier)
        {
            NXP_LOG_ERROR("Valid classifier instance required\n");
            ret = ENODEV;
        }
        else
        {
            temp_table.htable_base_va = htable_mem;
            temp_table.htable_size = config->rtable_hash_size;
            temp_table.pool_base_va = pool_mem;
            temp_table.pool_size = config->rtable_collision_size;
            platform->rtable = pfe_rtable_create(platform->classifier, platform->l2_bridge, temp_table);

            if (NULL == platform->rtable)
            {
                NXP_LOG_ERROR("Couldn't create routing table instance\n");
                ret = ENODEV;
            }
            else
            {
                NXP_LOG_INFO("Routing table created, Hash Table @ p0x%"PRINTADDR_T", Pool @ p0x%"PRINTADDR_T" (%u bytes)\n", (addr_t)htable_mem, (addr_t)htable_mem + (addr_t)pool_offs, (uint_t)platform->rtable_size);
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
 * @brief       Release Routing table-related resources
 */
static void pfe_platform_destroy_rtable(pfe_platform_t *platform)
{
    if (NULL != platform->rtable)
    {
        pfe_rtable_destroy(platform->rtable);
        platform->rtable = NULL;
    }

    platform->rtable_va = NULL;
}
#endif /* PFE_CFG_RTABLE_ENABLE */

/**
 * @brief       Assign TMU to the platform
 */
static errno_t pfe_platform_create_tmu(pfe_platform_t *platform)
{
    errno_t ret;
    pfe_tmu_cfg_t tmu_cfg =
    {
        .pe_sys_clk_ratio = PFE_CFG_CLMODE,
        .on_g3 = FALSE,
    };

    tmu_cfg.on_g3 = pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3);
    platform->tmu = pfe_tmu_create(platform->cbus_baseaddr, platform->tmu_pe_count, &tmu_cfg,
                                   platform->classifier);
    if (NULL == platform->tmu)
    {
        NXP_LOG_ERROR("Couldn't create TMU instance\n");
        ret = ENODEV;
    }
    else
    {
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Release TMU-related resources
 */
static void pfe_platform_destroy_tmu(pfe_platform_t *platform)
{
    if (NULL != platform->tmu)
    {
        pfe_tmu_destroy(platform->tmu);
        platform->tmu = NULL;
    }
}

/**
 * @brief       Create Default Util and Init Memory
 */
static errno_t pfe_platform_default_init_util(pfe_platform_t *platform)
{
    errno_t ret;
    pfe_util_cfg_t util_cfg =
    {
        .pe_sys_clk_ratio = PFE_CFG_CLMODE,
    };

    platform->util = pfe_util_create(platform->cbus_baseaddr, platform->util_pe_count, &util_cfg);

    if (NULL == platform->util)
    {
        NXP_LOG_ERROR("Couldn't create UTIL instance\n");
        ret = ENODEV;
    }
    else
    {
        ret = pfe_util_default_init(platform->util);
    }

    return ret;
}

/**
 * @brief       Assign UTIL to the platform
 */
static errno_t pfe_platform_create_util(pfe_platform_t *platform)
{
    errno_t ret;
    pfe_util_cfg_t util_cfg =
    {
        .pe_sys_clk_ratio = PFE_CFG_CLMODE,
        .on_g3 = FALSE,
    };

    util_cfg.on_g3 = pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3);
    platform->util = pfe_util_create(platform->cbus_baseaddr, platform->util_pe_count, &util_cfg);

    if (NULL == platform->util)
    {
        NXP_LOG_ERROR("Couldn't create UTIL instance\n");
        ret = ENODEV;
    }
    else
    {
        ELF_File_t elf;

        if (NULL == platform->fw->util_data)
        {
            NXP_LOG_WARNING("The UTIL firmware is not loaded\n");
            ret = EOK;
        }
        else
        {
            if (FALSE == ELF_Open(&elf, platform->fw->util_data))
            {
                NXP_LOG_ERROR("Can't parse UTIL firmware\n");
                ret = EIO;
            }
            else
            {
                NXP_LOG_INFO("Uploading UTIL firmware\n");
                ret = pfe_util_load_firmware(platform->util, &elf);

                ELF_Close(&elf);

                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Error during upload of UTIL firmware: %d\n", ret);
                    ret = EIO;
                }
            }
        }
    }

    return ret;
}

/**
 * @brief       Release UTIL-related resources
 */
static void pfe_platform_destroy_util(pfe_platform_t *platform)
{
    if (NULL != platform->util)
    {
        pfe_util_destroy(platform->util);
        platform->util = NULL;
    }
}

/**
 * @brief       Assign EMAC to the platform
 */
static errno_t pfe_platform_create_emac(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    /*  EMAC1 */
    platform->emac[0U] = pfe_emac_create(platform->cbus_baseaddr, CBUS_EMAC1_BASE_ADDR,
                            config->emac_mode[0U], EMAC_SPEED_1000_MBPS, EMAC_DUPLEX_FULL);
    if (NULL == platform->emac[0U])
    {
        NXP_LOG_ERROR("Couldn't create EMAC1 instance\n");
        ret = ENODEV;
    }
    else
    {
        (void)pfe_emac_set_max_frame_length(platform->emac[0U], 1522U);
        pfe_emac_enable_rx_flow_control(platform->emac[0U]);
        pfe_emac_enable_broadcast(platform->emac[0U]);

        /*  MAC address will be added with phy/log interface */
    }

    /*  EMAC2 */
    if (EOK == ret)
    {
        platform->emac[1U] = pfe_emac_create(platform->cbus_baseaddr, CBUS_EMAC2_BASE_ADDR,
                                config->emac_mode[1U], EMAC_SPEED_1000_MBPS, EMAC_DUPLEX_FULL);
        if (NULL == platform->emac[1U])
        {
            NXP_LOG_ERROR("Couldn't create EMAC2 instance\n");
            ret = ENODEV;
        }
        else
        {
            (void)pfe_emac_set_max_frame_length(platform->emac[1U], 1522U);
            pfe_emac_enable_rx_flow_control(platform->emac[1U]);
            pfe_emac_enable_broadcast(platform->emac[1U]);

            /*  MAC address will be added with phy/log interface */
        }
    }

    if (EOK == ret)
    {
        /*  EMAC3 */
        platform->emac[2U] = pfe_emac_create(platform->cbus_baseaddr, CBUS_EMAC3_BASE_ADDR,
                                config->emac_mode[2U], EMAC_SPEED_1000_MBPS, EMAC_DUPLEX_FULL);
        if (NULL == platform->emac[2U])
        {
            NXP_LOG_ERROR("Couldn't create EMAC3 instance\n");
            ret = ENODEV;
        }
        else
        {
            (void)pfe_emac_set_max_frame_length(platform->emac[2U], 1522U);
            pfe_emac_enable_rx_flow_control(platform->emac[2U]);
            pfe_emac_enable_broadcast(platform->emac[2U]);

            /*  MAC address will be added with phy/log interface */
        }
    }

    return ret;
}

#ifdef PFE_CFG_IEEE1588_SUPPORT
/**
 * @brief       Enable timestamping
 */
static void pfe_platform_enable_ts(pfe_platform_t *platform)
{
    if (EOK != pfe_emac_enable_ts(platform->emac[0U],
            PFE_CFG_IEEE1588_I_CLK_HZ, PFE_CFG_IEEE1588_EMAC0_O_CLK_HZ))
    {
        NXP_LOG_WARNING("EMAC0: Could not configure the timestamping unit\n");
    }
    else if (EOK != pfe_emac_enable_ts(platform->emac[1U],
            PFE_CFG_IEEE1588_I_CLK_HZ, PFE_CFG_IEEE1588_EMAC1_O_CLK_HZ))
    {
        NXP_LOG_WARNING("EMAC1: Could not configure the timestamping unit\n");
    }
    else if (EOK != pfe_emac_enable_ts(platform->emac[2U],
            PFE_CFG_IEEE1588_I_CLK_HZ, PFE_CFG_IEEE1588_EMAC2_O_CLK_HZ))
    {
        NXP_LOG_WARNING("EMAC2: Could not configure the timestamping unit\n");
    }
    else
    {
        /*Do nothing - Avoid MISRA rule 15.7 */
    }
}
#endif /* PFE_CFG_IEEE1588_SUPPORT */

/**
 * @brief       Release EMAC-related resources
 */
static void pfe_platform_destroy_emac(pfe_platform_t *platform)
{
    uint32 ii;

    for (ii=0U; ii<platform->emac_count; ii++)
    {
        if (NULL != platform->emac[ii])
        {
            pfe_emac_destroy(platform->emac[ii]);
            platform->emac[ii] = NULL;
        }
    }
}

/**
 * @brief       Unmask parity and wdt irq
 */
static void pfe_platform_irq_unmask_parity_wdt(pfe_platform_t *platform)
{
    pfe_parity_irq_unmask(platform->parity);
    pfe_wdt_irq_unmask(platform->wdt);
}

/**
 * @brief       Unmask fails and errors irq
 */
static void pfe_platform_irq_unmask_fails_and_errors(pfe_platform_t *platform)
{
    pfe_bus_err_irq_unmask(platform->bus_err);
    pfe_fw_fail_stop_irq_unmask(platform->fw_fail_stop);
    pfe_host_fail_stop_irq_unmask(platform->host_fail_stop);
    pfe_fail_stop_irq_unmask(platform->fail_stop);
    pfe_ecc_err_irq_unmask(platform->ecc_err);
}

/**
 * @brief       Assign PFE_ERRORS to the platform
 */
static errno_t pfe_platform_create_failures(pfe_platform_t *platform,addr_t cbus_base_va, addr_t parity_base)
{
    errno_t ret = EOK;
    /*  Bus Errors */
    platform->bus_err = pfe_bus_err_create(cbus_base_va, parity_base);

    if (NULL == platform->bus_err)
    {
        NXP_LOG_ERROR("Couldn't create PFE_ERRORS:Bus Error instance\n");
        ret = ENODEV;
    }
    else
    {
        NXP_LOG_INFO("PFE_ERRORS:Bus Error instance created\n");
    }

    /*  FW Fail Stop */
    platform->fw_fail_stop = pfe_fw_fail_stop_create(cbus_base_va, parity_base);

    if (NULL == platform->fw_fail_stop)
    {
        NXP_LOG_ERROR("Couldn't create PFE_ERRORS:FW Fail Stop instance\n");
        ret = ENODEV;
    }
    else
    {
        NXP_LOG_INFO("PFE_ERRORS:FW Fail Stop instance created\n");
    }

    /*  Host Fail Stop */
    platform->host_fail_stop = pfe_host_fail_stop_create(cbus_base_va, parity_base);

    if (NULL == platform->host_fail_stop)
    {
        NXP_LOG_ERROR("Couldn't create PFE_ERRORS:Host Fail Stop instance\n");
        ret = ENODEV;
    }
    else
    {
        NXP_LOG_INFO("PFE_ERRORS:Host Fail Stop instance created\n");
    }

    /*  Fail Stop */
    platform->fail_stop = pfe_fail_stop_create(cbus_base_va, parity_base);

    if (NULL == platform->fail_stop)
    {
        NXP_LOG_ERROR("Couldn't create PFE_ERRORS:Fail Stop instance\n");
        ret = ENODEV;
    }
    else
    {
        NXP_LOG_INFO("PFE_ERRORS:Fail Stop instance created\n");
    }

    /*  ECC Error */
    platform->ecc_err = pfe_ecc_err_create(cbus_base_va, parity_base);

    if (NULL == platform->ecc_err)
    {
        NXP_LOG_ERROR("Couldn't create PFE_ERRORS:ECC Err instance\n");
        ret = ENODEV;
    }
    else
    {
        NXP_LOG_INFO("PFE_ERRORS:ECC Err instance created\n");
    }

    return ret;
}
/**
 * @brief       Assign PFE_ERRORS to the platform
 */
static errno_t pfe_platform_create_pfe_errors(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    errno_t ret = EOK;
    bool_t bFeatureOnG3;
    (void)config;

    /*  Parity */
    platform->parity = pfe_parity_create(platform->cbus_baseaddr, CBUS_GLOBAL_CSR_BASE_ADDR);

    if (NULL == platform->parity)
    {
        NXP_LOG_ERROR("Couldn't create PFE_ERRORS:Parity instance\n");
        ret = ENODEV;
    }
    else
    {
        NXP_LOG_INFO("PFE_ERRORS:Parity instance created\n");
    }

    if (EOK == ret)
    {
        /*  Watchdogs */
        platform->wdt = pfe_wdt_create(platform->cbus_baseaddr, CBUS_GLOBAL_CSR_BASE_ADDR);

        if (NULL == platform->wdt)
        {
            NXP_LOG_ERROR("Couldn't create PFE_ERRORS:Watchdog instance\n");
            ret = ENODEV;
        }
        else
        {
            NXP_LOG_INFO("PFE_ERRORS:Watchdog instance created\n");
        }
    }

    bFeatureOnG3 = pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3);
    if ((EOK == ret) && (TRUE == bFeatureOnG3))
    {
        ret = pfe_platform_create_failures(platform,platform->cbus_baseaddr, CBUS_GLOBAL_CSR_BASE_ADDR);
    }

    if (EOK == ret)
    {
        pfe_platform_irq_unmask_parity_wdt(platform);

        if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
        {
            pfe_platform_irq_unmask_fails_and_errors(platform);
        }
    }

    return ret;
}

/**
 * @brief       Release PFE_ERRORS-related resources
 */
static void pfe_platform_destroy_pfe_errors(pfe_platform_t *platform)
{
    if (NULL != platform->ecc_err)
    {
        pfe_ecc_err_destroy(platform->ecc_err);
        platform->ecc_err = NULL;
    }

    if (NULL != platform->fail_stop)
    {
        pfe_fail_stop_destroy(platform->fail_stop);
        platform->fail_stop = NULL;
    }

    if (NULL != platform->host_fail_stop)
    {
        pfe_host_fail_stop_destroy(platform->host_fail_stop);
        platform->host_fail_stop = NULL;
    }

    if (NULL != platform->fw_fail_stop)
    {
        pfe_fw_fail_stop_destroy(platform->fw_fail_stop);
        platform->fw_fail_stop = NULL;
    }

    if (NULL != platform->bus_err)
    {
        pfe_bus_err_destroy(platform->bus_err);
        platform->bus_err = NULL;
    }

    if (NULL != platform->parity)
    {
        pfe_parity_destroy(platform->parity);
        platform->parity = NULL;
    }

    if (NULL != platform->wdt)
    {
        pfe_wdt_destroy(platform->wdt);
        platform->wdt = NULL;
    }
}

#ifdef PFE_CFG_FCI_ENABLE
/**
 * @brief       Start the FCI endpoint
 *
 */
static errno_t pfe_platform_create_fci(pfe_platform_t *platform)
{
    fci_init_info_t fci_init_info;
    errno_t ret;

#if defined(PFE_CFG_RTABLE_ENABLE)
    fci_init_info.rtable = platform->rtable;
#endif /* PFE_CFG_RTABLE_ENABLE */
#if defined(PFE_CFG_L2BRIDGE_ENABLE)
    fci_init_info.l2_bridge = platform->l2_bridge;
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
    fci_init_info.class = platform->classifier;
    fci_init_info.phy_if_db = platform->phy_if_db;
    fci_init_info.log_if_db = platform->log_if_db;
    fci_init_info.tmu = platform->tmu;
#ifdef PFE_CFG_MULTI_INSTANCE_SUPPORT
    fci_init_info.hif_fci_owner_chnls_mask = platform->hif_fci_owner_chnls_mask;
#endif /* PFE_CFG_MULTI_INSTANCE_SUPPORT */
    ret = fci_init(&fci_init_info, "pfe_fci");
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Could not create the FCI endpoint\n");
    }
    else
    {
        platform->fci_created = TRUE;
    }

    return ret;
}

/**
 * @brief       Release FCI-related resources
 */
static void pfe_platform_destroy_fci(pfe_platform_t *platform)
{
    fci_fini();
    platform->fci_created = FALSE;
}
#endif /* PFE_CFG_FCI_ENABLE */

/**
 * @brief       Register physical interface
 * @details     Function will crate mapping table between physical interface IDs and
 *              instances and add the physical interface instance with various validity
 *              checks.
 */
static errno_t pfe_platform_register_phy_if(uint32 session_id, pfe_phy_if_t *phy_if)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == phy_if))
    {
        NXP_LOG_ERROR("Null argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Owner of the interface is local driver instance */
        ret = pfe_if_db_add(pfe.phy_if_db, session_id, phy_if, PFE_CFG_LOCAL_IF);
    }

    return ret;
}

/**
 * @brief       Get physical interface by its ID
 * @param[in]   platform Platform instance
 * @param[in]   id Physical interface ID
 * @return      Physical interface instance or NULL if failed.
 */
pfe_phy_if_t *pfe_platform_get_phy_if_by_id(const pfe_platform_t *platform, pfe_ct_phy_if_id_t id)
{
    pfe_if_db_entry_t *entry = NULL;
    uint32 session_id = 0U;
    pfe_phy_if_t *phyif;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == platform))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        phyif = NULL;
    }
    else if (unlikely(NULL == platform->phy_if_db))
    {
        NXP_LOG_ERROR("Physical interface DB not found\n");
        phyif = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK != pfe_if_db_lock(&session_id))
        {
            NXP_LOG_DEBUG("DB lock failed\n");
        }

        (void)pfe_if_db_get_first(platform->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)id, &entry);

        if (EOK != pfe_if_db_unlock(session_id))
        {
            NXP_LOG_DEBUG("DB unlock failed\n");
        }

        phyif = pfe_if_db_entry_get_phy_if(entry);

    }
    return phyif;
}

/**
 * @brief       Add a default LOG_IF to a PHY_IF.
 */
static errno_t pfe_platform_create_default_log_if(pfe_phy_if_t *phy_if, const char *if_name, uint32 session_id)
{
    pfe_log_if_t *log_if = pfe_log_if_create(phy_if, if_name);
    errno_t ret = ENODEV;
    
    if (NULL == log_if)
    {
        NXP_LOG_ERROR("Couldn't create LOG_IF for %s\n", if_name);
        
    }
    else if (EOK != pfe_if_db_add(pfe.log_if_db, session_id, log_if, PFE_CFG_LOCAL_IF))
    {
        NXP_LOG_ERROR("Could not register LOG_IF %s\n", if_name);
        pfe_log_if_destroy(log_if);
    }
    else if (EOK != pfe_log_if_promisc_enable(log_if))
    {
        NXP_LOG_ERROR("Could not configure LOG_IF %s\n", if_name);
        pfe_log_if_destroy(log_if);
    }
    else
    {
        /* Enable default LOG_IF */
        ret = pfe_log_if_enable(log_if);
    }
    return ret;
}

/**
 * @brief       Bind HIF to the platform and add default log_if
 */
static errno_t pfe_platform_prepare_phy_if_hif(pfe_phy_if_t *phy_if, const pfe_platform_pfy_if *p_phy_ifs, uint32 session_id)
{
    errno_t ret = EOK;

    /*  If the HIF channel is managed by this driver instance */
    if (NULL != p_phy_ifs->phy.chnl)
    {
        /*  Bind HIF channel instance with the physical IF */
        if (EOK != pfe_phy_if_bind_hif(phy_if, p_phy_ifs->phy.chnl))
        {
            NXP_LOG_ERROR("Can't bind interface with HIF (%s)\n", p_phy_ifs->name);
            ret = ENODEV;
        }
    }
    if (EOK == ret)
    {
        if (EOK != pfe_platform_create_default_log_if(phy_if, p_phy_ifs->name, session_id))
        {
            NXP_LOG_ERROR("Can't create default log_if for %s\n", p_phy_ifs->name);
            ret = ENODEV;
        }
    }

    return ret;
}

/**
 * @brief       Bind EMAC to the platform and add default log_if
 */
static errno_t pfe_platform_prepare_phy_if_emac(pfe_phy_if_t *phy_if, const pfe_platform_pfy_if *p_phy_ifs, uint32 session_id)
{
    errno_t ret = ENODEV;

    /*  Bind EMAC instance with the physical IF */
    if (EOK != pfe_phy_if_bind_emac(phy_if, p_phy_ifs->phy.emac))
    {
        NXP_LOG_ERROR("Can't bind interface with EMAC (%s)\n", p_phy_ifs->name);
    }
    /* provide gpi handle to emac: emac phy_ifs need access to gpi to configure Ingress QoS */
    else if (EOK != pfe_emac_bind_gpi(p_phy_ifs->phy.emac, p_phy_ifs->phy.gpi))
    {
        NXP_LOG_ERROR("Can't bind interface with GPI (%s)\n", p_phy_ifs->name);
    }
    else if (EOK != pfe_platform_create_default_log_if(phy_if, p_phy_ifs->name, session_id))
    {
        NXP_LOG_ERROR("Can't create default log_if for %s\n", p_phy_ifs->name);
    }
    else
    {
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Prepare and configure a phy_if
 */
static errno_t pfe_platform_prepare_phy_if(pfe_phy_if_t *phy_if, const pfe_platform_pfy_if *p_phy_ifs, uint32 session_id)
{
    errno_t ret = EOK;
    pfe_ct_phy_if_id_t phy_if_id;

    /*  Set default operation mode */
    if (EOK != pfe_phy_if_set_op_mode(phy_if, IF_OP_DEFAULT))
    {
        NXP_LOG_ERROR("Could not set default operational mode (%s)\n", p_phy_ifs->name);
        ret = ENODEV;
    }
    else
    {
        phy_if_id = pfe_phy_if_get_id(phy_if);
        if ((phy_if_id == PFE_PHY_IF_ID_EMAC0)
         || (phy_if_id == PFE_PHY_IF_ID_EMAC1)
         || (phy_if_id == PFE_PHY_IF_ID_EMAC2))
        {
            ret = pfe_platform_prepare_phy_if_emac(phy_if, p_phy_ifs, session_id);
        }
        else if (phy_if_id == PFE_PHY_IF_ID_UTIL)
        {
            /* All actions on UTIL PHY will not do anything. */
            /* This phy is only present to allow adding new logical interfaces. */
            if (EOK != pfe_phy_if_bind_util(phy_if))
            {
                NXP_LOG_ERROR("Can't initialize UTIL PHY (%s)\n", p_phy_ifs->name);
                ret = ENODEV;
            }
        }
        else
        {
            /*  Bind HIF channel instance with the physical IF */
            ret = pfe_platform_prepare_phy_if_hif(phy_if, p_phy_ifs, session_id);
        }

        /*  Register in platform */
        if (EOK == ret) 
        {
            if (EOK != pfe_platform_register_phy_if(session_id, phy_if))
            {
                NXP_LOG_ERROR("Could not register %s\n", pfe_phy_if_get_name(phy_if));
                ret = ENODEV;
            }
        }
    }
    return ret;
}

/**
 * @brief       Assign interfaces to the platform.
 */
static errno_t pfe_platform_bind_ifaces(void)
{
    errno_t ret = EOK;
    sint32 ii;
    pfe_phy_if_t *phy_if = NULL;
    uint32 session_id = 0U;
    pfe_if_db_entry_t *entry = NULL;
    pfe_hif_chnl_t *channel_hif0 = NULL;
    pfe_hif_chnl_t *channel_hif1 = NULL;
    pfe_hif_chnl_t *channel_hif2 = NULL;
    pfe_hif_chnl_t *channel_hif3 = NULL;
    pfe_hif_chnl_t *channel_hifncpy = NULL;

    channel_hif0 = pfe_hif_get_channel(pfe.hif, HIF_CHNL_0);
    channel_hif1 = pfe_hif_get_channel(pfe.hif, HIF_CHNL_1);
    channel_hif2 = pfe_hif_get_channel(pfe.hif, HIF_CHNL_2);
    channel_hif3 = pfe_hif_get_channel(pfe.hif, HIF_CHNL_3);
    channel_hifncpy = pfe_hif_nocpy_get_channel(pfe.hif_nocpy, PFE_HIF_CHNL_NOCPY_ID);

    const pfe_platform_pfy_if phy_ifs[] =
    {
            {.name = "emac0", .id = PFE_PHY_IF_ID_EMAC0, .mac = GEMAC0_MAC, {.emac = pfe.emac[0], .gpi = pfe.gpi[0], .chnl = NULL}},
            {.name = "emac1", .id = PFE_PHY_IF_ID_EMAC1, .mac = GEMAC1_MAC, {.emac = pfe.emac[1], .gpi = pfe.gpi[1], .chnl = NULL}},
            {.name = "emac2", .id = PFE_PHY_IF_ID_EMAC2, .mac = GEMAC2_MAC, {.emac = pfe.emac[2], .gpi = pfe.gpi[2], .chnl = NULL}},
            {.name = "util", .id = PFE_PHY_IF_ID_UTIL, .mac = {0}, {.emac = NULL, .gpi = NULL, .chnl = NULL}},
            {.name = "hif0", .id = PFE_PHY_IF_ID_HIF0, .mac = {0}, {.emac = NULL, .gpi = NULL, .chnl = channel_hif0}},
            {.name = "hif1", .id = PFE_PHY_IF_ID_HIF1, .mac = {0}, {.emac = NULL, .gpi = NULL, .chnl = channel_hif1}},
            {.name = "hif2", .id = PFE_PHY_IF_ID_HIF2, .mac = {0}, {.emac = NULL, .gpi = NULL, .chnl = channel_hif2}},
            {.name = "hif3", .id = PFE_PHY_IF_ID_HIF3, .mac = {0}, {.emac = NULL, .gpi = NULL, .chnl = channel_hif3}},
            {.name = "hifncpy", .id = PFE_PHY_IF_ID_HIF_NOCPY, .mac = {0}, {.emac = NULL, .gpi = NULL, .chnl = channel_hifncpy}},
            {.name = NULL, .id = PFE_PHY_IF_ID_INVALID, .mac = {0}, {NULL, NULL, NULL}}
    };

    if (EOK != pfe_if_db_lock(&session_id))
    {
        NXP_LOG_ERROR("DB lock failed\n");
    }

    /*  Create interfaces */
    for (ii=0; phy_ifs[ii].id!=PFE_PHY_IF_ID_INVALID; ii++)
    {
        /*  Check if physical IF with given ID is already registered. We need
            only one local instance per PHY IF. */
        (void)pfe_if_db_get_first(pfe.phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)phy_ifs[ii].id, &entry);
        if (NULL != entry)
        {
            /*  Duplicate found */
            continue;
        }

        /*  Create physical IF */
        phy_if = pfe_phy_if_create(pfe.classifier, phy_ifs[ii].id, phy_ifs[ii].name);
        if (NULL == phy_if)
        {
            NXP_LOG_ERROR("Couldn't create %s\n", phy_ifs[ii].name);
            ret = ENODEV;
            break;
        }
        else
        {
            ret = pfe_platform_prepare_phy_if(phy_if, &phy_ifs[ii], session_id);
            if(EOK != ret)
            {
                pfe_phy_if_destroy(phy_if);
                break;
            }
        }
    }

    if (EOK != pfe_if_db_unlock(session_id))
    {
        NXP_LOG_ERROR("DB unlock failed\n");
    }

    return ret;
}

/**
 * @brief       Assign interfaces to the platform.
 */
static errno_t pfe_platform_create_ifaces(void)
{
    errno_t ret = EOK;

    /*  Create interface databases */
    if (NULL == pfe.log_if_db)
    {
        pfe.log_if_db = pfe_if_db_create(PFE_IF_DB_LOG);
        if (NULL == pfe.log_if_db)
        {
            NXP_LOG_DEBUG("Can't create logical interface DB\n");
            ret = ENODEV;
        }
        else
        {
          (void)pfe_log_ifs_init();
        }
    }
    if (EOK == ret)
    {
        if (NULL == pfe.phy_if_db)
        {
            pfe.phy_if_db = pfe_if_db_create(PFE_IF_DB_PHY);
            if (NULL == pfe.phy_if_db)
            {
                NXP_LOG_DEBUG("Can't create physical interface DB\n");
                ret = ENODEV;
            }
            else
            {
                ret = pfe_platform_bind_ifaces();
            }
        }
    }

    return ret;
}

static void pfe_platform_destroy_pfe_log_ifs(pfe_platform_t *platform)
{
    pfe_if_db_entry_t *entry = NULL;
    pfe_log_if_t *log_if;
    uint32 session_id = 0U;
    errno_t ret;

    /*lock database*/
    if(EOK != pfe_if_db_lock(&session_id))
    {
        NXP_LOG_DEBUG("DB lock failed\n");
    }

    /*get first entry*/
    ret = pfe_if_db_get_first(platform->log_if_db, session_id, IF_DB_CRIT_ALL, NULL, &entry);

    /*remove all entries*/
    while (NULL != entry)
    {
        log_if = pfe_if_db_entry_get_log_if(entry);

        if (EOK != pfe_if_db_remove(platform->log_if_db, session_id, entry))
        {
            NXP_LOG_DEBUG("Could not remove log_if DB entry\n");
        }

        /*remove the entry*/
        pfe_log_if_destroy(log_if);
        entry = NULL;

        /*get next entry*/
        ret = pfe_if_db_get_next(platform->log_if_db, session_id, &entry);
    }

    if(EOK != ret)
    {
        NXP_LOG_DEBUG("Could not remove log_if DB entry, DB was locked\n");
    }

    if(EOK != pfe_if_db_unlock(session_id))
    {
        NXP_LOG_DEBUG("DB unlock failed\n");
    }

    if (NULL != platform->log_if_db)
    {
        pfe_if_db_destroy(platform->log_if_db);
        platform->log_if_db = NULL;
    }
}

static void pfe_platform_destroy_pfe_phy_ifs(pfe_platform_t *platform)
{
    pfe_if_db_entry_t *entry = NULL;
    pfe_phy_if_t *phy_if;
    uint32 session_id = 0U;
    errno_t ret;

    /*lock database*/
    if(EOK != pfe_if_db_lock(&session_id))
    {
        NXP_LOG_DEBUG("DB lock failed\n");
    }
    /*get first entry*/
    ret = pfe_if_db_get_first(platform->phy_if_db, session_id, IF_DB_CRIT_ALL, NULL, &entry);

    while (NULL != entry)
    {
        phy_if = pfe_if_db_entry_get_phy_if(entry);

        if (EOK != pfe_if_db_remove(platform->phy_if_db, session_id, entry))
        {
            NXP_LOG_DEBUG("Could not remove phy_if DB entry\n");
        }

        /*remove the entry*/
        pfe_phy_if_destroy(phy_if);
        phy_if = NULL;
        entry = NULL;
        /*get next entry*/
        ret = pfe_if_db_get_next(platform->phy_if_db, session_id, &entry);
    }

    if(EOK != ret)
    {
        NXP_LOG_DEBUG("Could not remove log_if DB entry, DB was locked\n");
    }

    if(EOK != pfe_if_db_unlock(session_id))
    {
        NXP_LOG_DEBUG("DB unlock failed\n");
    }

    if (NULL != platform->phy_if_db)
    {
        pfe_if_db_destroy(platform->phy_if_db);
        platform->phy_if_db = NULL;
    }
}

/**
 * @brief       Release interface-related resources
 */
static void pfe_platform_destroy_ifaces(pfe_platform_t *platform)
{
    if (NULL != platform->log_if_db)
    {
        pfe_platform_destroy_pfe_log_ifs(platform);

        pfe_log_ifs_deinit();
    }

    if (NULL != platform->phy_if_db)
    {
        pfe_platform_destroy_pfe_phy_ifs(platform);
    }
}

/**
 * @brief       Perform PFE soft reset
 */
errno_t pfe_platform_soft_reset(const pfe_platform_t *platform)
{
    addr_t addr_gen, addr_dbug;
    uint32 regval;
    bool_t run_on_g3 = FALSE;
    uint32 timeout = 1000U;
    errno_t ret = EOK;

    (void)platform;

    if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
    {
        run_on_g3 = TRUE;
    }

    addr_gen = (addr_t)(pfe.cbus_baseaddr) + CBUS_GLOBAL_CSR_BASE_ADDR + WSP_SYS_GENERIC_CONTROL;
    regval = hal_read32(addr_gen);

    /* Clear the soft reset done */
    if (TRUE == run_on_g3)
    {
        regval |= WSP_SYS_GEN_SOFT_RST_DONE_CLR_MASK_G3;
        hal_write32(regval, addr_gen);
        regval &= ~WSP_SYS_GEN_SOFT_RST_DONE_CLR_MASK_G3;
        hal_write32(regval, addr_gen);
    }

    /* Set bit '30' to perform soft reset */
    regval |= WSP_SYS_GEN_SOFT_RST_BIT;
    hal_write32(regval, addr_gen);

    if (TRUE == run_on_g3)
    {
        /* Wait for soft reset done */
        addr_dbug = (addr_t)(pfe.cbus_baseaddr) + CBUS_GLOBAL_CSR_BASE_ADDR + WSP_DBUG_BUS1_G3;
        do
        {
            regval = hal_read32(addr_dbug) & WSP_DBUG_BUS1_SOFT_RST_DONE_BIT_G3;
            timeout--;
        }while ((WSP_DBUG_BUS1_SOFT_RST_DONE_BIT_G3 != regval) && (0U != timeout));

        if (0U == timeout)
        {
            NXP_LOG_INFO("Soft reset done indication timeouted\n");
            ret = ETIMEDOUT;
        }
        else
        {
            regval = hal_read32(addr_gen);
            regval &= ~WSP_SYS_GEN_SOFT_RST_BIT;
            regval |= WSP_SYS_GEN_SOFT_RST_DONE_CLR_MASK_G3;
            hal_write32(regval, addr_gen);
            regval &= ~WSP_SYS_GEN_SOFT_RST_DONE_CLR_MASK_G3;
            hal_write32(regval, addr_gen);
        }
    }
    else
    {
        oal_time_usleep(5U);
        regval &= ~WSP_SYS_GEN_SOFT_RST_BIT;
        hal_write32(regval, addr_gen);
    }

    return ret;
}

#ifdef NXP_LOG_ENABLED
/**
 * @brief   Print PFE FW features available on this target. For debug purposes only.
 */
static void pfe_platform_print_features(void)
{
    const char *feature_name;
    errno_t ret;

    ret = pfe_feature_mgr_get_first(&feature_name);
    while (EOK == ret)
    {
        NXP_LOG_INFO("Detected FW feature: %s\n", feature_name);
        ret = pfe_feature_mgr_get_next(&feature_name);
    }
}
#endif  /* NXP_LOG_ENABLED */

/**
 * @brief   Helper function to the platform init function part_1
 */
static errno_t pfe_platform_create_gpis_add_modules(const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    /*  Make sure all HIF/HIF_NOCPY chnl DMAs are disabled before the soft reset */
    pfe_hif_cfg_stop_all_chnl_dma();
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    pfe_hif_nocpy_cfg_stop_all_chnl_dma();
#endif

    /*  SOFT RESET */
    if (EOK != pfe_platform_soft_reset(&pfe))
    {
        NXP_LOG_ERROR("Platform reset failed\n");
    }

    /* Initialize the FW features */
    ret = pfe_feature_mgr_add_modules(pfe.classifier, pfe.util, pfe.tmu);
    if (EOK != ret)
    {
        (void)pfe_platform_remove();
    }
    else
    {
#ifdef NXP_LOG_ENABLED
        pfe_platform_print_features();
#endif

        /*  GPI */
        ret = pfe_platform_create_gpi(&pfe, config);
        if (EOK != ret)
        {
            (void)pfe_platform_remove();
        }
        else
        {
            /*  HGPI */
            ret = pfe_platform_create_hgpi(&pfe);
            if (EOK != ret)
            {
                (void)pfe_platform_remove();
            }
        }
    }

    return ret;
}
/**
 * @brief   Helper function to the platform init function part_1
 */
static errno_t pfe_platform_create_err_bmu_class_tmu_emac_util(const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    /*  PFE_ERRORS */
    ret = pfe_platform_create_pfe_errors(&pfe, config);
    if (EOK == ret)
    {
        /*  BMU */
        ret = pfe_platform_create_bmu(&pfe, config);
        if (EOK == ret)
        {
            /*  Classifier */
            ret = pfe_platform_create_class(&pfe, config);
            if (EOK == ret)
            {
                /*  TMU */
                ret = pfe_platform_create_tmu(&pfe);
                if (EOK == ret)
                {
                    /*  EMAC */
                    ret = pfe_platform_create_emac(&pfe, config);
                    if (EOK == ret)
                    {
                        if(config->enable_util)
                        {
                            /*  UTIL */
                            ret = pfe_platform_create_util(&pfe);
                        }
                        else
                        {
                            NXP_LOG_DEBUG("Util is not enabled but initializing Util Mem now..");
                            (void)pfe_platform_default_init_util(&pfe);
                            pfe_util_destroy(pfe.util);
                            pfe.util = NULL;
                        }
                    }
                }
            }
        }
    }
    if (EOK != ret)
    {
        (void)pfe_platform_remove();
    }
    return ret;
}

/**
 * @brief   The platform init function part_1
 */
static errno_t pfe_platform_init_hm_fw_features(const pfe_platform_config_t *config)
{
    errno_t ret = EOK;
    uint32 *addr;
    /*  Prevent LMEM initialization loop optimization to autolibc_memset() at -O3 */
    volatile uint32 *ii;

    (void)autolibc_memset(&pfe, 0, sizeof(pfe_platform_t));
    pfe.fci_created = FALSE;

    pfe.fw = config->fw;

    /*  Map CBUS address space */
    pfe.cbus_baseaddr = (addr_t) config->cbus_base;
    if (NULL_ADDR == pfe.cbus_baseaddr)
    {
        NXP_LOG_ERROR("Can't map PPFE CBUS\n");
        ret = EINVAL;
        (void)pfe_platform_remove();
    }
    else
    {
        NXP_LOG_INFO("PFE CBUS p0x%"PRINTADDR_T" mapped @ v0x%"PRINTADDR_T"\n", config->cbus_base, pfe.cbus_baseaddr);

        /* Get PFE Version */
        pfe.pfe_version = *(uint32*)(void*)((addr_t)pfe.cbus_baseaddr + CBUS_GLOBAL_CSR_BASE_ADDR + WSP_VERSION);
        NXP_LOG_INFO("HW version 0x%x\n", (uint_t)pfe.pfe_version);

        /* Initialize the features */
        ret = pfe_feature_mgr_init((void *)pfe.cbus_baseaddr);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Initialize the features failed.\n");
            (void)pfe_platform_remove();
        }
        else
        {
            if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
            {
                NXP_LOG_WARNING("Fail-Stop mode disabled\n");
                addr = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_FAIL_STOP_MODE_INT_EN + (addr_t)(pfe.cbus_baseaddr));
                hal_write32(0x0, addr);
                addr = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_FAIL_STOP_MODE_EN + (addr_t)(pfe.cbus_baseaddr));
                hal_write32(0x0, addr);
                addr = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + WSP_ECC_ERR_INT_EN + (addr_t)(pfe.cbus_baseaddr));
                hal_write32(0x0, addr);
            }

            addr = (uint32*)(void*)((addr_t)pfe.cbus_baseaddr + CBUS_LMEM_BASE_ADDR);
            for (ii = addr; ((addr_t)ii - (addr_t)addr) < CBUS_LMEM_SIZE; ++ii)
            {
                *ii = 0U;
            }

            /*  Create HW components */
            pfe.emac_count = 3U;
            pfe.gpi_count = 3U;
            pfe.etgpi_count = 3U;
            pfe.hgpi_count = 1U;
            pfe.bmu_count = 2U;
            pfe.class_pe_count = 8U;
            pfe.util_pe_count = 1U;
            pfe.tmu_pe_count = 0U;

            /* Health monitor */
            pfe_hm_init();

            ret = pfe_platform_create_err_bmu_class_tmu_emac_util(config);
            if (EOK == ret)
            {
                ret = pfe_platform_create_gpis_add_modules(config);
            }
        }
    }

    /* Remove pointer to firmware binary to support memory reuse */
    if (pfe.fw != NULL)
    {
        pfe.fw->class_data = NULL;
        pfe.fw->util_data = NULL;
    }
    pfe.fw = NULL;

    return ret;
}

/**
 * @brief   The platform init function part_3
 */
static errno_t pfe_platform_init_etgpi_l2br_rtable_hifs(const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    /*ETGPI*/
    ret = pfe_platform_create_etgpi(&pfe);
    if (EOK != ret)
    {
        (void)pfe_platform_remove();
    }
    else
    {
#ifdef PFE_CFG_FCI_ENABLE
#if defined(PFE_CFG_L2BRIDGE_ENABLE)
        /*L2 Bridge. Must be initialized after soft reset.*/
        ret = pfe_platform_create_l2_bridge(&pfe, config);
        if (EOK != ret)
        {
            (void)pfe_platform_remove();
        }
        else
#else
        pfe.l2_bridge = NULL_PTR;
#endif      /*PFE_CFG_L2BRIDGE_ENABLE*/
        {
#if defined(PFE_CFG_RTABLE_ENABLE)
            /*Routing Table*/
            ret = pfe_platform_create_rtable(&pfe, config);
            if (EOK != ret)
            {
                 (void)pfe_platform_remove();
            }
            else
#endif      /*PFE_CFG_RTABLE_ENABLE*/
#endif      /*PFE_CFG_FCI_ENABLE*/
            {
#if !defined(PFE_CFG_L2BRIDGE_ENABLE)
                ret = pfe_platform_init_l2br_mem(&pfe);
                if (EOK != ret)
                {
                    (void)pfe_platform_remove();
                }
                else
#endif      /*PFE_CFG_L2BRIDGE_ENABLE*/
                {
                /*HIF*/
                    ret = pfe_platform_create_hif(&pfe, config);
                    if (EOK != ret)
                    {
                         (void)pfe_platform_remove();
                    }
                    else
                    {
                        /*HIF NOCPY*/
                        ret = pfe_platform_create_hif_nocpy(&pfe);
                        if (EOK != ret)
                        {
                             (void)pfe_platform_remove();
                        }
                    }
                }
            }
#ifdef PFE_CFG_FCI_ENABLE
        }
#endif      /*PFE_CFG_FCI_ENABLE*/
    }
    return ret;
}

/**
 * @brief   The platform init function part_4
 */
static errno_t pfe_platform_init_tmu_mirror_queue_ifaces_fci(void)
{
    errno_t ret = EOK;

    /* Reset TMU prior to err051211_workaround manipulation */
    ret = pfe_tmu_queue_reset_tail_drop_policy(pfe.tmu);
    if (EOK != ret)
    {
        (void)pfe_platform_remove();
    }
    else
    {
        /* Errata 051211 */
        if (TRUE == pfe_feature_mgr_is_available("err051211_workaround"))
        {
            uint8 flg = 0U;

#ifndef PFE_CFG_ERR051211_WORKAROUND_ENABLE
            /*  Deactivate in non Master-Slave build */
            if (EOK != pfe_feature_mgr_set_val("err051211_workaround", 0U))
            {
                NXP_LOG_WARNING("Error disabling err051211_workaround feature\n");
            }
#endif /* PFE_CFG_ERR051211_WORKAROUND_ENABLE */

            ret = pfe_feature_mgr_get_val("err051211_workaround", &flg);
            if (EOK == ret)
            {
                NXP_LOG_INFO("Feature err051211_workaround: %s\n", (0U == flg ? "DISABLED" : "ENABLED"));
            }
            else
            {
                NXP_LOG_ERROR("Feature err051211_workaround status unknown\n");
            }

            /* Check HIF RX Ring size in relation to err051211_workaround. */
            if (PFE_HIF_RX_RING_CFG_LENGTH < PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH)
            {
                NXP_LOG_WARNING("HIF RX Rings are too small for FW feature err051211_workaround to fully work.");
                NXP_LOG_WARNING("The feature requires HIF RX Rings with at least %u slots, but rings currently have only %u slots.",
                                (uint_t)PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH, (uint_t)PFE_HIF_RX_RING_CFG_LENGTH);
            }
        }
        else
        {
            NXP_LOG_ERROR("Feature err051211_workaround is not supported in firmware\n");
        }

        ret = pfe_mirror_init(pfe.classifier);
        if (EOK != ret)
        {
            (void)pfe_platform_remove();
        }
        else
        {
            /*  Interfaces */
            ret = pfe_platform_create_ifaces();
            if (EOK != ret)
            {
                (void)pfe_platform_remove();
            }
            else
            {
                pfe.poller_state = POLLER_STATE_DISABLED;

#ifdef PFE_CFG_FCI_ENABLE
                ret = pfe_platform_create_fci(&pfe);
                if (EOK != ret)
                {
                    (void)pfe_platform_remove();
                }
#endif /* PFE_CFG_FCI_ENABLE */
            }
        }
    }
    return ret;
}

/**
 * @brief   The platform init function part_2
 */
static errno_t pfe_platform_init_mirror_spd_acc_features(const pfe_platform_config_t *config)
{
    errno_t ret = EOK;
    uint32 val = 0U;
    uint32 *addr;

    ret = pfe_platform_init_etgpi_l2br_rtable_hifs(config);
    if (EOK == ret)
    {
        /*  Activate the classifier */
        pfe_class_enable(pfe.classifier);
        ret = pfe_platform_init_tmu_mirror_queue_ifaces_fci();

        if(EOK == ret)
        {
            /*  Activate PFE blocks */
            pfe_bmu_enable(pfe.bmu[0U]);
            pfe_bmu_enable(pfe.bmu[1U]);
            pfe_gpi_enable(pfe.gpi[0]);
            pfe_gpi_enable(pfe.gpi[1]);
            pfe_gpi_enable(pfe.gpi[2]);
            pfe_gpi_enable(pfe.etgpi[0]);
            pfe_gpi_enable(pfe.etgpi[1]);
            pfe_gpi_enable(pfe.etgpi[2]);
            pfe_gpi_enable(pfe.hgpi[0]);
            pfe_tmu_enable(pfe.tmu);
            if(config->enable_util)
            {
                pfe_util_enable(pfe.util);
            }
            addr = (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + 0x20U + (addr_t)(pfe.cbus_baseaddr));
            val = hal_read32(addr);
            hal_write32((val | 0x80000003U), addr);

            pfe.probed = TRUE;

#ifdef PFE_CFG_IEEE1588_SUPPORT
            (void)pfe_platform_enable_ts(&pfe);
#ifdef PFE_CFG_EMAC0_PPS0_ENABLE
            (void)pfe_emac_pps0_configure(pfe.emac[0U], TRUE, PFE_CFG_EMAC0_PPS0_PERIOD_TICKS, PFE_CFG_EMAC0_PPS0_PULSE_TICKS);
            pfe_emac_pps0_resync(pfe.emac[0U]);
#else
            (void)pfe_emac_pps0_configure(pfe.emac[0U], FALSE, 0U, 0U);
#endif /* PFE_CFG_EMAC0_PPS0_ENABLE */     
#endif /* PFE_CFG_IEEE1588_SUPPORT */
        }
    }
    return ret;
}


/**
 * @brief   The platform init function
 * @details Initializes the PFE HW platform and prepares it for usage according to configuration.
 */
errno_t pfe_platform_init(const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    ret = pfe_platform_init_hm_fw_features(config);
    if (EOK == ret)
    {
        ret = pfe_platform_init_mirror_spd_acc_features(config);
    }

    return ret;
}

/**
* @brief       Destroy the platform
*/
static void pfe_platform_destroy_group1(void)
{
#ifdef PFE_CFG_FCI_ENABLE
    pfe_platform_destroy_fci(&pfe);
#endif /* PFE_CFG_FCI_ENABLE */
    pfe_platform_destroy_ifaces(&pfe);
    pfe_platform_destroy_hif(&pfe);
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    pfe_platform_destroy_hif_nocpy(&pfe);
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    pfe_platform_destroy_gpi(&pfe);
    pfe_platform_destroy_etgpi(&pfe);
    pfe_platform_destroy_hgpi(&pfe);
    pfe_platform_destroy_bmu(&pfe);
#if defined(PFE_CFG_RTABLE_ENABLE)
    pfe_platform_destroy_rtable(&pfe);
#endif /* PFE_CFG_RTABLE_ENABLE */
#if defined(PFE_CFG_L2BRIDGE_ENABLE)
    pfe_platform_destroy_l2_bridge(&pfe);
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
}

/**
* @brief       Destroy the platform
*/
static void pfe_platform_destroy_group2(void)
{
    pfe_mirror_deinit();
    pfe_platform_destroy_class(&pfe);
    pfe_platform_destroy_util(&pfe);
    pfe_platform_destroy_tmu(&pfe);
    pfe_platform_destroy_emac(&pfe);
    pfe_platform_destroy_pfe_errors(&pfe);
}

/**
 * @brief       Destroy the platform
 */
errno_t pfe_platform_remove(void)
{
    errno_t ret = EOK;
    /*  Remove and disable IRQ just before platform modules are destroyed. */
    if (NULL != pfe.irq_global)
    {
        oal_irq_destroy(pfe.irq_global);
        pfe.irq_global = NULL;
    }

    /*  Clear the generic control register */
    if (NULL_ADDR != pfe.cbus_baseaddr)
    {
        hal_write32(0U, (void *)(CBUS_GLOBAL_CSR_BASE_ADDR + 0x20U + (addr_t)(pfe.cbus_baseaddr)));
    }

    (void)pfe_hm_destroy();
    pfe_platform_destroy_group1();
    pfe_platform_destroy_group2();
    (void)pfe_feature_mgr_fini();

    pfe.cbus_baseaddr = (addr_t)0x0ULL;
    pfe.probed = FALSE;

    return ret;
}

/* deinit variables for shutdown*/
void pfe_platform_remove_sw_if(void)
{
    pfe.log_if_db = NULL_PTR;
    pfe.phy_if_db = NULL_PTR;
}

/**
 * @brief       Get the platform instance
 */
pfe_platform_t * pfe_platform_get_instance(void)
{
    pfe_platform_t *pfe_platform= NULL;
    if (TRUE == pfe.probed)
    {
        pfe_platform= &pfe;
    }

    return pfe_platform;
}

/**
 * @brief       Get firmware versions
 * @param[in]   platform Platform instance
 * @param[out]  class_fw The class fw parsed metadata or NULL if not needed
 * @param[out]  util_fw The util fw parsed metadata or NULL if not needed
 */
errno_t pfe_platform_get_fw_versions(const pfe_platform_t *platform, pfe_ct_version_t *class_fw, pfe_ct_version_t *util_fw)
{
    /*  CLASS fw */
    if (NULL != class_fw)
    {
        (void)pfe_class_get_fw_version(platform->classifier, class_fw);
    }

    /*  UTIL fw */
    if (NULL != util_fw)
    {
        (void)pfe_util_get_fw_version(platform->util, util_fw);
    }

    return EOK;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /*PFE_CFG_PFE_MASTER*/


===== 文件 [178/185]: src\pfe_platform_slave.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"

#ifdef PFE_CFG_PFE_SLAVE
#include "hal.h"
#include "pfe_cbus.h"
#include "pfe_platform_cfg.h"
#include "pfe_platform.h"
#include "pfe_ct.h"
#include "pfe_idex.h"
#include "pfe_hif_csr.h"
#include "pfe_global_wsp.h"

#ifdef PFE_CFG_FCI_ENABLE
#include "fci.h"
#endif /* PFE_CFG_FCI_ENABLE */

#define ETH_43_PFE_START_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

static pfe_platform_t pfe = {.probed = (bool_t)FALSE};

#define ETH_43_PFE_STOP_SEC_VAR_INIT_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* usage scope: pfe_platform_create_hif*/
static const pfe_hif_chnl_id_t hif_ids[HIF_CFG_MAX_CHANNELS] = {HIF_CHNL_0, HIF_CHNL_1, HIF_CHNL_2, HIF_CHNL_3};
/* usage scope: pfe_platform_create_ifaces*/
static const struct
{
    const char_t *name;
    pfe_ct_phy_if_id_t id;
    pfe_mac_addr_t mac;
}
phy_ifs[] =
{
        {.name = "emac0", .id = PFE_PHY_IF_ID_EMAC0, .mac = GEMAC0_MAC},
        {.name = "emac1", .id = PFE_PHY_IF_ID_EMAC1, .mac = GEMAC1_MAC},
        {.name = "emac2", .id = PFE_PHY_IF_ID_EMAC2, .mac = GEMAC2_MAC},
        {.name = "hif0", .id = PFE_PHY_IF_ID_HIF0, .mac = {0},},
        {.name = "hif1", .id = PFE_PHY_IF_ID_HIF1, .mac = {0},},
        {.name = "hif2", .id = PFE_PHY_IF_ID_HIF2, .mac = {0},},
        {.name = "hif3", .id = PFE_PHY_IF_ID_HIF3, .mac = {0},},
        {.name = "hifncpy", .id = PFE_PHY_IF_ID_HIF_NOCPY, .mac = {0}},
        {.name = NULL, .id = PFE_PHY_IF_ID_INVALID, .mac = {0}}
};

#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"


#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_platform_create_hif(pfe_platform_t *platform, const pfe_platform_config_t *config);
static void pfe_platform_destroy_hif(pfe_platform_t *platform);
static errno_t pfe_platform_register_phy_if(uint32 session_id, pfe_phy_if_t *phy_if);
static void pfe_platform_destroy_pfe_phy_ifs(pfe_platform_t *platform);
#if defined(PFE_CFG_FCI_ENABLE)
static errno_t pfe_platform_create_fci(pfe_platform_t *platform);
static void pfe_platform_destroy_fci(pfe_platform_t *platform);
#endif /* PFE_CFG_FCI_ENABLE */
static errno_t pfe_platform_create_emac(pfe_platform_t *platform, const pfe_platform_config_t *config);
static void pfe_platform_destroy_emac(pfe_platform_t *platform);
static boolean is_master_up(const pfe_platform_t *platform, pfe_hif_chnl_id_t hif_chnls_mask);
static errno_t phy_ifs_init(void);

/**
 * @brief       check if all assigned hif channles have been initialized by the master
 */
static boolean is_master_up(const pfe_platform_t *platform, pfe_hif_chnl_id_t hif_chnls_mask)
{
    const addr_t hif_cbus_base_va = platform->cbus_baseaddr + CBUS_HIF_BASE_ADDR;
    boolean master_up = TRUE;

    for (uint32 ii = 0U; ii < HIF_CFG_MAX_CHANNELS; ii++)
    {
        if (0U != ((uint32)(1U << ii) & (uint32)hif_chnls_mask))
        {
            if(!pfe_hif_chnl_cfg_get_master_up(hif_cbus_base_va, ii))
            {
                /* any hif not inited => master not fully up */
                master_up = FALSE;
                break;
            }
        }
    }

    return master_up;
}

/**
 * @brief       Assign HIF to the platform
 */
static errno_t pfe_platform_create_hif(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    errno_t res = EOK;
    uint32 ii;
    pfe_hif_chnl_t *chnl;
    addr_t hif_cbus_base_va = ADDR_BASE_OFFSET(platform->cbus_baseaddr, CBUS_HIF_BASE_ADDR);
    uint32 slave_tmout = PFE_CFG_SLAVE_HIF_MASTER_UP_TMOUT;

    if (FALSE == config->disable_master_detect)
    {
        /*  Wait for Master up before creation of the HIF channels. If the Slave were not waiting here for
            Master and continue with HIF channel initialization, then the Master would reset Slave's HIF
            configuration during Master init. */
        NXP_LOG_INFO("Wait for Master UP ...\n");
        while(EOK == res)
        {
            if(is_master_up(platform, config->hif_chnls_mask))
            {
                NXP_LOG_INFO("Detected Master UP\n");
                break;
            }

            oal_time_usleep(1000);
            /*  Decrement only for slave_tmout > 0 */
            if (0U < slave_tmout)
            {
                slave_tmout--;
                if (0U == slave_tmout)
                {
                    NXP_LOG_INFO("Detection Master UP timeouted\n");
                    res = ETIMEDOUT;
                }
            }
        }
    }
    else
    {
        NXP_LOG_INFO("Master UP detectection disabled\n");
    }

    if(EOK == res) 
    {
        platform->hif = pfe_hif_create(hif_cbus_base_va, config->hif_chnls_mask);
        if (NULL == platform->hif)
        {
            NXP_LOG_ERROR("Couldn't create HIF instance\n");
            res = ENODEV;
        }
        else 
        {
            pfe_hif_set_master_detect_cfg(platform->hif, !config->disable_master_detect);

            /*  Enable channel interrupts */
            for (ii = 0U; ii < HIF_CFG_MAX_CHANNELS; ii++)
            {
                chnl = pfe_hif_get_channel(platform->hif, hif_ids[ii]);
                if (NULL != chnl)
                {
                    pfe_hif_chnl_irq_unmask(chnl);
                }
            }
        }

    }

    return res;
}

/**
 * @brief       Release HIF-related resources
 */
static void pfe_platform_destroy_hif(pfe_platform_t *platform)
{
    if (NULL != platform->hif)
    {
        pfe_hif_destroy(platform->hif);
        platform->hif = NULL;
    }
}

/**
 * @brief       Register physical interface
 */
static errno_t pfe_platform_register_phy_if(uint32 session_id, pfe_phy_if_t *phy_if)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == phy_if))
    {
        NXP_LOG_ERROR("Null argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Owner of the interface is local driver instance */
        ret = pfe_if_db_add(pfe.phy_if_db, session_id, phy_if, PFE_CFG_LOCAL_IF);
    }

    return ret;
}

/**
 * @brief       Destroy physical interfaces
 */
static void pfe_platform_destroy_pfe_phy_ifs(pfe_platform_t *platform)
{
    pfe_if_db_entry_t *entry = NULL;
    pfe_phy_if_t *phy_if;
    uint32 session_id = 0U;
    errno_t ret;

    if(EOK != pfe_if_db_lock(&session_id))
    {
        NXP_LOG_DEBUG("DB lock failed\n");
    }

    ret = pfe_if_db_get_first(platform->phy_if_db, session_id, IF_DB_CRIT_ALL, NULL, &entry);

    while (NULL != entry)
    {
        phy_if = pfe_if_db_entry_get_phy_if(entry);

        if (EOK != pfe_if_db_remove(platform->phy_if_db, session_id, entry))
        {
            NXP_LOG_DEBUG("Could not remove phy_if DB entry\n");
        }

        pfe_phy_if_destroy(phy_if);
        phy_if = NULL;
        entry = NULL;

        ret = pfe_if_db_get_next(platform->phy_if_db, session_id, &entry);
    }

    if(EOK != ret)
    {
        NXP_LOG_DEBUG("Could not remove phy_if DB entry, DB was locked\n");
    }

    if(EOK != pfe_if_db_unlock(session_id))
    {
        NXP_LOG_DEBUG("DB unlock failed\n");
    }

    if (NULL != platform->phy_if_db)
    {
        pfe_if_db_destroy(platform->phy_if_db);
        platform->phy_if_db = NULL;
    }
}

#if defined(PFE_CFG_FCI_ENABLE)
/**
 * @brief       Start the FCI endpoint
 *
 */
static errno_t pfe_platform_create_fci(pfe_platform_t *platform)
{
    errno_t ret = EOK;

    ret = fci_init(NULL, "pfe_fci_slave");
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Could not create the FCI endpoint\n");
    }
    else 
    {
        platform->fci_created = TRUE;
    }

    return ret;
}

/**
 * @brief       Release FCI-related resources
 */
static void pfe_platform_destroy_fci(pfe_platform_t *platform)
{
    fci_fini();
    platform->fci_created = FALSE;
}
#endif /* PFE_CFG_FCI_ENABLE */

/**
 * @brief       Assign EMAC to the platform
 */
static errno_t pfe_platform_create_emac(pfe_platform_t *platform, const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    /*  EMAC1 */
    platform->emac[0U] = pfe_emac_create(platform->cbus_baseaddr, CBUS_EMAC1_BASE_ADDR,
                            config->emac_mode[0U], EMAC_SPEED_1000_MBPS, EMAC_DUPLEX_FULL);
    if (NULL == platform->emac[0U])
    {
        NXP_LOG_ERROR("Couldn't create EMAC1 instance\n");
        ret = ENODEV;
    }
#ifdef PFE_CFG_IEEE1588_SUPPORT
    else
    {
        platform->emac[0U]->i_clk_hz = PFE_CFG_IEEE1588_I_CLK_HZ;
        platform->emac[0U]->o_clk_hz = PFE_CFG_IEEE1588_EMAC0_O_CLK_HZ;
    }
#endif /* PFE_CFG_IEEE1588_SUPPORT */

    /*  EMAC2 */
    if (EOK == ret)
    {
        platform->emac[1U] = pfe_emac_create(platform->cbus_baseaddr, CBUS_EMAC2_BASE_ADDR,
                                config->emac_mode[1U], EMAC_SPEED_1000_MBPS, EMAC_DUPLEX_FULL);
        if (NULL == platform->emac[1U])
        {
            NXP_LOG_ERROR("Couldn't create EMAC2 instance\n");
            ret = ENODEV;
        }
#ifdef PFE_CFG_IEEE1588_SUPPORT
        else
        {
            platform->emac[1U]->i_clk_hz = PFE_CFG_IEEE1588_I_CLK_HZ;
            platform->emac[1U]->o_clk_hz = PFE_CFG_IEEE1588_EMAC1_O_CLK_HZ;
        }
#endif /* PFE_CFG_IEEE1588_SUPPORT */
    }

    if (EOK == ret)
    {
        /*  EMAC3 */
        platform->emac[2U] = pfe_emac_create(platform->cbus_baseaddr, CBUS_EMAC3_BASE_ADDR,
                                config->emac_mode[2U], EMAC_SPEED_1000_MBPS, EMAC_DUPLEX_FULL);
        if (NULL == platform->emac[2U])
        {
            NXP_LOG_ERROR("Couldn't create EMAC3 instance\n");
            ret = ENODEV;
        }
#ifdef PFE_CFG_IEEE1588_SUPPORT
        else
        {
            platform->emac[2U]->i_clk_hz = PFE_CFG_IEEE1588_I_CLK_HZ;
            platform->emac[2U]->o_clk_hz = PFE_CFG_IEEE1588_EMAC2_O_CLK_HZ;
        }
#endif /* PFE_CFG_IEEE1588_SUPPORT */
    }

    return ret;
}

/**
 * @brief       Release EMAC-related resources
 */
static void pfe_platform_destroy_emac(pfe_platform_t *platform)
{
    uint32 ii;

    for (ii=0U; ii<platform->emac_count; ii++)
    {
        if (NULL != platform->emac[ii])
        {
            platform->emac[ii] = NULL;
        }
    }
}

/**
 * @brief       IDEX RPC callback
 */
void pfe_platform_idex_rpc_cbk(pfe_ct_phy_if_id_t sender, uint32 id, void *buf, uint16 buf_len, void *arg)
{
    pfe_platform_t *platform = (pfe_platform_t *)arg;

    (void)sender;
    (void)id;
    (void)buf;
    (void)buf_len;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == platform))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else 
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)platform;

        NXP_LOG_INFO("Got IDEX RPC request (reference for future use)\n");

        /*  Report execution status to caller */
        if (EOK != pfe_idex_set_rpc_ret_val(EINVAL, NULL, 0U))
        {
            NXP_LOG_ERROR("Could not send RPC response\n");
        }
    }
}

/**
 * @brief       Get physical interface by its ID
 * @param[in]   platform Platform instance
 * @param[in]   id Physical interface ID
 * @return      Physical interface instance or NULL if failed.
 */
pfe_phy_if_t *pfe_platform_get_phy_if_by_id(const pfe_platform_t *platform, pfe_ct_phy_if_id_t id)
{
    pfe_phy_if_t *ret = NULL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == platform))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else if (unlikely(NULL == platform->phy_if_db))
    {
        NXP_LOG_ERROR("Physical interface DB not found\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_if_db_entry_t *entry = NULL;
        uint32 session_id = 0U;
        
        if (EOK != pfe_if_db_lock(&session_id))
        {
            NXP_LOG_DEBUG("DB lock failed\n");
        }

        (void)pfe_if_db_get_first(platform->phy_if_db, session_id, IF_DB_CRIT_BY_ID, (void *)(addr_t)id, &entry);
        ret = pfe_if_db_entry_get_phy_if(entry);

        if (EOK != pfe_if_db_unlock(session_id))
        {
            NXP_LOG_DEBUG("DB unlock failed\n");
        }
    }

    return ret;
}

/*===================================================================================*/
static errno_t phy_ifs_init(void)
{
    uint32 session_id = 0U;
    errno_t ret = pfe_if_db_lock(&session_id);

    if (EOK != ret)
    {
        NXP_LOG_ERROR("DB lock failed\n");
    }
    else
    {
        /*  Create physical interfaces */
        for (sint32 ii=0; phy_ifs[ii].id!=PFE_PHY_IF_ID_INVALID; ii++)
        {
            /*  Create physical IF */
            pfe_phy_if_t *phy_if = pfe_phy_if_create(NULL, phy_ifs[ii].id, phy_ifs[ii].name);
            if (NULL == phy_if)
            {
                NXP_LOG_ERROR("Couldn't create %s\n", phy_ifs[ii].name);
                ret = ENODEV;
            }
            else
            {
                /*  Register in platform */
                if (EOK != pfe_platform_register_phy_if(session_id, phy_if))
                {
                    NXP_LOG_ERROR("Could not register %s\n", pfe_phy_if_get_name(phy_if));
                    pfe_phy_if_destroy(phy_if);
                    ret = ENODEV;
                }
            }

            if(ret != EOK)
            {
                break;
            }
        }

        if (EOK != pfe_if_db_unlock(session_id))
        {
            NXP_LOG_ERROR("DB unlock failed\n");
        }
    }

    return ret;
}

/**
 * @brief       Assign interfaces to the platform.
 */
static errno_t pfe_platform_create_ifaces(void)
{
    errno_t ret = EOK;

    if (NULL == pfe.phy_if_db)
    {
        /*  Create database */
        pfe.phy_if_db = pfe_if_db_create(PFE_IF_DB_PHY);
        if (NULL == pfe.phy_if_db)
        {
            NXP_LOG_DEBUG("Can't create physical interface DB\n");
            ret = ENODEV;
        }
        else 
        {
            ret = phy_ifs_init();
        }
    }

    return ret;
}

/**
 * @brief       Release interface-related resources
 */
void pfe_platform_destroy_ifaces(void)
{
    if (NULL != pfe.phy_if_db)
    {
        pfe_platform_destroy_pfe_phy_ifs(&pfe);
    }
}

/**
 * @brief   The platform initialization function
 * @details Initializes the PFE HW platform and prepares it for usage according to configuration.
 */
errno_t pfe_platform_init(const pfe_platform_config_t *config)
{
    errno_t ret = EOK;

    (void)autolibc_memset(&pfe, 0, sizeof(pfe_platform_t));

    /*  Map CBUS address space */
    pfe.cbus_baseaddr = (addr_t) config->cbus_base;
    if (0ULL == pfe.cbus_baseaddr)
    {
        NXP_LOG_ERROR("Can't map PPFE CBUS\n");
        (void)pfe_platform_remove();
    }
    else
    {
        NXP_LOG_INFO("PFE CBUS p0x%p mapped @ v0x%"PRINTADDR_T"\n", (void *)config->cbus_base, pfe.cbus_baseaddr);

        pfe.pfe_version = *(uint32*)(void*)((addr_t)pfe.cbus_baseaddr + CBUS_GLOBAL_CSR_BASE_ADDR + WSP_VERSION);
        NXP_LOG_INFO("HW version 0x%x\n", (uint_t)pfe.pfe_version);

        /* Health monitor */
        pfe_hm_init();

        pfe.emac_count = 3U;
        ret = pfe_platform_create_emac(&pfe, config);
        if (EOK != ret)
        {
            (void)pfe_platform_remove();
        }
        else
        {
            ret = pfe_platform_create_hif(&pfe, config);
            if (EOK != ret)
            {
                (void)pfe_platform_remove();
            }
            else
            {
                ret = pfe_platform_create_ifaces();
                if (EOK != ret)
                {
                    (void)pfe_platform_remove();
                }
                else
                {
        #if defined(PFE_CFG_FCI_ENABLE)
                    ret = pfe_platform_create_fci(&pfe);
                    if (EOK != ret)
                    {
                        (void)pfe_platform_remove();
                    }
                    else
        #endif /* PFE_CFG_FCI_ENABLE */
                    {
                        pfe.probed = TRUE;
                    }
                }
            }
        }
    }
    return ret;
}

/**
 * @brief       Destroy PFE platform
 */
errno_t pfe_platform_remove(void)
{
    errno_t ret = EOK;

    pfe_hm_destroy();
    pfe_platform_destroy_emac(&pfe);

#if defined(PFE_CFG_FCI_ENABLE)
    pfe_platform_destroy_fci(&pfe);
#endif /* PFE_CFG_FCI_ENABLE */

    pfe_platform_destroy_hif(&pfe);

    pfe.cbus_baseaddr = 0x0ULL;
    pfe.probed = FALSE;

    return ret;
}

/* ========================================================================= */
pfe_platform_t * pfe_platform_get_instance(void)
{
    return pfe.probed ? &pfe : NULL;
}

/* ========================================================================= */
void pfe_platform_remove_sw_if(void)
{
    pfe.phy_if_db = NULL_PTR;
    pfe.hif = NULL_PTR;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /*PFE_CFG_PFE_SLAVE*/


===== 文件 [179/185]: src\pfe_rtable.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/**
 * @addtogroup  dxgr_PFE_RTABLE
 * @{
 *
 * @file        pfe_rtable.c
 * @brief       The RTable module source file.
 * @details     This file contains routing table-related functionality.
 *
 * All values at rtable input level (API) shall be in host byte order format.
 */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"

#if defined(PFE_CFG_RTABLE_ENABLE)

#include "hal.h"
#include "linked_list.h"

#include "fifo.h"
#include "pfe_platform_cfg.h"
#include "pfe_rtable.h"
#include "pfe_class.h"
#include "isa.h"

#define CLEAR_BITMASK(X,MASK)  (((X)|(MASK))^(MASK))
#define ADDU32_WRAP(X,Y)       (uint32)(((uint64)(X)+(Y)) & UINT32_MAX)

/**
 * @brief   If TRUE then driver performs an entry update only if it is ensured that firmware
 *          and the driver are not accessing/updating the same entry in the same time.
 */
#define PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE    TRUE

/* Maximum capacity of entries available in PFE routing table ISA */
#define PFE_CFG_RTABLE_ENTRIES_CAPACITY (PFE_CFG_RT_HASH_SIZE + PFE_CFG_RT_COLLISION_SIZE)

/**
 * @brief   Select criterion argument type
 * @details Used to store and pass argument to the pfe_rtable_match_criterion()
 * @see pfe_rtable_get_criterion_t
 * @see pfe_rtable_match_criterion()
 */
typedef union
{
    pfe_phy_if_t *iface;                /*!< Valid for the RTABLE_CRIT_BY_DST_IF criterion */
    uint32 route_id;                  /*!< Valid for the RTABLE_CRIT_BY_ROUTE_ID criterion */
    uint32 id5t;                      /*!< Valid for the RTABLE_CRIT_BY_ID5T criterion */
    pfe_5_tuple_t five_tuple;           /*!< Valid for the RTABLE_CRIT_BY_5_TUPLE criterion */
} pfe_rtable_criterion_arg_t;

/**
 * @brief   Routing table representation
 */
struct pfe_rtable_tag
{
    addr_t htable_base_pa;                  /*  Hash table: Base physical address */
    addr_t htable_base_va;                  /*  Hash table: Base virtual address */
    addr_t htable_end_pa;                   /*  Hash table: End of hash table, physical */
    addr_t htable_end_va;                   /*  Hash table: End of hash table, virtual */
    addr_t htable_va_pa_offset;             /*  Offset = VA - PA */
    uint32 htable_size;                   /*  Hash table: Number of entries */

    addr_t pool_base_pa;                    /*  Pool: Base physical address */
    addr_t pool_base_va;                    /*  Pool: Base virtual address */
    addr_t pool_end_pa;                     /*  Pool: End of pool, physical */
    addr_t pool_end_va;                     /*  Pool: End of pool, virtual */
    addr_t pool_va_pa_offset;               /*  Offset = VA - PA */
    uint32 pool_size;                     /*  Pool: Number of entries */
    fifo_t *pool_va;                        /*  Pool of entries (virtual addresses) */

    LLIST_t active_entries;                 /*  List of active entries. Need to be protected by mutex */

    pfe_rtable_get_criterion_t cur_crit;    /*  Current criterion */
    LLIST_t *cur_item;                      /*  Current entry to be returned. See ...get_first() and ...get_next() */
    pfe_rtable_criterion_arg_t cur_crit_arg;/*  Current criterion argument */
    pfe_l2br_t *bridge;                     /*  Bridge pointer */
    pfe_class_t *class;                     /*  Classifier */
    uint32 active_entries_count;          /*  Counter of active RTable entries, needed for enabling/disabling of RTable lookup */
    uint32 conntrack_stats_table_addr;
    uint16 conntrack_stats_table_size;
};

/**
 * @brief   Routing table entry at API level
 * @details Since routing table entries (pfe_ct_rtable_entry_t) are shared between
 *          firmware and the driver we're extending them using custom entries. Every
 *          physical entry has assigned an API entry to keep additional, driver-related
 *          information.
 */
struct pfe_rtable_entry_tag
{
    pfe_rtable_t *rtable;                       /*  !< Reference to the parent table */
    pfe_ct_rtable_entry_t *phys_entry;          /*  !< Pointer to the entry within the routing table */
    pfe_ct_rtable_entry_t temp_phys_entry;      /*  !< Temporary storage during entry creation process */
    struct pfe_rtable_entry_tag *next;          /*  !< Pointer to the next entry within the routing table */
    struct pfe_rtable_entry_tag *prev;          /*  !< Pointer to the previous entry within the routing table */
    struct pfe_rtable_entry_tag *child;         /*  !< Entry associated with this one (used to identify entries for 'reply' direction) */
    uint32 timeout;                           /*  !< Timeout value in seconds */
    uint32 curr_timeout;                      /*  !< Current timeout value */
    uint32 route_id;                          /*  !< User-defined route ID */
    bool_t route_id_valid;                      /*  !< If TRUE then 'route_id' is valid */
    sint8 ref_counter;                         /*  !< Count of leased references (pointers) to this entry */
    void *refptr;                               /*  !< User-defined value */
    LLIST_t list_entry;                         /*  !< Linked list element */
    LLIST_t list_to_remove_entry;               /*  !< Linked list element */
};

typedef struct
{
    pfe_ct_rtable_entry_t *new_phys_entry_va;
    pfe_ct_rtable_entry_t *new_phys_entry_pa;
    pfe_ct_rtable_entry_t *last_phys_entry_va;
    uint32 hash;
} pfe_rtable_phys_entry_infor_t;

typedef struct
{
    fifo_t instance;
    __attribute__((aligned(HAL_CACHE_LINE_SIZE))) void *data[PFE_CFG_RT_COLLISION_SIZE];
} pfe_rtable_fifo_t;

/**
 * @brief   IP version type
 */
typedef enum
{
    IPV4 = 0,
    IPV6,
    IPV_INVALID = 0xff
} pfe_ipv_type_t;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"

static uint8 stats_tbl_index[PFE_CFG_CONN_STATS_SIZE + 1];

#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_8
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/* PFE routing table entries storage ISA */
static pfe_isa_t pfe_rtable_entries;
/* PFE routing table entries storage ISA index */
static pfe_isa_index_t pfe_rtable_entries_index[PFE_CFG_RTABLE_ENTRIES_CAPACITY];
/* PFE routing table entries storage ISA pool */
static pfe_rtable_entry_t pfe_rtable_entries_pool[PFE_CFG_RTABLE_ENTRIES_CAPACITY];
/* RTABLE FIFO */
static pfe_rtable_fifo_t pfe_rtable_fifo;
/* routing table singleton */
static pfe_rtable_t pfe_rtable;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
/* usage scope: pfe_rtable_clear_stats */
static const pfe_ct_conntrack_stats_t pfe_rtable_clear_stats_stat = {0};
/* PFE routing table entries storage ISA properties definition */
static const pfe_isa_definition_t pfe_rtable_entries_isa_def =
{
    .item_count = PFE_CFG_RTABLE_ENTRIES_CAPACITY,
    .item_size = (uint32)sizeof(pfe_rtable_entry_t),
    .flags = { .ordered = ISA_FLAG_ANY_ORDER },
    .item_indexes = pfe_rtable_entries_index,
    .items = pfe_rtable_entries_pool
};
#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static uint32 pfe_get_crc32_be(uint32 crc, uint8 *data, uint16 len);
static void pfe_rtable_invalidate(pfe_rtable_t *rtable);
static uint32 pfe_rtable_entry_get_hash(pfe_rtable_entry_t *entry, pfe_ipv_type_t ipv_type, uint32 hash_mask);
static bool_t pfe_rtable_phys_entry_is_htable(const pfe_rtable_t *rtable, const pfe_ct_rtable_entry_t *phys_entry);
static bool_t pfe_rtable_phys_entry_is_pool(const pfe_rtable_t *rtable, const pfe_ct_rtable_entry_t *phys_entry);
static pfe_ct_rtable_entry_t *pfe_rtable_phys_entry_get_pa(pfe_rtable_t *rtable, pfe_ct_rtable_entry_t *phys_entry_va);
static pfe_ct_rtable_entry_t *pfe_rtable_phys_entry_get_va(pfe_rtable_t *rtable, pfe_ct_rtable_entry_t *phys_entry_pa);
static errno_t pfe_rtable_del_entry_nolock_htable(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
static errno_t pfe_rtable_del_entry_nolock_pool(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
static errno_t pfe_rtable_del_entry_nolock(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
static bool_t pfe_rtable_match_criterion(pfe_rtable_get_criterion_t crit, const pfe_rtable_criterion_arg_t *arg, pfe_rtable_entry_t *entry);
static bool_t pfe_rtable_entry_is_in_table(const pfe_rtable_entry_t *entry);
static pfe_rtable_entry_t *pfe_rtable_get_by_phys_entry_va(const pfe_rtable_t *rtable, const pfe_ct_rtable_entry_t *phys_entry_va);
static uint32 pfe_rtable_create_stats_table(pfe_class_t *class, uint16 conntrack_count);
static uint8 pfe_rtable_get_free_stats_index(const pfe_rtable_t *rtable);
static void pfe_rtable_free_stats_index(uint8 index);
static errno_t pfe_rtable_destroy_stats_table(pfe_class_t *class, uint32 table_address);
static bool_t pfe_rtable_entry_is_duplicate(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry);
static errno_t pfe_rtable_add_entry_get_phys_pa(pfe_rtable_t *rtable, pfe_rtable_phys_entry_infor_t *phys_entry_temp);
static errno_t pfe_rtable_add_entry_link(pfe_rtable_t *rtable, pfe_rtable_phys_entry_infor_t *phys_entry_temp);
static void pfe_rtable_add_entry_validate(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry, pfe_rtable_phys_entry_infor_t *phys_entry_temp);
static errno_t pfe_rtable_add_entry_id(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry, pfe_rtable_phys_entry_infor_t *phys_entry_temp);
static void pfe_rtable_entry_free_nolock(pfe_rtable_entry_t *entry, bool_t decrement_ref_counter);
static pfe_rtable_t *pfe_rtable_configure_table(pfe_class_t *class, pfe_rtable_t *rtable, uint32 pool_size);
static pfe_rtable_entry_t *pfe_rtable_prepare_first_entry(pfe_rtable_t *rtable);

errno_t pfe_rtable_clear_stats(const pfe_rtable_t *rtable, uint8 conntrack_index);

#define CRCPOLY_BE 0x04C11DB7U

/**
 * @brief       Get the next free index in the conntrack stats table
 * @return      The index
 */
static uint8 pfe_rtable_get_free_stats_index(const pfe_rtable_t *rtable)
{
    /* Index 0 is the default one. All conntracks that have no space
       in the table will be counted on default index */
    uint16 index = 1U;

    while (index < rtable->conntrack_stats_table_size)
    {
        if (stats_tbl_index[index] == 0U)
        {
            stats_tbl_index[index] = 1U;
            break;
        }
        index ++;
    }

    /* conntrack outside stats range. */
    if (index == rtable->conntrack_stats_table_size)
    {
        index = 0;
    }

    return index;
}

/**
 * @brief       Free the index in the stats table
 * @param[in]       Index of the table
 */
static void pfe_rtable_free_stats_index(uint8 index)
{
    if (index < (PFE_CFG_CONN_STATS_SIZE + 1U))
    {
        stats_tbl_index[index] = 0U;
    }
}

static pfe_rtable_entry_t *pfe_rtable_get_by_phys_entry_va(const pfe_rtable_t *rtable, const pfe_ct_rtable_entry_t *phys_entry_va)
{
    LLIST_t *item;
    pfe_rtable_entry_t *entry;
    bool_t match = FALSE;
    pfe_rtable_entry_t *ret;

    /* There is no protection for the multiple accesses to the table because the function is called
       from the code which has already locked the table */

    /*  Search for first matching entry */
    if (FALSE == LLIST_IsEmpty(&rtable->active_entries))
    {
        /*  Get first matching entry */
        LLIST_ForEach(item, &rtable->active_entries)
        {
            /*  Get data */
            entry = LLIST_Data(item, pfe_rtable_entry_t, list_entry);

            /*  Remember current item to know where to start later */
            if (NULL != entry)
            {
                if (phys_entry_va == entry->phys_entry)
                {
                    match = TRUE;
                    break;
                }
            }
        }
    }

    if (TRUE == match)
    {
        ret = entry;
    }
    else
    {
        ret = NULL;
    }
    return ret;
}

/**
 * @brief       Calculate 32 bit crc
 * @param{in]   initialization value
 * @param[in]   data to be calculated
 * @param[in]   length to be calculated
 * @retval      calculated crc value
 */
static uint32 pfe_get_crc32_be(uint32 crc, uint8 *data, uint16 len)
{
    uint32 tempcrc = crc;

    for(uint16 idx = 0u; idx < len; idx++)
    {
        tempcrc ^= (uint32)data[idx] << 24U;

        for (uint8 i = 0U; i < 8U; i++)
        {
            tempcrc = (tempcrc << 1U) ^ ((0U != (tempcrc & 0x80000000U)) ? CRCPOLY_BE : 0U);
        }
    }

    return tempcrc;
}

/**
 * @brief       Invalidate all routing table entries
 * @param[in]   rtable The routing table instance
 */
static void pfe_rtable_invalidate(pfe_rtable_t *rtable)
{
    uint32 ii;
    pfe_ct_rtable_entry_t *table;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == rtable))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
    table = (pfe_ct_rtable_entry_t *)rtable->htable_base_va;

    for (ii=0U; ii<rtable->htable_size; ii++)
    {
        table[ii].flags = (pfe_ct_rtable_flags_t)(oal_ntohl(0));
        table[ii].next = oal_ntohl(0);
    }

    table = (pfe_ct_rtable_entry_t *)rtable->pool_base_va;

    for (ii=0U; ii<rtable->pool_size; ii++)
    {
        table[ii].flags = (pfe_ct_rtable_flags_t)(oal_ntohl(0));
        table[ii].next = oal_ntohl(0);
    }
    }
}

/**
 * @brief       Get hash for a routing table entry
 * @param[in]   entry The entry
 * @param[in]   ipv_type Frame Ip type
 * @param[in]   hash_mask Mask to be applied on the resulting hash (bitwise AND)
 * @note        IPv4 addresses within entry are in network order due to way how the type is defined
 */
static uint32 pfe_rtable_entry_get_hash(pfe_rtable_entry_t *entry, pfe_ipv_type_t ipv_type, uint32 hash_mask)
{
    uint32 temp = 0U;
    uint32 crc = UINT32_MAX;
    uint32 sport = 0U;
    uint32 ret = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (IPV4 == ipv_type)
        {
            /*  CRC(SIP) + DIP + CRC(SPORT) + DPORT + PROTO */
            sport = entry->phys_entry->ipv.v4.sip ^ ((uint32)(entry->phys_entry->sport) << 16);
            temp = pfe_get_crc32_be(crc, (uint8 *)&sport, 4);
            temp = ADDU32_WRAP(temp, oal_ntohl(entry->phys_entry->ipv.v4.dip));
            temp = ADDU32_WRAP(temp, entry->phys_entry->proto);
            temp = ADDU32_WRAP(temp, (uint32)oal_ntohs(entry->phys_entry->dport));
            ret = (temp & hash_mask);

        }
        else if (IPV6 == ipv_type)
        {
            uint32 crc_ipv6 = 0U;
            sint32 jj;

            for(jj=0; jj<4 ; jj++)
            {
                crc_ipv6 = ADDU32_WRAP(crc_ipv6, oal_ntohl(entry->phys_entry->ipv.v6.sip[jj]));
            }

            /*  CRC(SIP) + DIP + CRC(SPORT) + DPORT + PROTO */
            sport = crc_ipv6 ^ (uint32)oal_ntohs(entry->phys_entry->sport);
            sport = oal_htonl(sport);  /* Convert to big endian because the subsequent crc32 algorithm expects big endian input data. */
            temp = pfe_get_crc32_be(crc,(uint8 *)&sport, 4);
            temp = ADDU32_WRAP(temp, oal_ntohl(entry->phys_entry->ipv.v6.dip[0]));
            temp = ADDU32_WRAP(temp, oal_ntohl(entry->phys_entry->ipv.v6.dip[1]));
            temp = ADDU32_WRAP(temp, oal_ntohl(entry->phys_entry->ipv.v6.dip[2]));
            temp = ADDU32_WRAP(temp, oal_ntohl(entry->phys_entry->ipv.v6.dip[3]));
            temp = ADDU32_WRAP(temp, entry->phys_entry->proto);
            temp = ADDU32_WRAP(temp, (uint32)oal_ntohs(entry->phys_entry->dport));
            ret = (temp & hash_mask);
        }
        else
        {
            NXP_LOG_ERROR("Unknown ip type requested\n");
        }
    }
    
    return ret;
}

/**
 * @brief       Check if entry belongs to hash table
 * @param[in]   rtable The routing table instance
 * @param[in]   phys_entry Entry to be checked (VA or PA)
 * @retval      TRUE Entry belongs to hash table
 * @retval      FALSE Entry does not belong to hash table
 */
static bool_t pfe_rtable_phys_entry_is_htable(const pfe_rtable_t *rtable, const pfe_ct_rtable_entry_t *phys_entry)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == phys_entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (((addr_t)phys_entry >= rtable->htable_base_va) && ((addr_t)phys_entry < rtable->htable_end_va))
        {
            ret = TRUE;
        }
        else
        {
            if (((addr_t)phys_entry >= rtable->htable_base_pa) && ((addr_t)phys_entry < rtable->htable_end_pa))
            {
                ret = TRUE;
            }
            else
            {
                ret = FALSE;
            }
        }
    }

    return ret;
}

/**
 * @brief       Check if entry belongs to the pool
 * @param[in]   rtable The routing table instance
 * @param[in]   phys_entry Entry to be checked (VA or PA)
 * @retval      TRUE Entry belongs to the pool
 * @retval      FALSE Entry does not belong to the pool
 */
static bool_t pfe_rtable_phys_entry_is_pool(const pfe_rtable_t *rtable, const pfe_ct_rtable_entry_t *phys_entry)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == phys_entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (((addr_t)phys_entry >= rtable->pool_base_va) && ((addr_t)phys_entry < rtable->pool_end_va))
        {
            ret = TRUE;
        }
        else
        {
            if (((addr_t)phys_entry >= rtable->pool_base_pa) && ((addr_t)phys_entry < rtable->pool_end_pa))
            {
                ret = TRUE;
            }
            else
            {
                ret = FALSE;
            }
        }
    }

    return ret;
}

/**
 * @brief       Convert entry to physical address
 * @param[in]   rtable The routing table instance
 * @param[in]   phys_entry_va The entry (virtual address)
 * @return      The PA or NULL if failed
 */
static pfe_ct_rtable_entry_t *pfe_rtable_phys_entry_get_pa(pfe_rtable_t *rtable, pfe_ct_rtable_entry_t *phys_entry_va)
{
    pfe_ct_rtable_entry_t *pa;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == phys_entry_va)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        pa = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == pfe_rtable_phys_entry_is_htable(rtable, phys_entry_va))
        {
            pa = (pfe_ct_rtable_entry_t *)OFFSET_ADDR_BASE((addr_t)phys_entry_va, rtable->htable_va_pa_offset);
        }
        else if (TRUE == pfe_rtable_phys_entry_is_pool(rtable, phys_entry_va))
        {
            pa = (pfe_ct_rtable_entry_t *)OFFSET_ADDR_BASE((addr_t)phys_entry_va, rtable->pool_va_pa_offset);
        }
        else
        {
            pa = NULL;
        }
    }

    return pa;
}

/**
 * @brief       Convert entry to virtual address
 * @param[in]   rtable The routing table instance
 * @param[in]   entry_pa The entry (physical address)
 * @return      The VA or NULL if failed
 */
static pfe_ct_rtable_entry_t *pfe_rtable_phys_entry_get_va(pfe_rtable_t *rtable, pfe_ct_rtable_entry_t *phys_entry_pa)
{
    pfe_ct_rtable_entry_t *va;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == phys_entry_pa)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        va = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == pfe_rtable_phys_entry_is_htable(rtable, phys_entry_pa))
        {
            va = (pfe_ct_rtable_entry_t *)ADDR_BASE_OFFSET((addr_t)phys_entry_pa, rtable->htable_va_pa_offset);
        }
        else if (TRUE == pfe_rtable_phys_entry_is_pool(rtable, phys_entry_pa))
        {
            va = (pfe_ct_rtable_entry_t *)ADDR_BASE_OFFSET((addr_t)phys_entry_pa, rtable->pool_va_pa_offset);
        }
        else
        {
            va = NULL;
        }
    }

    return va;
}

/**
 * @brief       Create routing table entry instance
 * @details     Instance is intended to be used to construct the entry before it is
 *              inserted into the routing table.
 * @return      The new instance or NULL if failed
 */
pfe_rtable_entry_t *pfe_rtable_entry_create(void)
{
    pfe_rtable_entry_t *entry;

    entry = (pfe_rtable_entry_t *)isa_reserve(&pfe_rtable_entries);
    if (NULL_PTR != entry)
    {
        (void)autolibc_memset(entry, 0, sizeof(pfe_rtable_entry_t));
        entry->phys_entry = &entry->temp_phys_entry;

        /*  Set defaults */
        entry->rtable = NULL;
        entry->timeout = UINT32_MAX;
        entry->curr_timeout = entry->timeout;
        entry->route_id = 0U;
        entry->route_id_valid = FALSE;
        entry->ref_counter = 0;
        entry->refptr = NULL;
        entry->child = NULL;
        entry->temp_phys_entry.flag_ipv6 = (uint8)IPV_INVALID;
    }
    else
    {
      NXP_LOG_ERROR("PFE RT ISA exhausted, no more entries left\n");
    }

    return entry;
}

/**
 * @brief        Decrement routing table entry refrence counter. Deallocate the entry if no more references.
 * @details      Internal "_nolock" function. It assumes that routing table mutex is already locked.
 * @param[in]    entry    Entry instance previously created by pfe_rtable_entry_create()
 * @param[in]    decrement_ref_counter
 *                         Flag for reference counter decrement.
 *                         TRUE : Function decrements ref_counter. This is a normal behavior.
 *                         FALSE: Function does not decrement ref_counter. This is a special behavior
 *                                for internal routing table contexts where pointer to entry can be 
 *                                 obtained directly, without a need for ref_counter increment.
 */
static void pfe_rtable_entry_free_nolock(pfe_rtable_entry_t *entry, bool_t decrement_ref_counter)
{
    if (NULL_PTR != entry)
    {
        if (TRUE == decrement_ref_counter)
        {
            entry->ref_counter--;
        }

        if (0 >= entry->ref_counter)
        {
            /* Sanity check: Entry is set for deallocation, but is still part of some rtable. THIS SHOULD NEVER HAPPEN */
            if (NULL_PTR != entry->rtable)
            {
                NXP_LOG_WARNING("Refused to deallocate RTable entry @ v0x%p, because the entry is still in some RTable.\n", (void *)entry->phys_entry);
            }
            else
            {
                /* If child link exists, then NULLify the link of child entry. This prevents invalid access to deallocated memory through child pointer. */
                if (NULL_PTR != entry->child)
                {
                    entry->child->child = NULL_PTR;
                }

                /* deallocate the entry */
                (void)isa_release(&pfe_rtable_entries, entry);
            }
        }
    }
}

/**
 * @brief        Decrement routing table entry refrence counter. Deallocate the entry if no more references.
 * @param[in]    rtable    The routing table instance. Needed only for mutex lock.
 *                            Can be NULL if working with standalone routing table entry which
 *                            has never been a part of any routing table. In all other cases,
 *                            provide last routing table which owned the entry.
 * @param[in]    entry    Entry instance previously created by pfe_rtable_entry_create()
 *
 * @important    When code outside of this module obtains pointer to some routing table entry
 *                 via _get_first()/_get_next() or via _get_child(), then call this function
 *                 in outside code when the outside code is done working with the entry.
 */
void pfe_rtable_entry_free(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
{
    if (NULL_PTR != entry)
    {
        /* protect ref_counter manipulation */
        if (NULL_PTR != rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_15);
        }

        pfe_rtable_entry_free_nolock(entry, TRUE);

        /* stop protecting ref_counter manipulation */
        if (NULL_PTR != rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_15);
        }
    }
}

/**
 * @brief       Set 5 tuple values
 * @param[in]   entry The routing table entry instance
 * @param[in]   tuple The 5 tuple type instance
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
errno_t pfe_rtable_entry_set_5t(pfe_rtable_entry_t *entry, const pfe_5_tuple_t *tuple)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_rtable_entry_set_sip(entry, &tuple->src_ip);
        if (EOK == ret)
        {
            ret = pfe_rtable_entry_set_dip(entry, &tuple->dst_ip);
            if (EOK == ret)
            {
                pfe_rtable_entry_set_sport(entry, tuple->sport);
                pfe_rtable_entry_set_dport(entry, tuple->dport);
                pfe_rtable_entry_set_proto(entry, tuple->proto);
            }
        }
    }

    return ret;
}

/**
 * @brief       Set source IP address
 * @param[in]   entry The routing table entry instance
 * @param[in]   ip_addr The IP address
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
errno_t pfe_rtable_entry_set_sip(pfe_rtable_entry_t *entry,const pfe_ip_addr_t *ip_addr)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == ip_addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (ip_addr->is_ipv4)
        {
            if ((entry->phys_entry->flag_ipv6 != (uint8)IPV_INVALID) && (entry->phys_entry->flag_ipv6 != (uint8)IPV4))
            {
                NXP_LOG_ERROR("IP version mismatch\n");
                ret = EINVAL;
            }
            else
            {
                (void)autolibc_memcpy(&entry->phys_entry->ipv.v4.sip, &ip_addr->v4, 4);
                entry->phys_entry->flag_ipv6 = (uint8)IPV4;
                ret = EOK;
            }
        }
        else
        {
            if ((entry->phys_entry->flag_ipv6 != (uint8)IPV_INVALID) && (entry->phys_entry->flag_ipv6 != (uint8)IPV6))
            {
                NXP_LOG_ERROR("IP version mismatch\n");
                ret = EINVAL;
            }
            else
            {
                (void)autolibc_memcpy(&entry->phys_entry->ipv.v6.sip[0], &ip_addr->v6, 16);
                entry->phys_entry->flag_ipv6 = (uint8)IPV6;
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
 * @brief       Get source IP address
 * @param[in]   entry The routing table entry instance
 * @param[out]  ip_addr Pointer where the IP address shall be written
 */
void pfe_rtable_entry_get_sip(pfe_rtable_entry_t *entry, pfe_ip_addr_t *ip_addr)
{
    pfe_5_tuple_t tuple;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == ip_addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK != pfe_rtable_entry_to_5t(entry, &tuple))
        {
            NXP_LOG_ERROR("Entry conversion failed\n");
        }

        (void)autolibc_memcpy(ip_addr, &tuple.src_ip, sizeof(pfe_ip_addr_t));
    }
}

/**
 * @brief       Set destination IP address
 * @param[in]   entry The routing table entry instance
 * @param[in]   ip_addr The IP address
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
errno_t pfe_rtable_entry_set_dip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *ip_addr)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == ip_addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (ip_addr->is_ipv4)
        {
            if ((entry->phys_entry->flag_ipv6 != (uint8)IPV_INVALID) && (entry->phys_entry->flag_ipv6 != (uint8)IPV4))
            {
                NXP_LOG_ERROR("IP version mismatch\n");
                ret = EINVAL;
            }
            else
            {
                (void)autolibc_memcpy(&entry->phys_entry->ipv.v4.dip, &ip_addr->v4, 4);
                entry->phys_entry->flag_ipv6 = (uint8)IPV4;
                ret = EOK;
            }
        }
        else
        {
            if ((entry->phys_entry->flag_ipv6 != (uint8)IPV_INVALID) && (entry->phys_entry->flag_ipv6 != (uint8)IPV6))
            {
                NXP_LOG_ERROR("IP version mismatch\n");
                ret = EINVAL;
            }
            else
            {
                (void)autolibc_memcpy(&entry->phys_entry->ipv.v6.dip[0], &ip_addr->v6, 16);
                entry->phys_entry->flag_ipv6 = (uint8)IPV6;
                ret = EOK;
            }
        }
    }
    return ret;
}

/**
 * @brief       Get destination IP address
 * @param[in]   entry The routing table entry instance
 * @param[out]  ip_addr Pointer where the IP address shall be written
 */
void pfe_rtable_entry_get_dip(pfe_rtable_entry_t *entry, pfe_ip_addr_t *ip_addr)
{
    pfe_5_tuple_t tuple;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == ip_addr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK != pfe_rtable_entry_to_5t(entry, &tuple))
        {
            NXP_LOG_ERROR("Entry conversion failed\n");
        }

        (void)autolibc_memcpy(ip_addr, &tuple.dst_ip, sizeof(pfe_ip_addr_t));
    }

}

/**
 * @brief       Set source L4 port number
 * @param[in]   entry The routing table entry instance
 * @param[in]   sport The port number
 */
void pfe_rtable_entry_set_sport(pfe_rtable_entry_t *entry, uint16 sport)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->phys_entry->sport = oal_htons(sport);
    }
}

/**
 * @brief       Get source L4 port number
 * @param[in]   entry The routing table entry instance
 * @return      The assigned source port number
 */
uint16 pfe_rtable_entry_get_sport(const pfe_rtable_entry_t *entry)
{
    uint16 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = oal_ntohs(entry->phys_entry->sport);
    }
    return ret;
}

/**
 * @brief       Set destination L4 port number
 * @param[in]   entry The routing table entry instance
 * @param[in]   sport The port number
 */
void pfe_rtable_entry_set_dport(pfe_rtable_entry_t *entry, uint16 dport)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->phys_entry->dport = oal_htons(dport);
    }
}

/**
 * @brief       Get destination L4 port number
 * @param[in]   entry The routing table entry instance
 * @return      The assigned destination port number
 */
uint16 pfe_rtable_entry_get_dport(const pfe_rtable_entry_t *entry)
{
    uint16 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = oal_ntohs(entry->phys_entry->dport);
    }
    return ret;
}

/**
 * @brief       Set IP protocol number
 * @param[in]   entry The routing table entry instance
 * @param[in]   sport The protocol number
 */
void pfe_rtable_entry_set_proto(pfe_rtable_entry_t *entry, uint8 proto)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->phys_entry->proto = proto;
    }
}

/**
 * @brief       Get IP protocol number
 * @param[in]   entry The routing table entry instance
 * @return      The assigned protocol number
 */
uint8 pfe_rtable_entry_get_proto(const pfe_rtable_entry_t *entry)
{
    uint8 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = entry->phys_entry->proto;
    }
    return ret;
}

/**
 * @brief       Set destination interface using its ID
 * @param[in]   entry The routing table entry instance
 * @param[in]   if_id Interface ID of interface to be used to forward traffic matching the entry
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
errno_t pfe_rtable_entry_set_dstif_id(pfe_rtable_entry_t *entry, pfe_ct_phy_if_id_t if_id)
{
    errno_t ret;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (if_id > PFE_PHY_IF_ID_MAX)
        {
            NXP_LOG_WARNING("Physical interface ID is invalid: 0x%x\n", if_id);
            ret = EINVAL;
        }
        else
        {
            entry->phys_entry->e_phy_if = if_id;
            ret = EOK;
        }
    }

    return ret;
}
/**
 * @brief       Set destination interface
 * @param[in]   entry The routing table entry instance
 * @param[in]   emac The destination interface to be used to forward traffic matching
 *                    the entry.
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
errno_t pfe_rtable_entry_set_dstif(pfe_rtable_entry_t *entry, const pfe_phy_if_t *iface)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == iface)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_ct_phy_if_id_t if_id = pfe_phy_if_get_id(iface);
        ret = pfe_rtable_entry_set_dstif_id(entry, if_id);
    }

    return ret;
}


/**
 * @brief       Set output source IP address
 * @details     IP address set using this call will be used to replace the original address
 *              if the RT_ACT_CHANGE_SIP_ADDR action is set.
 * @param[in]   entry The routing table entry instance
 * @param[in]   output_sip The desired output source IP address
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
errno_t pfe_rtable_entry_set_out_sip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *output_sip)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == output_sip)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (((uint8)IPV_INVALID != entry->phys_entry->flag_ipv6) && (output_sip->is_ipv4))
        {
            (void)autolibc_memcpy(&entry->phys_entry->args.ipv.v4.sip, &output_sip->v4, 4);
            entry->phys_entry->flag_ipv6 = (uint8)IPV4;
            ret = EOK;
        }
        else if (((uint8)IPV_INVALID != entry->phys_entry->flag_ipv6) && (!output_sip->is_ipv4))
        {
            (void)autolibc_memcpy(&entry->phys_entry->args.ipv.v6.sip[0], &output_sip->v6, 16);
            entry->phys_entry->flag_ipv6 = (uint8)IPV6;
            ret = EOK;
        }
        else
        {
            NXP_LOG_ERROR("IP version mismatch\n");
            ret = EINVAL;
        }

        if (EOK == ret)
        {
            if (NULL != entry->rtable)
            {
                oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_00);
            }
            entry->phys_entry->actions |= oal_htonl(RT_ACT_CHANGE_SIP_ADDR);
            if (NULL != entry->rtable)
            {
                oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_00);
            }
        }
    }

    return ret;
}

/**
 * @brief       Set output destination IP address
 * @details     IP address set using this call will be used to replace the original address
 *              if the RT_ACT_CHANGE_DIP_ADDR action is set.
 * @param[in]   entry The routing table entry instance
 * @param[in]   output_dip The desired output destination IP address
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
errno_t pfe_rtable_entry_set_out_dip(pfe_rtable_entry_t *entry, const pfe_ip_addr_t *output_dip)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == output_dip)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (((uint8)IPV_INVALID != entry->phys_entry->flag_ipv6) && (output_dip->is_ipv4))
        {
            (void)autolibc_memcpy(&entry->phys_entry->args.ipv.v4.dip, &output_dip->v4, 4);
            entry->phys_entry->flag_ipv6 = (uint8)IPV4;
            ret = EOK;
        }
        else if (((uint8)IPV_INVALID != entry->phys_entry->flag_ipv6) && (!output_dip->is_ipv4))
        {
            (void)autolibc_memcpy(&entry->phys_entry->args.ipv.v6.dip[0], &output_dip->v6, 16);
            entry->phys_entry->flag_ipv6 = (uint8)IPV6;
            ret = EOK;
        }
        else
        {
            NXP_LOG_ERROR("IP version mismatch\n");
            ret = EINVAL;
        }

        if (EOK == ret)
        {
            if (NULL != entry->rtable)
            {
                oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_01);
            }
            entry->phys_entry->actions |= oal_htonl(RT_ACT_CHANGE_DIP_ADDR);
            if (NULL != entry->rtable)
            {
                oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_01);
            }
        }
    }

    return ret;
}

/**
 * @brief       Set output source port number
 * @details     Port number set using this call will be used to replace the original source port
 *              if the RT_ACT_CHANGE_SPORT action is set.
 * @param[in]   entry The routing table entry instance
 * @param[in]   output_sport The desired output source port number
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
void pfe_rtable_entry_set_out_sport(const pfe_rtable_entry_t *entry, uint16 output_sport)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != entry->rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_02);
        }
        entry->phys_entry->args.sport = oal_htons(output_sport);
        entry->phys_entry->actions |= oal_htonl(RT_ACT_CHANGE_SPORT);
        if (NULL != entry->rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_02);
        }
    }
}

/**
 * @brief       Set output destination port number
 * @details     Port number set using this call will be used to replace the original destination port
 *              if the RT_ACT_CHANGE_DPORT action is set.
 * @param[in]   entry The routing table entry instance
 * @param[in]   output_sport The desired output destination port number
 * @retval      EOK Success
 * @retval      EINVAL Invalid argument
 */
void pfe_rtable_entry_set_out_dport(pfe_rtable_entry_t *entry, uint16 output_dport)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != entry->rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_03);
        }
        entry->phys_entry->args.dport = oal_htons(output_dport);
        entry->phys_entry->actions |= oal_htonl(RT_ACT_CHANGE_DPORT);
        if (NULL != entry->rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_03);
        }
    }
}

/**
 * @brief       Set TTL decrement
 * @details     Set TTL to be decremented
 *          if the RT_ACT_DEC_TTL action is set.
 * @param[in]   entry The routing table entry instance
 */

void pfe_rtable_entry_set_ttl_decrement(pfe_rtable_entry_t *entry)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != entry->rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_04);
        }
        entry->phys_entry->actions |= oal_htonl(RT_ACT_DEC_TTL);
        if (NULL != entry->rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_04);
        }
    }
}

/**
 * @brief       Remove TTL decrement
 * @details     Remove TTL to be decremented
 *          if the RT_ACT_DEC_TTL action is set.
 * @param[in]   entry The routing table entry instance
 */

void pfe_rtable_entry_remove_ttl_decrement(pfe_rtable_entry_t *entry)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != entry->rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_05);
        }
        entry->phys_entry->actions = CLEAR_BITMASK(entry->phys_entry->actions, oal_htonl(RT_ACT_DEC_TTL));
        if (NULL != entry->rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_05);
        }
    }
}

/**
 * @brief       Set output source and destination MAC address
 * @details     MAC address set using this call will be used to add/replace the original MAC
 *              address if the RT_ACT_ADD_ETH_HDR action is set.
 * @param[in]   entry The routing table entry instance
 * @param[in]   smac The desired output source MAC address
 * @param[in]   dmac The desired output destination MAC address
 */
void pfe_rtable_entry_set_out_mac_addrs(pfe_rtable_entry_t *entry, const pfe_mac_addr_t smac, const pfe_mac_addr_t dmac)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        (void)autolibc_memcpy(entry->phys_entry->args.smac, smac, sizeof(pfe_mac_addr_t));
        (void)autolibc_memcpy(entry->phys_entry->args.dmac, dmac, sizeof(pfe_mac_addr_t));
        if (NULL != entry->rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_06);
        }
        entry->phys_entry->actions |= oal_htonl(RT_ACT_ADD_ETH_HDR);
        if (NULL != entry->rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_06);
        }
    }
}

/**
 * @brief       Set output VLAN tag
 * @details     VLAN tag set using this call will be used to add/replace the original VLAN tag
 *              if the RT_ACT_ADD_VLAN_HDR/RT_ACT_MOD_VLAN_HDR action is set.
 * @param[in]   entry The routing table entry instance
 * @param[in]   vlan The desired output VLAN tag
 * @param[in]   replace When TRUE the VLAN tag will be replaced or added based on ingress
 *                  frame vlan tag presence. When FALSE then VLAN tag will be always added.
 */
void pfe_rtable_entry_set_out_vlan(pfe_rtable_entry_t *entry, uint16 vlan, bool_t replace)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->phys_entry->args.vlan = oal_htons(vlan);
        if (NULL != entry->rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_07);
        }

        entry->phys_entry->actions = CLEAR_BITMASK(entry->phys_entry->actions, oal_htonl(RT_ACT_MOD_VLAN_HDR | RT_ACT_ADD_VLAN_HDR));

        if (replace)
        {
            entry->phys_entry->actions |= oal_htonl(RT_ACT_MOD_VLAN_HDR);
        }
        else
        {
            entry->phys_entry->actions |= oal_htonl(RT_ACT_ADD_VLAN_HDR);
        }

        if (NULL != entry->rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_07);
        }
    }
}

/**
 * @brief       Get output VLAN tag
 * @details     If VLAN addition/replacement for the entry is requested via
 *              pfe_rtable_entry_set_out_vlan() then this function will return
 *              the VLAN tag. If no VLAN manipulation for the entry was has
 *              been requested then the return value is 0.
 * @param[in]   entry The routing table entry instance
 * return       Non-zero VLAN ID (host endian) if VLAN manipulation has been
 *              requested, zero otherwise
 */
uint16 pfe_rtable_entry_get_out_vlan(const pfe_rtable_entry_t *entry)
{
    uint16 ret = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
    {
#endif /* PFE_CFG_NULL_ARG_CHECK */

        if (0U != (oal_ntohl(entry->phys_entry->actions) & (RT_ACT_ADD_VLAN_HDR | RT_ACT_MOD_VLAN_HDR)))
        {
            ret = oal_ntohs(entry->phys_entry->args.vlan);
        }
#if defined(PFE_CFG_NULL_ARG_CHECK)
    }
#endif /* PFE_CFG_NULL_ARG_CHECK */

    return ret;
}

void pfe_rtable_entry_set_id5t(pfe_rtable_entry_t *entry, uint32 id5t)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->phys_entry->id5t = oal_htonl(id5t);
    }
}

errno_t pfe_rtable_entry_get_id5t(const pfe_rtable_entry_t *entry, uint32 *id5t)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        *id5t = oal_ntohl(entry->phys_entry->id5t);
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get actions associated with routing entry
 * @param[in]   entry The routing table entry instance
 * @return      Value (bitwise OR) consisting of flags (pfe_ct_route_actions_t).
 */
pfe_ct_route_actions_t pfe_rtable_entry_get_action_flags(pfe_rtable_entry_t *entry)
{
    pfe_ct_route_actions_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = RT_ACT_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = (pfe_ct_route_actions_t)oal_ntohl(entry->phys_entry->actions);
    }
    return ret;
}

/**
 * @brief       Set entry timeout value
 * @param[in]   entry The routing table entry instance
 * @param[in]   timeout Timeout value in seconds
 */
void pfe_rtable_entry_set_timeout(pfe_rtable_entry_t *entry, uint32 timeout)
{
    uint32 elapsed;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != entry->rtable)
        {
            oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_10);
        }

        if (UINT32_MAX == entry->timeout)
        {
            entry->curr_timeout = timeout;
        }
        else
        {
            elapsed = entry->timeout - entry->curr_timeout;

            if (elapsed >= timeout)
            {
                /*  This will cause entry timeout with next tick */
                entry->curr_timeout = 0U;
            }
            else
            {
                /*  Adjust current timeout by elapsed time of original timeout */
                entry->curr_timeout = timeout - elapsed;
            }
        }

        entry->timeout = timeout;

        if (NULL != entry->rtable)
        {
            oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_10);
        }
    }
}

/**
 * @brief       Set route ID
 * @param[in]   entry The routing table entry instance
 * @param[in]   route_id Custom route identifier value
 */
void pfe_rtable_entry_set_route_id(pfe_rtable_entry_t *entry, uint32 route_id)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->route_id = route_id;
        entry->route_id_valid = TRUE;
    }
}

/**
 * @brief       Get route ID
 * @param[in]   entry The routing table entry instance
 * @param[in]   route_id Pointer to memory where the ID shall be written
 * @retval      EOK Success
 * @retval      ENOENT No route ID associated with the entry
 * @retval      EINVAL Invalid value
 */
errno_t pfe_rtable_entry_get_route_id(const pfe_rtable_entry_t *entry, uint32 *route_id)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == route_id)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (TRUE == entry->route_id_valid)
        {
            *route_id = entry->route_id;
            ret = EOK;
        }
        else
        {
            ret = ENOENT;
        }
    }

    return ret;
}

/**
 * @brief       Bind custom reference pointer
 * @param[in]   entry The routing table entry instance
 * @param[in]   refptr Reference pointer to be bound with entry
 */
void pfe_rtable_entry_set_refptr(pfe_rtable_entry_t *entry, void *refptr)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->refptr = refptr;
    }
}

/**
 * @brief       Get reference pointer
 * @param[in]   entry The routing table entry instance
 * @retval      The reference pointer
 */
void *pfe_rtable_entry_get_refptr(pfe_rtable_entry_t *entry)
{
    void *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ptr = entry->refptr;
    }

    return ptr;
}

/**
 * @brief       Associate with another entry
 * @details     If there is a bi-directional connection, it consists of two routing table entries:
 *              one for original direction and one for reply direction. This function enables
 *              user to bind the associated entries together and simplify handling.
 * @param[in]   entry The routing table entry instance
 * @param[in]   child The routing table entry instance to be linked with the 'entry'. Can be NULL.
 */
void pfe_rtable_entry_set_child(pfe_rtable_entry_t *entry, pfe_rtable_entry_t *child)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        entry->child = child;
        if (NULL_PTR != child)
        {
            child->child = entry;
        }
    }
}

/**
 * @brief        Get associated entry
 * @details        "_nolock" function. It assumes that routing table mutex is already locked.
 *                Outside of the routing table module, this function should be called only from
 *                routing table callbacks.
 * @param[in]    entry    The routing table entry instance
 * @return        The associated routing table entry linked with the 'entry'. NULL if there is not link.
 *
 * @note        When execution thread which called this function finishes working with the provided entry,
 *                it must call pfe_rtable_entry_free() for the given entry to "release" it.
 */
pfe_rtable_entry_t *pfe_rtable_entry_get_child_nolock(const pfe_rtable_entry_t *entry)
{
    pfe_rtable_entry_t *ptr;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ptr = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ptr = entry->child;
        if (NULL_PTR != ptr)
        {
            ptr->ref_counter++;
        }
    }

    return ptr;
}

/**
 * @brief        Get associated entry
 * @param[in]    rtable    The routing table instance. Needed only for mutex lock.
 *                            Can be NULL if working with standalone routing table entry which
 *                            has never been a part of any routing table. In all other cases,
 *                            provide last routing table which owned the entry.
 * @param[in]    entry    The routing table entry instance
 * @return        The associated routing table entry linked with the 'entry'. NULL if there is not link.
 *
 * @note        When execution thread which called this function finishes working with the provided entry,
 *                it must call pfe_rtable_entry_free() for the given entry to "release" it.
 */
pfe_rtable_entry_t *pfe_rtable_entry_get_child(pfe_rtable_t *rtable, const pfe_rtable_entry_t *entry)
{
    pfe_rtable_entry_t *ptr;

    if (NULL_PTR != rtable)
    {
        oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_14);
    }

    ptr = pfe_rtable_entry_get_child_nolock(entry);

    if (NULL_PTR != rtable)
    {
        oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_14);
    }

    return ptr;
}

/**
 * @brief       Get index into statistics table
 * @param[in]   entry The routing table entry instance
 * @return      Index into statistics table.
 */
uint8 pfe_rtable_entry_get_stats_index(const pfe_rtable_entry_t *entry)
{
    uint8 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = (uint8)(oal_ntohs(entry->phys_entry->conntrack_stats_index) & UINT8_MAX);
    }
    return ret;
}

/***
 * @brief       Find out if entry has been added to a routing table
 * @param[in]   entry The routing table entry instance
 * @retval      TRUE Entry is in a routing table
 * @retval      FALSE Entry is not in a routing table
 */
static bool_t pfe_rtable_entry_is_in_table(const pfe_rtable_entry_t *entry)
{
    bool_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == entry))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (NULL != entry->rtable)
        {
            ret = TRUE;
        }
        else
        {
            ret = FALSE;
        }
    }

    return ret;
}

/**
 * @brief       Check if entry is already in the table (5-tuple)
 * @param[in]   rtable The routing table instance
 * @param[in]   entry Entry prototype to be used for search
 * @note        IPv4 addresses within 'entry' are in network order due to way how the type is defined
 * @retval      TRUE Entry already added
 * @retval      FALSE Entry not found
 * @warning     Function is accessing routing table without protection from concurrent accesses.
 *              Caller shall ensure proper protection.
 */
static bool_t pfe_rtable_entry_is_duplicate(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
{
    pfe_rtable_entry_t *entry2;
    pfe_rtable_criterion_arg_t arg;
    bool_t match = FALSE;
    LLIST_t *item;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Check for duplicates */
        if (EOK != pfe_rtable_entry_to_5t(entry, &arg.five_tuple))
        {
            NXP_LOG_ERROR("Entry conversion failed\n");
            match = FALSE;
        }
        else
        {
            /*  Search for first matching entry */
            if (FALSE == LLIST_IsEmpty(&rtable->active_entries))
            {
                /*  Get first matching entry */
                LLIST_ForEach(item, &rtable->active_entries)
                {
                    /*  Get data */
                    entry2 = LLIST_Data(item, pfe_rtable_entry_t, list_entry);

                    if (TRUE == pfe_rtable_match_criterion(RTABLE_CRIT_BY_5_TUPLE, &arg, entry2))
                    {
                        match = TRUE;
                        break;
                    }
                }
            }
        }
    }

    return match;
}

/**
 * @brief       Get physical address of entry
 * @param[in]   rtable The routing table instance
 * @param[in]   phys_entry_temp Temporary saved entry to be added
 * @retval      EOK Success, error code otherwise
 */
static errno_t pfe_rtable_add_entry_get_phys_pa(pfe_rtable_t *rtable, pfe_rtable_phys_entry_infor_t *phys_entry_temp)
{
    errno_t ret = EOK;

    /*  Get physical address */
    phys_entry_temp->new_phys_entry_pa = pfe_rtable_phys_entry_get_pa(rtable, phys_entry_temp->new_phys_entry_va);
    if (NULL == phys_entry_temp->new_phys_entry_pa)
    {
        NXP_LOG_ERROR("Couldn't get PA (entry @ v0x%p)\n", (void *)phys_entry_temp->new_phys_entry_va);
        if (pfe_rtable_phys_entry_is_pool(rtable, phys_entry_temp->new_phys_entry_va))
        {
            /*  Entry from the pool. Return it. */
            ret = fifo_put(rtable->pool_va, phys_entry_temp->new_phys_entry_va);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Couldn't return routing table entry to the pool\n");
            }
        }

        ret = EFAULT;
    }

    return ret;
}

/**
 * @brief       Link entry in the table
 * @param[in]   rtable The routing table instance
 * @param[in]   phys_entry_temp Temporary saved entry to be added
 * @retval      EOK Success, error code otherwise
 */
static errno_t pfe_rtable_add_entry_link(pfe_rtable_t *rtable, pfe_rtable_phys_entry_infor_t *phys_entry_temp)
{
    errno_t ret = EOK;

#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
    pfe_ct_rtable_flags_t valid_tmp;
#endif /* PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE */

    /*  Make sure the new entry is invalid */
    phys_entry_temp->new_phys_entry_va->flags = RT_FL_NONE;

    ret = pfe_rtable_add_entry_get_phys_pa(rtable, phys_entry_temp);

    if(EOK == ret)
    {
        /*  Set link */
        if (TRUE == pfe_rtable_phys_entry_is_htable(rtable, phys_entry_temp->new_phys_entry_va))
        {
            /*  This is very first entry in a hash bucket */
            phys_entry_temp->new_phys_entry_va->next = 0U;
        }
        else
        {
            /*  Find last entry in the chain */
            while (NULL != (void *)(addr_t)phys_entry_temp->last_phys_entry_va->next)
            {
                phys_entry_temp->last_phys_entry_va = pfe_rtable_phys_entry_get_va(rtable, (pfe_ct_rtable_entry_t *)oal_ntohl(phys_entry_temp->last_phys_entry_va->next));
                if(NULL == phys_entry_temp->last_phys_entry_va)
                {
                    ret = EINVAL;
                    break;   
                }
            }

            if(EOK == ret)
            {
                /*  Link last entry with the new one. Both are in network byte order. */
#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
                /*  Invalidate the last entry first */
                valid_tmp = phys_entry_temp->last_phys_entry_va->flags;
                phys_entry_temp->last_phys_entry_va->flags = RT_FL_NONE;

                /*  Wait some time due to sync with firmware */
                oal_time_usleep(10U);
#endif /* PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE */

                /*  Update the next pointer */
                phys_entry_temp->last_phys_entry_va->next = oal_htonl((addr_t)phys_entry_temp->new_phys_entry_pa);

#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
                /*  Ensure that all previous writes has been done */
                hal_wmb();

                /*  Re-enable the entry. Next (new last) entry remains invalid. */
                phys_entry_temp->last_phys_entry_va->flags = valid_tmp;
#endif /* PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE */
            }
        }
    }

    return ret;
}

/**
 * @brief       Add entry in the table
 * @param[in]   rtable The routing table instance
 * @param[in]   entry The entry to be added
 * @param[in]   phys_entry_temp Temporary saved entry to be added
 * @retval      EOK Success
 * @retval      ENOENT Routing table is full
 */
static errno_t pfe_rtable_add_entry_id(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry, pfe_rtable_phys_entry_infor_t *phys_entry_temp)
{
#ifdef PFE_CFG_L2BRIDGE_ENABLE
    pfe_l2br_domain_t *domain;
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
    pfe_ipv_type_t ipv_type = ((uint8)IPV4 == entry->phys_entry->flag_ipv6) ? IPV4: IPV6;
    pfe_ct_rtable_entry_t *hash_table_va = (pfe_ct_rtable_entry_t *)rtable->htable_base_va;
    errno_t ret = EOK;
    uint16 index;

    PfeDevAssert(rtable->htable_size != 0U);
    phys_entry_temp->hash = pfe_rtable_entry_get_hash(entry, ipv_type, (rtable->htable_size - 1U));
    entry->temp_phys_entry.flags = RT_FL_NONE;
    entry->temp_phys_entry.status = CLEAR_BITMASK(entry->temp_phys_entry.status, RT_STATUS_ACTIVE);
    index = (uint16)pfe_rtable_get_free_stats_index(rtable);
    entry->temp_phys_entry.conntrack_stats_index = oal_htons(index);

    /* Add vlan stats index into the phy_entry structure */
    if (0U != (oal_ntohl(entry->temp_phys_entry.actions) & (RT_ACT_ADD_VLAN_HDR | RT_ACT_MOD_VLAN_HDR)))
    {
#ifdef PFE_CFG_L2BRIDGE_ENABLE
        if (NULL != rtable->bridge)
        {
            domain = pfe_l2br_get_first_domain(rtable->bridge, L2BD_CRIT_BY_VLAN, (void *)(addr_t)oal_ntohs(entry->temp_phys_entry.args.vlan));
            if (domain != NULL)
            {
                index = pfe_l2br_get_vlan_stats_index(domain);
                entry->temp_phys_entry.args.vlan_stats_index = oal_htons(index);
            }
            else
            {
                /* Index 0 is the fallback domain */
                entry->temp_phys_entry.args.vlan_stats_index = 0U;
            }
        }
#endif /* PFE_CFG_L2BRIDGE_ENABLE */
    }

    /*  Allocate 'real' entry from hash heads or pool */
    if (0U == (oal_ntohl(hash_table_va[phys_entry_temp->hash].flags) & RT_FL_VALID))
    {
        phys_entry_temp->new_phys_entry_va = &hash_table_va[phys_entry_temp->hash];
    }
    else
    {
        /*  First-level entry is already occupied. Create entry within the pool. Get
            some free entry from the pool first. */
        phys_entry_temp->new_phys_entry_va = fifo_get(rtable->pool_va);
        if (NULL == phys_entry_temp->new_phys_entry_va)
        {
            ret = ENOENT;
        }
        NXP_LOG_WARNING("Routing table hash [%u] collision detected. New entry will be added to linked list leading to performance penalty during lookup.\n", (uint_t)(phys_entry_temp->hash));
    }

    if(EOK == ret)
    {
        /*  Find last entry in the chain */
        phys_entry_temp->last_phys_entry_va = &hash_table_va[phys_entry_temp->hash];
        ret = pfe_rtable_add_entry_link(rtable, phys_entry_temp);
    }

    return ret;
}

/**
 * @brief       Validate entry in the table
 * @param[in]   rtable The routing table instance
 * @param[in]   entry The entry to be added
 * @param[in]   phys_entry_temp Temporary saved hash to be used
 */
static void pfe_rtable_add_entry_validate(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry, pfe_rtable_phys_entry_infor_t *phys_entry_temp)
{
    /*  Validate the new entry */
    if((uint8)IPV4 == entry->phys_entry->flag_ipv6) {
        entry->phys_entry->flags = (pfe_ct_rtable_flags_t)oal_htonl(RT_FL_VALID);
    }
    else
    {
        entry->phys_entry->flags = (pfe_ct_rtable_flags_t)oal_htonl(RT_FL_VALID | RT_FL_IPV6);
    }
    entry->prev = (NULL == phys_entry_temp->last_phys_entry_va) ? NULL : pfe_rtable_get_by_phys_entry_va(rtable, phys_entry_temp->last_phys_entry_va);
    entry->next = NULL;
    if (NULL != entry->prev)
    {
        /*  Store pointer to the new entry */
        entry->prev->next = entry;
    }

    LLIST_AddAtEnd(&entry->list_entry, &rtable->active_entries);

    NXP_LOG_INFO("RTable entry added, hash: 0x%x\n", (uint_t)(phys_entry_temp->hash));

    entry->rtable = rtable;
    entry->ref_counter++;

    if (0U == rtable->active_entries_count)
    {
        NXP_LOG_INFO("RTable first entry added, enable hardware RTable lookup\n");
        pfe_class_rtable_lookup_enable(rtable->class);
    }

    rtable->active_entries_count++;
    NXP_LOG_INFO("RTable active_entries_count: %u\n", (uint_t)(rtable->active_entries_count));
}

/**
 * @brief       Add entry to the table
 * @param[in]   rtable The routing table instance
 * @param[in]   entry The entry to be added
 * @retval      EOK Success
 * @retval      ENOENT Routing table is full
 * @retval      EEXIST Entry is already added
 * @retval      EINVAL Invalid entry
 * @note        IPv4 addresses within entry are in network order due to way how the type is defined
 */
errno_t pfe_rtable_add_entry(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
{
    pfe_rtable_phys_entry_infor_t phys_entry_temp = { 0 };
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Protect table accesses */
        oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_11);

        /*  Check for duplicates */
        if (TRUE == pfe_rtable_entry_is_duplicate(rtable, entry))
        {
            NXP_LOG_INFO("Entry already added\n");
            ret = EEXIST;
        }
        else
        {
            ret = pfe_rtable_add_entry_id(rtable, entry, &phys_entry_temp);
            if(EOK == ret)
            {
                /*  Copy temporary entry into its destination (pool/hash entry) */
                (void)autolibc_memcpy(phys_entry_temp.new_phys_entry_va, &entry->temp_phys_entry, sizeof(pfe_ct_rtable_entry_t));

                /*  Remember the real pointer */
                entry->phys_entry = phys_entry_temp.new_phys_entry_va;

                /*  Remember (physical) location of the new entry within the DDR. */
                entry->phys_entry->rt_orig = oal_htonl((addr_t)phys_entry_temp.new_phys_entry_pa);

                /*  Just invalidate the ingress interface here to not confuse the firmware code */
                entry->phys_entry->i_phy_if = PFE_PHY_IF_ID_INVALID;

                /*  Ensure that all previous writes has been done */
                hal_wmb();

                pfe_rtable_add_entry_validate(rtable, entry, &phys_entry_temp);
            }
        }
        oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_11);
    }
    return ret;
}

/**
 * @brief       Delete an entry from the routing table
 * @param[in]   rtable The routing table instance
 * @param[in]   entry Entry to be deleted
 * @return      EOK if success, error code otherwise
 * @note        IPv4 addresses within entry are in network order due to way how the type is defined
 */
errno_t pfe_rtable_del_entry(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Protect table accesses */
        oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_12);

        ret = pfe_rtable_del_entry_nolock(rtable, entry);

        if (0U == rtable->active_entries_count)
        {
            NXP_LOG_INFO("RTable last entry removed, disable hardware RTable lookup\n");
            pfe_class_rtable_lookup_disable(rtable->class);
        }

        oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_12);
    }

    return ret;
}

/**
 * @brief       Delete an entry from the routing table when htable detected
 * @param[in]   rtable The routing table instance
 * @param[in]   entry Entry to be deleted
 * @return      EOK if success, error code otherwise
 * @note        IPv4 addresses within entry are in network order due to way how the type is defined
 */
static errno_t pfe_rtable_del_entry_nolock_htable(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
{
    pfe_ct_rtable_entry_t *next_phys_entry_pa = NULL;
    errno_t ret = ENOENT;
#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
    pfe_ct_rtable_flags_t valid_tmp;
#endif
    /*  Invalidate the found entry. This will disable the whole chain. */
    entry->phys_entry->flags = RT_FL_NONE;
    if ( entry->temp_phys_entry.conntrack_stats_index != 0U)
    {
        (void)pfe_rtable_clear_stats(rtable, (uint8)(oal_ntohs(entry->temp_phys_entry.conntrack_stats_index) & UINT8_MAX));
        pfe_rtable_free_stats_index((uint8)(oal_ntohs(entry->temp_phys_entry.conntrack_stats_index) & UINT8_MAX));
    }

    if (NULL != entry->next)
    {
#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
    /*  Invalidate also the next entry if any. This will prevent uncertainty
        during copying next entry to the place of the found one. */
    valid_tmp = entry->next->phys_entry->flags;
    entry->next->phys_entry->flags = RT_FL_NONE;

    /*  Ensure that all previous writes has been done */
    hal_wmb();

    /*  Wait some time due to sync with firmware */
    oal_time_usleep(10U);
#endif /* PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE */

                    /*  Replace hash table entry with next (pool) entry */
    (void)autolibc_memcpy(entry->phys_entry, entry->next->phys_entry, sizeof(pfe_ct_rtable_entry_t));

    /*  Clear the copied entry (next one) and return it back to the pool */
    (void)autolibc_memset(entry->next->phys_entry, 0, sizeof(pfe_ct_rtable_entry_t));
    if (TRUE == pfe_rtable_phys_entry_is_pool(rtable, entry->next->phys_entry))
    {
        ret = fifo_put(rtable->pool_va, entry->next->phys_entry);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("Couldn't return routing table entry to the pool\n");
        }
    }
    else
    {
        NXP_LOG_WARNING("Unexpected entry detected\n");
    }

    /*  Next entry now points to the copied physical one */
    entry->next->phys_entry = entry->phys_entry;
    next_phys_entry_pa = pfe_rtable_phys_entry_get_pa(rtable, entry->next->phys_entry);
    entry->next->phys_entry->rt_orig = oal_htonl((addr_t)next_phys_entry_pa);

    /*  Remove entry from the list of active entries and ensure consistency
        of get_first() and get_next() calls */
    if (&entry->list_entry == rtable->cur_item)
    {
        rtable->cur_item = entry->list_entry.prNext;
    }

    LLIST_Remove(&entry->list_entry);

#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
    /*  Validate the new entry */
    entry->next->phys_entry->flags = valid_tmp;
#endif /* PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE */

        /*  Set up links */
        if (NULL != entry->next)
        {
            entry->next->prev = entry->prev;
        }

        entry->prev = NULL;
        entry->next = NULL;
        entry->phys_entry = &entry->temp_phys_entry;
    }
    else
    {
        /*  Ensure that all previous writes has been done */
        hal_wmb();

        /*  Wait some time due to sync with firmware */
        oal_time_usleep(10U);

        /*  Zero-out the entry */
        (void)autolibc_memset(entry->phys_entry, 0, sizeof(pfe_ct_rtable_entry_t));

        /*  Remove entry from the list of active entries and ensure consistency
            of get_first() and get_next() calls */
        if (&entry->list_entry == rtable->cur_item)
        {
            rtable->cur_item = rtable->cur_item->prNext;
        }

        LLIST_Remove(&entry->list_entry);

        entry->prev = NULL;
        entry->next = NULL;
        entry->phys_entry = &entry->temp_phys_entry;
    }

    return ret;
}

/**
 * @brief       Delete an entry from the routing table when pool detected
 * @param[in]   rtable The routing table instance
 * @param[in]   entry Entry to be deleted
 * @return      EOK if success, error code otherwise
 * @note        IPv4 addresses within entry are in network order due to way how the type is defined
 */
static errno_t pfe_rtable_del_entry_nolock_pool(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
{
    errno_t ret;
#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
    pfe_ct_rtable_flags_t valid_tmp;
#endif

#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
    /*  Invalidate the previous entry */
    valid_tmp = entry->prev->phys_entry->flags;
    entry->prev->phys_entry->flags = RT_FL_NONE;

    /*  Invalidate the found entry */
    entry->phys_entry->flags = RT_FL_NONE;

    /*  Wait some time to sync with firmware */
    oal_time_usleep(10U);
#endif /* PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE */

    /*  Bypass the found entry */
    entry->prev->phys_entry->next = entry->phys_entry->next;

#if (TRUE == PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE)
    /*  Ensure that all previous writes has been done */
    hal_wmb();

    /*  Validate the previous entry */
    entry->prev->phys_entry->flags = valid_tmp;
#endif /* PFE_RTABLE_CFG_PARANOID_ENTRY_UPDATE */

    /*  Clear the found entry and return it back to the pool */
    (void)autolibc_memset(entry->phys_entry, 0, sizeof(pfe_ct_rtable_entry_t));
    ret = fifo_put(rtable->pool_va, entry->phys_entry);
    if (EOK != ret)
    {
        NXP_LOG_ERROR("Couldn't return routing table entry to the pool\n");
    }

    /*  Remove entry from the list of active entries and ensure consistency
        of get_first() and get_next() calls */
    if (&entry->list_entry == rtable->cur_item)
    {
        rtable->cur_item = rtable->cur_item->prNext;
    }

    LLIST_Remove(&entry->list_entry);

    /*  Set up links */
    entry->prev->next = entry->next;
    if (NULL != entry->next)
    {
        entry->next->prev = entry->prev;
    }

    entry->prev = NULL;
    entry->next = NULL;
    entry->phys_entry = &entry->temp_phys_entry;

    return ret;
}

/**
 * @brief       Delete an entry from the routing table
 * @details     Internal function to delete an entry from the routing table without locking the table
 * @param[in]   rtable  The routing table instance
 * @param[in]   entry   Entry to be deleted (taken by get_first() or get_next() calls)
 * @return      EOK if success, error code otherwise
 * @note        IPv4 addresses within entry are in network order due to way how the type is defined
 */
static errno_t pfe_rtable_del_entry_nolock(pfe_rtable_t *rtable, pfe_rtable_entry_t *entry)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == entry)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (FALSE == pfe_rtable_entry_is_in_table(entry))
        {
            ret = EOK;
        }
        else
        {

            if (TRUE == pfe_rtable_phys_entry_is_htable(rtable, entry->phys_entry))
            {
                (void)pfe_rtable_del_entry_nolock_htable(rtable, entry);

            }
            else if (TRUE == pfe_rtable_phys_entry_is_pool(rtable, entry->phys_entry))
            {
                (void)pfe_rtable_del_entry_nolock_pool(rtable, entry);
            }
            else
            {
                NXP_LOG_ERROR("Wrong address (found rtable entry @ v0x%p)\n", (void *)entry->phys_entry);
            }

            entry->rtable = NULL;
            entry->ref_counter--;

            if (rtable->active_entries_count > 0U)
            {
                rtable->active_entries_count -= 1U;
                NXP_LOG_INFO("RTable active_entries_count: %u\n", (uint_t)(rtable->active_entries_count));
            }
            else
            {
                NXP_LOG_WARNING("RTable removing active entry while active_entries_count is already = 0 (expected value > 0)\n");
            }

            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Scan the table and update timeouts
 * @param[in]   rtable The routing table instance
 * @note        Runs within the rtable worker thread context
 */
void pfe_rtable_do_timeouts(pfe_rtable_t *rtable)
{
    LLIST_t *item, *aux;
    LLIST_t to_be_removed_list;
    pfe_rtable_entry_t *entry;
    pfe_rtable_entry_status_t flags;
    errno_t err;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == rtable))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        oal_mutex_lock(PFE_RTABLE_LOCK_MUTEX_13);

        LLIST_Init(&to_be_removed_list);

        /*  Go through all active entries */
        LLIST_ForEach(item, &rtable->active_entries)
        {
            entry = LLIST_Data(item, pfe_rtable_entry_t, list_entry);
            flags = entry->phys_entry->status;

            if (UINT32_MAX == entry->timeout)
            {
                continue;
            }

            if (0U != (RT_STATUS_ACTIVE & flags))
            {
                /*  Entry is active. Reset timeout and the active flag. */
                entry->curr_timeout = entry->timeout;
                entry->phys_entry->status = CLEAR_BITMASK(entry->phys_entry->status, RT_STATUS_ACTIVE);
            }
            else
            {
                if (entry->curr_timeout >= PFE_RTABLE_CFG_TICK_PERIOD_SEC)
                {
                    entry->curr_timeout -= PFE_RTABLE_CFG_TICK_PERIOD_SEC;
                }
                else
                {
                    entry->curr_timeout = 0U;
                }

                /*  Entry is not active */
                if (0U == entry->curr_timeout)
                {
                    /*  Collect entries to be removed */
                    LLIST_AddAtEnd(&entry->list_to_remove_entry, &to_be_removed_list);
                }
            }
        }

        LLIST_ForEachRemovable(item, aux, &to_be_removed_list)
        {
            entry = LLIST_Data(item, pfe_rtable_entry_t, list_to_remove_entry);

            /*  Physically remove the entry from table */
            err = pfe_rtable_del_entry_nolock(rtable, entry);
            if (EOK != err)
            {
                NXP_LOG_ERROR("Couldn't delete timed-out entry: %d\n", err);
            }
            else
            {
                pfe_rtable_entry_free_nolock(entry, FALSE);
            }
        }

        oal_mutex_unlock(PFE_RTABLE_LOCK_MUTEX_13);
    }
}

/**
 * @brief       Create the conntrack stats table
 * @details     Create and allocate in dmem the space for stats table that
 *              include all configured conntracks
 * @param[in]   Class instance
 * @param[in]   conntrack_count Number of configured vlan
 * @return      DMEM address of the table
 */
static uint32 pfe_rtable_create_stats_table(pfe_class_t *class, uint16 conntrack_count)
{
    addr_t addr;
    uint32 size;
    pfe_ct_conntrack_statistics_t temp = {0U};
    errno_t res;
    pfe_ct_class_mmap_t mmap = {0U};

    /* Calculate needed size */
    size = (uint32)(((uint64)conntrack_count * sizeof(pfe_ct_conntrack_stats_t)) & UINT32_MAX);
    /* Allocate DMEM */
    addr = pfe_class_dmem_heap_alloc(class, size);
    if(0U == addr)
    {
        NXP_LOG_ERROR("Not enough DMEM memory\n");
    }
    else
    {
        res = pfe_class_get_mmap(class, 0, &mmap);

        if (EOK != res)
        {
            NXP_LOG_ERROR("Cannot get class memory map\n");
            addr = 0U;
        }
        else
        {
            /* Write the table header */
            temp.conntrack_count = oal_htons(conntrack_count);
            temp.stats_table = oal_htonl(addr);
            /*It is safe to write the table pointer because PEs are gracefully stopped in the write function
            * and the written config is read by the firmware */
            res = pfe_class_write_dmem(class, -1, oal_ntohl(mmap.conntrack_statistics), (void *)&temp, sizeof(pfe_ct_conntrack_statistics_t));
            if(EOK != res)
            {
                NXP_LOG_ERROR("Cannot write to DMEM\n");
                pfe_class_dmem_heap_free(class, addr);
                addr = 0U;
            }
        }
    }

    /* Return the DMEM address */
    return addr;
}

/**
 * @brief       Destroy the conntrack stats table
 * @details     Free from dmem the space filled by the table
 * @param[in]   table_address Conntrack stats table address
 * @param[in]   class instance
 */
static errno_t pfe_rtable_destroy_stats_table(pfe_class_t *class, uint32 table_address)
{
    pfe_ct_conntrack_statistics_t temp = {0U};
    pfe_ct_class_mmap_t mmap = {0U};
    errno_t res = EOK;

    if (0U == table_address)
    {
        res = EOK;
    }
    else
    {
        res = pfe_class_get_mmap(class, 0, &mmap);

        if (EOK != res)
        {
            NXP_LOG_ERROR("Cannot get class memory map\n");
        }
        else
        {
            /*It is safe to write the table pointer because PEs are gracefully stopped in the write function
            * and the written config is read by the firmware */
            res = pfe_class_write_dmem(class, -1, oal_ntohl(mmap.conntrack_statistics), (void *)&temp, sizeof(pfe_ct_conntrack_statistics_t));
            if(EOK != res)
            {
                NXP_LOG_ERROR("Cannot write to DMEM\n");
            }
            else
            {
                pfe_class_dmem_heap_free(class, table_address);
            }
        }
    }

    return res;
}

/**
 * @brief       Helper function to create routing table instance
 * @details     Initializes routing table at given memory location.
 * @param[in]   class The classifier instance implementing the routing
 * @param[in]   The routing table instance to be prepared
 * @param[in]   pool_size Number of entries within the pool
 * @return      The routing table instance or NULL if failed
 */

static pfe_rtable_t *pfe_rtable_configure_table(pfe_class_t *class, pfe_rtable_t *rtable, uint32 pool_size)
{
    uint32 ii;
    pfe_ct_rtable_entry_t *table_va;
    errno_t ret;

    rtable->htable_va_pa_offset = OFFSET_ADDR_BASE(rtable->htable_base_va, rtable->htable_base_pa);
    rtable->pool_va_pa_offset = OFFSET_ADDR_BASE(rtable->pool_base_va, rtable->pool_base_pa);


    /* Configure the classifier */
    if (EOK != pfe_class_set_rtable(class, rtable->htable_base_pa, rtable->htable_size, sizeof(pfe_ct_rtable_entry_t)))
    {
        NXP_LOG_ERROR("Unable to set routing table address\n");
        pfe_rtable_destroy(rtable);
        rtable = NULL_PTR;
    }
    else
    {
        /* Initialize the table */
        pfe_rtable_invalidate(rtable);

        /* Create pool. No protection needed. */
        rtable->pool_va = fifo_create(rtable->pool_size, &pfe_rtable_fifo.instance, pfe_rtable_fifo.data);
        if (NULL_PTR == rtable->pool_va)
        {
            NXP_LOG_ERROR("Can't create pool\n");
            pfe_rtable_destroy(rtable);
            rtable = NULL_PTR;
        }
        else
        {
            /*  Fill the pool */
            table_va = (pfe_ct_rtable_entry_t *)rtable->pool_base_va;
            for (ii=0U; ii<pool_size; ii++)
            {
                ret = fifo_put(rtable->pool_va, (void *)&table_va[ii]);
                if (EOK != ret)
                {
                    NXP_LOG_ERROR("Pool filling failed (VA pool)\n");
                    pfe_rtable_destroy(rtable);
                    rtable = NULL_PTR;
                    break;
                }
            }

            if(NULL_PTR != rtable)
            {
                /* Create list */
                LLIST_Init(&rtable->active_entries);

                /* Initialize PFE routined table entries ISA container */
                isa_init(&pfe_rtable_entries, &pfe_rtable_entries_isa_def);
            }
        }
    }
    return rtable;
}

/**
 * @brief       Create routing table instance
 * @details     Creates and initializes routing table at given memory location.
 * @param[in]   class The classifier instance implementing the routing
 * @param[in]   bridge instance for routing
 * @param[in]   table_params include the table sizes and locations
 * @return      The routing table instance or NULL if failed
 */
pfe_rtable_t *pfe_rtable_create(pfe_class_t *class, pfe_l2br_t *bridge, pfe_class_table_sizes_t table_params)
{
    pfe_rtable_t *rtable;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_ADDR == table_params.htable_base_va) || (NULL_ADDR == table_params.pool_base_va) || (NULL_PTR == class)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        rtable = NULL_PTR;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        rtable = &pfe_rtable;

        /*  Initialize the instance */
        (void)autolibc_memset(rtable, 0, sizeof(pfe_rtable_t));

        /*  Store properties */
        rtable->htable_base_va = table_params.htable_base_va;
        rtable->htable_base_pa = (addr_t)table_params.htable_base_va;
        rtable->htable_size = table_params.htable_size;
        PfeDevAssert(rtable->htable_size != 0U);
        rtable->htable_end_va = ADDR_BASE_OFFSET(rtable->htable_base_va, ((uint64)rtable->htable_size * sizeof(pfe_ct_rtable_entry_t)) - 1U);
        rtable->htable_end_pa = ADDR_BASE_OFFSET(rtable->htable_base_pa, ((uint64)rtable->htable_size * sizeof(pfe_ct_rtable_entry_t)) - 1U);

        rtable->pool_base_va = table_params.pool_base_va;
        rtable->pool_base_pa = ADDR_BASE_OFFSET(rtable->htable_base_pa, OFFSET_ADDR_BASE(table_params.pool_base_va, table_params.htable_base_va));
        rtable->pool_size = table_params.pool_size;
        PfeDevAssert(rtable->pool_size != 0U);
        rtable->pool_end_va = ADDR_BASE_OFFSET(rtable->pool_base_va, ((uint64)rtable->pool_size * sizeof(pfe_ct_rtable_entry_t)) - 1U);
        rtable->pool_end_pa = ADDR_BASE_OFFSET(rtable->pool_base_pa, ((uint64)rtable->pool_size * sizeof(pfe_ct_rtable_entry_t)) - 1U);
        rtable->bridge = bridge;
        rtable->class = class;
        rtable->active_entries_count = 0;

        rtable->conntrack_stats_table_size = PFE_CFG_CONN_STATS_SIZE;

        (void)autolibc_memset(&stats_tbl_index, 0, sizeof(stats_tbl_index));

        rtable->conntrack_stats_table_addr = pfe_rtable_create_stats_table(class, PFE_CFG_CONN_STATS_SIZE + 1U);

        if ((NULL_ADDR == rtable->htable_base_va) || (NULL_ADDR == rtable->pool_base_va))
        {
            NXP_LOG_ERROR("Can't map the table memory\n");
            pfe_rtable_destroy(rtable);
            rtable = NULL_PTR;
        }
        else
        {
            rtable = pfe_rtable_configure_table( class, rtable, table_params.pool_size);
        }
    }

    return rtable;
}

/**
* @brief        Returns total count of entries within the table
* @param[in]    rtable The routing table instance
* @return       Total count of entries within the table
*/
uint32 pfe_rtable_get_size(const pfe_rtable_t *rtable)
{
    uint32 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == rtable))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        PfeDevAssert((UINT32_MAX - rtable->pool_size) >= rtable->htable_size);
        ret = rtable->pool_size + rtable->htable_size;
    }

    return ret;
}

/**
 * @brief       Destroy routing table instance
 * @param[in]   rtable The routing table instance
 */
void pfe_rtable_destroy(pfe_rtable_t *rtable)
{
    if (NULL_PTR != rtable)
    {
        if (NULL_ADDR != rtable->htable_base_va)
        {
            /*  Just forget the address */
            rtable->htable_base_va = NULL_ADDR;
        }

        if (NULL_ADDR != rtable->pool_base_va)
        {
            /*  Just forget the address */
            rtable->pool_base_va = NULL_ADDR;
        }

        if (NULL_PTR != rtable->pool_va)
        {
            fifo_destroy(rtable->pool_va);
            rtable->pool_va = NULL_PTR;
        }

        if (EOK != pfe_rtable_destroy_stats_table(rtable->class, rtable->conntrack_stats_table_addr))
        {
            NXP_LOG_DEBUG("Could not destroy conntrack stats\n");
        }

        /* Destroy PFE routing table entries ISA */
        (void)autolibc_memset(&pfe_rtable_entries, 0, sizeof(pfe_rtable_entries));
    }
}

/**
 * @brief       Get size of routing table entry
 * @return      Size of entry in number of bytes
 */
uint32 pfe_rtable_get_entry_size(void)
{
    return (uint32)sizeof(pfe_ct_rtable_entry_t);
}

/**
 * @brief       Convert entry into 5-tuple representation
 * @param[in]   entry The entry to be converted
 * @param[out]  tuple Pointer where the 5-tuple will be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_rtable_entry_to_5t(const pfe_rtable_entry_t *entry, pfe_5_tuple_t *tuple)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Clean the destination */
        (void)autolibc_memset(tuple, 0, sizeof(pfe_5_tuple_t));

        if ((uint8)IPV4 == entry->phys_entry->flag_ipv6)
        {
            /*  SRC + DST IP */
            (void)autolibc_memcpy(&tuple->src_ip.v4, &entry->phys_entry->ipv.v4.sip, 4);
            (void)autolibc_memcpy(&tuple->dst_ip.v4, &entry->phys_entry->ipv.v4.dip, 4);
            tuple->src_ip.is_ipv4 = TRUE;
            tuple->dst_ip.is_ipv4 = TRUE;
            ret = EOK;
        }
        else if ((uint8)IPV6 == entry->phys_entry->flag_ipv6)
        {
            /*  SRC + DST IP */
            (void)autolibc_memcpy(&tuple->src_ip.v6, &entry->phys_entry->ipv.v6.sip[0], 16);
            (void)autolibc_memcpy(&tuple->dst_ip.v6, &entry->phys_entry->ipv.v6.dip[0], 16);
            tuple->src_ip.is_ipv4 = FALSE;
            tuple->dst_ip.is_ipv4 = FALSE;
            ret = EOK;
        }
        else
        {
            NXP_LOG_ERROR("Unknown IP version\n");
            ret = EINVAL;
        }

        if (EOK == ret)
        {
            tuple->sport = oal_ntohs(entry->phys_entry->sport);
            tuple->dport = oal_ntohs(entry->phys_entry->dport);
            tuple->proto = entry->phys_entry->proto;
        }
    }

    return ret;
}

/**
 * @brief       Convert entry into 5-tuple representation (output values)
 * @details     Returns entry values as it will behave after header fields
 *              are changed. See pfe_rtable_entry_set_out_xxx().
 * @param[in]   entry The entry to be converted
 * @param[out]  tuple Pointer where the 5-tuple will be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_rtable_entry_to_5t_out(const pfe_rtable_entry_t *entry, pfe_5_tuple_t *tuple)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == tuple)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Clean the destination */
        (void)autolibc_memset(tuple, 0, sizeof(pfe_5_tuple_t));

        if ((uint8)IPV6 == entry->phys_entry->flag_ipv6)
        {
            /*  SRC + DST IP */
            (void)autolibc_memcpy(&tuple->src_ip.v6, &entry->phys_entry->args.ipv.v6.sip[0], 16);
            (void)autolibc_memcpy(&tuple->dst_ip.v6, &entry->phys_entry->args.ipv.v6.dip[0], 16);
            tuple->src_ip.is_ipv4 = FALSE;
            tuple->dst_ip.is_ipv4 = FALSE;
        }
        else
        {
            /*  SRC + DST IP */
            (void)autolibc_memcpy(&tuple->src_ip.v4, &entry->phys_entry->args.ipv.v4.sip, 4);
            (void)autolibc_memcpy(&tuple->dst_ip.v4, &entry->phys_entry->args.ipv.v4.dip, 4);
            tuple->src_ip.is_ipv4 = TRUE;
            tuple->dst_ip.is_ipv4 = TRUE;
        }

        tuple->sport = oal_ntohs(entry->phys_entry->args.sport);
        tuple->dport = oal_ntohs(entry->phys_entry->args.dport);
        tuple->proto = entry->phys_entry->proto;
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Match entry with latest criterion provided via pfe_rtable_get_first()
 * @param[in]   crit Select criterion
 * @param[in]   arg Criterion argument
 * @param[in]   entry The entry to be matched
 * @retval      TRUE Entry matches the criterion
 * @retval      FALSE Entry does not match the criterion
 */
static bool_t pfe_rtable_match_criterion(pfe_rtable_get_criterion_t crit, const pfe_rtable_criterion_arg_t *arg, pfe_rtable_entry_t *entry)
{
    bool_t match;
    pfe_5_tuple_t five_tuple;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == entry) || (NULL == arg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        match = FALSE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        switch (crit)
        {
            case RTABLE_CRIT_ALL:
                match = TRUE;
                break;

            case RTABLE_CRIT_ALL_IPV4:
                match = ((uint8)IPV4 == entry->phys_entry->flag_ipv6);
                break;

            case RTABLE_CRIT_ALL_IPV6:
                match = ((uint8)IPV6 == entry->phys_entry->flag_ipv6);
                break;

            case RTABLE_CRIT_BY_DST_IF:
                match = (pfe_phy_if_get_id(arg->iface) == (pfe_ct_phy_if_id_t)entry->phys_entry->e_phy_if);
                break;

            case RTABLE_CRIT_BY_ROUTE_ID:
                match = (TRUE == entry->route_id_valid) && (arg->route_id == entry->route_id);
                break;

            case RTABLE_CRIT_BY_ID5T:
                match = (arg->id5t == entry->phys_entry->id5t);
                break;

            case RTABLE_CRIT_BY_5_TUPLE:
                if (EOK != pfe_rtable_entry_to_5t(entry, &five_tuple))
                {
                    NXP_LOG_ERROR("Entry conversion failed\n");
                    match = FALSE;
                }
                else
                {
                    match = (0 == autolibc_memcmp(&five_tuple, &arg->five_tuple, sizeof(pfe_5_tuple_t)));
                }
                break;

            default:
                NXP_LOG_ERROR("Unknown criterion\n");
                match = FALSE;
                break;
        }
    }

    return match;
}

/**
 * @brief       Helper function for pfe_rtable_get_first
 * @details     Intended to be used with pfe_rtable_get_next
 * @param[in]   rtable  The routing table instance
 * @return      The entry or NULL if not found
 */
static pfe_rtable_entry_t *pfe_rtable_prepare_first_entry(pfe_rtable_t *rtable)
{
    pfe_rtable_entry_t *entry = NULL;
    LLIST_t *item;
    bool_t match = FALSE;

/*  Search for first matching entry */
    if (FALSE == LLIST_IsEmpty(&rtable->active_entries))
    {
        /*  Get first matching entry */
        LLIST_ForEach(item, &rtable->active_entries)
        {
            /*  Get data */
            entry = LLIST_Data(item, pfe_rtable_entry_t, list_entry);

            /*  Remember current item to know where to start later */
            rtable->cur_item = item->prNext;
            if (NULL != entry)
            {
                if (TRUE == pfe_rtable_match_criterion(rtable->cur_crit, &rtable->cur_crit_arg, entry))
                {
                    match = TRUE;
                    entry->ref_counter++;
                    break;
                }
            }
        }
    }
    if (TRUE != match)
    {
        entry = NULL;
    }

    return entry;
}

/**
 * @brief       Get first record from the table matching given criterion
 * @details     Intended to be used with pfe_rtable_get_next
 * @param[in]   rtable  The routing table instance
 * @param[in]   crit    Search criterion
 * @param[in]   arg     Pointer to criterion argument. Every value shall to be in HOST endian format.
 * @return      The entry or NULL if not found
 * 
 * @warning     The routing table must be locked for the time the function and its returned entry
 *              is being used since the entry might become asynchronously invalid (timed-out).
 * @note        When execution thread which called this function finishes working with the provided entry,
 *              it must call pfe_rtable_entry_free() for the given entry to "release" it.
 */
pfe_rtable_entry_t *pfe_rtable_get_first(pfe_rtable_t *rtable, pfe_rtable_get_criterion_t crit, void *arg)
{
    pfe_rtable_entry_t *entry = NULL;
    bool_t known_crit = TRUE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == rtable))
    {
        NXP_LOG_ERROR("NULL rtable argument received\n");
        entry = NULL;
    }
    /*  Criterion argument *arg is not used if the criterions is RTABLE_CRIT_ALL, RTABLE_CRIT_ALL_IPV4, RTABLE_CRIT_ALL_IPV6,
        We will not check this argument, and not return NULL entry in these cases. */
    else if ((RTABLE_CRIT_ALL != crit) && (RTABLE_CRIT_ALL_IPV4 != crit) && (RTABLE_CRIT_ALL_IPV6 != crit) && (NULL_PTR == arg))
    {
        /*  All criterions except RTABLE_CRIT_ALL, RTABLE_CRIT_ALL_IPV4, RTABLE_CRIT_ALL_IPV6 require non-NULL argument */
        NXP_LOG_ERROR("NULL criterion argument received\n");
        entry = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Remember criterion and argument for possible subsequent pfe_rtable_get_next() calls */
        rtable->cur_crit = crit;
        switch (rtable->cur_crit)
        {
            case RTABLE_CRIT_ALL:
            case RTABLE_CRIT_ALL_IPV4:
            case RTABLE_CRIT_ALL_IPV6:
                break;

            case RTABLE_CRIT_BY_DST_IF:
                rtable->cur_crit_arg.iface = (pfe_phy_if_t *)arg;
                break;

            case RTABLE_CRIT_BY_ROUTE_ID:
                (void)autolibc_memcpy(&rtable->cur_crit_arg.route_id, arg, sizeof(uint32));
                break;

            case RTABLE_CRIT_BY_ID5T:
                (void)autolibc_memcpy(&rtable->cur_crit_arg.id5t, arg, sizeof(uint32));
                break;

            case RTABLE_CRIT_BY_5_TUPLE:
                (void)autolibc_memcpy(&rtable->cur_crit_arg.five_tuple, arg, sizeof(pfe_5_tuple_t));
                break;

            default:
            {
                NXP_LOG_ERROR("Unknown criterion\n");
                known_crit = FALSE;
                break;
            }
        }

        if(TRUE == known_crit)
        {
                entry = pfe_rtable_prepare_first_entry( rtable );
        }
    }

    return entry;
}

/**
 * @brief       Get next record from the table
 * @details     Intended to be used with pfe_rtable_get_first.
 * @param[in]   rtable  The routing table instance
 * @return      The entry or NULL if not found
 * @warning     The routing table must be locked for the time the function and its returned entry
 *              is being used since the entry might become asynchronously invalid (timed-out).
 * 
 * @note        When execution thread which called this function finishes working with the provided entry,
 *              it must call pfe_rtable_entry_free() for the given entry to "release" it.
 */
pfe_rtable_entry_t *pfe_rtable_get_next(pfe_rtable_t *rtable)
{
    pfe_rtable_entry_t *entry;
    bool_t match = FALSE;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == rtable))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        entry = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (FALSE == LLIST_IsEmpty(&rtable->active_entries))
        {
            if (rtable->cur_item == &rtable->active_entries)
            {
                /*  No more entries */
                entry = NULL;
            }
            else
            {
                while (rtable->cur_item != &rtable->active_entries)
                {
                    /*  Get data */
                    entry = LLIST_Data(rtable->cur_item, pfe_rtable_entry_t, list_entry);

                    /*  Remember current item to know where to start later */
                    rtable->cur_item = rtable->cur_item->prNext;

                    if (NULL != entry)
                    {
                        if (TRUE == pfe_rtable_match_criterion(rtable->cur_crit, &rtable->cur_crit_arg, entry))
                        {
                            match = TRUE;
                            entry->ref_counter++;
                            break;
                        }
                    }
                }
            }
        }

        if (TRUE != match)
        {
            entry = NULL;
        }
    }

    return entry;
}

/**
 * @brief       Get conntrack statistics
 * @param[in]   rtable      The routing table instance
 * @param[in]   conntrack_index     Index in conntrack statistics table
 * @param[out]  stat        Statistic structure
 * @retval      EOK         Success
 * @retval      ENOMEM       Not possible to allocate memory for read
 */
errno_t pfe_rtable_get_stats(const pfe_rtable_t *rtable, pfe_ct_conntrack_stats_t *stat, uint8 conntrack_index)
{
    uint32 i = 0U;
    errno_t ret = EOK;
    uint16 offset = 0;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == rtable) || (NULL == stat)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (conntrack_index > rtable->conntrack_stats_table_size)
        {
            NXP_LOG_ERROR("Invalid conntrack index\n");
        }

        (void)autolibc_memset(stat,0,sizeof(pfe_ct_conntrack_stats_t));

        offset = (uint16)sizeof(pfe_ct_conntrack_stats_t) * (uint16)conntrack_index;

        while(i < pfe_class_get_num_of_pes(rtable->class))
        {
            pfe_ct_conntrack_stats_t stats = {0U};
            /* Gather memory from all PEs*/
            ret = pfe_class_read_dmem((void *)rtable->class, (sint32)i, &stats, ADDR_BASE_OFFSET(rtable->conntrack_stats_table_addr, offset), sizeof(pfe_ct_conntrack_stats_t));
            if (EOK != ret)
            {
                break;
            }

            /* Calculate total statistics */
            stat->hit = ADDU32_WRAP(stat->hit, oal_ntohl(stats.hit));
            stat->hit_bytes = ADDU32_WRAP(stat->hit_bytes, oal_ntohl(stats.hit_bytes));
            ++i;
        }
    }

    return ret;
}

/**
 * @brief       Clear conntrack statistics
 * @param[in]   rtable      The routing table instance
 * @param[in]   conntrack_index Index in conntrack statistics table
 * @retval      EOK Success
 * @retval      NOMEM Not possible to allocate memory for read
 */
errno_t pfe_rtable_clear_stats(const pfe_rtable_t *rtable, uint8 conntrack_index)
{
    errno_t ret = EOK;
    uint16 offset = 0;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == rtable))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (conntrack_index > rtable->conntrack_stats_table_size)
        {
            NXP_LOG_ERROR("Invalid conntrack index\n");
            ret = EINVAL;
        }
        else
        {
            offset = (uint16)sizeof(pfe_ct_conntrack_stats_t) * (uint16)conntrack_index;
            ret = pfe_class_write_dmem((void *)rtable->class, -1, ADDR_BASE_OFFSET(rtable->conntrack_stats_table_addr, offset), &pfe_rtable_clear_stats_stat, sizeof(pfe_ct_conntrack_stats_t));
        }
    }
    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return conntrack statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   rtable      The routing table instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_rtable_get_text_statistics(const pfe_rtable_t *rtable, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;
    errno_t ret;
    pfe_ct_conntrack_stats_t stats = {0};
    LLIST_t *item;
    const pfe_rtable_entry_t *entry;

    /* We keep unused parameter verb_level for consistency with rest of the *_get_text_statistics() functions */
    (void)verb_level;

    ret = pfe_rtable_get_stats(rtable, &stats, 0);

    if (EOK != ret)
    {
        len = 0U;
    }
    else
    {
        len += oal_util_snprintf(buf + len, buf_len - len, "Default               hit: %12d hit_bytes: %12d\n", stats.hit, stats.hit_bytes);

        LLIST_ForEach(item, &rtable->active_entries)
        {
            entry = LLIST_Data(item, pfe_rtable_entry_t, list_entry);

            if (oal_ntohs(entry->phys_entry->conntrack_stats_index) != 0U)
            {
                ret = pfe_rtable_get_stats(rtable, &stats, oal_ntohs(entry->phys_entry->conntrack_stats_index));

                if (EOK != ret)
                {
                    continue;
                }

                len += oal_util_snprintf(buf + len, buf_len - len, "Conntrack route_id %2d hit: %12d hit_bytes: %12d\n", oal_ntohl(entry->route_id) , stats.hit, stats.hit_bytes);
            }
        }
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#endif /* PFE_CFG_RTABLE_ENABLE */


===== 文件 [180/185]: src\pfe_tmu.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_feature_mgr.h"
#include "pfe_tmu.h"
#include "pfe_tmu_csr.h"

struct pfe_tmu_tag
{
    addr_t cbus_base_va;
    pfe_class_t *class;
};


typedef struct
{
    pfe_tmu_queue_mode_t mode;  /*queue mode*/
    uint32 min;               /*Min threshold (number of packets)*/
    uint32 max;               /*Max threshold (number of packets)*/
    uint16 sum;               /*Sum of queue lengths*/
}pfe_tmu_queue_params;

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_tmu_t tmu_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_tmu_set_queue_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, pfe_tmu_queue_params parameters);

/**
 * @brief       Check whether the provided physical interface ID represents HIF-type interface or not.
 * @details     Optionally, for HIF-type interfaces the function can also provide index of the given HIF
 *              within  pfe_ct_hif_tmu_queue_sizes_t  (for FW feature err051211_workaround).
 * @param[in]   id  Interface ID
 * @param[out]  err051211_hif_id    [optional] Index of the HIF interface in  pfe_ct_hif_tmu_queue_sizes_t. Can be NULL.
 * @return      TRUE if the provided ID represents HIF-type physical interface.
 */
static bool_t is_hif_by_id(pfe_ct_phy_if_id_t id, uint8 *err051211_hif_idx)
{
    bool_t ret = FALSE;
    uint8 hif_idx;

    /* Check that indexes 0 .. 3 can be assigned */
    ct_assert((sizeof(pfe_ct_hif_tmu_queue_sizes_t) / sizeof(uint16)) == 4U);

    switch (id)
    {
        case PFE_PHY_IF_ID_HIF0:
            hif_idx = 0U;
            ret = TRUE;
            break;
        case PFE_PHY_IF_ID_HIF1:
            hif_idx = 1U;
            ret = TRUE;
            break;
        case PFE_PHY_IF_ID_HIF2:
            hif_idx = 2U;
            ret = TRUE;
            break;
        case PFE_PHY_IF_ID_HIF3:
            hif_idx = 3U;
            ret = TRUE;
            break;
        default:
            ret = FALSE;
            hif_idx = 0U;
            break;
    }

    if (NULL != err051211_hif_idx)
    {
        *err051211_hif_idx = hif_idx;
    }

    return ret;
}

/**
 * @brief       Compute new sum of queue lenghts for the given physical interface.
 *              Also check that the new sum does not exceed any applicable limitations.
 * @param[in]   tmu     The TMU instance
 * @parma[in]   phy     Physical interface ID
 * @param[in]   queue   The queue ID
 * @param[in]   max     New max threshold (number of packets) for the queue
 * @param[out]  sum     Pointer to result of sum calculation (passback)
 * @return      EOK if computation and all applicable checks are OK.
 */
static errno_t get_sum_of_queue_lengths(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy,
        uint8 queue, uint32 max, uint16* sum)
{
    errno_t ret_val = ENOSPC;
    uint32 tmp_sum = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == tmu) || (NULL == sum)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Compute new sum of queue lengths */
        const uint8 cnt = pfe_tmu_queue_get_cnt(tmu, phy);
        for (uint8 i = 0U; i < cnt; i++)
        {
            uint32 tmp_min = 0U;
            uint32 tmp_max = 0U;
            if (i == queue)
            {
                tmp_max = max;
            }
            else 
            {
                (void)pfe_tmu_queue_get_mode(tmu, phy, i, &tmp_min, &tmp_max);
            }
            PfeDevAssert(tmp_sum <= UINT32_MAX - tmp_max);
            tmp_sum += tmp_max;
        }

        /* Check the new sum */
        if (TRUE == is_hif_by_id(phy, NULL))
        {   /* HIF */
            if (TLITE_HIF_MAX_ENTRIES < tmp_sum)
            {
                NXP_LOG_ERROR("Sum of queue lengths (%u) exceeds max allowed sum (%u) for HIF interface.", (uint_t)tmp_sum, TLITE_HIF_MAX_ENTRIES);
                ret_val = ENOSPC;
            }
            else if ((TRUE == pfe_feature_mgr_is_available("err051211_workaround")) &&
                     (PFE_HIF_RX_RING_CFG_LENGTH < (tmp_sum + PFE_TMU_ERR051211_Q_OFFSET)))
            {
                NXP_LOG_ERROR("err051211_workaround is active and \"sum of queue lengths (%u) + Q_OFFSET (%u)\" exceeds HIF RX Ring length (%u).", (uint_t)tmp_sum, PFE_TMU_ERR051211_Q_OFFSET, PFE_HIF_RX_RING_CFG_LENGTH);
                ret_val = ENOSPC;
            }
            else
            {
                ret_val = EOK;
            }
        }
        else
        {   /* EMAC and 'others' */
            if (TLITE_MAX_ENTRIES < tmp_sum)
            {
                NXP_LOG_ERROR("Sum of queue lengths (%u) exceeds max allowed sum (%u) for EMAC/UTIL/HIF_NOCPY interface.", (uint_t)tmp_sum, TLITE_MAX_ENTRIES);
                ret_val = ENOSPC;
            }
            else
            {
                ret_val = EOK;
            }
        }

        /* Set passback value */
        *sum = (uint16)tmp_sum;
    }

    return ret_val;
}

/**
 * @brief       Set all TMU queues of the target physical interface to minimal possible lengths.
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @return      EOK if success, error code otherwise
 */
static errno_t set_all_queues_to_min_length(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy)
{
    errno_t ret_val = EINVAL;
    uint8 queue;
    uint8 queue_cnt = 0U;

    pfe_tmu_queue_mode_t mode = TMU_Q_MODE_TAIL_DROP;
    uint32 min = 0UL;
    uint32 max = 0UL;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        queue_cnt = pfe_tmu_queue_get_cnt(tmu, phy);
        for (queue = 0U; (queue_cnt > queue); queue++)
        {
            if (EOK != pfe_tmu_check_queue(tmu, phy, queue))
            {
                ret_val = EINVAL;
            }
            else
            {
                mode = pfe_tmu_queue_get_mode(tmu, phy, queue, &min, &max);
                switch (mode)
                {
                    case TMU_Q_MODE_TAIL_DROP:
                    {
                        ret_val = pfe_tmu_q_mode_set_tail_drop(tmu->cbus_base_va, phy, queue, 1U);
                        break;
                    }

                    case TMU_Q_MODE_WRED:
                    {
                        ret_val = pfe_tmu_q_mode_set_wred(tmu->cbus_base_va, phy, queue, 0U, 1U);
                        break;
                    }

                    case TMU_Q_MODE_DEFAULT:
                    {
                        ret_val = pfe_tmu_q_mode_set_default(tmu->cbus_base_va, phy, queue);
                        break;
                    }

                    default:
                    {
                        NXP_LOG_ERROR("Unknown queue mode: %d\n", mode);
                        ret_val = EINVAL;
                        break;
                    }
                }
            }
        }
    }
    return ret_val;
}

/**
 * @brief       Set the configuration of the TMU block.
 * @param[in]   tmu The TMU instance
 * @param[in]   cfg Pointer to the configuration structure
 */
static void pfe_tmu_init(const pfe_tmu_t *tmu, const pfe_tmu_cfg_t *cfg)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == tmu) || (NULL == cfg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_tmu_disable(tmu);

        if (EOK != pfe_tmu_cfg_init(tmu->cbus_base_va, cfg))
        {
            NXP_LOG_ERROR("Couldn't initialize the TMU\n");
        }
    }
}

/**
 * @brief       Set queue mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[in]   parameters The queue parameters
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_tmu_set_queue_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, pfe_tmu_queue_params parameters )
{
    errno_t ret_val = EOK;
    bool_t ReVal;
    uint16 sum_tmp = 0U;
    uint8 err051211_hif_idx = 0xFF;   /* Index of HIF in  pfe_ct_hif_tmu_queue_sizes_t */

    /* If err051211_workaround is active and queue of some HIF was modified, then update sum of queue lengths in firmware. */
    ReVal = pfe_feature_mgr_is_available("err051211_workaround");
    if ((TRUE == is_hif_by_id(phy, &err051211_hif_idx)) &&
        (TRUE == ReVal))
    {
        pfe_ct_class_mmap_t mmap = {0};
        ret_val = pfe_class_get_mmap(tmu->class, 0, &mmap);
        if (EOK == ret_val)
        {
            const uint32 addr = oal_ntohl(mmap.hif_tmu_queue_sizes) + (err051211_hif_idx * sizeof(uint16));
            sum_tmp = oal_htons(parameters.sum);
            ret_val = pfe_class_write_dmem(tmu->class, -1, addr, (void *)&sum_tmp, sizeof(uint16));
        }
    }

    /* Set new tmu configuration */
    if (EOK == ret_val)
    {
        switch (parameters.mode)
        {
            case TMU_Q_MODE_TAIL_DROP:
            {
                ret_val = pfe_tmu_q_mode_set_tail_drop(tmu->cbus_base_va, phy, queue, (uint16)(parameters.max & UINT16_MAX));
                break;
            }

            case TMU_Q_MODE_WRED:
            {
                ret_val = pfe_tmu_q_mode_set_wred(tmu->cbus_base_va, phy, queue, (uint16)(parameters.min & UINT16_MAX), (uint16)(parameters.max & UINT16_MAX));
                break;
            }

            case TMU_Q_MODE_DEFAULT:
            {
                ret_val = pfe_tmu_q_mode_set_default(tmu->cbus_base_va, phy, queue);
                break;
            }

            default:
            {
                NXP_LOG_ERROR("Unknown queue mode: %d\n", parameters.mode);
                ret_val = EINVAL;
                break;
            }
        }
    }

    return ret_val;
}

/**
* @brief Create new TMU instance
* @details      Creates and initializes TMU instance. After successful
*               call the TMU is configured and disabled.
* @param[in]    cbus_base_va CBUS base virtual address
* @param[in]    pe_num Number of PEs to be included
* @param[in]    cfg The TMU block configuration
* @param[in]    class Classifier instance
* @return       The TMU instance or NULL if failed
*/
pfe_tmu_t *pfe_tmu_create(addr_t cbus_base_va, uint32 pe_num, const pfe_tmu_cfg_t *cfg,
                          pfe_class_t *class)
{
    pfe_tmu_t *tmu;
    (void)pe_num;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_ADDR == cbus_base_va) || (NULL == cfg) || (NULL == class)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        tmu = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        tmu = &tmu_instance;
        (void)autolibc_memset(tmu, 0, sizeof(pfe_tmu_t));
        tmu->cbus_base_va = cbus_base_va;
        tmu->class = class;

        /*  Issue block reset */
        pfe_tmu_reset(tmu);

        /* Initialize reclaim memory */
        pfe_tmu_reclaim_init(cbus_base_va);

        /*  Disable the TMU */
        pfe_tmu_disable(tmu);

        /*  Set new configuration */
        pfe_tmu_init(tmu, cfg);
    }

    return tmu;
}

/**
 * @brief       Reset the TMU block
 * @param[in]   tmu The TMU instance
 */
void pfe_tmu_reset(const pfe_tmu_t *tmu)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_tmu_cfg_reset(tmu->cbus_base_va);
    }
}

/**
 * @brief       Enable the TMU block
 * @details     Enable all TMU PEs
 * @param[in]   tmu The TMU instance
 */
void pfe_tmu_enable(const pfe_tmu_t *tmu)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_tmu_cfg_enable(tmu->cbus_base_va);
    }
}

/**
 * @brief       Disable the TMU block
 * @details     Disable all TMU PEs
 * @param[in]   tmu The TMU instance
 */
void pfe_tmu_disable(const pfe_tmu_t *tmu)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_tmu_cfg_disable(tmu->cbus_base_va);
    }
}

/**
 * @brief       Destroy TMU instance
 * @param[in]   tmu The TMU instance
 */
void pfe_tmu_destroy(const pfe_tmu_t *tmu)
{
    if (NULL != tmu)
    {
        pfe_tmu_disable(tmu);
    }
}

/*
 * @brief       Check if phy+queue combination is valid
 * @param[in]   tmu The TMU instance
 * @param[in]   phy Physical interface ID
 * @param[in]   queue Queue ID
 * @return      EOK if the arguments are valid
 */
errno_t pfe_tmu_check_queue(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue)
{
    const pfe_tmu_phy_cfg_t *pcfg;
    errno_t ret;

    (void)tmu;

    pcfg = pfe_tmu_cfg_get_phy_config(phy);
    if (NULL == pcfg)
    {
        NXP_LOG_WARNING("Invalid phy: %d\n", phy);
        ret = EINVAL;
    }
    else
    {
        if ((queue >= pcfg->q_cnt) && (queue != PFE_TMU_INVALID_QUEUE))
        {
            NXP_LOG_WARNING("Invalid queue ID (%d). PHY %d implements %d queues\n",
                    queue, phy, pcfg->q_cnt);
            ret = ENOENT;
        }
        else
        {
            ret = EOK;
        }
    }

    return ret;
}

/*
 * @brief       Check if phy+scheduler combination is valid
 * @param[in]   tmu The TMU instance
 * @param[in]   phy Physical interface ID
 * @param[in]   sch Scheduler ID
 * @return      EOK if the arguments are valid
 */
errno_t pfe_tmu_check_scheduler(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch)
{
    const pfe_tmu_phy_cfg_t *pcfg;
    errno_t ret;

    (void)tmu;

    pcfg = pfe_tmu_cfg_get_phy_config(phy);
    if (NULL == pcfg)
    {
        NXP_LOG_WARNING("Invalid phy: %d\n", (int_t)phy);
        ret = EINVAL;
    }
    else
    {
        if (sch >= pcfg->sch_cnt)
        {
            NXP_LOG_WARNING("Invalid scheduler ID (%d). PHY %d implements %d schedulers\n",
                    sch, phy, pcfg->sch_cnt);
            ret = ENOENT;
        }
        else
        {
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Check if phy+shaper combination is valid
 * @param[in]   tmu The TMU instance
 * @param[in]   phy Physical interface ID
 * @param[in]   shp Shaper ID
 * @return      EOK if the arguments are valid
 */
errno_t pfe_tmu_check_shaper(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    const pfe_tmu_phy_cfg_t *pcfg;
    errno_t ret;

    (void)tmu;

    pcfg = pfe_tmu_cfg_get_phy_config(phy);
    if (NULL == pcfg)
    {
        NXP_LOG_WARNING("Invalid phy: %d\n", (int_t)phy);
        ret = EINVAL;
    }
    else
    {
        if (shp >= pcfg->shp_cnt)
        {
            NXP_LOG_WARNING("Invalid shaper ID (%d). PHY %d implements %d shapers\n",
                    shp, phy, pcfg->shp_cnt);
            ret = ENOENT;
        }
        else
        {
            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Get number of packets in the queue
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[out]  level Pointer to memory where the fill level value shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_queue_get_fill_level(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *level)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == tmu) || (NULL == level)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_queue(tmu, phy, queue))
        {
            ret = pfe_tmu_q_cfg_get_fill_level(tmu->cbus_base_va, phy, queue, level);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get number of packet dropped by queue
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[out]  level Pointer to memory where the count shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_queue_get_drop_count(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == tmu) || (NULL == cnt)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_queue(tmu, phy, queue))
        {
            ret = pfe_tmu_q_cfg_get_drop_count(tmu->cbus_base_va, phy, queue, cnt);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get number of packet transmitted from queue
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[out]  level Pointer to memory where the count shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_queue_get_tx_count(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == tmu) || (NULL == cnt)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_queue(tmu, phy, queue))
        {
            ret = pfe_tmu_q_cfg_get_tx_count(tmu->cbus_base_va, phy, queue, cnt);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Set queue mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[in]   mode Mode
 * @param[in]   min Min threshold (number of packets)
 * @param[in]   max Max threshold (number of packets)
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_queue_set_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue,
        pfe_tmu_queue_mode_t mode, uint32 min, uint32 max)
{
    errno_t ret_val = EOK;
    uint16 sum = 0U;  /* Sum of queue lengths */

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret_val = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /* Check and set mode + lengths */
        if (min > max)
        {
            NXP_LOG_ERROR("Wrong queue lengths: min queue length (%u) is larger than max queue length (%u)\n", (uint_t)min, (uint_t)max);
            ret_val = EINVAL;
        }
        else if (EOK != pfe_tmu_check_queue(tmu, phy, queue))
        {
            ret_val = EINVAL;
        }
        else if (EOK != get_sum_of_queue_lengths(tmu, phy, queue, max, &sum))
        {
            ret_val = ENOSPC;
        }
        else
        {
            pfe_tmu_queue_params queue_params = {.mode = mode, .min = min, .max = max,.sum = sum};
            ret_val = pfe_tmu_set_queue_mode(tmu, phy, queue, queue_params);
        }
    }

    return ret_val;
}

/**
 * @brief       Get queue mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[in]   mode Mode
 * @param[in]   min Pointer to memory where 'min' value shall be written
 * @param[in]   max Pointer to memory where 'max' value shall be written
 * @return      EOK if success, error code otherwise
 */
pfe_tmu_queue_mode_t pfe_tmu_queue_get_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy,
        uint8 queue, uint32 *min, uint32 *max)
{
    pfe_tmu_queue_mode_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = TMU_Q_MODE_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_queue(tmu, phy, queue))
        {
            ret = pfe_tmu_q_get_mode(tmu->cbus_base_va, phy, queue, min, max);
        }
        else
        {
            ret = TMU_Q_MODE_INVALID;
        }
    }
    return ret;
}

/**
 * @brief       Set WRED zone probability
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[in]   zone Zone index
 * @param[in]   prob Drop probability in [%]
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_queue_set_wred_prob(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 prob)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_queue(tmu, phy, queue))
        {
            if (zone >= pfe_tmu_queue_get_wred_zones(tmu, phy, queue))
            {
                NXP_LOG_DEBUG("Zone index out of range\n");
                ret = EINVAL;
            }
            else if (prob > 100U)
            {
                NXP_LOG_DEBUG("Probability out of range\n");
                ret = EINVAL;
            }
            else
            {
                ret = pfe_tmu_q_set_wred_probability(tmu->cbus_base_va, phy, queue, zone, prob);
            }
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get WRED zone probability
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @param[in]   zone Zone index
 * @param[in]   prob Poiter to memory where drop probability in [%] shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_queue_get_wred_prob(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 *prob)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_queue(tmu, phy, queue))
        {
            if (zone >= pfe_tmu_queue_get_wred_zones(tmu, phy, queue))
            {
                NXP_LOG_DEBUG("Zone index out of range\n");
                ret = EINVAL;
            }
            else
            {
                ret = pfe_tmu_q_get_wred_probability(tmu->cbus_base_va, phy, queue, zone, prob);
            }
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get number of WRED probability zones
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   queue The queue ID
 * @return      Number of zones between 'min' and 'max'
 */
uint8 pfe_tmu_queue_get_wred_zones(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 queue)
{
    uint8 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_queue(tmu, phy, queue))
        {
            ret = pfe_tmu_q_get_wred_zones(tmu->cbus_base_va, phy, queue);
        }
        else
        {
            ret = 0U;
        }
    }

    return ret;
}

errno_t pfe_tmu_queue_reset_tail_drop_policy(const pfe_tmu_t *tmu)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_tmu_q_reset_tail_drop_policy(tmu->cbus_base_va);
    }

    return ret;
}

/**
 * @brief       Enforce compliance of queue length sums of all HIF interfaces with
 *              err051211_workaround constraints. Also update data in FW.
 * @param[in]   tmu The TMU instance
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_queue_err051211_sync(const pfe_tmu_t *tmu)
{
    static const pfe_ct_phy_if_id_t phys[] = {
        PFE_PHY_IF_ID_HIF0, 
        PFE_PHY_IF_ID_HIF1, 
        PFE_PHY_IF_ID_HIF2, 
        PFE_PHY_IF_ID_HIF3,
    };
    pfe_tmu_queue_mode_t mode = TMU_Q_MODE_TAIL_DROP;
    uint32 min = 0UL;
    uint32 max = 0UL;
    uint32 default_max = 0UL;
    uint16 sum = 0U;  /* Sum of queue lengths */
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Pre-compute safe default HIF queue length (in case it is needed). Consider the following two limits:
                --> Size of HIF RX Ring
                --> Max allowed queue size for HIF */
        default_max = (PFE_HIF_RX_RING_CFG_LENGTH >= PFE_TMU_ERR051211_MINIMAL_REQUIRED_RX_RING_LENGTH) ? (((uint32)PFE_HIF_RX_RING_CFG_LENGTH - PFE_TMU_ERR051211_Q_OFFSET) / 2U) : (1U);
        default_max = (default_max >= TLITE_HIF_MAX_Q_SIZE) ? (TLITE_HIF_MAX_Q_SIZE) : (default_max);

        /* Check all HIF interfaces and update data in FW. */
        for (uint8 phy_idx = 0u; phy_idx < sizeof(phys)/sizeof(phys[0]); phy_idx++)
        {
            const pfe_ct_phy_if_id_t phy = phys[phy_idx];
            uint8 queue = 0U;
            const uint8 queue_cnt = pfe_tmu_queue_get_cnt(tmu, phy);

            /* Check sum of queue lengths for the given HIF ; 0xFF args ensure that real current sum is returned */
            if (ENOSPC == get_sum_of_queue_lengths(tmu, phy, 0xFF, 0xFF, &sum))
            {
                /* Reset queue lengths and then set them all to default_max length. This will update data in FW as well. */
                (void)set_all_queues_to_min_length(tmu, phy);
                for (queue = 0U; (queue_cnt > queue); queue++)
                {
                    mode = pfe_tmu_queue_get_mode(tmu, phy, queue, &min, &max);
                    (void)pfe_tmu_queue_set_mode(tmu, phy, queue, mode, min, default_max);
                }

                NXP_LOG_WARNING("Every TMU queue of physical interface id=%d was set to length %u, because err051211_workaround got activated.",
                                phy, (uint_t)default_max);
                NXP_LOG_WARNING("\"Original sum of queue lengths (%u) + Q_OFFSET (%u)\" for the given interface was exceeding HIF RX Ring length (%u).",
                                (uint_t)sum, (uint_t)PFE_TMU_ERR051211_Q_OFFSET, (uint_t)PFE_HIF_RX_RING_CFG_LENGTH);
            }
            else
            {
                /* Sum is OK. Simply reapply parameters. This will update data in FW as well. */
                for (queue = 0U; (queue_cnt > queue); queue++)
                {
                    mode = pfe_tmu_queue_get_mode(tmu, phy, queue, &min, &max);
                    (void)pfe_tmu_queue_set_mode(tmu, phy, queue, mode, min, max);
                }
            }
        }

        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get number of queues for given physical interface
 * @param[in]   tmu The TMU instance
 * @param[in]   phy Physical interface ID
 * @return      Number of queues
 */
uint8 pfe_tmu_queue_get_cnt(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy)
{
    const pfe_tmu_phy_cfg_t *pcfg;
    uint8 ret;

    (void)tmu;

    pcfg = pfe_tmu_cfg_get_phy_config(phy);
    if (NULL == pcfg)
    {
        NXP_LOG_ERROR("Invalid phy: 0x%x\n", phy);
        ret = 0U;
    }
    else
    {
        ret = pcfg->q_cnt;
    }

    return ret;
}

/**
 * @brief       Set shaper credit limits
 * @details     Value units depend on chosen shaper mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[in]   max_credit Maximum credit value
 * @param[in]   min_credit Minimum credit value
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_set_limits(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy,
        uint8 shp, sint32 max_credit, sint32 min_credit)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_set_limits(tmu->cbus_base_va, phy, shp, max_credit, min_credit);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get shaper credit limits
 * @details     Value units depend on chosen shaper mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[out]  max_credit Pointer to memory where maximum credit value shall be written
 * @param[out]  min_credit Pointer to memory where minimum credit value shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_get_limits(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, sint32 *max_credit, sint32 *min_credit)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu) || unlikely(NULL == max_credit) || unlikely(NULL == min_credit))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_get_limits(tmu->cbus_base_va, phy, shp, max_credit, min_credit);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Set shaper position within the QoS topology
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[in]   pos Shaper position. Setting to PFE_TMU_INVALID_POSITION makes
 *                  the shaper unused.
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_set_position(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, uint8 pos)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_set_position(tmu->cbus_base_va, phy, shp, pos);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get shaper position within the QoS topology
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[in]   pos Shaper position. Setting to PFE_TMU_INVALID_POSITION makes
 *                  the shaper unused.
 * @return      EOK if success, error code otherwise
 */
uint8 pfe_tmu_shp_get_position(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    uint8 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = PFE_TMU_INVALID_POSITION;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_get_position(tmu->cbus_base_va, phy, shp);
        }
        else
        {
            ret = PFE_TMU_INVALID_POSITION;
        }
    }

    return ret;
}

/**
 * @brief       Enable shaper
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 */
errno_t pfe_tmu_shp_enable(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_enable(tmu->cbus_base_va, phy, shp);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Set shaper rate mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[in]   mode Shaper mode
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_set_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, pfe_tmu_rate_mode_t mode)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_set_rate_mode(tmu->cbus_base_va, phy, shp, mode);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get shaper rate mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @return      Shaper rate mode
 */
pfe_tmu_rate_mode_t pfe_tmu_shp_get_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    pfe_tmu_rate_mode_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = RATE_MODE_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_get_rate_mode(tmu->cbus_base_va, phy, shp);
        }
        else
        {
            ret = RATE_MODE_INVALID;
        }
    }

    return ret;
}

/**
 * @brief       Set shaper idle slope
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[in]   isl Idle slope in units per second as given by chosen mode
 *                  (bits-per-second, packets-per-second)
 */
errno_t pfe_tmu_shp_set_idle_slope(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp, uint32 isl)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_set_idle_slope(tmu->cbus_base_va, phy, shp, isl);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get shaper idle slope
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @return      Current idle slope value
 */
uint32 pfe_tmu_shp_get_idle_slope(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    uint32 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            ret = pfe_tmu_shp_cfg_get_idle_slope(tmu->cbus_base_va, phy, shp);
        }
        else
        {
            ret = 0U;
        }
    }

    return ret;
}

/**
 * @brief       Disable shaper
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 */
errno_t pfe_tmu_shp_disable(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_shaper(tmu, phy, shp))
        {
            pfe_tmu_shp_cfg_disable(tmu->cbus_base_va, phy, shp);
            ret = EOK;
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Set scheduler rate mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @param[in]   mode The rate mode to be used by scheduler
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_set_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy,
        uint8 sch, pfe_tmu_rate_mode_t mode)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_set_rate_mode(tmu->cbus_base_va, phy, sch, mode);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief   Get scheduler rate mode
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @return      Current rate mode or RATE_MODE_INVALID in case of error
 */
pfe_tmu_rate_mode_t pfe_tmu_sch_get_rate_mode(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch)
{
    pfe_tmu_rate_mode_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = RATE_MODE_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_get_rate_mode(tmu->cbus_base_va, phy, sch);
        }
        else
        {
            ret = RATE_MODE_INVALID;
        }
    }

    return ret;
}

/**
 * @brief       Set scheduler algorithm
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @param[in]   algo The algorithm to be used
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_set_algo(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy,
        uint8 sch, pfe_tmu_sched_algo_t algo)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_set_algo(tmu->cbus_base_va, phy, sch, algo);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get scheduler algorithm
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @return      Current rate mode or SCHED_ALGO_INVALID in case of error
 */
pfe_tmu_sched_algo_t pfe_tmu_sch_get_algo(const pfe_tmu_t *tmu,
        pfe_ct_phy_if_id_t phy, uint8 sch)
{
    pfe_tmu_sched_algo_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = SCHED_ALGO_INVALID;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_get_algo(tmu->cbus_base_va, phy, sch);
        }
        else
        {
            ret = SCHED_ALGO_INVALID;
        }
    }

    return ret;
}

/**
 * @brief       Get number of scheduler inputs
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @return      Number of scheduler inputs
 */
uint8 pfe_tmu_sch_get_input_cnt(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch)
{
    uint8 ret;

    if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
    {
        /*  Number of scheduler inputs is equal to number of available queues */
        ret = pfe_tmu_queue_get_cnt(tmu, phy);
    }
    else
    {
        ret = 0U;
    }

    return ret;
}

/**
 * @brief       Set scheduler input weight
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @param[in]   input Scheduler input
 * @param[in]   weight The weight value to be used by chosen scheduling algorithm
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_set_input_weight(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy,
        uint8 sch, uint8 input, uint32 weight)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_set_input_weight(tmu->cbus_base_va,
                phy, sch, input, weight);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get scheduler input weight
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @param[in]   input Scheduler input
 * @return      Input weight
 */
uint32 pfe_tmu_sch_get_input_weight(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input)
{
    uint32 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_get_input_weight(tmu->cbus_base_va,
                    phy, sch, input);
        }
        else
        {
            ret = 0U;
        }
    }

    return ret;
}

/**
 * @brief       Connect another scheduler output to some scheduler input
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   src_sch Source scheduler instance/index
 * @param[in]   dst_sch Destination scheduler instance/index
 * @param[in]   input Input of 'dst_sch' where output of 'src_sch' shall be connected
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_bind_sch_output(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 src_sch, uint8 dst_sch, uint8 input)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_tmu_check_scheduler(tmu, phy, dst_sch);
        if ((EOK == pfe_tmu_check_scheduler(tmu, phy, src_sch))
                && (EOK == ret))
        {
            ret = pfe_tmu_sch_cfg_bind_sched_output(tmu->cbus_base_va, phy, src_sch, dst_sch, input);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get scheduler which output is connected to given scheduler input
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @param[in]   input Scheduler input
 * @return      ID of the connected scheduler or PFE_TMU_INVALID_SCHEDULER
 */
uint8 pfe_tmu_sch_get_bound_sch_output(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input)
{
    uint8 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = PFE_TMU_INVALID_SCHEDULER;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_get_bound_sched_output(tmu->cbus_base_va, phy, sch, input);
        }
        else
        {
            ret = PFE_TMU_INVALID_SCHEDULER;
        }
    }

    return ret;
}

/**
 * @brief       Connect queue to some scheduler input
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @param[in]   input Scheduler input the queue shall be connected to
 * @param[in]   queue Queue to be connected to the scheduler input
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_bind_queue(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy,
        uint8 sch, uint8 input, uint8 queue)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_tmu_check_queue(tmu, phy, queue);
        if ((EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
                && (EOK == ret))
        {
            ret = pfe_tmu_sch_cfg_bind_queue(tmu->cbus_base_va, phy, sch, input, queue);
        }
        else
        {
            ret = EINVAL;
        }
    }

    return ret;
}

/**
 * @brief       Get queue connected to given scheduler input
 * @param[in]   tmu The TMU instance
 * @parma[in]   phy Physical interface ID
 * @param[in]   sch The scheduler ID
 * @param[in]   input Scheduler input to be queried
 * @return      Queue ID connected to the input or PFE_TMU_INVALID_QUEUE if not present
 */
uint8 pfe_tmu_sch_get_bound_queue(const pfe_tmu_t *tmu, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input)
{
    uint8 ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = PFE_TMU_INVALID_QUEUE;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (EOK == pfe_tmu_check_scheduler(tmu, phy, sch))
        {
            ret = pfe_tmu_sch_cfg_get_bound_queue(tmu->cbus_base_va, phy, sch, input);
        }
        else
        {
            ret = PFE_TMU_INVALID_QUEUE;
        }
    }

    return ret;
}

#if defined(PFE_CFG_TEXT_STATS)

/**
 * @brief       Return TMU runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   tmu The TMU instance
 * @param[in]   buf Pointer to buffer to be written
 * @param[in]   buf_len Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_tmu_get_text_statistics(const pfe_tmu_t *tmu, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += pfe_tmu_cfg_get_text_stat(tmu->cbus_base_va, buf, buf_len, verb_level);
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get TMU statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              values from the tmu block, which can be access directly
 *              through reading a corresponding register
 * @param[in]   tmu        The TMU instance
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic or PFE_INVALID_STAT
 */
uint32 pfe_tmu_get_stat_value(const pfe_tmu_t* tmu, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == tmu))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = PFE_INVALID_STAT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = pfe_tmu_cfg_get_stat_value(tmu->cbus_base_va, stat_id);
    }
    return stat_value;
}

/**
 * @brief       Get TMU statistic in numeric form for queue
 * @details     This is a HW-specific function providing single statistic
 *              values from the tmu block, which can not be accessed directly, using
 *              bit manipulation
 * @param[in]   tmu   The TMU instance
 * @param[out]  special_stats special statistic
 * @return      EOK if possible to get special statistics, otherwise return EINVAL
 *              when tmu or special_stats is NULL
 */
errno_t pfe_tmu_get_special_stats(const pfe_tmu_t* tmu, pfe_tmu_stats_special_t* special_stats)
{
    errno_t ret = EOK;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == tmu) || unlikely(NULL_PTR == special_stats))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        pfe_tmu_cfg_get_special_stats(tmu->cbus_base_va, special_stats);
    }

    return ret;
}

/**
 * @brief       Get TMU statistic in numeric form for queue
 * @details     This is a HW-specific function providing single statistic
 *              values from the tmu block, these are based on queues with corresponding
 *              phys
 * @param[in]   tmu        The TMU instance
 * @param[in]   phy_id         index of phy
 * @param[in]   queue_id       index of queue
 * @param[in]   queue_stats    Requested stats related to queue
 * @return      EOK if possible to get queue-based stats, otherwise EFAULT or EINVAL
 */
errno_t pfe_tmu_get_queue_stats(const pfe_tmu_t* tmu, uint32 phy_id, uint32 queue_id, pfe_tmu_queue_stats* queue_stats)
{
    errno_t ret;

    #if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_PTR == tmu) || unlikely(NULL_PTR == queue_stats))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_tmu_cfg_get_queue_stats(tmu->cbus_base_va, phy_id, queue_id, queue_stats);
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [181/185]: src\pfe_tmu_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_tmu_csr.h"
#include "pfe_bmu_csr.h"
#include "pfe_hif_csr.h"
#include "pfe_hif_nocpy_csr.h"
#include "pfe_gpi_csr.h"
#include "pfe_util_csr.h"
#include "pfe_global_wsp.h"
#include "pfe_feature_mgr.h"
#include "Eth_43_PFE.h"

#ifndef PFE_CBUS_H_
#error Missing cbus.h
#endif /* PFE_CBUS_H_ */

#define ADDR_BASE_OFFSET(BASE,OFFS) (addr_t)(((uint64)(BASE)+(OFFS)) & UINT32_MAX)
#define CLK_DIV_LOG2 (8U - 1U) /* Value of CLK_DIV_LOG2 log2(clk_div/2) */
#define CLK_DIV ((uint64)1U << (CLK_DIV_LOG2 + 1U)) /* 256 */

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* usage scope: pfe_tmu_cfg_get_phy_config */
/*  List of QoS configuration for each physical interface terminated with invalid entry */
static const pfe_tmu_phy_cfg_t tmu_phys[] = {
    {.id = PFE_PHY_IF_ID_EMAC0, .q_cnt = 8U, .sch_cnt = 2U, .shp_cnt = 4U},
    {.id = PFE_PHY_IF_ID_EMAC1, .q_cnt = 8U, .sch_cnt = 2U, .shp_cnt = 4U},
    {.id = PFE_PHY_IF_ID_EMAC2, .q_cnt = 8U, .sch_cnt = 2U, .shp_cnt = 4U},
    {.id = PFE_PHY_IF_ID_HIF0, .q_cnt = 2U, .sch_cnt = 0U, .shp_cnt = 0U},
    {.id = PFE_PHY_IF_ID_HIF1, .q_cnt = 2U, .sch_cnt = 0U, .shp_cnt = 0U},
    {.id = PFE_PHY_IF_ID_HIF2, .q_cnt = 2U, .sch_cnt = 0U, .shp_cnt = 0U},
    {.id = PFE_PHY_IF_ID_HIF3, .q_cnt = 2U, .sch_cnt = 0U, .shp_cnt = 0U},
    {.id = PFE_PHY_IF_ID_HIF, .q_cnt = 8U, .sch_cnt = 2U, .shp_cnt = 4U},
    {.id = PFE_PHY_IF_ID_HIF_NOCPY, .q_cnt = 8U, .sch_cnt = 2U, .shp_cnt = 4U},
    {.id = PFE_PHY_IF_ID_UTIL, .q_cnt = 8U, .sch_cnt = 2U, .shp_cnt = 4U},
    {.id = PFE_PHY_IF_ID_INVALID}
};

#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static uint32 pfe_tmu_reclaim_mem_wrkarnd(uint32 drops, uint8 queue, pfe_ct_phy_if_id_t phy);
static errno_t pfe_tmu_set_default_queue_mode(addr_t cbus_base_va, uint32 ii, bool_t has_tlite_phy5);
static errno_t pfe_tmu_tdq_shp_on_phy5_g2(addr_t cbus_base_va, uint32 ii);
static errno_t pfe_tmu_cntx_mem_write(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 loc, uint32 data);
static errno_t pfe_tmu_cntx_mem_read(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 loc, uint32 *data);
static errno_t pfe_tmu_context_memory(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue_temp, uint16 min, uint16 max);
static uint8 pfe_tmu_hif_q_to_tmu_q(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue);

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

/* PHY lookup table */
static const pfe_ct_phy_if_id_t phy_if_id_temp[TLITE_PHYS_CNT] =
{
    PFE_PHY_IF_ID_EMAC0, PFE_PHY_IF_ID_EMAC1, PFE_PHY_IF_ID_EMAC2,
    PFE_PHY_IF_ID_HIF, PFE_PHY_IF_ID_HIF_NOCPY, PFE_PHY_IF_ID_UTIL
};

#define ETH_43_PFE_STOP_SEC_CONST_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       Return QoS configuration of given physical interface
 * @param[in]   phy The physical interface to get QoS configuration for
 * @return      Pointer to the configuration or NULL if not found
 */
const pfe_tmu_phy_cfg_t *pfe_tmu_cfg_get_phy_config(pfe_ct_phy_if_id_t phy)
{
    uint32 ii;

    const pfe_tmu_phy_cfg_t *phy_config = NULL;

    for (ii=0U; tmu_phys[ii].id != PFE_PHY_IF_ID_INVALID; ii++)
    {
        if (tmu_phys[ii].id == phy)
        {
            phy_config = &tmu_phys[ii];
            break;
        }
    }

    return phy_config;
}

/**
 * @brief       Initialize TMU reclaim memory
 * @details     This implements reclaim memory initialization workaround.
 *              It is necessary to call this function to initialize the ECC for
 *              TMU reclaim memory.
 * @warning     Function should be called before @ref pfe_tmu_cfg_init.
 * @param[in]   cbus_base_va The cbus base address
 */
void pfe_tmu_reclaim_init(addr_t cbus_base_va)
{
    uint8 queue;
    uint32 ii;
    uint32 dropped_packets = 0U;
    uint32 retries = 0U;

    hal_write32(0x1U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_ACCESS_CTRL));

    /*  Initialize queues */
    for (ii = 0U; ii < (uint32)TLITE_PHYS_CNT; ii++)
    {
        for (queue = 0U; queue < (uint8)TLITE_PHY_QUEUES_CNT; queue++)
        {
            hal_write32(((ii & 0x1fUL) << 8U) | ((uint32)queue & 0x7UL), ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY_QUEUE_SEL));
            hal_nop();

            /*  Clear direct access registers */
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CURQ_PTR));
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CURQ_PKT_CNT));
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CURQ_DROP_CNT));
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CURQ_TRANS_CNT));
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CURQ_QSTAT));
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_HW_PROB_CFG_TBL0));
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_HW_PROB_CFG_TBL1));
            hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CURQ_DEBUG));
        }
    }

    if (FALSE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
    {
        /* Queue 0 PHY 0*/
        /* WRED min 0 max 0*/
        if(EOK == pfe_tmu_context_memory(cbus_base_va, PFE_PHY_IF_ID_EMAC0, 0U, 0U, 0U))
        {

            /* Initialize internal TMU FIFO (length is hard coded in verilog)*/
            for(ii = 0U; ii < (uint32)TLITE_INQ_FIFODEPTH; ii++)
            {
                hal_write32(0UL, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY_INQ_PKTINFO));
            }

            do
            {
                oal_time_usleep(10U);
                /*  Queue 0 */
                /*  curQ_drop_cnt is @ position 2 per queue */
                (void)pfe_tmu_cntx_mem_read(cbus_base_va, PFE_PHY_IF_ID_EMAC0, ((8U * 0U) + 2U), &dropped_packets);

                retries++;
            }
            while ((TLITE_INQ_FIFODEPTH != dropped_packets) && (10U > retries));

            if (dropped_packets != TLITE_INQ_FIFODEPTH)
            {
                NXP_LOG_ERROR("Failed to initialize TMU reclaim memory %u\n", (uint_t)dropped_packets);
            }

            /* Set queue to default mode */
            (void)pfe_tmu_q_mode_set_default(cbus_base_va, PFE_PHY_IF_ID_EMAC0, 0U);
        }
    }
}

/**
 * @brief       Setting TMU queue sizes and configuration
 * @param[in]   cbus_base_va The cbus base address
 * @return      EOK if success
 */
errno_t pfe_tmu_q_reset_tail_drop_policy(addr_t cbus_base_va)
{
    uint32 ii;
    errno_t ret;
    uint8 queue;
    uint16 max;

    for (ii = 0U; ii < (uint32)TLITE_PHYS_CNT; ii++)
    {
        for (queue = 0; queue < (uint8)TLITE_PHY_QUEUES_CNT; queue++)
        {
            switch(ii)
            {
                case PFE_PHY_IF_ID_EMAC0:
                    /* Intentional fall through */
                case PFE_PHY_IF_ID_EMAC1:
                    /* Intentional fall through */
                case PFE_PHY_IF_ID_EMAC2:
                    /* EMACs - for endpoint performance improvement */
                    max = Eth_43_PFE_InternalCfgPtr->emac[(pfe_ct_phy_if_id_t) ii].EthTmuQueueSizes[queue];
                    break;
                case PFE_PHY_IF_ID_HIF:
                    /* HIF - special case for ERR051211 workaround */
                    max = (uint16) TLITE_HIF_MAX_Q_SIZE;
                    break;
                default:
                    /* Other: UTIL, HIF_NOCPY */
                    max = (uint16) TLITE_MAX_Q_SIZE;
                    break;
            }
            ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[(pfe_ct_phy_if_id_t) ii], queue, max);
            if (EOK != ret)
            {
                NXP_LOG_ERROR("Can't set the default queue size for PHY#%u queue %hhu: %d\n", (uint_t)ii, queue, (int_t)ret);
                break;
            }
        }
        if (EOK != ret)
        {
            break;
        }
    }

    return ret;
}
/**
 * @brief       Workaround for PHY5(util) on the G2
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   ii interface number
 * @param[in]   has_tlite_phy5 interface PHY5 is used
 * @return      EOK if success
 */
static errno_t pfe_tmu_set_default_queue_mode(addr_t cbus_base_va, uint32 ii, bool_t has_tlite_phy5)
{
    errno_t ret = EOK;
    uint8 queue;

    if (TRUE == has_tlite_phy5)
    {
        ret = pfe_tmu_sch_cfg_set_rate_mode(cbus_base_va, phy_if_id_temp[ii], 1U, RATE_MODE_DATA_RATE);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("Could not set scheduler 1 rate mode: %d\n", ret);
            ret = ENOEXEC;
        }
        else
        {
            ret = pfe_tmu_sch_cfg_set_algo(cbus_base_va, phy_if_id_temp[ii], 1U, SCHED_ALGO_RR);
            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Could not set scheduler 1 algo: %d\n", ret);
                ret = ENOEXEC;
            }
        }
    }
    if (EOK == ret)
    {
        /*  Set default queue mode */
        for (queue = 0U; queue < (uint8)TLITE_PHY_QUEUES_CNT; queue++)
        {
            if((uint32)PFE_PHY_IF_ID_HIF == ii)
            {   /* HIF - special case for ERR051211 workaround */
                ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], queue, TLITE_HIF_MAX_Q_SIZE);
            }
            else
            {   /* Other */
                ret = pfe_tmu_q_mode_set_tail_drop(cbus_base_va, phy_if_id_temp[ii], queue, TLITE_MAX_Q_SIZE);
            }

            if (EOK != ret)
            {
                NXP_LOG_DEBUG("Can't set default queue mode: %d\n", ret);
                break;
            }
        }
    }

    return ret;
}

/**
 * @brief       Workaround for PHY5(util) on the G2
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   ii interface number
 * @return      EOK if success
 */
static errno_t pfe_tmu_tdq_shp_on_phy5_g2(addr_t cbus_base_va, uint32 ii)
{
    uint8 queue;
    errno_t ret = EOK;

    pfe_tmu_sch_cfg_init(cbus_base_va, phy_if_id_temp[ii], 0U);
    pfe_tmu_sch_cfg_init(cbus_base_va, phy_if_id_temp[ii], 1U);

    /*  Initialize shapers. Make sure they are not connected. */
    pfe_tmu_shp_cfg_init(cbus_base_va, phy_if_id_temp[ii], 0U);
    pfe_tmu_shp_cfg_init(cbus_base_va, phy_if_id_temp[ii], 1U);
    pfe_tmu_shp_cfg_init(cbus_base_va, phy_if_id_temp[ii], 2U);
    pfe_tmu_shp_cfg_init(cbus_base_va, phy_if_id_temp[ii], 3U);

    /*  Set default topology:
        - All shapers are disabled and not associated with any queue
        - Scheduler 0 is not used
        - Queue[n]->SCH1.input[n]
    */
    for (queue = 0U; queue < (uint8)TLITE_PHY_QUEUES_CNT; queue++)
    {
        /*  Scheduler 1 */
        ret = pfe_tmu_sch_cfg_bind_queue(cbus_base_va, phy_if_id_temp[ii], 1U, queue, queue);
        if (EOK != ret)
        {
            NXP_LOG_DEBUG("Can't bind queue to scheduler: %d\n", ret);
            ret = ENOEXEC;
            break;
        }
    }
    return ret;
}

/**
 * @brief       Initialize and configure the TMU
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   cfg Pointer to the configuration structure
 * @return      EOK if success
 */
errno_t pfe_tmu_cfg_init(addr_t cbus_base_va, const pfe_tmu_cfg_t *cfg)
{

    uint32 ii;
    errno_t ret = EOK;
    uint32 regval;
    bool_t has_tlite_phy5;

    if (TRUE == cfg->on_g3)
    {
        regval = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, TMU_TEQ_CTRL));
        regval |= 0x4U;
        hal_write32(regval, ADDR_BASE_OFFSET(cbus_base_va, TMU_TEQ_CTRL));
    }

    hal_write32(0x0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY0_TDQ_CTRL));
    hal_write32(0x0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY1_TDQ_CTRL));
    hal_write32(0x0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY2_TDQ_CTRL));
    hal_write32(0x0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY3_TDQ_CTRL));
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    hal_write32(0x0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY4_TDQ_CTRL));
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    hal_write32(0x0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY5_TDQ_CTRL));    /* UTIL PE */

    /*  Reset */
    pfe_tmu_cfg_reset(cbus_base_va);

    /*  INQ */
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_EGPI1_BASE_ADDR + GPI_INQ_PKTPTR, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY0_INQ_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_EGPI2_BASE_ADDR + GPI_INQ_PKTPTR, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY1_INQ_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_EGPI3_BASE_ADDR + GPI_INQ_PKTPTR, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY2_INQ_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_HGPI_BASE_ADDR + GPI_INQ_PKTPTR, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY16_INQ_ADDR));
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_HGPI_BASE_ADDR + GPI_INQ_PKTPTR, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY3_INQ_ADDR));
#if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_HIF_NOCPY_BASE_ADDR + HIF_NOCPY_RX_INQ0_PKTPTR, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY4_INQ_ADDR));
#endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
    /* The macro UTIL_INQ_PKTPTR already contains the CBUS_UTIL_CSR_BASE_ADDR (difference to above lines) */
    hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + UTIL_INQ_PKTPTR, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY5_INQ_ADDR)); /* UTIL */

    /*  Context memory initialization */
    for (ii = 0U; ii < (uint32)TLITE_PHYS_CNT; ii++)
    {
        /* NOTE: Do not access the direct registers here it may result in bus fault.*/
        /* TDQ and SHP address range for PHY5(Util) does not exist on G2 */
        has_tlite_phy5 = !((FALSE == cfg->on_g3) && (PFE_PHY_IF_ID_UTIL == phy_if_id_temp[ii]));
        if (TRUE == has_tlite_phy5)
        {
            ret = pfe_tmu_tdq_shp_on_phy5_g2(cbus_base_va, ii);
        }

        if (EOK == ret)
        {
            ret = pfe_tmu_set_default_queue_mode(cbus_base_va, ii, has_tlite_phy5);
        }
        /* Incase one of the ret != EOK break */
        if (EOK != ret)
        {
            break;
        }
    }

    if (EOK == ret)
    {
        hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU1_BASE_ADDR + BMU_FREE_CTRL, ADDR_BASE_OFFSET(cbus_base_va, TMU_BMU_INQ_ADDR));
        hal_write32(PFE_CFG_CBUS_PHYS_BASE_ADDR + CBUS_BMU2_BASE_ADDR + BMU_FREE_CTRL, ADDR_BASE_OFFSET(cbus_base_va, TMU_BMU2_INQ_ADDR));
        hal_write32(0x100U, ADDR_BASE_OFFSET(cbus_base_va, TMU_AFULL_THRES));
        hal_write32(0xfcU, ADDR_BASE_OFFSET(cbus_base_va, TMU_INQ_WATERMARK));
        hal_write32(0xfU, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY0_TDQ_CTRL));
        hal_write32(0xfU, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY1_TDQ_CTRL));
        hal_write32(0xfU, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY2_TDQ_CTRL));
        hal_write32(0xfU, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY16_TDQ_CTRL));
        hal_write32(0xfU, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY3_TDQ_CTRL));
    #if defined(PFE_CFG_HIF_NOCPY_SUPPORT)
        hal_write32(0xfU, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY4_TDQ_CTRL));
    #endif /* PFE_CFG_HIF_NOCPY_SUPPORT */
        hal_write32(0xfU, ADDR_BASE_OFFSET(cbus_base_va, TMU_PHY5_TDQ_CTRL));    /* UTIL */
    }

    return ret;
}

/**
 * @brief       Issue TMU reset
 * @param[in]   cbus_base_va The cbus base address
 */
void pfe_tmu_cfg_reset(addr_t cbus_base_va)
{
    uint32 timeout = 200U;
    uint32 reg;

    hal_write32(0x1U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CTRL));

    do
    {
        oal_time_usleep(10U);
        timeout--;
        reg = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, TMU_CTRL));
    } while ((0U != (reg & 0x1U)) && (timeout > 0U));

    if (0U == timeout)
    {
        NXP_LOG_ERROR("FATAL: TMU reset timed-out\n");
    }
}

/**
 * @brief       Enable the TMU block
 * @param[in]   cbus_base_va The cbus base address
 */
void pfe_tmu_cfg_enable(addr_t cbus_base_va)
{
    /*  nop */
    (void)cbus_base_va;
}

/**
 * @brief       Disable the TMU block
 * @param[in]   base_va The cbus base address
 */
void pfe_tmu_cfg_disable(addr_t cbus_base_va)
{
    /*  nop */
    (void)cbus_base_va;
}

/**
 * @brief       Write TMU context memory
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   loc Location to be written
 * @param[out]  data Data to be written
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_tmu_cntx_mem_write(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 loc, uint32 data)
{
    uint32 reg;
    uint32 timeout = 200U;
    pfe_ct_phy_if_id_t phy_temp = phy;
    errno_t ret = EOK;

    hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_ACCESS_CTRL));

    switch (phy)
    {
        case PFE_PHY_IF_ID_EMAC0:
        case PFE_PHY_IF_ID_EMAC1:
        case PFE_PHY_IF_ID_EMAC2:
        case PFE_PHY_IF_ID_HIF_NOCPY:
        case PFE_PHY_IF_ID_UTIL:
            /*Do Nothing*/
            break;
        case PFE_PHY_IF_ID_HIF:
        case PFE_PHY_IF_ID_HIF0:
        case PFE_PHY_IF_ID_HIF1:
        case PFE_PHY_IF_ID_HIF2:
        case PFE_PHY_IF_ID_HIF3:
            phy_temp = PFE_PHY_IF_ID_HIF;
            break;
        default:
            ret = EINVAL;
            break;
    }

    if(ret == EOK)
    {
        hal_write32((((uint32)phy_temp & (uint32)0x1fU) << 16U) | (uint32)loc, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_ADDR));
        hal_write32(data, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_DATA));
        hal_write32(0x3U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_CMD));
        do
        {
            oal_time_usleep(1U);
            timeout--;
            reg = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_CMD));
        } while ((0U == (reg & 0x4U)) && (timeout > 0U));

        if (0U == timeout)
        {
            ret = ETIMEDOUT;
        }
    }

    return ret;
}

/**
 * @brief       Read TMU context memory
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   loc Location to be read
 * @param[out]  data Pointer to memory where read data shall be written
 * @return      EOK if success, error code otherwise
 */
static errno_t pfe_tmu_cntx_mem_read(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 loc, uint32 *data)
{
    uint32 reg;
    uint32 timeout = 20U;
    pfe_ct_phy_if_id_t phy_temp = phy;
    errno_t ret = EOK;

    hal_write32(0U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_ACCESS_CTRL));

    switch (phy)
    {
        case PFE_PHY_IF_ID_EMAC0:
        case PFE_PHY_IF_ID_EMAC1:
        case PFE_PHY_IF_ID_EMAC2:
        case PFE_PHY_IF_ID_HIF_NOCPY:
        case PFE_PHY_IF_ID_UTIL:
        {
            break;
        }
        case PFE_PHY_IF_ID_HIF:
        case PFE_PHY_IF_ID_HIF0:
        case PFE_PHY_IF_ID_HIF1:
        case PFE_PHY_IF_ID_HIF2:
        case PFE_PHY_IF_ID_HIF3:
        {
            phy_temp = PFE_PHY_IF_ID_HIF;
            break;
        }
        default:
        {
            ret = EINVAL;
            break;
        }
    }


    if(ret == EOK)
    {
        hal_write32((((uint32)phy_temp & (uint32)0x1fU) << 16U) | (uint32)loc, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_ADDR));
        hal_write32(0x2U, ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_CMD));

        do
        {
            oal_time_usleep(10U);
            timeout--;
            reg = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_CMD));
        } while ((0U == (reg & 0x4U)) && (timeout > 0U));

        if (0U == timeout)
        {
            ret = ETIMEDOUT;
        }
        else
        {
            *data = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, TMU_CNTX_DATA));
        }
    }

    return ret;
}

static uint8 pfe_tmu_hif_q_to_tmu_q(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue)
{
    uint32 reg, ii;
    sint8 hif_queue = -1;
    uint8 tmu_queue = PFE_TMU_INVALID_QUEUE;

    /*  Convert HIF channel queue` (range 0-`n`) to TMU queue (range 0-`m`) */
    if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
    {
        reg = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, (CBUS_HIF_BASE_ADDR + HIF_RX_QUEUE_MAP_CH_NO_ADDR)));
        for (ii=0U; ii<8U; ii++)
        {
            if ((uint32)((uint32)phy - (uint32)PFE_PHY_IF_ID_HIF0) == ((reg >> (ii * 4U)) & 0xfU))
            {
                PfeDevAssert(hif_queue < 8);
                hif_queue++;
                if (queue == (uint8)hif_queue)
                {
                    tmu_queue = (uint8)ii;
                    break;
                }
            }
        }
    }

    return tmu_queue;
}

static errno_t pfe_tmu_context_memory(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue_temp, uint16 min, uint16 max)
{
    uint32 reg;
    errno_t ret;
    /*  Initialize probabilities. Probability tables are @ position 5 and 6 per queue. */
    /*  Context memory position 5 (curQ_hw_prob_cfg_tbl0):
            [4:0]   Zone0 value
            [9:5]   Zone1 value
            [14:10] Zone2 value
            [19:15] Zone3 value
            [24:20] Zone4 value
            [29:25] Zone5 value
        Context memory position 6 (curQ_hw_prob_cfg_tbl1):
            [4:0]   Zone6 value
            [9:5]   Zone7 value
    */

    reg = 0U;
    PfeDevAssert(queue_temp < 8U);
    ret = pfe_tmu_cntx_mem_write(cbus_base_va, phy, (uint8)(((8U * queue_temp) + 5U) & UINT8_MAX), reg);
    if (EOK == ret)
    {
        ret = pfe_tmu_cntx_mem_write(cbus_base_va, phy, (uint8)(((8U * queue_temp) + 6U) & UINT8_MAX), reg);
        if (EOK == ret)
        {
            /*  curQ_Qmax[8:0], curQ_Qmin[8:0], curQ_cfg[1:0] are @ position 4 per queue */
            reg = ((uint32)max << 11U) | ((uint32)min << 2U) | 0x2UL;
            ret = pfe_tmu_cntx_mem_write(cbus_base_va, phy, (uint8)(((8U * queue_temp) + 4U) & UINT8_MAX), reg);
        }
    }
    return ret;
}

/**
 * @brief       Get number of packets in the queue
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[out]  level Pointer to memory where the fill level value shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_cfg_get_fill_level(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *level)
{
    uint8 queue_temp = queue;
    errno_t ret = EOK;

    if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
    {
        queue_temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
        if (PFE_TMU_INVALID_QUEUE == queue_temp)
        {
            ret = EINVAL;
        }
    }

    if (EOK == ret)
    {
        /*  curQ_pkt_cnt is @ position 1 per queue */
        PfeDevAssert(queue_temp < 8U);
        ret = pfe_tmu_cntx_mem_read(cbus_base_va, phy, (uint8)(((8U * queue_temp) + 1U) & UINT8_MAX), level);
    }
    return ret;
}

/**
 * @brief       Workaround function to reclaim memory
 * @param[in]   drops The drops counter
 * @param[in]   queue The queue ID
 * @param[in]   phy The physical interface
 * @return      returns the modified drops counter
 */

static uint32 pfe_tmu_reclaim_mem_wrkarnd(uint32 drops, uint8 queue, pfe_ct_phy_if_id_t phy)
{
    bool_t ReVal;
    uint32 cnt = 0;

    ReVal = pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3);
    if ((phy == PFE_PHY_IF_ID_EMAC0) &&
        (0U == queue) &&
        (FALSE == ReVal) &&
        (drops >= TLITE_INQ_FIFODEPTH))
    {
        cnt = drops - TLITE_INQ_FIFODEPTH;
    }
    else
    {
        cnt = drops;
    }

    return cnt;
}

/**
 * @brief       Get number of dropped packets for the queue
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[out]  cnt Pointer to memory where the drop count shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_cfg_get_drop_count(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt)
{
    uint32 drops;
    errno_t ret = EOK;
    uint8 temp = queue;

    if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
    {
        temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
        if (PFE_TMU_INVALID_QUEUE == temp)
        {
            ret = EINVAL;
        }
    }

    if (EOK == ret)
    {
        /*  curQ_drop_cnt is @ position 2 per queue */
        PfeDevAssert(temp < 8U);
        ret = pfe_tmu_cntx_mem_read(cbus_base_va, phy, (uint8)(((8U * temp) + 2U) & UINT8_MAX), &drops);

        /* S32G2: Mitigate side effect of TMU reclaim memory workaround */
        if (EOK == ret)
        {
            *cnt = pfe_tmu_reclaim_mem_wrkarnd(drops, queue, phy);
        }
    }
    return ret;
}

/**
 * @brief       Get number of transmitted packets for the queue
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[out]  cnt Pointer to memory where the TX count shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_cfg_get_tx_count(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *cnt)
{
    uint8 temp = queue;
    errno_t ret = EOK;

    if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
    {
        temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
        if (PFE_TMU_INVALID_QUEUE == temp)
        {
            ret = EINVAL;
        }
    }

    if (EOK == ret)
    {
        /*  curQ_trans_cnt is @ position 3 per queue */
        PfeDevAssert(temp < 8U);
        ret = pfe_tmu_cntx_mem_read(cbus_base_va, phy, (uint8)(((8U * temp) + 3U) & UINT8_MAX), cnt);
    }

    return ret;
}

/**
 * @brief       Get queue mode
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[out]  max Pointer to memory where 'max' value shall be written
 * @param[out]  max Pointer to memory where 'min' value shall be written
 * @return      The queue mode
 */
pfe_tmu_queue_mode_t pfe_tmu_q_get_mode(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint32 *min, uint32 *max)
{
    uint32 reg;
    errno_t ret;
    pfe_tmu_queue_mode_t mode = TMU_Q_MODE_DEFAULT;
    uint8 temp = queue;

    if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
    {
        temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
        if (PFE_TMU_INVALID_QUEUE == temp)
        {
            mode = TMU_Q_MODE_INVALID;
        }
    }
    if (TMU_Q_MODE_DEFAULT == mode)
    {
        PfeDevAssert(temp < 8U);
        /*  curQ_Qmax[8:0], curQ_Qmin[8:0], curQ_cfg[1:0] are @ position 4 per queue */
        ret = pfe_tmu_cntx_mem_read(cbus_base_va, phy, (uint8)(((8U * temp) + 4U) & UINT8_MAX), &reg);
        if (EOK != ret)
        {
            mode = TMU_Q_MODE_INVALID;
        }
        else
        {
            switch (reg & 0x3U)
            {
                case 1U:
                {
                    mode = TMU_Q_MODE_TAIL_DROP;
                    *max = (reg >> 11) & 0x1ffU;
                    *min = 0U;
                    break;
                }

                case 2U:
                {
                    mode = TMU_Q_MODE_WRED;
                    *max = (reg >> 11) & 0x1ffU;
                    *min = (reg >> 2) & 0x1ffU;
                    break;
                }

                default:
                {
                    mode = TMU_Q_MODE_DEFAULT;
                    *max = 0U;
                    *min = 0U;
                    break;
                }
            }
        }
    }

    return mode;
}

/**
 * @brief       Configure queue in default mode
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_mode_set_default(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue)
{
    uint8 temp = queue;
    errno_t ret = EOK;

    if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
    {
        temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
        if (PFE_TMU_INVALID_QUEUE == temp)
        {
            ret = EINVAL;
        }
    }

    if (EOK == ret)
    {

        /*  If bit 1 is zero then in case when LLM is full the TMU will wait. */
        hal_write32((uint32)0x0U | ((uint32)0x0U << 1), ADDR_BASE_OFFSET(cbus_base_va, TMU_TEQ_CTRL));

        /*  Put the queue to default mode */
        /*  curQ_Qmax[8:0], curQ_Qmin[8:0], curQ_cfg[1:0] are @ position 4 per queue */
        PfeDevAssert(temp < 8U);
        ret = pfe_tmu_cntx_mem_write(cbus_base_va, phy, (uint8)(((8U * temp) + 4U) & UINT8_MAX), 0U);
    }

    return ret;
}

/**
 * @brief       Configure queue in tail-drop mode
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[out]  max This is the maximum fill level the queue can achieve. When exceeded
 *                  the enqueue requests will result in packet drop.
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_mode_set_tail_drop(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint16 max)
{
    uint32 reg;
    uint8 queue_temp = queue;
    errno_t ret = EOK;

    if (TLITE_MAX_ENTRIES < max)
    {
        ret = EINVAL;
    }
    else
    {
        if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
        {
            queue_temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
            if (PFE_TMU_INVALID_QUEUE == queue_temp)
            {
                ret = EINVAL;
            }
        }

        if (EOK == ret)
        {
            PfeDevAssert(queue_temp < 8U);
            /*  curQ_Qmax[8:0], curQ_Qmin[8:0], curQ_cfg[1:0] are @ position 4 per queue */
            reg = ((uint32)max << (uint32)11U) | ((uint32)0U << (uint32)2U) | ((uint32)0x1U << 0U);
            ret = pfe_tmu_cntx_mem_write(cbus_base_va, phy, (uint8)(((8U * queue_temp) + 4U) & UINT8_MAX), reg);
        }
    }

    return ret;
}

/**
 * @brief       Configure queue in WRED mode
 * @details     There are 8 WRED zones with configurable drop probabilities. Zones are given
 *              by queue fill level thresholds as:
 *
 *                                      zone_threshold[n] = n*((max - min) / 8)
 *
 *              The WRED decides if packets shall be dropped using following algorithm:
 *
 *                              if ((queueFillLevel > min) && (rnd() <= currentZoneProbability))
 *                                  DROP;
 *                              else if (queueFillLevel >= max)
 *                                  DROP;
 *                              fi
 *
 *              where
 *                  - queueFillLevel is current fill level
 *                  - rnd() is (pseudo) random number generator
 *                  - currentZoneProbability is value assigned to current zone
 *                  - probability for zone above max is 100%
 *                  - probability for zone below min is 0%
 *
 *              Once queue is set to WRED mode, all zone probabilities are set to zero.
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[in]   min See algorithm above
 * @param[in]   max See algorithm above
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_mode_set_wred(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint16 min, uint16 max)
{
    errno_t ret = EOK;
    uint8 queue_temp = queue;

    if ((max > 0x1ffU) || (min > 0x1ffU))
    {
        NXP_LOG_ERROR("Queue WRED 'min and/or 'max' argument out of range\n");
        ret = EINVAL;
    }
    else
    {
        if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
        {
            queue_temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
            if (PFE_TMU_INVALID_QUEUE == queue_temp)
            {
                ret = EINVAL;
            }
        }

        if (EOK == ret)
        {
            ret = pfe_tmu_context_memory(cbus_base_va, phy, queue_temp, min, max);
        }
    }
    return ret;
}

/**
 * @brief       Set WRED zone drop probability
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[in]   zone The WRED zone (0-7). See pfe_tmu_q_mode_set_wred.
 * @param[in]   prob Zone probability [%]
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_set_wred_probability(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 prob)
{
    errno_t ret = EOK;
    uint32 reg;
    uint8 pos;
    uint8 queue_temp = queue;

    if ((prob > 100U) || (zone > 7U))
    {
        ret = EINVAL;
    }
    else
    {
        if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
        {
            queue_temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
            if (PFE_TMU_INVALID_QUEUE == queue_temp)
            {
                ret = EINVAL;
            }
        }

        /*  Context memory position 5 (curQ_hw_prob_cfg_tbl0):
                [4:0]   Zone0 value
                [9:5]   Zone1 value
                [14:10] Zone2 value
                [19:15] Zone3 value
                [24:20] Zone4 value
                [29:25] Zone5 value
            Context memory position 6 (curQ_hw_prob_cfg_tbl1):
                [4:0]   Zone6 value
                [9:5]   Zone7 value
        */
        if (EOK == ret)
        {
            PfeDevAssert(queue_temp < 8U);
            pos = 5U + (zone / 6U);

            ret = pfe_tmu_cntx_mem_read(cbus_base_va, phy, (uint8)(((8U * queue_temp) + pos) & UINT8_MAX), &reg);
            if (EOK == ret)
            {
                reg &= ~(0x1fUL << (5U * (zone % 6U)));
                reg |= (((0x1fU * (uint32)prob) / 100U) & 0x1fU) << (5U * (zone % 6U));

                ret = pfe_tmu_cntx_mem_write(cbus_base_va, phy, (uint8)(((8U * queue_temp) + pos) & UINT8_MAX), reg);
            }
        }
    }

    return ret;
}

/**
 * @brief       Get WRED zone drop probability
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @param[in]   zone The WRED zone (0-7). See pfe_tmu_q_mode_set_wred.
 * @param[in]   prob Pointer to memory where zone probability [%] shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_q_get_wred_probability(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue, uint8 zone, uint8 *prob)
{
    errno_t ret = EOK;
    uint32 reg;
    uint8 pos;
    uint8 queue_temp = queue;

    if (zone > 7U)
    {
        ret = EINVAL;
    }
    else
    {
        if ((phy >= PFE_PHY_IF_ID_HIF0) && (phy <= PFE_PHY_IF_ID_HIF3))
        {
            queue_temp = pfe_tmu_hif_q_to_tmu_q(cbus_base_va, phy, queue);
            if (PFE_TMU_INVALID_QUEUE == queue_temp)
            {
                ret = EINVAL;
            }
        }

        /*  Context memory position 5 (curQ_hw_prob_cfg_tbl0):
                [4:0]   Zone0 value
                [9:5]   Zone1 value
                [14:10] Zone2 value
                [19:15] Zone3 value
                [24:20] Zone4 value
                [29:25] Zone5 value
            Context memory position 6 (curQ_hw_prob_cfg_tbl1):
                [4:0]   Zone6 value
                [9:5]   Zone7 value
        */
        if (EOK == ret)
        {
            PfeDevAssert(queue_temp < 8U);
            pos = 5U + (zone / 6U);

            ret = pfe_tmu_cntx_mem_read(cbus_base_va, phy, (uint8)(((8U * queue_temp) + pos) & UINT8_MAX), &reg);
            if (EOK == ret)
            {
                reg = reg >> (5U * (zone % 6U));
                *prob = (uint8)(((reg & 0x1fU) * 100U) / 0x1fU);
            }
        }
    }

    return ret;
}

/**
 * @brief       Get number of WRED probability zones between 'min' and 'max' threshold
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   phy The physical interface
 * @param[in]   queue The queue ID
 * @return      Number of zones
 */
uint8 pfe_tmu_q_get_wred_zones(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 queue)
{
    (void) cbus_base_va;
    (void) phy;
    (void) queue;

    return 8U;
}

/**
 * @brief       Set shaper credit limits
 * @details     Value units depend on chosen shaper mode
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 * @param[in]   max_credit Maximum credit value. Must be positive.
 * @param[in]   min_credit Minimum credit value. Must be negative.
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_cfg_set_limits(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy,
        uint8 shp, sint32 max_credit, sint32 min_credit)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    errno_t ret;

    if ((max_credit > 0x3fffff) || (max_credit < 0))
    {
        NXP_LOG_ERROR("Max credit value exceeded\n");
        ret = EINVAL;
    }
    else if ((min_credit < -0x3fffff) || (min_credit > 0))
    {
        NXP_LOG_ERROR("Min credit value exceeded\n");
        ret = EINVAL;
    }
    else
    {
        hal_write32((uint32)max_credit << 10, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_MAX_CREDIT));
        hal_write32(-min_credit, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_MIN_CREDIT));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get shaper credit limits
 * @details     Value units depend on chosen shaper mode
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 * @param[in]   max_credit Pointer to memory where maximum credit value shall be written
 * @param[in]   min_credit Pointer to memory where minimum credit value shall be written
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_cfg_get_limits(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy,
        uint8 shp, sint32 *max_credit, sint32 *min_credit)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));

    *max_credit = (sint32)(hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_MAX_CREDIT)) >> 10);
    const uint32 min_credit_hw = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_MIN_CREDIT));
    PfeDevAssert(min_credit_hw < (1UL << 22)); /* HW register width is 22 bits */
    *min_credit = -(sint32)min_credit_hw;

    return EOK;
}

/**
 * @brief       Set shaper position
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 * @param[in]   pos New shaper position
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_cfg_set_position(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp, uint8 pos)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    uint32 reg;
    errno_t ret;

    if ((pos > 16U) && (pos != PFE_TMU_INVALID_POSITION))
    {
        NXP_LOG_ERROR("Invalid shaper position: %d\n", pos);
        ret = EINVAL;
    }
    else
    {
        reg = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL2));
        reg &= ~(0x1fU << 1);
        reg |= (((uint32)pos & (uint32)0x1fU) << 1);
        hal_write32(reg, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL2));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get shaper position
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 * @return      Shaper position
 */
uint8 pfe_tmu_shp_cfg_get_position(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    return (uint8)((hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL2)) >> 1U) & 0x1fU);
}

/**
 * @brief       Enable shaper
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 */
errno_t pfe_tmu_shp_cfg_enable(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    uint32 reg;

    /*  Enable the shaper */
    reg = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL)) | 0x1U;
    hal_write32(reg, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL));

    return EOK;
}

/**
 * @brief       Set shaper rate mode
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[in]   mode Shaper mode
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_shp_cfg_set_rate_mode(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 shp, pfe_tmu_rate_mode_t mode)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    errno_t ret = EOK;
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL2));
    if (mode == RATE_MODE_DATA_RATE)
    {
        reg &= ~(1U << 0);
    }
    else if (mode == RATE_MODE_PACKET_RATE)
    {
        reg |= 1U;
    }
    else
    {
        ret = EINVAL;
    }
    if (EOK == ret)
    {
        hal_write32(reg, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL2));
    }
    return ret;
}

/**
 * @brief       Get shaper rate mode
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @return      Shaper rate mode
 */
pfe_tmu_rate_mode_t pfe_tmu_shp_cfg_get_rate_mode(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 shp)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    pfe_tmu_rate_mode_t rate_mode;
    uint32 reg;

    reg = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL));
    if (0U == (reg & 0x1U))
    {
        /*  Shaper is disabled */
        rate_mode = RATE_MODE_INVALID;
    }
    else
    {
        reg = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL2));
        if (0U != (reg & 0x1U))
        {
            rate_mode = RATE_MODE_PACKET_RATE;
        }
        else
        {
            rate_mode = RATE_MODE_DATA_RATE;
        }
    }
    return rate_mode;
}

/**
 * @brief       Set shaper idle slope
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @param[in]   isl Idle slope in units per second as given by chosen mode
 *                  (bits-per-second, packets-per-second)
 */
errno_t pfe_tmu_shp_cfg_set_idle_slope(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 shp, uint32 isl)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    uint32 reg;
    errno_t ret = EOK;
    uint64 wgt;
    uint64 sys_clk_hz;

    reg = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, (CBUS_GLOBAL_CSR_BASE_ADDR + WSP_CLK_FRQ)));
    sys_clk_hz = (reg & 0xffffULL) * 1000000ULL;
    NXP_LOG_INFO("Using PFE sys_clk value %"PRINT64"uHz\n", sys_clk_hz);

    /*  Set weight (added to credit counter with each sys_clk_hz/clk_div tick) */
    /*  The '+1' in (isl + 1ULL) is needed for mitigating integer division inaccuracy */
    switch (pfe_tmu_shp_cfg_get_rate_mode(cbus_base_va, phy, shp))
    {
        case RATE_MODE_DATA_RATE:
        {
            /*  ISL is bps, WGT is [bytes-per-tick] */
            wgt = ((uint64)(isl + 1ULL) * CLK_DIV * (1ULL << 12)) / (8ULL * sys_clk_hz);
            break;
        }

        case RATE_MODE_PACKET_RATE:
        {
            /*  ISL is pps, WGT is [packets-per-tick] */
            wgt = ((uint64)(isl + 1ULL) * CLK_DIV * (1ULL << 12)) / (sys_clk_hz);
            break;
        }

        default:
        {
            ret = EINVAL;
            break;
        }
    }

    if(ret == EOK)
    {
        if (wgt > 0xfffffU)
        {
            NXP_LOG_WARNING("Shaper weight exceeds max value\n");
        }

        hal_write32(wgt & 0xfffffU, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_WGHT));
        NXP_LOG_INFO("Shaper weight set to %u.%u\n",
            (uint_t)((wgt >> 12) & 0xffU), (uint_t)(wgt & 0xfffU));

        /*  Set clk_div */
        reg = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL));
        reg &= 0x1U;
        hal_write32(reg | (CLK_DIV_LOG2 << 1), ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL));
        NXP_LOG_INFO("Shaper tick is %"PRINT64"uHz\n", sys_clk_hz / CLK_DIV);
    }

    return ret;
}

/**
 * @brief       Get shaper idle slope
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @parma[in]   phy Physical interface ID
 * @param[in]   shp The shaper ID
 * @return      Current idle slope value
 */
uint32 pfe_tmu_shp_cfg_get_idle_slope(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 shp)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));
    uint64 sys_clk_hz;
    uint32 wgt, reg;
    uint64 isl;

    reg = hal_read32(ADDR_BASE_OFFSET(cbus_base_va, (CBUS_GLOBAL_CSR_BASE_ADDR + WSP_CLK_FRQ)));
    sys_clk_hz = (reg & 0xffffULL) * 1000000ULL;
    wgt = hal_read32(ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_WGHT)) & 0xfffffU;

    switch (pfe_tmu_shp_cfg_get_rate_mode(cbus_base_va, phy, shp))
    {
        case RATE_MODE_DATA_RATE:
        {
            isl = ((uint64)wgt * 8ULL * sys_clk_hz) / (CLK_DIV * (1ULL << 12));
        }
        break;

        case RATE_MODE_PACKET_RATE:
        {
            isl = ((uint64)wgt * sys_clk_hz) / (CLK_DIV * (1ULL << 12));
        }
        break;

        default:
        {
            isl = 0ULL;
            break;
        }
    }

    return (uint32)(isl & UINT32_MAX);
}

/**
 * @brief       Disable shaper
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 */
void pfe_tmu_shp_cfg_disable(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));

    uint32 reg = hal_read32(shp_base_va + TMU_SHP_CTRL) & ~(uint32)0x1U;
    hal_write32(reg, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL));
}

/**
 * @brief       Initialize shaper
 * @details     After initialization the shaper is disabled and not connected
 *              to any queue.
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   shp Shaper instance/index
 */
void pfe_tmu_shp_cfg_init(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 shp)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(shp < TLITE_SHP_CNT);
    addr_t shp_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SHPm_BASE_ADDR((uint32)phy, shp));

    /*  Disable */
    pfe_tmu_shp_cfg_disable(cbus_base_va, phy, shp);

    /*  Set invalid position */
    hal_write32(((uint32)TLITE_SHP_INVALID_POS << 1), ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_CTRL2));

    /*  Set default limits */
    hal_write32(0U, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_MAX_CREDIT));
    hal_write32(0U, ADDR_BASE_OFFSET(shp_base_va, TMU_SHP_MIN_CREDIT));
}

/**
 * @brief       Initialize scheduler
 * @details     After initialization the scheduler is not connected
 *              to any queue.
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 */
void pfe_tmu_sch_cfg_init(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));

    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_Q_ALLOC0));
    hal_write32(0xffffffffU, ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_Q_ALLOC1));

    if (0U == sch)
    {
        hal_write32(0xfU, ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_POS));
    }
}

/**
 * @brief       Set rate mode
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   mode The rate mode to be used by scheduler
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_cfg_set_rate_mode(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy,
        uint8 sch, pfe_tmu_rate_mode_t mode)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    uint32 reg;
    errno_t ret = EOK;

    if (mode == RATE_MODE_DATA_RATE)
    {
        reg = 0U;
    }
    else if  (mode == RATE_MODE_PACKET_RATE)
    {
        reg = 1U;
    }
    else
    {
        ret = EINVAL;
    }

    if (EOK == ret)
    {
        hal_write32(reg, ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_BIT_RATE));
    }

    return ret;
}

/**
 * @brief       Get rate mode
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @return      Current rate mode or RATE_MODE_INVALID in case of error
 */
pfe_tmu_rate_mode_t pfe_tmu_sch_cfg_get_rate_mode(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 sch)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    pfe_tmu_rate_mode_t rmode = RATE_MODE_INVALID;
    uint32 reg = hal_read32(ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_BIT_RATE));

    if (0U == reg)
    {
        rmode = RATE_MODE_DATA_RATE;
    }
    else if (1U == reg)
    {
        rmode = RATE_MODE_PACKET_RATE;
    }
    else
    {
        rmode = RATE_MODE_INVALID;
    }

    return rmode;
}

/**
 * @brief       Set scheduler algorithm
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   algo The algorithm to be used
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_cfg_set_algo(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 sch, pfe_tmu_sched_algo_t algo)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    uint32 reg;
    errno_t ret = EOK;

    if (algo == SCHED_ALGO_PQ)
    {
        reg = 0U;
    }
    else if (algo == SCHED_ALGO_DWRR)
    {
        reg = 2U;
    }
    else if (algo == SCHED_ALGO_RR)
    {
        reg = 3U;
    }
    else if (algo == SCHED_ALGO_WRR)
    {
        if (RATE_MODE_PACKET_RATE != pfe_tmu_sch_cfg_get_rate_mode(cbus_base_va, phy, sch))
        {
            /*  See RTL and WRR pseudocode */
            NXP_LOG_ERROR("WRR only supported in Packet Rate scheduler mode\n");
            ret = EINVAL;
        }
        else
        {
            reg = 4U;
        }
    }
    else
    {
        ret = EINVAL;
    }

    if (EOK == ret)
    {
        hal_write32(reg, ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_CTRL));
    }

    return ret;
}

/**
 * @brief       Get scheduler algorithm
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   algo The algorithm to be used
 * @return      EOK if success, error code otherwise
 */
pfe_tmu_sched_algo_t pfe_tmu_sch_cfg_get_algo(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 sch)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    uint32 reg;
    pfe_tmu_sched_algo_t algo = SCHED_ALGO_INVALID;

    reg = hal_read32(ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_CTRL));

    switch (reg & 0xfU)
    {
        case 0x0U:
        {
            algo = SCHED_ALGO_PQ;
            break;
        }

        case 0x2U:
        {
            algo = SCHED_ALGO_DWRR;
            break;
        }

        case 0x3U:
        {
            algo = SCHED_ALGO_RR;
            break;
        }

        case 0x4U:
        {
            algo = SCHED_ALGO_WRR;
            break;
        }

        default:
        {
            algo = SCHED_ALGO_INVALID;
            break;
        }
    }

    return algo;
}

/**
 * @brief       Set input weight
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   input Scheduler input
 * @param[in]   weight The weight value to be used by chosen scheduling algorithm
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_cfg_set_input_weight(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input, uint32 weight)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    errno_t ret;

    if (input >= TLITE_SCH_INPUTS_CNT)
    {
        NXP_LOG_ERROR("Scheduler input (%d) out of range\n", input);
        ret = EINVAL;
    }
    else
    {
        hal_write32(weight, ADDR_BASE_OFFSET(sch_base_va, (uint32)(TMU_SCH_Qn_WGHT(input))));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get input weight
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   input Scheduler input
 * @return      The programmed weight value to be used by chosen scheduling algorithm
 */
uint32 pfe_tmu_sch_cfg_get_input_weight(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    uint32 input_weight;

    if (input >= TLITE_SCH_INPUTS_CNT)
    {
        NXP_LOG_ERROR("Scheduler input (%d) out of range\n", input);
        input_weight = 0U;
    }
    else
    {
        input_weight = hal_read32(ADDR_BASE_OFFSET(sch_base_va, (uint32)(TMU_SCH_Qn_WGHT(input))));
    }

    return input_weight;
}

/**
 * @brief       Connect queue to some scheduler input
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   input Scheduler input the queue shall be connected to
 * @param[in]   queue Queue to be connected to the scheduler input. 0xff will invalidate
 *                  the input.
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_cfg_bind_queue(addr_t cbus_base_va,
        pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input, uint8 queue)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    uint32 reg;
    errno_t ret;

    if ((queue >= TLITE_PHY_QUEUES_CNT) && (queue != TLITE_SCH_INVALID_INPUT))
    {
        NXP_LOG_ERROR("Invalid queue\n");
        ret = EINVAL;
    }
    else if (input >= TLITE_SCH_INPUTS_CNT)
    {
        NXP_LOG_ERROR("Scheduler input (%d) out of range\n", input);
        ret = EINVAL;
    }
    else
    {
        /*  Update appropriate "ALLOC_Q" register */
        reg = hal_read32(ADDR_BASE_OFFSET(sch_base_va, (uint32)(TMU_SCH_Q_ALLOCn((uint32)input / 4U))));
        reg &= ~(0xffUL << (8U * (input % 4U)));
        reg |= (((uint32)queue & 0x1fUL) << (8U * (input % 4U)));
        hal_write32(reg, ADDR_BASE_OFFSET(sch_base_va, (uint32)(TMU_SCH_Q_ALLOCn((uint32)input / 4U))));
        ret = EOK;
    }

    return ret;
}

/**
 * @brief       Get queue connected to given scheduler input
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   input Scheduler input to be queried
 * @return      Queue ID connected to the input or PFE_TMU_INVALID_QUEUE if not present
 */
uint8 pfe_tmu_sch_cfg_get_bound_queue(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, sch));
    uint32 reg;
    uint8 queue;

    if (input >= TLITE_SCH_INPUTS_CNT)
    {
        NXP_LOG_ERROR("Scheduler input (%d) out of range\n", input);
        queue = PFE_TMU_INVALID_QUEUE;
    }
    else
    {
        reg = hal_read32(ADDR_BASE_OFFSET(sch_base_va, (uint32)(TMU_SCH_Q_ALLOCn((uint32)input / 4U))));
        queue = (uint8)((reg >> (8U * (input % 4U))) & UINT8_MAX);

        if (TLITE_PHY_QUEUES_CNT <= queue)
        {
            queue = PFE_TMU_INVALID_QUEUE;
        }
    }

    return queue;
}

/**
 * @brief       Connect output of some other scheduler to current scheduler input
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   src_sch Source scheduler instance/index
 * @param[in]   dst_sch Destination scheduler instance/index
 * @param[in]   input The 'dst_sch' scheduler input where the output of 'src_sch' shall be connected
 * @return      EOK if success, error code otherwise
 */
errno_t pfe_tmu_sch_cfg_bind_sched_output(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 src_sch, uint8 dst_sch, uint8 input)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(src_sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, src_sch));
    errno_t ret;

    /*  Scheduler0 -> Scheduler1 is the only possible option */
    if ((src_sch != 0U) || (dst_sch != 1U))
    {
        NXP_LOG_ERROR("Scheduler 0 output can only be connected to Scheduler 1 input\n");
        ret = EINVAL;
    }
    else
    {

        /*  Invalidate the original Scheduler1 input */
        if (EOK != pfe_tmu_sch_cfg_bind_queue(cbus_base_va, phy, dst_sch, input, PFE_TMU_INVALID_QUEUE))
        {
            ret = EINVAL;
        }
        else
        {
            /*  Connect Scheduler0 to given Scheduler1 input */
            hal_write32((uint32)input & (uint32)0xfU, ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_POS));
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Get scheduler which output is connected to given scheduler input
 * @param[in]   cbus_base_va The cbus base address (VA)
 * @param[in]   phy The physical interface
 * @param[in]   sch Scheduler instance/index
 * @param[in]   input Scheduler input to be queried
 * @return      ID of the connected scheduler or PFE_TMU_INVALID_SCHEDULER
 */
uint8 pfe_tmu_sch_cfg_get_bound_sched_output(addr_t cbus_base_va, pfe_ct_phy_if_id_t phy, uint8 sch, uint8 input)
{
    PfeDevAssert(phy < PFE_PHY_IF_ID_INVALID);
    PfeDevAssert(sch < TLITE_SCH_CNT);
    addr_t sch_base_va = ADDR_BASE_OFFSET(cbus_base_va, TLITE_PHYn_SCHEDm_BASE_ADDR((uint32)phy, 0U));
    uint32 reg;
    uint8 sched_id;

    /*  Scheduler0 -> Scheduler1 is the only possible option */
    if (sch != 1U)
    {
        sched_id = PFE_TMU_INVALID_SCHEDULER;
    }

    reg = hal_read32(ADDR_BASE_OFFSET(sch_base_va, TMU_SCH_POS)) & 0xffU;

    if (input == reg)
    {
        sched_id = 0U;
    }
    else
    {
        sched_id = PFE_TMU_INVALID_SCHEDULER;
    }

    return sched_id;
}

#if defined(PFE_CFG_TEXT_STATS)

/**
 * @brief       Get TMU statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the TMU block.
 * @param[in]   base_va     Base address of TMU register space (virtual)
 * @param[in]   buf         Pointer to buffer to be written
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 *
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_tmu_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;
    uint32 reg, ii;
    uint8 prob, queue, zone;
    uint32 level, drops, tx;

    /* Debug registers */
    if(verb_level >= 10U)
    {
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_PHY_INQ_PKTPTR  : 0x%x\n", hal_read32(base_va + TMU_PHY_INQ_PKTPTR));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_PHY_INQ_PKTINFO : 0x%x\n", hal_read32(base_va + TMU_PHY_INQ_PKTINFO));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_PHY_INQ_STAT    : 0x%x\n", hal_read32(base_va + TMU_PHY_INQ_STAT));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_DBG_BUS_TOP     : 0x%x\n", hal_read32(base_va + TMU_DBG_BUS_TOP));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_DBG_BUS_PP0     : 0x%x\n", hal_read32(base_va + TMU_DBG_BUS_PP0));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_DBG_BUS_PP1     : 0x%x\n", hal_read32(base_va + TMU_DBG_BUS_PP1));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_DBG_BUS_PP2     : 0x%x\n", hal_read32(base_va + TMU_DBG_BUS_PP2));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_DBG_BUS_PP3     : 0x%x\n", hal_read32(base_va + TMU_DBG_BUS_PP3));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_DBG_BUS_PP4     : 0x%x\n", hal_read32(base_va + TMU_DBG_BUS_PP4));
        len += (uint32)oal_util_snprintf(buf + len, size - len, "TMU_DBG_BUS_PP5     : 0x%x\n", hal_read32(base_va + TMU_DBG_BUS_PP5));
    }

    if(verb_level >= 9U)
    {
        /*  Get version */
        reg = hal_read32(base_va + TMU_VERSION);
        len += oal_util_snprintf(buf + len, size - len, "Revision             : 0x%x\n", (reg >> 24) & 0xffU);
        len += oal_util_snprintf(buf + len, size - len, "Version              : 0x%x\n", (reg >> 16) & 0xffU);
        len += oal_util_snprintf(buf + len, size - len, "ID                   : 0x%x\n", reg & 0xffffU);
    }

    reg = hal_read32(base_va + TMU_CTRL);
    len += oal_util_snprintf(buf + len, size - len, "TMU_CTRL             : 0x%x\n", reg);
    reg = hal_read32(base_va + TMU_PHY_INQ_STAT);
    len += oal_util_snprintf(buf + len, size - len, "TMU_PHY_INQ_STAT     : 0x%x\n", reg);
    reg = hal_read32(base_va + TMU_PHY_INQ_PKTPTR);
    len += oal_util_snprintf(buf + len, size - len, "TMU_PHY_INQ_PKTPTR   : 0x%x\n", reg);
    reg = hal_read32(base_va + TMU_PHY_INQ_PKTINFO);
    len += oal_util_snprintf(buf + len, size - len, "TMU_PHY_INQ_PKTINFO  : 0x%x\n", reg);

    /*  Print per-queue statistics */
    for (ii=0U; ii < TLITE_PHYS_CNT; ii++)
    {
        len += oal_util_snprintf(buf + len, size - len, "[PHY: %d]\n", (int_t)ii);
        for (queue=0U; queue<TLITE_PHY_QUEUES_CNT; queue++)
        {
            /*  Fill level */
            level = (EOK != pfe_tmu_q_cfg_get_fill_level(base_va, phy_if_id_temp[ii], queue, &reg)) ? 0xffffffffU : reg;

            /*  Number of dropped packets */
            drops = (EOK != pfe_tmu_q_cfg_get_drop_count(base_va, phy_if_id_temp[ii], queue, &reg)) ? 0xffffffffU : reg;

            /*  Transmitted packets */
            tx = (EOK != pfe_tmu_q_cfg_get_tx_count(base_va, phy_if_id_temp[ii], queue, &reg)) ? 0xffffffffU : reg;

            if ((0U == level) && (0U == drops) && (0U == tx))
            {
                /*  Don't print emtpy queues */
                continue;
            }

            len += oal_util_snprintf(buf + len, size - len, "  [QUEUE: %d]\n", queue);

            /*  curQ_cfg is @ position 4 per queue */
            if (EOK != pfe_tmu_cntx_mem_read(base_va, phy_if_id_temp[ii], (uint8)(((8U * queue) + 4U) & UINT8_MAX), &reg))
            {
                NXP_LOG_ERROR("    Context memory read failed\n");
                continue;
            }

            /*  Configuration */
            switch (reg & 0x3U)
            {
                case 0x0U:
                {
                    len += oal_util_snprintf(buf + len, size - len, "    Mode       : Default\n");
                    break;
                }

                case 0x1U:
                {
                    len += oal_util_snprintf(buf + len, size - len, "    Mode       : Tail drop (max: %d)\n", (reg >> 11) & 0x1ffU);
                    break;
                }

                case 0x2U:
                {
                    len += oal_util_snprintf(buf + len, size - len, "    Mode       : WRED (max: %d, min: %d)\n", (reg >> 11) & 0x1ffU, (reg >> 2) & 0x1ffU);
                    for (zone=0U; zone<pfe_tmu_q_get_wred_zones(base_va, phy_if_id_temp[ii], queue); zone++)
                    {
                        if (EOK != pfe_tmu_q_get_wred_probability(base_va, phy_if_id_temp[ii], queue, zone, &prob))
                        {
                            len += oal_util_snprintf(buf + len, size - len, "      Zone %d   : ERROR\n", zone);
                        }
                        else
                        {
                            len += oal_util_snprintf(buf + len, size - len, "      Zone %d   : %d\n", zone, prob);
                        }
                    }

                    break;
                }

                default:
                {
                    len += oal_util_snprintf(buf + len, size - len, "    Mode       : ERROR\n");
                    break;
                }
            }

            len += oal_util_snprintf(buf + len, size - len, "    Fill level : % 8d Drops: % 8d, TX: % 8d\n", level, drops, tx);
        }
    }


    return len;
}

#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get TMU statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the TMU block.
 * @param[in]   base_va     Base address of TMU register space (virtual)
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic or PFE_INVALID_STAT
 */
uint32 pfe_tmu_cfg_get_stat_value(addr_t base_va, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = PFE_INVALID_STAT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = hal_read32(ADDR_BASE_OFFSET(base_va, stat_id));
    }
    return stat_value;
}

/**
 * @brief       Get TMU statistic in numeric form for queue
 * @details     This is a HW-specific function providing single statistic
 *              value from the TMU block.
 * @param[in]   base_va     Base address of TMU register space (virtual)
 * @param[out]  special_stats  Point to required special statistic
 */
void pfe_tmu_cfg_get_special_stats(addr_t base_va, pfe_tmu_stats_special_t* special_stats)
{
    special_stats->revision = (pfe_tmu_cfg_get_stat_value(base_va, TMU_VERSION) >> 24) & 0xffU;;
    special_stats->version = (pfe_tmu_cfg_get_stat_value(base_va, TMU_VERSION) >> 16) & 0xffU;
    special_stats->id = pfe_tmu_cfg_get_stat_value(base_va, TMU_VERSION) & 0xFFU;
}

/**
 * @brief       Get TMU statistic in numeric form for queue
 * @details     This is a HW-specific function providing single statistic
 *              value from the TMU block depending on queues
 * @param[in]   base_va      Base address of TMU register space (virtual)
 * @param[in]   phy_id       Index of phy
 * @param[in]   queue_id     Index of queue
 * @param[out]  queue_stats  Requested satistics of queue
 * @return      EOK if possible to get queue-based stats, otherwise EFAULT
 */
errno_t pfe_tmu_cfg_get_queue_stats(addr_t base_va, uint32 phy_id, uint32 queue_id, pfe_tmu_queue_stats* queue_stats)
{
    uint32 reg;
    uint8 zone, prob;
    errno_t ret = EFAULT;

    reg = 0;

    queue_id = queue_id & 7U; /* assert queue id < 8 */

    queue_stats->level = (EOK != pfe_tmu_q_cfg_get_fill_level(base_va, phy_if_id_temp[phy_id], queue_id, &reg)) ? 0xffffffffU : reg;

    /*  Number of dropped packets */
    queue_stats->drops = (EOK != pfe_tmu_q_cfg_get_drop_count(base_va, phy_if_id_temp[phy_id], queue_id, &reg)) ? 0xffffffffU : reg;

    /*  Transmitted packets */
    queue_stats->tx = (EOK != pfe_tmu_q_cfg_get_tx_count(base_va, phy_if_id_temp[phy_id], queue_id, &reg)) ? 0xffffffffU : reg;

    /*  curQ_cfg is @ position 4 per queue */
    if(EOK == pfe_tmu_cntx_mem_read(base_va, phy_if_id_temp[phy_id], (uint8)(((8U * queue_id) + 4U) & UINT8_MAX), &reg))
    {
        /*  Configuration */
        switch (reg & 0x3U)
        {
            /* Mode default*/
            case 0x0U:
            {
                queue_stats->mode = TMU_Q_MODE_DEFAULT;
                queue_stats->max = 0U;
                queue_stats->min = 0U;
                break;
            }

            /* Mode tail drop*/
            case 0x1U:
            {
                queue_stats->mode = TMU_Q_MODE_TAIL_DROP;
                queue_stats->max = (reg >> 11) & 0x1ffU;
                queue_stats->min = 0U;
                break;
            }

            /* Mode wred*/
            case 0x2U:
            {
                queue_stats->mode = TMU_Q_MODE_WRED;
                queue_stats->max = (reg >> 11) & 0x1ffU;
                queue_stats->min = (reg >> 2) & 0x1ffU;

                for (zone=0U; zone < 32; zone++)
                {
                    if (EOK != pfe_tmu_q_get_wred_probability(base_va, phy_if_id_temp[phy_id], queue_id, zone, &prob))
                    {
                        queue_stats->zprob[zone] = 0xFFU;
                    }
                    else
                    {
                        queue_stats->zprob[zone] = prob;
                    }
                }

                break;
            }

            default:
            {
                queue_stats->mode = TMU_Q_MODE_INVALID;
                queue_stats->max = 0U;
                queue_stats->min = 0U;
                break;
            }
        }
        ret = EOK;
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/** @}*/


===== 文件 [182/185]: src\pfe_util.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"

#include "pfe_platform_cfg.h"
#include "pfe_cbus.h"
#include "pfe_pe.h"
#include "pfe_util.h"
#include "pfe_util_csr.h"
#include "autolibc.h"

/* Configuration check */
#if ((PFE_CFG_PE_LMEM_BASE + PFE_CFG_PE_LMEM_SIZE) > CBUS_LMEM_SIZE)
    #error PE memory area exceeds LMEM capacity
#endif

#define PFE_UTIL_PE_COUNT 1U
#define PFE_UTIL_FW_FEATURES_COUNT 8U

struct pfe_util_tag
{
    bool_t is_fw_loaded;            /*  Flag indicating that firmware has been loaded */
    addr_t cbus_base_va;            /*  CBUS base virtual address */
    uint32 pe_num;                /*  Number of PEs */
    pfe_pe_t pe[PFE_UTIL_PE_COUNT]; /*  List of particular PEs */
    bool_t miflock_pe;              /*  Shared 'miflock' diagnostic flag for UTIL PE cores */
    uint32 current_feature;       /* Index of the feature to return by pfe_util_get_feature_next() */
    pfe_fw_feature_t fw_features[PFE_UTIL_FW_FEATURES_COUNT]; /* List of all features*/
    uint32 fw_features_count;     /* Number of items in fw_features */
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_util_t util_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

static errno_t pfe_util_read_dmem(void *util_p, sint32 pe_idx, void *dst_ptr, addr_t src_addr, uint32 len);
static errno_t pfe_util_write_dmem(void *util_p, sint32 pe_idx, addr_t dst_addr, const void *src_ptr, uint32 len);
static bool_t pfe_util_check_new_fw_features(pfe_util_t *util, errno_t *ret, uint32 features_idx);

/**
 * @brief       Get the features of the util PE block.
 * @param[in]   util The UTIL instance
 * @param[in]   features_idx The features indexs
 * @return      The status of PEs get features
 */
static bool_t pfe_util_check_new_fw_features(pfe_util_t *util, errno_t *ret, uint32 features_idx)
{
    bool_t val_break = FALSE;
    pfe_ct_feature_desc_t *entry;
    uint32 j;

    /* Get feature low level data */
    *ret = pfe_pe_get_fw_feature_entry(&util->pe[0U], features_idx, &entry);
    if(EOK != *ret)
    {
        NXP_LOG_ERROR("Failed get ll data for feature %u\n", (uint_t)features_idx);
        /* Destroy previously created and return failure */
        for(j = 0U; j < features_idx; j++)
        {
            pfe_fw_feature_destroy(&util->fw_features[j]);
        }
        util->fw_features_count = 0U;
        *ret = EINVAL;
        val_break = TRUE;
    }
    else
    {
        /* Set the low level data in the feature */
        PfeDevAssert(0xFFU >= util->pe_num);
        (void)pfe_fw_feature_set_ll_data(&util->fw_features[features_idx], entry, (uint8)util->pe_num);
        /* Set the feature string base */
        *ret = pfe_fw_feature_set_string_base(&util->fw_features[features_idx], pfe_pe_get_fw_feature_str_base(&util->pe[0U]));
        if(EOK != *ret)
        {
            NXP_LOG_ERROR("Failed to set string base for feature %u\n", (uint_t)features_idx);
            /* Destroy previously created and return failure */
            for(j = 0U; j < features_idx; j++)
            {
                pfe_fw_feature_destroy(&util->fw_features[j]);
            }
            util->fw_features_count = 0U;
            *ret = EINVAL;
            val_break = TRUE;
        }
        else
        {
            /* Set functions to read/write DMEM and their data */
            (void)pfe_fw_feature_set_dmem_funcs(&util->fw_features[features_idx], &pfe_util_read_dmem, &pfe_util_write_dmem, (void *)util);
        }
    }

    return val_break;
}

/**
 * @brief       Get the features of the util PE block.
 * @param[in]   util The UTIL instance
 * @return      The status of PEs get features
 */
static errno_t pfe_util_load_fw_features(pfe_util_t *util)
{
    pfe_ct_pe_mmap_t mmap;
    errno_t ret = EOK;
    uint32 fw_features_idx;
    bool_t val_break = FALSE;

    ret = pfe_pe_get_mmap(&util->pe[0U], &mmap);
    if(EOK == ret)
    {
        util->fw_features_count = oal_ntohl(mmap.common.version.features_count);
        if(util->fw_features_count > 0U)
        {
            if (util->fw_features_count > PFE_UTIL_FW_FEATURES_COUNT)
            {
                NXP_LOG_ERROR("Insufficient util features storage for %u entries\n", (uint_t)util->fw_features_count);
                util->fw_features_count = 0U;
                ret = ENOMEM;
            }
            else
            {
                /* Initialize current_feature */
                util->current_feature = 0U;
                for(fw_features_idx = 0 ; fw_features_idx < util->fw_features_count; fw_features_idx++)
                {
                    (void)pfe_fw_feature_create(&util->fw_features[fw_features_idx]);
                    val_break = pfe_util_check_new_fw_features(util, &ret, fw_features_idx);
                    if (TRUE == val_break)
                    {
                        break;
                    }
                }
            }
        } /* Else is OK too */
    }
    return ret;
}



/**
 * @brief       Set the configuration of the util PE block.
 * @param[in]   util The UTIL instance
 * @param[in]   cfg Pointer to the configuration structure
 */
static void pfe_util_set_config(const pfe_util_t *util, const pfe_util_cfg_t *cfg)
{
    uint32 regval;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == util) || (NULL == cfg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        hal_write32(cfg->pe_sys_clk_ratio, util->cbus_base_va + UTIL_PE_SYS_CLK_RATIO);
        if (TRUE == cfg->on_g3)
        {
            regval = hal_read32(util->cbus_base_va + UTIL_MISC_REG_ADDR);
            regval |= 0x3U;
            hal_write32(regval, util->cbus_base_va + UTIL_MISC_REG_ADDR);
        }
    }
}

/**
 * @brief       Create PEs
 * @param[in]   pe_num The number of pe
 * @param[in]   cbus_base_va The cbus base address
 * @param[in]   util The UTIL instance
 * @return      The status of PEs creating task
 */
static errno_t pfe_util_create_pe(uint32 pe_num, addr_t cbus_base_va, pfe_util_t *util)
{
    pfe_pe_t *pe;
    uint32 count;
    errno_t ret = EOK;

    /*  Create PEs */
    for (count = 0U; count < pe_num; count++)
    {
        pe = pfe_pe_create(cbus_base_va, PE_TYPE_UTIL, (uint8)count, &util->pe[count], &util->miflock_pe);

        if (NULL == pe)
        {
            ret = ECANCELED;
            break;
        }
        else
        {
            pfe_pe_set_iaccess(pe, UTIL_MEM_ACCESS_WDATA, UTIL_MEM_ACCESS_RDATA, UTIL_MEM_ACCESS_ADDR);
            pfe_pe_set_dmem(pe, PFE_CFG_UTIL_ELF_DMEM_BASE, PFE_CFG_UTIL_DMEM_SIZE);
            pfe_pe_set_imem(pe, PFE_CFG_UTIL_ELF_IMEM_BASE, PFE_CFG_UTIL_IMEM_SIZE);
            PfeDevAssert(util->pe_num < UINT32_MAX);
            util->pe_num++;
        }
    }

    return ret;
}

/**
 * @brief       Create new UTIL instance
 * @details     Creates and initializes UTIL instance. After successful
 *              call the UTIL is configured and disabled.
 * @param[in]   cbus_base_va CBUS base virtual address
 * @param[in]   pe_num Number of PEs to be included
 * @param[in]   cfg The UTIL block configuration
 * @return      The UTIL instance or NULL if failed
 */
pfe_util_t *pfe_util_create(addr_t cbus_base_va, uint32 pe_num, const pfe_util_cfg_t *cfg)
{
    pfe_util_t *util;
    errno_t ret = EOK;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL_ADDR == cbus_base_va) || (NULL == cfg)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        util = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        util = &util_instance;
        (void)autolibc_memset(util, 0, sizeof(pfe_util_t));
        util->cbus_base_va = cbus_base_va;

        if (pe_num > 0U)
        {
            /*  Create PEs */
            ret = pfe_util_create_pe(pe_num, cbus_base_va, util);
            if(EOK != ret)
            {
                pfe_util_destroy(util);
                util = NULL;
            }
            else
            {
                /*  Issue block reset */
                pfe_util_reset(util);

                /*  Disable the UTIL block */
                pfe_util_disable(util);

                /*  Set new configuration */
                pfe_util_set_config(util, cfg);
            }
        }
        else
        {
            util = NULL;
        }
    }

    return util;
}

/**
 * @brief       Reset the UTIL block
 * @param[in]   util The UTIL instance
 */
void pfe_util_reset(pfe_util_t *util)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == util))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        hal_write32(PFE_CORE_SW_RESET, util->cbus_base_va + UTIL_TX_CTRL);
    }
}

/**
 * @brief       Enable the UTIL block
 * @details     Enable all UTIL PEs
 * @param[in]   util The UTIL instance
 */
void pfe_util_enable(pfe_util_t *util)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == util))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if (unlikely(FALSE == util->is_fw_loaded))
        {
            NXP_LOG_WARNING("Attempt to enable UTIL PE(s) without previous firmware upload\n");
        }
        hal_write32(PFE_CORE_ENABLE, util->cbus_base_va + UTIL_TX_CTRL);
    }
}

/**
 * @brief       Disable the UTIL block
 * @param[in]   util The UTIL instance
 */
void pfe_util_disable(pfe_util_t *util)
{
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == util))
    {
        NXP_LOG_ERROR("NULL argument received\n");
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        hal_write32(PFE_CORE_DISABLE, util->cbus_base_va + UTIL_TX_CTRL);
    }
}

/**
 * @brief       Init Util PEs memories
 * @param[in]   util The UTIL instance
 */
errno_t pfe_util_default_init(pfe_util_t *util)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (NULL == util)
    {
        NXP_LOG_ERROR("NULL argument\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_pe_mem_default_init(util->pe, util->pe_num);
    }
    return ret;
}

/**
 * @brief       Load firmware elf into PEs memories
 * @param[in]   util The UTIL instance
 * @param[in]   elf The elf file object to be uploaded
 * @return      EOK when success or error code otherwise
 */
errno_t pfe_util_load_firmware(pfe_util_t *util, const void *elf)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == util) || (NULL == elf)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        ret = pfe_pe_load_firmware(util->pe, util->pe_num, elf);
        if (EOK != ret)
        {
            NXP_LOG_ERROR("UTIL firmware loading failed: %d\n", ret);
        }

        util->is_fw_loaded = TRUE;
        ret = pfe_util_load_fw_features(util);
        if(EOK != ret)
        {
            NXP_LOG_ERROR("Failed to initialize FW features\n");
        }
    }
    return ret;
}

/**
 * @brief       Destroy util block instance
 * @param[in]   util The util block instance
 */
void pfe_util_destroy(pfe_util_t *util)
{
    uint32 count;

    if (NULL != util)
    {
        pfe_pe_destroy(util->pe, util->pe_num);

        for(count = 0U; count < util->fw_features_count; count++)
        {
            pfe_fw_feature_destroy(&util->fw_features[count]);
        }
        util->fw_features_count = 0U;
        util->pe_num = 0U;
    }
}

/**
 * @brief Finds and returns Util FW feature by its name
 * @param[in] util The Util instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @param[in] name Name of the feature to be found
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
errno_t pfe_util_get_feature(pfe_util_t *util, pfe_fw_feature_t **feature, const char *name)
{
    uint32 count;
    const char *fname;
    errno_t ret = ENOENT;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == util)||(NULL == feature)||(NULL == name)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        for(count = 0U; count < util->fw_features_count; count++)
        {
            ret = pfe_fw_feature_get_name(&util->fw_features[count], &fname);
            if(EOK == ret)
            {
                if(0 == autolibc_strcmp(fname, name))
                {
                    *feature = &util->fw_features[count];
                    ret = EOK;
                    break;
                }
                else
                {
                    ret = ENOENT;
                }
            }
        }
    }
    return ret;
}

/**
 * @brief Finds and returns the 1st Util FW feature by order of their discovery - used for listing all features
 * @param[in] util The Util instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
errno_t pfe_util_get_feature_first(pfe_util_t *util, pfe_fw_feature_t **feature)
{
    errno_t ret;

 #if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == util)||(NULL == feature)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(util->fw_features_count > 0U)
        {
            util->current_feature = 0U;
            *feature = &util->fw_features[util->current_feature];
            ret = EOK;
        }
        else
        {
            ret = ENOENT;
        }
    }
    return ret;
}

/**
 * @brief Finds and returns the next Util FW feature by order of their discovery - used for listing all features
 * @param[in] util The Util instance
 * @param[out] feature Feature found (valid only if EOK is returned)
 * @return EOK when given entry is found, ENOENT when it is not found, error code otherwise
 */
errno_t pfe_util_get_feature_next(pfe_util_t *util, pfe_fw_feature_t **feature)
{
    errno_t ret;

 #if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == util)||(NULL == feature)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(util->fw_features_count > 0U)
        {
            /* Avoid going out of the array boundaries */
            if((util->current_feature + 1U) < util->fw_features_count)
            {
                util->current_feature += 1U;
                *feature = &util->fw_features[util->current_feature];
                ret = EOK;
            }
            else
            {
                ret = ENOENT;
            }
        }
        else
        {
            ret = ENOENT;
        }
    }
    return ret;
}

/**
 * @brief       Write data from host memory to DMEM
 * @param[in]   util_p The util instance
 * @param[in]   pe_idx PE index or -1 if all PEs shall be written
 * @param[in]   dst_addr Destination address within DMEM (physical)
 * @param[in]   src_ptr Pointer to data in host memory (virtual address)
 * @param[in]   len Number of bytes to be written
 * @return      EOK or error code in case of failure
 */
static errno_t pfe_util_write_dmem(void *util_p, sint32 pe_idx, addr_t dst_addr, const void *src_ptr, uint32 len)
{
    uint32 count;
    pfe_util_t *util = (pfe_util_t *)util_p;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == util))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((sint64)pe_idx >= (sint64)(util->pe_num))
        {
            ret = EINVAL;
        }
        else
        {
            if (pe_idx >= 0)
            {
                /*  Single PE */
                pfe_pe_memcpy_from_host_to_dmem_32(&util->pe[pe_idx], dst_addr, src_ptr, len);
            }
            else
            {
                /*  All PEs */
                for (count = 0U; count < util->pe_num; count++)
                {
                    pfe_pe_memcpy_from_host_to_dmem_32(&util->pe[count], dst_addr, src_ptr, len);
                }
            }

            ret = EOK;
        }
    }

    return ret;
}

/**
 * @brief       Read data from DMEM to host memory
 * @param[in]   util_p The util instance
 * @param[in]   pe_idx PE index
 * @param[in]   dst_ptr Destination address within host memory (virtual)
 * @param[in]   src_addr Source address within DMEM (physical)
 * @param[in]   len Number of bytes to be read
 * @return      EOK or error code in case of failure
 */
static errno_t pfe_util_read_dmem(void *util_p, sint32 pe_idx, void *dst_ptr, addr_t src_addr, uint32 len)
{
    pfe_util_t *util = (pfe_util_t *)util_p;
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely((NULL == util) || (NULL == dst_ptr)))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if ((sint64)pe_idx >= (sint64)(util->pe_num))
        {
            ret = EINVAL;
        }
        else
        {
            pfe_pe_memcpy_from_dmem_to_host_32(&util->pe[pe_idx], dst_ptr, src_addr, len);
            ret = EOK;
        }
    }
    return ret;
}

/**
 * @brief       Returns firmware versions
 * @param[in]   util The UTIL instance
 * @return      ver Parsed firmware metadata
 */
errno_t pfe_util_get_fw_version(const pfe_util_t *util, pfe_ct_version_t *ver)
{
    pfe_ct_pe_mmap_t pfe_pe_mmap;
    errno_t ret;

    /*  Get mmap base from PE[0] since all PEs have the same memory map */
    ret = pfe_pe_get_mmap(&util->pe[0], &pfe_pe_mmap);
    if ((util->pe_num == 0U) || (EOK != ret))
    {
        ret = EINVAL;
    }
    else
    {
        (void)autolibc_memcpy(ver, &pfe_pe_mmap.util_pe.common.version, sizeof(pfe_ct_version_t));
        ret = EOK;
    }

    return ret;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [183/185]: src\pfe_util_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2018-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "pfe_cbus.h"
#include "pfe_util_csr.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Get UTIL statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the UTIL block.
 * @param[in]   base_va     Base address of UTIL register space (virtual)
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_util_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U, reg;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Get version */
        if(verb_level >= 9U)
        {
            reg = hal_read32(base_va + UTIL_VERSION);
            len += oal_util_snprintf(buf + len, size - len, "Revision             : 0x%x\n", (reg >> 24U) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "Version              : 0x%x\n", (reg >> 16U) & 0xffU);
            len += oal_util_snprintf(buf + len, size - len, "ID                   : 0x%x\n", reg & 0xffffU);
        }

        len += oal_util_snprintf(buf + len, size - len, "Max buffer count\t0x%08x\n", hal_read32(base_va + UTIL_MAX_BUF_CNT));
        len += oal_util_snprintf(buf + len, size - len, "TQS max count\t\t0x%08x\n", hal_read32(base_va + UTIL_TSQ_MAX_CNT));
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"


===== 文件 [184/185]: src\pfe_wdt.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "Eth_43_PFE.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_wdt.h"
#include "pfe_wdt_csr.h"

struct pfe_wdt_tag
{
    addr_t cbus_base_va;
    addr_t wdt_base_offset;
    addr_t wdt_base_va;
};

#define ETH_43_PFE_START_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"
static pfe_wdt_t wdt_instance;
#define ETH_43_PFE_STOP_SEC_VAR_CLEARED_UNSPECIFIED
#include "Eth_43_PFE_MemMap.h"

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

pfe_wdt_t *pfe_wdt_create(addr_t cbus_base_va, addr_t wdt_base)
{
    pfe_wdt_t *wdt;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == cbus_base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        wdt = NULL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        wdt = &wdt_instance;
        (void)autolibc_memset(wdt, 0, sizeof(pfe_wdt_t));
        wdt->cbus_base_va = cbus_base_va;
        wdt->wdt_base_offset = wdt_base;
        wdt->wdt_base_va = (ADDR_BASE_OFFSET(wdt->cbus_base_va, wdt->wdt_base_offset));

        pfe_wdt_cfg_init(wdt->wdt_base_va);
    }
    return wdt;
}

/**
 * @brief       Destroy WDT instance
 * @param[in]   wdt The WDT instance
 */
void pfe_wdt_destroy(pfe_wdt_t *wdt)
{
    if (NULL != wdt)
    {
        pfe_wdt_cfg_fini(wdt->wdt_base_va);
    }
}

/**
 * @brief       WDT ISR
 * @param[in]   wdt The WDT instance
 * @return      EOK if interrupt has been handled
 */
errno_t pfe_wdt_isr(pfe_wdt_t *wdt)
{
    errno_t ret;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == wdt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        ret = EINVAL;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        /*  Run the low-level ISR to identify and process the interrupt */
        if (EOK == pfe_wdt_cfg_isr(wdt->wdt_base_va, wdt->cbus_base_va))
        {
            /*  IRQ handled */
            ret = EOK;
        }
        else
        {
            ret = EINVAL;
        }
    }
    return ret;
}

/**
 * @brief       Mask WDT interrupts
 * @param[in]   The WDT instance
 */
void pfe_wdt_irq_mask(pfe_wdt_t *wdt)
{
    pfe_wdt_cfg_irq_mask(wdt->wdt_base_va);
}

/**
 * @brief       Unmask WDT interrupts
 * @param[in]   The WDT instance
 */
void pfe_wdt_irq_unmask(pfe_wdt_t * wdt)
{
    pfe_wdt_cfg_irq_unmask(wdt->wdt_base_va);
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Return WDT runtime statistics in text form
 * @details     Function writes formatted text into given buffer.
 * @param[in]   wdt         The WDT instance
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   buf_len     Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_wdt_get_text_statistics(const pfe_wdt_t *wdt, char_t *buf, uint32 buf_len, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == wdt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        len += pfe_wdt_cfg_get_text_stat(wdt->wdt_base_va, buf, buf_len, verb_level);
    }
    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get Wdt statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the Wdt block.
 * @param[in]   wdt        The Wdt instance
 * @param[in]   stat_id    ID of required statistic (offset of register)
 * @return      Value of requested statistic and PFE_INVALID_STAT if wdt is NULL
 */
uint32 pfe_wdt_get_stat_value(const pfe_wdt_t* wdt, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL == wdt))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = PFE_INVALID_STAT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = pfe_wdt_cfg_get_stat_value(wdt->wdt_base_va, stat_id);
    }
    return stat_value;
}


#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif /* PFE_CFG_PFE_MASTER */


===== 文件 [185/185]: src\pfe_wdt_csr.c =====
/* =========================================================================
 *  Project              : AUTOSAR 4.4 MCAL
 *  Platform             : CORTEXM
 *  Peripheral           : PFE
 *  Dependencies         : none
 *
 *  Autosar Version      : 4.4.0
 *  Autosar Revision     : ASR_REL_4_4_REV_0000
 *  Autosar Conf.Variant :
 *  SW Version           : 1.5.0
 *  Build Version        : PFE-DRV_S32G_M7_MCAL_1.5.0_D2411_ASR_REL_4_4_REV_0000_20241119
 *
 *  This code (or certain portions of it) is released for use under license
 *  from Imagination Technologies Limited.
 *  Copyright (c) 2019 Imagination Technologies Limited
 *  Copyright (c) 2020-2021 Imagination Technologies Limited
 *  Copyright 2020-2024 NXP
 *
 *  NXP Confidential and Proprietary. This software is owned or controlled by NXP and may only
 *  be used strictly in accordance with the applicable license terms. By
 *  expressly accepting such terms or by downloading, installing, activating
 *  and/or otherwise using the software, you are agreeing that you have read,
 *  and that you agree to comply with and are bound by, such license terms. If
 *  you do not agree to be bound by the applicable license terms, then you may
 *  not retain, install, activate or otherwise use the software.
 *  <<< PFE Restricted Software >>>
 *
 * ========================================================================= */

/*==================================================================================================
*                              SOURCE FILE VERSION INFORMATION
==================================================================================================*/
#define PFE_SRC_VERSION_CHECK 43150440

#include "pfe_cfg.h"
#include "oal.h"
#include "hal.h"
#include "Eth_43_PFE.h"
#ifdef PFE_CFG_PFE_MASTER
#include "pfe_cbus.h"
#include "pfe_wdt_csr.h"
#include "pfe_feature_mgr.h"
#include "pfe_hm.h"
#include "pfe_global_wsp.h"
#include "Eth_43_PFE_Cfg.h"

#define WDT_INT_SRC_NUMBER_G2 11U
#define WDT_INT_SRC_NUMBER_G3 18U

#define ETH_43_PFE_START_SEC_CODE
#include "Eth_43_PFE_MemMap.h"

/**
 * @brief       WDT ISR
 * @details     MASK, ACK, and process triggered interrupts.
 *              Every WDT instance has its own handler. Access to registers is
 *              protected by mutex implemented within the WDT module (pfe_wdt.c).
 * @param[in]   base_va WDT register space base address (virtual)
 * @param[in]   cbus_base_va CBUS base address (virtual)
 * @return      EOK if interrupt has been handled, error code otherwise
 * @note        Make sure the call is protected by some per-BMU mutex
 */
errno_t pfe_wdt_cfg_isr(addr_t base_va, addr_t cbus_base_va)
{
    uint8 index = 0U;
    uint32 reg_en, reg_src, reg_reen = 0U;
    errno_t ret = ENOENT;

    /* G2 WDT bits */
    static const uint32 wdt_int_src_arr_g2[WDT_INT_SRC_NUMBER_G2] =
    {
        WDT_BMU1_WDT_INT_G2, WDT_BMU2_WDT_INT_G2, WDT_CLASS_WDT_INT_G2, WDT_EMAC0_GPI_WDT_INT_G2,
        WDT_EMAC1_GPI_WDT_INT_G2, WDT_EMAC2_GPI_WDT_INT_G2, WDT_HIF_GPI_WDT_INT_G2,
        WDT_HIF_NOCPY_WDT_INT_G2, WDT_HIF_WDT_INT_G2, WDT_TLITE_WDT_INT_G2, WDT_UTIL_WDT_INT_G2
    };
    static const uint32 wdt_int_en_arr_g2[WDT_INT_SRC_NUMBER_G2] =
    {
        WDT_BMU1_WDT_INT_EN_BIT_G2, WDT_BMU2_WDT_INT_EN_BIT_G2, WDT_CLASS_WDT_INT_EN_BIT_G2,
        WDT_EMAC0_GPI_WDT_INT_EN_BIT_G2, WDT_EMAC1_GPI_WDT_INT_EN_BIT_G2, WDT_EMAC2_GPI_WDT_INT_EN_BIT_G2,
        WDT_HIF_GPI_WDT_INT_EN_BIT_G2, WDT_HIF_NOCPY_WDT_INT_EN_BIT_G2, WDT_HIF_WDT_INT_EN_BIT_G2,
        WDT_TLITE_WDT_INT_EN_BIT_G2, WDT_UTIL_PE_WDT_INT_EN_BIT_G2
    };

    static const pfe_hm_evt_t wdt_int_event_id_g2[WDT_INT_SRC_NUMBER_G2] =
    {
        HM_EVT_WDT_BMU1, HM_EVT_WDT_BMU2, HM_EVT_WDT_CLASS, HM_EVT_WDT_EMAC0_GPI,
        HM_EVT_WDT_EMAC1_GPI, HM_EVT_WDT_EMAC2_GPI, HM_EVT_WDT_HIF_GPI, HM_EVT_WDT_HIF_NOCPY,
        HM_EVT_WDT_HIF, HM_EVT_WDT_TLITE, HM_EVT_WDT_UTIL_PE
    };

    /* G3 WDT bits */
    static const uint32 wdt_int_src_arr_g3[WDT_INT_SRC_NUMBER_G3] =
    {
        WDT_BMU1_WDT_INT, WDT_BMU2_WDT_INT, WDT_CLASS_WDT_INT, WDT_EMAC0_GPI_WDT_INT,
        WDT_EMAC1_GPI_WDT_INT, WDT_EMAC2_GPI_WDT_INT, WDT_HIF_GPI_WDT_INT,
        WDT_HIF_NOCPY_WDT_INT, WDT_HIF_WDT_INT, WDT_TLITE_WDT_INT, WDT_UTIL_PE_WDT_INT,
        WDT_EMAC0_ETGPI_WDT_INT, WDT_EMAC1_ETGPI_WDT_INT, WDT_EMAC2_ETGPI_WDT_INT,
        WDT_EXT_GPT1_WDT_INT, WDT_EXT_GPT2_WDT_INT, WDT_LMEM_WDT_INT, WDT_ROUTE_LMEM_WDT_INT
    };
    static const uint32 wdt_int_en_arr_g3[WDT_INT_SRC_NUMBER_G3] =
    {
        WDT_BMU1_WDT_INT_EN_BIT, WDT_BMU2_WDT_INT_EN_BIT, WDT_CLASS_WDT_INT_EN_BIT, WDT_EMAC0_GPI_WDT_INT_EN_BIT,
        WDT_EMAC1_GPI_WDT_INT_EN_BIT, WDT_EMAC2_GPI_WDT_INT_EN_BIT, WDT_HIF_GPI_WDT_INT_EN_BIT,
        WDT_HIF_NOCPY_WDT_INT_EN_BIT, WDT_HIF_WDT_INT_EN_BIT, WDT_TLITE_WDT_INT_EN_BIT, WDT_UTIL_PE_WDT_INT_EN_BIT,
        WDT_EMAC0_ETGPI_WDT_INT_EN_BIT, WDT_EMAC1_ETGPI_WDT_INT_EN_BIT, WDT_EMAC2_ETGPI_WDT_INT_EN_BIT,
        WDT_EXT_GPT1_WDT_INT_EN_BIT, WDT_EXT_GPT2_WDT_INT_EN_BIT, WDT_LMEM_WDT_INT_EN_BIT, WDT_ROUTE_LMEM_WDT_INT_EN_BIT
    };

    static const pfe_hm_evt_t wdt_int_event_id_g3[WDT_INT_SRC_NUMBER_G3] =
    {
        HM_EVT_WDT_BMU1, HM_EVT_WDT_BMU2, HM_EVT_WDT_CLASS, HM_EVT_WDT_EMAC0_GPI,
        HM_EVT_WDT_EMAC1_GPI, HM_EVT_WDT_EMAC2_GPI, HM_EVT_WDT_HIF_GPI, HM_EVT_WDT_HIF_NOCPY,
        HM_EVT_WDT_HIF, HM_EVT_WDT_TLITE, HM_EVT_WDT_UTIL_PE, HM_EVT_WDT_EMAC0_ETGPI,
        HM_EVT_WDT_EMAC1_ETGPI, HM_EVT_WDT_EMAC2_ETGPI, HM_EVT_WDT_EXT_GPT1,
        HM_EVT_WDT_EXT_GPT2, HM_EVT_WDT_LMEM, HM_EVT_WDT_ROUTE_LMEM
    };

    const uint32 *int_src_arr, *int_en_arr;
    const pfe_hm_evt_t *int_event_arr;
    uint8 int_src_nbr = 0;

    (void)cbus_base_va;

    if (FALSE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
    {
        int_src_arr = (uint32 *)wdt_int_src_arr_g2;
        int_en_arr = (uint32 *)wdt_int_en_arr_g2;
        int_event_arr = wdt_int_event_id_g2;
        int_src_nbr = (uint8)WDT_INT_SRC_NUMBER_G2;
    }
    else
    {
        int_src_arr = (uint32 *)wdt_int_src_arr_g3;
        int_en_arr = (uint32 *)wdt_int_en_arr_g3;
        int_event_arr = wdt_int_event_id_g3;
        int_src_nbr = (uint8)WDT_INT_SRC_NUMBER_G3;
    }

    /*  Get enabled interrupts */
    reg_en = hal_read32(base_va + WDT_INT_EN);
    /*  Mask ALL interrupts */
    hal_write32(0U, base_va + WDT_INT_EN);
    /*  Get triggered interrupts */
    reg_src = hal_read32(base_va + WDT_INT_SRC);
    /*  ACK triggered */
    hal_write32(reg_src, base_va + WDT_INT_SRC);

    /*  Process interrupts which are triggered AND enabled */
    for(index = 0U; index < int_src_nbr; index++)
    {
        if (((reg_src & int_src_arr[index]) != 0U) && ((reg_en & int_en_arr[index]) != 0U))
        {
            pfe_hm_report_error(HM_SRC_WDT, int_event_arr[index], "");
#if(STD_ON == ETH_43_PFE_DEM_EVENT_DETECT)
            (void)Dem_SetEventStatus((Dem_EventIdType)ETH_43_PFE_CFG_DEM_E_PFE_WDT_ERR, DEM_EVENT_STATUS_PREFAILED);
#endif /* ETH_43_PFE_DEM_EVENT_DETECT */
            reg_reen |= int_en_arr[index];
            ret = EOK;
        }
    }

    /*  Don't re-enable triggered ones since they can't be cleared until PFE
        is reset. Also don't reset master enable bit which is controlled
        by dedicated API (pfe_wdt_cfg_irq_mask/pfe_wdt_cfg_irq_unmask). */
    hal_write32((reg_en & ~reg_reen), base_va + WDT_INT_EN); /* Enable the non-triggered ones only */

    return ret;
}

/**
 * @brief       Mask WDT interrupts
 * @param[in]   base_va Base address of the WDT register space
 */
void pfe_wdt_cfg_irq_mask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WDT_INT_EN) & ~(WDT_INT_EN_BIT);
    hal_write32(reg, base_va + WDT_INT_EN);
}

/**
 * @brief       Unmask WDT interrupts
 * @param[in]   base_va Base address of the WDT register space
 */
void pfe_wdt_cfg_irq_unmask(addr_t base_va)
{
    uint32 reg;

    reg = hal_read32(base_va + WDT_INT_EN) | WDT_INT_EN_BIT;
    hal_write32(reg, base_va + WDT_INT_EN);
}

/**
 * @brief       init WDT interrupts
 * @param[in]   base_va Base address of the wsp register space
 */
void pfe_wdt_cfg_init(addr_t base_va)
{
    uint32 reg;

    /*  Disable the WDT interrupts */
    reg = hal_read32(base_va + WDT_INT_EN) & ~(WDT_INT_EN_BIT);
    hal_write32(reg, base_va + WDT_INT_EN);

    /*  Clear WDT interrupts */
    reg = hal_read32(base_va + WDT_INT_SRC);
    hal_write32(reg, base_va + WDT_INT_SRC);

    /*  Set default watchdog timer values. */
    hal_write32(0xFFFFFFFFU, base_va + WDT_TIMER_VAL_UPE);
    hal_write32(0xFFFFFFFFU, base_va + WDT_TIMER_VAL_BMU);
    hal_write32(0xFFFFFFFFU, base_va + WDT_TIMER_VAL_HIF);
    hal_write32(0xFFFFFFU, base_va + WDT_TIMER_VAL_TLITE);

    if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
    {
        /*  G3 watchdog default values */
        hal_write32(0xFFFFFFU, base_va + WDT_TIMER_VAL_HIF_NCPY);
        hal_write32(0xFFFFFFU, base_va + WDT_TIMER_VAL_CLASS);
        hal_write32(0xFFFFFFU, base_va + WDT_TIMER_VAL_GPI);
        hal_write32(0xFFFFFFU, base_va + WDT_TIMER_VAL_GPT);
        hal_write32(0xFFFFFFU, base_va + WDT_TIMER_VAL_LMEM);
        hal_write32(0xFFFFFFU, base_va + WDT_TIMER_VAL_ROUTE_LMEM);
    }

    /*  Enable ALL particular watchdogs */
    hal_write32(0xFFFFFFU, base_va + CLASS_WDT_INT_EN);
    hal_write32(0xFU, base_va + UPE_WDT_INT_EN);
    hal_write32(0xABU, base_va + HGPI_WDT_INT_EN);
    hal_write32(0xCU, base_va + HIF_WDT_INT_EN);
    hal_write32(0xFFFFFFU, base_va + TLITE_WDT_INT_EN);
    hal_write32(0x3FU, base_va + HNCPY_WDT_INT_EN);
    hal_write32(0xFU, base_va + BMU1_WDT_INT_EN);
    hal_write32(0xFU, base_va + BMU2_WDT_INT_EN);
    hal_write32(0xFFFU, base_va + EMAC0_WDT_INT_EN);
    hal_write32(0xFFFU, base_va + EMAC1_WDT_INT_EN);
    hal_write32(0xFFFU, base_va + EMAC2_WDT_INT_EN);

    if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
    {
        /*  G3 watchdogs */
        hal_write32(0x3U, base_va + EXT_GPT_WDT_INT_EN);
        hal_write32(0x3U, base_va + LMEM_WDT_INT_EN);
    }

    /*  Enable WDT interrupts except of the global enable bit */
    hal_write32((0xffffffffU & ~(WDT_INT_EN_BIT)), base_va + WDT_INT_EN);
}

/**
 * @brief       Clear the WDT interrupt control and status registers
 * @param[in]   base_va Base address of HIF register space (virtual)
 */
void pfe_wdt_cfg_fini(addr_t base_va)
{
    uint32 reg;

    /*  Disable and clear WDT interrupts */
    hal_write32(0x0U, base_va + WDT_INT_EN);
    reg = hal_read32(base_va + WDT_INT_SRC);
    hal_write32(reg, base_va + WDT_INT_SRC);
}

#if defined(PFE_CFG_TEXT_STATS)
/**
 * @brief       Get WDT statistics in text form
 * @details     This is a HW-specific function providing detailed text statistics
 *              about the WDT block.
 * @param[in]   base_va     Base address of WDT register space (virtual)
 * @param[in]   buf         Pointer to the buffer to write to
 * @param[in]   size        Buffer length
 * @param[in]   verb_level  Verbosity level
 * @return      Number of bytes written to the buffer
 */
uint32 pfe_wdt_cfg_get_text_stat(addr_t base_va, char_t *buf, uint32 size, uint8 verb_level)
{
    uint32 len = 0U;

#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va) || (NULL == buf))
    {
        NXP_LOG_ERROR("NULL argument received (pfe_wdt_cfg_get_text_stat)\n");
        len = 0U;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        if(verb_level >= 9U)
        {
            len += (uint32)oal_util_snprintf(buf + len, size - len, "base_va              : 0x%x\n", (uint_t)base_va);
            /*  Get version of wsp (wdt is part of wsp)*/
            len += (uint32)oal_util_snprintf(buf + len, size - len, "WSP Version          : 0x%x\n", hal_read32(base_va + WSP_VERSION));
        }
            len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_INT_EN           : 0x%x\n", hal_read32(base_va + WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "CLASS_WDT_INT_EN     : 0x%x\n", hal_read32(base_va + CLASS_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "UPE_WDT_INT_EN       : 0x%x\n", hal_read32(base_va + UPE_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HGPI_WDT_INT_EN      : 0x%x\n", hal_read32(base_va + HGPI_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HIF_WDT_INT_EN       : 0x%x\n", hal_read32(base_va + HIF_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "TLITE_WDT_INT_EN     : 0x%x\n", hal_read32(base_va + TLITE_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "HNCPY_WDT_INT_EN     : 0x%x\n", hal_read32(base_va + HNCPY_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "BMU1_WDT_INT_EN      : 0x%x\n", hal_read32(base_va + BMU1_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "BMU2_WDT_INT_EN      : 0x%x\n", hal_read32(base_va + BMU2_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "EMAC0_WDT_INT_EN     : 0x%x\n", hal_read32(base_va + EMAC0_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "EMAC1_WDT_INT_EN     : 0x%x\n", hal_read32(base_va + EMAC1_WDT_INT_EN));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "EMAC2_WDT_INT_EN     : 0x%x\n", hal_read32(base_va + EMAC2_WDT_INT_EN));
            if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
            {
                len += (uint32)oal_util_snprintf(buf + len, size - len, "EXT_GPT_WDT_INT_EN   : 0x%x\n", hal_read32(base_va + EXT_GPT_WDT_INT_EN));
                len += (uint32)oal_util_snprintf(buf + len, size - len, "LMEM_WDT_INT_EN      : 0x%x\n", hal_read32(base_va + LMEM_WDT_INT_EN));
            }
            len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_INT_SRC          : 0x%x\n", hal_read32(base_va + WDT_INT_SRC));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_UPE    : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_UPE));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_BMU    : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_BMU));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_HIF    : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_HIF));
            len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_TLITE  : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_TLITE));
            if (TRUE == pfe_feature_mgr_is_available(PFE_HW_FEATURE_RUN_ON_G3))
            {
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_HIF_NCPY 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_HIF_NCPY));
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_CLASS  : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_CLASS));
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_GPI    : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_GPI));
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_GPT    : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_GPT));
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_LMEM   : 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_LMEM));
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WDT_TIMER_VAL_RT_LMEM: 0x%x\n", hal_read32(base_va + WDT_TIMER_VAL_ROUTE_LMEM));
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WSP_DBUG_BUS1_G3     : 0x%x\n", hal_read32(base_va + WSP_DBUG_BUS1_G3));
            }
            else
            {
                len += (uint32)oal_util_snprintf(buf + len, size - len, "WSP_DBUG_BUS1        : 0x%x\n", hal_read32(base_va + WSP_DBUG_BUS1));
            }
    }

    return len;
}
#endif /* defined(PFE_CFG_TEXT_STATS) */

/**
 * @brief       Get Wdt statistic in numeric form
 * @details     This is a HW-specific function providing single statistic
 *              value from the Wdt block.
 * @param[in]   base_va     Base address of Wdt register space (virtual)
 * @param[in]   stat_id     ID of required statistic (offset of register)
 * @return      Value of requested statistic , otherwise PFE_INVALID_STAT if base_va is NULL
 */
uint32 pfe_wdt_cfg_get_stat_value(addr_t base_va, uint32 stat_id)
{
    uint32 stat_value;
#if defined(PFE_CFG_NULL_ARG_CHECK)
    if (unlikely(NULL_ADDR == base_va))
    {
        NXP_LOG_ERROR("NULL argument received\n");
        stat_value = PFE_INVALID_STAT;
    }
    else
#endif /* PFE_CFG_NULL_ARG_CHECK */
    {
        stat_value = hal_read32(base_va + stat_id);
    }
    return stat_value;
}

#define ETH_43_PFE_STOP_SEC_CODE
#include "Eth_43_PFE_MemMap.h"
#endif


